{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc51837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn import svm\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import pickle\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f5e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_type = {'1':'Gratitude','2':'About Recipe','3':'About Video','4':'Praising Chef','5':'Hybrid',\n",
    "                '6':'Undefined','7':'Suggestion/Query'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d6e54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thankyou for the video bilkul pasand karta hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mai try kiya aaj delicious recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video ki clarity bahot achi h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bahot beautiful dikh rahe ho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video achi h aur aap bhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yeh saal mein who is watching this video comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kaun si company chilli powder use kar rahe ho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments\n",
       "0  Thankyou for the video bilkul pasand karta hun...\n",
       "1                  Mai try kiya aaj delicious recipe\n",
       "2                      video ki clarity bahot achi h\n",
       "3                       bahot beautiful dikh rahe ho\n",
       "4                           video achi h aur aap bhi\n",
       "5  yeh saal mein who is watching this video comme...\n",
       "6      kaun si company chilli powder use kar rahe ho"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//Test_Data.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b232b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7a6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf627c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "sentences = list(data_df['comments'])\n",
    "for sen in sentences:\n",
    "    comments.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ada4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thankyou for the video bilkul pasand karta hun aapki videos',\n",
       " 'Mai try kiya aaj delicious recipe',\n",
       " 'video ki clarity bahot achi h',\n",
       " 'bahot beautiful dikh rahe ho',\n",
       " 'video achi aur aap bhi',\n",
       " 'yeh saal mein who is watching this video comment like karo',\n",
       " 'kaun si company chilli powder use kar rahe ho']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3025db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\verloop_Hinglish-Bert. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\verloop_Hinglish-Bert were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12100051 -0.30702236  0.17778549 ... -0.03112733 -0.43440607\n",
      "  -0.15938774]\n",
      " [-0.00626889 -0.21276009  0.3372688  ...  0.42898044 -0.36675984\n",
      "  -0.26373821]\n",
      " [-0.21520971 -0.30725047  0.37495995 ... -0.06397274  0.07015433\n",
      "  -0.249461  ]\n",
      " ...\n",
      " [-0.0346365  -0.41711336  0.30021864 ... -0.04054578  0.17144695\n",
      "  -0.22335693]\n",
      " [-0.43569008 -0.302707    0.17271754 ...  0.220048   -0.24916384\n",
      "  -0.14671196]\n",
      " [-0.50334793 -0.11135657  0.17930578 ... -0.00080812 -0.12539728\n",
      "  -0.09804695]]\n"
     ]
    }
   ],
   "source": [
    "# Converting comments to vectors through Verloop BERT Hinglish\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('verloop/Hinglish-Bert')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b32f164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.692131  , -0.35720742, -0.71820533, ..., -0.6008675 ,\n",
       "        -1.3717283 ,  0.5539496 ],\n",
       "       [ 1.2260015 ,  0.719132  ,  1.1104636 , ...,  2.0965326 ,\n",
       "        -1.0393343 , -1.3354238 ],\n",
       "       [ 0.25375557, -0.35981208,  1.5426382 , ..., -0.7934251 ,\n",
       "         1.1075345 , -1.0769199 ],\n",
       "       ...,\n",
       "       [ 1.0940009 , -1.6142881 ,  0.6856387 , ..., -0.6560836 ,\n",
       "         1.6052569 , -0.60427886],\n",
       "       [-0.7721863 , -0.30793202, -0.77631545, ...,  0.8716578 ,\n",
       "        -0.4615019 ,  0.7834577 ],\n",
       "       [-1.0870126 ,  1.8770142 , -0.7007734 , ..., -0.42311996,\n",
       "         0.14665093,  1.6645881 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing the data\n",
    "standard_model = StandardScaler()\n",
    "scaled_data = standard_model.fit_transform(embeddings)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a279a9",
   "metadata": {},
   "source": [
    "### Kabita's Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5adefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kabita_final_model = pickle.load(open(pwd+\"//Final_Models//Kabita_Standard_SVM_Model.sav\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd07de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 4 6 6 7]\n"
     ]
    }
   ],
   "source": [
    "pred = kabita_final_model.predict(scaled_data)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c1c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thankyou for the video bilkul pasand karta hun aapki videos : Gratitude\n",
      "**************************************************\n",
      "Mai try kiya aaj delicious recipe : About Recipe\n",
      "**************************************************\n",
      "video ki clarity bahot achi h : Praising Chef\n",
      "**************************************************\n",
      "bahot beautiful dikh rahe ho : Praising Chef\n",
      "**************************************************\n",
      "video achi h aur aap bhi : Undefined\n",
      "**************************************************\n",
      "yeh saal mein who is watching this video comment like karo : Undefined\n",
      "**************************************************\n",
      "kaun si company chilli powder use kar rahe ho : Suggestion/Query\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(pred)):\n",
    "    print(data_df['comments'][x]+\" : \"+comment_type[str(pred[x])])\n",
    "    print(50*\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77437bc",
   "metadata": {},
   "source": [
    "### Nisha's Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1844aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nisha_final_model = pickle.load(open(pwd+\"//Final_Models//Nisha_Standard_SVM_Model.sav\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "961b498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 4 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "pred = nisha_final_model.predict(scaled_data)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "993cfaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thankyou for the video bilkul pasand karta hun aapki videos : Gratitude\n",
      "**************************************************\n",
      "Mai try kiya aaj delicious recipe : About Recipe\n",
      "**************************************************\n",
      "video ki clarity bahot achi h : Praising Chef\n",
      "**************************************************\n",
      "bahot beautiful dikh rahe ho : Praising Chef\n",
      "**************************************************\n",
      "video achi h aur aap bhi : Praising Chef\n",
      "**************************************************\n",
      "yeh saal mein who is watching this video comment like karo : Undefined\n",
      "**************************************************\n",
      "kaun si company chilli powder use kar rahe ho : Suggestion/Query\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(pred)):\n",
    "    print(data_df['comments'][x]+\" : \"+comment_type[str(pred[x])])\n",
    "    print(50*\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b161e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
