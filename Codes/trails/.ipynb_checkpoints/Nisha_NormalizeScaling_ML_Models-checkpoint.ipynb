{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Nisha//Input//Nisha_dataset_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b63a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of Train-test split, Normalize Scaling\n",
    "def normalize_scaling(x_data, y_data):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.30,random_state=21,stratify=y_data)\n",
    "    # Normalize scaling of train data\n",
    "    normalize_model = Normalizer()\n",
    "    np.set_printoptions(precision=3)\n",
    "    scaled_data_train = normalize_model.fit_transform(x_train)\n",
    "    # Normalize scaling of test data\n",
    "    scaled_data_test = normalize_model.fit_transform(x_test)\n",
    "    return scaled_data_train, scaled_data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" after Standard Scaling is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7326530612244898\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[170   3   0   5  17  15   0]\n",
      " [  1 151  11  18   7  22   0]\n",
      " [  0   9 176  17   1   7   0]\n",
      " [  2  14  15 143  10  25   1]\n",
      " [ 23  18   5  26 124   8   6]\n",
      " [  1  15   2  30   0 134  28]\n",
      " [  1   1   0   0   1  28 179]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.81      0.83       210\n",
      "           2       0.72      0.72      0.72       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.78      0.59      0.67       210\n",
      "           6       0.56      0.64      0.60       210\n",
      "           7       0.84      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   9  31   3   6  19   1]\n",
      " [ 22 127  35  11   8   6   1]\n",
      " [  3   9 183  13   0   2   0]\n",
      " [ 29  29  55  82   3  12   0]\n",
      " [ 46  44  64  16  32   7   1]\n",
      " [ 28  24  78  11   3  52  14]\n",
      " [  8   3  56   0   1  20 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.67      0.58       210\n",
      "           2       0.52      0.60      0.56       210\n",
      "           3       0.36      0.87      0.51       210\n",
      "           4       0.60      0.39      0.47       210\n",
      "           5       0.60      0.15      0.24       210\n",
      "           6       0.44      0.25      0.32       210\n",
      "           7       0.88      0.58      0.70       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.48      1470\n",
      "weighted avg       0.56      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137  24   9   5   3  28   4]\n",
      " [ 17 138  25  13   4  12   1]\n",
      " [  3  19 178   6   1   3   0]\n",
      " [ 20  31  35  87   3  33   1]\n",
      " [ 42  46  28  26  26  39   3]\n",
      " [ 21  54  22  14   2  82  15]\n",
      " [  6  11  12   1   1  67 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.65      0.60       210\n",
      "           2       0.43      0.66      0.52       210\n",
      "           3       0.58      0.85      0.69       210\n",
      "           4       0.57      0.41      0.48       210\n",
      "           5       0.65      0.12      0.21       210\n",
      "           6       0.31      0.39      0.35       210\n",
      "           7       0.82      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.56      0.52      0.50      1470\n",
      "weighted avg       0.56      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133  17  16   7   4  29   4]\n",
      " [ 13 128  31  13   9  16   0]\n",
      " [  2  18 182   4   1   3   0]\n",
      " [ 11  28  38  94   2  36   1]\n",
      " [ 29  58  29  27  26  39   2]\n",
      " [ 18  36  39  18   4  79  16]\n",
      " [  4  10  10   3   0  72 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.63      0.63       210\n",
      "           2       0.43      0.61      0.51       210\n",
      "           3       0.53      0.87      0.66       210\n",
      "           4       0.57      0.45      0.50       210\n",
      "           5       0.57      0.12      0.20       210\n",
      "           6       0.29      0.38      0.33       210\n",
      "           7       0.83      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.50      1470\n",
      "weighted avg       0.55      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126  26  12   3   4  38   1]\n",
      " [  7 136  25  12   3  27   0]\n",
      " [  1  21 175   7   3   3   0]\n",
      " [ 11  38  32  93   2  33   1]\n",
      " [ 32  60  29  27  16  45   1]\n",
      " [ 15  57  18  18   3  87  12]\n",
      " [  3  16  10   4   0  72 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.60      0.62       210\n",
      "           2       0.38      0.65      0.48       210\n",
      "           3       0.58      0.83      0.68       210\n",
      "           4       0.57      0.44      0.50       210\n",
      "           5       0.52      0.08      0.13       210\n",
      "           6       0.29      0.41      0.34       210\n",
      "           7       0.88      0.50      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.48      1470\n",
      "weighted avg       0.55      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  26  10   5   3  46   0]\n",
      " [  8 135  26  13   2  26   0]\n",
      " [  1  17 177   9   0   6   0]\n",
      " [ 11  31  36  86   4  41   1]\n",
      " [ 33  55  26  25  15  54   2]\n",
      " [ 14  57  21  13   1  93  11]\n",
      " [  3  16   8   3   0  78 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.57      0.60       210\n",
      "           2       0.40      0.64      0.49       210\n",
      "           3       0.58      0.84      0.69       210\n",
      "           4       0.56      0.41      0.47       210\n",
      "           5       0.60      0.07      0.13       210\n",
      "           6       0.27      0.44      0.34       210\n",
      "           7       0.88      0.49      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.48      1470\n",
      "weighted avg       0.56      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.48639455782312924\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  20   8   7   4  50   0]\n",
      " [  7 125  29  14   6  29   0]\n",
      " [  3  18 168  12   2   7   0]\n",
      " [  8  28  27  89   7  50   1]\n",
      " [ 33  52  28  18  14  64   1]\n",
      " [ 13  49  23  14   0 102   9]\n",
      " [  2  17  10   2   0  83  96]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.58      0.61       210\n",
      "           2       0.40      0.60      0.48       210\n",
      "           3       0.57      0.80      0.67       210\n",
      "           4       0.57      0.42      0.49       210\n",
      "           5       0.42      0.07      0.12       210\n",
      "           6       0.26      0.49      0.34       210\n",
      "           7       0.90      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.54      0.49      0.47      1470\n",
      "weighted avg       0.54      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.527891156462585\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[134   2  11  45   6  10   2]\n",
      " [ 15 129  53   7   4   1   1]\n",
      " [  1   8 196   3   1   0   1]\n",
      " [  9  37  58  80  16   8   2]\n",
      " [ 60  20   4  79  29  14   4]\n",
      " [ 14  36  61  19   6  26  48]\n",
      " [  3   4   3   3   5  10 182]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.55      0.61      0.58       210\n",
      "           3       0.51      0.93      0.66       210\n",
      "           4       0.34      0.38      0.36       210\n",
      "           5       0.43      0.14      0.21       210\n",
      "           6       0.38      0.12      0.19       210\n",
      "           7       0.76      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.50      0.53      0.49      1470\n",
      "weighted avg       0.50      0.53      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[164   4  11   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 31  18   8  22 124   4   3]\n",
      " [  5  28  47  27   2  77  24]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.78      0.78       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.72      0.59      0.65       210\n",
      "           6       0.65      0.37      0.47       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7360544217687075\n",
      "Confusion Matrix of SVM is:\n",
      " [[164   1   0   1  25  19   0]\n",
      " [  1 153  12  16   4  24   0]\n",
      " [  0   8 178  17   1   6   0]\n",
      " [  2  17  15 134  11  30   1]\n",
      " [ 20  20   6  20 136   3   5]\n",
      " [  1  11   5  19   1 144  29]\n",
      " [  0   1   0   0   1  35 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.78      0.82       210\n",
      "           2       0.73      0.73      0.73       210\n",
      "           3       0.82      0.85      0.84       210\n",
      "           4       0.65      0.64      0.64       210\n",
      "           5       0.76      0.65      0.70       210\n",
      "           6       0.55      0.69      0.61       210\n",
      "           7       0.83      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of SVM is:\n",
      " [[128   4   1   3  31  43   0]\n",
      " [  4 132  12  20  18  23   1]\n",
      " [  0  13 165  16   5  11   0]\n",
      " [  3  12  12 121  19  42   1]\n",
      " [ 16  14   5  33 110  29   3]\n",
      " [  7  13   5  16   3 144  22]\n",
      " [  0   2   0   1   1  48 158]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.61      0.70       210\n",
      "           2       0.69      0.63      0.66       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.58      0.58      0.58       210\n",
      "           5       0.59      0.52      0.55       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.85      0.75      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   4   0   4  29  17   0]\n",
      " [  1 154   9  18   8  20   0]\n",
      " [  0  13 167  18   3   9   0]\n",
      " [  2  16  12 140  11  28   1]\n",
      " [ 17  18   5  25 132   7   6]\n",
      " [  4  15   2  23   0 139  27]\n",
      " [  0   1   0   1   1  31 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.74      0.80       210\n",
      "           2       0.70      0.73      0.71       210\n",
      "           3       0.86      0.80      0.82       210\n",
      "           4       0.61      0.67      0.64       210\n",
      "           5       0.72      0.63      0.67       210\n",
      "           6       0.55      0.66      0.60       210\n",
      "           7       0.84      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.73      1470\n",
      "weighted avg       0.73      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   4   1   2  24  16   1]\n",
      " [  1 129  29  25   5  21   0]\n",
      " [  0   5 181  17   1   6   0]\n",
      " [  1  15  20 135  10  23   6]\n",
      " [ 60  21  12  24  84   5   4]\n",
      " [  1  10   5  35   1 124  34]\n",
      " [  0   2   0   1   0  32 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.77      0.74       210\n",
      "           2       0.69      0.61      0.65       210\n",
      "           3       0.73      0.86      0.79       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.67      0.40      0.50       210\n",
      "           6       0.55      0.59      0.57       210\n",
      "           7       0.80      0.83      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.19931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [127   0  83   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.15      0.20      0.12      1470\n",
      "weighted avg       0.15      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25510204081632654\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   0   0   0   0   0 128]\n",
      " [  1   0   3   0   0   0 206]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   0   0 205]\n",
      " [ 64   0   1   0   0   0 145]\n",
      " [  1   0   0   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.24      0.26      0.19      1470\n",
      "weighted avg       0.24      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   0   0   0  56   0  44]\n",
      " [  2   0   3   0   0   0 205]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   3   0 202]\n",
      " [ 69   0   1   0  61   0  79]\n",
      " [  2   0   0   0   1   0 207]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.50      0.29      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      1.00      0.33       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.26      1470\n",
      "weighted avg       0.32      0.32      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  44   0   0  44   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  3 201   2   0   3   0   1]\n",
      " [ 59  77   1   0  71   0   2]\n",
      " [  1 199   0   0   2   0   8]\n",
      " [  0 134   0   0   0   0  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.21      0.97      0.34       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.34      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.46      0.38      0.35      1470\n",
      "weighted avg       0.46      0.38      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  44   0   0  68   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  0 201   2   0   6   0   1]\n",
      " [ 17  76   1   0 113   0   3]\n",
      " [  0 197   0   0   3   0  10]\n",
      " [  0 110   0   0   0   1  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.47      0.60       210\n",
      "           2       0.21      0.97      0.35       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.54      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.49      0.41      0.38      1470\n",
      "weighted avg       0.49      0.41      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4170068027210884\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   0   0   0  70  44   0]\n",
      " [  1  27   3   0   1 177   1]\n",
      " [  0   0  83   0   0 127   0]\n",
      " [  0   0   2   0   6 201   1]\n",
      " [ 13  13   1   0 117  63   3]\n",
      " [  0   0   0   0   3 197  10]\n",
      " [  0   0   0   0   6 111  93]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.46      0.60       210\n",
      "           2       0.68      0.13      0.22       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.58      0.56      0.57       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.44      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.59      0.42      0.41      1470\n",
      "weighted avg       0.59      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44625850340136053\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   1   0   1  41  43   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  35  83   0   0  92   0]\n",
      " [  3  14   2   0   3 187   1]\n",
      " [ 46  25   1   1  83  51   3]\n",
      " [  1   2   0   0   2 195  10]\n",
      " [  0   1   0   0   3 110  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.49      0.36      0.41       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.62      0.40      0.48       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.44      1470\n",
      "weighted avg       0.55      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   0  43  43   0]\n",
      " [  1  74  29   1   1 104   0]\n",
      " [  0   0 118   0   0  92   0]\n",
      " [  3   1  15   0   3 187   1]\n",
      " [ 45  19   9   3  82  49   3]\n",
      " [  1   0   2   0   2 195  10]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.77      0.35      0.48       210\n",
      "           3       0.68      0.56      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.39      0.48       210\n",
      "           6       0.25      0.93      0.39       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.56      0.47      0.46      1470\n",
      "weighted avg       0.56      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.482312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  44  43   0]\n",
      " [  1  80  25   0   1 102   1]\n",
      " [  0   0 134   0   0  76   0]\n",
      " [  3   1  16   0   3 186   1]\n",
      " [ 44  19   9   3  83  49   3]\n",
      " [  1   0   3   0   2 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64       210\n",
      "           2       0.78      0.38      0.51       210\n",
      "           3       0.72      0.64      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.40      0.48       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.47      1470\n",
      "weighted avg       0.56      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   0   0  43  44   0]\n",
      " [  1  94  12   0   2 100   1]\n",
      " [  0  14 126   0   0  70   0]\n",
      " [  3  10   7   0   3 186   1]\n",
      " [ 47  21   3   1  86  49   3]\n",
      " [  1   2   1   0   2 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64       210\n",
      "           2       0.66      0.45      0.53       210\n",
      "           3       0.85      0.60      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.41      0.49       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.56      0.49      0.48      1470\n",
      "weighted avg       0.56      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   0  18  44   0]\n",
      " [  1  93  10   2   5  98   1]\n",
      " [  0  11 129   0   0  70   0]\n",
      " [  4  10   7  16   2 170   1]\n",
      " [ 53  16   5   5  81  47   3]\n",
      " [  2   2   1   0   1 194  10]\n",
      " [  0   1   0   0   4 110  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.61      0.71       210\n",
      "           4       0.70      0.08      0.14       210\n",
      "           5       0.73      0.39      0.50       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.69      0.51      0.52      1470\n",
      "weighted avg       0.69      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   1  16  45   0]\n",
      " [  1  92  11   4   5  96   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  4  10   7  38   2 148   1]\n",
      " [ 55  19   4   4  79  46   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.81      0.18      0.30       210\n",
      "           5       0.74      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   3  15  43   0]\n",
      " [  2  90  12   3   4  98   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11   9  43   2 139   1]\n",
      " [ 54  19   4  11  76  43   3]\n",
      " [  2   1   2   1   1 193  10]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.43      0.53       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.70      0.20      0.32       210\n",
      "           5       0.75      0.36      0.49       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  18  37   0]\n",
      " [  2  92  11   4   4  97   0]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11  10  42   3 139   0]\n",
      " [ 51  19   4   7  88  39   2]\n",
      " [  2   1   2   1   1 194   9]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.78      0.20      0.32       210\n",
      "           5       0.75      0.42      0.54       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.90      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.71      0.54      0.55      1470\n",
      "weighted avg       0.71      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  20  35   0]\n",
      " [  2 106  11   1   6  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  17   9  43   3 133   0]\n",
      " [ 49  20   4   7  89  39   2]\n",
      " [  2   5   2   1   1 189  10]\n",
      " [  0   1   0   0   3 110  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.83      0.20      0.33       210\n",
      "           5       0.73      0.42      0.54       210\n",
      "           6       0.29      0.90      0.43       210\n",
      "           7       0.88      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.71      0.55      0.56      1470\n",
      "weighted avg       0.71      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   2  17  34   0]\n",
      " [  2 106  11   2   5  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  16  10  42   4 133   0]\n",
      " [ 54  21   4   6  90  32   3]\n",
      " [  2   5   2   1   1 190   9]\n",
      " [  0   1   0   0   4 111  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.74      0.43      0.54       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   0   0   0  22  32   0]\n",
      " [  2 104  13   2   6  82   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  11  44   3 131   0]\n",
      " [ 54  22   5   7  89  30   3]\n",
      " [  2   5   2   1   1 189  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.82      0.67      0.73       210\n",
      "           4       0.81      0.21      0.33       210\n",
      "           5       0.71      0.42      0.53       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.87      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.56      1470\n",
      "weighted avg       0.70      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   2  27  32   0]\n",
      " [  2 105  13   2   4  83   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  12  42   3 131   1]\n",
      " [ 50  21   5   6  92  30   6]\n",
      " [  2   4   2   1   1 188  12]\n",
      " [  0   1   0   0   4 105 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.71       210\n",
      "           2       0.67      0.50      0.57       210\n",
      "           3       0.81      0.67      0.73       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.83      0.48      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.69      0.56      0.56      1470\n",
      "weighted avg       0.69      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   0   1  23  34   0]\n",
      " [  2 104  11   2   7  83   1]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  15  13  41   4 130   2]\n",
      " [ 49  19   5   5  96  30   6]\n",
      " [  2   4   2   1   1 183  17]\n",
      " [  0   1   0   0   3  95 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.70      0.50      0.58       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.81      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   0  23  30   0]\n",
      " [  2 105  12   3   6  82   0]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  12  13  42   6 130   2]\n",
      " [ 47  18   5   5  97  32   6]\n",
      " [  3   5   2   1   1 183  15]\n",
      " [  0   1   0   0   4 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.71      0.50      0.59       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.82      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.57      1470\n",
      "weighted avg       0.70      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5680272108843537\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   4   1   2  23  35   2]\n",
      " [  1  91   6  21  17  73   1]\n",
      " [  2   0 124   3   0  81   0]\n",
      " [  4  10   3  92  15  83   3]\n",
      " [ 59  20   1  21  86  17   6]\n",
      " [  4   6   1  30   3 142  24]\n",
      " [  0   2   0   1   3  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.68      0.68       210\n",
      "           2       0.68      0.43      0.53       210\n",
      "           3       0.91      0.59      0.72       210\n",
      "           4       0.54      0.44      0.48       210\n",
      "           5       0.59      0.41      0.48       210\n",
      "           6       0.30      0.68      0.41       210\n",
      "           7       0.81      0.75      0.78       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.64      0.57      0.58      1470\n",
      "weighted avg       0.64      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   3  10  18  25   1]\n",
      " [  1 119   7  23   4  55   1]\n",
      " [  1   0 134   5   0  70   0]\n",
      " [  5  15   9 114  10  55   2]\n",
      " [ 65  22   2  22  81  13   5]\n",
      " [  3  12   4  41   3 119  28]\n",
      " [  0   5   1   9   1  32 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.69       210\n",
      "           2       0.68      0.57      0.62       210\n",
      "           3       0.84      0.64      0.72       210\n",
      "           4       0.51      0.54      0.53       210\n",
      "           5       0.69      0.39      0.50       210\n",
      "           6       0.32      0.57      0.41       210\n",
      "           7       0.81      0.77      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.65      0.60      0.61      1470\n",
      "weighted avg       0.65      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   2   4  22  32   1]\n",
      " [  1 117   7  20   7  57   1]\n",
      " [  0   0 134   3   1  72   0]\n",
      " [  3  15   6 110  13  61   2]\n",
      " [ 52  23   2  20  95  13   5]\n",
      " [  2  15   1  30   2 135  25]\n",
      " [  0   5   0   1   1  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.66      0.56      0.60       210\n",
      "           3       0.88      0.64      0.74       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.67      0.45      0.54       210\n",
      "           6       0.33      0.64      0.44       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.67      0.61      0.63      1470\n",
      "weighted avg       0.67      0.61      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   2   1   4  19  34   2]\n",
      " [  1 116  19  20  10  43   1]\n",
      " [  0   0 148   3   0  59   0]\n",
      " [  4  12  10 117  15  50   2]\n",
      " [ 61  26   4  20  81  13   5]\n",
      " [  3  11   2  29   3 135  27]\n",
      " [  0   5   0   1   1  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69       210\n",
      "           2       0.67      0.55      0.61       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.36      0.64      0.46       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   1   1  11  18  28   2]\n",
      " [  1 117  21  24   8  38   1]\n",
      " [  0   0 153   7   0  50   0]\n",
      " [  3  12  11 129  13  41   1]\n",
      " [ 56  27   5  21  89   7   5]\n",
      " [  3  11   2  40   3 126  25]\n",
      " [  0   4   0   8   2  35 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.54      0.61      0.57       210\n",
      "           5       0.67      0.42      0.52       210\n",
      "           6       0.39      0.60      0.47       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  17  35   1]\n",
      " [  1 123  17  20   7  41   1]\n",
      " [  0   1 147   6   0  56   0]\n",
      " [  3  13  10 122  13  48   1]\n",
      " [ 58  23   4  19  89  12   5]\n",
      " [  3  11   2  27   4 138  25]\n",
      " [  0   5   0   0   1  43 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.59      0.63       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.37      0.66      0.47       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   3   2   4  17  33   1]\n",
      " [  1 126  21  19   3  39   1]\n",
      " [  0   1 152   3   0  54   0]\n",
      " [  3  12  11 119  13  50   2]\n",
      " [ 48  25   6  18  97  11   5]\n",
      " [  3  13   3  28   1 136  26]\n",
      " [  0   4   0   0   2  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.71      0.72       210\n",
      "           2       0.68      0.60      0.64       210\n",
      "           3       0.78      0.72      0.75       210\n",
      "           4       0.62      0.57      0.59       210\n",
      "           5       0.73      0.46      0.57       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   3   2   3  17  33   1]\n",
      " [  1 134  11  19   5  39   1]\n",
      " [  0   9 144   2   0  55   0]\n",
      " [  4  14  10 119  11  50   2]\n",
      " [ 47  29   3  18  98  10   5]\n",
      " [  3  13   1  22   3 145  23]\n",
      " [  0   5   0   1   1  37 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.65      0.64      0.64       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.73      0.47      0.57       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.66      1470\n",
      "weighted avg       0.69      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   2   3  21  29   0]\n",
      " [  1 134  12  17   5  40   1]\n",
      " [  0   9 144   5   0  52   0]\n",
      " [  4  12  11 118  11  52   2]\n",
      " [ 58  26   2  17  92  10   5]\n",
      " [  4  13   1  25   2 142  23]\n",
      " [  0   5   0   0   1  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.71       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.84      0.69      0.75       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.39      0.68      0.49       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   4  23  25   0]\n",
      " [  1 133  11  19   3  42   1]\n",
      " [  0   9 144   4   0  53   0]\n",
      " [  3  15   9 119  11  51   2]\n",
      " [ 46  26   2  19 103   9   5]\n",
      " [  4  10   1  22   2 149  22]\n",
      " [  0   5   0   0   1  36 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       210\n",
      "           2       0.67      0.63      0.65       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.64      0.57      0.60       210\n",
      "           5       0.72      0.49      0.58       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.85      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   2  22  26   0]\n",
      " [  1 136  10  18   2  42   1]\n",
      " [  0   9 144   3   0  54   0]\n",
      " [  3  16   9 121  12  47   2]\n",
      " [ 41  23   1  17 113  10   5]\n",
      " [  3  10   1  18   3 153  22]\n",
      " [  0   1   0   0   3  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.86      0.69      0.76       210\n",
      "           4       0.68      0.58      0.62       210\n",
      "           5       0.73      0.54      0.62       210\n",
      "           6       0.42      0.73      0.53       210\n",
      "           7       0.85      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   2   4  19  25   1]\n",
      " [  1 140  11  18   3  36   1]\n",
      " [  0   8 145   2   0  55   0]\n",
      " [  3  16  10 121  10  47   3]\n",
      " [ 51  26   1  17 100  10   5]\n",
      " [  3  10   2  17   3 150  25]\n",
      " [  0   5   0   1   2  29 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.68      0.67      0.67       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.73      0.48      0.58       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   3  22  27   0]\n",
      " [  1 137  13  17   4  37   1]\n",
      " [  0  10 146   5   0  49   0]\n",
      " [  4  14  10 123   9  48   2]\n",
      " [ 53  25   1  19  98   9   5]\n",
      " [  3  10   1  17   2 154  23]\n",
      " [  0   1   0   1   2  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.85      0.70      0.76       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.72      0.47      0.56       210\n",
      "           6       0.43      0.73      0.54       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   1   3  21  26   0]\n",
      " [  1 138  11  17   4  38   1]\n",
      " [  0  12 145   2   0  51   0]\n",
      " [  2  16  10 120  13  47   2]\n",
      " [ 47  24   1  20 102  11   5]\n",
      " [  3  13   2  14   3 150  25]\n",
      " [  0   2   0   0   2  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.67      0.66      0.66       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.70      0.49      0.57       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.84      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   1   2   1  19  24   0]\n",
      " [  1 140  10  17   5  36   1]\n",
      " [  0   9 148   1   0  52   0]\n",
      " [  3  13  11 117  14  50   2]\n",
      " [ 48  23   1  18 107   8   5]\n",
      " [  3  11   1  18   2 153  22]\n",
      " [  0   3   0   1   1  39 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.78      0.76       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.72      0.51      0.60       210\n",
      "           6       0.42      0.73      0.53       210\n",
      "           7       0.85      0.79      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   3  24  24   0]\n",
      " [  1 141  12  16   3  36   1]\n",
      " [  0  12 145   3   0  50   0]\n",
      " [  2  14   9 117  14  52   2]\n",
      " [ 41  22   2  20 111   9   5]\n",
      " [  2  12   1  18   3 149  25]\n",
      " [  0   4   0   2   1  35 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.76       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   5  23  24   0]\n",
      " [  1 140  11  17   5  35   1]\n",
      " [  0  12 146   5   0  47   0]\n",
      " [  3  13  11 120  12  49   2]\n",
      " [ 42  24   1  19 112   7   5]\n",
      " [  3  11   1  24   3 143  25]\n",
      " [  0   4   0   1   2  34 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.68      0.67      0.67       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   2   3  25  22   1]\n",
      " [  1 138  12  15   7  36   1]\n",
      " [  0  11 146   5   0  48   0]\n",
      " [  3  13  11 119  13  49   2]\n",
      " [ 47  22   1  20 105   9   6]\n",
      " [  3  11   2  20   3 149  22]\n",
      " [  0   1   0   0   3  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.67      0.50      0.57       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   2   4  24  26   0]\n",
      " [  1 144  10  16   3  35   1]\n",
      " [  0  13 145   4   0  48   0]\n",
      " [  2  14   9 124  13  46   2]\n",
      " [ 44  21   1  21 112   6   5]\n",
      " [  3  12   1  19   2 148  25]\n",
      " [  0   1   0   4   2  33 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.70      0.69      0.69       210\n",
      "           3       0.86      0.69      0.77       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.43      0.70      0.54       210\n",
      "           7       0.84      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   5  23  23   0]\n",
      " [  1 143  10  17   3  35   1]\n",
      " [  0  12 148   4   0  46   0]\n",
      " [  3  13  10 125  12  44   3]\n",
      " [ 36  22   1  20 117   9   5]\n",
      " [  3  10   2  22   2 147  24]\n",
      " [  0   0   0   1   2  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.71      0.68      0.70       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.74      0.56      0.63       210\n",
      "           6       0.43      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[166   3   0   5  23  12   1]\n",
      " [ 13 154  10  11  18   4   0]\n",
      " [  5  14 168  18   5   0   0]\n",
      " [ 16   8  13 133  29  11   0]\n",
      " [ 20  20   2  35 114  15   4]\n",
      " [ 36  21   5  32   4  79  33]\n",
      " [  2   1   1   0   0  30 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.79      0.71       210\n",
      "           2       0.70      0.73      0.71       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.59      0.54      0.57       210\n",
      "           6       0.52      0.38      0.44       210\n",
      "           7       0.82      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[169   1   0   5  16  17   2]\n",
      " [  1 141  22  19   4  22   1]\n",
      " [  0   7 178  17   0   8   0]\n",
      " [  2  14  20 140   9  19   6]\n",
      " [ 29  21   6  23 122   4   5]\n",
      " [  2  12   6  33   1 123  33]\n",
      " [  0   1   2   0   1  26 180]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.80      0.82       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.76      0.85      0.80       210\n",
      "           4       0.59      0.67      0.63       210\n",
      "           5       0.80      0.58      0.67       210\n",
      "           6       0.56      0.59      0.57       210\n",
      "           7       0.79      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158  10  16   2  12  12   0]\n",
      " [ 17 135  40   8   6   4   0]\n",
      " [  4  13 177  13   0   3   0]\n",
      " [ 31  30  62  65   3  19   0]\n",
      " [ 72  38  44   9  41   5   1]\n",
      " [ 23  27  75  13   2  60  10]\n",
      " [ 10   6  45   4   2  21 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60       210\n",
      "           2       0.52      0.64      0.58       210\n",
      "           3       0.39      0.84      0.53       210\n",
      "           4       0.57      0.31      0.40       210\n",
      "           5       0.62      0.20      0.30       210\n",
      "           6       0.48      0.29      0.36       210\n",
      "           7       0.92      0.58      0.71       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.57      0.52      0.50      1470\n",
      "weighted avg       0.57      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157  14   7   5   8  18   1]\n",
      " [ 11 138  30  10   5  16   0]\n",
      " [  3  12 183   7   0   5   0]\n",
      " [ 26  31  36  77   5  35   0]\n",
      " [ 70  53  23  11  32  21   0]\n",
      " [ 24  24  18  16   2 116  10]\n",
      " [  8  14  12   3   1  61 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.75      0.62       210\n",
      "           2       0.48      0.66      0.56       210\n",
      "           3       0.59      0.87      0.71       210\n",
      "           4       0.60      0.37      0.45       210\n",
      "           5       0.60      0.15      0.24       210\n",
      "           6       0.43      0.55      0.48       210\n",
      "           7       0.91      0.53      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.53      1470\n",
      "weighted avg       0.59      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154  16   4   6   8  21   1]\n",
      " [  7 131  34  14   5  19   0]\n",
      " [  1  14 183   6   0   6   0]\n",
      " [ 20  29  37  81   5  38   0]\n",
      " [ 59  52  25  12  39  23   0]\n",
      " [ 19  21  19  18   3 121   9]\n",
      " [  6  10  14   4   0  61 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.73      0.65       210\n",
      "           2       0.48      0.62      0.54       210\n",
      "           3       0.58      0.87      0.70       210\n",
      "           4       0.57      0.39      0.46       210\n",
      "           5       0.65      0.19      0.29       210\n",
      "           6       0.42      0.58      0.48       210\n",
      "           7       0.92      0.55      0.69       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.60      0.56      0.54      1470\n",
      "weighted avg       0.60      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149  17  12   6   8  18   0]\n",
      " [  8 131  40  13   4  14   0]\n",
      " [  0  14 188   5   0   3   0]\n",
      " [ 13  38  40  75   6  38   0]\n",
      " [ 62  49  29  10  37  22   1]\n",
      " [ 14  23  46  16   1 102   8]\n",
      " [  6  11  17   4   0  62 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.71      0.65       210\n",
      "           2       0.46      0.62      0.53       210\n",
      "           3       0.51      0.90      0.65       210\n",
      "           4       0.58      0.36      0.44       210\n",
      "           5       0.66      0.18      0.28       210\n",
      "           6       0.39      0.49      0.43       210\n",
      "           7       0.92      0.52      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.59      0.54      0.52      1470\n",
      "weighted avg       0.59      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146  18   6   6   8  26   0]\n",
      " [  6 132  33  11   4  23   1]\n",
      " [  0  13 181   7   0   9   0]\n",
      " [ 12  42  34  71   4  47   0]\n",
      " [ 59  42  29   9  40  30   1]\n",
      " [ 12  21  17  19   2 130   9]\n",
      " [  5  10  14   3   0  69 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.70      0.65       210\n",
      "           2       0.47      0.63      0.54       210\n",
      "           3       0.58      0.86      0.69       210\n",
      "           4       0.56      0.34      0.42       210\n",
      "           5       0.69      0.19      0.30       210\n",
      "           6       0.39      0.62      0.48       210\n",
      "           7       0.91      0.52      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146  15   6   4   8  31   0]\n",
      " [  7 126  36  14   2  25   0]\n",
      " [  0  10 176  15   0   9   0]\n",
      " [ 10  37  29  79   4  51   0]\n",
      " [ 59  44  30   9  32  35   1]\n",
      " [  5  15  23  15   1 144   7]\n",
      " [  6   9  11   5   0  75 104]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.70      0.66       210\n",
      "           2       0.49      0.60      0.54       210\n",
      "           3       0.57      0.84      0.68       210\n",
      "           4       0.56      0.38      0.45       210\n",
      "           5       0.68      0.15      0.25       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.93      0.50      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.61      0.55      0.53      1470\n",
      "weighted avg       0.61      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   3  13  80   8   6   0]\n",
      " [ 15 129  53   8   3   1   1]\n",
      " [  1   9 195   3   1   0   1]\n",
      " [  9  37  58  82  17   6   1]\n",
      " [ 61  21   4  84  24  12   4]\n",
      " [ 15  35  62  21   4  24  49]\n",
      " [  4   4   3   4   3  13 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.48      0.48       210\n",
      "           2       0.54      0.61      0.58       210\n",
      "           3       0.50      0.93      0.65       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.40      0.11      0.18       210\n",
      "           6       0.39      0.11      0.18       210\n",
      "           7       0.76      0.85      0.80       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.48      0.50      0.46      1470\n",
      "weighted avg       0.48      0.50      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7217687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   0   0   4  23  22   0]\n",
      " [  1 143  17  22   2  24   1]\n",
      " [  0   8 178  17   0   7   0]\n",
      " [  1  16  20 137   7  28   1]\n",
      " [ 21  20   9  20 130   5   5]\n",
      " [  2  10   6  25   1 137  29]\n",
      " [  0   1   1   0   1  32 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.77      0.81       210\n",
      "           2       0.72      0.68      0.70       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.79      0.62      0.70       210\n",
      "           6       0.54      0.65      0.59       210\n",
      "           7       0.83      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[141   4   0   4  29  31   1]\n",
      " [  1 142  10  17   7  33   0]\n",
      " [  0   9 162  20   2  17   0]\n",
      " [  1  15  10 126  11  47   0]\n",
      " [ 17  16   3  23 115  32   4]\n",
      " [  3   9   1  23   1 156  17]\n",
      " [  1   0   0   0   2  48 159]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.87      0.77      0.82       210\n",
      "           4       0.59      0.60      0.60       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.43      0.74      0.54       210\n",
      "           7       0.88      0.76      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   3   0   4  26  23   1]\n",
      " [  1 157  10  20   1  21   0]\n",
      " [  0  10 170  21   1   8   0]\n",
      " [  1  18  14 138   8  30   1]\n",
      " [ 21  25   3  23 124   8   6]\n",
      " [  2  11   1  31   1 135  29]\n",
      " [  0   0   0   2   1  28 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.73      0.79       210\n",
      "           2       0.70      0.75      0.72       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.58      0.66      0.61       210\n",
      "           5       0.77      0.59      0.67       210\n",
      "           6       0.53      0.64      0.58       210\n",
      "           7       0.83      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6258503401360545\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   0   0   8  50  16   2]\n",
      " [  0 109  33  28  20  20   0]\n",
      " [  0   7 160  35   1   7   0]\n",
      " [  2  20  24 131   6  21   6]\n",
      " [ 54  24  16  17  89   6   4]\n",
      " [  3  11   6  33   0 125  32]\n",
      " [  0   1   3   1   1  32 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.64      0.67       210\n",
      "           2       0.63      0.52      0.57       210\n",
      "           3       0.66      0.76      0.71       210\n",
      "           4       0.52      0.62      0.57       210\n",
      "           5       0.53      0.42      0.47       210\n",
      "           6       0.55      0.60      0.57       210\n",
      "           7       0.80      0.82      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   0   0   0 209]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   0   1   0   0   0 128]\n",
      " [  1   9  18   0   0   0 182]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   0   0 199]\n",
      " [ 63   0   5   0   0   0 142]\n",
      " [  1   0   1   0   0   0 208]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.36      0.28      0.21      1470\n",
      "weighted avg       0.36      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   1   0  41   0  44]\n",
      " [  2   9  18   0   0   0 181]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   3   0 196]\n",
      " [ 71   0   5   0  58   0  76]\n",
      " [  2   0   1   0   1   0 206]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.56      0.28      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      1.00      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.45      0.35      0.29      1470\n",
      "weighted avg       0.45      0.35      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1   0  42  44   0]\n",
      " [  1   9  18   0   1 180   1]\n",
      " [  0   0 108   0   0 102   0]\n",
      " [  3   0   8   0   3 195   1]\n",
      " [ 54   0   5   0  75  74   2]\n",
      " [  1   0   1   0   2 198   8]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.59      0.63       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.36      0.45       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.38      1470\n",
      "weighted avg       0.59      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   1   0   0  37  44   0]\n",
      " [  1  24   3   0   1 180   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 50   4   1   0  79  73   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.47      0.11      0.18       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.38      0.48       210\n",
      "           6       0.22      0.93      0.35       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.55      0.42      0.41      1470\n",
      "weighted avg       0.55      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  43  44   0]\n",
      " [  1  50   3   0   1 154   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 40  16   1   1  88  61   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.65       210\n",
      "           2       0.56      0.24      0.33       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.64      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.57      0.44      0.44      1470\n",
      "weighted avg       0.57      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45918367346938777\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 38  17   1   2  89  60   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   1 110  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.59      0.65       210\n",
      "           2       0.65      0.36      0.46       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.58      0.46      0.46      1470\n",
      "weighted avg       0.58      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   5   0   1 127   1]\n",
      " [  0  12 110   0   0  88   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 35  17   1   2  92  61   2]\n",
      " [  2   1   0   0   1 197   9]\n",
      " [  0   0   0   0   0 111  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.67      0.36      0.47       210\n",
      "           3       0.93      0.52      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.67      0.44      0.53       210\n",
      "           6       0.24      0.94      0.38       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.47      1470\n",
      "weighted avg       0.59      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   0   1  41  44   0]\n",
      " [  1 104   5   1   1  98   0]\n",
      " [  0  26 111   0   0  73   0]\n",
      " [  3  18   2   0   3 183   1]\n",
      " [ 42  28   1   2  89  45   3]\n",
      " [  2   3   0   0   1 194  10]\n",
      " [  0   3   0   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.58      0.64       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.66      0.42      0.52       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  1  88  21   0   2  97   1]\n",
      " [  0  11 131   0   0  68   0]\n",
      " [  5   7  13   0   1 183   1]\n",
      " [ 63  18  11   1  69  45   3]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.69      0.42      0.52       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.33      0.46       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   2   0   0  19  44   0]\n",
      " [  1  93  15   2   3  95   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  4   8  12  22   2 161   1]\n",
      " [ 55  16  11   3  79  44   2]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.71      0.44      0.55       210\n",
      "           3       0.76      0.63      0.69       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.77      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.52      1470\n",
      "weighted avg       0.70      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   0   1  35  43   0]\n",
      " [  1  94  15   4   2  93   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  2   7  16  34   4 146   1]\n",
      " [ 28  17  11   4 105  42   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   2   0   2 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.71      0.45      0.55       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.79      0.16      0.27       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  2  91   8   4   9  96   0]\n",
      " [  0  10 120   0  12  68   0]\n",
      " [  5   7   7  42  11 137   1]\n",
      " [ 52  18   1   5  91  40   3]\n",
      " [  3   1   1   2   1 193   9]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.70      0.43      0.54       210\n",
      "           3       0.88      0.57      0.69       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.62      0.43      0.51       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   2   0   0  22  35   0]\n",
      " [  2  94  11   7   2  94   0]\n",
      " [  0  10 126   6   0  68   0]\n",
      " [  5   7   8  50   2 137   1]\n",
      " [ 56  19   6   9  81  37   2]\n",
      " [  3   1   1   3   0 192  10]\n",
      " [  0   1   0   2   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.70      0.45      0.55       210\n",
      "           3       0.83      0.60      0.70       210\n",
      "           4       0.65      0.24      0.35       210\n",
      "           5       0.76      0.39      0.51       210\n",
      "           6       0.29      0.91      0.44       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   2   0   0  19  37   0]\n",
      " [  2  96  10   1   5  95   1]\n",
      " [  0  12 128   0   2  68   0]\n",
      " [  5   9   9  41   8 137   1]\n",
      " [ 48  22   4   5  91  37   3]\n",
      " [  1   1   1   2   3 193   9]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.67      0.46      0.54       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.29      0.92      0.44       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0   0  25  34   0]\n",
      " [  2 108  10   2   7  81   0]\n",
      " [  0  10 130   0   2  68   0]\n",
      " [  4  17   8  41   9 130   1]\n",
      " [ 50  22   4   5  97  29   3]\n",
      " [  2   6   1   2   2 188   9]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.72       210\n",
      "           2       0.65      0.51      0.58       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.67      0.46      0.55       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   1  30  33   0]\n",
      " [  2 109  11   1   8  78   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  4  17  10  42   9 127   1]\n",
      " [ 44  21   5   4 102  30   4]\n",
      " [  1   6   1   2   3 189   8]\n",
      " [  0   1   0   0   3 108  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.69      0.71       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  26  32   0]\n",
      " [  2 107  11   2   7  80   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  3  16  10  41  11 128   1]\n",
      " [ 46  21   5   6 102  27   3]\n",
      " [  2   5   1   2   2 186  12]\n",
      " [  0   1   0   0   4 103 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.66      0.51      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.80      0.20      0.31       210\n",
      "           5       0.66      0.49      0.56       210\n",
      "           6       0.30      0.89      0.45       210\n",
      "           7       0.86      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  28  36   0]\n",
      " [  2 104  12   3  10  78   1]\n",
      " [  0   8 139   3   1  59   0]\n",
      " [  3  14  12  40  12 127   2]\n",
      " [ 40  18   6   8 103  30   5]\n",
      " [  2   5   1   3   1 181  17]\n",
      " [  0   1   0   0   4  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.69      0.72       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.82      0.66      0.73       210\n",
      "           4       0.70      0.19      0.30       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.82      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.68      0.56      0.57      1470\n",
      "weighted avg       0.68      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0   0  37  32   0]\n",
      " [  2 111  11   2  10  73   1]\n",
      " [  0  10 139   1   1  59   0]\n",
      " [  2  16  10  41  13 126   2]\n",
      " [ 28  23   4   5 122  23   5]\n",
      " [  1   5   1   3   2 184  14]\n",
      " [  0   1   0   0   3  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.65      0.58      0.61       210\n",
      "           6       0.31      0.88      0.46       210\n",
      "           7       0.83      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.58      1470\n",
      "weighted avg       0.70      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   3   2   6  15  19   2]\n",
      " [  1  84  40  27   6  49   3]\n",
      " [  0   0 139   9   0  62   0]\n",
      " [  3  11  11 122  12  47   4]\n",
      " [ 65  20  11  20  79  10   5]\n",
      " [  5   6   1  49   2 120  27]\n",
      " [  0   1   0  13   2  31 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.67      0.40      0.50       210\n",
      "           3       0.68      0.66      0.67       210\n",
      "           4       0.50      0.58      0.54       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.36      0.57      0.44       210\n",
      "           7       0.80      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   2   5  20  21   4]\n",
      " [  1  95  41  22   7  39   5]\n",
      " [  0   7 145   6   0  49   3]\n",
      " [  4  13  12 108  15  40  18]\n",
      " [ 67  20   9  16  81  10   7]\n",
      " [  3  11   1  32   3 118  42]\n",
      " [  0   2   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.64      0.45      0.53       210\n",
      "           3       0.69      0.69      0.69       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.39      0.56      0.46       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   2   7  21  18   1]\n",
      " [  1  96  31  26   5  49   2]\n",
      " [  0   0 140   9   0  61   0]\n",
      " [  3   8  11 135  12  39   2]\n",
      " [ 58  19  10  20  90   7   6]\n",
      " [  2  10   1  37   4 128  28]\n",
      " [  0   4   0   9   1  28 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.69      0.46      0.55       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.68      0.43      0.52       210\n",
      "           6       0.39      0.61      0.47       210\n",
      "           7       0.81      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   6  22  21   1]\n",
      " [  1 101  31  26   4  46   1]\n",
      " [  0   0 147   7   0  56   0]\n",
      " [  3  13  13 125  11  44   1]\n",
      " [ 58  21   5  20  91   9   6]\n",
      " [  2  10   1  29   4 138  26]\n",
      " [  0   1   0   2   4  35 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.48      0.56       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.58      0.60      0.59       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   2   3  24  24   1]\n",
      " [  1 112  30  23   2  41   1]\n",
      " [  0   2 149   6   0  53   0]\n",
      " [  3  12  13 119  12  49   2]\n",
      " [ 59  21   5  19  91   9   6]\n",
      " [  3   9   2  28   3 138  27]\n",
      " [  0   3   0   0   1  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.70      0.53      0.61       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.60      0.57      0.58       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  23  24   2]\n",
      " [  1 108  31  23   4  42   1]\n",
      " [  0   1 149   2   0  58   0]\n",
      " [  4  15  13 115   7  54   2]\n",
      " [ 56  21   5  20  92  11   5]\n",
      " [  3   8   1  21   4 146  27]\n",
      " [  0   4   0   1   0  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.71      0.44      0.54       210\n",
      "           6       0.39      0.70      0.50       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   3  22  24   1]\n",
      " [  1 112  27  23   4  42   1]\n",
      " [  0   0 150   1   0  59   0]\n",
      " [  4  10  13 117  12  52   2]\n",
      " [ 44  23   5  19 101  13   5]\n",
      " [  2   8   1  29   4 137  29]\n",
      " [  0   3   0   1   2  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.71      0.53      0.61       210\n",
      "           3       0.76      0.71      0.74       210\n",
      "           4       0.61      0.56      0.58       210\n",
      "           5       0.70      0.48      0.57       210\n",
      "           6       0.37      0.65      0.48       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  21  27   1]\n",
      " [  1 113  26  22   5  42   1]\n",
      " [  0   1 152   4   0  53   0]\n",
      " [  3  14  13 114  10  54   2]\n",
      " [ 52  25   5  18  93  12   5]\n",
      " [  2   8   1  21   4 148  26]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.40      0.70      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   1   3  23  23   1]\n",
      " [  1 113  31  20   4  40   1]\n",
      " [  0   3 151   3   0  53   0]\n",
      " [  3  12  13 114  13  53   2]\n",
      " [ 50  19   4  20 102  10   5]\n",
      " [  2   9   2  24   4 145  24]\n",
      " [  0   3   0   0   1  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.62      0.54      0.58       210\n",
      "           5       0.69      0.49      0.57       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6448979591836734\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   1   4  23  25   1]\n",
      " [  1 113  30  22   3  40   1]\n",
      " [  0   3 151  10   0  46   0]\n",
      " [  3  13  12 122  10  48   2]\n",
      " [ 51  23   4  20  97  10   5]\n",
      " [  3   8   3  28   3 140  25]\n",
      " [  0   2   0   0   1  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.59      0.58      0.59       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   4  24  24   1]\n",
      " [  1 118  25  22   4  39   1]\n",
      " [  0   1 155   6   0  48   0]\n",
      " [  3  14  12 118  11  50   2]\n",
      " [ 41  25   4  20 105  10   5]\n",
      " [  2   7   3  29   4 138  27]\n",
      " [  0   3   0   0   1  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.69      0.56      0.62       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   1   4  26  24   1]\n",
      " [  1 117  24  21   5  41   1]\n",
      " [  0   1 156   6   0  47   0]\n",
      " [  3  12  13 121  10  49   2]\n",
      " [ 39  20   4  24 110   8   5]\n",
      " [  3   7   1  20   3 147  29]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.73      0.56      0.63       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.71      0.52      0.60       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   1   1   4  27  24   1]\n",
      " [  1 119  25  23   3  38   1]\n",
      " [  0   2 159   5   0  44   0]\n",
      " [  3  14  13 116  11  51   2]\n",
      " [ 45  22   5  22 104   7   5]\n",
      " [  2   7   3  18   4 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.74       210\n",
      "           2       0.72      0.57      0.63       210\n",
      "           3       0.77      0.76      0.76       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   4  28  24   1]\n",
      " [  1 118  24  21   7  38   1]\n",
      " [  0   4 157   6   0  43   0]\n",
      " [  3  15  12 118  10  50   2]\n",
      " [ 39  23   4  18 112   9   5]\n",
      " [  1   7   3  18   5 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75       210\n",
      "           2       0.70      0.56      0.62       210\n",
      "           3       0.78      0.75      0.76       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  29  23   1]\n",
      " [  1 121  25  20   4  38   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  3  13  13 118  11  50   2]\n",
      " [ 36  22   5  17 116   9   5]\n",
      " [  1   8   2  21   4 148  26]\n",
      " [  0   2   0   0   1  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.71      0.75       210\n",
      "           2       0.70      0.58      0.63       210\n",
      "           3       0.78      0.77      0.78       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.55      0.62       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   4  24  23   1]\n",
      " [  1 120  25  21   5  37   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  2  14  13 120  12  47   2]\n",
      " [ 37  20   5  18 116   9   5]\n",
      " [  1   9   3  26   5 140  26]\n",
      " [  0   1   0   0   2  38 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.76       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.71      0.55      0.62       210\n",
      "           6       0.42      0.67      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   1   5  28  22   1]\n",
      " [  1 125  25  18   4  36   1]\n",
      " [  0   5 158  12   0  35   0]\n",
      " [  2  13  13 124  11  45   2]\n",
      " [ 38  22   4  18 114   9   5]\n",
      " [  2   8   3  24   3 144  26]\n",
      " [  0   1   0   0   1  40 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.72      0.75       210\n",
      "           2       0.71      0.60      0.65       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.44      0.69      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   3  27  23   1]\n",
      " [  1 123  24  18   7  36   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 125  11  45   2]\n",
      " [ 36  22   5  20 115   7   5]\n",
      " [  3   8   3  24   3 141  28]\n",
      " [  0   1   0   0   3  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.70      0.59      0.64       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.82      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  26  24   0]\n",
      " [  1 124  26  18   6  34   1]\n",
      " [  0   3 162  11   0  34   0]\n",
      " [  2  13  13 121  13  46   2]\n",
      " [ 37  20   4  18 117   9   5]\n",
      " [  2   7   3  20   3 147  28]\n",
      " [  0   0   0   0   3  36 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.73      0.59      0.65       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.70      0.56      0.62       210\n",
      "           6       0.45      0.70      0.54       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   1   4  24  22   1]\n",
      " [  1 124  24  20   5  35   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 122  12  47   2]\n",
      " [ 36  20   4  22 116   7   5]\n",
      " [  2   8   2  23   4 143  28]\n",
      " [  0   2   0   0   1  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.77       210\n",
      "           2       0.71      0.59      0.64       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.72      0.55      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   2   0   6  25   9   0]\n",
      " [ 13 153  11  14  14   5   0]\n",
      " [  5  11 172  18   4   0   0]\n",
      " [ 17  10  13 135  25  10   0]\n",
      " [ 22  19   1  32 122  10   4]\n",
      " [ 32  20   4  36   2  85  31]\n",
      " [  3   1   1   0   2  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.80      0.71       210\n",
      "           2       0.71      0.73      0.72       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.63      0.58      0.60       210\n",
      "           6       0.58      0.40      0.48       210\n",
      "           7       0.83      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[169   1   0   5  16  17   2]\n",
      " [  1 141  22  19   4  22   1]\n",
      " [  0   7 178  17   0   8   0]\n",
      " [  2  14  20 140   9  19   6]\n",
      " [ 29  21   6  23 122   4   5]\n",
      " [  2  12   6  33   1 123  33]\n",
      " [  0   1   2   0   1  26 180]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.80      0.82       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.76      0.85      0.80       210\n",
      "           4       0.59      0.67      0.63       210\n",
      "           5       0.80      0.58      0.67       210\n",
      "           6       0.56      0.59      0.57       210\n",
      "           7       0.79      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158  10  16   2  12  12   0]\n",
      " [ 17 135  39   9   6   4   0]\n",
      " [  4  13 176  13   1   3   0]\n",
      " [ 32  30  62  64   3  19   0]\n",
      " [ 71  37  46   9  41   5   1]\n",
      " [ 25  27  73  12   3  59  11]\n",
      " [ 10   6  45   4   2  21 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60       210\n",
      "           2       0.52      0.64      0.58       210\n",
      "           3       0.39      0.84      0.53       210\n",
      "           4       0.57      0.30      0.40       210\n",
      "           5       0.60      0.20      0.29       210\n",
      "           6       0.48      0.28      0.35       210\n",
      "           7       0.91      0.58      0.71       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.57      0.51      0.49      1470\n",
      "weighted avg       0.57      0.51      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154  11   8   2   9  25   1]\n",
      " [ 16 131  28  14   4  16   1]\n",
      " [  5  12 180   7   0   6   0]\n",
      " [ 29  33  41  65   5  37   0]\n",
      " [ 69  48  27  14  30  21   1]\n",
      " [ 26  33  13  17   2 111   8]\n",
      " [ 14  12  11   3   1  49 120]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.73      0.59       210\n",
      "           2       0.47      0.62      0.53       210\n",
      "           3       0.58      0.86      0.69       210\n",
      "           4       0.53      0.31      0.39       210\n",
      "           5       0.59      0.14      0.23       210\n",
      "           6       0.42      0.53      0.47       210\n",
      "           7       0.92      0.57      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.52      1470\n",
      "weighted avg       0.57      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153  14   7   2   9  25   0]\n",
      " [  7 129  29  16   4  25   0]\n",
      " [  0  14 172  15   0   9   0]\n",
      " [ 27  29  38  77   5  34   0]\n",
      " [ 60  49  26  14  36  23   2]\n",
      " [ 18  31  16  21   3 112   9]\n",
      " [  9  12  15   4   0  55 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.73      0.63       210\n",
      "           2       0.46      0.61      0.53       210\n",
      "           3       0.57      0.82      0.67       210\n",
      "           4       0.52      0.37      0.43       210\n",
      "           5       0.63      0.17      0.27       210\n",
      "           6       0.40      0.53      0.45       210\n",
      "           7       0.91      0.55      0.68       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.58      0.54      0.52      1470\n",
      "weighted avg       0.58      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152  15   8   2   9  24   0]\n",
      " [  8 132  31  12   5  22   0]\n",
      " [  3  14 177   8   0   8   0]\n",
      " [ 15  37  37  69   4  48   0]\n",
      " [ 63  49  25  10  34  28   1]\n",
      " [ 16  31  19  19   1 116   8]\n",
      " [  8  12  19   4   0  56 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.72      0.64       210\n",
      "           2       0.46      0.63      0.53       210\n",
      "           3       0.56      0.84      0.67       210\n",
      "           4       0.56      0.33      0.41       210\n",
      "           5       0.64      0.16      0.26       210\n",
      "           6       0.38      0.55      0.45       210\n",
      "           7       0.93      0.53      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.59      0.54      0.52      1470\n",
      "weighted avg       0.59      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148  13   7   2  10  30   0]\n",
      " [  7 131  34  14   1  23   0]\n",
      " [  3  14 174  11   0   8   0]\n",
      " [ 12  35  37  70   4  52   0]\n",
      " [ 61  46  27  10  34  31   1]\n",
      " [ 11  34  16  18   2 121   8]\n",
      " [  5   9  20   3   0  63 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.70      0.65       210\n",
      "           2       0.46      0.62      0.53       210\n",
      "           3       0.55      0.83      0.66       210\n",
      "           4       0.55      0.33      0.41       210\n",
      "           5       0.67      0.16      0.26       210\n",
      "           6       0.37      0.58      0.45       210\n",
      "           7       0.92      0.52      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.59      0.54      0.52      1470\n",
      "weighted avg       0.59      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148  12   8   2   9  31   0]\n",
      " [  8 122  38  13   1  28   0]\n",
      " [  3  14 176   8   0   9   0]\n",
      " [ 11  33  32  72   5  57   0]\n",
      " [ 58  44  25  10  34  38   1]\n",
      " [  9  33  16  18   1 125   8]\n",
      " [  4  10  17   2   0  72 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.70      0.66       210\n",
      "           2       0.46      0.58      0.51       210\n",
      "           3       0.56      0.84      0.67       210\n",
      "           4       0.58      0.34      0.43       210\n",
      "           5       0.68      0.16      0.26       210\n",
      "           6       0.35      0.60      0.44       210\n",
      "           7       0.92      0.50      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.59      0.53      0.52      1470\n",
      "weighted avg       0.59      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   3  13  80   8   6   0]\n",
      " [ 15 129  53   8   3   1   1]\n",
      " [  1   9 195   3   1   0   1]\n",
      " [  9  37  58  82  17   6   1]\n",
      " [ 61  21   4  84  24  12   4]\n",
      " [ 15  35  62  21   4  24  49]\n",
      " [  4   4   3   4   3  13 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.48      0.48       210\n",
      "           2       0.54      0.61      0.58       210\n",
      "           3       0.50      0.93      0.65       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.40      0.11      0.18       210\n",
      "           6       0.39      0.11      0.18       210\n",
      "           7       0.76      0.85      0.80       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.48      0.50      0.46      1470\n",
      "weighted avg       0.48      0.50      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7217687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   0   0   4  23  22   0]\n",
      " [  1 143  17  22   2  24   1]\n",
      " [  0   8 178  17   0   7   0]\n",
      " [  1  16  20 137   7  28   1]\n",
      " [ 21  20   9  20 130   5   5]\n",
      " [  2  10   6  25   1 137  29]\n",
      " [  0   1   1   0   1  32 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.77      0.81       210\n",
      "           2       0.72      0.68      0.70       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.79      0.62      0.70       210\n",
      "           6       0.54      0.65      0.59       210\n",
      "           7       0.83      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[141   4   0   4  29  31   1]\n",
      " [  1 142  10  17   7  33   0]\n",
      " [  0   9 162  20   2  17   0]\n",
      " [  1  15  10 126  11  47   0]\n",
      " [ 17  16   3  23 115  32   4]\n",
      " [  3   9   1  23   1 156  17]\n",
      " [  1   0   0   0   2  48 159]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.87      0.77      0.82       210\n",
      "           4       0.59      0.60      0.60       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.43      0.74      0.54       210\n",
      "           7       0.88      0.76      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   3   0   4  26  23   1]\n",
      " [  1 157  10  20   1  21   0]\n",
      " [  0  10 170  21   1   8   0]\n",
      " [  1  18  14 138   8  30   1]\n",
      " [ 21  25   3  23 124   8   6]\n",
      " [  2  11   1  31   1 135  29]\n",
      " [  0   0   0   2   1  28 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.73      0.79       210\n",
      "           2       0.70      0.75      0.72       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.58      0.66      0.61       210\n",
      "           5       0.77      0.59      0.67       210\n",
      "           6       0.53      0.64      0.58       210\n",
      "           7       0.83      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6272108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   0   0   8  50  16   2]\n",
      " [  0 109  33  28  20  20   0]\n",
      " [  0   7 160  35   1   7   0]\n",
      " [  2  18  24 133   6  21   6]\n",
      " [ 54  24  16  17  89   6   4]\n",
      " [  3  11   6  33   0 125  32]\n",
      " [  0   1   3   1   1  32 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.64      0.67       210\n",
      "           2       0.64      0.52      0.57       210\n",
      "           3       0.66      0.76      0.71       210\n",
      "           4       0.52      0.63      0.57       210\n",
      "           5       0.53      0.42      0.47       210\n",
      "           6       0.55      0.60      0.57       210\n",
      "           7       0.80      0.82      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   0   0   0 209]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   0   1   0   0   0 128]\n",
      " [  1   9  18   0   0   0 182]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   0   0 199]\n",
      " [ 63   0   5   0   0   0 142]\n",
      " [  1   0   1   0   0   0 208]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.36      0.28      0.21      1470\n",
      "weighted avg       0.36      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   1   0  41   0  44]\n",
      " [  2   9  18   0   0   0 181]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   3   0 196]\n",
      " [ 71   0   5   0  58   0  76]\n",
      " [  2   0   1   0   1   0 206]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.56      0.28      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      1.00      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.45      0.35      0.29      1470\n",
      "weighted avg       0.45      0.35      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1   0  42  44   0]\n",
      " [  1   9  18   0   1 180   1]\n",
      " [  0   0 108   0   0 102   0]\n",
      " [  3   0   8   0   3 195   1]\n",
      " [ 54   0   5   0  75  74   2]\n",
      " [  1   0   1   0   2 198   8]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.59      0.63       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.36      0.45       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.38      1470\n",
      "weighted avg       0.59      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   1   0   0  37  44   0]\n",
      " [  1  24   3   0   1 180   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 50   4   1   0  79  73   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.47      0.11      0.18       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.38      0.48       210\n",
      "           6       0.22      0.93      0.35       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.55      0.42      0.41      1470\n",
      "weighted avg       0.55      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  43  44   0]\n",
      " [  1  50   3   0   1 154   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 40  16   1   1  88  61   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.65       210\n",
      "           2       0.56      0.24      0.33       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.64      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.57      0.44      0.44      1470\n",
      "weighted avg       0.57      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45918367346938777\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 38  17   1   2  89  60   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   1 110  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.59      0.65       210\n",
      "           2       0.65      0.36      0.46       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.58      0.46      0.46      1470\n",
      "weighted avg       0.58      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   5   0   1 127   1]\n",
      " [  0  12 110   0   0  88   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 35  17   1   2  92  61   2]\n",
      " [  2   1   0   0   1 197   9]\n",
      " [  0   0   0   0   0 111  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.67      0.36      0.47       210\n",
      "           3       0.93      0.52      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.67      0.44      0.53       210\n",
      "           6       0.24      0.94      0.38       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.47      1470\n",
      "weighted avg       0.59      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   0   1  41  44   0]\n",
      " [  1 104   5   1   1  98   0]\n",
      " [  0  26 111   0   0  73   0]\n",
      " [  3  18   2   0   3 183   1]\n",
      " [ 42  28   1   2  89  45   3]\n",
      " [  2   3   0   0   1 194  10]\n",
      " [  0   3   0   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.58      0.64       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.66      0.42      0.52       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  1  88  21   0   2  97   1]\n",
      " [  0  11 131   0   0  68   0]\n",
      " [  5   7  13   0   1 183   1]\n",
      " [ 63  18  11   1  69  45   3]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.69      0.42      0.52       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.33      0.46       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   2   0   0  19  44   0]\n",
      " [  1  93  15   2   3  95   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  4   8  12  22   2 161   1]\n",
      " [ 55  16  11   3  79  44   2]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.71      0.44      0.55       210\n",
      "           3       0.76      0.63      0.69       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.77      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.52      1470\n",
      "weighted avg       0.70      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   0   1  35  43   0]\n",
      " [  1  94  15   4   2  93   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  2   7  16  34   4 146   1]\n",
      " [ 28  17  11   4 105  42   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   2   0   2 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.71      0.45      0.55       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.79      0.16      0.27       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  2  91   8   4   9  96   0]\n",
      " [  0  10 120   0  12  68   0]\n",
      " [  5   7   7  42  11 137   1]\n",
      " [ 52  18   1   5  91  40   3]\n",
      " [  3   1   1   2   1 193   9]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.70      0.43      0.54       210\n",
      "           3       0.88      0.57      0.69       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.62      0.43      0.51       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   2   0   0  22  35   0]\n",
      " [  2  94  11   7   2  94   0]\n",
      " [  0  10 126   6   0  68   0]\n",
      " [  5   7   8  50   2 137   1]\n",
      " [ 56  19   6   9  81  37   2]\n",
      " [  3   1   1   3   0 192  10]\n",
      " [  0   1   0   2   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.70      0.45      0.55       210\n",
      "           3       0.83      0.60      0.70       210\n",
      "           4       0.65      0.24      0.35       210\n",
      "           5       0.76      0.39      0.51       210\n",
      "           6       0.29      0.91      0.44       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   2   0   0  19  37   0]\n",
      " [  2  96  10   1   5  95   1]\n",
      " [  0  12 128   0   2  68   0]\n",
      " [  5   9   9  41   8 137   1]\n",
      " [ 48  22   4   5  91  37   3]\n",
      " [  1   1   1   2   3 193   9]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.67      0.46      0.54       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.29      0.92      0.44       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0   0  25  34   0]\n",
      " [  2 108  10   2   7  81   0]\n",
      " [  0  10 130   0   2  68   0]\n",
      " [  4  17   8  41   9 130   1]\n",
      " [ 50  22   4   5  97  29   3]\n",
      " [  2   6   1   2   2 188   9]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.72       210\n",
      "           2       0.65      0.51      0.58       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.67      0.46      0.55       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   1  30  33   0]\n",
      " [  2 109  11   1   8  78   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  4  17  10  42   9 127   1]\n",
      " [ 44  21   5   4 102  30   4]\n",
      " [  1   6   1   2   3 189   8]\n",
      " [  0   1   0   0   3 108  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.69      0.71       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  26  32   0]\n",
      " [  2 107  11   2   7  80   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  3  16  10  41  11 128   1]\n",
      " [ 46  21   5   6 102  27   3]\n",
      " [  2   5   1   2   2 186  12]\n",
      " [  0   1   0   0   4 103 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.66      0.51      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.80      0.20      0.31       210\n",
      "           5       0.66      0.49      0.56       210\n",
      "           6       0.30      0.89      0.45       210\n",
      "           7       0.86      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  28  36   0]\n",
      " [  2 104  12   3  10  78   1]\n",
      " [  0   8 139   3   1  59   0]\n",
      " [  3  14  12  40  12 127   2]\n",
      " [ 40  18   6   8 103  30   5]\n",
      " [  2   5   1   3   1 181  17]\n",
      " [  0   1   0   0   4  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.69      0.72       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.82      0.66      0.73       210\n",
      "           4       0.70      0.19      0.30       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.82      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.68      0.56      0.57      1470\n",
      "weighted avg       0.68      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0   0  37  32   0]\n",
      " [  2 111  11   2  10  73   1]\n",
      " [  0  10 139   1   1  59   0]\n",
      " [  2  16  10  41  13 126   2]\n",
      " [ 28  23   4   5 122  23   5]\n",
      " [  1   5   1   3   2 184  14]\n",
      " [  0   1   0   0   3  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.65      0.58      0.61       210\n",
      "           6       0.31      0.88      0.46       210\n",
      "           7       0.83      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.58      1470\n",
      "weighted avg       0.70      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   3   2   6  15  19   2]\n",
      " [  1  84  40  27   6  49   3]\n",
      " [  0   0 139   9   0  62   0]\n",
      " [  3  11  11 122  12  47   4]\n",
      " [ 65  20  11  20  79  10   5]\n",
      " [  5   6   1  49   2 120  27]\n",
      " [  0   1   0  13   2  31 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.67      0.40      0.50       210\n",
      "           3       0.68      0.66      0.67       210\n",
      "           4       0.50      0.58      0.54       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.36      0.57      0.44       210\n",
      "           7       0.80      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   2   5  20  21   4]\n",
      " [  1  95  41  22   7  39   5]\n",
      " [  0   7 145   6   0  49   3]\n",
      " [  4  13  12 108  15  40  18]\n",
      " [ 67  20   9  16  81  10   7]\n",
      " [  3  11   1  32   3 118  42]\n",
      " [  0   2   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.64      0.45      0.53       210\n",
      "           3       0.69      0.69      0.69       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.39      0.56      0.46       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   2   7  21  18   1]\n",
      " [  1  96  31  26   5  49   2]\n",
      " [  0   0 140   9   0  61   0]\n",
      " [  3   8  11 135  12  39   2]\n",
      " [ 58  19  10  20  90   7   6]\n",
      " [  2  10   1  37   4 128  28]\n",
      " [  0   4   0   9   1  28 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.69      0.46      0.55       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.68      0.43      0.52       210\n",
      "           6       0.39      0.61      0.47       210\n",
      "           7       0.81      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   6  22  21   1]\n",
      " [  1 101  31  26   4  46   1]\n",
      " [  0   0 147   7   0  56   0]\n",
      " [  3  13  13 125  11  44   1]\n",
      " [ 58  21   5  20  91   9   6]\n",
      " [  2  10   1  29   4 138  26]\n",
      " [  0   1   0   2   4  35 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.48      0.56       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.58      0.60      0.59       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   2   3  24  24   1]\n",
      " [  1 112  30  23   2  41   1]\n",
      " [  0   2 149   6   0  53   0]\n",
      " [  3  12  13 119  12  49   2]\n",
      " [ 59  21   5  19  91   9   6]\n",
      " [  3   9   2  28   3 138  27]\n",
      " [  0   3   0   0   1  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.70      0.53      0.61       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.60      0.57      0.58       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  23  24   2]\n",
      " [  1 108  31  23   4  42   1]\n",
      " [  0   1 149   2   0  58   0]\n",
      " [  4  15  13 115   7  54   2]\n",
      " [ 56  21   5  20  92  11   5]\n",
      " [  3   8   1  21   4 146  27]\n",
      " [  0   4   0   1   0  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.71      0.44      0.54       210\n",
      "           6       0.39      0.70      0.50       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   3  22  24   1]\n",
      " [  1 112  27  23   4  42   1]\n",
      " [  0   0 150   1   0  59   0]\n",
      " [  4  10  13 117  12  52   2]\n",
      " [ 44  23   5  19 101  13   5]\n",
      " [  2   8   1  29   4 137  29]\n",
      " [  0   3   0   1   2  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.71      0.53      0.61       210\n",
      "           3       0.76      0.71      0.74       210\n",
      "           4       0.61      0.56      0.58       210\n",
      "           5       0.70      0.48      0.57       210\n",
      "           6       0.37      0.65      0.48       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  21  27   1]\n",
      " [  1 113  26  22   5  42   1]\n",
      " [  0   1 152   4   0  53   0]\n",
      " [  3  14  13 114  10  54   2]\n",
      " [ 52  25   5  18  93  12   5]\n",
      " [  2   8   1  21   4 148  26]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.40      0.70      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   1   3  23  23   1]\n",
      " [  1 113  31  20   4  40   1]\n",
      " [  0   3 151   3   0  53   0]\n",
      " [  3  12  13 114  13  53   2]\n",
      " [ 50  19   4  20 102  10   5]\n",
      " [  2   9   2  24   4 145  24]\n",
      " [  0   3   0   0   1  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.62      0.54      0.58       210\n",
      "           5       0.69      0.49      0.57       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6448979591836734\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   1   4  23  25   1]\n",
      " [  1 113  30  22   3  40   1]\n",
      " [  0   3 151  10   0  46   0]\n",
      " [  3  13  12 122  10  48   2]\n",
      " [ 51  23   4  20  97  10   5]\n",
      " [  3   8   3  28   3 140  25]\n",
      " [  0   2   0   0   1  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.59      0.58      0.59       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   4  24  24   1]\n",
      " [  1 118  25  22   4  39   1]\n",
      " [  0   1 155   6   0  48   0]\n",
      " [  3  14  12 118  11  50   2]\n",
      " [ 41  25   4  20 105  10   5]\n",
      " [  2   7   3  29   4 138  27]\n",
      " [  0   3   0   0   1  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.69      0.56      0.62       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   1   4  26  24   1]\n",
      " [  1 117  24  21   5  41   1]\n",
      " [  0   1 156   6   0  47   0]\n",
      " [  3  12  13 121  10  49   2]\n",
      " [ 39  20   4  24 110   8   5]\n",
      " [  3   7   1  20   3 147  29]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.73      0.56      0.63       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.71      0.52      0.60       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   1   1   4  27  24   1]\n",
      " [  1 119  25  23   3  38   1]\n",
      " [  0   2 159   5   0  44   0]\n",
      " [  3  14  13 116  11  51   2]\n",
      " [ 45  22   5  22 104   7   5]\n",
      " [  2   7   3  18   4 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.74       210\n",
      "           2       0.72      0.57      0.63       210\n",
      "           3       0.77      0.76      0.76       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   4  28  24   1]\n",
      " [  1 118  24  21   7  38   1]\n",
      " [  0   4 157   6   0  43   0]\n",
      " [  3  15  12 118  10  50   2]\n",
      " [ 39  23   4  18 112   9   5]\n",
      " [  1   7   3  18   5 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75       210\n",
      "           2       0.70      0.56      0.62       210\n",
      "           3       0.78      0.75      0.76       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  29  23   1]\n",
      " [  1 121  25  20   4  38   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  3  13  13 118  11  50   2]\n",
      " [ 36  22   5  17 116   9   5]\n",
      " [  1   8   2  21   4 148  26]\n",
      " [  0   2   0   0   1  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.71      0.75       210\n",
      "           2       0.70      0.58      0.63       210\n",
      "           3       0.78      0.77      0.78       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.55      0.62       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   4  24  23   1]\n",
      " [  1 120  25  21   5  37   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  2  14  13 120  12  47   2]\n",
      " [ 37  20   5  18 116   9   5]\n",
      " [  1   9   3  26   5 140  26]\n",
      " [  0   1   0   0   2  38 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.76       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.71      0.55      0.62       210\n",
      "           6       0.42      0.67      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   1   5  28  22   1]\n",
      " [  1 125  25  18   4  36   1]\n",
      " [  0   5 158  12   0  35   0]\n",
      " [  2  13  13 124  11  45   2]\n",
      " [ 38  22   4  18 114   9   5]\n",
      " [  2   8   3  24   3 144  26]\n",
      " [  0   1   0   0   1  40 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.72      0.75       210\n",
      "           2       0.71      0.60      0.65       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.44      0.69      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   3  27  23   1]\n",
      " [  1 123  24  18   7  36   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 125  11  45   2]\n",
      " [ 36  22   5  20 115   7   5]\n",
      " [  3   8   3  24   3 141  28]\n",
      " [  0   1   0   0   3  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.70      0.59      0.64       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.82      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  26  24   0]\n",
      " [  1 124  26  18   6  34   1]\n",
      " [  0   3 162  11   0  34   0]\n",
      " [  2  13  13 121  13  46   2]\n",
      " [ 37  20   4  18 117   9   5]\n",
      " [  2   7   3  20   3 147  28]\n",
      " [  0   0   0   0   3  36 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.73      0.59      0.65       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.70      0.56      0.62       210\n",
      "           6       0.45      0.70      0.54       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   1   4  24  22   1]\n",
      " [  1 124  24  20   5  35   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 122  12  47   2]\n",
      " [ 36  20   4  22 116   7   5]\n",
      " [  2   8   2  23   4 143  28]\n",
      " [  0   2   0   0   1  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.77       210\n",
      "           2       0.71      0.59      0.64       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.72      0.55      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   2   0   6  25   9   0]\n",
      " [ 13 153  11  14  14   5   0]\n",
      " [  5  11 172  18   4   0   0]\n",
      " [ 17  10  13 135  25  10   0]\n",
      " [ 22  19   1  32 122  10   4]\n",
      " [ 32  20   4  36   2  85  31]\n",
      " [  3   1   1   0   2  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.80      0.71       210\n",
      "           2       0.71      0.73      0.72       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.63      0.58      0.60       210\n",
      "           6       0.58      0.40      0.48       210\n",
      "           7       0.83      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7122448979591837\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[150   3   3   1  30  20   3]\n",
      " [  3 150  13  10  20  12   2]\n",
      " [  0   4 192   7   4   3   0]\n",
      " [  4  18   9 124  28  17  10]\n",
      " [ 28  13   2  14 139   4  10]\n",
      " [ 10   7  11  24   6 106  46]\n",
      " [  0   1   0   0   4  19 186]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.77      0.71      0.74       210\n",
      "           3       0.83      0.91      0.87       210\n",
      "           4       0.69      0.59      0.64       210\n",
      "           5       0.60      0.66      0.63       210\n",
      "           6       0.59      0.50      0.54       210\n",
      "           7       0.72      0.89      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149  11   3   4  33   7   3]\n",
      " [  8 165   6   9  19   2   1]\n",
      " [  0   6 195   4   1   4   0]\n",
      " [ 20  28  21  99  30   8   4]\n",
      " [ 44  30   7  20 103   0   6]\n",
      " [ 30  27   9  15  14  69  46]\n",
      " [  8   7   2   9   8  15 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.71      0.64       210\n",
      "           2       0.60      0.79      0.68       210\n",
      "           3       0.80      0.93      0.86       210\n",
      "           4       0.62      0.47      0.54       210\n",
      "           5       0.50      0.49      0.49       210\n",
      "           6       0.66      0.33      0.44       210\n",
      "           7       0.73      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6503401360544218\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   8   5   2  34  10   6]\n",
      " [  6 167   6  10  17   2   2]\n",
      " [  0   6 195   4   1   4   0]\n",
      " [ 13  20  21 109  36   7   4]\n",
      " [ 40  33   5  25  97   2   8]\n",
      " [ 28  26   8  15  13  82  38]\n",
      " [  6   3   0   5   7  28 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.69      0.65       210\n",
      "           2       0.63      0.80      0.71       210\n",
      "           3       0.81      0.93      0.87       210\n",
      "           4       0.64      0.52      0.57       210\n",
      "           5       0.47      0.46      0.47       210\n",
      "           6       0.61      0.39      0.48       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.64      0.65      0.64      1470\n",
      "weighted avg       0.64      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   6   5   4  36  11   5]\n",
      " [  8 164   8   7  19   2   2]\n",
      " [  0   6 195   5   1   3   0]\n",
      " [ 10  24  22 109  32   8   5]\n",
      " [ 34  30   7  26 103   3   7]\n",
      " [ 25  25   6  16  12  80  46]\n",
      " [  6   3   0   2   9  25 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.68      0.66       210\n",
      "           2       0.64      0.78      0.70       210\n",
      "           3       0.80      0.93      0.86       210\n",
      "           4       0.64      0.52      0.58       210\n",
      "           5       0.49      0.49      0.49       210\n",
      "           6       0.61      0.38      0.47       210\n",
      "           7       0.72      0.79      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   5   3   7  35  11   3]\n",
      " [  4 165   8   5  22   3   3]\n",
      " [  0   5 196   4   2   3   0]\n",
      " [ 13  25  25 100  36   5   6]\n",
      " [ 27  31   8  20 115   2   7]\n",
      " [ 25  20   8  23  14  70  50]\n",
      " [  5   3   0   1   9  23 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.70      0.68       210\n",
      "           2       0.65      0.79      0.71       210\n",
      "           3       0.79      0.93      0.86       210\n",
      "           4       0.62      0.48      0.54       210\n",
      "           5       0.49      0.55      0.52       210\n",
      "           6       0.60      0.33      0.43       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   2   4   6  39  11   3]\n",
      " [  4 163  10   5  22   3   3]\n",
      " [  0   6 195   4   2   3   0]\n",
      " [ 14  27  22  96  35   8   8]\n",
      " [ 27  33   8  16 116   3   7]\n",
      " [ 24  21   8  21  15  72  49]\n",
      " [  7   3   0   2   5  19 174]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.67       210\n",
      "           2       0.64      0.78      0.70       210\n",
      "           3       0.79      0.93      0.85       210\n",
      "           4       0.64      0.46      0.53       210\n",
      "           5       0.50      0.55      0.52       210\n",
      "           6       0.61      0.34      0.44       210\n",
      "           7       0.71      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   2   4   5  39  11   5]\n",
      " [  4 161  12   5  22   2   4]\n",
      " [  1   6 194   4   2   3   0]\n",
      " [ 10  26  24  93  39  10   8]\n",
      " [ 27  27   8  15 121   3   9]\n",
      " [ 25  21   9  21  12  71  51]\n",
      " [  5   2   0   2   5  16 180]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.66      0.77      0.71       210\n",
      "           3       0.77      0.92      0.84       210\n",
      "           4       0.64      0.44      0.52       210\n",
      "           5       0.50      0.58      0.54       210\n",
      "           6       0.61      0.34      0.44       210\n",
      "           7       0.70      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.64      1470\n",
      "weighted avg       0.65      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 99   3  33   5  37  25   8]\n",
      " [  0 105  38   9  34  20   4]\n",
      " [  0   4 175   7   6  18   0]\n",
      " [  6  19  27  53  65  27  13]\n",
      " [ 21  17   4   6 137   9  16]\n",
      " [ 11  11  15   7  12  99  55]\n",
      " [  0   1   0   0   2  46 161]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.47      0.57       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.60      0.83      0.70       210\n",
      "           4       0.61      0.25      0.36       210\n",
      "           5       0.47      0.65      0.54       210\n",
      "           6       0.41      0.47      0.44       210\n",
      "           7       0.63      0.77      0.69       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 97   2  37   4  37  22  11]\n",
      " [  0 108  32   9  34  24   3]\n",
      " [  0   3 174   6   6  21   0]\n",
      " [  6  13  29  54  66  30  12]\n",
      " [ 23  19   5   5 132  10  16]\n",
      " [ 12   6  18   7  11  94  62]\n",
      " [  0   1   0   0   3  51 155]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.46      0.56       210\n",
      "           2       0.71      0.51      0.60       210\n",
      "           3       0.59      0.83      0.69       210\n",
      "           4       0.64      0.26      0.37       210\n",
      "           5       0.46      0.63      0.53       210\n",
      "           6       0.37      0.45      0.41       210\n",
      "           7       0.60      0.74      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.58      0.55      0.54      1470\n",
      "weighted avg       0.58      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   2   3   0  33  21   3]\n",
      " [  3 163   6  14  13   9   2]\n",
      " [  0   6 194   5   4   1   0]\n",
      " [  2  15   9 125  25  26   8]\n",
      " [ 25  17   0  18 138   4   8]\n",
      " [ 11   8   7  24   5 117  38]\n",
      " [  0   0   0   0   4  22 184]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74       210\n",
      "           2       0.77      0.78      0.77       210\n",
      "           3       0.89      0.92      0.90       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.62      0.66      0.64       210\n",
      "           6       0.58      0.56      0.57       210\n",
      "           7       0.76      0.88      0.81       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.72      1470\n",
      "weighted avg       0.73      0.73      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7537414965986394\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   2   1   1  31  21   2]\n",
      " [  3 160   4  18  14   9   2]\n",
      " [  0   5 196   3   4   2   0]\n",
      " [  4  14   7 132  26  24   3]\n",
      " [ 16  13   0  18 149   7   7]\n",
      " [ 11   6   4  18   5 132  34]\n",
      " [  0   0   0   0   3  20 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.72      0.77       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.92      0.93      0.93       210\n",
      "           4       0.69      0.63      0.66       210\n",
      "           5       0.64      0.71      0.67       210\n",
      "           6       0.61      0.63      0.62       210\n",
      "           7       0.80      0.89      0.84       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7387755102040816\n",
      "Confusion Matrix of SVM is:\n",
      " [[150   2   1   2  32  21   2]\n",
      " [  3 158   5  16  15  11   2]\n",
      " [  0   7 193   6   3   1   0]\n",
      " [  3  12   7 130  27  27   4]\n",
      " [ 17  14   0  19 146   7   7]\n",
      " [ 10   9   3  21   6 125  36]\n",
      " [  0   0   0   0   3  23 184]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.71      0.76       210\n",
      "           2       0.78      0.75      0.77       210\n",
      "           3       0.92      0.92      0.92       210\n",
      "           4       0.67      0.62      0.64       210\n",
      "           5       0.63      0.70      0.66       210\n",
      "           6       0.58      0.60      0.59       210\n",
      "           7       0.78      0.88      0.83       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   2   3   1  32  17   3]\n",
      " [  3 144  15  21  13  13   1]\n",
      " [  0   3 193   9   2   3   0]\n",
      " [  6  19  14 111  27  23  10]\n",
      " [ 32  13   2  20 130   6   7]\n",
      " [ 16   6  14  22   5 103  44]\n",
      " [  0   0   0   0   4  25 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.77      0.69      0.73       210\n",
      "           3       0.80      0.92      0.86       210\n",
      "           4       0.60      0.53      0.56       210\n",
      "           5       0.61      0.62      0.61       210\n",
      "           6       0.54      0.49      0.52       210\n",
      "           7       0.74      0.86      0.79       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2578231292517007\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   4   0   0   0 206]\n",
      " [  0   0  56   0   0   0 154]\n",
      " [  0   0 169   0   0   0  41]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0  21   0   0   0 189]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.60      0.80      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.11      0.26      0.14      1470\n",
      "weighted avg       0.11      0.26      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.39931972789115644\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   1   3   0 175   0  31]\n",
      " [  0  46  10   0 130   0  24]\n",
      " [  0   2 167   0  26   0  15]\n",
      " [  0   4  23   0 148   0  35]\n",
      " [  0   3   3   0 186   0  18]\n",
      " [  0   5  16   0  62   0 127]\n",
      " [  0   0   0   0  22   0 188]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.75      0.22      0.34       210\n",
      "           3       0.75      0.80      0.77       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.25      0.89      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.90      0.58       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.31      0.40      0.30      1470\n",
      "weighted avg       0.31      0.40      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[139   0   4   0  36  20  11]\n",
      " [ 13  45  10   1 117  19   5]\n",
      " [  1   0 164   5  25  15   0]\n",
      " [ 17   4  13  10 131  19  16]\n",
      " [ 32   3   2   1 154   9   9]\n",
      " [ 27   1  16   4  35  64  63]\n",
      " [ 10   0   0   0  12  30 158]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.66      0.62       210\n",
      "           2       0.85      0.21      0.34       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.48      0.05      0.09       210\n",
      "           5       0.30      0.73      0.43       210\n",
      "           6       0.36      0.30      0.33       210\n",
      "           7       0.60      0.75      0.67       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.57      0.50      0.47      1470\n",
      "weighted avg       0.57      0.50      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   7   1   0  51  28   6]\n",
      " [  2 133   5   1  40  25   4]\n",
      " [  0  15 156   5  11  23   0]\n",
      " [  4  63   8  10  85  24  16]\n",
      " [ 13  40   0   1 136  17   3]\n",
      " [  6  16   4   4  41 106  33]\n",
      " [  4   4   0   0  14  83 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.56      0.66       210\n",
      "           2       0.48      0.63      0.55       210\n",
      "           3       0.90      0.74      0.81       210\n",
      "           4       0.48      0.05      0.09       210\n",
      "           5       0.36      0.65      0.46       210\n",
      "           6       0.35      0.50      0.41       210\n",
      "           7       0.63      0.50      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.57      0.52      0.50      1470\n",
      "weighted avg       0.57      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   1  14  37  28   6]\n",
      " [  3 117   8  31  23  24   4]\n",
      " [  0   5 162  20   4  19   0]\n",
      " [  4  32   8  75  49  34   8]\n",
      " [ 16  19   2  37 118  15   3]\n",
      " [ 10   7   7  26  12 118  30]\n",
      " [  4   0   0   9   5  71 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.58      0.66       210\n",
      "           2       0.64      0.56      0.60       210\n",
      "           3       0.86      0.77      0.81       210\n",
      "           4       0.35      0.36      0.36       210\n",
      "           5       0.48      0.56      0.52       210\n",
      "           6       0.38      0.56      0.45       210\n",
      "           7       0.70      0.58      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.58      1470\n",
      "weighted avg       0.60      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   5   2  16  35  22   9]\n",
      " [  2 123   4  35  23  20   3]\n",
      " [  0   7 163  13  10  17   0]\n",
      " [  3  35   5  85  48  27   7]\n",
      " [ 15  20   2  33 123  13   4]\n",
      " [  5  17   2  34  11 104  37]\n",
      " [  3   0   0   9   5  64 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.58      0.67       210\n",
      "           2       0.59      0.59      0.59       210\n",
      "           3       0.92      0.78      0.84       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.48      0.59      0.53       210\n",
      "           6       0.39      0.50      0.44       210\n",
      "           7       0.68      0.61      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.59      1470\n",
      "weighted avg       0.61      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   7   4   7  42  22   5]\n",
      " [  3 132   9  12  33  18   3]\n",
      " [  0   8 176  11  11   4   0]\n",
      " [  7  37  11  56  65  24  10]\n",
      " [ 17  22   4  19 131  12   5]\n",
      " [ 12  18  18  20  20  90  32]\n",
      " [  1   0   2   8  10  58 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.59      0.63      0.61       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.42      0.27      0.33       210\n",
      "           5       0.42      0.62      0.50       210\n",
      "           6       0.39      0.43      0.41       210\n",
      "           7       0.70      0.62      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132  13   2   8  37  12   6]\n",
      " [  2 135   6  26  31   7   3]\n",
      " [  0   6 179  12  10   3   0]\n",
      " [  6  33   6  83  55  17  10]\n",
      " [ 16  26   3  27 126   7   5]\n",
      " [ 12  28  18  16  22  81  33]\n",
      " [  3   9   2  10   8  46 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.63      0.69       210\n",
      "           2       0.54      0.64      0.59       210\n",
      "           3       0.83      0.85      0.84       210\n",
      "           4       0.46      0.40      0.42       210\n",
      "           5       0.44      0.60      0.51       210\n",
      "           6       0.47      0.39      0.42       210\n",
      "           7       0.70      0.63      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[131  11   2  11  37   9   9]\n",
      " [  6 124   9  20  43   4   4]\n",
      " [  2   6 177  12  10   3   0]\n",
      " [  7  26   6  82  61  14  14]\n",
      " [ 24  24   2  24 125   6   5]\n",
      " [ 16  22  26  22  24  62  38]\n",
      " [  9   1   3  11   8  42 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.62      0.65       210\n",
      "           2       0.58      0.59      0.58       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.45      0.39      0.42       210\n",
      "           5       0.41      0.60      0.48       210\n",
      "           6       0.44      0.30      0.35       210\n",
      "           7       0.66      0.65      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130  11   3   9  38  12   7]\n",
      " [  7 125   9  15  40   7   7]\n",
      " [  0   6 179  12   8   3   2]\n",
      " [ 13  27  11  74  55  18  12]\n",
      " [ 27  30   2  26 109   7   9]\n",
      " [ 12  20  20  16  25  82  35]\n",
      " [  5   2   4  12  11  42 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.62      0.64       210\n",
      "           2       0.57      0.60      0.58       210\n",
      "           3       0.79      0.85      0.82       210\n",
      "           4       0.45      0.35      0.40       210\n",
      "           5       0.38      0.52      0.44       210\n",
      "           6       0.48      0.39      0.43       210\n",
      "           7       0.65      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   8   2  13  32  13   9]\n",
      " [  7 125   6  27  30   5  10]\n",
      " [  1   7 175  14   7   4   2]\n",
      " [  9  32   8  73  54  21  13]\n",
      " [ 32  23   6  23 104  10  12]\n",
      " [ 16  22  13  25  13  75  46]\n",
      " [  6   1   1   9  11  42 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.63      0.64       210\n",
      "           2       0.57      0.60      0.58       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.40      0.35      0.37       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.44      0.36      0.39       210\n",
      "           7       0.60      0.67      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5578231292517006\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[127   9   4  10  33  19   8]\n",
      " [  5 119  11  24  41   3   7]\n",
      " [  2   6 176  16   5   3   2]\n",
      " [  9  29   9  72  57  24  10]\n",
      " [ 33  22   5  24  99  15  12]\n",
      " [ 18  15  14  23  20  87  33]\n",
      " [  8   2   2  12   7  39 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.60      0.62       210\n",
      "           2       0.59      0.57      0.58       210\n",
      "           3       0.80      0.84      0.82       210\n",
      "           4       0.40      0.34      0.37       210\n",
      "           5       0.38      0.47      0.42       210\n",
      "           6       0.46      0.41      0.44       210\n",
      "           7       0.66      0.67      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132  11   4  11  30  13   9]\n",
      " [  8 120  12  24  38   2   6]\n",
      " [  2   4 178  14   5   5   2]\n",
      " [  5  27  11  77  54  22  14]\n",
      " [ 37  23   5  26  99  12   8]\n",
      " [ 22  14  17  27  18  79  33]\n",
      " [  5   4   5  14   8  31 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.63      0.63       210\n",
      "           2       0.59      0.57      0.58       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.40      0.37      0.38       210\n",
      "           5       0.39      0.47      0.43       210\n",
      "           6       0.48      0.38      0.42       210\n",
      "           7       0.67      0.68      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129  11   3   8  34  18   7]\n",
      " [ 11 123  11  20  35   4   6]\n",
      " [  2   8 175  14   6   4   1]\n",
      " [ 12  31   9  73  52  25   8]\n",
      " [ 36  24   2  25  98  15  10]\n",
      " [ 17  13  16  33  13  93  25]\n",
      " [  5   3   2  12   8  45 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.61      0.61       210\n",
      "           2       0.58      0.59      0.58       210\n",
      "           3       0.80      0.83      0.82       210\n",
      "           4       0.39      0.35      0.37       210\n",
      "           5       0.40      0.47      0.43       210\n",
      "           6       0.46      0.44      0.45       210\n",
      "           7       0.70      0.64      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   9   3   8  38  11  11]\n",
      " [  9 121   8  27  35   4   6]\n",
      " [  1   6 176  16   5   5   1]\n",
      " [ 16  24  11  80  44  23  12]\n",
      " [ 35  23   4  25 100  12  11]\n",
      " [ 20  14  16  27  23  80  30]\n",
      " [  7   3   3  13  11  41 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.80      0.84      0.82       210\n",
      "           4       0.41      0.38      0.39       210\n",
      "           5       0.39      0.48      0.43       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.65      0.63      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   8   3  11  28  17  10]\n",
      " [  7 121  11  28  33   5   5]\n",
      " [  3   5 178  15   5   3   1]\n",
      " [ 10  27  11  82  48  20  12]\n",
      " [ 33  23   5  25 100  14  10]\n",
      " [ 22  15  14  24  19  85  31]\n",
      " [  4   4   1  17   7  38 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.63      0.63       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.42      0.48      0.44       210\n",
      "           6       0.47      0.40      0.43       210\n",
      "           7       0.67      0.66      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[127   9   5   7  32  18  12]\n",
      " [  8 118  11  24  37   5   7]\n",
      " [  5   5 180  13   4   2   1]\n",
      " [ 14  32  13  75  38  23  15]\n",
      " [ 40  21   4  29  95  13   8]\n",
      " [ 26  15  14  20  18  83  34]\n",
      " [  3   3   1  18  11  38 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.60      0.59       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.79      0.86      0.82       210\n",
      "           4       0.40      0.36      0.38       210\n",
      "           5       0.40      0.45      0.43       210\n",
      "           6       0.46      0.40      0.42       210\n",
      "           7       0.64      0.65      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   6   4  10  32  17  13]\n",
      " [  9 116  12  24  35   7   7]\n",
      " [  2   4 180  14   4   5   1]\n",
      " [ 15  26   7  80  46  22  14]\n",
      " [ 38  23   4  29  91  18   7]\n",
      " [ 21  15  15  21  20  83  35]\n",
      " [  4   2   1  18  11  38 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.61      0.60       210\n",
      "           2       0.60      0.55      0.58       210\n",
      "           3       0.81      0.86      0.83       210\n",
      "           4       0.41      0.38      0.39       210\n",
      "           5       0.38      0.43      0.41       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.64      0.65      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   6   3   9  33  18  13]\n",
      " [  7 121  11  19  35  10   7]\n",
      " [  2   6 178  14   5   3   2]\n",
      " [ 13  28  12  78  44  22  13]\n",
      " [ 41  22   4  29  91  17   6]\n",
      " [ 21  17  13  20  16  90  33]\n",
      " [  3   2   0  19  13  37 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.60       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.41      0.37      0.39       210\n",
      "           5       0.38      0.43      0.41       210\n",
      "           6       0.46      0.43      0.44       210\n",
      "           7       0.65      0.65      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   8   3  11  30  18  12]\n",
      " [  7 119   9  24  37   7   7]\n",
      " [  2   6 175  15   6   4   2]\n",
      " [ 14  28  10  81  43  20  14]\n",
      " [ 41  23   4  30  89  16   7]\n",
      " [ 21  14  15  23  21  83  33]\n",
      " [  4   2   1  18  11  38 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.61      0.60       210\n",
      "           2       0.59      0.57      0.58       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.38      0.42      0.40       210\n",
      "           6       0.45      0.40      0.42       210\n",
      "           7       0.64      0.65      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95   2   9   0  57   0  47]\n",
      " [  1  65  80   0  45   0  19]\n",
      " [  1   1 188   0   8   0  12]\n",
      " [ 14  14  41   1  87   0  53]\n",
      " [  7  11  14   0 137   0  41]\n",
      " [  5   7  23   0  22   0 153]\n",
      " [  0   1   1   0   2   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.45      0.57       210\n",
      "           2       0.64      0.31      0.42       210\n",
      "           3       0.53      0.90      0.66       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.38      0.65      0.48       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.98      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.53      0.47      0.39      1470\n",
      "weighted avg       0.53      0.47      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   1   3   0  56   3  28]\n",
      " [  3 120  24   0  45   3  15]\n",
      " [  2   4 181   0   8  10   5]\n",
      " [ 17  15  32   1  98   3  44]\n",
      " [ 15  20   2   0 146   0  27]\n",
      " [ 12   6  18   0  23  11 140]\n",
      " [  0   2   0   0   2   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.57      0.63       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.70      0.86      0.77       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.39      0.70      0.50       210\n",
      "           6       0.37      0.05      0.09       210\n",
      "           7       0.44      0.98      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.46      1470\n",
      "weighted avg       0.62      0.53      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.573469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   3   0   0  43  15  15]\n",
      " [  2 146   7   0  37   9   9]\n",
      " [  1  12 173   1   8  14   1]\n",
      " [ 15  31  18  11  93  12  30]\n",
      " [ 21  31   2   0 134   3  19]\n",
      " [ 12  16   9   3  17  45 108]\n",
      " [  0   2   0   0   4   4 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.83      0.82      0.83       210\n",
      "           4       0.73      0.05      0.10       210\n",
      "           5       0.40      0.64      0.49       210\n",
      "           6       0.44      0.21      0.29       210\n",
      "           7       0.52      0.95      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.61      0.57      0.53      1470\n",
      "weighted avg       0.61      0.57      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   2   0   3  48  17  11]\n",
      " [  1 153   3   2  32  14   5]\n",
      " [  0   9 174   7   7  12   1]\n",
      " [  9  29  10  40  79  21  22]\n",
      " [ 17  24   1   1 147   3  17]\n",
      " [ 10  14   5  11  17  68  85]\n",
      " [  0   1   0   1   2  10 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.61      0.69       210\n",
      "           2       0.66      0.73      0.69       210\n",
      "           3       0.90      0.83      0.86       210\n",
      "           4       0.62      0.19      0.29       210\n",
      "           5       0.44      0.70      0.54       210\n",
      "           6       0.47      0.32      0.38       210\n",
      "           7       0.58      0.93      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.60      1470\n",
      "weighted avg       0.64      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   0   4  50  18  10]\n",
      " [  1 151   2   5  31  17   3]\n",
      " [  0   9 179  10   4   8   0]\n",
      " [  7  21   4  65  71  24  18]\n",
      " [ 16  20   1   2 150   5  16]\n",
      " [  6  15   4  14  13  85  73]\n",
      " [  0   1   0   1   3  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.69      0.72      0.71       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.64      0.31      0.42       210\n",
      "           5       0.47      0.71      0.56       210\n",
      "           6       0.48      0.40      0.44       210\n",
      "           7       0.61      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.63      1470\n",
      "weighted avg       0.66      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   1   0   4  48  21   7]\n",
      " [  2 148   3   5  34  16   2]\n",
      " [  0   7 177  11   5  10   0]\n",
      " [  5  22   7  82  54  27  13]\n",
      " [ 15  20   1   9 145   7  13]\n",
      " [  7  12   1  19   9  92  70]\n",
      " [  0   1   0   1   3  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.61      0.70       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.94      0.84      0.89       210\n",
      "           4       0.63      0.39      0.48       210\n",
      "           5       0.49      0.69      0.57       210\n",
      "           6       0.47      0.44      0.46       210\n",
      "           7       0.64      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   2   0   5  46  20   6]\n",
      " [  1 150   2  11  27  16   3]\n",
      " [  0   9 179  10   4   8   0]\n",
      " [  5  15   3  99  48  28  12]\n",
      " [ 14  16   1  12 147   7  13]\n",
      " [  6  12   1  21   9 106  55]\n",
      " [  0   0   0   1   3  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.62      0.71       210\n",
      "           2       0.74      0.71      0.72       210\n",
      "           3       0.96      0.85      0.90       210\n",
      "           4       0.62      0.47      0.54       210\n",
      "           5       0.52      0.70      0.60       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.67      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   1   1   7  43  17   7]\n",
      " [  3 144   3  16  27  15   2]\n",
      " [  0   7 182   8   5   8   0]\n",
      " [  2  12   4 113  42  26  11]\n",
      " [ 16  16   1  12 144   8  13]\n",
      " [  8  10   2  18   8 111  53]\n",
      " [  0   1   0   0   2  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.75      0.69      0.72       210\n",
      "           3       0.94      0.87      0.90       210\n",
      "           4       0.65      0.54      0.59       210\n",
      "           5       0.53      0.69      0.60       210\n",
      "           6       0.53      0.53      0.53       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   2   0   6  45  23   3]\n",
      " [  2 148   2  16  26  13   3]\n",
      " [  0   7 184   6   4   9   0]\n",
      " [  1  12   3 114  40  27  13]\n",
      " [ 11  14   1  16 147   7  14]\n",
      " [  8   9   2  22   7 108  54]\n",
      " [  1   0   0   0   2  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.62      0.72       210\n",
      "           2       0.77      0.70      0.74       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.54      0.70      0.61       210\n",
      "           6       0.52      0.51      0.52       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   0   4  42  19   5]\n",
      " [  4 150   4  16  22  12   2]\n",
      " [  0   7 185   9   3   6   0]\n",
      " [  6  13   4 111  40  22  14]\n",
      " [ 16  12   0  16 146  10  10]\n",
      " [ 10  11   1  16   8 116  48]\n",
      " [  0   1   0   0   2  24 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.77      0.71      0.74       210\n",
      "           3       0.95      0.88      0.92       210\n",
      "           4       0.65      0.53      0.58       210\n",
      "           5       0.56      0.70      0.62       210\n",
      "           6       0.56      0.55      0.55       210\n",
      "           7       0.70      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   1   6  40  22   3]\n",
      " [  2 154   4  10  25  13   2]\n",
      " [  0   6 184   9   4   7   0]\n",
      " [  4  10   3 114  39  29  11]\n",
      " [ 18  13   0  16 142   9  12]\n",
      " [  7  10   2  22   7 110  52]\n",
      " [  0   0   0   1   2  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.65      0.72       210\n",
      "           2       0.79      0.73      0.76       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.52      0.52      0.52       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   2   2   4  43  21   4]\n",
      " [  4 149   5  13  25  12   2]\n",
      " [  0   6 187   9   4   4   0]\n",
      " [  4   8   3 117  39  29  10]\n",
      " [ 19  13   0  16 143   8  11]\n",
      " [  9   7   1  22   6 112  53]\n",
      " [  0   2   0   0   2  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.80      0.71      0.75       210\n",
      "           3       0.94      0.89      0.92       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.54      0.53      0.53       210\n",
      "           7       0.70      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7013605442176871\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   2   5  36  19   5]\n",
      " [  2 147   5  21  20  13   2]\n",
      " [  0   7 186   9   4   4   0]\n",
      " [  7   9   3 118  38  22  13]\n",
      " [ 17  14   0  16 143   8  12]\n",
      " [ 10  10   1  19   5 115  50]\n",
      " [  0   0   0   0   2  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       210\n",
      "           2       0.78      0.70      0.74       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.58      0.68      0.62       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   2   1   4  42  21   3]\n",
      " [  1 151   6  16  22  12   2]\n",
      " [  0   6 186   8   4   6   0]\n",
      " [  5   9   3 117  42  18  16]\n",
      " [ 13  17   1  14 147   8  10]\n",
      " [  9  12   1  17   8 113  50]\n",
      " [  0   1   0   0   2  21 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.65      0.73       210\n",
      "           2       0.76      0.72      0.74       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.66      0.56      0.61       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.57      0.54      0.55       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   3   2   4  36  21   5]\n",
      " [  4 150   5  13  23  13   2]\n",
      " [  0   7 189   6   3   5   0]\n",
      " [  5  10   3 122  33  25  12]\n",
      " [ 18  15   0  20 138  10   9]\n",
      " [  8  11   1  21   7 113  49]\n",
      " [  0   1   0   0   2  17 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.72       210\n",
      "           2       0.76      0.71      0.74       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.66      0.58      0.62       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.55      0.54      0.55       210\n",
      "           7       0.71      0.90      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   3   1   3  41  20   4]\n",
      " [  3 149   6  16  21  13   2]\n",
      " [  0   8 185   8   3   6   0]\n",
      " [  5  11   4 120  35  26   9]\n",
      " [ 19  17   0  17 138   7  12]\n",
      " [  9   9   1  25   7 110  49]\n",
      " [  0   2   0   1   2  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.94      0.88      0.91       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.56      0.66      0.60       210\n",
      "           6       0.54      0.52      0.53       210\n",
      "           7       0.71      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   4  39  20   5]\n",
      " [  3 150   6  15  21  13   2]\n",
      " [  0   5 190   8   3   4   0]\n",
      " [  7  10   3 118  36  27   9]\n",
      " [ 19  12   0  20 141   8  10]\n",
      " [ 10  10   1  20   7 111  51]\n",
      " [  0   1   0   1   2  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.72       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.63      0.56      0.60       210\n",
      "           5       0.57      0.67      0.61       210\n",
      "           6       0.55      0.53      0.54       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   1   7  36  17   4]\n",
      " [  1 149   7  14  22  15   2]\n",
      " [  0   7 185   7   3   8   0]\n",
      " [  4   9   4 120  37  27   9]\n",
      " [ 18  12   0  19 142  10   9]\n",
      " [ 13  12   1  19   3 110  52]\n",
      " [  0   0   0   1   1  21 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.74       210\n",
      "           2       0.78      0.71      0.74       210\n",
      "           3       0.93      0.88      0.91       210\n",
      "           4       0.64      0.57      0.60       210\n",
      "           5       0.58      0.68      0.63       210\n",
      "           6       0.53      0.52      0.53       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   1   4  36  19   5]\n",
      " [  3 151   6  14  21  13   2]\n",
      " [  0   6 188   5   4   7   0]\n",
      " [  5   9   2 126  31  25  12]\n",
      " [ 17  15   0  19 141   8  10]\n",
      " [  9  12   2  17   4 120  46]\n",
      " [  0   0   0   1   3  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.68      0.74       210\n",
      "           2       0.77      0.72      0.75       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.59      0.67      0.63       210\n",
      "           6       0.58      0.57      0.57       210\n",
      "           7       0.72      0.90      0.80       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   2   1   4  38  15   6]\n",
      " [  2 154   6  12  21  13   2]\n",
      " [  0   8 186   6   4   6   0]\n",
      " [  5   9   4 120  35  26  11]\n",
      " [ 18  14   0  18 143   7  10]\n",
      " [ 12  11   1  18   4 117  47]\n",
      " [  0   0   0   2   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.78      0.73      0.75       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.67      0.57      0.62       210\n",
      "           5       0.58      0.68      0.63       210\n",
      "           6       0.58      0.56      0.57       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 93   3  42   3  35  26   8]\n",
      " [  0  94  46  11  34  23   2]\n",
      " [  1   1 180   8   3  17   0]\n",
      " [  8  15  35  44  65  31  12]\n",
      " [ 22  16   7   9 133  10  13]\n",
      " [  9   9  17  11   8  91  65]\n",
      " [  0   0   0   1   6  54 149]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.44      0.54       210\n",
      "           2       0.68      0.45      0.54       210\n",
      "           3       0.55      0.86      0.67       210\n",
      "           4       0.51      0.21      0.30       210\n",
      "           5       0.47      0.63      0.54       210\n",
      "           6       0.36      0.43      0.39       210\n",
      "           7       0.60      0.71      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ab723",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.35034013605442177\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[102   0  41  27   0   9  31]\n",
      " [ 25   2 108  25   0  14  36]\n",
      " [  7   0 179  11   0   4   9]\n",
      " [ 19   0 120  33   0   8  30]\n",
      " [ 30   0 124  38   0   3  15]\n",
      " [ 34   0  35  24   0  20  97]\n",
      " [ 14   1   4   4   0   8 179]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.49      0.46       210\n",
      "           2       0.67      0.01      0.02       210\n",
      "           3       0.29      0.85      0.44       210\n",
      "           4       0.20      0.16      0.18       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.30      0.10      0.14       210\n",
      "           7       0.45      0.85      0.59       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.34      0.35      0.26      1470\n",
      "weighted avg       0.34      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Model after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  19   5  16  23   9   9]\n",
      " [ 40 108   8  11  23  11   9]\n",
      " [ 12  14 169  11   2   1   1]\n",
      " [ 43  45  13  51  37   7  14]\n",
      " [ 60  43   8  25  61   7   6]\n",
      " [ 39  32  16  17  20  44  42]\n",
      " [ 22  19   4  13  15  39  98]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.61      0.46       210\n",
      "           2       0.39      0.51      0.44       210\n",
      "           3       0.76      0.80      0.78       210\n",
      "           4       0.35      0.24      0.29       210\n",
      "           5       0.34      0.29      0.31       210\n",
      "           6       0.37      0.21      0.27       210\n",
      "           7       0.55      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126  20   4  16  23  11  10]\n",
      " [ 35 101   9  19  19  16  11]\n",
      " [  8   9 175  10   3   3   2]\n",
      " [ 43  31  13  59  37  15  12]\n",
      " [ 47  36   7  30  66  16   8]\n",
      " [ 32  28  14  18  18  56  44]\n",
      " [ 15  12   3  12   8  60 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.60      0.49       210\n",
      "           2       0.43      0.48      0.45       210\n",
      "           3       0.78      0.83      0.80       210\n",
      "           4       0.36      0.28      0.32       210\n",
      "           5       0.38      0.31      0.34       210\n",
      "           6       0.32      0.27      0.29       210\n",
      "           7       0.53      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  23   4  23  22  11  10]\n",
      " [ 29  96  10  25  17  23  10]\n",
      " [  9   9 174  12   2   2   2]\n",
      " [ 32  35  13  63  37  14  16]\n",
      " [ 43  36  11  33  65  12  10]\n",
      " [ 28  30  14  18  20  59  41]\n",
      " [ 16  13   3   7   9  53 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.56      0.48       210\n",
      "           2       0.40      0.46      0.42       210\n",
      "           3       0.76      0.83      0.79       210\n",
      "           4       0.35      0.30      0.32       210\n",
      "           5       0.38      0.31      0.34       210\n",
      "           6       0.34      0.28      0.31       210\n",
      "           7       0.55      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.463265306122449\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122  21   4  22  22  10   9]\n",
      " [ 30  95  11  26  24  15   9]\n",
      " [  7   8 178  12   2   1   2]\n",
      " [ 33  45  12  59  36  13  12]\n",
      " [ 43  32  11  38  66  12   8]\n",
      " [ 29  31  15  22  16  51  46]\n",
      " [ 13   7   4   8  14  54 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.58      0.50       210\n",
      "           2       0.40      0.45      0.42       210\n",
      "           3       0.76      0.85      0.80       210\n",
      "           4       0.32      0.28      0.30       210\n",
      "           5       0.37      0.31      0.34       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.56      0.52      0.54       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.45      1470\n",
      "weighted avg       0.45      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  28   2  19  22   6   8]\n",
      " [ 29  98  12  29  20  11  11]\n",
      " [  8  10 176  11   1   2   2]\n",
      " [ 30  46  11  60  35   9  19]\n",
      " [ 43  35  10  34  72   8   8]\n",
      " [ 29  26  16  19  20  49  51]\n",
      " [ 15   9   3   5  12  54 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.60      0.51       210\n",
      "           2       0.39      0.47      0.42       210\n",
      "           3       0.77      0.84      0.80       210\n",
      "           4       0.34      0.29      0.31       210\n",
      "           5       0.40      0.34      0.37       210\n",
      "           6       0.35      0.23      0.28       210\n",
      "           7       0.53      0.53      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.47210884353741495\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  25   3  22  20   6   9]\n",
      " [ 27  99  10  26  20  16  12]\n",
      " [  6  13 175   9   1   3   3]\n",
      " [ 27  41  10  61  43  12  16]\n",
      " [ 36  30   8  48  71   8   9]\n",
      " [ 27  26  17  21  17  48  54]\n",
      " [ 15  10   3   5  12  50 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.60      0.53       210\n",
      "           2       0.41      0.47      0.44       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.32      0.29      0.30       210\n",
      "           5       0.39      0.34      0.36       210\n",
      "           6       0.34      0.23      0.27       210\n",
      "           7       0.53      0.55      0.54       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.2755102040816326\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 46   0   0  96   0   7  61]\n",
      " [ 13   0   0 142   0   1  54]\n",
      " [  4   0   0 184   0   9  13]\n",
      " [  9   0   0 162   0   1  38]\n",
      " [ 13   0   0 175   0   2  20]\n",
      " [ 12   0   0  72   0   7 119]\n",
      " [  5   0   0  14   0   1 190]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.22      0.29       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.19      0.77      0.31       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.25      0.03      0.06       210\n",
      "           7       0.38      0.90      0.54       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.18      0.28      0.17      1470\n",
      "weighted avg       0.18      0.28      0.17      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 44   0  32  64   0  13  57]\n",
      " [ 16   0  97  41   0   3  53]\n",
      " [  5   0 166  17   0   9  13]\n",
      " [ 10   0 111  50   0   5  34]\n",
      " [ 18   0 122  48   0   1  21]\n",
      " [ 16   0  31  38   0  11 114]\n",
      " [  6   0   4   9   0  14 177]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.21      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.29      0.79      0.43       210\n",
      "           4       0.19      0.24      0.21       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.20      0.05      0.08       210\n",
      "           7       0.38      0.84      0.52       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.21      0.30      0.22      1470\n",
      "weighted avg       0.21      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.33197278911564626\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 99   0  64   8   0   0  39]\n",
      " [ 27   3 124   7   0   0  49]\n",
      " [  7   0 190   0   0   1  12]\n",
      " [ 18   0 150   3   0   1  38]\n",
      " [ 31   0 153   9   0   0  17]\n",
      " [ 29   0  55   7   0   5 114]\n",
      " [  9   0   7   4   0   2 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.47      0.46       210\n",
      "           2       1.00      0.01      0.03       210\n",
      "           3       0.26      0.90      0.40       210\n",
      "           4       0.08      0.01      0.02       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.56      0.02      0.05       210\n",
      "           7       0.41      0.90      0.56       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.39      0.33      0.22      1470\n",
      "weighted avg       0.39      0.33      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of SVM is:\n",
      " [[113   0  51  21   0   5  20]\n",
      " [ 24   5 117  15   0  15  34]\n",
      " [  9   1 189   1   0   4   6]\n",
      " [ 18   1 141  14   0   6  30]\n",
      " [ 31   1 145  17   0   2  14]\n",
      " [ 31   1  50  14   0  17  97]\n",
      " [ 21   0   6   5   0   7 171]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.54      0.49       210\n",
      "           2       0.56      0.02      0.05       210\n",
      "           3       0.27      0.90      0.42       210\n",
      "           4       0.16      0.07      0.09       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.30      0.08      0.13       210\n",
      "           7       0.46      0.81      0.59       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.32      0.35      0.25      1470\n",
      "weighted avg       0.32      0.35      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.33945578231292517\n",
      "Confusion Matrix of SVM is:\n",
      " [[113   0  53  19   0   3  22]\n",
      " [ 28   3 117  14   0   4  44]\n",
      " [ 10   0 189   1   0   3   7]\n",
      " [ 19   1 143  11   0   4  32]\n",
      " [ 32   1 148  14   0   1  14]\n",
      " [ 34   1  51  12   0  14  98]\n",
      " [ 23   0   6   5   0   7 169]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.54      0.48       210\n",
      "           2       0.50      0.01      0.03       210\n",
      "           3       0.27      0.90      0.41       210\n",
      "           4       0.14      0.05      0.08       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.39      0.07      0.11       210\n",
      "           7       0.44      0.80      0.57       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.31      0.34      0.24      1470\n",
      "weighted avg       0.31      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.29183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 62   0  70  13   6   0  59]\n",
      " [ 21   0 134   3   2   6  44]\n",
      " [  5   0 190   2   0   1  12]\n",
      " [ 15   0 153   4   0   5  33]\n",
      " [ 25   0 160   6   1   0  18]\n",
      " [ 25   0  60   3   2  11 109]\n",
      " [ 12   0  14   1   3  19 161]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.30      0.33       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.24      0.90      0.38       210\n",
      "           4       0.12      0.02      0.03       210\n",
      "           5       0.07      0.00      0.01       210\n",
      "           6       0.26      0.05      0.09       210\n",
      "           7       0.37      0.77      0.50       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.21      0.29      0.19      1470\n",
      "weighted avg       0.21      0.29      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.22517006802721087\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3   0   0   0 207]\n",
      " [  0   0  17   0   0   0 193]\n",
      " [  0   0 121   0   0   0  89]\n",
      " [  0   0   4   0   0   0 206]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.76      0.58      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.13      1470\n",
      "weighted avg       0.13      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   2   1 172   0   0  35]\n",
      " [  0   8   9 148   0   0  45]\n",
      " [  0  13 108  67   0   0  22]\n",
      " [  0   1   3 170   0   0  36]\n",
      " [  0   4   2 187   0   0  17]\n",
      " [  0   3   5  93   0   0 109]\n",
      " [  0   0   0  26   0   0 184]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.26      0.04      0.07       210\n",
      "           3       0.84      0.51      0.64       210\n",
      "           4       0.20      0.81      0.32       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.41      0.88      0.56       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.24      0.32      0.23      1470\n",
      "weighted avg       0.24      0.32      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3904761904761905\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91   0   3  81   0   0  35]\n",
      " [ 24  11   9 124   0   0  42]\n",
      " [  4   3 132  63   0   0   8]\n",
      " [ 12   1   4 158   0   0  35]\n",
      " [ 21   2   5 166   0   0  16]\n",
      " [ 30   0  13  63   0   0 104]\n",
      " [ 12   0   2  14   0   0 182]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.43      0.45       210\n",
      "           2       0.65      0.05      0.10       210\n",
      "           3       0.79      0.63      0.70       210\n",
      "           4       0.24      0.75      0.36       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.87      0.58       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.37      0.39      0.31      1470\n",
      "weighted avg       0.37      0.39      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41904761904761906\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   7   1  76   0   8  21]\n",
      " [ 15  54   5  82   0  13  41]\n",
      " [  4  36 125  35   0   2   8]\n",
      " [  9  20   3 139   0   4  35]\n",
      " [ 18  15   3 155   0   3  16]\n",
      " [ 16   5   5  61   0  20 103]\n",
      " [  7   2   0  12   0   8 181]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.46      0.52       210\n",
      "           2       0.39      0.26      0.31       210\n",
      "           3       0.88      0.60      0.71       210\n",
      "           4       0.25      0.66      0.36       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.34      0.10      0.15       210\n",
      "           7       0.45      0.86      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.41      0.42      0.38      1470\n",
      "weighted avg       0.41      0.42      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43537414965986393\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   3   1  52  28  17  12]\n",
      " [ 15  45   5  42  52  37  14]\n",
      " [  4  20 125  32  19   5   5]\n",
      " [  9  13   3  67  79  17  22]\n",
      " [ 18   5   2  52 114   8  11]\n",
      " [ 16   5   5  38  23  51  72]\n",
      " [  7   2   0   6  10  44 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.46      0.52       210\n",
      "           2       0.48      0.21      0.30       210\n",
      "           3       0.89      0.60      0.71       210\n",
      "           4       0.23      0.32      0.27       210\n",
      "           5       0.35      0.54      0.43       210\n",
      "           6       0.28      0.24      0.26       210\n",
      "           7       0.51      0.67      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.44      1470\n",
      "weighted avg       0.48      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.463265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   3   3  46  18  16  12]\n",
      " [ 12  69  11  62  24  21  11]\n",
      " [  2  19 136  33   9   6   5]\n",
      " [  9  18   8 101  39  14  21]\n",
      " [ 20   7   5  80  77  10  11]\n",
      " [ 18  11   6  44  14  45  72]\n",
      " [  6   9   0  10   6  38 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.53      0.58       210\n",
      "           2       0.51      0.33      0.40       210\n",
      "           3       0.80      0.65      0.72       210\n",
      "           4       0.27      0.48      0.34       210\n",
      "           5       0.41      0.37      0.39       210\n",
      "           6       0.30      0.21      0.25       210\n",
      "           7       0.52      0.67      0.58       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   5   3  45  28  13  15]\n",
      " [ 10  71  14  43  39  20  13]\n",
      " [  1  18 160  13   8   3   7]\n",
      " [  5  17  13  87  52  11  25]\n",
      " [ 13   8   7  62  99  10  11]\n",
      " [ 12   8  10  39  22  46  73]\n",
      " [  4  10   0   6  10  26 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.48      0.57       210\n",
      "           2       0.52      0.34      0.41       210\n",
      "           3       0.77      0.76      0.77       210\n",
      "           4       0.29      0.41      0.34       210\n",
      "           5       0.38      0.47      0.42       210\n",
      "           6       0.36      0.22      0.27       210\n",
      "           7       0.52      0.73      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.48      1470\n",
      "weighted avg       0.50      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8   1  46  24  12  19]\n",
      " [  8  78  11  47  36  19  11]\n",
      " [  2  14 150  33   4   3   4]\n",
      " [  6  23   8  95  44  12  22]\n",
      " [ 18  24   8  64  76   8  12]\n",
      " [ 14  14   6  44  17  44  71]\n",
      " [  3  11   1  10   8  23 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.48      0.55       210\n",
      "           2       0.45      0.37      0.41       210\n",
      "           3       0.81      0.71      0.76       210\n",
      "           4       0.28      0.45      0.35       210\n",
      "           5       0.36      0.36      0.36       210\n",
      "           6       0.36      0.21      0.27       210\n",
      "           7       0.53      0.73      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.47      1470\n",
      "weighted avg       0.49      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   7   5  46  18  16  16]\n",
      " [ 10  69   9  62  29  18  13]\n",
      " [  2  22 151  23   3   5   4]\n",
      " [  9  16   8 102  41  11  23]\n",
      " [ 17  17   4  74  75  11  12]\n",
      " [ 13  14   8  44  16  40  75]\n",
      " [  6  12   1  11   8  19 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.49      0.55       210\n",
      "           2       0.44      0.33      0.38       210\n",
      "           3       0.81      0.72      0.76       210\n",
      "           4       0.28      0.49      0.36       210\n",
      "           5       0.39      0.36      0.38       210\n",
      "           6       0.33      0.19      0.24       210\n",
      "           7       0.52      0.73      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.47      1470\n",
      "weighted avg       0.49      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46598639455782315\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  17   4  43  20  12  13]\n",
      " [  8  89  11  36  32  24  10]\n",
      " [  2  18 160  18   3   6   3]\n",
      " [  8  36   7  72  51  15  21]\n",
      " [ 13  24  10  52  85  15  11]\n",
      " [ 16  34   7  28  16  40  69]\n",
      " [  4  13   1   9   7  38 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.48      0.56       210\n",
      "           2       0.39      0.42      0.40       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.28      0.34      0.31       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.27      0.19      0.22       210\n",
      "           7       0.52      0.66      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  16   6  41  17  11  14]\n",
      " [ 15  89  10  40  27  18  11]\n",
      " [  2  14 166  19   2   4   3]\n",
      " [ 16  35   9  71  40  16  23]\n",
      " [ 21  21   9  62  70  16  11]\n",
      " [ 15  30  13  28  16  39  69]\n",
      " [  4  15   1   8   7  32 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.50      0.54       210\n",
      "           2       0.40      0.42      0.41       210\n",
      "           3       0.78      0.79      0.78       210\n",
      "           4       0.26      0.34      0.30       210\n",
      "           5       0.39      0.33      0.36       210\n",
      "           6       0.29      0.19      0.23       210\n",
      "           7       0.52      0.68      0.59       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  14   5  37  16   9  13]\n",
      " [ 24  82  12  37  27  18  10]\n",
      " [  6  18 163  14   2   4   3]\n",
      " [ 18  35   7  85  32  11  22]\n",
      " [ 41  18   7  59  61  11  13]\n",
      " [ 20  24  10  32  16  40  68]\n",
      " [  9  12   0   5   8  31 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.55      0.52       210\n",
      "           2       0.40      0.39      0.40       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.32      0.40      0.35       210\n",
      "           5       0.38      0.29      0.33       210\n",
      "           6       0.32      0.19      0.24       210\n",
      "           7       0.53      0.69      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129  13   3  19  19  14  13]\n",
      " [ 19  84  12  33  28  24  10]\n",
      " [  5  17 164  13   3   5   3]\n",
      " [ 29  31   9  68  32  18  23]\n",
      " [ 49  23   5  40  64  18  11]\n",
      " [ 30  19  13  20  16  43  69]\n",
      " [ 14   8   1   8  11  31 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.61      0.53       210\n",
      "           2       0.43      0.40      0.41       210\n",
      "           3       0.79      0.78      0.79       210\n",
      "           4       0.34      0.32      0.33       210\n",
      "           5       0.37      0.30      0.33       210\n",
      "           6       0.28      0.20      0.24       210\n",
      "           7       0.52      0.65      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  15   3  20  31  17  10]\n",
      " [ 15  86  14  22  38  24  11]\n",
      " [  5  14 167  13   3   5   3]\n",
      " [ 18  26  10  60  51  23  22]\n",
      " [ 31  19  13  34  80  24   9]\n",
      " [ 21  19  15  19  27  43  66]\n",
      " [ 11  15   3  10  15  30 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.54       210\n",
      "           2       0.44      0.41      0.43       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.34      0.29      0.31       210\n",
      "           5       0.33      0.38      0.35       210\n",
      "           6       0.26      0.20      0.23       210\n",
      "           7       0.51      0.60      0.55       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.45      1470\n",
      "weighted avg       0.45      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44421768707482995\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112  11   5  20  38  16   8]\n",
      " [ 17  79  12  27  43  23   9]\n",
      " [  3  15 166  14   5   5   2]\n",
      " [ 20  27  11  55  52  34  11]\n",
      " [ 28  22   9  35  83  24   9]\n",
      " [ 20  21  13  20  28  66  42]\n",
      " [  7  13   4  12  10  72  92]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.54       210\n",
      "           2       0.42      0.38      0.40       210\n",
      "           3       0.75      0.79      0.77       210\n",
      "           4       0.30      0.26      0.28       210\n",
      "           5       0.32      0.40      0.35       210\n",
      "           6       0.28      0.31      0.29       210\n",
      "           7       0.53      0.44      0.48       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  13   6  19  26  13  12]\n",
      " [ 14  83  16  30  34  26   7]\n",
      " [  3  18 165  12   5   5   2]\n",
      " [ 24  30  12  56  50  25  13]\n",
      " [ 35  22  10  32  79  19  13]\n",
      " [ 22  23  12  17  29  59  48]\n",
      " [  7  13   3   9  16  62 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56       210\n",
      "           2       0.41      0.40      0.40       210\n",
      "           3       0.74      0.79      0.76       210\n",
      "           4       0.32      0.27      0.29       210\n",
      "           5       0.33      0.38      0.35       210\n",
      "           6       0.28      0.28      0.28       210\n",
      "           7       0.51      0.48      0.49       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44761904761904764\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  16   7  16  24  19  12]\n",
      " [ 17  84  16  27  34  22  10]\n",
      " [  4  14 166  13   5   6   2]\n",
      " [ 28  29  11  53  48  30  11]\n",
      " [ 30  25  10  32  78  24  11]\n",
      " [ 21  28  10  17  24  67  43]\n",
      " [ 10  17   1  12  13  63  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.55      0.53       210\n",
      "           2       0.39      0.40      0.40       210\n",
      "           3       0.75      0.79      0.77       210\n",
      "           4       0.31      0.25      0.28       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.29      0.32      0.30       210\n",
      "           7       0.51      0.45      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  13   6  20  25  21  11]\n",
      " [ 19  85  13  28  31  25   9]\n",
      " [  4  15 166  13   4   7   1]\n",
      " [ 24  28  10  61  42  30  15]\n",
      " [ 29  18  15  39  76  23  10]\n",
      " [ 22  27  12  20  23  58  48]\n",
      " [ 11  12   1   9  12  60 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.54      0.53       210\n",
      "           2       0.43      0.40      0.42       210\n",
      "           3       0.74      0.79      0.77       210\n",
      "           4       0.32      0.29      0.31       210\n",
      "           5       0.36      0.36      0.36       210\n",
      "           6       0.26      0.28      0.27       210\n",
      "           7       0.53      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  15   6  18  24  18  11]\n",
      " [ 17  89  13  27  30  27   7]\n",
      " [  4  14 167  13   4   7   1]\n",
      " [ 24  29  11  55  42  31  18]\n",
      " [ 26  25  11  39  72  25  12]\n",
      " [ 20  23  12  25  25  63  42]\n",
      " [ 13  11   2  12  16  60  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.56      0.55       210\n",
      "           2       0.43      0.42      0.43       210\n",
      "           3       0.75      0.80      0.77       210\n",
      "           4       0.29      0.26      0.28       210\n",
      "           5       0.34      0.34      0.34       210\n",
      "           6       0.27      0.30      0.29       210\n",
      "           7       0.51      0.46      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   9   5  17  25  21  13]\n",
      " [ 19  84  16  29  30  22  10]\n",
      " [  4  15 166  14   3   6   2]\n",
      " [ 27  24  12  59  43  31  14]\n",
      " [ 30  20  11  38  75  24  12]\n",
      " [ 20  25  12  21  23  55  54]\n",
      " [ 11  11   3  11  15  53 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.57      0.54       210\n",
      "           2       0.45      0.40      0.42       210\n",
      "           3       0.74      0.79      0.76       210\n",
      "           4       0.31      0.28      0.30       210\n",
      "           5       0.35      0.36      0.35       210\n",
      "           6       0.26      0.26      0.26       210\n",
      "           7       0.50      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.3510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 32   0   8 129   0   0  41]\n",
      " [  5   0  34 118   0   0  53]\n",
      " [  0   0 142  55   0   0  13]\n",
      " [  1   0  17 154   0   0  38]\n",
      " [  0   0  16 172   0   0  22]\n",
      " [  8   0  14  67   0   0 121]\n",
      " [  4   0   0  18   0   0 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.15      0.25       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.61      0.68      0.64       210\n",
      "           4       0.22      0.73      0.33       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.90      0.55       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.27      0.35      0.25      1470\n",
      "weighted avg       0.27      0.35      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 63   0   4 116   0   2  25]\n",
      " [  9   0  36 109   5   1  50]\n",
      " [  1   0 150  46   0   0  13]\n",
      " [  4   0  21 141   6   0  38]\n",
      " [  9   0  11 170   1   0  19]\n",
      " [ 12   0  13  64   3   5 113]\n",
      " [  6   0   1  16   0   1 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.30      0.40       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.64      0.71      0.67       210\n",
      "           4       0.21      0.67      0.32       210\n",
      "           5       0.07      0.00      0.01       210\n",
      "           6       0.56      0.02      0.05       210\n",
      "           7       0.42      0.89      0.57       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.36      0.37      0.29      1470\n",
      "weighted avg       0.36      0.37      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.44421768707482995\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   2   2  35  14   6  19]\n",
      " [ 42  26  17  42  33  18  32]\n",
      " [  8   8 142  33   6   3  10]\n",
      " [ 30   8   7  83  45   4  33]\n",
      " [ 43   4   4  67  75   2  15]\n",
      " [ 47   2  11  25  12  14  99]\n",
      " [ 18   0   0   4   2   5 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.63      0.50       210\n",
      "           2       0.52      0.12      0.20       210\n",
      "           3       0.78      0.68      0.72       210\n",
      "           4       0.29      0.40      0.33       210\n",
      "           5       0.40      0.36      0.38       210\n",
      "           6       0.27      0.07      0.11       210\n",
      "           7       0.47      0.86      0.60       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.41      1470\n",
      "weighted avg       0.45      0.44      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   4   1  27  20   8  18]\n",
      " [ 40  56   8  29  31  19  27]\n",
      " [  8  17 155  19   2   4   5]\n",
      " [ 30  11   7  65  60   8  29]\n",
      " [ 44   8   2  41  97   5  13]\n",
      " [ 47   9   8  21  12  19  94]\n",
      " [ 17   0   0   2   4  12 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.63      0.50       210\n",
      "           2       0.53      0.27      0.36       210\n",
      "           3       0.86      0.74      0.79       210\n",
      "           4       0.32      0.31      0.31       210\n",
      "           5       0.43      0.46      0.44       210\n",
      "           6       0.25      0.09      0.13       210\n",
      "           7       0.48      0.83      0.61       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.47      0.48      0.45      1470\n",
      "weighted avg       0.47      0.48      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   5   2  29  23   9  16]\n",
      " [ 35  63   6  34  32  18  22]\n",
      " [  8  19 160  10   4   4   5]\n",
      " [ 23  14   6  69  60  10  28]\n",
      " [ 37   5   3  47 102   3  13]\n",
      " [ 41   7   9  24  12  33  84]\n",
      " [ 15   0   0   4   4  15 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.60      0.51       210\n",
      "           2       0.56      0.30      0.39       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.32      0.33      0.32       210\n",
      "           5       0.43      0.49      0.46       210\n",
      "           6       0.36      0.16      0.22       210\n",
      "           7       0.51      0.82      0.63       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.48      1470\n",
      "weighted avg       0.50      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   4   1  28  21  10  14]\n",
      " [ 35  69   5  30  34  17  20]\n",
      " [  8  16 162  11   4   3   6]\n",
      " [ 24  12   5  79  52  12  26]\n",
      " [ 38   6   2  46  99   6  13]\n",
      " [ 37  10   5  27  12  42  77]\n",
      " [ 14   0   0   5   4  16 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.63      0.53       210\n",
      "           2       0.59      0.33      0.42       210\n",
      "           3       0.90      0.77      0.83       210\n",
      "           4       0.35      0.38      0.36       210\n",
      "           5       0.44      0.47      0.45       210\n",
      "           6       0.40      0.20      0.27       210\n",
      "           7       0.52      0.81      0.64       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   4   1  19  24  10  13]\n",
      " [ 31  70   7  40  29  15  18]\n",
      " [  7  15 170  10   2   2   4]\n",
      " [ 21  11   8  82  50  15  23]\n",
      " [ 43   7   3  42  98   5  12]\n",
      " [ 30  11   8  30  13  47  71]\n",
      " [ 13   0   0   6   4  16 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.66      0.56       210\n",
      "           2       0.59      0.33      0.43       210\n",
      "           3       0.86      0.81      0.84       210\n",
      "           4       0.36      0.39      0.37       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.43      0.22      0.29       210\n",
      "           7       0.55      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.51      1470\n",
      "weighted avg       0.53      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.545578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   4   0  21  22   9  15]\n",
      " [ 24  89   6  36  25  15  15]\n",
      " [  6  12 170  14   2   2   4]\n",
      " [ 17  15   6  89  46  12  25]\n",
      " [ 38   4   2  46 102   7  11]\n",
      " [ 30  11   5  31  15  47  71]\n",
      " [ 11   0   0   5   4  24 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.66      0.59       210\n",
      "           2       0.66      0.42      0.52       210\n",
      "           3       0.90      0.81      0.85       210\n",
      "           4       0.37      0.42      0.39       210\n",
      "           5       0.47      0.49      0.48       210\n",
      "           6       0.41      0.22      0.29       210\n",
      "           7       0.54      0.79      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.545578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   5   0  17  25   9  15]\n",
      " [ 21  91   7  36  26  12  17]\n",
      " [  6  11 172  13   2   2   4]\n",
      " [ 19  12   6  84  51  13  25]\n",
      " [ 37   4   3  41 105   7  13]\n",
      " [ 29  13   8  28  13  48  71]\n",
      " [  9   4   0   4   5  25 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.66      0.59       210\n",
      "           2       0.65      0.43      0.52       210\n",
      "           3       0.88      0.82      0.85       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.41      0.23      0.29       210\n",
      "           7       0.53      0.78      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   5   0  19  26   9  14]\n",
      " [ 17  91   5  37  29  17  14]\n",
      " [  5  10 175  12   2   3   3]\n",
      " [ 20  14   6  84  50  12  24]\n",
      " [ 34   5   2  44 108   6  11]\n",
      " [ 19  13   6  31  17  54  70]\n",
      " [  7   1   0   6   8  21 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.65      0.61       210\n",
      "           2       0.65      0.43      0.52       210\n",
      "           3       0.90      0.83      0.87       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.45      0.51      0.48       210\n",
      "           6       0.44      0.26      0.33       210\n",
      "           7       0.55      0.80      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   4   1  17  27   8  15]\n",
      " [ 13  93   6  39  26  15  18]\n",
      " [  2  13 170  15   3   3   4]\n",
      " [ 18  13   8  83  52  10  26]\n",
      " [ 36   2   3  40 108   9  12]\n",
      " [ 20  18   7  25  18  57  65]\n",
      " [ 10   4   0   3   8  23 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.66      0.62       210\n",
      "           2       0.63      0.44      0.52       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.37      0.40      0.38       210\n",
      "           5       0.45      0.51      0.48       210\n",
      "           6       0.46      0.27      0.34       210\n",
      "           7       0.54      0.77      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.54      1470\n",
      "weighted avg       0.56      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5578231292517006\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   4   1  19  22  11  15]\n",
      " [ 15  96   6  34  25  20  14]\n",
      " [  4   9 171  16   3   4   3]\n",
      " [ 13  13   6  90  49  16  23]\n",
      " [ 35   8   2  38 105   8  14]\n",
      " [ 20  12   4  32  16  60  66]\n",
      " [  7   1   0   7   8  27 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.66      0.62       210\n",
      "           2       0.67      0.46      0.54       210\n",
      "           3       0.90      0.81      0.85       210\n",
      "           4       0.38      0.43      0.40       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.41      0.29      0.34       210\n",
      "           7       0.54      0.76      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   5   1  17  30  12  15]\n",
      " [ 16 100   7  34  23  16  14]\n",
      " [  4  11 174  13   2   1   5]\n",
      " [ 12  16   7  90  50  14  21]\n",
      " [ 24   9   2  40 113   9  13]\n",
      " [ 19  12   7  27  16  58  71]\n",
      " [  6   5   0   6   9  30 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       210\n",
      "           2       0.63      0.48      0.54       210\n",
      "           3       0.88      0.83      0.85       210\n",
      "           4       0.40      0.43      0.41       210\n",
      "           5       0.47      0.54      0.50       210\n",
      "           6       0.41      0.28      0.33       210\n",
      "           7       0.53      0.73      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   5   0  14  30  12  15]\n",
      " [ 13  97   9  30  26  24  11]\n",
      " [  1  12 175  15   2   4   1]\n",
      " [  9  13   7  87  53  16  25]\n",
      " [ 30   8   3  40 109   8  12]\n",
      " [ 19  14   7  30  16  60  64]\n",
      " [  8   4   0   4   8  30 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.64      0.63       210\n",
      "           2       0.63      0.46      0.53       210\n",
      "           3       0.87      0.83      0.85       210\n",
      "           4       0.40      0.41      0.40       210\n",
      "           5       0.45      0.52      0.48       210\n",
      "           6       0.39      0.29      0.33       210\n",
      "           7       0.55      0.74      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   4   0  17  29  14  13]\n",
      " [ 12 105   7  36  19  17  14]\n",
      " [  4  10 174  15   3   2   2]\n",
      " [ 14  14   6  88  48  14  26]\n",
      " [ 28   9   2  42 107  11  11]\n",
      " [ 23  13   7  30  15  61  61]\n",
      " [  6   3   0   5   8  27 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.63      0.62       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.38      0.42      0.40       210\n",
      "           5       0.47      0.51      0.49       210\n",
      "           6       0.42      0.29      0.34       210\n",
      "           7       0.56      0.77      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   5   0  15  32  11  14]\n",
      " [ 13 105   6  36  22  16  12]\n",
      " [  3  11 175  15   2   2   2]\n",
      " [ 14  17   7  83  50  14  25]\n",
      " [ 29  10   3  46 104   8  10]\n",
      " [ 13  16   5  29  16  65  66]\n",
      " [  4   3   0   6  10  27 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.63      0.63       210\n",
      "           2       0.63      0.50      0.56       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.45      0.31      0.37       210\n",
      "           7       0.55      0.76      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   0  20  32  11  13]\n",
      " [ 17 100   7  31  25  15  15]\n",
      " [  3   8 176  15   3   2   3]\n",
      " [  9  14   8  91  48  16  24]\n",
      " [ 25  12   2  46 103   8  14]\n",
      " [ 19  18   6  28  14  62  63]\n",
      " [  4   3   0   4  10  36 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.61      0.62       210\n",
      "           2       0.62      0.48      0.54       210\n",
      "           3       0.88      0.84      0.86       210\n",
      "           4       0.39      0.43      0.41       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.41      0.30      0.34       210\n",
      "           7       0.54      0.73      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   8   0  18  28  11  15]\n",
      " [ 13  99   8  37  24  18  11]\n",
      " [  3  12 173  16   3   1   2]\n",
      " [ 12  18   7  87  50  13  23]\n",
      " [ 28   9   3  47 102  10  11]\n",
      " [ 16  18   7  24  18  65  62]\n",
      " [  6   5   0   7   7  34 151]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       210\n",
      "           2       0.59      0.47      0.52       210\n",
      "           3       0.87      0.82      0.85       210\n",
      "           4       0.37      0.41      0.39       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.43      0.31      0.36       210\n",
      "           7       0.55      0.72      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   4   0  17  31  11  17]\n",
      " [ 14 103   5  39  20  13  16]\n",
      " [  0  12 176  13   4   3   2]\n",
      " [ 15  20   8  77  53  16  21]\n",
      " [ 30  11   3  46 103   7  10]\n",
      " [ 18  20   7  26  12  69  58]\n",
      " [  4   3   0   8   9  31 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       210\n",
      "           2       0.60      0.49      0.54       210\n",
      "           3       0.88      0.84      0.86       210\n",
      "           4       0.34      0.37      0.35       210\n",
      "           5       0.44      0.49      0.47       210\n",
      "           6       0.46      0.33      0.38       210\n",
      "           7       0.56      0.74      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5578231292517006\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126  10   0  23  26  10  15]\n",
      " [ 11 104   9  28  24  17  17]\n",
      " [  0  11 178  14   1   4   2]\n",
      " [ 13  19   7  86  48  13  24]\n",
      " [ 31   7   3  38 109  13   9]\n",
      " [ 21  14   7  27  15  63  63]\n",
      " [  6   6   0   5   9  30 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.60      0.60       210\n",
      "           2       0.61      0.50      0.55       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.47      0.52      0.49       210\n",
      "           6       0.42      0.30      0.35       210\n",
      "           7       0.54      0.73      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3054421768707483\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 42   0  49  49   0  14  56]\n",
      " [ 13   0 108  32   1   4  52]\n",
      " [  3   0 173  12   0   6  16]\n",
      " [  8   0 124  38   1  10  29]\n",
      " [ 14   0 129  41   4   3  19]\n",
      " [ 12   0  39  30   4  26  99]\n",
      " [  4   0   5   9   1  25 166]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.20      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.28      0.82      0.41       210\n",
      "           4       0.18      0.18      0.18       210\n",
      "           5       0.36      0.02      0.04       210\n",
      "           6       0.30      0.12      0.17       210\n",
      "           7       0.38      0.79      0.51       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.28      0.31      0.23      1470\n",
      "weighted avg       0.28      0.31      0.23      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_gkb.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[141   4   4   8  31  17   5]\n",
      " [  3 124  20  17  26  15   5]\n",
      " [  1   4 185  10   1   9   0]\n",
      " [  7   4  12 139  27  18   3]\n",
      " [ 26  11   3  31 131   2   6]\n",
      " [ 18  10   9  25   9  95  44]\n",
      " [  0   5   0   1   1  17 186]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.67      0.69       210\n",
      "           2       0.77      0.59      0.67       210\n",
      "           3       0.79      0.88      0.84       210\n",
      "           4       0.60      0.66      0.63       210\n",
      "           5       0.58      0.62      0.60       210\n",
      "           6       0.55      0.45      0.50       210\n",
      "           7       0.75      0.89      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6034013605442177\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   5   4   4  44   5   3]\n",
      " [ 23 134   9   6  30   5   3]\n",
      " [  5   5 186   4   8   2   0]\n",
      " [ 28  24  12  91  48   5   2]\n",
      " [ 59  16   8  21  98   7   1]\n",
      " [ 33  26   6  18  11  59  57]\n",
      " [  8   3   1   4   6  14 174]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.69      0.57       210\n",
      "           2       0.63      0.64      0.63       210\n",
      "           3       0.82      0.89      0.85       210\n",
      "           4       0.61      0.43      0.51       210\n",
      "           5       0.40      0.47      0.43       210\n",
      "           6       0.61      0.28      0.38       210\n",
      "           7       0.72      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.608843537414966\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   5   5   7  44   7   2]\n",
      " [ 12 137  10   8  33   6   4]\n",
      " [  3   7 186   3   8   3   0]\n",
      " [ 29  14  16  88  54   7   2]\n",
      " [ 48  15   8  27 105   6   1]\n",
      " [ 26  17   4  17  12  72  62]\n",
      " [  6   1   0   2   1  33 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.67      0.59       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.81      0.89      0.85       210\n",
      "           4       0.58      0.42      0.49       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.54      0.34      0.42       210\n",
      "           7       0.70      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   4   2   8  53   8   1]\n",
      " [ 11 142  10   8  28   7   4]\n",
      " [  2   9 183   7   7   2   0]\n",
      " [ 27  15  13  86  60   7   2]\n",
      " [ 49  14   7  26 108   5   1]\n",
      " [ 23  20   3  18  18  61  67]\n",
      " [  3   1   0   1   1  22 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.64      0.58       210\n",
      "           2       0.69      0.68      0.68       210\n",
      "           3       0.84      0.87      0.86       210\n",
      "           4       0.56      0.41      0.47       210\n",
      "           5       0.39      0.51      0.45       210\n",
      "           6       0.54      0.29      0.38       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   6   3   5  51   6   2]\n",
      " [ 13 137   8   6  34   7   5]\n",
      " [  3   9 184   5   6   3   0]\n",
      " [ 28  14  14  81  64   6   3]\n",
      " [ 36  14   6  24 123   5   2]\n",
      " [ 27  20   5  17  13  59  69]\n",
      " [  2   1   0   1   2  24 180]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.65      0.60       210\n",
      "           2       0.68      0.65      0.67       210\n",
      "           3       0.84      0.88      0.86       210\n",
      "           4       0.58      0.39      0.46       210\n",
      "           5       0.42      0.59      0.49       210\n",
      "           6       0.54      0.28      0.37       210\n",
      "           7       0.69      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138   4   3   5  50   8   2]\n",
      " [  9 135  11  10  31   8   6]\n",
      " [  4   7 181   5  10   3   0]\n",
      " [ 23  12  12  91  62   6   4]\n",
      " [ 36  12   6  22 127   4   3]\n",
      " [ 29  16   4  19  15  56  71]\n",
      " [  2   1   0   0   2  17 188]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.66      0.61       210\n",
      "           2       0.72      0.64      0.68       210\n",
      "           3       0.83      0.86      0.85       210\n",
      "           4       0.60      0.43      0.50       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.55      0.27      0.36       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.61      1470\n",
      "weighted avg       0.63      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   1   3   6  52   9   2]\n",
      " [ 10 132  13  10  32   5   8]\n",
      " [  4   6 184   3  10   3   0]\n",
      " [ 23  12  11  92  62   7   3]\n",
      " [ 38  13   4  21 127   3   4]\n",
      " [ 31  17   6  17  10  62  67]\n",
      " [  2   1   0   0   3  23 181]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.65      0.60       210\n",
      "           2       0.73      0.63      0.67       210\n",
      "           3       0.83      0.88      0.85       210\n",
      "           4       0.62      0.44      0.51       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.55      0.30      0.39       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.61      1470\n",
      "weighted avg       0.63      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 83   6  22   9  60  25   5]\n",
      " [  1  86  19  11  57  29   7]\n",
      " [  4  13 157   6  12  18   0]\n",
      " [  6  10  19  49  97  27   2]\n",
      " [  9  12   8  20 145  11   5]\n",
      " [ 14  14   6  13  14  78  71]\n",
      " [  0   5   0   1   0  25 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.40      0.51       210\n",
      "           2       0.59      0.41      0.48       210\n",
      "           3       0.68      0.75      0.71       210\n",
      "           4       0.45      0.23      0.31       210\n",
      "           5       0.38      0.69      0.49       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 88  12  24  11  47  23   5]\n",
      " [  2  91  16  11  54  28   8]\n",
      " [  9  15 142  16  12  15   1]\n",
      " [ 11  10  18  67  76  26   2]\n",
      " [ 12  11   7  24 141  11   4]\n",
      " [ 20  15   3  16  10  81  65]\n",
      " [  0   5   0   1   0  34 170]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.42      0.50       210\n",
      "           2       0.57      0.43      0.49       210\n",
      "           3       0.68      0.68      0.68       210\n",
      "           4       0.46      0.32      0.38       210\n",
      "           5       0.41      0.67      0.51       210\n",
      "           6       0.37      0.39      0.38       210\n",
      "           7       0.67      0.81      0.73       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.52      1470\n",
      "weighted avg       0.54      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of SVM is:\n",
      " [[131   4   2   8  41  20   4]\n",
      " [  4 142  10  12  25  12   5]\n",
      " [  2   3 182  13   5   5   0]\n",
      " [  3   6   8 132  39  20   2]\n",
      " [ 19  11   1  26 145   3   5]\n",
      " [ 18  12   6  26   8  99  41]\n",
      " [  0   3   0   1   1  18 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.68       210\n",
      "           2       0.78      0.68      0.73       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.61      0.63      0.62       210\n",
      "           5       0.55      0.69      0.61       210\n",
      "           6       0.56      0.47      0.51       210\n",
      "           7       0.77      0.89      0.82       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7231292517006803\n",
      "Confusion Matrix of SVM is:\n",
      " [[137   2   2   8  38  20   3]\n",
      " [  4 156   7  13  14  13   3]\n",
      " [  0   5 186  12   3   4   0]\n",
      " [  5   6   9 140  31  17   2]\n",
      " [ 16  14   1  29 141   4   5]\n",
      " [  9  11   3  28   8 117  34]\n",
      " [  0   1   0   1   1  21 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.65      0.72       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.89      0.89      0.89       210\n",
      "           4       0.61      0.67      0.63       210\n",
      "           5       0.60      0.67      0.63       210\n",
      "           6       0.60      0.56      0.58       210\n",
      "           7       0.80      0.89      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of SVM is:\n",
      " [[135   3   2  10  36  21   3]\n",
      " [  3 154   7  14  14  14   4]\n",
      " [  2   4 181  15   4   4   0]\n",
      " [  3   7   7 140  32  19   2]\n",
      " [ 18  15   1  32 136   3   5]\n",
      " [ 12  12   3  27   7 110  39]\n",
      " [  0   1   0   1   1  21 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.64      0.70       210\n",
      "           2       0.79      0.73      0.76       210\n",
      "           3       0.90      0.86      0.88       210\n",
      "           4       0.59      0.67      0.62       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.57      0.52      0.55       210\n",
      "           7       0.78      0.89      0.83       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of SVM is:\n",
      " [[129   3   0   4  51  19   4]\n",
      " [  3 116  21  15  37  13   5]\n",
      " [  1   5 179  10   5  10   0]\n",
      " [  7   4  11 117  50  19   2]\n",
      " [ 20   9   5  15 152   3   6]\n",
      " [ 16   9   8  28  14  88  47]\n",
      " [  1   4   0   1   2  15 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.61      0.67       210\n",
      "           2       0.77      0.55      0.64       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.62      0.56      0.58       210\n",
      "           5       0.49      0.72      0.58       210\n",
      "           6       0.53      0.42      0.47       210\n",
      "           7       0.75      0.89      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0 186   0   0   0  24]\n",
      " [  0   0 179   0   0   0  31]\n",
      " [  0   0 194   0   0   0  16]\n",
      " [  0   0 196   0   0   0  14]\n",
      " [  0   0 202   0   0   0   8]\n",
      " [  0   0  77   0   0   0 133]\n",
      " [  0   0  23   0   0   0 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.18      0.92      0.31       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.45      0.89      0.60       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.09      0.26      0.13      1470\n",
      "weighted avg       0.09      0.26      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0 177  21   3]\n",
      " [  0   0   6   0 173  23   8]\n",
      " [  0   0 113   0  81  14   2]\n",
      " [  0   0   8   0 188  10   4]\n",
      " [  0   0   5   0 197   5   3]\n",
      " [  0   0   4   0  73  68  65]\n",
      " [  0   0   0   0  23  35 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.78      0.54      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.94      0.35       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.64      0.72      0.68       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.29      0.36      0.29      1470\n",
      "weighted avg       0.29      0.36      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.42857142857142855\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   0   5  69   0  21   3]\n",
      " [ 21   9   4 154   0  18   4]\n",
      " [  5   0 107  82   0  16   0]\n",
      " [ 23   0   4 169   0  13   1]\n",
      " [ 48   0   2 152   0   5   3]\n",
      " [ 23   0   3  51   0  90  43]\n",
      " [ 16   0   0   7   0  44 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.53      0.49       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.86      0.51      0.64       210\n",
      "           4       0.25      0.80      0.38       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.73      0.68      0.70       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.53      0.43      0.39      1470\n",
      "weighted avg       0.53      0.43      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  17   3  65   0  20   4]\n",
      " [  9  74   4 101   0  16   6]\n",
      " [  3   7 107  77   0  15   1]\n",
      " [ 13  29   4 150   0  13   1]\n",
      " [ 33  26   2 141   0   5   3]\n",
      " [  9  24   2  42   0  75  58]\n",
      " [  0  17   0   6   0  32 155]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.48      0.53       210\n",
      "           2       0.38      0.35      0.37       210\n",
      "           3       0.88      0.51      0.64       210\n",
      "           4       0.26      0.71      0.38       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.43      0.36      0.39       210\n",
      "           7       0.68      0.74      0.71       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.43      1470\n",
      "weighted avg       0.46      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47210884353741495\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   4   6  64   0  19   2]\n",
      " [ 11  71  21  86   1  15   5]\n",
      " [  7   6 135  49   0  12   1]\n",
      " [ 24  19   4 148   0  15   0]\n",
      " [ 49  11   6 135   0   6   3]\n",
      " [ 22  11   9  39   0  83  46]\n",
      " [ 16   1   3   4   0  44 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.55      0.51       210\n",
      "           2       0.58      0.34      0.43       210\n",
      "           3       0.73      0.64      0.69       210\n",
      "           4       0.28      0.70      0.40       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.43      0.40      0.41       210\n",
      "           7       0.71      0.68      0.69       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.45      1470\n",
      "weighted avg       0.46      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   4   6   9  70  18   3]\n",
      " [  9  77  14  19  72  15   4]\n",
      " [  5  13 129  16  35  12   0]\n",
      " [ 19   6   4  98  69  14   0]\n",
      " [ 31  13   0  36 122   5   3]\n",
      " [ 19  14   6  20  26  80  45]\n",
      " [ 16   2   1   2   3  31 155]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.48      0.49       210\n",
      "           2       0.60      0.37      0.45       210\n",
      "           3       0.81      0.61      0.70       210\n",
      "           4       0.49      0.47      0.48       210\n",
      "           5       0.31      0.58      0.40       210\n",
      "           6       0.46      0.38      0.42       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.56      0.52      0.52      1470\n",
      "weighted avg       0.56      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   4   4  11  79   8   3]\n",
      " [ 10 101   5  24  53  14   3]\n",
      " [  5   9 130  15  39  11   1]\n",
      " [ 15   9   4 101  65  14   2]\n",
      " [ 31  18   0  36 117   5   3]\n",
      " [ 16  10   5  19  35  75  50]\n",
      " [ 15   0   1   3   5  30 156]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.48      0.50       210\n",
      "           2       0.67      0.48      0.56       210\n",
      "           3       0.87      0.62      0.72       210\n",
      "           4       0.48      0.48      0.48       210\n",
      "           5       0.30      0.56      0.39       210\n",
      "           6       0.48      0.36      0.41       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.58      0.53      0.54      1470\n",
      "weighted avg       0.58      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   4   6  22  51  14   4]\n",
      " [ 11 103   7  38  33  13   5]\n",
      " [  6   9 137  32  15   8   3]\n",
      " [  9   9   5 115  48  23   1]\n",
      " [ 23  17   1  54  97  15   3]\n",
      " [ 11  14   6  33  17  85  44]\n",
      " [  4   3   1   5   3  46 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.52      0.57       210\n",
      "           2       0.65      0.49      0.56       210\n",
      "           3       0.84      0.65      0.73       210\n",
      "           4       0.38      0.55      0.45       210\n",
      "           5       0.37      0.46      0.41       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.71      0.70      0.71       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.55      1470\n",
      "weighted avg       0.57      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   8   5  20  36   8   4]\n",
      " [ 14 103   5  25  47  13   3]\n",
      " [  7   6 134  26  23  11   3]\n",
      " [ 22  20   3  94  46  25   0]\n",
      " [ 46   9   2  38 102  10   3]\n",
      " [ 18  16   5  21  22  81  47]\n",
      " [  3   3   0   9   2  40 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.61      0.57       210\n",
      "           2       0.62      0.49      0.55       210\n",
      "           3       0.87      0.64      0.74       210\n",
      "           4       0.40      0.45      0.42       210\n",
      "           5       0.37      0.49      0.42       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.72      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.55      1470\n",
      "weighted avg       0.56      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.545578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   9  10  19  43   9   4]\n",
      " [ 14 107  14  18  35  19   3]\n",
      " [  8  13 149  13  15   9   3]\n",
      " [ 15  19  16  92  41  27   0]\n",
      " [ 41  10  10  36 103   7   3]\n",
      " [ 10  17   9  25  24  88  37]\n",
      " [  5   4   3   7   4  40 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.55      0.55       210\n",
      "           2       0.60      0.51      0.55       210\n",
      "           3       0.71      0.71      0.71       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.39      0.49      0.43       210\n",
      "           6       0.44      0.42      0.43       210\n",
      "           7       0.75      0.70      0.72       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123  15   5  12  38  11   6]\n",
      " [ 24 105  10  18  34  16   3]\n",
      " [ 11  14 146  15  14   7   3]\n",
      " [ 22  22  10  91  36  28   1]\n",
      " [ 45  21   3  42  85  11   3]\n",
      " [ 17  20   8  26  11  87  41]\n",
      " [ 12   6   2   5   3  33 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.59      0.53       210\n",
      "           2       0.52      0.50      0.51       210\n",
      "           3       0.79      0.70      0.74       210\n",
      "           4       0.44      0.43      0.43       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.45      0.41      0.43       210\n",
      "           7       0.72      0.71      0.72       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.54      1470\n",
      "weighted avg       0.54      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123  14   8  12  38  11   4]\n",
      " [ 21 106  14  20  33  11   5]\n",
      " [  5  13 157  16   9   7   3]\n",
      " [ 24  26   9  92  36  22   1]\n",
      " [ 45  21   4  38  91   7   4]\n",
      " [ 23  27   6  26  16  77  35]\n",
      " [  8   7   2  10   4  40 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.54       210\n",
      "           2       0.50      0.50      0.50       210\n",
      "           3       0.79      0.75      0.77       210\n",
      "           4       0.43      0.44      0.43       210\n",
      "           5       0.40      0.43      0.42       210\n",
      "           6       0.44      0.37      0.40       210\n",
      "           7       0.73      0.66      0.69       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.54      1470\n",
      "weighted avg       0.54      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  22   8  11  35  10   6]\n",
      " [ 16 108  14  19  31  16   6]\n",
      " [  3  13 163  12   7   9   3]\n",
      " [ 16  23  11  89  40  30   1]\n",
      " [ 31  24   4  40  94  12   5]\n",
      " [ 14  29   7  26  19  77  38]\n",
      " [  5   9   2   6   3  39 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.56      0.57       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.40      0.37      0.38       210\n",
      "           7       0.71      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  12  10  20  30  10   6]\n",
      " [ 21 105  11  18  33  17   5]\n",
      " [  5  11 166   8  10   7   3]\n",
      " [ 25  22  14  81  42  26   0]\n",
      " [ 37  21   4  45  91   8   4]\n",
      " [ 16  27  10  20  16  80  41]\n",
      " [ 10   1   4  10   1  38 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.58      0.55       210\n",
      "           2       0.53      0.50      0.51       210\n",
      "           3       0.76      0.79      0.77       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.41      0.43      0.42       210\n",
      "           6       0.43      0.38      0.40       210\n",
      "           7       0.71      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120  13  11  17  32  12   5]\n",
      " [ 19 107  12  23  27  18   4]\n",
      " [  8   6 161  10  13   9   3]\n",
      " [ 21  21  10  83  45  27   3]\n",
      " [ 36  18   6  39  92  16   3]\n",
      " [ 13  24   8  19  17  87  42]\n",
      " [  8   8   3   4   4  33 150]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.57      0.55       210\n",
      "           2       0.54      0.51      0.53       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.43      0.40      0.41       210\n",
      "           5       0.40      0.44      0.42       210\n",
      "           6       0.43      0.41      0.42       210\n",
      "           7       0.71      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  17   8  17  35  10   5]\n",
      " [ 15 106  10  26  32  15   6]\n",
      " [  2   9 167  16   8   6   2]\n",
      " [ 18  31   6  86  36  30   3]\n",
      " [ 37  24   4  38  86  16   5]\n",
      " [ 13  23   8  25  19  81  41]\n",
      " [ 10   7   1   3   6  40 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.56       210\n",
      "           2       0.49      0.50      0.50       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.70      0.68      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  11   8  20  37   9   9]\n",
      " [ 16 104  13  30  25  19   3]\n",
      " [  5  12 161  12  11   5   4]\n",
      " [ 17  28  10  86  38  29   2]\n",
      " [ 27  26   7  36  94  15   5]\n",
      " [ 16  23  11  15  17  80  48]\n",
      " [  6   3   1   5   7  41 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.55      0.56       210\n",
      "           2       0.50      0.50      0.50       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.40      0.38      0.39       210\n",
      "           7       0.67      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  15  11  20  27  11   8]\n",
      " [ 18 110  11  20  26  20   5]\n",
      " [  5   9 161  13   9   9   4]\n",
      " [ 20  26  14  78  45  26   1]\n",
      " [ 42  23   3  34  89  15   4]\n",
      " [ 16  33   8  20  12  79  42]\n",
      " [  9   5   5   3   5  37 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.56      0.54       210\n",
      "           2       0.50      0.52      0.51       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.41      0.37      0.39       210\n",
      "           5       0.42      0.42      0.42       210\n",
      "           6       0.40      0.38      0.39       210\n",
      "           7       0.70      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  14   8  16  38  15   4]\n",
      " [ 20 108  12  22  28  17   3]\n",
      " [  2   8 165  10  13   9   3]\n",
      " [ 27  26  11  78  40  25   3]\n",
      " [ 33  26   8  35  82  22   4]\n",
      " [ 11  24   8  21  18  84  44]\n",
      " [ 11   3   2   3   2  40 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.52      0.51      0.52       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.42      0.37      0.39       210\n",
      "           5       0.37      0.39      0.38       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.71      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119  11  10  18  33  12   7]\n",
      " [ 18 109  14  22  27  15   5]\n",
      " [  4  14 160   8  12   9   3]\n",
      " [ 22  27  11  81  40  27   2]\n",
      " [ 39  21   9  36  85  16   4]\n",
      " [ 16  25   5  18  17  85  44]\n",
      " [  6   2   2   7   2  38 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.57      0.55       210\n",
      "           2       0.52      0.52      0.52       210\n",
      "           3       0.76      0.76      0.76       210\n",
      "           4       0.43      0.39      0.41       210\n",
      "           5       0.39      0.40      0.40       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.70      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.2836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  1   0 177   1   2   3  26]\n",
      " [  0   5 143   0   4   0  58]\n",
      " [  0   0 194   0   0   0  16]\n",
      " [  0   0 176   3   6   1  24]\n",
      " [  0   2 190   0   5   1  12]\n",
      " [  0   5  60   1   1   3 140]\n",
      " [  0   0   4   0   0   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.01       210\n",
      "           2       0.42      0.02      0.05       210\n",
      "           3       0.21      0.92      0.34       210\n",
      "           4       0.60      0.01      0.03       210\n",
      "           5       0.28      0.02      0.04       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.43      0.98      0.60       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.47      0.28      0.16      1470\n",
      "weighted avg       0.47      0.28      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.48027210884353744\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 52   6  50   2  74  15  11]\n",
      " [  5  67  29   4  67  23  15]\n",
      " [  7   1 177   4   7  11   3]\n",
      " [  6   8  32  13 127  10  14]\n",
      " [  7  11  12   1 167   5   7]\n",
      " [ 12  14  11   1  32  30 110]\n",
      " [  1   2   0   0   3   4 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.25      0.35       210\n",
      "           2       0.61      0.32      0.42       210\n",
      "           3       0.57      0.84      0.68       210\n",
      "           4       0.52      0.06      0.11       210\n",
      "           5       0.35      0.80      0.49       210\n",
      "           6       0.31      0.14      0.19       210\n",
      "           7       0.56      0.95      0.70       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.42      1470\n",
      "weighted avg       0.50      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.572108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122  11   2   8  39  20   8]\n",
      " [  5 111  10  15  43  17   9]\n",
      " [  5  18 158   9   6  13   1]\n",
      " [  9  18  11  75  75  17   5]\n",
      " [ 25  15   5  19 134   6   6]\n",
      " [ 20  22   4  11  14  50  89]\n",
      " [  0   6   0   1   0  12 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.55      0.53      0.54       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.54      0.36      0.43       210\n",
      "           5       0.43      0.64      0.51       210\n",
      "           6       0.37      0.24      0.29       210\n",
      "           7       0.62      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6068027210884354\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133  12   0  10  27  22   6]\n",
      " [  5 117   4  29  31  19   5]\n",
      " [  5  15 163  10   5  12   0]\n",
      " [ 12  21   5 107  43  18   4]\n",
      " [ 31  17   0  30 122   5   5]\n",
      " [ 19  21   5  16   7  64  78]\n",
      " [  0   5   0   1   0  18 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.63      0.64       210\n",
      "           2       0.56      0.56      0.56       210\n",
      "           3       0.92      0.78      0.84       210\n",
      "           4       0.53      0.51      0.52       210\n",
      "           5       0.52      0.58      0.55       210\n",
      "           6       0.41      0.30      0.35       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6136054421768707\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123  10   2   7  41  22   5]\n",
      " [  5 113   5  28  36  18   5]\n",
      " [  3   9 168  14   6  10   0]\n",
      " [  9  12   5 115  45  21   3]\n",
      " [ 18  19   2  38 123   6   4]\n",
      " [ 19  20   1  19   9  74  68]\n",
      " [  0   5   0   1   0  18 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.59      0.64       210\n",
      "           2       0.60      0.54      0.57       210\n",
      "           3       0.92      0.80      0.85       210\n",
      "           4       0.52      0.55      0.53       210\n",
      "           5       0.47      0.59      0.52       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.69      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6353741496598639\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   5   0  14  40  25   3]\n",
      " [  4 120   5  21  37  18   5]\n",
      " [  3   9 170  11   6  10   1]\n",
      " [  8  13   5 123  39  20   2]\n",
      " [ 15  14   0  39 130   9   3]\n",
      " [ 12  18   1  21  10  87  61]\n",
      " [  0   5   0   1   0  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.65      0.57      0.61       210\n",
      "           3       0.94      0.81      0.87       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.50      0.62      0.55       210\n",
      "           6       0.45      0.41      0.43       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   7   1  13  33  24   3]\n",
      " [  2 122   4  24  37  17   4]\n",
      " [  3   7 165  16  10   9   0]\n",
      " [ 10  15   5 128  29  19   4]\n",
      " [ 17  11   1  42 126   9   4]\n",
      " [ 17  17   1  24   6  92  53]\n",
      " [  0   5   0   1   0  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.61      0.66       210\n",
      "           2       0.66      0.58      0.62       210\n",
      "           3       0.93      0.79      0.85       210\n",
      "           4       0.52      0.61      0.56       210\n",
      "           5       0.52      0.60      0.56       210\n",
      "           6       0.48      0.44      0.46       210\n",
      "           7       0.73      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   5   0  13  37  24   3]\n",
      " [  2 131   3  19  34  16   5]\n",
      " [  1   9 169  10  12   9   0]\n",
      " [  4  11   4 134  36  18   3]\n",
      " [ 20  17   0  35 129   6   3]\n",
      " [ 15  19   1  21   6 100  48]\n",
      " [  0   3   0   1   1  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.61      0.67       210\n",
      "           2       0.67      0.62      0.65       210\n",
      "           3       0.95      0.80      0.87       210\n",
      "           4       0.58      0.64      0.60       210\n",
      "           5       0.51      0.61      0.55       210\n",
      "           6       0.52      0.48      0.50       210\n",
      "           7       0.75      0.88      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   0  12  36  24   4]\n",
      " [  2 132   3  22  30  17   4]\n",
      " [  2   6 171  13   8  10   0]\n",
      " [  9  10   3 132  33  22   1]\n",
      " [ 17  15   0  40 128   6   4]\n",
      " [ 12  18   0  22   8  98  52]\n",
      " [  0   4   0   1   1  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.61      0.68       210\n",
      "           2       0.69      0.63      0.66       210\n",
      "           3       0.97      0.81      0.88       210\n",
      "           4       0.55      0.63      0.58       210\n",
      "           5       0.52      0.61      0.56       210\n",
      "           6       0.49      0.47      0.48       210\n",
      "           7       0.74      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   0  11  37  21   3]\n",
      " [  5 133   5  22  25  16   4]\n",
      " [  2   3 175  10  10  10   0]\n",
      " [  7   9   4 133  34  20   3]\n",
      " [ 19  15   1  33 131   8   3]\n",
      " [ 14  19   2  22   5  94  54]\n",
      " [  0   2   0   1   1  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.64      0.69       210\n",
      "           2       0.72      0.63      0.67       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.54      0.62      0.58       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.73      0.88      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   7   1   8  41  20   5]\n",
      " [  4 135   6  22  23  16   4]\n",
      " [  3   4 175  12   5  10   1]\n",
      " [  7   8   3 138  32  22   0]\n",
      " [ 18  13   2  38 130   3   6]\n",
      " [  8  14   1  28   7 101  51]\n",
      " [  0   5   0   1   0  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.61      0.68       210\n",
      "           2       0.73      0.64      0.68       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.56      0.66      0.60       210\n",
      "           5       0.55      0.62      0.58       210\n",
      "           6       0.52      0.48      0.50       210\n",
      "           7       0.73      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   0  10  36  22   4]\n",
      " [  2 143   5  18  21  19   2]\n",
      " [  3   7 168  13  10   8   1]\n",
      " [  8   7   4 130  40  21   0]\n",
      " [ 22  17   0  33 129   6   3]\n",
      " [ 14  13   1  23   8 104  47]\n",
      " [  0   4   0   1   0  24 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.94      0.80      0.87       210\n",
      "           4       0.57      0.62      0.59       210\n",
      "           5       0.53      0.61      0.57       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.76      0.86      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   2   5  45  20   4]\n",
      " [  2 132   4  28  22  19   3]\n",
      " [  3   8 178   6   6   9   0]\n",
      " [  9   7   4 134  34  19   3]\n",
      " [ 16  13   0  38 134   4   5]\n",
      " [ 11  20   1  19   6 113  40]\n",
      " [  0   4   0   1   1  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.61      0.68       210\n",
      "           2       0.70      0.63      0.66       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.58      0.64      0.61       210\n",
      "           5       0.54      0.64      0.59       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.77      0.86      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   3  11  35  16   5]\n",
      " [  2 140   3  20  24  15   6]\n",
      " [  2   7 174  13   5   9   0]\n",
      " [  8  10   4 131  37  19   1]\n",
      " [ 18  16   1  35 130   8   2]\n",
      " [ 14  17   0  21   5 103  50]\n",
      " [  0   5   0   1   0  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.64      0.69       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.56      0.62      0.59       210\n",
      "           5       0.55      0.62      0.58       210\n",
      "           6       0.54      0.49      0.51       210\n",
      "           7       0.74      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   5   1   8  39  21   3]\n",
      " [  5 136   4  26  20  15   4]\n",
      " [  2   6 176  11   6   9   0]\n",
      " [  7   8   4 139  34  16   2]\n",
      " [ 20  15   1  35 129   5   5]\n",
      " [  9  13   1  31   7 104  45]\n",
      " [  0   4   0   1   1  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.63      0.69       210\n",
      "           2       0.73      0.65      0.69       210\n",
      "           3       0.94      0.84      0.89       210\n",
      "           4       0.55      0.66      0.60       210\n",
      "           5       0.55      0.61      0.58       210\n",
      "           6       0.54      0.50      0.51       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   1  11  36  23   3]\n",
      " [  4 139   6  19  22  17   3]\n",
      " [  2   9 175  11   4   9   0]\n",
      " [ 13   8   3 132  33  19   2]\n",
      " [ 21  15   0  43 123   4   4]\n",
      " [ 10  15   1  24   7 111  42]\n",
      " [  0   5   0   1   0  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.62      0.67       210\n",
      "           2       0.71      0.66      0.68       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.55      0.63      0.59       210\n",
      "           5       0.55      0.59      0.57       210\n",
      "           6       0.54      0.53      0.53       210\n",
      "           7       0.77      0.86      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.68      1470\n",
      "weighted avg       0.68      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   3   8  38  20   3]\n",
      " [  5 141   4  20  22  14   4]\n",
      " [  4   9 176   9   3   9   0]\n",
      " [ 11   8   5 130  32  22   2]\n",
      " [ 26  16   0  38 117  10   3]\n",
      " [ 10  15   2  23   6 119  35]\n",
      " [  0   4   0   1   1  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.57      0.62      0.59       210\n",
      "           5       0.53      0.56      0.55       210\n",
      "           6       0.55      0.57      0.56       210\n",
      "           7       0.79      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   4   2  11  35  20   3]\n",
      " [  6 140   4  22  19  15   4]\n",
      " [  1   6 177  11   6   9   0]\n",
      " [ 11  11   4 131  35  17   1]\n",
      " [ 22  15   0  42 119   7   5]\n",
      " [ 13  17   1  20   6 108  45]\n",
      " [  0   3   0   1   1  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.71      0.67      0.69       210\n",
      "           3       0.94      0.84      0.89       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.54      0.57      0.55       210\n",
      "           6       0.53      0.51      0.52       210\n",
      "           7       0.75      0.85      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   2   8  36  20   4]\n",
      " [  5 142   6  21  16  16   4]\n",
      " [  3   8 180   8   5   6   0]\n",
      " [  7  11   3 138  33  17   1]\n",
      " [ 28  14   0  40 118   6   4]\n",
      " [ 12  17   1  25   5 110  40]\n",
      " [  0   3   0   1   1  23 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       210\n",
      "           2       0.71      0.68      0.69       210\n",
      "           3       0.94      0.86      0.90       210\n",
      "           4       0.57      0.66      0.61       210\n",
      "           5       0.55      0.56      0.56       210\n",
      "           6       0.56      0.52      0.54       210\n",
      "           7       0.77      0.87      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   3   1   9  32  21   4]\n",
      " [  5 141   4  22  16  18   4]\n",
      " [  4   6 178   9   4   9   0]\n",
      " [  8   8   3 140  31  18   2]\n",
      " [ 30  14   0  40 115   5   6]\n",
      " [ 16  13   1  23   7 104  46]\n",
      " [  0   3   0   0   2  28 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.95      0.85      0.90       210\n",
      "           4       0.58      0.67      0.62       210\n",
      "           5       0.56      0.55      0.55       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.74      0.84      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 88  11  33   9  40  23   6]\n",
      " [  2  84  25  12  48  31   8]\n",
      " [ 14  14 155   6   6  14   1]\n",
      " [ 12  13  33  59  65  26   2]\n",
      " [ 17  17  19  21 121  11   4]\n",
      " [ 21  16   9  13   7  74  70]\n",
      " [  0   6   0   1   0  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.42      0.48       210\n",
      "           2       0.52      0.40      0.45       210\n",
      "           3       0.57      0.74      0.64       210\n",
      "           4       0.49      0.28      0.36       210\n",
      "           5       0.42      0.58      0.49       210\n",
      "           6       0.36      0.35      0.36       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_ndisbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80480feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7408163265306122\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[156   1   3   2  34  11   3]\n",
      " [  2 146   8  17  16  18   3]\n",
      " [  1   7 190   4   4   4   0]\n",
      " [  2   8  11 141  32  14   2]\n",
      " [ 16   9   2  18 152   3  10]\n",
      " [ 10  12   8  17   6 116  41]\n",
      " [  0   0   0   0   3  19 188]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.79       210\n",
      "           2       0.80      0.70      0.74       210\n",
      "           3       0.86      0.90      0.88       210\n",
      "           4       0.71      0.67      0.69       210\n",
      "           5       0.62      0.72      0.67       210\n",
      "           6       0.63      0.55      0.59       210\n",
      "           7       0.76      0.90      0.82       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   5   3   4  37   3   1]\n",
      " [ 12 146  11   7  29   4   1]\n",
      " [  0  10 189   5   4   2   0]\n",
      " [ 16  14  19 103  53   4   1]\n",
      " [ 59  17   6  20 105   1   2]\n",
      " [ 41  25  20  25  20  50  29]\n",
      " [ 13   0   0   4   4  12 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.75      0.62       210\n",
      "           2       0.67      0.70      0.68       210\n",
      "           3       0.76      0.90      0.83       210\n",
      "           4       0.61      0.49      0.54       210\n",
      "           5       0.42      0.50      0.45       210\n",
      "           6       0.66      0.24      0.35       210\n",
      "           7       0.84      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.62      1470\n",
      "weighted avg       0.64      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158   5   3   3  35   4   2]\n",
      " [ 12 142  15   9  26   4   2]\n",
      " [  2  10 186   4   5   3   0]\n",
      " [ 10  13  19 111  50   5   2]\n",
      " [ 57  18   4  20 108   1   2]\n",
      " [ 35  21  17  18  24  57  38]\n",
      " [  5   0   0   3   7  16 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.75      0.65       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.76      0.89      0.82       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.42      0.51      0.46       210\n",
      "           6       0.63      0.27      0.38       210\n",
      "           7       0.80      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   4   2   2  43   3   3]\n",
      " [ 10 138  17  12  29   3   1]\n",
      " [  1  10 189   3   5   2   0]\n",
      " [ 12  12  17 110  50   6   3]\n",
      " [ 48  16   6  25 112   1   2]\n",
      " [ 26  16  19  25  25  56  43]\n",
      " [  8   0   0   2   6  11 183]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.73      0.65       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.76      0.90      0.82       210\n",
      "           4       0.61      0.52      0.57       210\n",
      "           5       0.41      0.53      0.47       210\n",
      "           6       0.68      0.27      0.38       210\n",
      "           7       0.78      0.87      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   3   2   2  43   6   1]\n",
      " [  9 140  15  10  33   1   2]\n",
      " [  3   9 189   2   6   1   0]\n",
      " [  9  12  17 108  57   5   2]\n",
      " [ 46  11   5  22 124   0   2]\n",
      " [ 31  19  18  25  19  60  38]\n",
      " [  6   0   0   2   8  15 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.73      0.66       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.77      0.90      0.83       210\n",
      "           4       0.63      0.51      0.57       210\n",
      "           5       0.43      0.59      0.50       210\n",
      "           6       0.68      0.29      0.40       210\n",
      "           7       0.80      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   2   3   2  47   4   2]\n",
      " [  9 141  19   6  32   1   2]\n",
      " [  1  10 191   2   5   1   0]\n",
      " [  9   9  18 107  60   4   3]\n",
      " [ 41   8   4  18 135   1   3]\n",
      " [ 31  15  17  23  20  58  46]\n",
      " [  4   1   0   4   6  13 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.71      0.66       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.76      0.91      0.83       210\n",
      "           4       0.66      0.51      0.58       210\n",
      "           5       0.44      0.64      0.52       210\n",
      "           6       0.71      0.28      0.40       210\n",
      "           7       0.76      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.64      1470\n",
      "weighted avg       0.67      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   2   3   2  45   5   2]\n",
      " [  8 141  20   5  31   2   3]\n",
      " [  1  10 191   2   6   0   0]\n",
      " [  9  10  15 111  59   5   1]\n",
      " [ 38   9   5  15 141   0   2]\n",
      " [ 33  18  17  21  20  56  45]\n",
      " [  3   1   0   3   7  14 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.72      0.67       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.76      0.91      0.83       210\n",
      "           4       0.70      0.53      0.60       210\n",
      "           5       0.46      0.67      0.54       210\n",
      "           6       0.68      0.27      0.38       210\n",
      "           7       0.77      0.87      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.65      1470\n",
      "weighted avg       0.68      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[104   9  13   0  51  10  23]\n",
      " [  2 123  15  16  30  11  13]\n",
      " [  0  24 164   5  11   5   1]\n",
      " [  3  13  14  90  48  14  28]\n",
      " [  7  18   0  11 142   4  28]\n",
      " [  7  22  18  14  21  61  67]\n",
      " [  0   5   0   2   5  29 169]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.50      0.62       210\n",
      "           2       0.57      0.59      0.58       210\n",
      "           3       0.73      0.78      0.76       210\n",
      "           4       0.65      0.43      0.52       210\n",
      "           5       0.46      0.68      0.55       210\n",
      "           6       0.46      0.29      0.35       210\n",
      "           7       0.51      0.80      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.57      1470\n",
      "weighted avg       0.60      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[109   7  16   1  44  10  23]\n",
      " [  1 124  15  17  31  13   9]\n",
      " [  4  22 168   5   7   3   1]\n",
      " [  6  14  16  83  50  16  25]\n",
      " [ 16  16   0   6 137   3  32]\n",
      " [  8  20  23  20  18  57  64]\n",
      " [  0   6   0   5   9  22 168]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.52      0.62       210\n",
      "           2       0.59      0.59      0.59       210\n",
      "           3       0.71      0.80      0.75       210\n",
      "           4       0.61      0.40      0.48       210\n",
      "           5       0.46      0.65      0.54       210\n",
      "           6       0.46      0.27      0.34       210\n",
      "           7       0.52      0.80      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.56      1470\n",
      "weighted avg       0.59      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7496598639455783\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   1   1   2  38  11   3]\n",
      " [  2 149   8  12  19  18   2]\n",
      " [  0   7 193   6   2   2   0]\n",
      " [  1  11   7 138  32  19   2]\n",
      " [ 13   8   2  16 160   3   8]\n",
      " [  5  10  12  13   5 126  39]\n",
      " [  0   0   0   0   2  26 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.73      0.80       210\n",
      "           2       0.80      0.71      0.75       210\n",
      "           3       0.87      0.92      0.89       210\n",
      "           4       0.74      0.66      0.70       210\n",
      "           5       0.62      0.76      0.68       210\n",
      "           6       0.61      0.60      0.61       210\n",
      "           7       0.77      0.87      0.82       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7714285714285715\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   2   1   1  35  12   1]\n",
      " [  5 157   5  13  11  18   1]\n",
      " [  0   4 193   7   2   4   0]\n",
      " [  1   8   7 148  30  15   1]\n",
      " [ 21   9   1  15 154   4   6]\n",
      " [  3   8   6  14   5 145  29]\n",
      " [  0   0   0   2   1  28 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.75      0.79       210\n",
      "           2       0.84      0.75      0.79       210\n",
      "           3       0.91      0.92      0.91       210\n",
      "           4       0.74      0.70      0.72       210\n",
      "           5       0.65      0.73      0.69       210\n",
      "           6       0.64      0.69      0.67       210\n",
      "           7       0.82      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.78      0.77      0.77      1470\n",
      "weighted avg       0.78      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7653061224489796\n",
      "Confusion Matrix of SVM is:\n",
      " [[157   2   1   1  36  12   1]\n",
      " [  5 152   7  12  14  18   2]\n",
      " [  0   5 194   6   2   3   0]\n",
      " [  1   8   9 145  31  15   1]\n",
      " [ 19  10   1  15 154   5   6]\n",
      " [  2   9   9  11   6 142  31]\n",
      " [  0   0   0   1   2  26 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.75      0.80       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.88      0.92      0.90       210\n",
      "           4       0.76      0.69      0.72       210\n",
      "           5       0.63      0.73      0.68       210\n",
      "           6       0.64      0.68      0.66       210\n",
      "           7       0.82      0.86      0.84       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[147   1   3   1  41  13   4]\n",
      " [  1 146   8  16  18  20   1]\n",
      " [  1  10 188   4   3   4   0]\n",
      " [  2   9  12 128  39  18   2]\n",
      " [ 10   9   2  16 161   4   8]\n",
      " [  7   8  13  17   6 113  46]\n",
      " [  0   0   0   0   2  18 190]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78       210\n",
      "           2       0.80      0.70      0.74       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.70      0.61      0.65       210\n",
      "           5       0.60      0.77      0.67       210\n",
      "           6       0.59      0.54      0.56       210\n",
      "           7       0.76      0.90      0.82       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   7   0   0   0 203]\n",
      " [  0   0  53   0   0   0 157]\n",
      " [  0   0 175   0   0   0  35]\n",
      " [  0   0  45   0   0   0 165]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0  31   0   0   0 179]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.55      0.83      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      0.99      0.30       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.10      0.26      0.14      1470\n",
      "weighted avg       0.10      0.26      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   4   3 185   0  18]\n",
      " [  0   0  16  37 135   0  22]\n",
      " [  0   0 145  30  30   0   5]\n",
      " [  0   0   9  36 140   0  25]\n",
      " [  0   0   2   3 187   0  18]\n",
      " [  0   0   8  23  85   0  94]\n",
      " [  0   0   1   2  38   0 169]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.78      0.69      0.73       210\n",
      "           4       0.27      0.17      0.21       210\n",
      "           5       0.23      0.89      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.48      0.80      0.60       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.25      0.37      0.27      1470\n",
      "weighted avg       0.25      0.37      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   6   0   1 107  14   4]\n",
      " [  4  40  10   3 131  16   6]\n",
      " [  0  31 140   4  30   5   0]\n",
      " [  9  13   6  26 131  19   6]\n",
      " [ 12   1   2   2 175  10   8]\n",
      " [  6  14   5  12  79  54  40]\n",
      " [  0   2   1   0  38  49 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.37      0.49       210\n",
      "           2       0.37      0.19      0.25       210\n",
      "           3       0.85      0.67      0.75       210\n",
      "           4       0.54      0.12      0.20       210\n",
      "           5       0.25      0.83      0.39       210\n",
      "           6       0.32      0.26      0.29       210\n",
      "           7       0.65      0.57      0.61       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.53      0.43      0.43      1470\n",
      "weighted avg       0.53      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  20   2   5 100  11   7]\n",
      " [  3 109  25   2  49  16   6]\n",
      " [  0  21 166   4  14   4   1]\n",
      " [  4  33  15  27 106  16   9]\n",
      " [  5  22   2   2 161  11   7]\n",
      " [  4  21  15  14  62  41  53]\n",
      " [  0  12   3   0  26  41 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.31      0.45       210\n",
      "           2       0.46      0.52      0.49       210\n",
      "           3       0.73      0.79      0.76       210\n",
      "           4       0.50      0.13      0.20       210\n",
      "           5       0.31      0.77      0.44       210\n",
      "           6       0.29      0.20      0.23       210\n",
      "           7       0.61      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.53      0.47      0.45      1470\n",
      "weighted avg       0.53      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  20   0  24  75  17   3]\n",
      " [  4 107   9  29  24  34   3]\n",
      " [  0  19 151  13   6  21   0]\n",
      " [  7  33   7  69  61  28   5]\n",
      " [  7  22   2  40 121  10   8]\n",
      " [  4  20   6  60  16  60  44]\n",
      " [  0  12   1  21   5  51 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.34      0.47       210\n",
      "           2       0.46      0.51      0.48       210\n",
      "           3       0.86      0.72      0.78       210\n",
      "           4       0.27      0.33      0.30       210\n",
      "           5       0.39      0.58      0.47       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.66      0.57      0.61       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.52      0.48      0.48      1470\n",
      "weighted avg       0.52      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  17   0  38  61  14   2]\n",
      " [  8 122   6  32  17  23   2]\n",
      " [  0  23 156  12   6  13   0]\n",
      " [  8  43   9  93  37  16   4]\n",
      " [ 11  19   2  51 110  12   5]\n",
      " [  5  31  10  67   5  54  38]\n",
      " [  1  17   1  22   4  43 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.37      0.49       210\n",
      "           2       0.45      0.58      0.51       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.30      0.44      0.35       210\n",
      "           5       0.46      0.52      0.49       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.71      0.58      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.51      1470\n",
      "weighted avg       0.54      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114   6   0  18  33  38   1]\n",
      " [ 17 106   8  28  15  34   2]\n",
      " [  1  10 154  21   6  18   0]\n",
      " [ 20  16   6  89  30  45   4]\n",
      " [ 61   8   1  39  68  28   5]\n",
      " [ 21   9   7  29   3 102  39]\n",
      " [  1   5   1  11   5  75 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.54      0.51       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.87      0.73      0.80       210\n",
      "           4       0.38      0.42      0.40       210\n",
      "           5       0.42      0.32      0.37       210\n",
      "           6       0.30      0.49      0.37       210\n",
      "           7       0.69      0.53      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.54      0.51      0.52      1470\n",
      "weighted avg       0.54      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   4   1  28  43  21   2]\n",
      " [ 13  98   8  41  28  20   2]\n",
      " [  2   8 164  18   7  10   1]\n",
      " [ 14  10   7 108  50  16   5]\n",
      " [ 43   9   3  32 105  11   7]\n",
      " [ 20   7   6  59  10  76  32]\n",
      " [  3   4   1  29   7  51 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.53       210\n",
      "           2       0.70      0.47      0.56       210\n",
      "           3       0.86      0.78      0.82       210\n",
      "           4       0.34      0.51      0.41       210\n",
      "           5       0.42      0.50      0.46       210\n",
      "           6       0.37      0.36      0.37       210\n",
      "           7       0.70      0.55      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.56      0.53      0.54      1470\n",
      "weighted avg       0.56      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103   7   1  20  57  13   9]\n",
      " [ 12  92  15  23  50  12   6]\n",
      " [  5   8 166  11  13   6   1]\n",
      " [ 17  17   5  92  58  15   6]\n",
      " [ 28   8   2  42 117   5   8]\n",
      " [ 28   7   7  41  25  52  50]\n",
      " [  8   3   0  20  14  38 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.49      0.50       210\n",
      "           2       0.65      0.44      0.52       210\n",
      "           3       0.85      0.79      0.82       210\n",
      "           4       0.37      0.44      0.40       210\n",
      "           5       0.35      0.56      0.43       210\n",
      "           6       0.37      0.25      0.30       210\n",
      "           7       0.61      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.51      1470\n",
      "weighted avg       0.53      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  12   3  18  55  12   5]\n",
      " [  9 108  11  23  32  22   5]\n",
      " [  1  10 173  16   5   5   0]\n",
      " [  9  20  12 100  41  22   6]\n",
      " [ 22  14   2  37 114  12   9]\n",
      " [ 15  17  13  40  14  70  41]\n",
      " [  5   8   4  19   9  48 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.50      0.56       210\n",
      "           2       0.57      0.51      0.54       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.40      0.48      0.43       210\n",
      "           5       0.42      0.54      0.48       210\n",
      "           6       0.37      0.33      0.35       210\n",
      "           7       0.64      0.56      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  11   1  13  45  14  12]\n",
      " [ 12 100  19  18  33  20   8]\n",
      " [  4  10 174  13   5   4   0]\n",
      " [ 19  15   8  91  43  25   9]\n",
      " [ 32  20   3  31  96  17  11]\n",
      " [ 21  28   9  31  14  66  41]\n",
      " [  5   7   1  19   6  46 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.54      0.55       210\n",
      "           2       0.52      0.48      0.50       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.40      0.46      0.42       210\n",
      "           6       0.34      0.31      0.33       210\n",
      "           7       0.61      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   8   2  11  54  15   8]\n",
      " [ 14 104  13  22  34  16   7]\n",
      " [  3  13 168  14   5   5   2]\n",
      " [ 22  22   5  89  47  19   6]\n",
      " [ 37  25   2  34  89  16   7]\n",
      " [ 23  23  10  33  16  64  41]\n",
      " [  4   7   2  14   7  50 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.53      0.53       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.83      0.80      0.82       210\n",
      "           4       0.41      0.42      0.42       210\n",
      "           5       0.35      0.42      0.39       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.64      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   8   3   9  45  15   9]\n",
      " [  9  97  15  23  41  20   5]\n",
      " [  2   9 168  14   7  10   0]\n",
      " [ 26  19   9  90  36  24   6]\n",
      " [ 45  20   4  26  94  11  10]\n",
      " [ 21  19  11  37  15  64  43]\n",
      " [  6   8   3  17   9  51 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.58      0.55       210\n",
      "           2       0.54      0.46      0.50       210\n",
      "           3       0.79      0.80      0.79       210\n",
      "           4       0.42      0.43      0.42       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.33      0.30      0.32       210\n",
      "           7       0.61      0.55      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  12   2  12  41  10  12]\n",
      " [ 13 104  11  20  36  18   8]\n",
      " [  3  12 169   8   8  10   0]\n",
      " [ 28  20  10  86  36  21   9]\n",
      " [ 41  23   1  34  86  12  13]\n",
      " [ 18  21   8  37  13  69  44]\n",
      " [  8  10   2  17   3  43 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.58      0.55       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.83      0.80      0.82       210\n",
      "           4       0.40      0.41      0.41       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.38      0.33      0.35       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119  13   4  15  35  13  11]\n",
      " [ 13 104  11  18  34  22   8]\n",
      " [  2   9 171  13   6   9   0]\n",
      " [ 25  24  12  91  29  23   6]\n",
      " [ 44  17   3  34  86  13  13]\n",
      " [ 22  22  15  33  17  54  47]\n",
      " [  5   7   3  14   8  43 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.57      0.54       210\n",
      "           2       0.53      0.50      0.51       210\n",
      "           3       0.78      0.81      0.80       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.40      0.41      0.40       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.60      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.507482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   8   3  13  36  16  13]\n",
      " [ 18 100  14  23  28  21   6]\n",
      " [  2  10 168  16   6   8   0]\n",
      " [ 26  21   9  89  35  20  10]\n",
      " [ 48  20   5  31  80  16  10]\n",
      " [ 18  20  14  33  17  65  43]\n",
      " [  8   8   3  15   4  49 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.58      0.54       210\n",
      "           2       0.53      0.48      0.50       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.40      0.42      0.41       210\n",
      "           5       0.39      0.38      0.38       210\n",
      "           6       0.33      0.31      0.32       210\n",
      "           7       0.60      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  13   3  15  36  13   9]\n",
      " [ 15 104  11  18  35  22   5]\n",
      " [  5   9 171  11   6   7   1]\n",
      " [ 24  21   7  91  37  27   3]\n",
      " [ 41  20   3  41  77  17  11]\n",
      " [ 23  24  11  28  19  62  43]\n",
      " [  8   8   1  16   7  44 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.58      0.54       210\n",
      "           2       0.52      0.50      0.51       210\n",
      "           3       0.83      0.81      0.82       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.64      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   8   5  14  36  17  12]\n",
      " [ 15  96  13  19  40  15  12]\n",
      " [  1   9 173  12   4  10   1]\n",
      " [ 25  22   9  89  34  24   7]\n",
      " [ 45  23   5  32  79  18   8]\n",
      " [ 21  17   9  35  18  68  42]\n",
      " [  6   8   2  15   8  49 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.56      0.54       210\n",
      "           2       0.52      0.46      0.49       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.41      0.42      0.42       210\n",
      "           5       0.36      0.38      0.37       210\n",
      "           6       0.34      0.32      0.33       210\n",
      "           7       0.60      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  13   3  14  39  17  11]\n",
      " [ 11 100  11  16  40  25   7]\n",
      " [  2  13 170   9   5  11   0]\n",
      " [ 21  23   9  91  31  30   5]\n",
      " [ 39  25   8  32  80  16  10]\n",
      " [ 23  17  12  34  14  62  48]\n",
      " [  6   5   0  15   7  57 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.53       210\n",
      "           2       0.51      0.48      0.49       210\n",
      "           3       0.80      0.81      0.80       210\n",
      "           4       0.43      0.43      0.43       210\n",
      "           5       0.37      0.38      0.38       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.60      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  10   4  18  37  19   8]\n",
      " [ 11  99  15  20  35  22   8]\n",
      " [  0  10 174  10   6   9   1]\n",
      " [ 24  23   9  94  32  23   5]\n",
      " [ 38  23   6  33  84  15  11]\n",
      " [ 23  19  15  29  15  60  49]\n",
      " [  9   8   1  15   4  48 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53       210\n",
      "           2       0.52      0.47      0.49       210\n",
      "           3       0.78      0.83      0.80       210\n",
      "           4       0.43      0.45      0.44       210\n",
      "           5       0.39      0.40      0.40       210\n",
      "           6       0.31      0.29      0.30       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.37755102040816324\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 24   0  58   0  70   0  58]\n",
      " [  0  14  52   4 102   0  38]\n",
      " [  2   4 180   2  17   0   5]\n",
      " [  1   2  28   6  96   0  77]\n",
      " [  0   2   4   0 126   0  78]\n",
      " [  2   4  44   4  33   0 123]\n",
      " [  0   1   1   0   3   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.11      0.20       210\n",
      "           2       0.52      0.07      0.12       210\n",
      "           3       0.49      0.86      0.62       210\n",
      "           4       0.38      0.03      0.05       210\n",
      "           5       0.28      0.60      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.98      0.52       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.41      0.38      0.27      1470\n",
      "weighted avg       0.41      0.38      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78   8  13   0  76   0  35]\n",
      " [  1  97  24   0  60   0  28]\n",
      " [  0  15 175   0  17   0   3]\n",
      " [  2  14  19  16 106   0  53]\n",
      " [  0   9   2   0 160   0  39]\n",
      " [  4  16  35   1  22   3 129]\n",
      " [  0   1   1   1   5   0 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.37      0.53       210\n",
      "           2       0.61      0.46      0.52       210\n",
      "           3       0.65      0.83      0.73       210\n",
      "           4       0.89      0.08      0.14       210\n",
      "           5       0.36      0.76      0.49       210\n",
      "           6       1.00      0.01      0.03       210\n",
      "           7       0.41      0.96      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.69      0.50      0.43      1470\n",
      "weighted avg       0.69      0.50      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113  11   4   0  56   3  23]\n",
      " [  1 135  14   5  36   3  16]\n",
      " [  0  28 170   1   8   0   3]\n",
      " [  3  27  14  32  95   3  36]\n",
      " [  6  15   0   3 155   1  30]\n",
      " [  3  36  24   6  24  11 106]\n",
      " [  0   5   0   1   5   1 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.54      0.67       210\n",
      "           2       0.53      0.64      0.58       210\n",
      "           3       0.75      0.81      0.78       210\n",
      "           4       0.67      0.15      0.25       210\n",
      "           5       0.41      0.74      0.53       210\n",
      "           6       0.50      0.05      0.09       210\n",
      "           7       0.48      0.94      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.51      1470\n",
      "weighted avg       0.60      0.55      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   9   4   1  50   7  18]\n",
      " [  1 136   9  13  33   6  12]\n",
      " [  0  29 171   1   5   3   1]\n",
      " [  5  19  12  70  73   8  23]\n",
      " [  6  15   2   7 160   4  16]\n",
      " [  5  29  25   7  22  24  98]\n",
      " [  1   7   0   0   6   3 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.58      0.69       210\n",
      "           2       0.56      0.65      0.60       210\n",
      "           3       0.77      0.81      0.79       210\n",
      "           4       0.71      0.33      0.45       210\n",
      "           5       0.46      0.76      0.57       210\n",
      "           6       0.44      0.11      0.18       210\n",
      "           7       0.53      0.92      0.68       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.57      1470\n",
      "weighted avg       0.62      0.60      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118  11   3   1  49  13  15]\n",
      " [  1 141   9  13  29   5  12]\n",
      " [  0  22 176   1   8   2   1]\n",
      " [  5  17  12  98  52  12  14]\n",
      " [ 11  13   2   8 157   4  15]\n",
      " [  6  27  17  14  18  40  88]\n",
      " [  0   3   0   0   5   8 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.56      0.67       210\n",
      "           2       0.60      0.67      0.64       210\n",
      "           3       0.80      0.84      0.82       210\n",
      "           4       0.73      0.47      0.57       210\n",
      "           5       0.49      0.75      0.59       210\n",
      "           6       0.48      0.19      0.27       210\n",
      "           7       0.57      0.92      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.61      1470\n",
      "weighted avg       0.64      0.63      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   7   3   4  52  17   9]\n",
      " [  2 139   9  16  25  12   7]\n",
      " [  0  19 175   6   4   5   1]\n",
      " [  2  13   8 113  49  13  12]\n",
      " [  3  12   0  17 161   5  12]\n",
      " [  6  14  10  19  16  69  76]\n",
      " [  0   1   0   1   4  12 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.56      0.69       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.52      0.77      0.62       210\n",
      "           6       0.52      0.33      0.40       210\n",
      "           7       0.62      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.65      1470\n",
      "weighted avg       0.68      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   5   3   5  46  17   9]\n",
      " [  1 142   8  13  25  14   7]\n",
      " [  0  17 178   7   3   4   1]\n",
      " [  1  12   7 118  50  14   8]\n",
      " [  5  12   1  15 160   6  11]\n",
      " [  7  16  11  15  14  83  64]\n",
      " [  1   3   0   0   5   7 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.60      0.71       210\n",
      "           2       0.69      0.68      0.68       210\n",
      "           3       0.86      0.85      0.85       210\n",
      "           4       0.68      0.56      0.62       210\n",
      "           5       0.53      0.76      0.62       210\n",
      "           6       0.57      0.40      0.47       210\n",
      "           7       0.66      0.92      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.67      1470\n",
      "weighted avg       0.70      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   4   3   3  52  16   7]\n",
      " [  1 141   8  19  21  15   5]\n",
      " [  0  13 182   5   4   6   0]\n",
      " [  0  11   7 130  42  11   9]\n",
      " [  4  11   1  17 159   8  10]\n",
      " [  4  14  10  20  13  87  62]\n",
      " [  1   0   0   2   3  15 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.60      0.72       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.86      0.87      0.86       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.54      0.76      0.63       210\n",
      "           6       0.55      0.41      0.47       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   2   2   7  43  23   7]\n",
      " [  2 142   8  19  18  14   7]\n",
      " [  0  16 180   7   3   4   0]\n",
      " [  2  12   7 121  47  14   7]\n",
      " [  8  11   0  12 160   8  11]\n",
      " [  3  13  10  20  11  98  55]\n",
      " [  0   1   0   1   3  16 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.60      0.72       210\n",
      "           2       0.72      0.68      0.70       210\n",
      "           3       0.87      0.86      0.86       210\n",
      "           4       0.65      0.58      0.61       210\n",
      "           5       0.56      0.76      0.65       210\n",
      "           6       0.55      0.47      0.51       210\n",
      "           7       0.68      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   3   2   3  47  20   4]\n",
      " [  1 143   7  19  20  13   7]\n",
      " [  0  13 180   7   5   5   0]\n",
      " [  1  11   7 136  35  13   7]\n",
      " [ 10  15   0  21 148   7   9]\n",
      " [  5  18  11  18  12  92  54]\n",
      " [  1   1   0   0   2  18 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.62      0.73       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.87      0.86      0.86       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.55      0.44      0.49       210\n",
      "           7       0.70      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   2   3   1  52  20   6]\n",
      " [  1 140   4  21  22  18   4]\n",
      " [  1  12 183   8   3   3   0]\n",
      " [  2  11   6 130  45  11   5]\n",
      " [  9  10   1  19 154   9   8]\n",
      " [ 10  11   8  13  11 109  48]\n",
      " [  0   3   0   2   4  16 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.60      0.70       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.67      0.62      0.64       210\n",
      "           5       0.53      0.73      0.61       210\n",
      "           6       0.59      0.52      0.55       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   4   2   6  38  20   5]\n",
      " [  1 141  10  15  20  19   4]\n",
      " [  0  13 183   7   3   4   0]\n",
      " [  5   9   6 134  37  13   6]\n",
      " [  8  11   0  21 158   2  10]\n",
      " [  8  17  11  16   9 100  49]\n",
      " [  1   1   0   1   2  15 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.64      0.73       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.86      0.87      0.87       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.59      0.75      0.66       210\n",
      "           6       0.58      0.48      0.52       210\n",
      "           7       0.72      0.90      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   4   1   3  41  20   5]\n",
      " [  1 146  11  12  20  16   4]\n",
      " [  0  13 185   3   3   6   0]\n",
      " [  1   9   5 134  42  13   6]\n",
      " [ 10  10   0  21 155   5   9]\n",
      " [  6  14  12  20  13  91  54]\n",
      " [  1   1   0   2   2  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.65      0.75       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.56      0.74      0.64       210\n",
      "           6       0.54      0.43      0.48       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   5   3   4  41  21   6]\n",
      " [  2 143   8  18  19  17   3]\n",
      " [  2  12 180   9   4   3   0]\n",
      " [  2  11   5 138  34  15   5]\n",
      " [ 14  11   2  22 148   4   9]\n",
      " [  8  14   6  19  11  98  54]\n",
      " [  0   1   0   1   4  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.71       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.88      0.86      0.87       210\n",
      "           4       0.65      0.66      0.66       210\n",
      "           5       0.57      0.70      0.63       210\n",
      "           6       0.55      0.47      0.51       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   6   1   3  40  20   4]\n",
      " [  2 140   9  15  22  19   3]\n",
      " [  1  15 183   3   5   3   0]\n",
      " [  2  13   6 130  37  17   5]\n",
      " [ 15  12   1  20 150   2  10]\n",
      " [  9  16  10  16   6  97  56]\n",
      " [  1   2   0   1   1  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.65      0.72       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.57      0.71      0.64       210\n",
      "           6       0.55      0.46      0.50       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   5   3   5  43  19   5]\n",
      " [  1 144   6  16  19  21   3]\n",
      " [  1  13 183   6   4   3   0]\n",
      " [  3  12   6 124  43  16   6]\n",
      " [ 17  14   3  19 144   5   8]\n",
      " [ 10  12  10  15   9 101  53]\n",
      " [  1   1   0   2   2  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.62      0.70       210\n",
      "           2       0.72      0.69      0.70       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.55      0.69      0.61       210\n",
      "           6       0.55      0.48      0.51       210\n",
      "           7       0.71      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   3   1   5  39  21   3]\n",
      " [  2 146  10  18  16  14   4]\n",
      " [  0  14 184   8   3   1   0]\n",
      " [  5  13   7 124  39  18   4]\n",
      " [ 16  14   2  19 145   4  10]\n",
      " [  7  15  10  16   9 100  53]\n",
      " [  1   1   0   2   2  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.66      0.73       210\n",
      "           2       0.71      0.70      0.70       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.57      0.69      0.63       210\n",
      "           6       0.56      0.48      0.51       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7068027210884353\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   5   2   4  36  20   5]\n",
      " [  2 150   5  16  17  16   4]\n",
      " [  1  11 185   6   3   4   0]\n",
      " [  2  11   6 131  40  15   5]\n",
      " [ 21  14   2  22 140   5   6]\n",
      " [ 11  10   8  16   5 110  50]\n",
      " [  1   1   0   1   2  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.72       210\n",
      "           2       0.74      0.71      0.73       210\n",
      "           3       0.89      0.88      0.89       210\n",
      "           4       0.67      0.62      0.65       210\n",
      "           5       0.58      0.67      0.62       210\n",
      "           6       0.58      0.52      0.55       210\n",
      "           7       0.73      0.88      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   1   5  41  20   5]\n",
      " [  2 143   6  23  16  17   3]\n",
      " [  0  15 180   6   4   5   0]\n",
      " [  5  11   6 132  38  14   4]\n",
      " [ 18  13   2  20 140   9   8]\n",
      " [ 13  11   8  17   7 104  50]\n",
      " [  1   2   0   2   3  19 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.63      0.69       210\n",
      "           2       0.71      0.68      0.70       210\n",
      "           3       0.89      0.86      0.87       210\n",
      "           4       0.64      0.63      0.64       210\n",
      "           5       0.56      0.67      0.61       210\n",
      "           6       0.55      0.50      0.52       210\n",
      "           7       0.72      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   4   2   4  42  21   5]\n",
      " [  2 144   5  17  21  17   4]\n",
      " [  2  15 181   6   3   3   0]\n",
      " [  4  11   6 133  36  13   7]\n",
      " [ 18  13   1  17 147   7   7]\n",
      " [  9  12   7  16   9 107  50]\n",
      " [  1   0   0   2   3  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.63      0.70       210\n",
      "           2       0.72      0.69      0.70       210\n",
      "           3       0.90      0.86      0.88       210\n",
      "           4       0.68      0.63      0.66       210\n",
      "           5       0.56      0.70      0.62       210\n",
      "           6       0.56      0.51      0.53       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[104   5  19   0  49  10  23]\n",
      " [  2 114  21  16  33  13  11]\n",
      " [  4  20 165   7  10   3   1]\n",
      " [  6  11  17  79  53  18  26]\n",
      " [ 21  12   1   7 138   4  27]\n",
      " [ 12  21  28  13  26  39  71]\n",
      " [  0   8   0   3  11  13 175]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.50      0.58       210\n",
      "           2       0.60      0.54      0.57       210\n",
      "           3       0.66      0.79      0.72       210\n",
      "           4       0.63      0.38      0.47       210\n",
      "           5       0.43      0.66      0.52       210\n",
      "           6       0.39      0.19      0.25       210\n",
      "           7       0.52      0.83      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.54      1470\n",
      "weighted avg       0.56      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_vbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[160   3   0   2  26  13   6]\n",
      " [  2 160   7  10  13  17   1]\n",
      " [  0   4 194   7   2   3   0]\n",
      " [  1  14  10 134  24  20   7]\n",
      " [ 20  12   3  25 137   7   6]\n",
      " [ 13  19  11  24   6  95  42]\n",
      " [  0   1   0   3   2  20 184]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.76      0.79       210\n",
      "           2       0.75      0.76      0.76       210\n",
      "           3       0.86      0.92      0.89       210\n",
      "           4       0.65      0.64      0.65       210\n",
      "           5       0.65      0.65      0.65       210\n",
      "           6       0.54      0.45      0.49       210\n",
      "           7       0.75      0.88      0.81       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[159   4   3   7  25   5   7]\n",
      " [ 12 168   7   5  13   3   2]\n",
      " [  4   6 194   0   3   3   0]\n",
      " [ 20  26  13 109  33   7   2]\n",
      " [ 54  41   3  24  85   1   2]\n",
      " [ 46  42  13  23  18  38  30]\n",
      " [ 16   5   0  16   9   8 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.76      0.61       210\n",
      "           2       0.58      0.80      0.67       210\n",
      "           3       0.83      0.92      0.88       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.46      0.40      0.43       210\n",
      "           6       0.58      0.18      0.28       210\n",
      "           7       0.78      0.74      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.60      1470\n",
      "weighted avg       0.62      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6292517006802721\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[159   6   2   6  26   6   5]\n",
      " [ 13 164   7   6  15   4   1]\n",
      " [  4   5 193   0   4   4   0]\n",
      " [ 11  24  18 116  33   6   2]\n",
      " [ 44  39   6  28  89   3   1]\n",
      " [ 41  37  18  21  16  45  32]\n",
      " [ 12   4   1   7  13  14 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.76      0.64       210\n",
      "           2       0.59      0.78      0.67       210\n",
      "           3       0.79      0.92      0.85       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.45      0.42      0.44       210\n",
      "           6       0.55      0.21      0.31       210\n",
      "           7       0.80      0.76      0.78       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.62      0.63      0.61      1470\n",
      "weighted avg       0.62      0.63      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   8   8   5  31   5   6]\n",
      " [ 12 169   8   7  12   1   1]\n",
      " [  3   5 196   1   4   1   0]\n",
      " [ 12  20  18 120  31   9   0]\n",
      " [ 40  37   6  25  98   2   2]\n",
      " [ 32  35  22  23  25  43  30]\n",
      " [  7   3   1   8  12  10 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.63       210\n",
      "           2       0.61      0.80      0.69       210\n",
      "           3       0.76      0.93      0.84       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.46      0.47      0.46       210\n",
      "           6       0.61      0.20      0.31       210\n",
      "           7       0.81      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.62      1470\n",
      "weighted avg       0.64      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6394557823129252\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154  11   3   6  27   4   5]\n",
      " [ 12 166   8   9  11   3   1]\n",
      " [  4   5 197   0   3   1   0]\n",
      " [ 12  19  20 122  31   4   2]\n",
      " [ 44  37   6  25  95   2   1]\n",
      " [ 32  33  23  25  21  44  32]\n",
      " [  8   5   1   8  10  16 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.73      0.65       210\n",
      "           2       0.60      0.79      0.68       210\n",
      "           3       0.76      0.94      0.84       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.48      0.45      0.47       210\n",
      "           6       0.59      0.21      0.31       210\n",
      "           7       0.80      0.77      0.78       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.63      0.64      0.62      1470\n",
      "weighted avg       0.63      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   8   3   5  30   5   7]\n",
      " [ 14 167  10   7  10   2   0]\n",
      " [  1   6 197   0   4   2   0]\n",
      " [ 13  19  19 117  32   7   3]\n",
      " [ 43  33   7  24 101   0   2]\n",
      " [ 32  33  26  22  19  41  37]\n",
      " [  5   4   1   9  10  12 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.72      0.65       210\n",
      "           2       0.62      0.80      0.70       210\n",
      "           3       0.75      0.94      0.83       210\n",
      "           4       0.64      0.56      0.59       210\n",
      "           5       0.49      0.48      0.49       210\n",
      "           6       0.59      0.20      0.29       210\n",
      "           7       0.78      0.80      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.62      1470\n",
      "weighted avg       0.64      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6428571428571429\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   8   4   5  30   3   8]\n",
      " [  8 167  11   7  12   2   3]\n",
      " [  3   4 197   0   4   2   0]\n",
      " [  9  20  20 120  31   7   3]\n",
      " [ 43  31   6  23 104   1   2]\n",
      " [ 33  33  27  21  19  36  41]\n",
      " [  5   4   1   8   9  14 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.72      0.66       210\n",
      "           2       0.63      0.80      0.70       210\n",
      "           3       0.74      0.94      0.83       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.50      0.50      0.50       210\n",
      "           6       0.55      0.17      0.26       210\n",
      "           7       0.75      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.63      0.64      0.62      1470\n",
      "weighted avg       0.63      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[111   3  14   4  29  29  20]\n",
      " [  0 125  14  15  22  26   8]\n",
      " [  6   4 168  14   1  17   0]\n",
      " [  5  13   8 104  24  29  27]\n",
      " [ 17  12   1  18 125  11  26]\n",
      " [ 11  11   5  28   4  88  63]\n",
      " [  0   0   0   1   3  27 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.53      0.62       210\n",
      "           2       0.74      0.60      0.66       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.39      0.42      0.40       210\n",
      "           7       0.55      0.85      0.67       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[112   4  13   3  30  28  20]\n",
      " [  0 121  19  12  25  23  10]\n",
      " [ 20  11 147  16   3  13   0]\n",
      " [  6  13   8  97  31  23  32]\n",
      " [ 21  10   1  16 122  13  27]\n",
      " [ 16  15   6  24   6  79  64]\n",
      " [  0   2   0   1   3  30 174]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.53      0.58       210\n",
      "           2       0.69      0.58      0.63       210\n",
      "           3       0.76      0.70      0.73       210\n",
      "           4       0.57      0.46      0.51       210\n",
      "           5       0.55      0.58      0.57       210\n",
      "           6       0.38      0.38      0.38       210\n",
      "           7       0.53      0.83      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7414965986394558\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   2   1   3  27  16   5]\n",
      " [  3 164   6  12   8  16   1]\n",
      " [  0   3 196   4   2   5   0]\n",
      " [  0  12  11 142  23  17   5]\n",
      " [ 21  11   1  25 141   7   4]\n",
      " [ 14  18  11  22   4 106  35]\n",
      " [  0   1   0   2   2  20 185]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.74      0.77       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.87      0.93      0.90       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.68      0.67      0.68       210\n",
      "           6       0.57      0.50      0.53       210\n",
      "           7       0.79      0.88      0.83       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7510204081632653\n",
      "Confusion Matrix of SVM is:\n",
      " [[157   2   1   2  25  19   4]\n",
      " [  2 167   6   9  10  16   0]\n",
      " [  0   1 197   6   2   4   0]\n",
      " [  1   9   9 143  25  19   4]\n",
      " [ 21  10   2  27 138   8   4]\n",
      " [  9  12   7  24   3 125  30]\n",
      " [  0   0   0   1   3  29 177]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.75      0.79       210\n",
      "           2       0.83      0.80      0.81       210\n",
      "           3       0.89      0.94      0.91       210\n",
      "           4       0.67      0.68      0.68       210\n",
      "           5       0.67      0.66      0.66       210\n",
      "           6       0.57      0.60      0.58       210\n",
      "           7       0.81      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7503401360544217\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   2   1   2  26  22   4]\n",
      " [  2 166   4   9  10  19   0]\n",
      " [  0   1 196   5   4   4   0]\n",
      " [  1  12  10 145  21  16   5]\n",
      " [ 24  11   2  21 141   7   4]\n",
      " [ 11  16   7  22   4 120  30]\n",
      " [  0   0   0   1   2  25 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.73      0.76       210\n",
      "           2       0.80      0.79      0.79       210\n",
      "           3       0.89      0.93      0.91       210\n",
      "           4       0.71      0.69      0.70       210\n",
      "           5       0.68      0.67      0.67       210\n",
      "           6       0.56      0.57      0.57       210\n",
      "           7       0.81      0.87      0.84       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   3   2   3  26  17   7]\n",
      " [  3 159   7  10  15  15   1]\n",
      " [  0   3 197   6   1   3   0]\n",
      " [  2  14  11 130  23  22   8]\n",
      " [ 20  11   2  23 138   9   7]\n",
      " [ 15  18  12  24   5  96  40]\n",
      " [  0   1   0   2   2  24 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.72      0.76       210\n",
      "           2       0.76      0.76      0.76       210\n",
      "           3       0.85      0.94      0.89       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.66      0.66      0.66       210\n",
      "           6       0.52      0.46      0.48       210\n",
      "           7       0.74      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.71      0.72      0.71      1470\n",
      "weighted avg       0.71      0.72      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  21   0 189   0   0]\n",
      " [  0   0  19   0 191   0   0]\n",
      " [  0   0 162   0  48   0   0]\n",
      " [  0   0  23   0 187   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0  25   0 185   0   0]\n",
      " [  0   0  15   0 195   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.60      0.77      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.17      0.98      0.29       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.11      0.25      0.14      1470\n",
      "weighted avg       0.11      0.25      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  21   0 150   0  39]\n",
      " [  0   0  19   0 151   0  40]\n",
      " [  0   0 162   0  36   0  12]\n",
      " [  0   0  23   0 124   0  63]\n",
      " [  0   0   4   0 172   0  34]\n",
      " [  0   0  25   0  89   0  96]\n",
      " [  0   0  15   0  32   0 163]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.60      0.77      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.82      0.36       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      0.78      0.50       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.17      0.34      0.22      1470\n",
      "weighted avg       0.17      0.34      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124  46   1   0   0   0  39]\n",
      " [ 20 144   5   1   0   0  40]\n",
      " [ 26  34 131   7   0   0  12]\n",
      " [ 31 105   5   6   0   0  63]\n",
      " [ 36 138   1   1   0   0  34]\n",
      " [ 35  73   4   2   0   0  96]\n",
      " [ 19  26   1   1   0   0 163]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.59      0.50       210\n",
      "           2       0.25      0.69      0.37       210\n",
      "           3       0.89      0.62      0.73       210\n",
      "           4       0.33      0.03      0.05       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      0.78      0.50       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.32      0.39      0.31      1470\n",
      "weighted avg       0.32      0.39      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   7   1  14  39  29  10]\n",
      " [  7  79   6  13  65  27  13]\n",
      " [  3   9 135  25  25  13   0]\n",
      " [ 20  12   5  15  93  51  14]\n",
      " [ 34  13   1   3 125  23  11]\n",
      " [ 16  13   5  20  60  54  42]\n",
      " [  7   0   1  13  26  33 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54       210\n",
      "           2       0.59      0.38      0.46       210\n",
      "           3       0.88      0.64      0.74       210\n",
      "           4       0.15      0.07      0.10       210\n",
      "           5       0.29      0.60      0.39       210\n",
      "           6       0.23      0.26      0.25       210\n",
      "           7       0.59      0.62      0.60       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.44      1470\n",
      "weighted avg       0.47      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104   3  11  26  22  36   8]\n",
      " [  3  69  17  49  35  27  10]\n",
      " [  2   5 150  33   7  13   0]\n",
      " [ 13   7  12  79  30  60   9]\n",
      " [ 23   9   2  50  81  37   8]\n",
      " [  7   5  22  54  17  75  30]\n",
      " [  0   1   8  17  13  57 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.50      0.57       210\n",
      "           2       0.70      0.33      0.45       210\n",
      "           3       0.68      0.71      0.69       210\n",
      "           4       0.26      0.38      0.31       210\n",
      "           5       0.40      0.39      0.39       210\n",
      "           6       0.25      0.36      0.29       210\n",
      "           7       0.64      0.54      0.59       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.51      0.46      0.47      1470\n",
      "weighted avg       0.51      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48367346938775513\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8   4   8  28  52  10]\n",
      " [  3  75  16  17  40  56   3]\n",
      " [  2  11 146  19   7  24   1]\n",
      " [  8   7   9  74  37  69   6]\n",
      " [ 20  14   1  16  92  63   4]\n",
      " [  4  10  16  17  27 112  24]\n",
      " [  0   1   3   9  22  63 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.48      0.58       210\n",
      "           2       0.60      0.36      0.45       210\n",
      "           3       0.75      0.70      0.72       210\n",
      "           4       0.46      0.35      0.40       210\n",
      "           5       0.36      0.44      0.40       210\n",
      "           6       0.26      0.53      0.35       210\n",
      "           7       0.70      0.53      0.61       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.55      0.48      0.50      1470\n",
      "weighted avg       0.55      0.48      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  12   4  21  27  41   8]\n",
      " [  6  92   8  29  29  45   1]\n",
      " [  1   9 146  23   9  21   1]\n",
      " [ 11  16   4  98  36  40   5]\n",
      " [ 11  15   2  51 101  25   5]\n",
      " [  8  23   8  42  19  80  30]\n",
      " [  2   6   0  14  13  63 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.46      0.56       210\n",
      "           2       0.53      0.44      0.48       210\n",
      "           3       0.85      0.70      0.76       210\n",
      "           4       0.35      0.47      0.40       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.25      0.38      0.30       210\n",
      "           7       0.69      0.53      0.60       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.55      0.49      0.51      1470\n",
      "weighted avg       0.55      0.49      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   9   7  13  28  44   8]\n",
      " [  5  91  21  24  25  41   3]\n",
      " [  0   4 158  22   9  16   1]\n",
      " [ 16  13   8  91  32  42   8]\n",
      " [ 25  11   3  26 106  34   5]\n",
      " [ 13  18  18  33  16  85  27]\n",
      " [  2   7   2  13  13  63 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.59      0.43      0.50       210\n",
      "           3       0.73      0.75      0.74       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.26      0.40      0.32       210\n",
      "           7       0.68      0.52      0.59       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.51      1470\n",
      "weighted avg       0.54      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  11   6  16  23  35   9]\n",
      " [ 15 103   6  29  25  24   8]\n",
      " [  5  19 153  17   7   8   1]\n",
      " [ 30  22   5  84  29  30  10]\n",
      " [ 32  17   3  31  99  24   4]\n",
      " [ 18  39  13  28  13  68  31]\n",
      " [  6  15   3  16   8  51 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.52      0.52       210\n",
      "           2       0.46      0.49      0.47       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.49      0.47      0.48       210\n",
      "           6       0.28      0.32      0.30       210\n",
      "           7       0.64      0.53      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   7   5  17  25  39   8]\n",
      " [ 12  95   8  25  31  37   2]\n",
      " [  4  14 154  16   6  15   1]\n",
      " [ 19  19   7  79  32  47   7]\n",
      " [ 28  17   1  24 103  32   5]\n",
      " [ 14  21  27  22  17  79  30]\n",
      " [  7   8   1  10  11  64 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54       210\n",
      "           2       0.52      0.45      0.49       210\n",
      "           3       0.76      0.73      0.75       210\n",
      "           4       0.41      0.38      0.39       210\n",
      "           5       0.46      0.49      0.47       210\n",
      "           6       0.25      0.38      0.30       210\n",
      "           7       0.67      0.52      0.59       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.50      1470\n",
      "weighted avg       0.52      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  10   6  17  25  31   6]\n",
      " [ 23  98   7  26  30  25   1]\n",
      " [  9  14 153  12   7  14   1]\n",
      " [ 28  26  10  73  26  38   9]\n",
      " [ 27  25   3  31 101  19   4]\n",
      " [ 24  24  12  32  15  77  26]\n",
      " [ 10  13   4  15   7  49 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52       210\n",
      "           2       0.47      0.47      0.47       210\n",
      "           3       0.78      0.73      0.76       210\n",
      "           4       0.35      0.35      0.35       210\n",
      "           5       0.48      0.48      0.48       210\n",
      "           6       0.30      0.37      0.33       210\n",
      "           7       0.70      0.53      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.48707482993197276\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  13   7  18  22  18  17]\n",
      " [ 20 107   9  20  24  21   9]\n",
      " [  8  11 154  17   7  11   2]\n",
      " [ 21  26   9  79  29  25  21]\n",
      " [ 28  29   3  27  97  16  10]\n",
      " [ 22  25  22  27  13  53  48]\n",
      " [ 12  14   8  14   6  45 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.55      0.53       210\n",
      "           2       0.48      0.51      0.49       210\n",
      "           3       0.73      0.73      0.73       210\n",
      "           4       0.39      0.38      0.38       210\n",
      "           5       0.49      0.46      0.48       210\n",
      "           6       0.28      0.25      0.27       210\n",
      "           7       0.51      0.53      0.52       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.48      1470\n",
      "weighted avg       0.48      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48707482993197276\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  16   3  11  27  29  13]\n",
      " [ 24 104   9  17  27  21   8]\n",
      " [  9  16 156  11   6   9   3]\n",
      " [ 30  22   8  73  34  30  13]\n",
      " [ 29  21   4  33  97  18   8]\n",
      " [ 27  21  18  24  25  56  39]\n",
      " [ 14  12   1  12  13  39 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.53      0.49       210\n",
      "           2       0.49      0.50      0.49       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.40      0.35      0.37       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.28      0.27      0.27       210\n",
      "           7       0.59      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117  11  10  11  28  21  12]\n",
      " [ 22 105  10  21  25  22   5]\n",
      " [ 10  13 160  10   6   9   2]\n",
      " [ 33  23  11  72  25  30  16]\n",
      " [ 30  17   6  30  96  21  10]\n",
      " [ 24  22  24  22  22  55  41]\n",
      " [ 10   8   4  11  15  41 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.56      0.51       210\n",
      "           2       0.53      0.50      0.51       210\n",
      "           3       0.71      0.76      0.74       210\n",
      "           4       0.41      0.34      0.37       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.58      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.501360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  13   6  17  23  24   9]\n",
      " [ 21 103   9  15  29  29   4]\n",
      " [  8  11 159  13   5  11   3]\n",
      " [ 25  24   9  81  27  30  14]\n",
      " [ 34  16   7  33  94  18   8]\n",
      " [ 24  27  20  23  17  60  39]\n",
      " [  8   8   2  12  17  41 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.56      0.53       210\n",
      "           2       0.51      0.49      0.50       210\n",
      "           3       0.75      0.76      0.75       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.44      0.45      0.45       210\n",
      "           6       0.28      0.29      0.28       210\n",
      "           7       0.61      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112  14  12  11  27  25   9]\n",
      " [ 18 102  13  18  28  23   8]\n",
      " [  7  15 160  15   3   8   2]\n",
      " [ 18  22   7  80  31  35  17]\n",
      " [ 32  19   5  30  99  21   4]\n",
      " [ 24  24  17  29  18  57  41]\n",
      " [  5  15   4  15  10  44 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.53      0.53       210\n",
      "           2       0.48      0.49      0.48       210\n",
      "           3       0.73      0.76      0.75       210\n",
      "           4       0.40      0.38      0.39       210\n",
      "           5       0.46      0.47      0.46       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.59      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117  10   9  16  25  21  12]\n",
      " [ 16 100   9  21  29  25  10]\n",
      " [  7  15 157  11   7  10   3]\n",
      " [ 25  19   8  81  33  28  16]\n",
      " [ 27  20   4  32  92  28   7]\n",
      " [ 25  23  20  28  19  56  39]\n",
      " [ 13  13   6  14   7  42 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.56      0.53       210\n",
      "           2       0.50      0.48      0.49       210\n",
      "           3       0.74      0.75      0.74       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.43      0.44      0.44       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.57      0.55      0.56       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48027210884353744\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109  21   5  12  24  27  12]\n",
      " [ 16 102  13  22  28  25   4]\n",
      " [  8  13 162  11   5  10   1]\n",
      " [ 18  21  10  77  37  32  15]\n",
      " [ 35  20   7  30  91  20   7]\n",
      " [ 37  31  20  22  14  50  36]\n",
      " [ 11   5   3  14  15  47 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.52      0.49       210\n",
      "           2       0.48      0.49      0.48       210\n",
      "           3       0.74      0.77      0.75       210\n",
      "           4       0.41      0.37      0.39       210\n",
      "           5       0.43      0.43      0.43       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.61      0.55      0.57       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  15   9  20  24  18  11]\n",
      " [ 15 100  11  18  23  34   9]\n",
      " [  7  13 157  16   7   8   2]\n",
      " [ 25  25   8  77  31  29  15]\n",
      " [ 30  21   5  30  95  19  10]\n",
      " [ 25  31  14  29  14  62  35]\n",
      " [  4  11   2  19  12  48 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53       210\n",
      "           2       0.46      0.48      0.47       210\n",
      "           3       0.76      0.75      0.75       210\n",
      "           4       0.37      0.37      0.37       210\n",
      "           5       0.46      0.45      0.46       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.58      0.54      0.56       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  13   7  13  29  26   9]\n",
      " [ 16  98   9  24  31  27   5]\n",
      " [  8  13 159  13   5   9   3]\n",
      " [ 21  19  11  87  23  31  18]\n",
      " [ 31  23   3  33  96  16   8]\n",
      " [ 24  29  20  28  17  55  37]\n",
      " [ 14  10   6  11  15  36 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52       210\n",
      "           2       0.48      0.47      0.47       210\n",
      "           3       0.74      0.76      0.75       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.60      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 53   2  37   1  60   3  54]\n",
      " [  7  55  41   0  60   3  44]\n",
      " [  4   2 190   0   8   1   5]\n",
      " [ 10   4  33   9  87   0  67]\n",
      " [ 14   3   8   3 132   0  50]\n",
      " [ 10   7  39   2  18   7 127]\n",
      " [  2   1  11   0   8   0 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.25      0.34       210\n",
      "           2       0.74      0.26      0.39       210\n",
      "           3       0.53      0.90      0.67       210\n",
      "           4       0.60      0.04      0.08       210\n",
      "           5       0.35      0.63      0.45       210\n",
      "           6       0.50      0.03      0.06       210\n",
      "           7       0.35      0.90      0.50       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.52      0.43      0.36      1470\n",
      "weighted avg       0.52      0.43      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   3  14   0  36   1  51]\n",
      " [  3 111  23   0  38   3  32]\n",
      " [  6  11 172   0  10   7   4]\n",
      " [ 18  15  15  16  85   2  59]\n",
      " [ 16  16   1   2 129   0  46]\n",
      " [ 19  20  17   5  15   9 125]\n",
      " [  0   1   0   0   6   0 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.50      0.56       210\n",
      "           2       0.63      0.53      0.57       210\n",
      "           3       0.71      0.82      0.76       210\n",
      "           4       0.70      0.08      0.14       210\n",
      "           5       0.40      0.61      0.49       210\n",
      "           6       0.41      0.04      0.08       210\n",
      "           7       0.39      0.97      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.45      1470\n",
      "weighted avg       0.55      0.51      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   6   0   0  26   8  40]\n",
      " [  3 139  10   2  26   5  25]\n",
      " [  5  11 171   5   6  10   2]\n",
      " [ 13  25  13  41  61   4  53]\n",
      " [ 22  18   0   4 124   1  41]\n",
      " [  9  25  11  10  18  27 110]\n",
      " [  0   5   0   0   2   2 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.62      0.66       210\n",
      "           2       0.61      0.66      0.63       210\n",
      "           3       0.83      0.81      0.82       210\n",
      "           4       0.66      0.20      0.30       210\n",
      "           5       0.47      0.59      0.52       210\n",
      "           6       0.47      0.13      0.20       210\n",
      "           7       0.43      0.96      0.59       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.53      1470\n",
      "weighted avg       0.60      0.57      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   4   0   1  28  13  29]\n",
      " [  1 151   5   5  23  11  14]\n",
      " [  6  11 172   9   4   7   1]\n",
      " [ 12  22   8  68  48  18  34]\n",
      " [ 28  21   0  12 113  10  26]\n",
      " [ 16  27   6  17  12  35  97]\n",
      " [  0   4   0   0   3   5 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.64      0.66       210\n",
      "           2       0.63      0.72      0.67       210\n",
      "           3       0.90      0.82      0.86       210\n",
      "           4       0.61      0.32      0.42       210\n",
      "           5       0.49      0.54      0.51       210\n",
      "           6       0.35      0.17      0.23       210\n",
      "           7       0.50      0.94      0.65       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.57      1470\n",
      "weighted avg       0.59      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   6   0   3  29  24  20]\n",
      " [  1 145   5   5  27  19   8]\n",
      " [  2   6 177  13   4   7   1]\n",
      " [  4  12   7  90  39  27  31]\n",
      " [ 23  17   0   7 126  15  22]\n",
      " [ 13  21   3  25   7  57  84]\n",
      " [  0   3   0   0   3   6 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.61      0.67       210\n",
      "           2       0.69      0.69      0.69       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.63      0.43      0.51       210\n",
      "           5       0.54      0.60      0.57       210\n",
      "           6       0.37      0.27      0.31       210\n",
      "           7       0.54      0.94      0.69       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   5   0   4  27  29  12]\n",
      " [  1 146   4  14  19  23   3]\n",
      " [  1   3 183  13   4   5   1]\n",
      " [  2  13   6  98  35  34  22]\n",
      " [ 19  15   0  14 127  20  15]\n",
      " [  9  22   6  23   8  71  71]\n",
      " [  0   3   0   0   3   9 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       210\n",
      "           2       0.71      0.70      0.70       210\n",
      "           3       0.92      0.87      0.89       210\n",
      "           4       0.59      0.47      0.52       210\n",
      "           5       0.57      0.60      0.59       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.61      0.93      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   0   5  29  23  17]\n",
      " [  1 150   2  11  22  20   4]\n",
      " [  0   3 183  10   6   6   2]\n",
      " [  3  10   2 121  28  26  20]\n",
      " [ 15  13   0  21 128  20  13]\n",
      " [ 10  16   6  25   6  83  64]\n",
      " [  0   2   0   1   4  13 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.71       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.95      0.87      0.91       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.43      0.40      0.41       210\n",
      "           7       0.61      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   5   0   5  28  30   9]\n",
      " [  1 139   4  12  28  22   4]\n",
      " [  2   7 180  10   4   7   0]\n",
      " [  5  11   4 119  29  28  14]\n",
      " [ 13  13   1  23 129  16  15]\n",
      " [  7  17   8  18   7  90  63]\n",
      " [  0   1   0   1   4  14 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.63      0.72       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.91      0.86      0.88       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.56      0.61      0.59       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   0   8  32  23  11]\n",
      " [  1 145   4  15  19  24   2]\n",
      " [  0   5 186  10   3   6   0]\n",
      " [  4  14   5 116  30  26  15]\n",
      " [ 23  11   1  18 131  12  14]\n",
      " [  7  15   6  23   5  95  59]\n",
      " [  0   0   0   0   3  14 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.63      0.70       210\n",
      "           2       0.75      0.69      0.72       210\n",
      "           3       0.92      0.89      0.90       210\n",
      "           4       0.61      0.55      0.58       210\n",
      "           5       0.59      0.62      0.61       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.66      0.92      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   3   0   4  33  27   9]\n",
      " [  1 146   4  14  20  23   2]\n",
      " [  0   3 187   8   7   5   0]\n",
      " [  3   9   3 135  25  25  10]\n",
      " [ 18  15   0  21 132  13  11]\n",
      " [  7  20   5  20   7 100  51]\n",
      " [  1   0   0   0   4  16 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.67      0.64      0.66       210\n",
      "           5       0.58      0.63      0.60       210\n",
      "           6       0.48      0.48      0.48       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   3   0   3  34  25  11]\n",
      " [  3 158   3  11  16  17   2]\n",
      " [  0   5 186   9   5   5   0]\n",
      " [  1  13   3 126  31  28   8]\n",
      " [ 19  11   1  21 129  13  16]\n",
      " [ 12  15   5  18   6  97  57]\n",
      " [  0   1   0   1   3  17 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.77      0.75      0.76       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.58      0.61      0.59       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.67      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   4   0   1  30  26  11]\n",
      " [  2 147   4  16  16  22   3]\n",
      " [  0   3 188   8   6   4   1]\n",
      " [  4  11   3 125  30  23  14]\n",
      " [ 20  12   2  21 126  10  19]\n",
      " [  9  13   6  24   7 102  49]\n",
      " [  0   3   0   2   2  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.72       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.93      0.90      0.91       210\n",
      "           4       0.63      0.60      0.61       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.65      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   4   0   2  34  27  10]\n",
      " [  1 152   3  13  18  21   2]\n",
      " [  0   3 191  10   2   4   0]\n",
      " [  2   9   2 126  30  29  12]\n",
      " [ 18  11   0  29 128  14  10]\n",
      " [  6  13   4  27   6 101  53]\n",
      " [  0   0   0   0   4  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.63      0.72       210\n",
      "           2       0.79      0.72      0.76       210\n",
      "           3       0.95      0.91      0.93       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.58      0.61      0.59       210\n",
      "           6       0.45      0.48      0.47       210\n",
      "           7       0.67      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   5   0   2  28  26   8]\n",
      " [  1 147   4  15  19  21   3]\n",
      " [  1   5 186   8   4   6   0]\n",
      " [  2  11   6 121  31  28  11]\n",
      " [ 22  12   0  24 129  12  11]\n",
      " [ 11  13   3  22   9  92  60]\n",
      " [  0   1   0   1   3  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.67      0.73       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.58      0.61      0.60       210\n",
      "           6       0.45      0.44      0.44       210\n",
      "           7       0.67      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   3   1  10  27  26   6]\n",
      " [  3 147   5  11  22  20   2]\n",
      " [  0   6 185   9   4   5   1]\n",
      " [  0   9   6 131  30  26   8]\n",
      " [ 21  10   0  28 125  15  11]\n",
      " [  6  16   5  21   9  95  58]\n",
      " [  0   0   0   2   4  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.65      0.73       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   4   1   2  37  22   8]\n",
      " [  1 149   6  17  14  20   3]\n",
      " [  0   4 188   8   5   5   0]\n",
      " [  1  10   3 127  29  28  12]\n",
      " [ 22  18   0  23 128   9  10]\n",
      " [ 10  17   4  23   6  91  59]\n",
      " [  0   1   0   1   3  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.65      0.72       210\n",
      "           2       0.73      0.71      0.72       210\n",
      "           3       0.93      0.90      0.91       210\n",
      "           4       0.63      0.60      0.62       210\n",
      "           5       0.58      0.61      0.59       210\n",
      "           6       0.47      0.43      0.45       210\n",
      "           7       0.67      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   2   1   3  32  25  12]\n",
      " [  1 146   4   9  24  22   4]\n",
      " [  1   3 190   9   2   5   0]\n",
      " [  4   8   4 120  31  29  14]\n",
      " [ 21  13   1  25 127  15   8]\n",
      " [  9  16   3  18  10  99  55]\n",
      " [  1   0   0   1   2  25 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.64      0.71       210\n",
      "           2       0.78      0.70      0.73       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.45      0.47      0.46       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   4   0   4  32  24   6]\n",
      " [  1 146   2  14  22  21   4]\n",
      " [  0   2 188  10   5   5   0]\n",
      " [  4  11   2 128  26  25  14]\n",
      " [ 20  15   1  26 128   9  11]\n",
      " [ 11  16   4  24   9  95  51]\n",
      " [  0   0   0   1   3  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       210\n",
      "           2       0.75      0.70      0.72       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.62      0.61      0.61       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   6   0   3  29  22  10]\n",
      " [  1 151   3  15  19  17   4]\n",
      " [  0   4 189  11   4   2   0]\n",
      " [  4  12   4 127  27  23  13]\n",
      " [ 18  15   1  26 125  14  11]\n",
      " [ 10  12   4  25  11  98  50]\n",
      " [  1   0   0   3   2  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       210\n",
      "           2       0.76      0.72      0.74       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.60      0.60      0.60       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.49      0.47      0.48       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   4   1   5  31  18   9]\n",
      " [  2 148   5  14  20  16   5]\n",
      " [  0   2 188   8   6   6   0]\n",
      " [  5  11   4 130  22  24  14]\n",
      " [ 20  16   1  28 126  11   8]\n",
      " [  8  15   7  26   8  94  52]\n",
      " [  0   0   0   2   3  24 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.73       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.91      0.90      0.90       210\n",
      "           4       0.61      0.62      0.61       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.67      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.580952380952381\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[108   3  21   4  25  37  12]\n",
      " [  0 115  27  11  23  25   9]\n",
      " [ 21   3 165  10   2   9   0]\n",
      " [ 10  14  12  94  24  34  22]\n",
      " [ 23  11   2  16 119  18  21]\n",
      " [ 18  20  14  19   5  74  60]\n",
      " [  0  10   0   0   3  18 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.51      0.55       210\n",
      "           2       0.65      0.55      0.60       210\n",
      "           3       0.68      0.79      0.73       210\n",
      "           4       0.61      0.45      0.52       210\n",
      "           5       0.59      0.57      0.58       210\n",
      "           6       0.34      0.35      0.35       210\n",
      "           7       0.59      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//gpt_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7476190476190476\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[155   2   3   2  28  18   2]\n",
      " [  3 169   5  10  11  10   2]\n",
      " [  0   4 195   3   2   6   0]\n",
      " [  1  14   8 130  28  24   5]\n",
      " [ 22  16   1  19 142   2   8]\n",
      " [  8  10   7  23   4 121  37]\n",
      " [  0   0   0   1   1  21 187]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.74      0.78       210\n",
      "           2       0.79      0.80      0.80       210\n",
      "           3       0.89      0.93      0.91       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.66      0.68      0.67       210\n",
      "           6       0.60      0.58      0.59       210\n",
      "           7       0.78      0.89      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   3   4   5  33   7   3]\n",
      " [ 10 164   9   8  13   6   0]\n",
      " [  3   2 196   7   1   1   0]\n",
      " [ 21  24  22 100  32   7   4]\n",
      " [ 40  28   3  16 119   0   4]\n",
      " [ 27  28  13  28  10  67  37]\n",
      " [ 16   1   0   8   6  12 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.74      0.64       210\n",
      "           2       0.66      0.78      0.71       210\n",
      "           3       0.79      0.93      0.86       210\n",
      "           4       0.58      0.48      0.52       210\n",
      "           5       0.56      0.57      0.56       210\n",
      "           6       0.67      0.32      0.43       210\n",
      "           7       0.78      0.80      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   2   4   4  34   9   3]\n",
      " [  5 172   9   8  12   3   1]\n",
      " [  1   6 196   5   0   2   0]\n",
      " [ 14  21  24 109  29  10   3]\n",
      " [ 38  30   5  18 109   4   6]\n",
      " [ 18  26  11  23  15  75  42]\n",
      " [ 10   1   0   4   3  23 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.68       210\n",
      "           2       0.67      0.82      0.74       210\n",
      "           3       0.79      0.93      0.85       210\n",
      "           4       0.64      0.52      0.57       210\n",
      "           5       0.54      0.52      0.53       210\n",
      "           6       0.60      0.36      0.45       210\n",
      "           7       0.75      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   3   3   5  42   7   4]\n",
      " [  4 169   8   6  16   4   3]\n",
      " [  1   5 194   7   2   1   0]\n",
      " [  9  23  24 109  33  10   2]\n",
      " [ 27  30   6  14 125   2   6]\n",
      " [ 19  28  11  25  14  73  40]\n",
      " [  8   1   0   5   1  28 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69       210\n",
      "           2       0.65      0.80      0.72       210\n",
      "           3       0.79      0.92      0.85       210\n",
      "           4       0.64      0.52      0.57       210\n",
      "           5       0.54      0.60      0.56       210\n",
      "           6       0.58      0.35      0.44       210\n",
      "           7       0.75      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   4   4   3  39   8   5]\n",
      " [  4 174   5   6  13   6   2]\n",
      " [  1   5 198   4   1   1   0]\n",
      " [  9  20  28 105  34  10   4]\n",
      " [ 30  30   6  16 121   0   7]\n",
      " [ 19  27  14  20  10  71  49]\n",
      " [  6   1   0   6   3  25 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69       210\n",
      "           2       0.67      0.83      0.74       210\n",
      "           3       0.78      0.94      0.85       210\n",
      "           4       0.66      0.50      0.57       210\n",
      "           5       0.55      0.58      0.56       210\n",
      "           6       0.59      0.34      0.43       210\n",
      "           7       0.72      0.80      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   4   4   5  41   7   6]\n",
      " [  2 175   7   5  13   6   2]\n",
      " [  1   4 194   6   3   2   0]\n",
      " [ 10  22  28 105  31  11   3]\n",
      " [ 21  24   5  14 139   0   7]\n",
      " [ 20  24  14  25  16  67  44]\n",
      " [  3   1   0   5   4  22 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.70       210\n",
      "           2       0.69      0.83      0.75       210\n",
      "           3       0.77      0.92      0.84       210\n",
      "           4       0.64      0.50      0.56       210\n",
      "           5       0.56      0.66      0.61       210\n",
      "           6       0.58      0.32      0.41       210\n",
      "           7       0.74      0.83      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   3   4   4  43   8   7]\n",
      " [  2 174   8   4  15   4   3]\n",
      " [  1   6 192   5   4   2   0]\n",
      " [  9  20  28 103  34  10   6]\n",
      " [ 21  27   5  13 136   0   8]\n",
      " [ 20  21  14  24  15  67  49]\n",
      " [  6   1   0   3   3  22 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69       210\n",
      "           2       0.69      0.83      0.75       210\n",
      "           3       0.76      0.91      0.83       210\n",
      "           4       0.66      0.49      0.56       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.59      0.32      0.41       210\n",
      "           7       0.71      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.6326530612244898\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[135   1   1   5  35  26   7]\n",
      " [  3 132  15  10  24  21   5]\n",
      " [  5   4 174  12   3  12   0]\n",
      " [  2  17  14  85  45  35  12]\n",
      " [ 34  18   2  10 128   5  13]\n",
      " [ 11   9  10  19   4 102  55]\n",
      " [  0   0   0   1   2  33 174]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       210\n",
      "           2       0.73      0.63      0.68       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.60      0.40      0.48       210\n",
      "           5       0.53      0.61      0.57       210\n",
      "           6       0.44      0.49      0.46       210\n",
      "           7       0.65      0.83      0.73       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[135   1   1   7  38  21   7]\n",
      " [  4 137  14   7  22  21   5]\n",
      " [ 21   5 153  16   3  12   0]\n",
      " [  4  18  14  79  45  34  16]\n",
      " [ 31  14   2  11 130   6  16]\n",
      " [ 13  14  11  13   7  96  56]\n",
      " [  0   0   0   1   3  32 174]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.64      0.65       210\n",
      "           2       0.72      0.65      0.69       210\n",
      "           3       0.78      0.73      0.76       210\n",
      "           4       0.59      0.38      0.46       210\n",
      "           5       0.52      0.62      0.57       210\n",
      "           6       0.43      0.46      0.44       210\n",
      "           7       0.64      0.83      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7489795918367347\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   3   0   2  31  21   2]\n",
      " [  1 171   3  10  11  12   2]\n",
      " [  0   5 194   4   2   5   0]\n",
      " [  0  14  10 127  24  31   4]\n",
      " [ 19  18   0  17 146   3   7]\n",
      " [  6   8   2  24   4 128  38]\n",
      " [  0   0   0   2   1  23 184]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.72      0.78       210\n",
      "           2       0.78      0.81      0.80       210\n",
      "           3       0.93      0.92      0.93       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.67      0.70      0.68       210\n",
      "           6       0.57      0.61      0.59       210\n",
      "           7       0.78      0.88      0.82       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7775510204081633\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   2   2   2  30  19   2]\n",
      " [  2 175   2  10   8  11   2]\n",
      " [  0   4 195   6   2   3   0]\n",
      " [  2  13   6 142  21  24   2]\n",
      " [ 15  14   0  17 154   4   6]\n",
      " [  3   9   1  20   2 142  33]\n",
      " [  1   0   0   0   1  26 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.73      0.79       210\n",
      "           2       0.81      0.83      0.82       210\n",
      "           3       0.95      0.93      0.94       210\n",
      "           4       0.72      0.68      0.70       210\n",
      "           5       0.71      0.73      0.72       210\n",
      "           6       0.62      0.68      0.65       210\n",
      "           7       0.80      0.87      0.83       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.78      0.78      0.78      1470\n",
      "weighted avg       0.78      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7605442176870748\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   2   1   4  33  18   4]\n",
      " [  2 174   2   9   8  13   2]\n",
      " [  0   3 193   7   3   4   0]\n",
      " [  1  13   6 135  23  31   1]\n",
      " [ 15  16   0  16 152   4   7]\n",
      " [  4   7   1  24   3 132  39]\n",
      " [  1   0   0   0   1  24 184]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.70      0.78       210\n",
      "           2       0.81      0.83      0.82       210\n",
      "           3       0.95      0.92      0.93       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.68      0.72      0.70       210\n",
      "           6       0.58      0.63      0.61       210\n",
      "           7       0.78      0.88      0.82       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7095238095238096\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   2   3   1  29  20   2]\n",
      " [  2 158   8  18  10  13   1]\n",
      " [  0   4 194   4   3   5   0]\n",
      " [  2  22  13 107  28  34   4]\n",
      " [ 22  14   1  22 140   5   6]\n",
      " [ 11   9   9  20   7 115  39]\n",
      " [  0   0   0   2   2  30 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.76       210\n",
      "           2       0.76      0.75      0.75       210\n",
      "           3       0.85      0.92      0.89       210\n",
      "           4       0.61      0.51      0.56       210\n",
      "           5       0.64      0.67      0.65       210\n",
      "           6       0.52      0.55      0.53       210\n",
      "           7       0.77      0.84      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0   0   0 200]\n",
      " [  0   0  12   0   0   0 198]\n",
      " [  0   0 135   0   0   0  75]\n",
      " [  0   0  11   0   0   0 199]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0  22   0   0   0 188]\n",
      " [  0   0   4   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.68      0.64      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.98      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.12      0.23      0.13      1470\n",
      "weighted avg       0.12      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   2   0 180   8  20]\n",
      " [  0   0   6   0 176   6  22]\n",
      " [  0   0 120   0  67  15   8]\n",
      " [  0   0   8   0 171   3  28]\n",
      " [  0   0   3   0 192   2  13]\n",
      " [  0   0   3   0  75  19 113]\n",
      " [  0   0   0   0  32   4 174]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.85      0.57      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.91      0.35       210\n",
      "           6       0.33      0.09      0.14       210\n",
      "           7       0.46      0.83      0.59       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.26      0.34      0.25      1470\n",
      "weighted avg       0.26      0.34      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[162  19   8   0   0   9  12]\n",
      " [ 17 161   9   0   0  15   8]\n",
      " [  4  65 130   0   0  11   0]\n",
      " [ 55 117  10   0   0  13  15]\n",
      " [127  67   3   0   0   2  11]\n",
      " [ 42  33  15   0   0  46  74]\n",
      " [ 25   7   3   0   0  11 164]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.77      0.50       210\n",
      "           2       0.34      0.77      0.47       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.43      0.22      0.29       210\n",
      "           7       0.58      0.78      0.66       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.35      0.45      0.37      1470\n",
      "weighted avg       0.35      0.45      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   5   2  13  67  15  12]\n",
      " [  1 127   3  35  16  20   8]\n",
      " [  0  19 124  51   5  11   0]\n",
      " [  1  47   7  70  55  15  15]\n",
      " [ 13  34   0  32 116   4  11]\n",
      " [  2  19   4  14  42  55  74]\n",
      " [  0   5   0   2  25  14 164]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.46      0.59       210\n",
      "           2       0.50      0.60      0.55       210\n",
      "           3       0.89      0.59      0.71       210\n",
      "           4       0.32      0.33      0.33       210\n",
      "           5       0.36      0.55      0.43       210\n",
      "           6       0.41      0.26      0.32       210\n",
      "           7       0.58      0.78      0.66       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.56      0.51      0.51      1470\n",
      "weighted avg       0.56      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   5   3  26  56  19   7]\n",
      " [  1 116   6  59   7  18   3]\n",
      " [  3  11 159  24   8   5   0]\n",
      " [  0  11  12 130  29  19   9]\n",
      " [  5  24   3  60 103   8   7]\n",
      " [  5  11   7  54  13  76  44]\n",
      " [  0   1   0  29   3  40 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.45      0.59       210\n",
      "           2       0.65      0.55      0.60       210\n",
      "           3       0.84      0.76      0.79       210\n",
      "           4       0.34      0.62      0.44       210\n",
      "           5       0.47      0.49      0.48       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.66      0.65      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.61      0.55      0.56      1470\n",
      "weighted avg       0.61      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   2   2  28  59  18   4]\n",
      " [  6 120   3  41  24  13   3]\n",
      " [  5  17 157  21   7   3   0]\n",
      " [  2  31   6 113  28  23   7]\n",
      " [  9  20   1  46 121   7   6]\n",
      " [ 11  21   4  40  11  89  34]\n",
      " [  0   6   0  20   0  62 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.46      0.57       210\n",
      "           2       0.55      0.57      0.56       210\n",
      "           3       0.91      0.75      0.82       210\n",
      "           4       0.37      0.54      0.44       210\n",
      "           5       0.48      0.58      0.53       210\n",
      "           6       0.41      0.42      0.42       210\n",
      "           7       0.69      0.58      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.57      1470\n",
      "weighted avg       0.59      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   5   2  25  41  10  14]\n",
      " [  3 130   7  38  15   9   8]\n",
      " [  2  16 166  19   3   4   0]\n",
      " [  3  38   5 111  22  11  20]\n",
      " [ 26  23   1  42 102   4  12]\n",
      " [ 12  24   6  43   4  53  68]\n",
      " [  1   5   2   9   0  41 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.54      0.61       210\n",
      "           2       0.54      0.62      0.58       210\n",
      "           3       0.88      0.79      0.83       210\n",
      "           4       0.39      0.53      0.45       210\n",
      "           5       0.55      0.49      0.51       210\n",
      "           6       0.40      0.25      0.31       210\n",
      "           7       0.55      0.72      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.572108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   8   4  23  38  11   8]\n",
      " [  3 126   8  49  11   8   5]\n",
      " [  3  11 168  22   3   3   0]\n",
      " [  2  19   5 127  25  19  13]\n",
      " [ 29  16   1  46  99  15   4]\n",
      " [  9  22   4  45   9  62  59]\n",
      " [  3   4   3  11   0  48 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.56      0.63       210\n",
      "           2       0.61      0.60      0.61       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.39      0.60      0.48       210\n",
      "           5       0.54      0.47      0.50       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.61      0.67      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   4   4  19  44  18   5]\n",
      " [  3 129   8  32  19  15   4]\n",
      " [  3  10 175  12   4   6   0]\n",
      " [  6  15   8 106  34  27  14]\n",
      " [ 23  16   2  38 114  13   4]\n",
      " [ 11  20   6  37  11  75  50]\n",
      " [  7   3   3  10   4  45 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.55      0.61       210\n",
      "           2       0.65      0.61      0.63       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.42      0.50      0.46       210\n",
      "           5       0.50      0.54      0.52       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.64      0.66      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   7   5  13  49  14   6]\n",
      " [  5 117  10  29  24  18   7]\n",
      " [  5  10 174  13   4   4   0]\n",
      " [ 12  20  10  90  38  30  10]\n",
      " [ 36  15   3  29 112  11   4]\n",
      " [ 17  24   6  27  18  65  53]\n",
      " [  9   2   3  12   4  38 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.55      0.57       210\n",
      "           2       0.60      0.56      0.58       210\n",
      "           3       0.82      0.83      0.83       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.36      0.31      0.33       210\n",
      "           7       0.64      0.68      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.55      1470\n",
      "weighted avg       0.55      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   7   2  13  50  14   5]\n",
      " [  4 131  10  30  16  16   3]\n",
      " [  5   7 176  10   7   5   0]\n",
      " [ 12  19   7  98  38  25  11]\n",
      " [ 32  24   4  26 105  13   6]\n",
      " [ 20  19  12  32  14  65  48]\n",
      " [  5   4   4  14   3  41 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.57      0.58       210\n",
      "           2       0.62      0.62      0.62       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.44      0.47      0.45       210\n",
      "           5       0.45      0.50      0.47       210\n",
      "           6       0.36      0.31      0.33       210\n",
      "           7       0.66      0.66      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   5   2  14  49  19   5]\n",
      " [  5 132   9  29  19  12   4]\n",
      " [  6   9 175  11   4   5   0]\n",
      " [ 10  18  10  98  35  26  13]\n",
      " [ 30  29   1  25 106  11   8]\n",
      " [ 20  21   8  30  18  68  45]\n",
      " [  7   2   3  10   4  42 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.55      0.57       210\n",
      "           2       0.61      0.63      0.62       210\n",
      "           3       0.84      0.83      0.84       210\n",
      "           4       0.45      0.47      0.46       210\n",
      "           5       0.45      0.50      0.48       210\n",
      "           6       0.37      0.32      0.35       210\n",
      "           7       0.65      0.68      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   7   5  10  51  11   6]\n",
      " [  6 121  12  28  22  13   8]\n",
      " [  2   8 178   5  11   5   1]\n",
      " [  9  17  11 101  39  24   9]\n",
      " [ 36  22   4  31 101  11   5]\n",
      " [ 19  15  14  28  20  71  43]\n",
      " [  7   4   2  12   2  37 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.57      0.59       210\n",
      "           2       0.62      0.58      0.60       210\n",
      "           3       0.79      0.85      0.82       210\n",
      "           4       0.47      0.48      0.48       210\n",
      "           5       0.41      0.48      0.44       210\n",
      "           6       0.41      0.34      0.37       210\n",
      "           7       0.67      0.70      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.573469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   5   8   9  44  14   9]\n",
      " [  6 124   9  30  18  16   7]\n",
      " [  3  11 172  13   6   5   0]\n",
      " [ 10  17  11 101  35  22  14]\n",
      " [ 37  16   3  29 106  11   8]\n",
      " [ 13  18  12  32  17  71  47]\n",
      " [  3   4   4   7   3  41 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.60       210\n",
      "           2       0.64      0.59      0.61       210\n",
      "           3       0.79      0.82      0.80       210\n",
      "           4       0.46      0.48      0.47       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.39      0.34      0.36       210\n",
      "           7       0.64      0.70      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5578231292517006\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   8   8   8  43  14  12]\n",
      " [  7 126  11  28  19  14   5]\n",
      " [  5   8 174  13   5   5   0]\n",
      " [  8  22  10 101  28  28  13]\n",
      " [ 37  22   4  34  93  12   8]\n",
      " [ 23  23  15  25  13  66  45]\n",
      " [  6   6   3  11   1  40 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.56      0.57       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.46      0.48      0.47       210\n",
      "           5       0.46      0.44      0.45       210\n",
      "           6       0.37      0.31      0.34       210\n",
      "           7       0.63      0.68      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.55      1470\n",
      "weighted avg       0.55      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   6   7  11  40  13  10]\n",
      " [  5 122  13  28  24  14   4]\n",
      " [  1  11 174  13   4   6   1]\n",
      " [  7  19   7  92  37  33  15]\n",
      " [ 33  22   3  29 103  14   6]\n",
      " [ 16  24   9  24  20  73  44]\n",
      " [  5   3   2  10   2  45 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.59      0.61       210\n",
      "           2       0.59      0.58      0.59       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.45      0.49      0.47       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.64      0.68      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   8   5   7  47  13  10]\n",
      " [  4 128  12  26  25  12   3]\n",
      " [  4   7 178  10   5   3   3]\n",
      " [  8  19  10  96  38  24  15]\n",
      " [ 36  25   4  29  97  12   7]\n",
      " [ 22  22  11  22  21  66  46]\n",
      " [  4   6   2  11   1  40 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.57      0.59       210\n",
      "           2       0.60      0.61      0.60       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.48      0.46      0.47       210\n",
      "           5       0.41      0.46      0.44       210\n",
      "           6       0.39      0.31      0.35       210\n",
      "           7       0.63      0.70      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   8   8   6  46  13   8]\n",
      " [  5 125  10  28  26  11   5]\n",
      " [  5   7 177  13   5   2   1]\n",
      " [  7  16   9  97  38  29  14]\n",
      " [ 32  27   6  28 100  10   7]\n",
      " [ 19  19  13  24  15  73  47]\n",
      " [  6   3   3  14   2  38 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.58      0.60       210\n",
      "           2       0.61      0.60      0.60       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.41      0.35      0.38       210\n",
      "           7       0.64      0.69      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   8   7   8  44  15  11]\n",
      " [  6 120  13  24  29  13   5]\n",
      " [  3  12 173  11   7   3   1]\n",
      " [ 11  16   8  94  38  28  15]\n",
      " [ 38  25   2  29  96  16   4]\n",
      " [ 19  21  12  24  19  70  45]\n",
      " [  4   5   2  11   1  44 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.56      0.57       210\n",
      "           2       0.58      0.57      0.58       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.47      0.45      0.46       210\n",
      "           5       0.41      0.46      0.43       210\n",
      "           6       0.37      0.33      0.35       210\n",
      "           7       0.64      0.68      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   6   6   7  44  15  10]\n",
      " [  4 119  12  33  21  17   4]\n",
      " [  3   9 175  14   4   3   2]\n",
      " [  8  14  14  97  34  29  14]\n",
      " [ 45  22   5  32  87  13   6]\n",
      " [ 19  22  13  27  18  66  45]\n",
      " [  3   4   2  12   1  44 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59       210\n",
      "           2       0.61      0.57      0.59       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.44      0.46      0.45       210\n",
      "           5       0.42      0.41      0.42       210\n",
      "           6       0.35      0.31      0.33       210\n",
      "           7       0.64      0.69      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   1  11   0  61   0  35]\n",
      " [  6  86  53   1  34   0  30]\n",
      " [  1   7 192   0   6   0   4]\n",
      " [  5  17  54   0  74   0  60]\n",
      " [ 11   8  11   0 152   0  28]\n",
      " [  6   3  32   1  20   2 146]\n",
      " [  1   0   0   0   2   1 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.49      0.60       210\n",
      "           2       0.70      0.41      0.52       210\n",
      "           3       0.54      0.91      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.44      0.72      0.54       210\n",
      "           6       0.67      0.01      0.02       210\n",
      "           7       0.40      0.98      0.57       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.42      1470\n",
      "weighted avg       0.50      0.50      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   3   2   0  34   7  28]\n",
      " [  3 134  13   0  34   6  20]\n",
      " [  1  12 181   0   8   5   3]\n",
      " [  8  39  31   4  69   9  50]\n",
      " [ 42  20   4   0 122   1  21]\n",
      " [ 11  11  15   1  17  22 133]\n",
      " [  1   0   0   0   2   2 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.65      0.66       210\n",
      "           2       0.61      0.64      0.62       210\n",
      "           3       0.74      0.86      0.79       210\n",
      "           4       0.80      0.02      0.04       210\n",
      "           5       0.43      0.58      0.49       210\n",
      "           6       0.42      0.10      0.17       210\n",
      "           7       0.45      0.98      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.48      1470\n",
      "weighted avg       0.59      0.55      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   7   0   2  33  12  20]\n",
      " [  1 165   5   1  15  10  13]\n",
      " [  1  16 176   2   6   7   2]\n",
      " [  4  51  15  19  67  17  37]\n",
      " [ 36  25   2   0 129   0  18]\n",
      " [  8  16  10   8  14  39 115]\n",
      " [  0   0   0   1   2   4 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.65      0.69       210\n",
      "           2       0.59      0.79      0.67       210\n",
      "           3       0.85      0.84      0.84       210\n",
      "           4       0.58      0.09      0.16       210\n",
      "           5       0.48      0.61      0.54       210\n",
      "           6       0.44      0.19      0.26       210\n",
      "           7       0.50      0.97      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.55      1470\n",
      "weighted avg       0.59      0.59      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   2   0   8  44  17  13]\n",
      " [  1 156   1   9  20  15   8]\n",
      " [  1  11 174   9   6   9   0]\n",
      " [  1  28  11  58  59  31  22]\n",
      " [ 18  21   0   3 149   4  15]\n",
      " [  5  19   5  15  11  71  84]\n",
      " [  0   0   0   1   2  15 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.70       210\n",
      "           2       0.66      0.74      0.70       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.56      0.28      0.37       210\n",
      "           5       0.51      0.71      0.59       210\n",
      "           6       0.44      0.34      0.38       210\n",
      "           7       0.57      0.91      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.62      1470\n",
      "weighted avg       0.64      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   3   0   5  42  19   9]\n",
      " [  1 163   1   7  15  18   5]\n",
      " [  0   9 178  10   5   8   0]\n",
      " [  0  26   6  72  52  36  18]\n",
      " [ 14  25   0   6 148   4  13]\n",
      " [  5  12   1  22  14  81  75]\n",
      " [  0   0   0   1   2  16 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.63      0.73       210\n",
      "           2       0.68      0.78      0.73       210\n",
      "           3       0.96      0.85      0.90       210\n",
      "           4       0.59      0.34      0.43       210\n",
      "           5       0.53      0.70      0.61       210\n",
      "           6       0.45      0.39      0.41       210\n",
      "           7       0.61      0.91      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   3   0   7  46  23   7]\n",
      " [  1 156   1  10  19  19   4]\n",
      " [  0   6 180  10   5   9   0]\n",
      " [  0  14   4  90  51  36  15]\n",
      " [ 12  22   0   7 153   6  10]\n",
      " [  3   9   2  21  12  94  69]\n",
      " [  0   0   0   1   2  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.59      0.71       210\n",
      "           2       0.74      0.74      0.74       210\n",
      "           3       0.96      0.86      0.91       210\n",
      "           4       0.62      0.43      0.51       210\n",
      "           5       0.53      0.73      0.61       210\n",
      "           6       0.46      0.45      0.45       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   1   8  46  22   5]\n",
      " [  1 160   1  15  12  19   2]\n",
      " [  0   5 183  10   5   7   0]\n",
      " [  0  11   3 104  42  39  11]\n",
      " [ 10  18   0  11 155   6  10]\n",
      " [  3   8   3  23   9 104  60]\n",
      " [  0   0   0   1   2  20 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.60      0.72       210\n",
      "           2       0.79      0.76      0.77       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.60      0.50      0.54       210\n",
      "           5       0.57      0.74      0.64       210\n",
      "           6       0.48      0.50      0.49       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   2   1   7  39  18   9]\n",
      " [  2 164   1  10  13  18   2]\n",
      " [  0   5 181  13   5   6   0]\n",
      " [  1  11   4 115  36  33  10]\n",
      " [  9  20   0  13 151   8   9]\n",
      " [  6   7   1  29   5 109  53]\n",
      " [  0   0   0   1   2  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.64      0.74       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.96      0.86      0.91       210\n",
      "           4       0.61      0.55      0.58       210\n",
      "           5       0.60      0.72      0.66       210\n",
      "           6       0.50      0.52      0.51       210\n",
      "           7       0.69      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   2   1   5  40  21   6]\n",
      " [  2 166   1   8  13  18   2]\n",
      " [  0   5 186  10   3   6   0]\n",
      " [  1  11   3 119  35  36   5]\n",
      " [ 10  17   0  16 152   5  10]\n",
      " [  5   9   0  28   5 111  52]\n",
      " [  0   0   0   1   2  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.64      0.74       210\n",
      "           2       0.79      0.79      0.79       210\n",
      "           3       0.97      0.89      0.93       210\n",
      "           4       0.64      0.57      0.60       210\n",
      "           5       0.61      0.72      0.66       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.71      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   7  36  19   6]\n",
      " [  1 164   1   8  15  19   2]\n",
      " [  0   6 186  10   3   5   0]\n",
      " [  2   8   4 125  30  29  12]\n",
      " [ 17  17   0  16 146   7   7]\n",
      " [  3  12   1  26   7 112  49]\n",
      " [  0   0   0   1   2  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.65      0.60      0.62       210\n",
      "           5       0.61      0.70      0.65       210\n",
      "           6       0.52      0.53      0.52       210\n",
      "           7       0.70      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   2   1   4  42  20   4]\n",
      " [  2 164   1  10  13  18   2]\n",
      " [  0   3 187   9   6   5   0]\n",
      " [  0  12   5 119  31  36   7]\n",
      " [  8  16   0  17 154   5  10]\n",
      " [  4   9   0  24   8 117  48]\n",
      " [  0   0   0   1   2  25 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.65      0.76       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.96      0.89      0.93       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.60      0.73      0.66       210\n",
      "           6       0.52      0.56      0.54       210\n",
      "           7       0.72      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.72      1470\n",
      "weighted avg       0.74      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7197278911564626\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   3   1   5  32  22   5]\n",
      " [  2 160   3   9  14  20   2]\n",
      " [  0   5 190   6   4   5   0]\n",
      " [  1  14   4 123  33  28   7]\n",
      " [ 13  16   0  17 151   4   9]\n",
      " [  3   7   2  27   7 112  52]\n",
      " [  0   0   0   1   2  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.68      0.77       210\n",
      "           2       0.78      0.76      0.77       210\n",
      "           3       0.95      0.90      0.93       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.62      0.72      0.67       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.71      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   0   1   8  40  18   4]\n",
      " [  2 167   1  12  11  14   3]\n",
      " [  0   4 189  10   2   5   0]\n",
      " [  1   5   3 131  31  33   6]\n",
      " [ 15  14   0  19 148   5   9]\n",
      " [  5   9   2  26   6 109  53]\n",
      " [  0   0   0   2   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.84      0.80      0.82       210\n",
      "           3       0.96      0.90      0.93       210\n",
      "           4       0.63      0.62      0.63       210\n",
      "           5       0.62      0.70      0.66       210\n",
      "           6       0.54      0.52      0.53       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   1   5  38  17   7]\n",
      " [  2 162   2  13  13  17   1]\n",
      " [  0   5 190   6   4   5   0]\n",
      " [  0   9   5 128  34  27   7]\n",
      " [ 14  14   0  16 152   5   9]\n",
      " [  0   9   1  26   9 114  51]\n",
      " [  0   0   0   2   2  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.67      0.77       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.95      0.90      0.93       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.60      0.72      0.66       210\n",
      "           6       0.55      0.54      0.54       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   1   7  40  18   4]\n",
      " [  2 165   2  11  12  16   2]\n",
      " [  0   5 184  12   3   6   0]\n",
      " [  0   9   3 128  32  31   7]\n",
      " [ 13  13   0  20 150   3  11]\n",
      " [  7   8   1  24   7 116  47]\n",
      " [  0   0   0   0   2  28 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.82      0.79      0.80       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.63      0.61      0.62       210\n",
      "           5       0.61      0.71      0.66       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   2   1   5  35  20   5]\n",
      " [  3 165   1  12  11  16   2]\n",
      " [  0   5 185  12   3   5   0]\n",
      " [  2   9   5 126  34  26   8]\n",
      " [ 17  15   0  21 143   3  11]\n",
      " [  4  12   2  26   4 116  46]\n",
      " [  1   0   0   1   1  24 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.68      0.75       210\n",
      "           2       0.79      0.79      0.79       210\n",
      "           3       0.95      0.88      0.92       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.62      0.68      0.65       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.72      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7292517006802721\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   8  36  17   7]\n",
      " [  3 167   1  10  12  16   1]\n",
      " [  0   4 190   7   3   6   0]\n",
      " [  3   9   1 131  26  30  10]\n",
      " [ 13  17   0  18 149   7   6]\n",
      " [  6  11   1  26   4 115  47]\n",
      " [  1   0   0   1   1  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.98      0.90      0.94       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.65      0.71      0.68       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7285714285714285\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   2   5  38  18   6]\n",
      " [  2 167   2   8  15  13   3]\n",
      " [  0   4 191   6   3   6   0]\n",
      " [  1   9   1 133  28  28  10]\n",
      " [ 17  16   0  21 141   4  11]\n",
      " [  6   9   0  25   7 118  45]\n",
      " [  1   0   0   1   1  25 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.81      0.80      0.80       210\n",
      "           3       0.97      0.91      0.94       210\n",
      "           4       0.67      0.63      0.65       210\n",
      "           5       0.61      0.67      0.64       210\n",
      "           6       0.56      0.56      0.56       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7258503401360544\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   4  40  20   4]\n",
      " [  2 167   3   8  13  13   4]\n",
      " [  0   4 191   5   4   6   0]\n",
      " [  0  10   5 134  27  26   8]\n",
      " [ 14  14   0  21 148   2  11]\n",
      " [  7  11   2  27   5 109  49]\n",
      " [  1   0   0   1   1  28 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.75       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.95      0.91      0.93       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.62      0.70      0.66       210\n",
      "           6       0.53      0.52      0.53       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   1   1   4  44  19   7]\n",
      " [  4 169   1   6  12  15   3]\n",
      " [  0   4 191   6   3   6   0]\n",
      " [  1  10   3 132  26  30   8]\n",
      " [ 16  15   1  19 146   5   8]\n",
      " [  5  10   0  27   7 116  45]\n",
      " [  1   0   0   1   1  25 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.72       210\n",
      "           2       0.81      0.80      0.81       210\n",
      "           3       0.97      0.91      0.94       210\n",
      "           4       0.68      0.63      0.65       210\n",
      "           5       0.61      0.70      0.65       210\n",
      "           6       0.54      0.55      0.54       210\n",
      "           7       0.72      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[137   1   4   6  36  21   5]\n",
      " [  5 119  26   5  27  21   7]\n",
      " [ 21   3 168   5   3  10   0]\n",
      " [  8  18  22  64  46  36  16]\n",
      " [ 36  17   5   6 125   5  16]\n",
      " [ 12  14  14   9   8  93  60]\n",
      " [  0   0   0   1   3  34 172]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.65      0.64       210\n",
      "           2       0.69      0.57      0.62       210\n",
      "           3       0.70      0.80      0.75       210\n",
      "           4       0.67      0.30      0.42       210\n",
      "           5       0.50      0.60      0.55       210\n",
      "           6       0.42      0.44      0.43       210\n",
      "           7       0.62      0.82      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//xlm_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[138   4   3   7  39   8  11]\n",
      " [  7 132  12  12  20  20   7]\n",
      " [  5  22 170   4   1   6   2]\n",
      " [  5  18   7 107  27  24  22]\n",
      " [ 22  18   2   9 136  10  13]\n",
      " [ 17  17   5  16   5  86  64]\n",
      " [  1   1   0   1   4  21 182]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.66      0.68       210\n",
      "           2       0.62      0.63      0.63       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.69      0.51      0.58       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.49      0.41      0.45       210\n",
      "           7       0.60      0.87      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   5   1   9  32   7   4]\n",
      " [ 30 116  17  16  22   5   4]\n",
      " [  9  21 172   1   3   2   2]\n",
      " [ 39  30   6  76  38  10  11]\n",
      " [ 55  20   2  23  96   4  10]\n",
      " [ 48  19  11  38  15  39  40]\n",
      " [ 21   5   0  22  13  13 136]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.72      0.54       210\n",
      "           2       0.54      0.55      0.54       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.41      0.36      0.38       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.49      0.19      0.27       210\n",
      "           7       0.66      0.65      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   3   4   9  30   8  10]\n",
      " [ 22 118  16  14  26   6   8]\n",
      " [  6  25 166   3   3   3   4]\n",
      " [ 31  19   9  80  43  11  17]\n",
      " [ 54  20   1  26  97   4   8]\n",
      " [ 52  16  10  24  11  48  49]\n",
      " [ 17   3   1  12   9  19 149]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.70      0.54       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.80      0.79      0.80       210\n",
      "           4       0.48      0.38      0.42       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.48      0.23      0.31       210\n",
      "           7       0.61      0.71      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5523809523809524\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   4   4   9  33   6   8]\n",
      " [ 24 116  17  11  27   5  10]\n",
      " [  9  22 166   4   3   3   3]\n",
      " [ 23  19   6  83  45  14  20]\n",
      " [ 42  20   2  26 101   4  15]\n",
      " [ 43  25   9  23  15  52  43]\n",
      " [ 13   3   0  13  11  22 148]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.70      0.57       210\n",
      "           2       0.56      0.55      0.55       210\n",
      "           3       0.81      0.79      0.80       210\n",
      "           4       0.49      0.40      0.44       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.49      0.25      0.33       210\n",
      "           7       0.60      0.70      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   5   6   9  31   5   9]\n",
      " [ 22 114  20  15  26   6   7]\n",
      " [ 14  26 161   4   2   1   2]\n",
      " [ 26  21   6  75  46  10  26]\n",
      " [ 38  22   1  27 106   3  13]\n",
      " [ 43  26   9  24  18  42  48]\n",
      " [ 13   1   0  10   8  18 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.69      0.57       210\n",
      "           2       0.53      0.54      0.54       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.46      0.36      0.40       210\n",
      "           5       0.45      0.50      0.47       210\n",
      "           6       0.49      0.20      0.28       210\n",
      "           7       0.60      0.76      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.54      0.55      0.53      1470\n",
      "weighted avg       0.54      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   4   7   8  35   6   8]\n",
      " [ 23 114  19  14  24   7   9]\n",
      " [ 14  26 158   2   4   2   4]\n",
      " [ 23  23   7  76  50  12  19]\n",
      " [ 34  20   2  23 115   1  15]\n",
      " [ 47  23   9  26  18  38  49]\n",
      " [ 12   1   0   9  10  12 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.68      0.56       210\n",
      "           2       0.54      0.54      0.54       210\n",
      "           3       0.78      0.75      0.77       210\n",
      "           4       0.48      0.36      0.41       210\n",
      "           5       0.45      0.55      0.49       210\n",
      "           6       0.49      0.18      0.26       210\n",
      "           7       0.61      0.79      0.69       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.53      1470\n",
      "weighted avg       0.55      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   3   5  10  36   4  11]\n",
      " [ 22 112  20  11  27   8  10]\n",
      " [ 13  26 159   1   4   4   3]\n",
      " [ 24  19   7  78  48  10  24]\n",
      " [ 33  18   0  21 123   2  13]\n",
      " [ 50  14  10  29  13  43  51]\n",
      " [ 11   2   0   7   8  13 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.67      0.56       210\n",
      "           2       0.58      0.53      0.55       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.50      0.37      0.43       210\n",
      "           5       0.47      0.59      0.52       210\n",
      "           6       0.51      0.20      0.29       210\n",
      "           7       0.60      0.80      0.69       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.4605442176870748\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 65  16  34  13  40   7  35]\n",
      " [  2 122  18  11  29  10  18]\n",
      " [  4  67 128   4   3   3   1]\n",
      " [  2  29   9  54  56   8  52]\n",
      " [  6  22   2   6 131   3  40]\n",
      " [ 16  31  19  15  23  29  77]\n",
      " [  8   7   5  16   9  17 148]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.31      0.42       210\n",
      "           2       0.41      0.58      0.48       210\n",
      "           3       0.60      0.61      0.60       210\n",
      "           4       0.45      0.26      0.33       210\n",
      "           5       0.45      0.62      0.52       210\n",
      "           6       0.38      0.14      0.20       210\n",
      "           7       0.40      0.70      0.51       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.44      1470\n",
      "weighted avg       0.47      0.46      0.44      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 71  17  35  11  36   4  36]\n",
      " [  2 118  22  12  24  17  15]\n",
      " [  2  68 125   4   5   5   1]\n",
      " [  2  33   9  60  49   8  49]\n",
      " [  9  22   3  10 123   6  37]\n",
      " [ 14  32  19  21  20  33  71]\n",
      " [ 12   9   2  15  11  11 150]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.34      0.44       210\n",
      "           2       0.39      0.56      0.46       210\n",
      "           3       0.58      0.60      0.59       210\n",
      "           4       0.45      0.29      0.35       210\n",
      "           5       0.46      0.59      0.51       210\n",
      "           6       0.39      0.16      0.22       210\n",
      "           7       0.42      0.71      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.44      1470\n",
      "weighted avg       0.48      0.46      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of SVM is:\n",
      " [[133   6   3   6  42   9  11]\n",
      " [  5 140  10  12  15  21   7]\n",
      " [  2  19 170   4   1  12   2]\n",
      " [  4  17   7 101  25  29  27]\n",
      " [ 20  18   1   9 136  11  15]\n",
      " [ 13  14   3  16   7  96  61]\n",
      " [  1   2   0   0   5  20 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.63      0.69       210\n",
      "           2       0.65      0.67      0.66       210\n",
      "           3       0.88      0.81      0.84       210\n",
      "           4       0.68      0.48      0.56       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.60      0.87      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of SVM is:\n",
      " [[143   6   3   4  38   9   7]\n",
      " [  1 146   9  13  16  21   4]\n",
      " [  0  16 179   3   2   9   1]\n",
      " [  5  15   8 112  23  30  17]\n",
      " [ 22  14   3  16 135   9  11]\n",
      " [ 14  12   3  18   7 112  44]\n",
      " [  1   0   0   0   6  24 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.67      0.53      0.60       210\n",
      "           5       0.59      0.64      0.62       210\n",
      "           6       0.52      0.53      0.53       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of SVM is:\n",
      " [[137   7   2   4  42  10   8]\n",
      " [  3 143   7  13  15  24   5]\n",
      " [  1  16 178   3   1   9   2]\n",
      " [  5  17   7 110  23  29  19]\n",
      " [ 16  15   1  13 140  12  13]\n",
      " [ 15  12   2  16   7 106  52]\n",
      " [  1   1   0   0   6  20 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.65      0.71       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.90      0.85      0.87       210\n",
      "           4       0.69      0.52      0.60       210\n",
      "           5       0.60      0.67      0.63       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.65      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6272108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[127   6   2   8  43   9  15]\n",
      " [  6 131  13  14  14  24   8]\n",
      " [  2  22 160  11   2  11   2]\n",
      " [  5  21   6  93  28  28  29]\n",
      " [ 20  17   1   9 138   8  17]\n",
      " [ 14  13   5  14   9  86  69]\n",
      " [  0   2   0   1   4  16 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.60      0.66       210\n",
      "           2       0.62      0.62      0.62       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.62      0.44      0.52       210\n",
      "           5       0.58      0.66      0.62       210\n",
      "           6       0.47      0.41      0.44       210\n",
      "           7       0.57      0.89      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.62      1470\n",
      "weighted avg       0.64      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  15   0 195   0   0]\n",
      " [  0   0   8   0 202   0   0]\n",
      " [  0   0  92   0 118   0   0]\n",
      " [  0   0   1   0 209   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.77      0.44      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.13      0.21      0.12      1470\n",
      "weighted avg       0.13      0.21      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29591836734693877\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 14 166   1   0   0   0  29]\n",
      " [  6 175   2   0   0   0  27]\n",
      " [  1 114  91   0   0   0   4]\n",
      " [  1 147   0   0   0   0  62]\n",
      " [  0 156   0   0   0   0  54]\n",
      " [  3 132   1   0   0   0  74]\n",
      " [  0  55   0   0   0   0 155]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.07      0.12       210\n",
      "           2       0.19      0.83      0.30       210\n",
      "           3       0.96      0.43      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.74      0.50       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.30      0.30      0.22      1470\n",
      "weighted avg       0.30      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32653061224489793\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 13  64   0   0 103   1  29]\n",
      " [  1  84   2   0  91   5  27]\n",
      " [  0  61  91   0  53   1   4]\n",
      " [  0  40   0   0 107   1  62]\n",
      " [  0  22   0   0 134   0  54]\n",
      " [  0  48   0   0  85   3  74]\n",
      " [  0  18   0   0  37   0 155]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.06      0.12       210\n",
      "           2       0.25      0.40      0.31       210\n",
      "           3       0.98      0.43      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.64      0.33       210\n",
      "           6       0.27      0.01      0.03       210\n",
      "           7       0.38      0.74      0.50       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.43      0.33      0.27      1470\n",
      "weighted avg       0.43      0.33      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60  16   0  59  47   2  26]\n",
      " [ 13  74   2  64  46   4   7]\n",
      " [ 19  42  90  23  32   2   2]\n",
      " [ 13  28   0  67  66   6  30]\n",
      " [  7  15   0  60  96   3  29]\n",
      " [  9  40   0  74  29   5  53]\n",
      " [  6  12   0  45  10  10 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.29      0.36       210\n",
      "           2       0.33      0.35      0.34       210\n",
      "           3       0.98      0.43      0.60       210\n",
      "           4       0.17      0.32      0.22       210\n",
      "           5       0.29      0.46      0.36       210\n",
      "           6       0.16      0.02      0.04       210\n",
      "           7       0.46      0.60      0.52       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.41      0.35      0.35      1470\n",
      "weighted avg       0.41      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3816326530612245\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 48  15  15   5  47  54  26]\n",
      " [  3  67  23  25  46  39   7]\n",
      " [  4  19 131   2  32  20   2]\n",
      " [  1  26  16  37  66  34  30]\n",
      " [  4  18   3  22  96  38  29]\n",
      " [  3  39   8  23  29  55  53]\n",
      " [  0  13   6  21  10  33 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.23      0.35       210\n",
      "           2       0.34      0.32      0.33       210\n",
      "           3       0.65      0.62      0.64       210\n",
      "           4       0.27      0.18      0.21       210\n",
      "           5       0.29      0.46      0.36       210\n",
      "           6       0.20      0.26      0.23       210\n",
      "           7       0.46      0.60      0.52       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.43      0.38      0.38      1470\n",
      "weighted avg       0.43      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3952380952380952\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 51  15   6  33  28  67  10]\n",
      " [  4  70  16  53  15  48   4]\n",
      " [  5  17 128  25   9  25   1]\n",
      " [  2  27  11  93  15  42  20]\n",
      " [  8  12   2  67  60  49  12]\n",
      " [  6  19   5  46  12  80  42]\n",
      " [ 13  10   2  30  15  41  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.24      0.34       210\n",
      "           2       0.41      0.33      0.37       210\n",
      "           3       0.75      0.61      0.67       210\n",
      "           4       0.27      0.44      0.33       210\n",
      "           5       0.39      0.29      0.33       210\n",
      "           6       0.23      0.38      0.28       210\n",
      "           7       0.53      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.45      0.40      0.40      1470\n",
      "weighted avg       0.45      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40680272108843535\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   5   4  33  15  62  24]\n",
      " [  8  56  17  51  17  53   8]\n",
      " [  9  14 134  17   2  27   7]\n",
      " [  4  13   8  97  11  50  27]\n",
      " [ 15   5   2  66  54  49  19]\n",
      " [  7  11   8  47   7  86  44]\n",
      " [  6   4   0  33   4  59 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.32      0.41       210\n",
      "           2       0.52      0.27      0.35       210\n",
      "           3       0.77      0.64      0.70       210\n",
      "           4       0.28      0.46      0.35       210\n",
      "           5       0.49      0.26      0.34       210\n",
      "           6       0.22      0.41      0.29       210\n",
      "           7       0.45      0.50      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.47      0.41      0.42      1470\n",
      "weighted avg       0.47      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   7   2  25  11  37  16]\n",
      " [ 50  51  12  35  12  45   5]\n",
      " [ 24  13 134  16   1  18   4]\n",
      " [ 47  12   7  68  10  47  19]\n",
      " [ 61  10   2  45  42  35  15]\n",
      " [ 31   9   5  37   8  87  33]\n",
      " [ 18   6   0  23   3  66  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.53      0.41       210\n",
      "           2       0.47      0.24      0.32       210\n",
      "           3       0.83      0.64      0.72       210\n",
      "           4       0.27      0.32      0.30       210\n",
      "           5       0.48      0.20      0.28       210\n",
      "           6       0.26      0.41      0.32       210\n",
      "           7       0.51      0.45      0.47       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.45      0.40      0.40      1470\n",
      "weighted avg       0.45      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  11   1  17  29  33  19]\n",
      " [ 40  63  15  31  20  36   5]\n",
      " [ 15  17 136  16   6  14   6]\n",
      " [ 39  18   6  76  16  36  19]\n",
      " [ 50  19   1  46  52  26  16]\n",
      " [ 26  15   4  44  16  74  31]\n",
      " [ 15   7   0  29  16  55  88]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.48      0.40       210\n",
      "           2       0.42      0.30      0.35       210\n",
      "           3       0.83      0.65      0.73       210\n",
      "           4       0.29      0.36      0.32       210\n",
      "           5       0.34      0.25      0.28       210\n",
      "           6       0.27      0.35      0.31       210\n",
      "           7       0.48      0.42      0.45       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.43      0.40      0.41      1470\n",
      "weighted avg       0.43      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88   9   5  14  45  34  15]\n",
      " [ 26  72  16  20  33  32  11]\n",
      " [ 10  24 136   3  18  16   3]\n",
      " [ 23  17  10  46  55  34  25]\n",
      " [ 41  24   3  26  76  26  14]\n",
      " [ 23  15  11  30  29  69  33]\n",
      " [  9  10   0  19  25  46 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.42      0.41       210\n",
      "           2       0.42      0.34      0.38       210\n",
      "           3       0.75      0.65      0.70       210\n",
      "           4       0.29      0.22      0.25       210\n",
      "           5       0.27      0.36      0.31       210\n",
      "           6       0.27      0.33      0.30       210\n",
      "           7       0.50      0.48      0.49       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.408843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  12   6  13  41  35  10]\n",
      " [ 20  75  16  26  31  27  15]\n",
      " [  5  26 143   9  14  11   2]\n",
      " [ 27  25   9  51  48  27  23]\n",
      " [ 39  26   9  27  73  22  14]\n",
      " [ 25  26   9  23  27  67  33]\n",
      " [ 14   9   0  18  21  49  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.44      0.43       210\n",
      "           2       0.38      0.36      0.37       210\n",
      "           3       0.74      0.68      0.71       210\n",
      "           4       0.31      0.24      0.27       210\n",
      "           5       0.29      0.35      0.31       210\n",
      "           6       0.28      0.32      0.30       210\n",
      "           7       0.51      0.47      0.49       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41904761904761906\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  17  11  18  32  26  13]\n",
      " [ 27  76  17  27  27  29   7]\n",
      " [  8  20 149  12  11   8   2]\n",
      " [ 22  27   8  68  31  32  22]\n",
      " [ 40  22   8  43  69  15  13]\n",
      " [ 30  18  14  30  30  55  33]\n",
      " [ 15   9   1  27  12  40 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.44      0.42       210\n",
      "           2       0.40      0.36      0.38       210\n",
      "           3       0.72      0.71      0.71       210\n",
      "           4       0.30      0.32      0.31       210\n",
      "           5       0.33      0.33      0.33       210\n",
      "           6       0.27      0.26      0.27       210\n",
      "           7       0.54      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  17   9  18  36  21  17]\n",
      " [ 24  83  10  31  29  26   7]\n",
      " [  5  15 153  16  11   7   3]\n",
      " [ 16  32  11  69  35  28  19]\n",
      " [ 37  22   6  39  71  20  15]\n",
      " [ 35  19   9  36  31  52  28]\n",
      " [ 15  10   3  27  20  38  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.44      0.42       210\n",
      "           2       0.42      0.40      0.41       210\n",
      "           3       0.76      0.73      0.74       210\n",
      "           4       0.29      0.33      0.31       210\n",
      "           5       0.30      0.34      0.32       210\n",
      "           6       0.27      0.25      0.26       210\n",
      "           7       0.52      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.427891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  16  10  13  30  27  17]\n",
      " [ 32  80  20  20  25  22  11]\n",
      " [  7  17 154  11   9   7   5]\n",
      " [ 23  26  12  68  34  25  22]\n",
      " [ 39  24   8  38  68  20  13]\n",
      " [ 28  23   9  31  26  59  34]\n",
      " [ 12  14   1  24  18  38 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.46      0.43       210\n",
      "           2       0.40      0.38      0.39       210\n",
      "           3       0.72      0.73      0.73       210\n",
      "           4       0.33      0.32      0.33       210\n",
      "           5       0.32      0.32      0.32       210\n",
      "           6       0.30      0.28      0.29       210\n",
      "           7       0.50      0.49      0.50       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.43      1470\n",
      "weighted avg       0.43      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 89  23  11  12  36  25  14]\n",
      " [ 22  82  21  25  30  20  10]\n",
      " [  9  19 156  10   7   7   2]\n",
      " [ 25  29  14  61  24  37  20]\n",
      " [ 37  22  10  44  61  21  15]\n",
      " [ 34  26  12  31  22  52  33]\n",
      " [ 13  13   3  20  19  47  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.42      0.41       210\n",
      "           2       0.38      0.39      0.39       210\n",
      "           3       0.69      0.74      0.71       210\n",
      "           4       0.30      0.29      0.30       210\n",
      "           5       0.31      0.29      0.30       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.50      0.45      0.48       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.40      0.41      0.40      1470\n",
      "weighted avg       0.40      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41768707482993195\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  24  10  14  33  19  15]\n",
      " [ 26  86  17  26  27  15  13]\n",
      " [  8   9 163  11   9   9   1]\n",
      " [ 25  19  11  60  31  40  24]\n",
      " [ 38  19   9  40  68  21  15]\n",
      " [ 31  15  18  35  25  46  40]\n",
      " [ 16  15   5  22  21  35  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.45      0.42       210\n",
      "           2       0.46      0.41      0.43       210\n",
      "           3       0.70      0.78      0.74       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.32      0.32      0.32       210\n",
      "           6       0.25      0.22      0.23       210\n",
      "           7       0.47      0.46      0.46       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.41      0.42      0.41      1470\n",
      "weighted avg       0.41      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41496598639455784\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  20   7  13  31  25  17]\n",
      " [ 24  79  23  25  27  21  11]\n",
      " [  9  14 156   9  10   7   5]\n",
      " [ 22  19  10  67  37  32  23]\n",
      " [ 43  21   7  34  62  29  14]\n",
      " [ 28  24  15  29  23  52  39]\n",
      " [ 12  13   4  23  22  39  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.46      0.44       210\n",
      "           2       0.42      0.38      0.40       210\n",
      "           3       0.70      0.74      0.72       210\n",
      "           4       0.34      0.32      0.33       210\n",
      "           5       0.29      0.30      0.29       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.47      0.46      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  16  12  13  28  26  20]\n",
      " [ 30  79  20  21  25  24  11]\n",
      " [ 10  13 154  15   7   7   4]\n",
      " [ 25  25  11  65  31  34  19]\n",
      " [ 43  17  10  40  66  22  12]\n",
      " [ 29  15  20  37  23  50  36]\n",
      " [ 13   8   1  29  25  34 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.45      0.42       210\n",
      "           2       0.46      0.38      0.41       210\n",
      "           3       0.68      0.73      0.70       210\n",
      "           4       0.30      0.31      0.30       210\n",
      "           5       0.32      0.31      0.32       210\n",
      "           6       0.25      0.24      0.25       210\n",
      "           7       0.50      0.48      0.49       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  17  10  13  28  25  18]\n",
      " [ 27  81  19  19  25  26  13]\n",
      " [  3  17 159  11   7   7   6]\n",
      " [ 24  24  13  60  31  36  22]\n",
      " [ 40  22  11  36  60  29  12]\n",
      " [ 36  20  12  36  22  50  34]\n",
      " [ 20  12   3  25  14  38  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.47      0.43       210\n",
      "           2       0.42      0.39      0.40       210\n",
      "           3       0.70      0.76      0.73       210\n",
      "           4       0.30      0.29      0.29       210\n",
      "           5       0.32      0.29      0.30       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.48      0.47      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  17  12  15  29  26  16]\n",
      " [ 31  82  12  19  28  25  13]\n",
      " [  7  15 153  15  11   5   4]\n",
      " [ 21  21  11  69  33  34  21]\n",
      " [ 37  22  12  39  62  25  13]\n",
      " [ 32  24   9  33  25  48  39]\n",
      " [ 16  14   4  26  15  33 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.45      0.42       210\n",
      "           2       0.42      0.39      0.40       210\n",
      "           3       0.72      0.73      0.72       210\n",
      "           4       0.32      0.33      0.32       210\n",
      "           5       0.31      0.30      0.30       210\n",
      "           6       0.24      0.23      0.24       210\n",
      "           7       0.49      0.49      0.49       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.41      0.42      0.41      1470\n",
      "weighted avg       0.41      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  8   4  57   2  43   0  96]\n",
      " [  1  32  56   1  48   0  72]\n",
      " [  0  18 160   0  25   0   7]\n",
      " [  1   6  21   0  46   0 136]\n",
      " [  3   8   9   2  70   0 118]\n",
      " [  3   9  37   4  17   0 140]\n",
      " [  1   0   8   1   7   0 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.04      0.07       210\n",
      "           2       0.42      0.15      0.22       210\n",
      "           3       0.46      0.76      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.27      0.33      0.30       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.25      0.92      0.40       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.27      0.31      0.22      1470\n",
      "weighted avg       0.27      0.31      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.41836734693877553\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 59  45  15   0  39   0  52]\n",
      " [  5 109  27   1  38   0  30]\n",
      " [  1  55 149   1   1   0   3]\n",
      " [  9  36  13   7  63   0  82]\n",
      " [  4  27   6   0 117   0  56]\n",
      " [  8  41  20   2  32   1 106]\n",
      " [  2  15   3   0  14   3 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.28      0.40       210\n",
      "           2       0.33      0.52      0.41       210\n",
      "           3       0.64      0.71      0.67       210\n",
      "           4       0.64      0.03      0.06       210\n",
      "           5       0.38      0.56      0.46       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.34      0.82      0.49       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.47      0.42      0.36      1470\n",
      "weighted avg       0.47      0.42      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.445578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 72  33  14   3  47   0  41]\n",
      " [  3 122  19   1  39   0  26]\n",
      " [  2  56 146   1   1   0   4]\n",
      " [  3  42   7  18  77   0  63]\n",
      " [  1  31   3   3 131   0  41]\n",
      " [  9  42  15   4  41   4  95]\n",
      " [  1  13   2   6  24   2 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.34      0.48       210\n",
      "           2       0.36      0.58      0.44       210\n",
      "           3       0.71      0.70      0.70       210\n",
      "           4       0.50      0.09      0.15       210\n",
      "           5       0.36      0.62      0.46       210\n",
      "           6       0.67      0.02      0.04       210\n",
      "           7       0.38      0.77      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.54      0.45      0.40      1470\n",
      "weighted avg       0.54      0.45      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79  32   7   9  46   1  36]\n",
      " [  5 134  11   2  37   1  20]\n",
      " [  4  56 144   3   2   0   1]\n",
      " [  1  44   4  37  68   2  54]\n",
      " [  2  29   0   2 139   0  38]\n",
      " [ 10  52   6   8  33   8  93]\n",
      " [  4  18   2   3  19   1 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.38      0.50       210\n",
      "           2       0.37      0.64      0.47       210\n",
      "           3       0.83      0.69      0.75       210\n",
      "           4       0.58      0.18      0.27       210\n",
      "           5       0.40      0.66      0.50       210\n",
      "           6       0.62      0.04      0.07       210\n",
      "           7       0.40      0.78      0.53       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.44      1470\n",
      "weighted avg       0.56      0.48      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97  16   8   7  43   4  35]\n",
      " [  6 133   8   9  29   9  16]\n",
      " [  3  61 141   2   1   1   1]\n",
      " [  4  43   4  46  56   3  54]\n",
      " [  5  27   0   5 136   0  37]\n",
      " [ 10  52   6  17  27  15  83]\n",
      " [  4  12   0  11  12   6 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.46      0.57       210\n",
      "           2       0.39      0.63      0.48       210\n",
      "           3       0.84      0.67      0.75       210\n",
      "           4       0.47      0.22      0.30       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.39      0.07      0.12       210\n",
      "           7       0.42      0.79      0.55       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.47      1470\n",
      "weighted avg       0.53      0.50      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5231292517006803\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96  19   6  12  44   4  29]\n",
      " [  8 127   9  19  29   4  14]\n",
      " [  2  52 146   0   5   4   1]\n",
      " [  2  31   5  61  55   8  48]\n",
      " [  4  24   0   6 142   1  33]\n",
      " [ 12  41   5  17  22  25  88]\n",
      " [  3   6   1   6  12  10 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.46      0.57       210\n",
      "           2       0.42      0.60      0.50       210\n",
      "           3       0.85      0.70      0.76       210\n",
      "           4       0.50      0.29      0.37       210\n",
      "           5       0.46      0.68      0.55       210\n",
      "           6       0.45      0.12      0.19       210\n",
      "           7       0.45      0.82      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.50      1470\n",
      "weighted avg       0.55      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105  16   6  10  38   5  30]\n",
      " [  3 132   9  17  26   8  15]\n",
      " [  3  44 149   4   4   5   1]\n",
      " [  7  30   4  66  52  13  38]\n",
      " [  6  24   0  11 133   6  30]\n",
      " [ 14  34   3  18  26  34  81]\n",
      " [  4   5   0   5   8  17 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.50      0.60       210\n",
      "           2       0.46      0.63      0.53       210\n",
      "           3       0.87      0.71      0.78       210\n",
      "           4       0.50      0.31      0.39       210\n",
      "           5       0.46      0.63      0.54       210\n",
      "           6       0.39      0.16      0.23       210\n",
      "           7       0.47      0.81      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.52      1470\n",
      "weighted avg       0.56      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107  14   3   8  42  13  23]\n",
      " [  5 129  10  12  29  16   9]\n",
      " [  2  47 149   6   1   4   1]\n",
      " [  3  29   6  65  53  17  37]\n",
      " [ 11  23   0  10 133   6  27]\n",
      " [  6  33   3  22  18  54  74]\n",
      " [  1   5   2   5   9  14 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.51      0.62       210\n",
      "           2       0.46      0.61      0.53       210\n",
      "           3       0.86      0.71      0.78       210\n",
      "           4       0.51      0.31      0.38       210\n",
      "           5       0.47      0.63      0.54       210\n",
      "           6       0.44      0.26      0.32       210\n",
      "           7       0.50      0.83      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.58      0.55      0.54      1470\n",
      "weighted avg       0.58      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108  14   5   8  44  12  19]\n",
      " [  4 132  10  20  20  16   8]\n",
      " [  4  34 155   6   3   6   2]\n",
      " [  3  25   6  74  52  16  34]\n",
      " [  7  21   0  11 145   6  20]\n",
      " [ 17  24   7  21  16  53  72]\n",
      " [  0   4   2   8   9  18 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.51      0.61       210\n",
      "           2       0.52      0.63      0.57       210\n",
      "           3       0.84      0.74      0.78       210\n",
      "           4       0.50      0.35      0.41       210\n",
      "           5       0.50      0.69      0.58       210\n",
      "           6       0.42      0.25      0.31       210\n",
      "           7       0.52      0.80      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112  10   4  11  43  12  18]\n",
      " [  5 132  11  11  24  19   8]\n",
      " [  2  39 156   4   2   6   1]\n",
      " [  2  21   7  79  47  22  32]\n",
      " [ 10  20   1   7 142   8  22]\n",
      " [ 12  31   5  24  11  52  75]\n",
      " [  2   6   1   5   6  18 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.53      0.63       210\n",
      "           2       0.51      0.63      0.56       210\n",
      "           3       0.84      0.74      0.79       210\n",
      "           4       0.56      0.38      0.45       210\n",
      "           5       0.52      0.68      0.59       210\n",
      "           6       0.38      0.25      0.30       210\n",
      "           7       0.52      0.82      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111  11   6   9  41  12  20]\n",
      " [  5 132  10  18  21  16   8]\n",
      " [  5  34 155   6   2   7   1]\n",
      " [ 11  28   5  75  41  19  31]\n",
      " [ 12  23   1  13 133   7  21]\n",
      " [  8  24   9  19  19  60  71]\n",
      " [  3   5   1   6   7  16 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.53      0.61       210\n",
      "           2       0.51      0.63      0.57       210\n",
      "           3       0.83      0.74      0.78       210\n",
      "           4       0.51      0.36      0.42       210\n",
      "           5       0.50      0.63      0.56       210\n",
      "           6       0.44      0.29      0.35       210\n",
      "           7       0.53      0.82      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5816326530612245\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114  12   6  11  37   6  24]\n",
      " [  7 126   8  17  21  17  14]\n",
      " [  3  35 157   5   2   6   2]\n",
      " [  5  21   8  84  45  24  23]\n",
      " [  9  19   3  13 137  11  18]\n",
      " [ 10  23   6  25  15  63  68]\n",
      " [  3   2   1   6   5  19 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.54      0.63       210\n",
      "           2       0.53      0.60      0.56       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.52      0.40      0.45       210\n",
      "           5       0.52      0.65      0.58       210\n",
      "           6       0.43      0.30      0.35       210\n",
      "           7       0.54      0.83      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.57      1470\n",
      "weighted avg       0.59      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111  13   7  11  37  11  20]\n",
      " [  5 126  10  21  24  18   6]\n",
      " [  1  36 157   5   1   8   2]\n",
      " [  5  18   6  85  46  29  21]\n",
      " [ 14  16   2  19 130  10  19]\n",
      " [ 12  19   7  28  15  64  65]\n",
      " [  0   4   0   6   7  22 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.53      0.62       210\n",
      "           2       0.54      0.60      0.57       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.49      0.40      0.44       210\n",
      "           5       0.50      0.62      0.55       210\n",
      "           6       0.40      0.30      0.34       210\n",
      "           7       0.56      0.81      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  14   8  11  35  14  19]\n",
      " [  8 130   5  19  19  21   8]\n",
      " [  2  29 158   8   4   7   2]\n",
      " [  2  22   5  77  54  19  31]\n",
      " [ 10  19   2  17 131  11  20]\n",
      " [ 13  25   5  12  18  73  64]\n",
      " [  2   3   0   7   9  21 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.52      0.61       210\n",
      "           2       0.54      0.62      0.58       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.51      0.37      0.43       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.54      0.80      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.57      1470\n",
      "weighted avg       0.59      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114  10   6  10  43  12  15]\n",
      " [  6 122  13  16  21  28   4]\n",
      " [  2  38 154   5   1   8   2]\n",
      " [ 11  22   8  76  46  18  29]\n",
      " [ 12  16   4  18 129   7  24]\n",
      " [ 11  21   5  21  19  72  61]\n",
      " [  1   4   1   4   5  25 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.54      0.62       210\n",
      "           2       0.52      0.58      0.55       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.51      0.36      0.42       210\n",
      "           5       0.49      0.61      0.54       210\n",
      "           6       0.42      0.34      0.38       210\n",
      "           7       0.56      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5789115646258504\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112   8   7  11  40  19  13]\n",
      " [  7 124  10  20  18  25   6]\n",
      " [  5  30 161   5   2   7   0]\n",
      " [  7  21   6  82  42  23  29]\n",
      " [ 18  17   2  16 129   7  21]\n",
      " [ 10  28   6  15  15  73  63]\n",
      " [  2   6   1   3   6  22 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.53      0.60       210\n",
      "           2       0.53      0.59      0.56       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.54      0.39      0.45       210\n",
      "           5       0.51      0.61      0.56       210\n",
      "           6       0.41      0.35      0.38       210\n",
      "           7       0.56      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108  11   6  15  41  10  19]\n",
      " [  7 126   6  14  28  21   8]\n",
      " [  2  29 162   7   1   8   1]\n",
      " [ 10  20   6  79  45  22  28]\n",
      " [ 15  18   2  15 135   8  17]\n",
      " [ 15  24   5  22  14  67  63]\n",
      " [  2   1   1   5   7  23 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.51      0.59       210\n",
      "           2       0.55      0.60      0.57       210\n",
      "           3       0.86      0.77      0.81       210\n",
      "           4       0.50      0.38      0.43       210\n",
      "           5       0.50      0.64      0.56       210\n",
      "           6       0.42      0.32      0.36       210\n",
      "           7       0.56      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   6   7  12  37  12  15]\n",
      " [  5 119   9  31  19  19   8]\n",
      " [  5  42 156   3   0   3   1]\n",
      " [  5  25   7  72  51  23  27]\n",
      " [ 20  16   1  15 130   7  21]\n",
      " [ 17  23   6  22  17  74  51]\n",
      " [  1   2   0   1   9  25 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.58      0.63       210\n",
      "           2       0.51      0.57      0.54       210\n",
      "           3       0.84      0.74      0.79       210\n",
      "           4       0.46      0.34      0.39       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.45      0.35      0.40       210\n",
      "           7       0.58      0.82      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   5   6  19  39  15  16]\n",
      " [ 10 121   8  19  23  21   8]\n",
      " [  6  33 162   3   2   3   1]\n",
      " [  8  20   8  81  45  23  25]\n",
      " [ 18  19   2  15 125  12  19]\n",
      " [ 15  23   6  23  11  73  59]\n",
      " [  2   2   1   1  10  26 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.52      0.58       210\n",
      "           2       0.54      0.58      0.56       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.50      0.39      0.44       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.57      0.80      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   8   8  10  39  17  13]\n",
      " [  8 126   6  20  19  22   9]\n",
      " [  4  38 156   3   3   4   2]\n",
      " [  2  20   7  91  43  20  27]\n",
      " [ 16  16   0  15 131  13  19]\n",
      " [ 13  20   7  18  18  74  60]\n",
      " [  2   1   0   7   6  26 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.55      0.62       210\n",
      "           2       0.55      0.60      0.57       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.55      0.43      0.49       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.56      0.80      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 76  13  35   9  36   8  33]\n",
      " [  5 116  23  14  25  13  14]\n",
      " [  4  63 128   3   6   5   1]\n",
      " [  3  30  10  65  45   9  48]\n",
      " [  8  23   2   6 128   3  40]\n",
      " [ 17  26  20  21  22  27  77]\n",
      " [ 11   7   3  19  10  11 149]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.36      0.46       210\n",
      "           2       0.42      0.55      0.48       210\n",
      "           3       0.58      0.61      0.59       210\n",
      "           4       0.47      0.31      0.37       210\n",
      "           5       0.47      0.61      0.53       210\n",
      "           6       0.36      0.13      0.19       210\n",
      "           7       0.41      0.71      0.52       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.45      1470\n",
      "weighted avg       0.47      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//bert_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[111   5   9  17  41  22   5]\n",
      " [  7 142  10  14  22  11   4]\n",
      " [  4  15 174   8   2   7   0]\n",
      " [ 14  15   4 112  48  11   6]\n",
      " [ 19  10   1  18 150   4   8]\n",
      " [ 14  24  13  25   9  74  51]\n",
      " [  4   1   1   3   3  17 181]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.53      0.58       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.82      0.83      0.82       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.55      0.71      0.62       210\n",
      "           6       0.51      0.35      0.42       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132  13  11   9  30  10   5]\n",
      " [ 19 140   8   9  20   7   7]\n",
      " [ 12  17 172   4   2   3   0]\n",
      " [ 38  23   7  82  50   7   3]\n",
      " [ 64  17   6  32  79   6   6]\n",
      " [ 57  23   8  13  12  52  45]\n",
      " [ 10   3   0   5   6  18 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.63      0.49       210\n",
      "           2       0.59      0.67      0.63       210\n",
      "           3       0.81      0.82      0.82       210\n",
      "           4       0.53      0.39      0.45       210\n",
      "           5       0.40      0.38      0.39       210\n",
      "           6       0.50      0.25      0.33       210\n",
      "           7       0.72      0.80      0.76       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  13  12  13  33  12   7]\n",
      " [ 15 143   7  10  19   7   9]\n",
      " [ 10  16 173   5   5   1   0]\n",
      " [ 29  21   3  93  52   7   5]\n",
      " [ 47  22   4  36  89   5   7]\n",
      " [ 45  21  11  16  13  58  46]\n",
      " [  6   3   0   3   2  30 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.57      0.50       210\n",
      "           2       0.60      0.68      0.64       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.53      0.44      0.48       210\n",
      "           5       0.42      0.42      0.42       210\n",
      "           6       0.48      0.28      0.35       210\n",
      "           7       0.69      0.79      0.74       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5816326530612245\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  14  12  12  36   8   8]\n",
      " [ 15 143  10  10  19   4   9]\n",
      " [ 11  16 172   5   5   1   0]\n",
      " [ 27  21   2  97  51   7   5]\n",
      " [ 45  19   2  34  96   5   9]\n",
      " [ 38  24  12  17  12  55  52]\n",
      " [  6   1   0   2   5  24 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.57      0.51       210\n",
      "           2       0.60      0.68      0.64       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.43      0.46      0.44       210\n",
      "           6       0.53      0.26      0.35       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5850340136054422\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  14  11   9  37   7   7]\n",
      " [ 16 146   8  10  15   6   9]\n",
      " [ 10  20 168   7   4   1   0]\n",
      " [ 25  20   3  97  54   6   5]\n",
      " [ 43  18   1  28 107   5   8]\n",
      " [ 42  26   9  22  13  48  50]\n",
      " [  7   2   0   2   5  25 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.60      0.52       210\n",
      "           2       0.59      0.70      0.64       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.46      0.51      0.48       210\n",
      "           6       0.49      0.23      0.31       210\n",
      "           7       0.68      0.80      0.74       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.58      0.59      0.57      1470\n",
      "weighted avg       0.58      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  16  10  12  37   6  10]\n",
      " [ 12 147   9  10  18   6   8]\n",
      " [  7  20 168   9   5   1   0]\n",
      " [ 22  19   3  98  57   6   5]\n",
      " [ 41  19   1  26 111   4   8]\n",
      " [ 37  29   9  21  10  40  64]\n",
      " [  4   3   0   3   5  17 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.57      0.53       210\n",
      "           2       0.58      0.70      0.63       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.55      0.47      0.50       210\n",
      "           5       0.46      0.53      0.49       210\n",
      "           6       0.50      0.19      0.28       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.58      0.59      0.57      1470\n",
      "weighted avg       0.58      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  16  10  11  37   7   8]\n",
      " [  9 146  10  10  21   7   7]\n",
      " [  9  21 165  12   3   0   0]\n",
      " [ 22  21   5  95  54   6   7]\n",
      " [ 33  16   3  29 118   3   8]\n",
      " [ 41  28   8  22  15  38  58]\n",
      " [  5   1   0   3   6  19 176]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.58      0.54       210\n",
      "           2       0.59      0.70      0.64       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.52      0.45      0.48       210\n",
      "           5       0.46      0.56      0.51       210\n",
      "           6       0.47      0.18      0.26       210\n",
      "           7       0.67      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 68  13   2   7  76  33  11]\n",
      " [  6  91   2   4  58  40   9]\n",
      " [ 17   9  57  17  72  38   0]\n",
      " [  9  10   1  29 123  30   8]\n",
      " [  5  14   0   3 160  19   9]\n",
      " [ 11  22   3  11  25  68  70]\n",
      " [  4   5   0   2   3  21 175]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.32      0.41       210\n",
      "           2       0.55      0.43      0.49       210\n",
      "           3       0.88      0.27      0.41       210\n",
      "           4       0.40      0.14      0.20       210\n",
      "           5       0.31      0.76      0.44       210\n",
      "           6       0.27      0.32      0.30       210\n",
      "           7       0.62      0.83      0.71       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.51      0.44      0.42      1470\n",
      "weighted avg       0.51      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.4448979591836735\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 68  13   2  11  68  36  12]\n",
      " [  5  93   2   6  54  39  11]\n",
      " [ 16   8  64  15  74  33   0]\n",
      " [  9  11   1  36 116  27  10]\n",
      " [  6  20   0   5 155  16   8]\n",
      " [ 12  21   3  15  21  72  66]\n",
      " [  2   8   0   1   2  31 166]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.32      0.41       210\n",
      "           2       0.53      0.44      0.48       210\n",
      "           3       0.89      0.30      0.45       210\n",
      "           4       0.40      0.17      0.24       210\n",
      "           5       0.32      0.74      0.44       210\n",
      "           6       0.28      0.34      0.31       210\n",
      "           7       0.61      0.79      0.69       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.52      0.44      0.43      1470\n",
      "weighted avg       0.52      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of SVM is:\n",
      " [[110   6  10  11  47  23   3]\n",
      " [  7 145   9  14  18  14   3]\n",
      " [  2  11 177  11   3   6   0]\n",
      " [  9  13   5 106  60  11   6]\n",
      " [ 19  11   1  16 149   6   8]\n",
      " [ 17  22  12  21  13  77  48]\n",
      " [  2   2   1   2   4  19 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.52      0.59       210\n",
      "           2       0.69      0.69      0.69       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.51      0.71      0.59       210\n",
      "           6       0.49      0.37      0.42       210\n",
      "           7       0.73      0.86      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of SVM is:\n",
      " [[108   6  12   7  50  24   3]\n",
      " [  4 149   7  15  15  17   3]\n",
      " [  3   6 181   9   3   8   0]\n",
      " [  8  10   4 123  47  14   4]\n",
      " [ 21  13   1  15 144   8   8]\n",
      " [ 15  12  10  19   9 104  41]\n",
      " [  3   0   0   3   3  21 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.51      0.58       210\n",
      "           2       0.76      0.71      0.73       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.53      0.69      0.60       210\n",
      "           6       0.53      0.50      0.51       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of SVM is:\n",
      " [[113   6   9  10  48  20   4]\n",
      " [  5 148   8  14  16  16   3]\n",
      " [  3   7 181   8   3   8   0]\n",
      " [  9  13   4 115  52  12   5]\n",
      " [ 21  13   1  13 147   7   8]\n",
      " [ 15  17  13  20  10  89  46]\n",
      " [  2   1   0   3   3  20 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.54      0.60       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.53      0.70      0.60       210\n",
      "           6       0.52      0.42      0.47       210\n",
      "           7       0.73      0.86      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 87  10  15  25  47  21   5]\n",
      " [  6 125  10  20  32  14   3]\n",
      " [  4   9 173  15   3   6   0]\n",
      " [  8   8   5 100  68  15   6]\n",
      " [ 10  10   1  24 150   8   7]\n",
      " [ 15  23  15  28  12  63  54]\n",
      " [  3   2   1   2   4  16 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.41      0.51       210\n",
      "           2       0.67      0.60      0.63       210\n",
      "           3       0.79      0.82      0.80       210\n",
      "           4       0.47      0.48      0.47       210\n",
      "           5       0.47      0.71      0.57       210\n",
      "           6       0.44      0.30      0.36       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   8   0 202   0   0]\n",
      " [  0   0  13   0 197   0   0]\n",
      " [  0   0 115   0  95   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0  12   0 198   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.76      0.55      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3258503401360544\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   4   4   0 174   0  28]\n",
      " [  0   9   4   0 178   0  19]\n",
      " [  0   7 108   0  93   0   2]\n",
      " [  0   0   4   0 182   0  24]\n",
      " [  0   0   0   0 189   0  21]\n",
      " [  0   6   6   0 111   0  87]\n",
      " [  0   0   0   0  37   0 173]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.35      0.04      0.08       210\n",
      "           3       0.86      0.51      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.20      0.90      0.32       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.49      0.82      0.61       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.27      0.33      0.24      1470\n",
      "weighted avg       0.27      0.33      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38503401360544215\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  4  32   4   0 142  20   8]\n",
      " [  1 114   4   0  72  12   7]\n",
      " [  4  45 108   0  51   0   2]\n",
      " [  0  18   4   0 164  18   6]\n",
      " [  0  27   0   0 162  15   6]\n",
      " [  4  44   6   0  69  38  49]\n",
      " [  0  20   0   0  17  33 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.02      0.04       210\n",
      "           2       0.38      0.54      0.45       210\n",
      "           3       0.86      0.51      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.24      0.77      0.37       210\n",
      "           6       0.28      0.18      0.22       210\n",
      "           7       0.64      0.67      0.65       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.34      1470\n",
      "weighted avg       0.39      0.39      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66  16   3  10  78  29   8]\n",
      " [  9  92   4   2  63  33   7]\n",
      " [ 10  30 110   4  41  13   2]\n",
      " [ 14  11   2   8 150  19   6]\n",
      " [  9  19   0   7 153  16   6]\n",
      " [ 25  20   7   8  44  57  49]\n",
      " [ 13   6   0   5   4  42 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.31      0.37       210\n",
      "           2       0.47      0.44      0.46       210\n",
      "           3       0.87      0.52      0.65       210\n",
      "           4       0.18      0.04      0.06       210\n",
      "           5       0.29      0.73      0.41       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.64      0.67      0.65       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.41      1470\n",
      "weighted avg       0.45      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  31   1  16  71  23   7]\n",
      " [  3 114   3  24  40  17   9]\n",
      " [  4  42 109  21  23  10   1]\n",
      " [  6  18   2  53 105  16  10]\n",
      " [  4  27   0  21 138   8  12]\n",
      " [ 11  41   4  22  27  44  61]\n",
      " [  2  20   0   6   2  21 159]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.29      0.41       210\n",
      "           2       0.39      0.54      0.45       210\n",
      "           3       0.92      0.52      0.66       210\n",
      "           4       0.33      0.25      0.28       210\n",
      "           5       0.34      0.66      0.45       210\n",
      "           6       0.32      0.21      0.25       210\n",
      "           7       0.61      0.76      0.68       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.51      0.46      0.45      1470\n",
      "weighted avg       0.51      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 62  28  12  23  64  17   4]\n",
      " [ 17 103   7  36  32  10   5]\n",
      " [ 16  28 124  25   9   8   0]\n",
      " [  4  19  11  79  79  12   6]\n",
      " [  7  26   1  33 125   8  10]\n",
      " [ 20  37   8  24  27  47  47]\n",
      " [  4  20   0   3   5  34 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.30      0.36       210\n",
      "           2       0.39      0.49      0.44       210\n",
      "           3       0.76      0.59      0.66       210\n",
      "           4       0.35      0.38      0.36       210\n",
      "           5       0.37      0.60      0.45       210\n",
      "           6       0.35      0.22      0.27       210\n",
      "           7       0.67      0.69      0.68       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.46      1470\n",
      "weighted avg       0.48      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  34   2  14  63  23   4]\n",
      " [ 20 113  11  15  21  23   7]\n",
      " [ 14  17 139  10  17  10   3]\n",
      " [  9  25   4  53  83  28   8]\n",
      " [  7  48   2  23 106  15   9]\n",
      " [ 22  37   8  13  23  62  45]\n",
      " [  5  19   1   0   3  47 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.33      0.39       210\n",
      "           2       0.39      0.54      0.45       210\n",
      "           3       0.83      0.66      0.74       210\n",
      "           4       0.41      0.25      0.31       210\n",
      "           5       0.34      0.50      0.40       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.64      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  15   4  13  57  38   5]\n",
      " [ 18 108   8  12  28  30   6]\n",
      " [ 10  17 146  12  12  11   2]\n",
      " [ 18  18   3  52  86  26   7]\n",
      " [ 13  22   1  22 126  20   6]\n",
      " [ 31  28   6  19  19  67  40]\n",
      " [  5  13   1   3   5  57 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.37      0.41       210\n",
      "           2       0.49      0.51      0.50       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.39      0.25      0.30       210\n",
      "           5       0.38      0.60      0.46       210\n",
      "           6       0.27      0.32      0.29       210\n",
      "           7       0.66      0.60      0.63       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.48      1470\n",
      "weighted avg       0.50      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  19  10  29  48  29   4]\n",
      " [ 12 115   8  19  19  27  10]\n",
      " [  5  10 149  16  10  18   2]\n",
      " [ 14  16  11  71  66  24   8]\n",
      " [ 12  23   4  47 100  17   7]\n",
      " [ 28  25   9  28  15  65  40]\n",
      " [  8  15   0   5   4  50 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.34      0.39       210\n",
      "           2       0.52      0.55      0.53       210\n",
      "           3       0.78      0.71      0.74       210\n",
      "           4       0.33      0.34      0.33       210\n",
      "           5       0.38      0.48      0.42       210\n",
      "           6       0.28      0.31      0.30       210\n",
      "           7       0.64      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.48      1470\n",
      "weighted avg       0.49      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  19   9  30  45  23   4]\n",
      " [ 17 104  10  27  18  24  10]\n",
      " [  5  15 151  15   6  16   2]\n",
      " [ 14  18   6  92  53  18   9]\n",
      " [ 13  26   6  51  93  13   8]\n",
      " [ 22  22  13  32  11  64  46]\n",
      " [  8  12   3   8   4  41 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.38      0.43       210\n",
      "           2       0.48      0.50      0.49       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.36      0.44      0.40       210\n",
      "           5       0.40      0.44      0.42       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.63      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  20   6  22  42  22   4]\n",
      " [ 16 113  11  18  20  23   9]\n",
      " [  6  13 151  18   8  12   2]\n",
      " [ 22  18   7  65  68  21   9]\n",
      " [ 19  26   5  23 111  17   9]\n",
      " [ 32  30   8  24  15  59  42]\n",
      " [  7  14   1   4   9  54 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.45      0.46       210\n",
      "           2       0.48      0.54      0.51       210\n",
      "           3       0.80      0.72      0.76       210\n",
      "           4       0.37      0.31      0.34       210\n",
      "           5       0.41      0.53      0.46       210\n",
      "           6       0.28      0.28      0.28       210\n",
      "           7       0.62      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  18  11  19  45  19   6]\n",
      " [ 18 105  12  24  21  21   9]\n",
      " [  7  15 151  15   8  10   4]\n",
      " [ 21  17  12  77  57  16  10]\n",
      " [ 24  24   6  29 104  14   9]\n",
      " [ 29  27  10  27  13  59  45]\n",
      " [  9  12   0   6   6  53 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.44      0.45       210\n",
      "           2       0.48      0.50      0.49       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.31      0.28      0.29       210\n",
      "           7       0.60      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.48      1470\n",
      "weighted avg       0.49      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  12  10  26  43  21   5]\n",
      " [ 21 109  10  18  22  23   7]\n",
      " [ 10  11 150  15   6  13   5]\n",
      " [ 24  18   8  74  57  19  10]\n",
      " [ 37  21   4  33  91  18   6]\n",
      " [ 34  22  10  27  12  62  43]\n",
      " [ 10  15   4   5   7  44 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.44      0.42       210\n",
      "           2       0.52      0.52      0.52       210\n",
      "           3       0.77      0.71      0.74       210\n",
      "           4       0.37      0.35      0.36       210\n",
      "           5       0.38      0.43      0.41       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  18  13  18  42  19   6]\n",
      " [ 20 104   9  23  23  21  10]\n",
      " [  6   8 158  14   7  13   4]\n",
      " [ 21  24   9  72  54  20  10]\n",
      " [ 33  22   3  28  99  17   8]\n",
      " [ 28  26  11  25  14  58  48]\n",
      " [ 13   8   0   7   7  48 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.45      0.44       210\n",
      "           2       0.50      0.50      0.50       210\n",
      "           3       0.78      0.75      0.77       210\n",
      "           4       0.39      0.34      0.36       210\n",
      "           5       0.40      0.47      0.43       210\n",
      "           6       0.30      0.28      0.29       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47619047619047616\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  17  11  17  41  22   8]\n",
      " [ 20 106  10  16  20  27  11]\n",
      " [ 11  12 156   9  10   8   4]\n",
      " [ 22  20   9  69  56  25   9]\n",
      " [ 33  23   4  34  90  19   7]\n",
      " [ 26  26  13  24  14  62  45]\n",
      " [ 11  13   3   7   6  47 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.45      0.44       210\n",
      "           2       0.49      0.50      0.50       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.39      0.33      0.36       210\n",
      "           5       0.38      0.43      0.40       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.59      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48027210884353744\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  15  11  16  46  22   6]\n",
      " [ 22 109  13  17  19  20  10]\n",
      " [  7  10 158  15   8   9   3]\n",
      " [ 31  19   7  75  49  18  11]\n",
      " [ 42  27   6  34  77  16   8]\n",
      " [ 31  24  10  26  12  67  40]\n",
      " [ 13   9   2   5   4  51 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.45      0.42       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.76      0.75      0.76       210\n",
      "           4       0.40      0.36      0.38       210\n",
      "           5       0.36      0.37      0.36       210\n",
      "           6       0.33      0.32      0.32       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  15  10  23  40  22   8]\n",
      " [ 19 107   9  16  23  27   9]\n",
      " [ 10  14 153  11   7  11   4]\n",
      " [ 29  24  11  69  48  19  10]\n",
      " [ 35  27   8  35  81  15   9]\n",
      " [ 30  22  14  27  12  60  45]\n",
      " [ 10  10   1   8   6  51 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.44      0.42       210\n",
      "           2       0.49      0.51      0.50       210\n",
      "           3       0.74      0.73      0.74       210\n",
      "           4       0.37      0.33      0.35       210\n",
      "           5       0.37      0.39      0.38       210\n",
      "           6       0.29      0.29      0.29       210\n",
      "           7       0.59      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4775510204081633\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  16  14  19  43  19   7]\n",
      " [ 23 109   9  16  22  19  12]\n",
      " [  9  11 156  10   6  14   4]\n",
      " [ 27  23   5  73  46  25  11]\n",
      " [ 33  23   6  34  82  24   8]\n",
      " [ 28  25  13  24  10  66  44]\n",
      " [  9  13   2   9   9  44 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.44      0.43       210\n",
      "           2       0.50      0.52      0.51       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.39      0.35      0.37       210\n",
      "           5       0.38      0.39      0.38       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.59      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46598639455782315\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  17  13  19  38  22   7]\n",
      " [ 19 103  14  16  26  21  11]\n",
      " [  8   9 157  11   9  11   5]\n",
      " [ 31  27  11  65  47  20   9]\n",
      " [ 42  21   9  29  76  26   7]\n",
      " [ 25  24  13  31  11  62  44]\n",
      " [ 11  11   1   4   3  52 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.45      0.43       210\n",
      "           2       0.49      0.49      0.49       210\n",
      "           3       0.72      0.75      0.73       210\n",
      "           4       0.37      0.31      0.34       210\n",
      "           5       0.36      0.36      0.36       210\n",
      "           6       0.29      0.30      0.29       210\n",
      "           7       0.61      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46802721088435373\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  16   9  15  38  22   9]\n",
      " [ 26 103  11  15  18  29   8]\n",
      " [ 12  10 155   9  10  10   4]\n",
      " [ 33  20  15  66  38  24  14]\n",
      " [ 42  21   7  33  79  21   7]\n",
      " [ 28  24  14  22  12  63  47]\n",
      " [ 13  11   3   6   8  48 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.48      0.43       210\n",
      "           2       0.50      0.49      0.50       210\n",
      "           3       0.72      0.74      0.73       210\n",
      "           4       0.40      0.31      0.35       210\n",
      "           5       0.39      0.38      0.38       210\n",
      "           6       0.29      0.30      0.30       210\n",
      "           7       0.58      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  6   7  29   0 102  12  54]\n",
      " [  0  15  24   2  84   4  81]\n",
      " [  0   5 132   0  41   0  32]\n",
      " [  0   4   7   2 154   1  42]\n",
      " [  2   3   2   0 170   0  33]\n",
      " [  0   5  15   0  39   2 149]\n",
      " [  0   2   0   0   5   0 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.03      0.06       210\n",
      "           2       0.37      0.07      0.12       210\n",
      "           3       0.63      0.63      0.63       210\n",
      "           4       0.50      0.01      0.02       210\n",
      "           5       0.29      0.81      0.42       210\n",
      "           6       0.11      0.01      0.02       210\n",
      "           7       0.34      0.97      0.50       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.43      0.36      0.25      1470\n",
      "weighted avg       0.43      0.36      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 12  25  39   0  95  11  28]\n",
      " [  0  65  18   0  81  17  29]\n",
      " [  0   4 146   1  39  12   8]\n",
      " [  2  14   8   4 150   8  24]\n",
      " [  2   9   0   0 170   3  26]\n",
      " [  2  17  22   0  34  22 113]\n",
      " [  1   6   0   0   4   1 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.06      0.10       210\n",
      "           2       0.46      0.31      0.37       210\n",
      "           3       0.63      0.70      0.66       210\n",
      "           4       0.80      0.02      0.04       210\n",
      "           5       0.30      0.81      0.43       210\n",
      "           6       0.30      0.10      0.15       210\n",
      "           7       0.46      0.94      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.51      0.42      0.34      1470\n",
      "weighted avg       0.51      0.42      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.48299319727891155\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 42  35  17   3  82  14  17]\n",
      " [  1 124   9   2  49  11  14]\n",
      " [  2  20 142   3  30  12   1]\n",
      " [  4  21   4  28 124  10  19]\n",
      " [  0  25   0   0 160   6  19]\n",
      " [  6  41  11   6  24  25  97]\n",
      " [  0   8   0   0   4   9 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.20      0.32       210\n",
      "           2       0.45      0.59      0.51       210\n",
      "           3       0.78      0.68      0.72       210\n",
      "           4       0.67      0.13      0.22       210\n",
      "           5       0.34      0.76      0.47       210\n",
      "           6       0.29      0.12      0.17       210\n",
      "           7       0.53      0.90      0.67       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.55      0.48      0.44      1470\n",
      "weighted avg       0.55      0.48      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61  29   7  23  59  17  14]\n",
      " [  2 136   8   7  34  10  13]\n",
      " [  2  23 144  18  10  13   0]\n",
      " [  7  20   2  69  81  14  17]\n",
      " [  3  20   0   8 152  11  16]\n",
      " [ 10  36  10  12  18  39  85]\n",
      " [  0   7   0   1   3  13 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.29      0.41       210\n",
      "           2       0.50      0.65      0.57       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.50      0.33      0.40       210\n",
      "           5       0.43      0.72      0.54       210\n",
      "           6       0.33      0.19      0.24       210\n",
      "           7       0.56      0.89      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.51      1470\n",
      "weighted avg       0.55      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78  20   5  26  46  25  10]\n",
      " [  2 137   8  12  28  13  10]\n",
      " [  9  31 140  11   7  12   0]\n",
      " [  8  17   2  91  63  15  14]\n",
      " [  4  22   0  10 148  13  13]\n",
      " [ 11  32  10  16  14  51  76]\n",
      " [  0   7   0   0   2  16 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.37      0.48       210\n",
      "           2       0.52      0.65      0.58       210\n",
      "           3       0.85      0.67      0.75       210\n",
      "           4       0.55      0.43      0.48       210\n",
      "           5       0.48      0.70      0.57       210\n",
      "           6       0.35      0.24      0.29       210\n",
      "           7       0.60      0.88      0.71       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 88  17   4  26  45  18  12]\n",
      " [  3 135   7  15  25  13  12]\n",
      " [  7  17 157  11   6  12   0]\n",
      " [  9  18   2  99  52  18  12]\n",
      " [  6  17   1  13 145  17  11]\n",
      " [ 13  28   9  16  16  55  73]\n",
      " [  1   4   0   0   3  20 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.42      0.52       210\n",
      "           2       0.57      0.64      0.61       210\n",
      "           3       0.87      0.75      0.81       210\n",
      "           4       0.55      0.47      0.51       210\n",
      "           5       0.50      0.69      0.58       210\n",
      "           6       0.36      0.26      0.30       210\n",
      "           7       0.60      0.87      0.71       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  19   3  18  44  21  12]\n",
      " [  3 136   7  12  25  16  11]\n",
      " [  7  17 160  13   4   9   0]\n",
      " [  9  14   3  97  57  23   7]\n",
      " [  7  18   0  17 142  15  11]\n",
      " [ 13  27   8  16  11  65  70]\n",
      " [  0   4   1   1   3  20 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.44      0.54       210\n",
      "           2       0.58      0.65      0.61       210\n",
      "           3       0.88      0.76      0.82       210\n",
      "           4       0.56      0.46      0.51       210\n",
      "           5       0.50      0.68      0.57       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94  15   7  24  37  22  11]\n",
      " [  5 140   8   9  23  17   8]\n",
      " [ 10  11 160   9   4  16   0]\n",
      " [ 10  16   2  99  56  17  10]\n",
      " [  8  20   0  17 138  14  13]\n",
      " [ 12  21   7  15  15  68  72]\n",
      " [  1   5   1   0   3  21 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.45      0.54       210\n",
      "           2       0.61      0.67      0.64       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.57      0.47      0.52       210\n",
      "           5       0.50      0.66      0.57       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.61      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99  16   4  12  47  25   7]\n",
      " [  4 130   9  11  26  21   9]\n",
      " [  7  12 164  11   4  12   0]\n",
      " [  9  12   2  99  52  26  10]\n",
      " [ 12  12   0  17 143  16  10]\n",
      " [ 13  19   7  17  12  76  66]\n",
      " [  3   4   1   0   4  13 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.47      0.55       210\n",
      "           2       0.63      0.62      0.63       210\n",
      "           3       0.88      0.78      0.83       210\n",
      "           4       0.59      0.47      0.53       210\n",
      "           5       0.50      0.68      0.57       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.64      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  13   5  14  44  20  10]\n",
      " [  4 134   7   9  22  27   7]\n",
      " [ 11  11 163  11   3  11   0]\n",
      " [  9  12   1 103  53  26   6]\n",
      " [  9  19   0  18 141  11  12]\n",
      " [ 18  16   6  14  13  77  66]\n",
      " [  4   4   0   1   2  15 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.50      0.56       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.61      0.49      0.54       210\n",
      "           5       0.51      0.67      0.58       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.65      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100  14   5  18  43  22   8]\n",
      " [  5 139   4  10  22  22   8]\n",
      " [  8  13 168   8   5   8   0]\n",
      " [ 12  12   2 103  55  14  12]\n",
      " [ 11  17   0  22 136  10  14]\n",
      " [ 14  22   8  16  13  74  63]\n",
      " [  3   3   1   1   3  20 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.48      0.55       210\n",
      "           2       0.63      0.66      0.65       210\n",
      "           3       0.89      0.80      0.84       210\n",
      "           4       0.58      0.49      0.53       210\n",
      "           5       0.49      0.65      0.56       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.63      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110  12   6  13  39  24   6]\n",
      " [  5 137   7  13  18  21   9]\n",
      " [  6  14 165   8   4  13   0]\n",
      " [ 12  13   3 108  47  20   7]\n",
      " [ 11  19   1  16 140  11  12]\n",
      " [ 11  16   8  19  12  78  66]\n",
      " [  0   2   0   1   4  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.52      0.60       210\n",
      "           2       0.64      0.65      0.65       210\n",
      "           3       0.87      0.79      0.82       210\n",
      "           4       0.61      0.51      0.56       210\n",
      "           5       0.53      0.67      0.59       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.64      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  11   5  19  39  26   7]\n",
      " [  5 137   4  11  18  28   7]\n",
      " [  7  11 166   9   5  12   0]\n",
      " [  6  15   2 103  56  23   5]\n",
      " [ 10  15   1  20 140  14  10]\n",
      " [ 20  18   7  13  11  79  62]\n",
      " [  1   2   1   1   4  19 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.49      0.57       210\n",
      "           2       0.66      0.65      0.65       210\n",
      "           3       0.89      0.79      0.84       210\n",
      "           4       0.59      0.49      0.53       210\n",
      "           5       0.51      0.67      0.58       210\n",
      "           6       0.39      0.38      0.38       210\n",
      "           7       0.67      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  12   5  16  38  23   7]\n",
      " [  5 136   6  12  22  22   7]\n",
      " [  6   8 172  11   4   9   0]\n",
      " [ 10  12   3 110  47  21   7]\n",
      " [ 13  21   0  22 131  11  12]\n",
      " [ 16  14   8  19  12  78  63]\n",
      " [  2   2   1   0   4  14 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.52      0.59       210\n",
      "           2       0.66      0.65      0.66       210\n",
      "           3       0.88      0.82      0.85       210\n",
      "           4       0.58      0.52      0.55       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.44      0.37      0.40       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105  14   6  11  42  25   7]\n",
      " [  6 133   8  13  22  20   8]\n",
      " [  7  10 169   9   4  11   0]\n",
      " [  6   9   2 108  51  24  10]\n",
      " [ 18  14   0  19 134  14  11]\n",
      " [ 17  16   5  15  10  87  60]\n",
      " [  2   1   1   1   4  16 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.50      0.57       210\n",
      "           2       0.68      0.63      0.65       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.61      0.51      0.56       210\n",
      "           5       0.50      0.64      0.56       210\n",
      "           6       0.44      0.41      0.43       210\n",
      "           7       0.66      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107  14   4  17  40  17  11]\n",
      " [  4 133   7  12  22  26   6]\n",
      " [  4  10 170   9   5  12   0]\n",
      " [ 10  12   2 111  49  17   9]\n",
      " [ 13  15   2  24 135  10  11]\n",
      " [ 14  22   9  17  10  70  68]\n",
      " [  4   2   0   1   2  17 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.51      0.58       210\n",
      "           2       0.64      0.63      0.64       210\n",
      "           3       0.88      0.81      0.84       210\n",
      "           4       0.58      0.53      0.55       210\n",
      "           5       0.51      0.64      0.57       210\n",
      "           6       0.41      0.33      0.37       210\n",
      "           7       0.64      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   8   5  12  39  32   5]\n",
      " [  2 136   6  18  19  22   7]\n",
      " [  7  10 167  10   5  11   0]\n",
      " [ 10  14   2 107  46  22   9]\n",
      " [ 11  14   1  28 132  13  11]\n",
      " [ 14  21   8  15  11  76  65]\n",
      " [  3   3   0   0   3  16 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.52      0.60       210\n",
      "           2       0.66      0.65      0.65       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.56      0.51      0.53       210\n",
      "           5       0.52      0.63      0.57       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.66      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  11   4  15  41  25   8]\n",
      " [  3 143   7  13  19  17   8]\n",
      " [  7   9 168  11   5  10   0]\n",
      " [ 14  15   2 102  49  21   7]\n",
      " [ 13  15   1  20 138  13  10]\n",
      " [ 15  18   9  16  12  76  64]\n",
      " [  1   2   1   2   3  19 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57       210\n",
      "           2       0.67      0.68      0.68       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.57      0.49      0.52       210\n",
      "           5       0.52      0.66      0.58       210\n",
      "           6       0.42      0.36      0.39       210\n",
      "           7       0.65      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107  14   4  15  39  23   8]\n",
      " [  5 140   7  17  14  20   7]\n",
      " [  9   9 168  10   4  10   0]\n",
      " [ 12  12   1 100  53  25   7]\n",
      " [ 16  16   0  19 135  11  13]\n",
      " [ 15  20   6  14  12  76  67]\n",
      " [  1   1   1   2   4  21 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.51      0.57       210\n",
      "           2       0.66      0.67      0.66       210\n",
      "           3       0.90      0.80      0.85       210\n",
      "           4       0.56      0.48      0.52       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.64      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   9   3  20  40  27   7]\n",
      " [  8 140   6  12  20  19   5]\n",
      " [ 10  10 167  11   3   9   0]\n",
      " [ 11  15   2 110  42  23   7]\n",
      " [ 14  19   2  20 130  14  11]\n",
      " [ 14  17   7  15  12  81  64]\n",
      " [  1   1   1   0   4  22 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.50      0.56       210\n",
      "           2       0.66      0.67      0.67       210\n",
      "           3       0.89      0.80      0.84       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.52      0.62      0.56       210\n",
      "           6       0.42      0.39      0.40       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.4340136054421769\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 55  11   2   7  73  50  12]\n",
      " [  6  80   5  10  51  44  14]\n",
      " [ 16   9  71  45  46  22   1]\n",
      " [ 10  10   2  38 113  26  11]\n",
      " [  8  13   0   3 156  20  10]\n",
      " [  9  19   3  19  19  66  75]\n",
      " [  2   5   0   2   2  27 172]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.26      0.35       210\n",
      "           2       0.54      0.38      0.45       210\n",
      "           3       0.86      0.34      0.48       210\n",
      "           4       0.31      0.18      0.23       210\n",
      "           5       0.34      0.74      0.47       210\n",
      "           6       0.26      0.31      0.28       210\n",
      "           7       0.58      0.82      0.68       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.49      0.43      0.42      1470\n",
      "weighted avg       0.49      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 89   1  30  12  31  10  37]\n",
      " [ 18  51  30  22  21   7  61]\n",
      " [ 25  20 114  25   9   4  13]\n",
      " [ 25  10   9  44  52   8  62]\n",
      " [ 26   6   3  28  80   2  65]\n",
      " [ 27   9  12  30  27   6  99]\n",
      " [  1   2   0  22  20   3 162]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.42      0.42       210\n",
      "           2       0.52      0.24      0.33       210\n",
      "           3       0.58      0.54      0.56       210\n",
      "           4       0.24      0.21      0.22       210\n",
      "           5       0.33      0.38      0.36       210\n",
      "           6       0.15      0.03      0.05       210\n",
      "           7       0.32      0.77      0.46       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.37      0.37      0.34      1470\n",
      "weighted avg       0.37      0.37      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138   8   4  15  32   7   6]\n",
      " [ 25 116  12  23  19   4  11]\n",
      " [ 16  24 154   5   5   5   1]\n",
      " [ 36  27   5  88  44   6   4]\n",
      " [ 58  17   3  35  86   5   6]\n",
      " [ 40  29   9  48  24  28  32]\n",
      " [ 35   5   1  17  14  20 118]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.66      0.49       210\n",
      "           2       0.51      0.55      0.53       210\n",
      "           3       0.82      0.73      0.77       210\n",
      "           4       0.38      0.42      0.40       210\n",
      "           5       0.38      0.41      0.40       210\n",
      "           6       0.37      0.13      0.20       210\n",
      "           7       0.66      0.56      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132   6   4  15  36  11   6]\n",
      " [ 20 118   7  23  22   6  14]\n",
      " [ 17  23 151   5   6   6   2]\n",
      " [ 38  21   2  87  43   9  10]\n",
      " [ 50  13   2  35  92   7  11]\n",
      " [ 39  19   6  44  26  39  37]\n",
      " [ 28   5   0  12  15  30 120]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.63      0.49       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.88      0.72      0.79       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.38      0.44      0.41       210\n",
      "           6       0.36      0.19      0.25       210\n",
      "           7       0.60      0.57      0.59       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128   3   4  20  37  13   5]\n",
      " [ 16 112   9  27  23  10  13]\n",
      " [ 14  22 153   6   6   7   2]\n",
      " [ 31  17   4  85  54  11   8]\n",
      " [ 53  14   1  32  91   7  12]\n",
      " [ 30  18   7  41  36  36  42]\n",
      " [ 18   6   0  14  21  28 123]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.61      0.51       210\n",
      "           2       0.58      0.53      0.56       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.34      0.43      0.38       210\n",
      "           6       0.32      0.17      0.22       210\n",
      "           7       0.60      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[130   3   4  15  42  12   4]\n",
      " [ 19 108  14  26  24   8  11]\n",
      " [ 10  23 156   6   7   6   2]\n",
      " [ 32  18   4  81  54  10  11]\n",
      " [ 53  13   0  32  95   3  14]\n",
      " [ 29  16   8  47  32  34  44]\n",
      " [ 14   2   0  17  21  22 134]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.62      0.52       210\n",
      "           2       0.59      0.51      0.55       210\n",
      "           3       0.84      0.74      0.79       210\n",
      "           4       0.36      0.39      0.37       210\n",
      "           5       0.35      0.45      0.39       210\n",
      "           6       0.36      0.16      0.22       210\n",
      "           7       0.61      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   2   1  18  42   9   3]\n",
      " [ 22  99  16  27  26   9  11]\n",
      " [  7  26 156   5  10   5   1]\n",
      " [ 28  16   4  76  62  11  13]\n",
      " [ 50  14   0  34  96   3  13]\n",
      " [ 33  19   6  42  31  31  48]\n",
      " [ 14   2   0  18  13  21 142]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.64      0.54       210\n",
      "           2       0.56      0.47      0.51       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.35      0.36      0.35       210\n",
      "           5       0.34      0.46      0.39       210\n",
      "           6       0.35      0.15      0.21       210\n",
      "           7       0.61      0.68      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[131   4   1  14  46  11   3]\n",
      " [ 19  99  14  28  29   9  12]\n",
      " [ 10  25 157   4  10   3   1]\n",
      " [ 27  14   6  76  64  11  12]\n",
      " [ 50  12   0  36  93   7  12]\n",
      " [ 29  15   7  44  25  37  53]\n",
      " [ 15   3   1   9  17  25 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.62      0.53       210\n",
      "           2       0.58      0.47      0.52       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.36      0.36      0.36       210\n",
      "           5       0.33      0.44      0.38       210\n",
      "           6       0.36      0.18      0.24       210\n",
      "           7       0.60      0.67      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 83   6  16  11  54   7  33]\n",
      " [  1 122  14  17  29  14  13]\n",
      " [  9  40 142  12   3   3   1]\n",
      " [  0  13   9  70  60   9  49]\n",
      " [ 10  12   0  10 135   1  42]\n",
      " [  6  32  11  27  25  23  86]\n",
      " [  0  13   0   8  14  17 158]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.40      0.52       210\n",
      "           2       0.51      0.58      0.54       210\n",
      "           3       0.74      0.68      0.71       210\n",
      "           4       0.45      0.33      0.38       210\n",
      "           5       0.42      0.64      0.51       210\n",
      "           6       0.31      0.11      0.16       210\n",
      "           7       0.41      0.75      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.48      1470\n",
      "weighted avg       0.52      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[113   7  16   5  29   8  32]\n",
      " [  1 135  15  12  18  15  14]\n",
      " [  3  23 162  15   3   3   1]\n",
      " [  4  20  11  81  33  15  46]\n",
      " [ 21  26   1  10 107   6  39]\n",
      " [ 11  42   9  22  16  32  78]\n",
      " [  2  20   0  12   6  23 147]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.54      0.62       210\n",
      "           2       0.49      0.64      0.56       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.52      0.39      0.44       210\n",
      "           5       0.50      0.51      0.51       210\n",
      "           6       0.31      0.15      0.21       210\n",
      "           7       0.41      0.70      0.52       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.2979591836734694\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 77   2  16  11  36   9  59]\n",
      " [  7  17   5  34  36  24  87]\n",
      " [ 34   7  56  51  24  11  27]\n",
      " [  9   4   2  24  62   8 101]\n",
      " [  6   4   0  14  96   4  86]\n",
      " [ 17   2   4  23  36   5 123]\n",
      " [  0   0   0  15  32   0 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.37      0.43       210\n",
      "           2       0.47      0.08      0.14       210\n",
      "           3       0.67      0.27      0.38       210\n",
      "           4       0.14      0.11      0.13       210\n",
      "           5       0.30      0.46      0.36       210\n",
      "           6       0.08      0.02      0.04       210\n",
      "           7       0.25      0.78      0.38       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.35      0.30      0.26      1470\n",
      "weighted avg       0.35      0.30      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.39183673469387753\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 93   4  15  10  36  14  38]\n",
      " [ 10  72   7  17  36  20  48]\n",
      " [ 40  35  87  11  17  11   9]\n",
      " [ 15  10   2  28  79  16  60]\n",
      " [ 11   6   1  21 106   5  60]\n",
      " [ 16   8   5  25  39  20  97]\n",
      " [  0   1   0  14  21   4 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.44      0.47       210\n",
      "           2       0.53      0.34      0.42       210\n",
      "           3       0.74      0.41      0.53       210\n",
      "           4       0.22      0.13      0.17       210\n",
      "           5       0.32      0.50      0.39       210\n",
      "           6       0.22      0.10      0.13       210\n",
      "           7       0.35      0.81      0.49       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.37      1470\n",
      "weighted avg       0.41      0.39      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.345578231292517\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 87   4  13  11  41  11  43]\n",
      " [  7  44   5  27  36  25  66]\n",
      " [ 37  24  63  38  18  15  15]\n",
      " [ 12   9   2  22  82  16  67]\n",
      " [  9   4   0  13 109   7  68]\n",
      " [ 16   6   4  18  43  19 104]\n",
      " [  0   0   0  14  30   2 164]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.41      0.46       210\n",
      "           2       0.48      0.21      0.29       210\n",
      "           3       0.72      0.30      0.42       210\n",
      "           4       0.15      0.10      0.12       210\n",
      "           5       0.30      0.52      0.38       210\n",
      "           6       0.20      0.09      0.12       210\n",
      "           7       0.31      0.78      0.45       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.38      0.35      0.32      1470\n",
      "weighted avg       0.38      0.35      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.2619047619047619\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 50   0  17  14  34   2  93]\n",
      " [  2   0   6  43  24   6 129]\n",
      " [ 12   0  57  56  12  10  63]\n",
      " [  3   0   2  28  41   2 134]\n",
      " [  3   0   0  18  73   1 115]\n",
      " [  4   0   5  24  27   5 145]\n",
      " [  0   0   0  14  24   0 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.24      0.35       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.66      0.27      0.38       210\n",
      "           4       0.14      0.13      0.14       210\n",
      "           5       0.31      0.35      0.33       210\n",
      "           6       0.19      0.02      0.04       210\n",
      "           7       0.20      0.82      0.32       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.31      0.26      0.22      1470\n",
      "weighted avg       0.31      0.26      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.23469387755102042\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  22   0   0   0 188]\n",
      " [  0   0  10   0   0   0 200]\n",
      " [  0   0 135   0   0   0  75]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0   2   0   0   0 208]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.75      0.64      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.14      1470\n",
      "weighted avg       0.13      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.319047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 19 170   3   0   0   0  18]\n",
      " [  4 185   6   0   0   0  15]\n",
      " [  1  70 134   0   0   0   5]\n",
      " [  1 156   5   0   0   0  48]\n",
      " [  2 178   0   0   0   0  30]\n",
      " [  2 135   3   0   0   0  70]\n",
      " [  0  79   0   0   0   0 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.09      0.16       210\n",
      "           2       0.19      0.88      0.31       210\n",
      "           3       0.89      0.64      0.74       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.41      0.62      0.50       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.31      0.32      0.24      1470\n",
      "weighted avg       0.31      0.32      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.354421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 18   8   3   9 162   0  10]\n",
      " [  1  67   6  14 118   0   4]\n",
      " [  1  17 134   5  53   0   0]\n",
      " [  0  11   5  41 145   0   8]\n",
      " [  0  10   0  23 168   0   9]\n",
      " [  0  12   3  44 123   0  28]\n",
      " [  0   4   0  38  75   0  93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.09      0.16       210\n",
      "           2       0.52      0.32      0.40       210\n",
      "           3       0.89      0.64      0.74       210\n",
      "           4       0.24      0.20      0.21       210\n",
      "           5       0.20      0.80      0.32       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.61      0.44      0.51       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.48      0.35      0.33      1470\n",
      "weighted avg       0.48      0.35      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37755102040816324\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63   8   3   6 117   7   6]\n",
      " [  2  67   6  10 117   1   7]\n",
      " [  3  17 129   1  51   5   4]\n",
      " [  5  11   4  31 140   7  12]\n",
      " [ 10  10   0  22 158   5   5]\n",
      " [  1  12   1  22 122  14  38]\n",
      " [  0   4   0  14  75  24  93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.30      0.43       210\n",
      "           2       0.52      0.32      0.40       210\n",
      "           3       0.90      0.61      0.73       210\n",
      "           4       0.29      0.15      0.20       210\n",
      "           5       0.20      0.75      0.32       210\n",
      "           6       0.22      0.07      0.10       210\n",
      "           7       0.56      0.44      0.50       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.49      0.38      0.38      1470\n",
      "weighted avg       0.49      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63   5   6  87  30  17   2]\n",
      " [  2  59  12  84  36  12   5]\n",
      " [  3   6 141  43  12   3   2]\n",
      " [  5   5   9 110  47  30   4]\n",
      " [ 10  10   1  82  81  22   4]\n",
      " [  1   7   6 112  14  47  23]\n",
      " [  0   0   2  70   7  41  90]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.30      0.43       210\n",
      "           2       0.64      0.28      0.39       210\n",
      "           3       0.80      0.67      0.73       210\n",
      "           4       0.19      0.52      0.28       210\n",
      "           5       0.36      0.39      0.37       210\n",
      "           6       0.27      0.22      0.25       210\n",
      "           7       0.69      0.43      0.53       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.53      0.40      0.42      1470\n",
      "weighted avg       0.53      0.40      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  58   1   3  69  12   2]\n",
      " [  2 129  10   5  54   5   5]\n",
      " [  1  45 140   5  13   4   2]\n",
      " [  5  60   2  20 102  18   3]\n",
      " [  7  35   0   3 156   6   3]\n",
      " [  1  60   1   8  83  40  17]\n",
      " [  0  24   0   6  68  29  83]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.31      0.45       210\n",
      "           2       0.31      0.61      0.42       210\n",
      "           3       0.91      0.67      0.77       210\n",
      "           4       0.40      0.10      0.15       210\n",
      "           5       0.29      0.74      0.41       210\n",
      "           6       0.35      0.19      0.25       210\n",
      "           7       0.72      0.40      0.51       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.54      0.43      0.42      1470\n",
      "weighted avg       0.54      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  27   1   8  64  13   2]\n",
      " [ 18 112   9  10  49   7   5]\n",
      " [  6  35 141   8  13   6   1]\n",
      " [ 25  39   3  27  93  19   4]\n",
      " [  9  32   0  15 140   8   6]\n",
      " [ 18  45   1  20  68  33  25]\n",
      " [ 10  14   0  16  44  27  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.45      0.49       210\n",
      "           2       0.37      0.53      0.44       210\n",
      "           3       0.91      0.67      0.77       210\n",
      "           4       0.26      0.13      0.17       210\n",
      "           5       0.30      0.67      0.41       210\n",
      "           6       0.29      0.16      0.20       210\n",
      "           7       0.70      0.47      0.56       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.43      1470\n",
      "weighted avg       0.48      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  23   5  13  59  13   3]\n",
      " [  8 114  10  19  47   6   6]\n",
      " [  3  23 158  11  11   3   1]\n",
      " [ 10  42   4  51  83  15   5]\n",
      " [ 18  32   2  13 131   5   9]\n",
      " [ 15  44   1  32  53  26  39]\n",
      " [  9  16   0  17  32  26 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.45      0.51       210\n",
      "           2       0.39      0.54      0.45       210\n",
      "           3       0.88      0.75      0.81       210\n",
      "           4       0.33      0.24      0.28       210\n",
      "           5       0.31      0.62      0.42       210\n",
      "           6       0.28      0.12      0.17       210\n",
      "           7       0.64      0.52      0.57       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.46      1470\n",
      "weighted avg       0.49      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  18   5  12  50  21   4]\n",
      " [  9 101  18  22  39  16   5]\n",
      " [  1  20 158  11  12   7   1]\n",
      " [ 11  26   4  59  77  28   5]\n",
      " [ 32  33   0  19 107  11   8]\n",
      " [ 14  29   1  35  48  53  30]\n",
      " [  3   5   1  17  32  47 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.48      0.53       210\n",
      "           2       0.44      0.48      0.46       210\n",
      "           3       0.84      0.75      0.80       210\n",
      "           4       0.34      0.28      0.31       210\n",
      "           5       0.29      0.51      0.37       210\n",
      "           6       0.29      0.25      0.27       210\n",
      "           7       0.66      0.50      0.57       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  13  12  11  39  26   5]\n",
      " [ 16  91  26  18  25  28   6]\n",
      " [  7   6 171  10   9   6   1]\n",
      " [ 21  14  13  54  62  37   9]\n",
      " [ 34  25   7  15 104  17   8]\n",
      " [ 24  20   7  28  34  58  39]\n",
      " [ 10   6   2  13  25  41 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.50      0.49       210\n",
      "           2       0.52      0.43      0.47       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       0.36      0.26      0.30       210\n",
      "           5       0.35      0.50      0.41       210\n",
      "           6       0.27      0.28      0.27       210\n",
      "           7       0.62      0.54      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  13  13   7  56  10   5]\n",
      " [ 18  96  12  20  32  22  10]\n",
      " [  6   9 167   7  13   7   1]\n",
      " [ 21  23   8  62  62  30   4]\n",
      " [ 36  26   3  25  99  14   7]\n",
      " [ 22  27   2  25  46  55  33]\n",
      " [ 14   4   0  10  30  42 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.50      0.49       210\n",
      "           2       0.48      0.46      0.47       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.40      0.30      0.34       210\n",
      "           5       0.29      0.47      0.36       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.65      0.52      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.48      1470\n",
      "weighted avg       0.49      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  20  10  16  43  15   6]\n",
      " [ 20  96  18  26  27  15   8]\n",
      " [  2  10 166  11  12   8   1]\n",
      " [ 19  24   8  81  46  22  10]\n",
      " [ 36  27   3  30  95  12   7]\n",
      " [ 28  29   4  47  28  41  33]\n",
      " [ 12  11   0  22  19  39 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.44      0.46      0.45       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.35      0.39      0.37       210\n",
      "           5       0.35      0.45      0.40       210\n",
      "           6       0.27      0.20      0.23       210\n",
      "           7       0.62      0.51      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  18   8  19  46  19   5]\n",
      " [ 17  99  15  27  25  21   6]\n",
      " [  3  12 166  13   8   7   1]\n",
      " [ 16  21   8  81  40  38   6]\n",
      " [ 34  29   6  25  91  17   8]\n",
      " [ 30  23   5  47  28  46  31]\n",
      " [ 15  10   1  21  18  40 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.45      0.45       210\n",
      "           2       0.47      0.47      0.47       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.35      0.39      0.37       210\n",
      "           5       0.36      0.43      0.39       210\n",
      "           6       0.24      0.22      0.23       210\n",
      "           7       0.65      0.50      0.56       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.47      1470\n",
      "weighted avg       0.47      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  17  11  13  42  23   4]\n",
      " [ 17 100  18  26  25  17   7]\n",
      " [  2   9 170  13   5  10   1]\n",
      " [ 18  20   8  80  43  33   8]\n",
      " [ 34  30   6  26  86  21   7]\n",
      " [ 26  24   8  44  35  42  31]\n",
      " [  6   9   2  29  20  40 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.48      0.48       210\n",
      "           2       0.48      0.48      0.48       210\n",
      "           3       0.76      0.81      0.79       210\n",
      "           4       0.35      0.38      0.36       210\n",
      "           5       0.34      0.41      0.37       210\n",
      "           6       0.23      0.20      0.21       210\n",
      "           7       0.64      0.50      0.56       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  17  11  16  38  18   6]\n",
      " [ 15  96  17  33  20  22   7]\n",
      " [  6   4 168  15   6   8   3]\n",
      " [ 26  20   9  87  22  37   9]\n",
      " [ 39  24   3  28  84  21  11]\n",
      " [ 27  13   6  47  25  56  36]\n",
      " [ 10   7   1  21  18  45 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.50      0.48       210\n",
      "           2       0.53      0.46      0.49       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.35      0.41      0.38       210\n",
      "           5       0.39      0.40      0.40       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.60      0.51      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46598639455782315\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  14  11  15  36  19   5]\n",
      " [ 24  89  17  34  20  15  11]\n",
      " [  4   5 166  14   9  10   2]\n",
      " [ 31  16   9  80  30  34  10]\n",
      " [ 43  24   5  28  78  22  10]\n",
      " [ 29  14   7  46  27  54  33]\n",
      " [ 12   5   2  28  17  38 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.52      0.48       210\n",
      "           2       0.53      0.42      0.47       210\n",
      "           3       0.76      0.79      0.78       210\n",
      "           4       0.33      0.38      0.35       210\n",
      "           5       0.36      0.37      0.37       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.60      0.51      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  17  10  12  33  24   4]\n",
      " [ 17  96  22  34  16  17   8]\n",
      " [  4   4 169  14   8   9   2]\n",
      " [ 26  22   8  80  31  34   9]\n",
      " [ 39  24   5  25  83  21  13]\n",
      " [ 33  15   9  45  25  47  36]\n",
      " [ 18   4   2  21  22  37 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.52      0.48       210\n",
      "           2       0.53      0.46      0.49       210\n",
      "           3       0.75      0.80      0.78       210\n",
      "           4       0.35      0.38      0.36       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.25      0.22      0.24       210\n",
      "           7       0.60      0.50      0.55       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  18  12  12  35  20   6]\n",
      " [ 20  98  17  28  16  18  13]\n",
      " [  2   8 169  11   9   8   3]\n",
      " [ 23  25   9  79  32  35   7]\n",
      " [ 39  24   4  28  86  20   9]\n",
      " [ 23  19   7  43  24  54  40]\n",
      " [ 15  11   3  21  16  39 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.51      0.49       210\n",
      "           2       0.48      0.47      0.47       210\n",
      "           3       0.76      0.80      0.78       210\n",
      "           4       0.36      0.38      0.37       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.57      0.50      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  21  10   8  33  22  10]\n",
      " [ 22  97  20  27  17  20   7]\n",
      " [  4   6 169  12   9   9   1]\n",
      " [ 23  23   9  74  35  31  15]\n",
      " [ 38  27   6  30  79  18  12]\n",
      " [ 30  20   8  37  22  55  38]\n",
      " [  9  12   2  20  12  40 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.50      0.48       210\n",
      "           2       0.47      0.46      0.47       210\n",
      "           3       0.75      0.80      0.78       210\n",
      "           4       0.36      0.35      0.35       210\n",
      "           5       0.38      0.38      0.38       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.58      0.55      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  17  10  16  30  21   8]\n",
      " [ 18  91  27  28  14  21  11]\n",
      " [  7   4 166  10   9  11   3]\n",
      " [ 25  22  11  76  32  31  13]\n",
      " [ 44  24   5  25  82  20  10]\n",
      " [ 25  19  13  43  20  56  34]\n",
      " [ 11   9   3  17  14  39 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.51      0.48       210\n",
      "           2       0.49      0.43      0.46       210\n",
      "           3       0.71      0.79      0.75       210\n",
      "           4       0.35      0.36      0.36       210\n",
      "           5       0.41      0.39      0.40       210\n",
      "           6       0.28      0.27      0.27       210\n",
      "           7       0.60      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.31700680272108844\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  4  14  69   2  36   1  84]\n",
      " [  0  18  79   0  37   0  76]\n",
      " [  1   6 176   1  17   0   9]\n",
      " [  2   4  19   0  31   1 153]\n",
      " [  2   5  11   0  61   0 131]\n",
      " [  0  12  40   0  10   2 146]\n",
      " [  1   1   3   0   0   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.02      0.04       210\n",
      "           2       0.30      0.09      0.13       210\n",
      "           3       0.44      0.84      0.58       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.32      0.29      0.30       210\n",
      "           6       0.50      0.01      0.02       210\n",
      "           7       0.25      0.98      0.40       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.21      1470\n",
      "weighted avg       0.32      0.32      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43537414965986393\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 55  28  16   1  75   0  35]\n",
      " [  2  80  28   1  73   1  25]\n",
      " [  3  23 162   0  21   0   1]\n",
      " [  1  17  12   9 111   0  60]\n",
      " [  8  20   1   0 135   0  46]\n",
      " [  0  43  13   3  42   1 108]\n",
      " [  0   4   0   0   8   0 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.26      0.39       210\n",
      "           2       0.37      0.38      0.38       210\n",
      "           3       0.70      0.77      0.73       210\n",
      "           4       0.64      0.04      0.08       210\n",
      "           5       0.29      0.64      0.40       210\n",
      "           6       0.50      0.00      0.01       210\n",
      "           7       0.42      0.94      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.53      0.44      0.37      1470\n",
      "weighted avg       0.53      0.44      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95  11   4   6  61   2  31]\n",
      " [  3 108  12  12  55   4  16]\n",
      " [  0  33 159   4  13   0   1]\n",
      " [  1  21  10  44  88   0  46]\n",
      " [ 14  17   0   5 133   0  41]\n",
      " [  6  46   8  19  33   3  95]\n",
      " [  0   4   0   2   6   1 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.45      0.58       210\n",
      "           2       0.45      0.51      0.48       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.48      0.21      0.29       210\n",
      "           5       0.34      0.63      0.44       210\n",
      "           6       0.30      0.01      0.03       210\n",
      "           7       0.46      0.94      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.46      1470\n",
      "weighted avg       0.52      0.50      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  15   0   9  53   1  28]\n",
      " [  1 130   3  13  44   7  12]\n",
      " [  0  39 161   4   5   0   1]\n",
      " [  1  21   7  71  65   5  40]\n",
      " [ 18  18   0   9 128   1  36]\n",
      " [  6  46   8  24  26   9  91]\n",
      " [  0   4   0   3   5   2 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.50      0.61       210\n",
      "           2       0.48      0.62      0.54       210\n",
      "           3       0.90      0.77      0.83       210\n",
      "           4       0.53      0.34      0.41       210\n",
      "           5       0.39      0.61      0.48       210\n",
      "           6       0.36      0.04      0.08       210\n",
      "           7       0.49      0.93      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.51      1470\n",
      "weighted avg       0.56      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117  10   1  12  42   4  24]\n",
      " [  1 136   1  15  38   8  11]\n",
      " [  0  30 170   4   5   1   0]\n",
      " [  2  21   7  90  48  18  24]\n",
      " [ 15  19   0  15 128   8  25]\n",
      " [  4  40  11  29  20  16  90]\n",
      " [  0   5   0   3   6   4 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.56      0.67       210\n",
      "           2       0.52      0.65      0.58       210\n",
      "           3       0.89      0.81      0.85       210\n",
      "           4       0.54      0.43      0.48       210\n",
      "           5       0.45      0.61      0.52       210\n",
      "           6       0.27      0.08      0.12       210\n",
      "           7       0.52      0.91      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.55      1470\n",
      "weighted avg       0.58      0.58      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112  10   0  14  42   8  24]\n",
      " [  2 135   6  16  27  14  10]\n",
      " [  0  28 171   6   4   1   0]\n",
      " [  2  15   6 102  41  19  25]\n",
      " [ 12  18   1  18 130   6  25]\n",
      " [  6  36  10  30  18  26  84]\n",
      " [  0   2   0   2   4   6 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.53      0.65       210\n",
      "           2       0.55      0.64      0.59       210\n",
      "           3       0.88      0.81      0.85       210\n",
      "           4       0.54      0.49      0.51       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.33      0.12      0.18       210\n",
      "           7       0.54      0.93      0.68       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.57      1470\n",
      "weighted avg       0.60      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.608843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   6   2   9  48  11  17]\n",
      " [  1 136   3  19  28  15   8]\n",
      " [  0  23 177   4   3   3   0]\n",
      " [  2  22   6 104  36  25  15]\n",
      " [ 15  18   0  18 131   7  21]\n",
      " [  7  32  10  30  16  38  77]\n",
      " [  0   2   0   1   3  12 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.56      0.66       210\n",
      "           2       0.57      0.65      0.61       210\n",
      "           3       0.89      0.84      0.87       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.34      0.18      0.24       210\n",
      "           7       0.58      0.91      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.59      1470\n",
      "weighted avg       0.61      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   9   3   9  43  14  14]\n",
      " [  1 140   2  17  28  14   8]\n",
      " [  0  11 185   6   3   5   0]\n",
      " [  0  17   7 105  39  30  12]\n",
      " [ 14  18   0  20 131  10  17]\n",
      " [  6  22   7  29  11  68  67]\n",
      " [  0   4   0   1   3   8 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.56      0.68       210\n",
      "           2       0.63      0.67      0.65       210\n",
      "           3       0.91      0.88      0.89       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.46      0.32      0.38       210\n",
      "           7       0.62      0.92      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6394557823129252\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   5   6   7  42  18  15]\n",
      " [  3 141   5  15  22  16   8]\n",
      " [  0  20 181   4   2   3   0]\n",
      " [  2  17   6 112  35  28  10]\n",
      " [ 12  15   1  25 136  10  11]\n",
      " [  8  27   6  28  11  62  68]\n",
      " [  0   1   0   0   4  14 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.56      0.66       210\n",
      "           2       0.62      0.67      0.65       210\n",
      "           3       0.88      0.86      0.87       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.41      0.30      0.34       210\n",
      "           7       0.63      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   2   4   7  45  17  11]\n",
      " [  4 138   5  16  26  13   8]\n",
      " [  0  15 184   5   3   3   0]\n",
      " [  1  12  10 115  36  25  11]\n",
      " [ 12  15   2  19 137  13  12]\n",
      " [  4  20   6  29  12  75  64]\n",
      " [  0   1   0   1   2  12 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.87      0.88      0.87       210\n",
      "           4       0.60      0.55      0.57       210\n",
      "           5       0.52      0.65      0.58       210\n",
      "           6       0.47      0.36      0.41       210\n",
      "           7       0.65      0.92      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   7   2   6  39  17  10]\n",
      " [  2 144   3  15  22  17   7]\n",
      " [  0  17 184   5   3   1   0]\n",
      " [  2  15   6 113  36  28  10]\n",
      " [ 16  17   0  23 131  11  12]\n",
      " [  7  21   9  25  12  71  65]\n",
      " [  0   2   0   1   2  12 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.70       210\n",
      "           2       0.65      0.69      0.67       210\n",
      "           3       0.90      0.88      0.89       210\n",
      "           4       0.60      0.54      0.57       210\n",
      "           5       0.53      0.62      0.58       210\n",
      "           6       0.45      0.34      0.39       210\n",
      "           7       0.65      0.92      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   3   8   9  45  14   6]\n",
      " [  4 140   4  19  22  15   6]\n",
      " [  0  12 188   5   1   4   0]\n",
      " [  2  19   5 120  35  19  10]\n",
      " [ 12  14   1  22 141   9  11]\n",
      " [  7  19   8  30   9  73  64]\n",
      " [  0   3   0   0   2  12 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.69       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.88      0.90      0.89       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.55      0.67      0.61       210\n",
      "           6       0.50      0.35      0.41       210\n",
      "           7       0.67      0.92      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   6   4   8  40  11  10]\n",
      " [  5 144   6  11  21  18   5]\n",
      " [  0  17 185   5   0   2   1]\n",
      " [  1  15   9 107  42  23  13]\n",
      " [ 14  17   1  24 136   5  13]\n",
      " [  8  20   6  28  11  82  55]\n",
      " [  0   1   0   1   3  15 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.71       210\n",
      "           2       0.65      0.69      0.67       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.58      0.51      0.54       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.53      0.39      0.45       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   4   5   4  46  18   9]\n",
      " [  3 142   6  14  21  18   6]\n",
      " [  1  13 184   6   2   4   0]\n",
      " [  2  12   8 121  37  20  10]\n",
      " [ 20  19   1  16 134  10  10]\n",
      " [  8  14   8  29   8  82  61]\n",
      " [  0   1   0   0   3  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.59      0.67       210\n",
      "           2       0.69      0.68      0.68       210\n",
      "           3       0.87      0.88      0.87       210\n",
      "           4       0.64      0.58      0.60       210\n",
      "           5       0.53      0.64      0.58       210\n",
      "           6       0.49      0.39      0.43       210\n",
      "           7       0.66      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   4   3   7  43  14   7]\n",
      " [  2 140   5  18  28  11   6]\n",
      " [  1  15 186   6   1   0   1]\n",
      " [  1  14  10 110  38  24  13]\n",
      " [ 23  15   1  17 135   7  12]\n",
      " [ 10  20   9  28   9  75  59]\n",
      " [  0   0   0   0   3  17 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.63      0.70       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.87      0.89      0.88       210\n",
      "           4       0.59      0.52      0.56       210\n",
      "           5       0.53      0.64      0.58       210\n",
      "           6       0.51      0.36      0.42       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   4   9  36  12  11]\n",
      " [  3 144   5  12  22  19   5]\n",
      " [  1  16 182   6   4   1   0]\n",
      " [  2  16   6 111  36  34   5]\n",
      " [ 14  16   1  22 141   6  10]\n",
      " [  9  17  11  28   7  82  56]\n",
      " [  0   1   0   3   2  14 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.63      0.71       210\n",
      "           2       0.67      0.69      0.68       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.58      0.53      0.55       210\n",
      "           5       0.57      0.67      0.62       210\n",
      "           6       0.49      0.39      0.43       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   7   5   7  37  16   7]\n",
      " [  3 147   3  15  21  15   6]\n",
      " [  2  16 184   6   1   1   0]\n",
      " [  1  13   8 117  34  28   9]\n",
      " [ 20  16   1  24 133   9   7]\n",
      " [  6  14   9  34  10  83  54]\n",
      " [  0   2   0   2   2  11 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.62      0.70       210\n",
      "           2       0.68      0.70      0.69       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.57      0.56      0.56       210\n",
      "           5       0.56      0.63      0.59       210\n",
      "           6       0.51      0.40      0.45       210\n",
      "           7       0.70      0.92      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   3   8   4  46  11  10]\n",
      " [  2 147   3  11  20  18   9]\n",
      " [  1  12 188   4   2   3   0]\n",
      " [  2  14  10 112  36  27   9]\n",
      " [ 17  16   2  25 133   7  10]\n",
      " [ 10  17   9  24  14  77  59]\n",
      " [  0   3   0   0   3  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.69      0.70      0.70       210\n",
      "           3       0.85      0.90      0.87       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.52      0.63      0.57       210\n",
      "           6       0.48      0.37      0.41       210\n",
      "           7       0.66      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   4   5   5  45  14   9]\n",
      " [  2 142   5  11  28  14   8]\n",
      " [  1  17 183   6   0   3   0]\n",
      " [  1  15   8 114  41  19  12]\n",
      " [ 16  15   2  24 135   7  11]\n",
      " [  7  15  10  26  11  83  58]\n",
      " [  0   2   0   1   3  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.70       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.86      0.87      0.87       210\n",
      "           4       0.61      0.54      0.57       210\n",
      "           5       0.51      0.64      0.57       210\n",
      "           6       0.53      0.40      0.45       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   7   4  10  41  13  11]\n",
      " [  3 139   7  12  26  16   7]\n",
      " [  1  17 184   4   2   2   0]\n",
      " [  1  16   8 119  34  19  13]\n",
      " [ 20  17   2  26 128   6  11]\n",
      " [  8  17   8  28  11  83  55]\n",
      " [  0   3   0   0   5  19 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.59      0.68       210\n",
      "           2       0.64      0.66      0.65       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.60      0.57      0.58       210\n",
      "           5       0.52      0.61      0.56       210\n",
      "           6       0.53      0.40      0.45       210\n",
      "           7       0.65      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[114   1  15  12  20  17  31]\n",
      " [  0 105  18  32  20  18  17]\n",
      " [ 15  19 142  25   1   7   1]\n",
      " [  5  12   7  95  24  22  45]\n",
      " [ 32  16   1  21  90   8  42]\n",
      " [ 11  20   6  39  12  44  78]\n",
      " [  0   6   0  26   5  11 162]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.54      0.59       210\n",
      "           2       0.59      0.50      0.54       210\n",
      "           3       0.75      0.68      0.71       210\n",
      "           4       0.38      0.45      0.41       210\n",
      "           5       0.52      0.43      0.47       210\n",
      "           6       0.35      0.21      0.26       210\n",
      "           7       0.43      0.77      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.3380952380952381\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 57   6  63   2  55  17  10]\n",
      " [  2  26 100   8  59   8   7]\n",
      " [  1   1 179   8  21   0   0]\n",
      " [  3   6  98  13  66  11  13]\n",
      " [ 20  11  37  11  97  12  22]\n",
      " [  7   7  77   5  51  27  36]\n",
      " [  0   0  34   6  48  24  98]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.27      0.38       210\n",
      "           2       0.46      0.12      0.19       210\n",
      "           3       0.30      0.85      0.45       210\n",
      "           4       0.25      0.06      0.10       210\n",
      "           5       0.24      0.46      0.32       210\n",
      "           6       0.27      0.13      0.17       210\n",
      "           7       0.53      0.47      0.49       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.38      0.34      0.30      1470\n",
      "weighted avg       0.38      0.34      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137  14  10  10  28   4   7]\n",
      " [ 28 120  16  12  22   6   6]\n",
      " [ 11  31 157   6   3   2   0]\n",
      " [ 30  36  10  88  34   5   7]\n",
      " [ 68  25   4  28  71   8   6]\n",
      " [ 43  31   9  28  20  37  42]\n",
      " [ 20   9   0  12  14  15 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.65      0.50       210\n",
      "           2       0.45      0.57      0.50       210\n",
      "           3       0.76      0.75      0.75       210\n",
      "           4       0.48      0.42      0.45       210\n",
      "           5       0.37      0.34      0.35       210\n",
      "           6       0.48      0.18      0.26       210\n",
      "           7       0.67      0.67      0.67       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134  11  13  13  28   5   6]\n",
      " [ 17 126  14  15  21   8   9]\n",
      " [  9  21 161  11   3   4   1]\n",
      " [ 25  29   9  86  38  12  11]\n",
      " [ 69  16   5  28  72  11   9]\n",
      " [ 32  30   7  25  25  45  46]\n",
      " [ 16   6   0   9  12  28 139]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.64      0.52       210\n",
      "           2       0.53      0.60      0.56       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.46      0.41      0.43       210\n",
      "           5       0.36      0.34      0.35       210\n",
      "           6       0.40      0.21      0.28       210\n",
      "           7       0.63      0.66      0.65       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.51      0.52      0.51      1470\n",
      "weighted avg       0.51      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  10  14  10  36   8   7]\n",
      " [ 19 121  15  17  19  11   8]\n",
      " [  9  25 157  11   2   4   2]\n",
      " [ 25  27  10  90  35  12  11]\n",
      " [ 47  16   5  29  94   9  10]\n",
      " [ 29  27   7  29  25  42  51]\n",
      " [ 16   5   0   4  14  27 144]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.60      0.52       210\n",
      "           2       0.52      0.58      0.55       210\n",
      "           3       0.75      0.75      0.75       210\n",
      "           4       0.47      0.43      0.45       210\n",
      "           5       0.42      0.45      0.43       210\n",
      "           6       0.37      0.20      0.26       210\n",
      "           7       0.62      0.69      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.52      1470\n",
      "weighted avg       0.52      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128  11  11  12  36   3   9]\n",
      " [ 14 116  15  23  26   8   8]\n",
      " [ 10  24 159  10   4   2   1]\n",
      " [ 23  25  11  94  37   9  11]\n",
      " [ 43  18   5  31  99   6   8]\n",
      " [ 28  27   6  36  26  36  51]\n",
      " [ 15   5   0   7  19  19 145]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.61      0.54       210\n",
      "           2       0.51      0.55      0.53       210\n",
      "           3       0.77      0.76      0.76       210\n",
      "           4       0.44      0.45      0.44       210\n",
      "           5       0.40      0.47      0.43       210\n",
      "           6       0.43      0.17      0.25       210\n",
      "           7       0.62      0.69      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.52      1470\n",
      "weighted avg       0.52      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[127  10   9  15  37   5   7]\n",
      " [ 13 111  15  23  30   8  10]\n",
      " [  6  27 157  11   8   1   0]\n",
      " [ 12  24  11  97  45   8  13]\n",
      " [ 41  20   5  30  99   5  10]\n",
      " [ 23  26   8  40  25  34  54]\n",
      " [ 12   7   0   7  19  17 148]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.60      0.57       210\n",
      "           2       0.49      0.53      0.51       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.43      0.46      0.45       210\n",
      "           5       0.38      0.47      0.42       210\n",
      "           6       0.44      0.16      0.24       210\n",
      "           7       0.61      0.70      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.51      1470\n",
      "weighted avg       0.52      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126  10   9  14  35   6  10]\n",
      " [ 13 112  15  24  29   8   9]\n",
      " [  7  25 161   8   8   1   0]\n",
      " [ 16  28  12  87  45   9  13]\n",
      " [ 32  20   6  23 112   7  10]\n",
      " [ 23  26  11  35  20  31  64]\n",
      " [ 11   8   0   6  17  19 149]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.60      0.58       210\n",
      "           2       0.49      0.53      0.51       210\n",
      "           3       0.75      0.77      0.76       210\n",
      "           4       0.44      0.41      0.43       210\n",
      "           5       0.42      0.53      0.47       210\n",
      "           6       0.38      0.15      0.21       210\n",
      "           7       0.58      0.71      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.51      1470\n",
      "weighted avg       0.52      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[107   7  12   2  39  13  30]\n",
      " [  2 119  12  13  27  23  14]\n",
      " [  9  24 152   7   5  12   1]\n",
      " [  5  26   5  78  30  30  36]\n",
      " [ 12  11   0   8 131  10  38]\n",
      " [ 13  26   6  29  10  45  81]\n",
      " [  1   3   0   9   7  21 169]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.51      0.60       210\n",
      "           2       0.55      0.57      0.56       210\n",
      "           3       0.81      0.72      0.77       210\n",
      "           4       0.53      0.37      0.44       210\n",
      "           5       0.53      0.62      0.57       210\n",
      "           6       0.29      0.21      0.25       210\n",
      "           7       0.46      0.80      0.58       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[106   6  15   3  32  19  29]\n",
      " [  5 106  18  13  27  29  12]\n",
      " [ 16  27 140   7   5  14   1]\n",
      " [  5  20   5  86  30  29  35]\n",
      " [ 16  12   0   6 125  16  35]\n",
      " [ 12  20   6  34  10  52  76]\n",
      " [  1   3   0  12   6  16 172]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.50      0.57       210\n",
      "           2       0.55      0.50      0.52       210\n",
      "           3       0.76      0.67      0.71       210\n",
      "           4       0.53      0.41      0.46       210\n",
      "           5       0.53      0.60      0.56       210\n",
      "           6       0.30      0.25      0.27       210\n",
      "           7       0.48      0.82      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.53      1470\n",
      "weighted avg       0.54      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.21904761904761905\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 12   0 151   0  36  11   0]\n",
      " [  0   1 164   2  31  12   0]\n",
      " [  0   0 204   0   4   2   0]\n",
      " [  3   0 145   5  42  15   0]\n",
      " [  4   1 113   1  75  16   0]\n",
      " [  0   0 155   3  31  20   1]\n",
      " [  0   0 156   2  33  14   5]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.06      0.10       210\n",
      "           2       0.50      0.00      0.01       210\n",
      "           3       0.19      0.97      0.31       210\n",
      "           4       0.38      0.02      0.04       210\n",
      "           5       0.30      0.36      0.32       210\n",
      "           6       0.22      0.10      0.13       210\n",
      "           7       0.83      0.02      0.05       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.44      0.22      0.14      1470\n",
      "weighted avg       0.44      0.22      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.27414965986394557\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 23  85  55   2  36   9   0]\n",
      " [  0  88  80   5  34   3   0]\n",
      " [  1  22 182   1   4   0   0]\n",
      " [  4  64  79   8  47   8   0]\n",
      " [  7  78  29   5  80  11   0]\n",
      " [  0 111  40   4  36  19   0]\n",
      " [  0 131   6   8  36  26   3]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.11      0.19       210\n",
      "           2       0.15      0.42      0.22       210\n",
      "           3       0.39      0.87      0.53       210\n",
      "           4       0.24      0.04      0.07       210\n",
      "           5       0.29      0.38      0.33       210\n",
      "           6       0.25      0.09      0.13       210\n",
      "           7       1.00      0.01      0.03       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.43      0.27      0.21      1470\n",
      "weighted avg       0.43      0.27      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.25170068027210885\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 13  30  96   2  37  32   0]\n",
      " [  0  16 131   5  32  25   1]\n",
      " [  0   2 198   1   4   5   0]\n",
      " [  4  13 113   8  47  25   0]\n",
      " [  1  32  56   4  79  38   0]\n",
      " [  1  25  95   4  34  51   0]\n",
      " [  0  47  43   4  35  76   5]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.06      0.11       210\n",
      "           2       0.10      0.08      0.09       210\n",
      "           3       0.27      0.94      0.42       210\n",
      "           4       0.29      0.04      0.07       210\n",
      "           5       0.29      0.38      0.33       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.83      0.02      0.05       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.38      0.25      0.18      1470\n",
      "weighted avg       0.38      0.25      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.21360544217687075\n",
      "Confusion Matrix of SVM is:\n",
      " [[  8   0 158   0  37   7   0]\n",
      " [  0   4 168   1  27  10   0]\n",
      " [  0   0 204   0   4   2   0]\n",
      " [  1   4 149   4  39  13   0]\n",
      " [  0   3 118   0  74  15   0]\n",
      " [  0   0 158   2  32  18   0]\n",
      " [  0   0 158   3  33  14   2]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.04      0.07       210\n",
      "           2       0.36      0.02      0.04       210\n",
      "           3       0.18      0.97      0.31       210\n",
      "           4       0.40      0.02      0.04       210\n",
      "           5       0.30      0.35      0.32       210\n",
      "           6       0.23      0.09      0.12       210\n",
      "           7       1.00      0.01      0.02       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.48      0.21      0.13      1470\n",
      "weighted avg       0.48      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.21564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  20   0   0   0 190]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0 107   0   0   0 103]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.73      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31700680272108844\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[162   0   1   0   0   0  47]\n",
      " [ 43   0   4   0   0   0 163]\n",
      " [ 46   0 102   0   0   0  62]\n",
      " [104   0   6   0   0   0 100]\n",
      " [137   0   0   0   0   0  73]\n",
      " [ 54   0   1   0   0   0 155]\n",
      " [  8   0   0   0   0   0 202]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.77      0.42       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.89      0.49      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.25      0.96      0.40       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.21      0.32      0.21      1470\n",
      "weighted avg       0.21      0.32      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 69  19   0   2  92   0  28]\n",
      " [  2 116   3   1  41   0  47]\n",
      " [  9  51  96  10  33   0  11]\n",
      " [  1  45   3   5 101   0  55]\n",
      " [  4  23   0   0 133   0  50]\n",
      " [  4  34   1   2  48   0 121]\n",
      " [  0  21   0   0   8   0 181]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.33      0.46       210\n",
      "           2       0.38      0.55      0.45       210\n",
      "           3       0.93      0.46      0.61       210\n",
      "           4       0.25      0.02      0.04       210\n",
      "           5       0.29      0.63      0.40       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.37      0.86      0.51       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.43      0.41      0.35      1470\n",
      "weighted avg       0.43      0.41      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4496598639455782\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66  19   3  29  85   1   7]\n",
      " [  1 116   3  32  30   0  28]\n",
      " [  0  51 109  30  10   4   6]\n",
      " [  1  45   1  75  56   1  31]\n",
      " [  2  23   2  37 130   0  16]\n",
      " [  3  34   1  34  45   3  90]\n",
      " [  0  21   0   6  21   0 162]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.31      0.47       210\n",
      "           2       0.38      0.55      0.45       210\n",
      "           3       0.92      0.52      0.66       210\n",
      "           4       0.31      0.36      0.33       210\n",
      "           5       0.34      0.62      0.44       210\n",
      "           6       0.33      0.01      0.03       210\n",
      "           7       0.48      0.77      0.59       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.52      0.45      0.42      1470\n",
      "weighted avg       0.52      0.45      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  18  11  23  83   6   2]\n",
      " [  2 107  23  23  26  27   2]\n",
      " [  3  36 148   9   8   6   0]\n",
      " [  1  41  12  78  44  21  13]\n",
      " [  4  22   7  42 119  11   5]\n",
      " [  2  33  16  24  40  59  36]\n",
      " [  0  21   4   3  15  58 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.32      0.46       210\n",
      "           2       0.38      0.51      0.44       210\n",
      "           3       0.67      0.70      0.69       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.36      0.57      0.44       210\n",
      "           6       0.31      0.28      0.30       210\n",
      "           7       0.65      0.52      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.52      0.47      0.47      1470\n",
      "weighted avg       0.52      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  28   1   8  55  14   2]\n",
      " [  4 109   8  12  25  48   4]\n",
      " [  1  37 144   7   4  15   2]\n",
      " [  6  45   7  57  40  41  14]\n",
      " [ 14  33   2  17 117  21   6]\n",
      " [  6  44   3  14  27  76  40]\n",
      " [  0  16   0   2   6  47 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.49      0.59       210\n",
      "           2       0.35      0.52      0.42       210\n",
      "           3       0.87      0.69      0.77       210\n",
      "           4       0.49      0.27      0.35       210\n",
      "           5       0.43      0.56      0.48       210\n",
      "           6       0.29      0.36      0.32       210\n",
      "           7       0.67      0.66      0.67       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.51      1470\n",
      "weighted avg       0.55      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  28   2  14  67  14   1]\n",
      " [  8 112   8  19  13  44   6]\n",
      " [  2  38 142   9   3  16   0]\n",
      " [  6  38   3  80  25  50   8]\n",
      " [ 21  35   2  28 103  17   4]\n",
      " [  6  42   4  21  16  93  28]\n",
      " [  0  17   0  10   3  55 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.40      0.50       210\n",
      "           2       0.36      0.53      0.43       210\n",
      "           3       0.88      0.68      0.77       210\n",
      "           4       0.44      0.38      0.41       210\n",
      "           5       0.45      0.49      0.47       210\n",
      "           6       0.32      0.44      0.37       210\n",
      "           7       0.73      0.60      0.65       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.51      1470\n",
      "weighted avg       0.55      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  13  10  17  38  16   0]\n",
      " [ 12  97  23  21  10  45   2]\n",
      " [  3  16 153  11   6  20   1]\n",
      " [ 14  17  14  86  28  45   6]\n",
      " [ 42  22  11  26  87  19   3]\n",
      " [ 15  23  13  21  14 103  21]\n",
      " [  2   5   3  16   3  65 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.55      0.56       210\n",
      "           2       0.50      0.46      0.48       210\n",
      "           3       0.67      0.73      0.70       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.47      0.41      0.44       210\n",
      "           6       0.33      0.49      0.39       210\n",
      "           7       0.78      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.52      1470\n",
      "weighted avg       0.54      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  11   2  17  36  17   5]\n",
      " [ 11  96   7  23  33  32   8]\n",
      " [ 10  16 143  13   8  18   2]\n",
      " [ 13  17   3  90  35  41  11]\n",
      " [ 42  19   2  27  98  15   7]\n",
      " [ 15  25   6  25  18  88  33]\n",
      " [  3   4   0  17   5  57 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.58      0.57       210\n",
      "           2       0.51      0.46      0.48       210\n",
      "           3       0.88      0.68      0.77       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.42      0.47      0.44       210\n",
      "           6       0.33      0.42      0.37       210\n",
      "           7       0.65      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.53      1470\n",
      "weighted avg       0.54      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112  16   4  21  38  15   4]\n",
      " [  9  94  12  40  27  20   8]\n",
      " [  8  17 148  17   7  12   1]\n",
      " [ 16  21   6  93  29  36   9]\n",
      " [ 37  21   2  22  98  21   9]\n",
      " [ 22  23  10  26  15  87  27]\n",
      " [  6   7   1  17   3  55 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.39      0.44      0.42       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.35      0.41      0.38       210\n",
      "           7       0.68      0.58      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.52      1470\n",
      "weighted avg       0.53      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  21   2  21  32  21   3]\n",
      " [ 11 101  18  29  22  24   5]\n",
      " [  4  17 151  14   9  13   2]\n",
      " [ 11  36   5  88  32  31   7]\n",
      " [ 37  28   3  29  91  18   4]\n",
      " [ 15  27   9  44  12  80  23]\n",
      " [  5   6   2  24   4  50 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.52      0.55       210\n",
      "           2       0.43      0.48      0.45       210\n",
      "           3       0.79      0.72      0.76       210\n",
      "           4       0.35      0.42      0.38       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.34      0.38      0.36       210\n",
      "           7       0.73      0.57      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.51      1470\n",
      "weighted avg       0.52      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  17   5  25  33  22   1]\n",
      " [ 18 101  11  27  18  29   6]\n",
      " [  5  12 154  18   5  13   3]\n",
      " [ 14  25   7  92  29  32  11]\n",
      " [ 44  21   4  28  83  21   9]\n",
      " [ 19  28  11  36   8  78  30]\n",
      " [  7   4   3  21   6  42 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.50       210\n",
      "           2       0.49      0.48      0.48       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.37      0.44      0.40       210\n",
      "           5       0.46      0.40      0.42       210\n",
      "           6       0.33      0.37      0.35       210\n",
      "           7       0.68      0.60      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.51      1470\n",
      "weighted avg       0.52      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  17   3  17  36  20   1]\n",
      " [ 16  92  17  30  20  30   5]\n",
      " [  4  13 156  18   7  10   2]\n",
      " [ 21  25   6  87  32  28  11]\n",
      " [ 47  22   3  28  88  15   7]\n",
      " [ 23  20  13  33  18  78  25]\n",
      " [ 11   2   2  21   4  42 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52       210\n",
      "           2       0.48      0.44      0.46       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.37      0.41      0.39       210\n",
      "           5       0.43      0.42      0.42       210\n",
      "           6       0.35      0.37      0.36       210\n",
      "           7       0.72      0.61      0.66       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  15   8  26  31  22   4]\n",
      " [ 15  95  14  27  27  25   7]\n",
      " [  3  12 156  15   7  15   2]\n",
      " [ 17  18   8  90  31  36  10]\n",
      " [ 38  18   3  31  86  22  12]\n",
      " [ 20  24   9  32  18  80  27]\n",
      " [ 11   3   1  20   5  51 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       210\n",
      "           2       0.51      0.45      0.48       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.37      0.43      0.40       210\n",
      "           5       0.42      0.41      0.41       210\n",
      "           6       0.32      0.38      0.35       210\n",
      "           7       0.66      0.57      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  15   7  21  32  26   3]\n",
      " [ 14 100  10  31  22  26   7]\n",
      " [  6  14 154  13   7  14   2]\n",
      " [ 16  22  12  88  32  28  12]\n",
      " [ 45  19   4  30  85  17  10]\n",
      " [ 19  31   6  38  16  70  30]\n",
      " [ 12   5   0  15   6  48 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.50       210\n",
      "           2       0.49      0.48      0.48       210\n",
      "           3       0.80      0.73      0.76       210\n",
      "           4       0.37      0.42      0.39       210\n",
      "           5       0.42      0.40      0.41       210\n",
      "           6       0.31      0.33      0.32       210\n",
      "           7       0.66      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.50      1470\n",
      "weighted avg       0.50      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  17   8  22  33  18   4]\n",
      " [ 12 102  17  25  24  20  10]\n",
      " [  4  14 158  15   5  10   4]\n",
      " [ 18  25  12  89  29  25  12]\n",
      " [ 46  19   5  29  85  16  10]\n",
      " [ 21  26   9  35  15  70  34]\n",
      " [  9   5   2  13   8  44 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.50       210\n",
      "           2       0.49      0.49      0.49       210\n",
      "           3       0.75      0.75      0.75       210\n",
      "           4       0.39      0.42      0.41       210\n",
      "           5       0.43      0.40      0.42       210\n",
      "           6       0.34      0.33      0.34       210\n",
      "           7       0.64      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  16   4  24  36  18   6]\n",
      " [ 16 105  13  26  16  23  11]\n",
      " [  3  13 155  15   8  14   2]\n",
      " [ 14  23  10  86  30  34  13]\n",
      " [ 42  20   7  29  83  19  10]\n",
      " [ 23  26   7  32  11  74  37]\n",
      " [  4   4   2  22   6  43 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.50      0.51       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.37      0.41      0.39       210\n",
      "           5       0.44      0.40      0.42       210\n",
      "           6       0.33      0.35      0.34       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109  19   6  15  39  16   6]\n",
      " [ 14 108  12  25  22  22   7]\n",
      " [  3  17 156  13   8  11   2]\n",
      " [ 15  26  10  86  29  32  12]\n",
      " [ 40  18   6  31  87  18  10]\n",
      " [ 21  25  11  36  14  69  34]\n",
      " [ 13   7   2  16   8  39 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.52      0.51       210\n",
      "           2       0.49      0.51      0.50       210\n",
      "           3       0.77      0.74      0.76       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.42      0.41      0.42       210\n",
      "           6       0.33      0.33      0.33       210\n",
      "           7       0.64      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  17   5  18  39  17   4]\n",
      " [ 15 103  13  29  17  25   8]\n",
      " [  4  11 158  12   8  13   4]\n",
      " [ 14  24   8  87  31  35  11]\n",
      " [ 46  18   5  26  82  22  11]\n",
      " [ 21  25   7  32  20  75  30]\n",
      " [  8   6   0  17   9  46 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.52      0.51       210\n",
      "           2       0.50      0.49      0.50       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.40      0.39      0.39       210\n",
      "           6       0.32      0.36      0.34       210\n",
      "           7       0.65      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.51      1470\n",
      "weighted avg       0.51      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  15   5  20  37  21   5]\n",
      " [ 11 105  13  31  17  23  10]\n",
      " [  3  11 154  16   8  16   2]\n",
      " [ 13  22  10  88  31  34  12]\n",
      " [ 39  18   6  34  83  20  10]\n",
      " [ 18  27  11  35  13  75  31]\n",
      " [  7   7   0  14  12  40 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.52       210\n",
      "           2       0.51      0.50      0.51       210\n",
      "           3       0.77      0.73      0.75       210\n",
      "           4       0.37      0.42      0.39       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.33      0.36      0.34       210\n",
      "           7       0.65      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.51      1470\n",
      "weighted avg       0.51      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44421768707482995\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 46  12  40   1  74   0  37]\n",
      " [  2  65  49   8  49   0  37]\n",
      " [  3  18 181   0   4   0   4]\n",
      " [  2  13  29  25  86   0  55]\n",
      " [  4  12  10   5 131   0  48]\n",
      " [  2   9  31  10  26   0 132]\n",
      " [  0   0   2   0   3   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.22      0.34       210\n",
      "           2       0.50      0.31      0.38       210\n",
      "           3       0.53      0.86      0.66       210\n",
      "           4       0.51      0.12      0.19       210\n",
      "           5       0.35      0.62      0.45       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.98      0.56       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.37      1470\n",
      "weighted avg       0.44      0.44      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.49183673469387756\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95   8   8   0  67   2  30]\n",
      " [  5  89  24   2  58   3  29]\n",
      " [ 10  24 164   0   8   1   3]\n",
      " [  4  17  14  20  99   1  55]\n",
      " [  8  10   1   1 148   0  42]\n",
      " [ 12  22  13   7  29   2 125]\n",
      " [  0   0   0   0   5   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.45      0.55       210\n",
      "           2       0.52      0.42      0.47       210\n",
      "           3       0.73      0.78      0.76       210\n",
      "           4       0.67      0.10      0.17       210\n",
      "           5       0.36      0.70      0.47       210\n",
      "           6       0.22      0.01      0.02       210\n",
      "           7       0.42      0.98      0.59       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.52      0.49      0.43      1470\n",
      "weighted avg       0.52      0.49      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  16   2   2  51   2  28]\n",
      " [  2 144   8   5  27   2  22]\n",
      " [  4  39 160   2   3   0   2]\n",
      " [  5  39  10  36  67   7  46]\n",
      " [ 17  14   1   4 136   2  36]\n",
      " [  9  48   5  12  16   7 113]\n",
      " [  0   0   0   0   5   2 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.52      0.61       210\n",
      "           2       0.48      0.69      0.56       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.59      0.17      0.27       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.32      0.03      0.06       210\n",
      "           7       0.45      0.97      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.49      1470\n",
      "weighted avg       0.56      0.54      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5789115646258504\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113  14   1   1  51   9  21]\n",
      " [  1 151   3   5  28   7  15]\n",
      " [  1  43 160   3   2   0   1]\n",
      " [  2  37   7  65  52  11  36]\n",
      " [ 16  19   0   7 133   9  26]\n",
      " [  9  35   7  17  18  28  96]\n",
      " [  0   1   0   0   4   4 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.54      0.64       210\n",
      "           2       0.50      0.72      0.59       210\n",
      "           3       0.90      0.76      0.82       210\n",
      "           4       0.66      0.31      0.42       210\n",
      "           5       0.46      0.63      0.53       210\n",
      "           6       0.41      0.13      0.20       210\n",
      "           7       0.51      0.96      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.55      1470\n",
      "weighted avg       0.61      0.58      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115  11   0   7  46  18  13]\n",
      " [  1 144   3  11  26  16   9]\n",
      " [  1  42 160   4   1   2   0]\n",
      " [  1  27   6  88  40  25  23]\n",
      " [ 14  12   0  18 132  12  22]\n",
      " [ 10  29   3  25  11  44  88]\n",
      " [  0   1   0   0   5   5 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.55      0.65       210\n",
      "           2       0.54      0.69      0.61       210\n",
      "           3       0.93      0.76      0.84       210\n",
      "           4       0.58      0.42      0.48       210\n",
      "           5       0.51      0.63      0.56       210\n",
      "           6       0.36      0.21      0.27       210\n",
      "           7       0.56      0.95      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112   7   1   8  53  16  13]\n",
      " [  1 154   1  12  17  19   6]\n",
      " [  1  34 166   7   1   0   1]\n",
      " [  1  23   3 101  35  32  15]\n",
      " [  9  10   0  17 144  14  16]\n",
      " [  9  28   4  21  12  58  78]\n",
      " [  0   2   0   1   2   7 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.53      0.65       210\n",
      "           2       0.60      0.73      0.66       210\n",
      "           3       0.95      0.79      0.86       210\n",
      "           4       0.60      0.48      0.54       210\n",
      "           5       0.55      0.69      0.61       210\n",
      "           6       0.40      0.28      0.33       210\n",
      "           7       0.61      0.94      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115  12   1   5  45  22  10]\n",
      " [  1 149   1  11  20  22   6]\n",
      " [  1  26 171   4   5   3   0]\n",
      " [  2  23   3 103  36  27  16]\n",
      " [  9  14   0  19 140  14  14]\n",
      " [  7  23   4  21  15  73  67]\n",
      " [  0   0   0   1   3  12 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.55      0.67       210\n",
      "           2       0.60      0.71      0.65       210\n",
      "           3       0.95      0.81      0.88       210\n",
      "           4       0.63      0.49      0.55       210\n",
      "           5       0.53      0.67      0.59       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.63      0.92      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   8   3   5  51  19   9]\n",
      " [  3 147   1  16  17  23   3]\n",
      " [  0  26 170   6   2   6   0]\n",
      " [  2  25   4 104  31  35   9]\n",
      " [ 11  17   0  19 139  11  13]\n",
      " [  6  16   7  28   8  82  63]\n",
      " [  0   2   0   0   3   9 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.55      0.66       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.92      0.81      0.86       210\n",
      "           4       0.58      0.50      0.54       210\n",
      "           5       0.55      0.66      0.60       210\n",
      "           6       0.44      0.39      0.42       210\n",
      "           7       0.67      0.93      0.78       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   6   3   8  46  18   7]\n",
      " [  1 150   2  14  17  21   5]\n",
      " [  1  23 172   5   5   3   1]\n",
      " [  1  22   3 109  28  35  12]\n",
      " [ 10  15   0  20 137  18  10]\n",
      " [  7  20   7  22   8  87  59]\n",
      " [  0   0   0   0   2  14 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.64      0.71      0.67       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.61      0.52      0.56       210\n",
      "           5       0.56      0.65      0.60       210\n",
      "           6       0.44      0.41      0.43       210\n",
      "           7       0.67      0.92      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   5   3   5  47  21   6]\n",
      " [  1 146   1  18  21  18   5]\n",
      " [  1  25 173   6   2   3   0]\n",
      " [  1  22   6 105  31  37   8]\n",
      " [ 10  15   0  26 134  14  11]\n",
      " [  7  18   6  27  11  80  61]\n",
      " [  0   1   0   1   2   8 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.63      0.70      0.66       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.54      0.64      0.59       210\n",
      "           6       0.44      0.38      0.41       210\n",
      "           7       0.69      0.94      0.79       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   5   3   8  45  20   5]\n",
      " [  3 146   3  11  18  26   3]\n",
      " [  2  25 172   1   4   5   1]\n",
      " [  2  16   6 118  27  29  12]\n",
      " [ 12  14   0  27 139   9   9]\n",
      " [  9  19   4  24   7  87  60]\n",
      " [  0   0   0   0   2  12 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.91      0.82      0.86       210\n",
      "           4       0.62      0.56      0.59       210\n",
      "           5       0.57      0.66      0.62       210\n",
      "           6       0.46      0.41      0.44       210\n",
      "           7       0.69      0.93      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.66      1470\n",
      "weighted avg       0.68      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   5   2   7  46  19   4]\n",
      " [  3 152   2  17  16  15   5]\n",
      " [  1  24 177   6   1   1   0]\n",
      " [  2  18   6 111  30  32  11]\n",
      " [ 13  13   0  19 144  15   6]\n",
      " [  9  16   4  24  15  83  59]\n",
      " [  0   0   0   0   3  15 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.67      0.72      0.69       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.60      0.53      0.56       210\n",
      "           5       0.56      0.69      0.62       210\n",
      "           6       0.46      0.40      0.43       210\n",
      "           7       0.69      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   7   3   4  42  20   5]\n",
      " [  1 146   2  15  21  20   5]\n",
      " [  0  19 177   6   4   4   0]\n",
      " [  4  24   5 100  31  39   7]\n",
      " [ 13  15   0  16 142  12  12]\n",
      " [  6  15   5  25   9  96  54]\n",
      " [  0   0   0   0   3  11 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.61      0.71       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.60      0.48      0.53       210\n",
      "           5       0.56      0.68      0.61       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.70      0.93      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   3   7  43  15   6]\n",
      " [  1 145   2  15  18  26   3]\n",
      " [  1  15 181   8   2   2   1]\n",
      " [  2  21   4 111  30  35   7]\n",
      " [ 10  14   0  24 139  14   9]\n",
      " [  5  21   7  25  10  97  45]\n",
      " [  0   1   0   0   3  11 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.62      0.73       210\n",
      "           2       0.65      0.69      0.67       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.58      0.53      0.55       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.73      0.93      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   3   4  48  15   6]\n",
      " [  1 152   3  18  10  22   4]\n",
      " [  1  19 176   3   3   8   0]\n",
      " [  3  21   5 111  28  32  10]\n",
      " [ 11  19   0  23 136  13   8]\n",
      " [  8  15   7  29   5  95  51]\n",
      " [  0   0   0   0   3  15 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.61      0.71       210\n",
      "           2       0.66      0.72      0.69       210\n",
      "           3       0.91      0.84      0.87       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.58      0.65      0.61       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.71      0.91      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   4   4   9  44  16   5]\n",
      " [  1 149   3  13  17  22   5]\n",
      " [  1  17 179   4   3   6   0]\n",
      " [  4  17   5 118  26  36   4]\n",
      " [ 21  16   0  19 134  10  10]\n",
      " [ 10  16   7  25   7  90  55]\n",
      " [  1   0   0   0   1  19 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.61      0.68       210\n",
      "           2       0.68      0.71      0.69       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.45      0.43      0.44       210\n",
      "           7       0.71      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   6   3   7  44  17   6]\n",
      " [  1 147   3  17  17  21   4]\n",
      " [  0  18 181   4   1   6   0]\n",
      " [  2  18   4 116  27  32  11]\n",
      " [ 17  15   0  21 133  16   8]\n",
      " [  7  15   6  19  10  97  56]\n",
      " [  0   0   0   0   1  21 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.67      0.70      0.69       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.46      0.46      0.46       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   5   4   6  40  18   4]\n",
      " [  1 153   2  18  16  17   3]\n",
      " [  0  20 180   7   1   2   0]\n",
      " [  2  17   7 111  30  32  11]\n",
      " [ 14  13   0  21 139  12  11]\n",
      " [  8  19   4  26   6  92  55]\n",
      " [  1   2   0   0   2  17 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.63      0.72       210\n",
      "           2       0.67      0.73      0.70       210\n",
      "           3       0.91      0.86      0.88       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.59      0.66      0.63       210\n",
      "           6       0.48      0.44      0.46       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   5   5   6  34  18   6]\n",
      " [  2 152   2  14  15  22   3]\n",
      " [  0  21 179   4   1   5   0]\n",
      " [  1  22   3 108  33  34   9]\n",
      " [ 19  16   0  21 133  11  10]\n",
      " [  7  17   6  23   8  96  53]\n",
      " [  0   0   0   0   3  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.65      0.73       210\n",
      "           2       0.65      0.72      0.69       210\n",
      "           3       0.92      0.85      0.88       210\n",
      "           4       0.61      0.51      0.56       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.47      0.46      0.46       210\n",
      "           7       0.70      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   5   3   7  35  15   8]\n",
      " [  1 154   2  16  14  19   4]\n",
      " [  0  21 179   5   1   4   0]\n",
      " [  2  24   3 107  32  33   9]\n",
      " [ 18  14   0  22 134  14   8]\n",
      " [  8  20   3  23   6  94  56]\n",
      " [  0   1   0   0   2  16 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.65      0.73       210\n",
      "           2       0.64      0.73      0.69       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.59      0.51      0.55       210\n",
      "           5       0.60      0.64      0.62       210\n",
      "           6       0.48      0.45      0.46       210\n",
      "           7       0.69      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[103   5  17   3  38  25  19]\n",
      " [  3 103  28  13  27  25  11]\n",
      " [  5  21 160   5   8  11   0]\n",
      " [  4  14  10  83  40  34  25]\n",
      " [ 16  11   1   9 126  19  28]\n",
      " [ 13  24   9  34  12  48  70]\n",
      " [  1   4   0  12   8   7 178]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.49      0.58       210\n",
      "           2       0.57      0.49      0.53       210\n",
      "           3       0.71      0.76      0.74       210\n",
      "           4       0.52      0.40      0.45       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.54      0.85      0.66       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[108  19   7  11  36  12  17]\n",
      " [ 10 111  15  20  30  17   7]\n",
      " [  5  21 168   7   4   4   1]\n",
      " [ 14  23   9  90  30  23  21]\n",
      " [ 27  24   5  23 103  11  17]\n",
      " [ 15  32  10  30  21  52  50]\n",
      " [  3   5   0  20  11  30 141]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.51      0.55       210\n",
      "           2       0.47      0.53      0.50       210\n",
      "           3       0.79      0.80      0.79       210\n",
      "           4       0.45      0.43      0.44       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.35      0.25      0.29       210\n",
      "           7       0.56      0.67      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.52      1470\n",
      "weighted avg       0.52      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.42857142857142855\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  17   6  16  22   6  14]\n",
      " [ 31 115  15  11  19  10   9]\n",
      " [ 24  17 160   3   3   3   0]\n",
      " [ 55  28   3  68  41  10   5]\n",
      " [ 66  34   3  28  61   9   9]\n",
      " [ 65  34   8  38  23  18  24]\n",
      " [ 36  19   1  32  33  10  79]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.61      0.42       210\n",
      "           2       0.44      0.55      0.49       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.35      0.32      0.33       210\n",
      "           5       0.30      0.29      0.30       210\n",
      "           6       0.27      0.09      0.13       210\n",
      "           7       0.56      0.38      0.45       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.42      1470\n",
      "weighted avg       0.44      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[118  15   9  20  23   8  17]\n",
      " [ 29 108  15  12  22  16   8]\n",
      " [ 19  17 164   5   2   2   1]\n",
      " [ 41  23   4  68  46  16  12]\n",
      " [ 51  28   1  29  61  18  22]\n",
      " [ 61  29   6  28  26  28  32]\n",
      " [ 33  11   0  23  28  18  97]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.56      0.42       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.37      0.32      0.34       210\n",
      "           5       0.29      0.29      0.29       210\n",
      "           6       0.26      0.13      0.18       210\n",
      "           7       0.51      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.43      1470\n",
      "weighted avg       0.44      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4523809523809524\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[116  17   8  20  26   7  16]\n",
      " [ 18  99  17  21  31  15   9]\n",
      " [ 17  22 163   3   1   2   2]\n",
      " [ 26  22   6  76  55  12  13]\n",
      " [ 40  25   1  32  78  15  19]\n",
      " [ 51  28   5  29  36  33  28]\n",
      " [ 21   7   0  30  31  21 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.55      0.46       210\n",
      "           2       0.45      0.47      0.46       210\n",
      "           3       0.81      0.78      0.80       210\n",
      "           4       0.36      0.36      0.36       210\n",
      "           5       0.30      0.37      0.33       210\n",
      "           6       0.31      0.16      0.21       210\n",
      "           7       0.53      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.454421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114  20   7  21  27   5  16]\n",
      " [ 20 107  16  17  30  13   7]\n",
      " [ 19  22 162   2   0   3   2]\n",
      " [ 37  19   7  82  43   7  15]\n",
      " [ 46  22   2  32  79  11  18]\n",
      " [ 54  26   7  31  37  26  29]\n",
      " [ 17  12   0  27  40  16  98]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.54      0.44       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.31      0.38      0.34       210\n",
      "           6       0.32      0.12      0.18       210\n",
      "           7       0.53      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[115  19   6  18  30   5  17]\n",
      " [ 23 100  17  16  34  12   8]\n",
      " [ 18  20 162   4   2   2   2]\n",
      " [ 35  21   8  77  46   7  16]\n",
      " [ 41  21   3  27  87  14  17]\n",
      " [ 52  26   7  30  36  23  36]\n",
      " [ 16   8   0  31  37  15 103]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.55      0.45       210\n",
      "           2       0.47      0.48      0.47       210\n",
      "           3       0.80      0.77      0.78       210\n",
      "           4       0.38      0.37      0.37       210\n",
      "           5       0.32      0.41      0.36       210\n",
      "           6       0.29      0.11      0.16       210\n",
      "           7       0.52      0.49      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[108  17   6  22  35   6  16]\n",
      " [ 22 100  17  18  35  10   8]\n",
      " [ 17  20 161   5   3   1   3]\n",
      " [ 31  22   8  81  45   7  16]\n",
      " [ 43  24   4  27  87  10  15]\n",
      " [ 46  19   9  32  41  30  33]\n",
      " [ 16   7   0  23  33  20 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.51      0.44       210\n",
      "           2       0.48      0.48      0.48       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.31      0.41      0.36       210\n",
      "           6       0.36      0.14      0.20       210\n",
      "           7       0.55      0.53      0.54       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.41360544217687073\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 87  46   9  15  28   5  20]\n",
      " [ 13 114  25  16  23   7  12]\n",
      " [ 15  44 146   2   2   0   1]\n",
      " [ 18  48   5  52  31  21  35]\n",
      " [ 22  47   3  20  77   8  33]\n",
      " [ 20  65   1  26  28  20  50]\n",
      " [ 14  15   0  27  20  22 112]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.41      0.44       210\n",
      "           2       0.30      0.54      0.39       210\n",
      "           3       0.77      0.70      0.73       210\n",
      "           4       0.33      0.25      0.28       210\n",
      "           5       0.37      0.37      0.37       210\n",
      "           6       0.24      0.10      0.14       210\n",
      "           7       0.43      0.53      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.40      1470\n",
      "weighted avg       0.41      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.3986394557823129\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 84  52   6  15  27   5  21]\n",
      " [ 14 112  24  18  20   6  16]\n",
      " [ 18  52 135   2   2   0   1]\n",
      " [ 18  52   5  49  32  19  35]\n",
      " [ 21  47   3  20  80   6  33]\n",
      " [ 25  67   0  26  25  17  50]\n",
      " [ 14  22   0  24  22  19 109]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.40      0.42       210\n",
      "           2       0.28      0.53      0.36       210\n",
      "           3       0.78      0.64      0.70       210\n",
      "           4       0.32      0.23      0.27       210\n",
      "           5       0.38      0.38      0.38       210\n",
      "           6       0.24      0.08      0.12       210\n",
      "           7       0.41      0.52      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.39      1470\n",
      "weighted avg       0.41      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of SVM is:\n",
      " [[106  18   4  14  37  14  17]\n",
      " [  8 114  11  24  31  19   3]\n",
      " [  3  23 170   6   3   4   1]\n",
      " [ 13  18   6  96  29  31  17]\n",
      " [ 27  25   3  26  99  11  19]\n",
      " [ 16  25   7  40  22  57  43]\n",
      " [  5   5   0  19  11  40 130]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.50      0.55       210\n",
      "           2       0.50      0.54      0.52       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.43      0.46      0.44       210\n",
      "           5       0.43      0.47      0.45       210\n",
      "           6       0.32      0.27      0.30       210\n",
      "           7       0.57      0.62      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of SVM is:\n",
      " [[108  25   4  13  31  13  16]\n",
      " [  6 118   8  22  27  24   5]\n",
      " [  4  24 165   7   2   8   0]\n",
      " [  8  22   7  99  35  27  12]\n",
      " [ 22  26   4  29 100  16  13]\n",
      " [ 11  29   4  31  22  68  45]\n",
      " [  3   4   0  17  16  41 129]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.51      0.58       210\n",
      "           2       0.48      0.56      0.52       210\n",
      "           3       0.86      0.79      0.82       210\n",
      "           4       0.45      0.47      0.46       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.35      0.32      0.33       210\n",
      "           7       0.59      0.61      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of SVM is:\n",
      " [[109  20   4  12  36  12  17]\n",
      " [  7 116  11  24  28  21   3]\n",
      " [  4  26 165   6   2   6   1]\n",
      " [ 13  20   7 100  28  27  15]\n",
      " [ 23  24   3  28 104  11  17]\n",
      " [ 12  26   6  34  25  63  44]\n",
      " [  3   3   0  22  14  38 130]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.52      0.57       210\n",
      "           2       0.49      0.55      0.52       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.44      0.48      0.46       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.57      0.62      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of SVM is:\n",
      " [[105  20   5  11  38  14  17]\n",
      " [  9 112  11  23  33  17   5]\n",
      " [  5  24 169   6   2   3   1]\n",
      " [ 12  18   7  94  31  29  19]\n",
      " [ 25  28   3  23 103  10  18]\n",
      " [ 17  27   6  38  25  51  46]\n",
      " [  4   6   0  22  12  32 134]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.50      0.54       210\n",
      "           2       0.48      0.53      0.50       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.43      0.45      0.44       210\n",
      "           5       0.42      0.49      0.45       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.56      0.64      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.21496598639455783\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0   0   0 197]\n",
      " [  0   0  12   0   0   0 198]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   2   0   0   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.51      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.99      0.27       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.13      0.21      0.13      1470\n",
      "weighted avg       0.13      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2612244897959184\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  9  75   4   0   0   0 122]\n",
      " [  6  88   6   0   0   0 110]\n",
      " [  1  63 107   0   0   0  39]\n",
      " [  2  54   1   0   0   0 153]\n",
      " [  1  49   2   0   0   0 158]\n",
      " [  3  54   2   0   0   0 151]\n",
      " [  1  28   1   0   0   0 180]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.04      0.08       210\n",
      "           2       0.21      0.42      0.28       210\n",
      "           3       0.87      0.51      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.86      0.32       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.24      0.26      0.19      1470\n",
      "weighted avg       0.24      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.30680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 46  36   6  55   0   0  67]\n",
      " [ 12  78  10  69   0   0  41]\n",
      " [  6  57 108  23   0   0  16]\n",
      " [ 11  43   3  92   0   0  61]\n",
      " [ 20  29   3  79   0   0  79]\n",
      " [ 19  35   5  74   0   0  77]\n",
      " [ 13  15   2  53   0   0 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.22      0.27       210\n",
      "           2       0.27      0.37      0.31       210\n",
      "           3       0.79      0.51      0.62       210\n",
      "           4       0.21      0.44      0.28       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.27      0.60      0.37       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.27      0.31      0.27      1470\n",
      "weighted avg       0.27      0.31      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3346938775510204\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 47   8  30  55  16   0  54]\n",
      " [  3  53  35  69  10   0  40]\n",
      " [  1   9 159  20   5   0  16]\n",
      " [  1  11  36  91  10   0  61]\n",
      " [  4  12  20  79  16   0  79]\n",
      " [  5  12  28  74  14   0  77]\n",
      " [  1   1  16  53  13   0 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.22      0.35       210\n",
      "           2       0.50      0.25      0.34       210\n",
      "           3       0.49      0.76      0.60       210\n",
      "           4       0.21      0.43      0.28       210\n",
      "           5       0.19      0.08      0.11       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.28      0.60      0.38       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.35      0.33      0.29      1470\n",
      "weighted avg       0.35      0.33      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.33877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60   8   6  42   4  23  67]\n",
      " [ 13  54  14  58   4  16  51]\n",
      " [  5   9 147  20   2  11  16]\n",
      " [  8  11   5  64   4  29  89]\n",
      " [ 12  12   5  57   9  14 101]\n",
      " [ 12  13   9  58   8  17  93]\n",
      " [ 11   1   3  32   3  13 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.29      0.36       210\n",
      "           2       0.50      0.26      0.34       210\n",
      "           3       0.78      0.70      0.74       210\n",
      "           4       0.19      0.30      0.24       210\n",
      "           5       0.26      0.04      0.07       210\n",
      "           6       0.14      0.08      0.10       210\n",
      "           7       0.26      0.70      0.38       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.38      0.34      0.32      1470\n",
      "weighted avg       0.38      0.34      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  26   3  73  13   0  28]\n",
      " [ 18  65   8  88   9   0  22]\n",
      " [ 11  28 135  27   0   0   9]\n",
      " [ 17  28   4  97  14   0  50]\n",
      " [ 20  17   4  99  21   1  48]\n",
      " [ 25  24   5  79   8   0  69]\n",
      " [ 10  14   2  67  12   0 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.32      0.35       210\n",
      "           2       0.32      0.31      0.32       210\n",
      "           3       0.84      0.64      0.73       210\n",
      "           4       0.18      0.46      0.26       210\n",
      "           5       0.27      0.10      0.15       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.50      0.39       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.33      0.33      0.31      1470\n",
      "weighted avg       0.33      0.33      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  30   4  49  19  23  20]\n",
      " [ 13  86   9  56  13  18  15]\n",
      " [  4  33 142  15   4   7   5]\n",
      " [ 11  39   3  77  21  27  32]\n",
      " [ 16  42   4  72  25  13  38]\n",
      " [ 15  39   6  61  22  17  50]\n",
      " [ 12  19   2  46  20  16  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.31      0.38       210\n",
      "           2       0.30      0.41      0.35       210\n",
      "           3       0.84      0.68      0.75       210\n",
      "           4       0.20      0.37      0.26       210\n",
      "           5       0.20      0.12      0.15       210\n",
      "           6       0.14      0.08      0.10       210\n",
      "           7       0.37      0.45      0.41       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.36      0.34      0.34      1470\n",
      "weighted avg       0.36      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  34   3  45  28  22   8]\n",
      " [ 15  74   5  56  29  23   8]\n",
      " [ 14  16 140  23   9   6   2]\n",
      " [ 13  29   4  93  32  16  23]\n",
      " [ 19  23   3  67  53  28  17]\n",
      " [ 23  38   3  73  19  24  30]\n",
      " [  9  13   2  63  18  46  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.33      0.38       210\n",
      "           2       0.33      0.35      0.34       210\n",
      "           3       0.88      0.67      0.76       210\n",
      "           4       0.22      0.44      0.30       210\n",
      "           5       0.28      0.25      0.27       210\n",
      "           6       0.15      0.11      0.13       210\n",
      "           7       0.40      0.28      0.33       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.38      0.35      0.36      1470\n",
      "weighted avg       0.38      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  31   5  39  27  16  15]\n",
      " [ 12  79   9  53  25  20  12]\n",
      " [ 10  15 140  23  13   5   4]\n",
      " [ 13  29   5  85  35  18  25]\n",
      " [ 18  26   4  62  55  23  22]\n",
      " [ 15  37   6  68  28  18  38]\n",
      " [ 24  13   2  60  17  18  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.37      0.41       210\n",
      "           2       0.34      0.38      0.36       210\n",
      "           3       0.82      0.67      0.73       210\n",
      "           4       0.22      0.40      0.28       210\n",
      "           5       0.28      0.26      0.27       210\n",
      "           6       0.15      0.09      0.11       210\n",
      "           7       0.40      0.36      0.38       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.36      1470\n",
      "weighted avg       0.38      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  35   3  31  33  17  18]\n",
      " [ 14  70  11  46  36  22  11]\n",
      " [  6  14 144  17  13  13   3]\n",
      " [ 15  34   5  63  46  20  27]\n",
      " [ 20  29   5  42  67  26  21]\n",
      " [ 13  37   5  42  44  32  37]\n",
      " [ 17  16   3  31  42  28  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.35      0.40       210\n",
      "           2       0.30      0.33      0.31       210\n",
      "           3       0.82      0.69      0.75       210\n",
      "           4       0.23      0.30      0.26       210\n",
      "           5       0.24      0.32      0.27       210\n",
      "           6       0.20      0.15      0.17       210\n",
      "           7       0.38      0.35      0.36       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.36      1470\n",
      "weighted avg       0.38      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  23   4  29  26  37  10]\n",
      " [ 19  66   8  48  24  35  10]\n",
      " [ 14   9 144  17  10  14   2]\n",
      " [ 31  34   5  65  30  27  18]\n",
      " [ 30  26   3  37  58  38  18]\n",
      " [ 23  28   4  39  37  49  30]\n",
      " [ 22  17   3  31  37  44  56]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.39      0.38       210\n",
      "           2       0.33      0.31      0.32       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.24      0.31      0.27       210\n",
      "           5       0.26      0.28      0.27       210\n",
      "           6       0.20      0.23      0.22       210\n",
      "           7       0.39      0.27      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.38      0.35      0.36      1470\n",
      "weighted avg       0.38      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36666666666666664\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  18   7  29  24  19  22]\n",
      " [ 17  65  13  44  30  27  14]\n",
      " [  9   9 149  18   7  13   5]\n",
      " [ 35  24  10  62  27  23  29]\n",
      " [ 30  19   9  36  52  41  23]\n",
      " [ 24  23  12  42  33  43  33]\n",
      " [ 19  12   7  30  33  32  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.43      0.42       210\n",
      "           2       0.38      0.31      0.34       210\n",
      "           3       0.72      0.71      0.71       210\n",
      "           4       0.24      0.30      0.26       210\n",
      "           5       0.25      0.25      0.25       210\n",
      "           6       0.22      0.20      0.21       210\n",
      "           7       0.38      0.37      0.37       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.37      0.37      0.37      1470\n",
      "weighted avg       0.37      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  23   6  20  23  24  19]\n",
      " [ 15  79  16  34  25  25  16]\n",
      " [ 10  16 143  13  10  15   3]\n",
      " [ 46  34  10  42  34  18  26]\n",
      " [ 33  37  10  21  49  39  21]\n",
      " [ 26  27   9  29  34  46  39]\n",
      " [ 24  23   5  20  26  36  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.45      0.41       210\n",
      "           2       0.33      0.38      0.35       210\n",
      "           3       0.72      0.68      0.70       210\n",
      "           4       0.23      0.20      0.22       210\n",
      "           5       0.24      0.23      0.24       210\n",
      "           6       0.23      0.22      0.22       210\n",
      "           7       0.38      0.36      0.37       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  19   6  35  24  23  18]\n",
      " [ 14  75  22  40  24  24  11]\n",
      " [ 15  14 147  15   8   9   2]\n",
      " [ 30  28   9  68  31  22  22]\n",
      " [ 31  31  12  33  49  36  18]\n",
      " [ 20  26   7  46  38  38  35]\n",
      " [ 24  18   5  45  32  30  56]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.40       210\n",
      "           2       0.36      0.36      0.36       210\n",
      "           3       0.71      0.70      0.70       210\n",
      "           4       0.24      0.32      0.28       210\n",
      "           5       0.24      0.23      0.24       210\n",
      "           6       0.21      0.18      0.19       210\n",
      "           7       0.35      0.27      0.30       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35578231292517004\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  28   4  30  20  18  19]\n",
      " [ 17  69  16  34  34  29  11]\n",
      " [  8  13 148  15  14  10   2]\n",
      " [ 26  30  12  52  38  30  22]\n",
      " [ 27  29   9  27  58  37  23]\n",
      " [ 24  22  10  40  38  45  31]\n",
      " [ 22  21   8  31  24  44  60]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.43      0.43       210\n",
      "           2       0.33      0.33      0.33       210\n",
      "           3       0.71      0.70      0.71       210\n",
      "           4       0.23      0.25      0.24       210\n",
      "           5       0.26      0.28      0.27       210\n",
      "           6       0.21      0.21      0.21       210\n",
      "           7       0.36      0.29      0.32       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88  21   4  27  22  24  24]\n",
      " [ 16  74   8  35  28  36  13]\n",
      " [  9  12 147  12   8  19   3]\n",
      " [ 38  25  12  41  33  33  28]\n",
      " [ 29  29  12  26  46  44  24]\n",
      " [ 21  26   9  31  38  51  34]\n",
      " [ 25  22   6  23  29  42  63]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.42      0.40       210\n",
      "           2       0.35      0.35      0.35       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.21      0.20      0.20       210\n",
      "           5       0.23      0.22      0.22       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.33      0.30      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  19   6  28  24  23  18]\n",
      " [ 16  78  13  22  32  36  13]\n",
      " [  9  10 144  15  13  15   4]\n",
      " [ 41  24  12  47  36  27  23]\n",
      " [ 28  32  12  30  47  39  22]\n",
      " [ 22  21  11  38  36  50  32]\n",
      " [ 27  25   9  22  31  35  61]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.44      0.41       210\n",
      "           2       0.37      0.37      0.37       210\n",
      "           3       0.70      0.69      0.69       210\n",
      "           4       0.23      0.22      0.23       210\n",
      "           5       0.21      0.22      0.22       210\n",
      "           6       0.22      0.24      0.23       210\n",
      "           7       0.35      0.29      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  19   5  23  23  27  21]\n",
      " [ 20  68  19  28  28  31  16]\n",
      " [ 10  11 146  10  10  18   5]\n",
      " [ 46  29  12  42  28  26  27]\n",
      " [ 28  28   9  33  54  39  19]\n",
      " [ 20  27   9  24  41  54  35]\n",
      " [ 32  18   8  18  34  41  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.44      0.40       210\n",
      "           2       0.34      0.32      0.33       210\n",
      "           3       0.70      0.70      0.70       210\n",
      "           4       0.24      0.20      0.22       210\n",
      "           5       0.25      0.26      0.25       210\n",
      "           6       0.23      0.26      0.24       210\n",
      "           7       0.32      0.28      0.30       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34965986394557824\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 90  20   9  20  24  27  20]\n",
      " [ 18  69  18  30  29  32  14]\n",
      " [  8  14 147  15  11  12   3]\n",
      " [ 38  27  17  46  29  23  30]\n",
      " [ 30  32  13  27  51  37  20]\n",
      " [ 21  27  10  31  36  48  37]\n",
      " [ 27  16  10  23  31  40  63]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.43      0.41       210\n",
      "           2       0.34      0.33      0.33       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.24      0.22      0.23       210\n",
      "           5       0.24      0.24      0.24       210\n",
      "           6       0.22      0.23      0.22       210\n",
      "           7       0.34      0.30      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35374149659863946\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  20   7  23  17  29  23]\n",
      " [ 21  71  16  29  33  30  10]\n",
      " [ 10  15 144  12   6  18   5]\n",
      " [ 35  29  17  48  34  19  28]\n",
      " [ 31  27  11  24  50  43  24]\n",
      " [ 25  22  11  27  35  53  37]\n",
      " [ 25  18  13  22  26  43  63]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.43      0.41       210\n",
      "           2       0.35      0.34      0.34       210\n",
      "           3       0.66      0.69      0.67       210\n",
      "           4       0.26      0.23      0.24       210\n",
      "           5       0.25      0.24      0.24       210\n",
      "           6       0.23      0.25      0.24       210\n",
      "           7       0.33      0.30      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.35      0.35      0.35      1470\n",
      "weighted avg       0.35      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.29863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 34  16  21  14   4   2 119]\n",
      " [ 10  26  46   9  15   4 100]\n",
      " [  4  11 161   9   2   1  22]\n",
      " [  4   8  14  13   8   3 160]\n",
      " [  3   5  13   6  10   1 172]\n",
      " [  8   4  25  16   6   4 147]\n",
      " [  7   1   0   3   7   1 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.16      0.24       210\n",
      "           2       0.37      0.12      0.19       210\n",
      "           3       0.57      0.77      0.66       210\n",
      "           4       0.19      0.06      0.09       210\n",
      "           5       0.19      0.05      0.08       210\n",
      "           6       0.25      0.02      0.04       210\n",
      "           7       0.21      0.91      0.34       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.23      1470\n",
      "weighted avg       0.32      0.30      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3414965986394558\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 58  50  11  10   4   0  77]\n",
      " [ 14  92  24   6  15   2  57]\n",
      " [ 12  43 143   1   1   2   8]\n",
      " [ 19  48   7  15   9   1 111]\n",
      " [ 15  31   6   5  12   1 140]\n",
      " [ 14  50   9   8  11   4 114]\n",
      " [  7  15   0   7   1   2 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.28      0.33       210\n",
      "           2       0.28      0.44      0.34       210\n",
      "           3       0.71      0.68      0.70       210\n",
      "           4       0.29      0.07      0.11       210\n",
      "           5       0.23      0.06      0.09       210\n",
      "           6       0.33      0.02      0.04       210\n",
      "           7       0.26      0.85      0.40       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.36      0.34      0.29      1470\n",
      "weighted avg       0.36      0.34      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3625850340136054\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 60  66   7   9  10   2  56]\n",
      " [ 10 122  12  14  10   3  39]\n",
      " [ 10  45 144   4   2   1   4]\n",
      " [  8  63   5  28  14   5  87]\n",
      " [ 17  51   3  13  18   0 108]\n",
      " [ 15  67   3  18  11   6  90]\n",
      " [  5  33   0  10   5   2 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.29      0.36       210\n",
      "           2       0.27      0.58      0.37       210\n",
      "           3       0.83      0.69      0.75       210\n",
      "           4       0.29      0.13      0.18       210\n",
      "           5       0.26      0.09      0.13       210\n",
      "           6       0.32      0.03      0.05       210\n",
      "           7       0.29      0.74      0.41       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.39      0.36      0.32      1470\n",
      "weighted avg       0.39      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4095238095238095\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 80  46   6  14  20   3  41]\n",
      " [  8 126   9  12  24   6  25]\n",
      " [  5  53 143   0   4   3   2]\n",
      " [  9  56   3  44  33   3  62]\n",
      " [ 14  43   3  24  59   0  67]\n",
      " [ 11  71   5  25  18   5  75]\n",
      " [  6  25   0  18  12   4 145]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.38      0.47       210\n",
      "           2       0.30      0.60      0.40       210\n",
      "           3       0.85      0.68      0.75       210\n",
      "           4       0.32      0.21      0.25       210\n",
      "           5       0.35      0.28      0.31       210\n",
      "           6       0.21      0.02      0.04       210\n",
      "           7       0.35      0.69      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.38      1470\n",
      "weighted avg       0.42      0.41      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41496598639455784\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 72  49   5  19  26   3  36]\n",
      " [  5 124  12  18  23   5  23]\n",
      " [  6  47 147   4   3   0   3]\n",
      " [  7  55   4  47  30  10  57]\n",
      " [ 15  51   0  19  72   3  50]\n",
      " [ 12  60   2  21  28  15  72]\n",
      " [  5  15   0  28  18  11 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.34      0.43       210\n",
      "           2       0.31      0.59      0.41       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.30      0.22      0.26       210\n",
      "           5       0.36      0.34      0.35       210\n",
      "           6       0.32      0.07      0.12       210\n",
      "           7       0.36      0.63      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.40      1470\n",
      "weighted avg       0.44      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 73  42   8  18  37   6  26]\n",
      " [  3 125   9  25  24   6  18]\n",
      " [  5  45 144   6   2   6   2]\n",
      " [ 10  45   1  62  34   9  49]\n",
      " [ 15  39   2  30  85   1  38]\n",
      " [ 12  47   2  40  35  21  53]\n",
      " [  5  11   0  33  21   9 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.35      0.44       210\n",
      "           2       0.35      0.60      0.44       210\n",
      "           3       0.87      0.69      0.77       210\n",
      "           4       0.29      0.30      0.29       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.36      0.10      0.16       210\n",
      "           7       0.41      0.62      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.42      1470\n",
      "weighted avg       0.46      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77  43   5  19  32   7  27]\n",
      " [  4 111  11  27  30  10  17]\n",
      " [  7  45 143   8   3   2   2]\n",
      " [  8  36   5  67  38  16  40]\n",
      " [ 11  35   2  24  94   5  39]\n",
      " [  7  43   0  41  31  28  60]\n",
      " [  6   6   0  31  24  13 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.37      0.47       210\n",
      "           2       0.35      0.53      0.42       210\n",
      "           3       0.86      0.68      0.76       210\n",
      "           4       0.31      0.32      0.31       210\n",
      "           5       0.37      0.45      0.41       210\n",
      "           6       0.35      0.13      0.19       210\n",
      "           7       0.41      0.62      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.44      1470\n",
      "weighted avg       0.47      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.454421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  35   4  20  38   7  23]\n",
      " [  2 122   9  23  35   9  10]\n",
      " [  8  41 146  10   2   1   2]\n",
      " [  7  32   5  64  41  22  39]\n",
      " [  9  38   2  27  89  10  35]\n",
      " [ 11  48   0  37  31  31  52]\n",
      " [  6   8   0  26  19  18 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.40      0.49       210\n",
      "           2       0.38      0.58      0.46       210\n",
      "           3       0.88      0.70      0.78       210\n",
      "           4       0.31      0.30      0.31       210\n",
      "           5       0.35      0.42      0.38       210\n",
      "           6       0.32      0.15      0.20       210\n",
      "           7       0.45      0.63      0.53       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.48      0.45      0.45      1470\n",
      "weighted avg       0.48      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 88  19   6  33  35   7  22]\n",
      " [  6 115   9  33  25  10  12]\n",
      " [  6  38 145  12   2   3   4]\n",
      " [ 11  29   5  60  39  29  37]\n",
      " [ 17  28   1  29  92   8  35]\n",
      " [ 15  40   0  41  26  35  53]\n",
      " [  3   9   0  23  23  25 127]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.42      0.49       210\n",
      "           2       0.41      0.55      0.47       210\n",
      "           3       0.87      0.69      0.77       210\n",
      "           4       0.26      0.29      0.27       210\n",
      "           5       0.38      0.44      0.41       210\n",
      "           6       0.30      0.17      0.21       210\n",
      "           7       0.44      0.60      0.51       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.45      1470\n",
      "weighted avg       0.47      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  29   7  20  29  16  19]\n",
      " [  6 115   8  30  26  16   9]\n",
      " [ 12  33 148   9   5   2   1]\n",
      " [  8  31   4  70  40  24  33]\n",
      " [ 14  32   1  25  90  11  37]\n",
      " [ 14  37   0  34  28  42  55]\n",
      " [  3   5   0  25  25  24 128]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.43      0.50       210\n",
      "           2       0.41      0.55      0.47       210\n",
      "           3       0.88      0.70      0.78       210\n",
      "           4       0.33      0.33      0.33       210\n",
      "           5       0.37      0.43      0.40       210\n",
      "           6       0.31      0.20      0.24       210\n",
      "           7       0.45      0.61      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45850340136054424\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  24   5  25  38  14  21]\n",
      " [  5 114   7  26  31  14  13]\n",
      " [ 13  29 149  10   3   5   1]\n",
      " [  9  24   6  76  39  27  29]\n",
      " [ 16  23   2  40  84  13  32]\n",
      " [ 12  30   5  42  29  38  54]\n",
      " [  8   6   0  28  18  20 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.40      0.47       210\n",
      "           2       0.46      0.54      0.50       210\n",
      "           3       0.86      0.71      0.78       210\n",
      "           4       0.31      0.36      0.33       210\n",
      "           5       0.35      0.40      0.37       210\n",
      "           6       0.29      0.18      0.22       210\n",
      "           7       0.46      0.62      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 88  29   6  23  32  15  17]\n",
      " [  4 115   8  27  28  16  12]\n",
      " [  3  26 156  11   5   8   1]\n",
      " [ 20  25   3  67  34  24  37]\n",
      " [ 18  33   2  34  78  18  27]\n",
      " [  8  39   2  31  29  50  51]\n",
      " [  7   7   0  23  23  22 128]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.42      0.49       210\n",
      "           2       0.42      0.55      0.48       210\n",
      "           3       0.88      0.74      0.81       210\n",
      "           4       0.31      0.32      0.31       210\n",
      "           5       0.34      0.37      0.36       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.47      0.61      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 86  28   8  26  32  12  18]\n",
      " [  6 116  11  25  24  14  14]\n",
      " [  6  27 157   8   4   6   2]\n",
      " [ 15  29   4  60  36  34  32]\n",
      " [ 17  28   2  32  84  21  26]\n",
      " [ 15  33   2  36  30  39  55]\n",
      " [  4   7   0  19  23  28 129]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.41      0.48       210\n",
      "           2       0.43      0.55      0.49       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.25      0.19      0.21       210\n",
      "           7       0.47      0.61      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89  31   6  17  34  16  17]\n",
      " [  9 111   8  23  26  21  12]\n",
      " [  5  26 159  10   2   6   2]\n",
      " [ 11  26   4  70  40  32  27]\n",
      " [ 21  32   2  31  81  18  25]\n",
      " [ 16  33   0  42  29  44  46]\n",
      " [  5   3   0  31  19  34 118]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.42      0.49       210\n",
      "           2       0.42      0.53      0.47       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.31      0.33      0.32       210\n",
      "           5       0.35      0.39      0.37       210\n",
      "           6       0.26      0.21      0.23       210\n",
      "           7       0.48      0.56      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79  33   5  22  35  12  24]\n",
      " [ 12 104  10  24  25  25  10]\n",
      " [  7  28 152   6   4  12   1]\n",
      " [  9  17   5  70  38  37  34]\n",
      " [ 24  29   2  30  83  17  25]\n",
      " [ 17  45   3  26  28  41  50]\n",
      " [  3  12   0  20  25  31 119]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.38      0.44       210\n",
      "           2       0.39      0.50      0.44       210\n",
      "           3       0.86      0.72      0.79       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.35      0.40      0.37       210\n",
      "           6       0.23      0.20      0.21       210\n",
      "           7       0.45      0.57      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  28   5  21  36  11  16]\n",
      " [  9 107   9  28  29  19   9]\n",
      " [  7  25 153  10   4   8   3]\n",
      " [ 14  30   4  72  30  29  31]\n",
      " [ 14  26   4  37  85  17  27]\n",
      " [ 17  27   2  41  34  38  51]\n",
      " [  6   5   0  27  29  29 114]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.44      0.50       210\n",
      "           2       0.43      0.51      0.47       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.31      0.34      0.32       210\n",
      "           5       0.34      0.40      0.37       210\n",
      "           6       0.25      0.18      0.21       210\n",
      "           7       0.45      0.54      0.49       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.44421768707482995\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  24   7  19  35  13  19]\n",
      " [  9 110   9  22  29  25   6]\n",
      " [ 10  28 154   7   4   6   1]\n",
      " [ 16  28   3  63  38  34  28]\n",
      " [ 25  24   3  33  78  19  28]\n",
      " [ 12  36   2  34  33  37  56]\n",
      " [  9   6   0  22  23  32 118]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.44      0.48       210\n",
      "           2       0.43      0.52      0.47       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.32      0.30      0.31       210\n",
      "           5       0.33      0.37      0.35       210\n",
      "           6       0.22      0.18      0.20       210\n",
      "           7       0.46      0.56      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  31   6  14  38  13  16]\n",
      " [  9 119   8  20  28  17   9]\n",
      " [ 12  29 149  11   1   7   1]\n",
      " [ 12  22   6  77  35  28  30]\n",
      " [ 20  29   1  38  84  15  23]\n",
      " [ 16  32   3  39  27  42  51]\n",
      " [  5   7   0  23  23  26 126]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.44      0.49       210\n",
      "           2       0.44      0.57      0.50       210\n",
      "           3       0.86      0.71      0.78       210\n",
      "           4       0.35      0.37      0.36       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.28      0.20      0.23       210\n",
      "           7       0.49      0.60      0.54       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  21   4  20  32  17  23]\n",
      " [  7 113   8  22  29  21  10]\n",
      " [  8  28 155   5   1  10   3]\n",
      " [ 11  21   7  74  37  31  29]\n",
      " [ 22  27   3  32  81  17  28]\n",
      " [ 12  37   2  31  23  51  54]\n",
      " [  8  11   0  20  24  34 113]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.44      0.50       210\n",
      "           2       0.44      0.54      0.48       210\n",
      "           3       0.87      0.74      0.80       210\n",
      "           4       0.36      0.35      0.36       210\n",
      "           5       0.36      0.39      0.37       210\n",
      "           6       0.28      0.24      0.26       210\n",
      "           7       0.43      0.54      0.48       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  26   8  20  30  14  22]\n",
      " [ 10 114  11  24  29  15   7]\n",
      " [  8  28 158   6   0   7   3]\n",
      " [ 15  21   5  65  36  35  33]\n",
      " [ 20  31   2  25  78  15  39]\n",
      " [ 17  30   4  36  28  39  56]\n",
      " [  8   3   0  28  23  28 120]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.43      0.48       210\n",
      "           2       0.45      0.54      0.49       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.32      0.31      0.31       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.25      0.19      0.21       210\n",
      "           7       0.43      0.57      0.49       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3925170068027211\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 87  49  12  12  21   5  24]\n",
      " [ 16 104  34  17  20   6  13]\n",
      " [ 18  44 143   2   2   0   1]\n",
      " [ 21  54   7  41  32  21  34]\n",
      " [ 26  48   5  17  74   6  34]\n",
      " [ 22  63   6  26  25  18  50]\n",
      " [ 12  23   0  25  23  17 110]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.41      0.42       210\n",
      "           2       0.27      0.50      0.35       210\n",
      "           3       0.69      0.68      0.69       210\n",
      "           4       0.29      0.20      0.23       210\n",
      "           5       0.38      0.35      0.36       210\n",
      "           6       0.25      0.09      0.13       210\n",
      "           7       0.41      0.52      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.38      1470\n",
      "weighted avg       0.39      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//xlm_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
