{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bb0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import re\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a510bdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>commentText</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugy_CBm-_CKA3YqrzcB4AaABAg</td>\n",
       "      <td>Pudina ptta nhi dalu to</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugy9mx9nuTWJu4dRac14AaABAg</td>\n",
       "      <td>Chiken kacha tu ni rhy ga sis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugz8T2MKLYucL3dM9nh4AaABAg</td>\n",
       "      <td>Hello mam, I love your all recipes.... ðŸ˜‹ðŸ˜‹ðŸ˜‹\\nAl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugx_1cCjRbCaDgL0FLF4AaABAg</td>\n",
       "      <td>Its awesome recipe plzz make handi chicken in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgzLhKVAJ6NN3nZXyjN4AaABAg</td>\n",
       "      <td>Yeh jo measurement hai.........kitne logon ke ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>UgjFXyC0Qhzk5ngCoAEC</td>\n",
       "      <td>i love chole...thank you kabitaji for sharing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>UghP3bitlJuM13gCoAEC</td>\n",
       "      <td>thnakyou mm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>UghztLZOqvedfXgCoAEC</td>\n",
       "      <td>thanks mam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>UggX5Fi2Y430zXgCoAEC</td>\n",
       "      <td>u r fabulous</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>UghTaB9XvOQ_MngCoAEC</td>\n",
       "      <td>thnq fr the recipe.  ðŸ’œ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "0     Ugy_CBm-_CKA3YqrzcB4AaABAg   \n",
       "1     Ugy9mx9nuTWJu4dRac14AaABAg   \n",
       "2     Ugz8T2MKLYucL3dM9nh4AaABAg   \n",
       "3     Ugx_1cCjRbCaDgL0FLF4AaABAg   \n",
       "4     UgzLhKVAJ6NN3nZXyjN4AaABAg   \n",
       "...                          ...   \n",
       "4895        UgjFXyC0Qhzk5ngCoAEC   \n",
       "4896        UghP3bitlJuM13gCoAEC   \n",
       "4897        UghztLZOqvedfXgCoAEC   \n",
       "4898        UggX5Fi2Y430zXgCoAEC   \n",
       "4899        UghTaB9XvOQ_MngCoAEC   \n",
       "\n",
       "                                            commentText  Labels  \n",
       "0                               Pudina ptta nhi dalu to       7  \n",
       "1                         Chiken kacha tu ni rhy ga sis       7  \n",
       "2     Hello mam, I love your all recipes.... ðŸ˜‹ðŸ˜‹ðŸ˜‹\\nAl...       4  \n",
       "3     Its awesome recipe plzz make handi chicken in ...       2  \n",
       "4     Yeh jo measurement hai.........kitne logon ke ...       7  \n",
       "...                                                 ...     ...  \n",
       "4895  i love chole...thank you kabitaji for sharing ...       1  \n",
       "4896                                        thnakyou mm       1  \n",
       "4897                                         thanks mam       1  \n",
       "4898                                       u r fabulous       4  \n",
       "4899                             thnq fr the recipe.  ðŸ’œ       1  \n",
       "\n",
       "[4900 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset\n",
    "kb_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//kabitakitchen.csv\", encoding_errors='ignore')\n",
    "kb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1004bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77fb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b65d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707c25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "sentences = list(kb_df['commentText'])\n",
    "for sen in sentences:\n",
    "    comments.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c912fece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pudina ptta nhi dalu to',\n",
       " 'Chiken kacha tu ni rhy ga sis',\n",
       " 'Hello mam love your all recipes All the ingredients are easily available and your way of explaining is too good ',\n",
       " 'Its awesome recipe plzz make handi chicken in handi ',\n",
       " 'Yeh jo measurement hai kitne logon ke liye hai ',\n",
       " 'Kabita mam tried ur egg biryani everyone in my house just loved it thank so much that was so delicious it was all because of ur recipe',\n",
       " 'cooker me kar sakte he na',\n",
       " 'Mujhe bhot ache lagi apki respi mene subscribe kardia bhot ache he',\n",
       " 'Mam dahi jgh kuch or use kr skte kya',\n",
       " 'Wooooooo it very yummmmmm love it',\n",
       " 'This is perfect biryani recipe Apko follow kar banaya acchi bani biryani ',\n",
       " 'Hi Didi was always curious that How Biryani Made Thank you so much for putting this detailed video This Weekend will try and serve it to family Really Motivatied ',\n",
       " 'thanx respect from Madam appne tel nahy dala ',\n",
       " 'I made this it taste awesome thank you kabita ji ',\n",
       " 'You re amazing ',\n",
       " 'nice video',\n",
       " 'Aur kya is recipe ko cokar me bana sakte heplease zarur reply kijiye ga',\n",
       " 'Aur mam isme aap chawal kitne g use kiya he',\n",
       " 'Rice me oil dale to chalega',\n",
       " 'Masha Allah so yummy The main thing about I like in this video is the way show all the steps one by one and the way cook it really looking so beautiful ',\n",
       " 'Thank you my friend to post your video to make chicken biryani like it thank so much love my friend m from Dubai ',\n",
       " 'Curd ko skip Kar sakte maa Sahi bariyani masala and chicken masala ensabko skip Kar sakte maa',\n",
       " 'why not show to how to make merinate the chicken ',\n",
       " 'Hi Kabita Agar briyani ki quantity jyada ho to BHI kya cooking timing same rahegi ',\n",
       " 'U awesome kabita ji',\n",
       " 'Chicken Marinette me oil ya ghee ni dalenge to wo jis bartan me hum bna rahe uske niche chipkegi nahi kya pls bttaiye na Mujhe bnani h',\n",
       " 'I love your recipes',\n",
       " 'Kabita didi plz tell us which brand basmati rice you are using plz',\n",
       " 'Measure of rice and water ',\n",
       " 'U too sweet even after getting so many views and comments you read everyone comments and respond them such gesture ',\n",
       " 'I have already tried egg biryani now it time for chicken and Mam you are master',\n",
       " 'Its very delicious',\n",
       " 'Aap mujhe bahut pasand ho mam ',\n",
       " 'Though am unable to follow your language your step by step preparation is very clear to me easy and simple method of preparing dum briyani definitely will try ',\n",
       " 'Mast ',\n",
       " 'Ap boht achi hain our apki recipe bhi kamal ki hai ',\n",
       " 'Wao very nice recipe ',\n",
       " 'Ma abhi tak isko baar bana chuki hu Unexpressable Par comment pahli baar kar rahi hu ',\n",
       " 'Very good',\n",
       " 'I had made today ur biryani receipe it was tasty nd nice ',\n",
       " 'Very nice recipe yummy',\n",
       " 'Nice recipe ',\n",
       " 'Very well explained and it is hit in my home have prepared it many times everyone has just loved it superb mam keep it up',\n",
       " 'Superb mam',\n",
       " 'So nice',\n",
       " 'Mam Wheh have to mix rose water ',\n",
       " 'Kewda water bhi use krte kya isme ',\n",
       " 'This is the most simplest way of cooking biryani will try it Thanks for the video',\n",
       " 'Which brand shahi biryani masala and chicken masala as different brand is different flavour pls advice ',\n",
       " 'agr dhi pudina na ho to',\n",
       " 'can we skip mint leaves ',\n",
       " 'Hi didi Mujhe puchna tha ki Jo dahi apna dala Oo kesa tha Mene last time dahi dala Dahi khata tha Toh Chiken gravy khata ho geya',\n",
       " 'Thanks',\n",
       " 'Oooooh',\n",
       " 'Kya tamatar nahi Dalna hai',\n",
       " 'Very taste',\n",
       " 'chicken ko freeze mein nehi rakhne se koi prblm ho gaya kya Di ',\n",
       " 'I tried ur recipe of dum biryani It too good tasty But chicken got burnt little What should do to avoid it again Please give your suggestion',\n",
       " 'Shahi chicken masala is combination of what Because yahan pe shahi masala nahi milta pls reply mam',\n",
       " 'Big process',\n",
       " 'I tried it today it came out delicious have added kade masala and other ingredients times more for kg chicken and kg gm basmathi rice and followed each and every step it came out really well My family loved the recipe Thank for sharing this recipe ',\n",
       " 'Kitne log khayenge',\n",
       " 'Ab ye javitri kya hota hai ',\n",
       " 'Mene ye try kiya it delicious Thnkuu for lovely recipe mam',\n",
       " 'Very nice kabita sis m in Madurai Tamil nadu',\n",
       " 'nice presentation',\n",
       " 'Wow nice',\n",
       " ' kg chiken main kitna dahi cahiye',\n",
       " 'Agar rice and chicken ka quantity Kam ho to timing same rahega ',\n",
       " 'mene app ki biryani try ki bahot achi bani sab ko achi lagi lekin muje agar jada grevy chahiye to kya kare thank you ',\n",
       " 'Maam Kya Ghe ke jagah batter use kar sakte he kya',\n",
       " 'How much time should cook on stove if m making it with beef ',\n",
       " 'U the best chef on youtube mam ',\n",
       " 'Mam aapne kitne chawal me kitna pani liya pakane ke liye kyuki jb bhi mai banati hu tb chawal sahj se cook hote hi nhi plzz mam ek baar sahi se bata dijiye',\n",
       " 'Super recipe mam tried it It was awesome Thanks lot super you are Keep going ',\n",
       " 'Amazing recipe best',\n",
       " 'mam chikn ke pis kacche nahi rahenge pls mere qustion ka aanswer dena pls',\n",
       " 'Hai dear m from Kerala Big fan of you and hyderabadi Biriyani have doubt don have non stick pan In that case what type of vessel is to be used for the dum step',\n",
       " 'Thank you',\n",
       " 'I tried it it was very testy ',\n",
       " 'Your cooking is so neat and clean',\n",
       " 'World best briyani have moved to Canada and have craved for my moms Biryani and this tastes exactly like it Thank you so much MUST TRYYYYY IT',\n",
       " 'Hii maam have question to ask have taken of chicken for dis biryani and so timing is as according but what if we vary amount of chicken is timing stil same or how vl we change timing pls help ',\n",
       " 'Bhauji agar mutton kg aur chawal kg ho to timing kya hoga ',\n",
       " 'Itna aata zayaah krna dum dene lye himaqat nahi ',\n",
       " 'Pahle Mai sochta tha doctor se hi Sadi karunga but iss video ko dekhne ke bad lagta hai hotel management best hogi mere liye your husband is really lucky wish someday my wife coocked same for me ',\n",
       " 'I tried yummy thank kabita mam ',\n",
       " 'It a perfect recipe for Chicken Dum biriyani simply followed each step and my biriyani was awsum in first try thanks for sharing and we ll describing during the video ',\n",
       " 'Hello Kabita Ji Good day am in Dubai and had cooked today Biryani and its cooked so delicious Thank you so much ',\n",
       " 'I made exactly same And knw what It was insanely awesome best ever than any restaurant Thank you very much Ms Kabita ',\n",
       " 'Nice recipe',\n",
       " 'Kukar me ni bna skte ',\n",
       " 'Hyderabadi khachy ghost ki biryani',\n",
       " 'Hello mam tried this biryani recipe today and it turns amazing Thanks alot for such delicious biryani India No cooking Channel Kabita Kitchen ',\n",
       " 'hi mam have tried many receip such as upma pea nut chutney phoa dosa and now biryani all the recipe turned out so good that was appreciated thank so much for your clear explaination of ur recipe god bless you and keep it up ',\n",
       " 'Madam ye rice kitne rs waale ha ',\n",
       " 'Oh wow that was so simple yet delicious Will try',\n",
       " 'Bhai koy try mat karna me ne try kiya me ra pura chikan jalgaya',\n",
       " 'I will try it You are doing great job ',\n",
       " 'Hi kabita tried the biriyani it was tasty but had lot of water collected at the bottom of the vessel How can solve that',\n",
       " 'MADAM CHICKEN ME DAHI DALNE SE CHICKEN KHATA TO NAHI HOTA HAI NA ',\n",
       " 'Madam simple wale chawal bna skte hai kya',\n",
       " 'Madam chiken kaun sa legne leg piece wala ki Jo dukan pr kaat kr dete hai',\n",
       " 'madam shahi biryani masala kaisey banaye ya phir bahar karidley ',\n",
       " ' The measurements are pretty accurate with simple step by step explanation Best wishes from Malaysia ',\n",
       " 'Agar kg chaval lege to kitna Dahi lena hai plz pty',\n",
       " 'Sahi me use aap but jyda mere hai',\n",
       " 'Nice kabitaji for easy information',\n",
       " 'HE RAAM CHICKEN J WALO SE BACH KE RAHIYO MULAA GHOSIT KAR DENGE SORRY JOKES ',\n",
       " 'Your way of cooking is very good your all recipes are fantastic will try this biryani on saunday please upload the recipe of chicken momos Love so much kabita dii',\n",
       " 'So nice Awesome ',\n",
       " 'Atta Dough me crack aa ja rha he aur pressure release ho ja rhe he any solution ',\n",
       " 'Kabita mam you are the only reason learned cooking Not only that made cooking as my hobby being bachelor my roommates always wait for me to come from office and make something for them All the credit goes to you mam you are really awesome ',\n",
       " 'Hello mam tried this recipe today and it was awesome have never tasted such biryani in any other restaurant earlier',\n",
       " 'So nice ',\n",
       " 'U a magician jus love your every recipe ',\n",
       " 'yummy recipe very nice tried it it was very tasty',\n",
       " 'Or Bht Achchi Bani Thi Chicken Dum Biryani Thanku So Much Kabita Di ',\n",
       " 'Am sorry can please the cooking time once again how many minutes ',\n",
       " 'Mam aapki recipe bahut achha laga aur aapka bathane ka tarika bhi bahuti achha hai Mam mera ek sawal hai Aapne usko seal karke banaya hai agar mai iss beiyani ko pressure cooker me banane se kaisa rahega pl mam aap bathayenge ',\n",
       " 'This is going to my first cook ever in my life ',\n",
       " 'Delicious kabita mam are really great ',\n",
       " 'nice recipe',\n",
       " 'apne to aata bataya hi nahi',\n",
       " 'What is low medium flame either it wud low or medium ',\n",
       " 'It delicious but very time consuming ',\n",
       " 'I never cooked biryani but looking at this video have to try this looks ever so nice',\n",
       " 'Just perfect recipe mam Thanks lot Keep up the good work ',\n",
       " 'Trying today hope it comes gud',\n",
       " 'Oil to bilkul daala hi nahi aap ne',\n",
       " 'How many people will it serve Want to try it tomorrow',\n",
       " 'Bahut hi achhi recipe hai Mujhe bahut pasand hai Hmesa market me hi khane jana padta tha Lekin ab ye problem bhi door ho gyi Thanks mam ',\n",
       " 'Very nice cooking style',\n",
       " 'This biryani is just awesome had made in my home The major problem we face while making in biryani was that the bottom use to get burned but the way said nothing got burned And one more thing if we add table spoon of oil while marinating the chicken it will even give more taste',\n",
       " 'You are wonderful chef and instructor Keep up the good work ',\n",
       " 'U added no cooking oil wil it work ',\n",
       " 'Pls learn Telugu',\n",
       " 'Jab ghee dalte hai to uska taste ya smell aata hai kya kyu ki mujhe ghee kewal roti saath hi aacha lagta hai',\n",
       " 'Biryani pan ki jgah cookar me bna skte kya',\n",
       " 'what if don want dum biriyani but want normal one shouldn I seal the edges of the pan answer me please',\n",
       " 'Tq sister It was amazing All of you try it Superb sister ',\n",
       " 'If we make kg of chicken biryani then what are the timing ',\n",
       " 'Hi and thank u',\n",
       " 'Super your recipes are amazing ',\n",
       " 'Hello mam plzz want recipe of biryani masala powder plzzz',\n",
       " 'Thanks',\n",
       " 'Very nice recipe',\n",
       " ' good Mam very nice recipe',\n",
       " 'Today tried this recipe it was Awesome My husband loved it Thanks alot for making my day ',\n",
       " 'Timing explain kijiye plzzzzz',\n",
       " 'Biryani ka timing nhi samjha',\n",
       " 'Ma am kitina bhi jayada biriyani ho timeing same rahega na Plz reply maam',\n",
       " 'Agar tawa nahi hai to direct heat kar sakte hai',\n",
       " 'hii mam mera biryani bht acha bna bt chckn hlka sa lg jata aisa hota h',\n",
       " 'Bahot best',\n",
       " 'Thanx mam ur biryani is just superb my family loves it very much ',\n",
       " 'Pudina patta na ho to kadi ptta use kr sakte h',\n",
       " 'man dahi ko replace karke kuch aur nhi daal sakte',\n",
       " 'Awesome recipe thank you very much',\n",
       " 'Love the content keep up the good work ',\n",
       " 'Hi mam people ke liye kitna amount Rice and Chicken use krna chahiye plzzzzz reply me mam',\n",
       " 'ye meri rd tym me aapki recipe follow karti hnu ye toh restaurant ki biriyani se bahat bahat bahat acha juzz lv it Well done mam',\n",
       " 'Seeing other people positive comments definitely makes me want to try this recipe m giving it go this weekend thanks for sharing your recipe ',\n",
       " 'Mam you are the nest chef ',\n",
       " 'Kesar na ho to madam',\n",
       " 'Ma am please app fried chicken biriyani recipe ki video baaniye',\n",
       " 'Please never forget to write ingredients in the description below ',\n",
       " 'You had explained it so well that even the cook at my house can make biryani so well it soooo yumm yumm one of the best biryanis have ever tasted we should thank you for such good recipe and because of you we can have biryani at home now',\n",
       " 'itne der tak biryani banane se accha bahar se hi order kar lo ',\n",
       " 'Kitchen king acha sabji poudar masala bataiye na',\n",
       " 'Very nice biryani',\n",
       " 'Maam you are one of the nicest youtubers of the country Keep the good work going on ',\n",
       " 'Chicken me masala lagakar fridge me kitna Samai tak rakh sakhte hai ',\n",
       " 'agar thora masale dar chaye to kya kre',\n",
       " 'U are great mam so cute ',\n",
       " 'I from India but living in Germany Ur recipe has been life saver for me thankyu',\n",
       " 'You only marinated the chicken did not cook before putting rice',\n",
       " 'Hi Kavita tired ur recipe it was delicious but only one problem was there the rice was dry can you please suggest how to make rice soft thanks ',\n",
       " 'Mam mujhe nai khana bana ke itna lamba proses kuch chhota or aasan sa btaiye plzz',\n",
       " 'We can skip curd mam',\n",
       " 'Which brand of Basmati do you recommend for this recipe Do you recommend parboiled Basmati sela seila over regular basmati ',\n",
       " 'Pudina ko skip nhi kar skte kya qki ye local market me available nhi hote',\n",
       " ' calories in one go',\n",
       " 'Mam agar aloo bokhare dalne ho tho wo chicken ke andar daal dene jo marinate karte howe Our kya chicken ko pehle cook nei kar sakte Ese darr lagta ke chicken pakke naa yaa jal na jae Please reply',\n",
       " 'Mam chiken ko ache saaf to krlijiye gnda jb chiken itna gnda to biryani ka test kaise acha ho akta Plz agli recipie chiken ko ache saaf kriyega safai pr dhiyan de',\n",
       " 'I tried this recipe today chicken was cooked beautifully as well as rice but my masala got burned stuck on the bottom was it due to little steam which was passing during dum My dough has two leakage spot',\n",
       " 'very nice recipe will try ',\n",
       " 'Hi Kabita tried this biryani at home and taste was good used flour to seal the pot but seal got leaked in middle and biryani got burns in bottom Any idea how to properly seal the pot ',\n",
       " 'Hi Dear made this Biryani yesterday same as per your instructions but my lower chicken got burned and it ruined the whole dish ',\n",
       " ' kg chicken biryani how much time required for cook the chicken can say that PLEASE',\n",
       " 'Thick pot ki jagah par kya use kar sakte h',\n",
       " 'The meat looked uncooked',\n",
       " 'How to make shahi biryani masala',\n",
       " 'kabita ji apki recipe bohot simple hai ap jeshe bol kar karte hai bhot acha hai ',\n",
       " 'Mam oil kab dalna hai',\n",
       " 'it taking more time',\n",
       " 'Will try it sure Thank you ',\n",
       " 'Superb mam ',\n",
       " 'This is too much spiciy',\n",
       " 'I have also tried this recipe multiple times Really yummy recipe if anyone is beginner can check her cooker biryani recipe its easy quick and delicious',\n",
       " 'chicken pak jaayega aise',\n",
       " 'Maam Kia hum chicken ki do layr laga skate hai',\n",
       " 'Isse achchi to meri mumma bnati h',\n",
       " 'aap master chef ho',\n",
       " 'Oh Wow ',\n",
       " 'Ye kachi dum biriyani he',\n",
       " 'I tried it it really soo yummy mam Thanks lot for uploading this delicious receip',\n",
       " 'galti sy mint low ker dia ab kia keron ',\n",
       " 'were is your chicken',\n",
       " 'Love you',\n",
       " 'Superb',\n",
       " 'nice',\n",
       " 'Hello mam super ',\n",
       " 'Maam ye Jo Apne banaya hai vo kitne lg ke liye hai And tamatar nai use krna hota hai ',\n",
       " 'Kabitaji maine aapki recipe last year banayi thi bahut mast bani thi bacchonko ab tak yaad hai Ab savan ka mahina chalu hone se pahale banani hai isliye vapas aapki ye haidrabadi biryani ki video dekh rahi hoon Thanks kabitaji aapka recipe bataneka tarika itna acchha hai ki sab aasan ho jata hai ',\n",
       " 'mam apne to oil nehi dala chicken marinate me ',\n",
       " 'Today for the first time prepared biryani Turned out really well Thanks ',\n",
       " 'I like your recipe this recipe very useful',\n",
       " 'Steam toh nikla hi nehi end mein Iski CBI jaanch honi chahiye ',\n",
       " 'pehle khood sikho phir sab ko sikha ',\n",
       " 'I love this recipe of chicken dam biryani kabita mam its really awesome mashaa Allah will deffinately try this recipe but whenever made biryani at home every time got confused about rice quantity and my biryani looks like lott of masala insiden with less rice please give me any tip to correct my rice quantity ',\n",
       " 'lovely way to explain nice and fast tried excellent',\n",
       " 'Mam chicken rubber jaisa cook hota hai mere se How can make soft chicken',\n",
       " 'I tried this rspy it was really nice now can cook biryani thnqq keep sharing ur rspy ',\n",
       " 'Agar Shahi biryani masala Na ho to kya kru',\n",
       " 'Very yummy Mam ham is me tomato Dal sakte H',\n",
       " 'yummy',\n",
       " 'Thank you for sharing cant wait to make this',\n",
       " 'Rice ko kitne time ubale',\n",
       " 'Very easy and tasty recipe Thank you',\n",
       " 'Agar refrigerator naho to',\n",
       " 'Thank you for sharing this recipie',\n",
       " 'SuperBBB',\n",
       " 'Mam ayse pakane se kiya chiken acchi tarha pak jayga',\n",
       " 'Curd mix karne pe chicken agar jyda khatta ho gya to',\n",
       " 'I from france and your video are very helpful thank you so much for your lovely food',\n",
       " 'I love you darling',\n",
       " 'nice taste',\n",
       " 'Mam mein Jb bante hu ye jal jata aap kuch Tips doo taki jale',\n",
       " 'Wonderful',\n",
       " 'Hey dear Kabita thank for making it soooooo easy and it tastes like tandoor biryani m yours big fan love a lot ',\n",
       " 'u super sister',\n",
       " 'Today make this recipe It so yummy Thank so much ma am ',\n",
       " 'Har chiz Ko bhut hi simple bna deti ho mam aap ',\n",
       " 'Superb',\n",
       " 'Kabita mene apki recipe se biryani bnai bahut hi tasty bni thanks for nicerecipe',\n",
       " 'Biryani ban Jane ke Baad turant dhakkan hatana zaroori hai kya Agar hum ghante Baad hatayenge to kya taste mein fark padega ',\n",
       " 'use cooker',\n",
       " 'Not good',\n",
       " 'ye ham pardesh walon liye kafi qeemti hai thanks maim',\n",
       " 'Thank you',\n",
       " 'Very nice briyani kabita ',\n",
       " 'Wow very very nice ',\n",
       " 'Wow just had the best home made biryani ever Thanks lot Kabita didi ',\n",
       " 'Mam ghee jgha refine oil use kr skte hai',\n",
       " 'Ma am have tried it yesterday Bhot delicious bani but dahi phat gya Maine aapki recipe step by step follow ki thi to phir kya galti ho sakti hai ',\n",
       " 'Tumhari recipe taste kaise karenge ',\n",
       " 'For how much time should cook for kg biryani ',\n",
       " 'Could cook meat first then layer it with the rice ',\n",
       " 'Sister aapka video dekhne ke baad mene life me first time biryani banai aur jab biryani ban gayi toh gharwale ungliya chatate reh gaye thank you sister ',\n",
       " 'Agr chicken gram le aur rice gram to kya masalo aur sbhi ingredients ka measurements itna hi rkh skte ',\n",
       " 'Ma am agar rice or chicken ki quantity aap jo dikhaye hain usse double ho to kya biriyani cook krne ki time bhi double hogi Yaa phir jitna time Apne bataya utne mee hi ho jayega plz ans mee ma am Jaldi mujhe yeh suggestion ki bohot jarurat hai ',\n",
       " 'Nice recipe mam maja agya',\n",
       " ' pyaz Barik Kate hue nice recipe',\n",
       " 'Hello Kabita Ma am Aaj Maine Aapne bataya huye tarike se biryani Banayi Bahut he acchi Bani thi Thanks for sharing this recepe with us ',\n",
       " 'It tasted superb m satisfied',\n",
       " 'Just awwsome recipe ',\n",
       " 'Hiee Di Hows uh Hope All Fine naa Bdw As told uh yesterday made the biriyani truly it worked wonders My lucky charm thanks for being Di God bless Luv loads',\n",
       " 'Wahh mam apka koi jabab nhi bahut hi achhe se har ek chij batati ap',\n",
       " 'you are best',\n",
       " 'I have never tried biriyani except all have made Will try it once i know it will turn well coz my lucky charm always ur dishes had helped me grow Luv uu di blessed',\n",
       " 'all your recipes are best',\n",
       " 'Best',\n",
       " 'Where can get ghee',\n",
       " 'Maam log liye bnane se cooking time same rahega ya or tym lagega',\n",
       " 'Shouldn I soak rice ',\n",
       " 'I don have non stick cookware still the prep wud remain the same or not ',\n",
       " 'Mam ghee ki jgh refined oil use kr skte he ',\n",
       " 'Mam mujhe ek doubt hai kya chicken sach me accha pak jayega qki usually chicken bnane me jyada time lagta hai aur chicken accha nahi hota',\n",
       " 'Wow Nice chicken biriyani recipe mam So tasty',\n",
       " 'Instead of ghee can we use oil',\n",
       " 'Mam ghee ki jagah tel use kr sakte kya ',\n",
       " 'i like bcoz ur cooking process is very clear and finising so first time in cooking videos subscibe only ur site so keep it up best of luck',\n",
       " 'Hello Kabita made this biryani it came out really well Thanks for sharing this recipe ',\n",
       " 'Hi mam tried making the biryani but it was bit dry may know what would have went wrong also the masala became less Tell me solution for both the thing Thanks mam',\n",
       " 'Kya Kesar dalna jaruri Usk jgh pr jldi ni use kr skte',\n",
       " 'Hi mam mene aaj chicken dum biryani banay sab ko bhut pasand aay yummy yummy thank you sooooo much ',\n",
       " 'Very nice',\n",
       " 'mam how many pieces will come in grams chicken if we cut same as you have cut in big pieces',\n",
       " 'WooW',\n",
       " 'Dahi is mandatory ',\n",
       " 'Nice recipe have question how much total time taken to ready the biryani',\n",
       " 'It is so tasty dear mam',\n",
       " 'ur voice resembles like air hostess explaining in plane',\n",
       " 'it was realy tasty tried it thank for showing show some fried chicken kabab',\n",
       " 'kabita mam just for change can we add cashew nut and almond paste almost just tblspn not more than that what your opinion',\n",
       " 'yr videos helped lot in my kitchen thanx for giving us all lovely videos ',\n",
       " 'Humko fried chiken Biriyani batayiye ',\n",
       " 'Kabita ji this is suppppper',\n",
       " 'Mam have very important question mam apne esmai water nahi dala aur lagabhag mint cook kiya to niche jo chiken hai wo jaal jayega aur baki chiz sahi se paak nahi payega aur hamne ese pack kar diya to ho sakta hai ye blast kar jaye kyounki mai jaha apne samne chiken ya matan ki biryani pakte dekha hai usmai gravy hoti hai Apne nahi dala koi gravy ya water eska kya tricks hai plz mam give me details',\n",
       " 'I also make like this',\n",
       " 'So easy delicious learned frm only',\n",
       " 'so nice',\n",
       " 'Mam please upload haleem recipe ',\n",
       " 'Hello sister All the ingredients are used for gm of chicken If make for instance of chicken should double all the ingredients based on the amount of meat or the amount of ingredients should remain same ',\n",
       " 'hello sorry didn watch this video earlier love your recipe you are wonderful cook your hands contain magic tell you',\n",
       " 'Mam hie its nivedita here main kaun se brand ka basmati chawal use karun mere biryani chawal achhe nae hote main india gate basmati use karty',\n",
       " 'Good recipe will try it',\n",
       " 'Didi app reshma ji math bolo jt Reshma bolna',\n",
       " 'Didi app aisach new rcpys post Karo hum app ka har ek vdo hmara frds ko jarur share karagay ',\n",
       " 'Tqqq Didi muja reply daynay ka khaliea ',\n",
       " 'Kabitha Didi ek doubt appko katnay recipes cook karsakthi',\n",
       " 'Kabitha mam appki lookg so cuteeeeeee ',\n",
       " 'Ye chicken nicha oly one layer dalna kya ',\n",
       " 'wow',\n",
       " 'Delicious recipe can we cook this in cooker ',\n",
       " 'I need to go to Latin indian and korean grocery store to collect all ingredients but still not guarantee that can find everything ',\n",
       " 'I tried this recepie and it was soo delicious thanku soo much ',\n",
       " 'Amazing mam',\n",
       " 'Good',\n",
       " 'Smell kaisy khatamkaron',\n",
       " 'Kesar dalny sy smell ati hai',\n",
       " 'pakane kitna time lagega',\n",
       " 'I love your cooking style know aapki cooking bilkul waise hi hoti jaisa mughe pasand hai ',\n",
       " 'i will try it it very awesome tasty di love you so much',\n",
       " 'Mam aupka language bahut acha lagta hai ',\n",
       " 'Hi can use yoghurt instead of curd ',\n",
       " 'Much testy ',\n",
       " 'I tried this biryani at my home by seeing your video it super tasty ',\n",
       " 'Didi kayea may kesor ko pani na Vigo saktay hu plz answar do may aj app recipe bannunge so plzzzzzz answar me ',\n",
       " 'Mam mere ghar dum biriyani banane pr usme halka sa meetha flavour rha tha yesa kyu mam please reply',\n",
       " 'I have learnt cooking with your videos ',\n",
       " 'Mama mere adhe kilo chicken ke paise upper se mera time mere ko waapis chahiye',\n",
       " 'Ise bekar biryani ni dekhi pyaj to jal gya upar adhe chawal colour ni aya',\n",
       " 'very nice recipe ',\n",
       " 'You are too cute and your voice is killer',\n",
       " 'I tried yesterday it is very tasty Thank so much',\n",
       " 'Mam main kg chiken ki Biriyani banana chahti hu Kya main is tarah bana sakti hu ki or time ',\n",
       " 'Food colour nahi dene se vi hoga kya ',\n",
       " 'It a long video but don cut it you describe the whole steps nicely From watch this video anyone can fall love with you mam Thanks And m very glad to being your subscriber ',\n",
       " 'Apko chicken acche se saf krna chaiye',\n",
       " 'It am and watching ur chicken biryani recipe ll really miss it as in hostel ll surely try it once go home ',\n",
       " 'do knw how unhealthy ur biriyani becomes when add food colour store bought chicken nd biriyani masala and when drain ur rice in plastic container have seen ur videos before and always use non stick mostly everyone does that still it is extremely dangerous ',\n",
       " 'Khaake coma me chalijaa',\n",
       " 'For kg chckn How much rice needed maam ',\n",
       " 'I tried it following all ur steps and it came out very delicious Thank so much for the recipe mam',\n",
       " 'Hi ma am m from Karnataka bhut hi easy recipe hai but ek bt hai kya chicken puri tarah se pak jayega kyunki aap ne chicken ko kisi level me pakaya nhi just marinate kiya hai aur jab last me aapne jo low flame me rakha to kya chicken poori tarah se pakega ',\n",
       " 'yeh maine try ki bhut hi laziz bani and easy bhi lagi thankyou so much mam ',\n",
       " 'Thanks for the Beautiful recipee ma am Can we use maida instead of wheat flour for wraping around the handi ',\n",
       " 'didi boiled rice me ghee kyun dalte hain',\n",
       " 'Cooker main bana sakte hain kya ',\n",
       " 'very time consuming recipes job walas cant give this much time to prepare',\n",
       " 'Mam mettha attar nahi diya apne',\n",
       " 'Yeh miytha ya khatta dahi tha mam',\n",
       " 'Nice',\n",
       " 'Thank you maam',\n",
       " 'Aur aapne chicken kaccha rkha ',\n",
       " 'What to use instead of biryani masala or can we skip it ',\n",
       " 'It was tooo gud everyone liked it Thank you kabita for wonderful recipe ',\n",
       " 'Today m preparing this Let see how it tastes ',\n",
       " 'Chawal kitna Dalenge',\n",
       " ' food colour dal sakte hai na Kaser bdle',\n",
       " 'Kaun SA oil dalu',\n",
       " 'To oil kauna SA dalenge',\n",
       " 'Kyon Makhan Shi nhi rhega',\n",
       " 'Ghee bdle Makhan dal sakte kya',\n",
       " 'Mam main ne try ki same aap ke bataye Gaye tarike se par masala jal Gaya puri pateli Ko chipak Gaya Aisa man plz bataiye',\n",
       " 'wow',\n",
       " 'woooooow',\n",
       " 'wao',\n",
       " 'Masla jal gya Kya kru ',\n",
       " 'Mam apne pan mei bnai hair Pls tell the name of utensil',\n",
       " 'Mam can we use chicken curry msala instead of chicken msala',\n",
       " 'Kabita Ji thoda bataiye Chicken biriyani banane keliye agar hum aluminum pot use karenge to Kitna total kitna minute gas uper bithayenge',\n",
       " 'No kevda essence',\n",
       " 'I dont like it at all ',\n",
       " 'Prawn biriyani recipe',\n",
       " 'Nice ',\n",
       " 'Sooooper ',\n",
       " 'nice',\n",
       " 'Hi Kabita this looks so yummy suppose can use my big crockpot to make this Any good advice Thanks for sharing your knowledge so appreciate your video ',\n",
       " 'Can you show how to make biryani masala',\n",
       " 'Biryani looks good but think you put too much garam masala in the chicken',\n",
       " 'thank mam',\n",
       " 'Mem apki smile ',\n",
       " 'biriyani khaneke liye adha kilo ata fekana padega isiliye hamko pasand nehi aya',\n",
       " 'Will adding boneless chicken make any difference to taste or cooking method ',\n",
       " 'Apne alu nahi dala aur chicken ko sirf marinate kar ke usa dum mea dal diya apne tu chicken ko marinate ke baad fry nahi kiya Please bhut confusion hai next video mea achha se explain karya ga Agar koy suggestion dena hai tu reply mea de digia ga ',\n",
       " 'Jal gaya tha',\n",
       " ' kg chiken ke liye kitta rice curd kitta gram lgega',\n",
       " 'kabita mam tried this at home it tastes super love you for such delicious recipe Ankita you are the best chef ever ',\n",
       " 'There are more easy biryani recipes than this',\n",
       " 'I am hungry Such nice biryani',\n",
       " 'mam aapki sari recipe mst ',\n",
       " 'Hi Kabita ma am Can we cook it in cooker ',\n",
       " 'ma am dont have this pot so can make layers cook dt in pressure cooker or plz suggest some other utensils other thn dis pot ',\n",
       " 'My few chicken biryani thanks mam',\n",
       " 'tasty biryani',\n",
       " 'You are from Jharkhand ',\n",
       " 'Nyc',\n",
       " 'I tried this menu with pieces how much time have to cook',\n",
       " 'Plz put my recipe of seeg biryani',\n",
       " 'How do make the shahi biryani masala ',\n",
       " 'Kabitaji kg biryani ka ingredients batayiye please',\n",
       " 'Thank you for sharing this video',\n",
       " 'ok mast welcome',\n",
       " 'waw very nice thank you and very yammi really',\n",
       " 'Mam ye dough toh waste ho jaega',\n",
       " 'is it cow ghee or gagan vanaspati ghee',\n",
       " 'Bohat acchi biryani lag rahi hai aaj hi me banaungi',\n",
       " 'Nice mam',\n",
       " 'Can use yellow food colour',\n",
       " 'where do you get the shahi biriyani masala and also chicken masala please let me know',\n",
       " 'very nice video mam',\n",
       " 'super',\n",
       " 'best',\n",
       " 'very tste',\n",
       " 'mam biryani ko aur jyada masaledar krne keliye kya krna chahiye',\n",
       " 'I like your all recipe',\n",
       " 'Chicken gal hi nahi raha esa ku',\n",
       " 'Very nice mam Maine banaya bhut testy Bani thanks',\n",
       " 'Nice',\n",
       " 'So yummy',\n",
       " 'Very Tasty Thank you Kabita ji',\n",
       " 'Yummy',\n",
       " 'Mam agr itta tym tk chikn ko naa chlaau to wo pan me chipkega n',\n",
       " 'Thanks sekhany ka liy Allah mngheban',\n",
       " 'bhaut easy se mam Aap ni bataya',\n",
       " 'Hi mam good morning mujhe aaj chicken Biryani banana hai for people pls give me proportion Rice curd chicken before days made chicken Biryani It was awesome taste love it Today making Biryani for guest Pls reply ',\n",
       " 'aap her recipe acha banati ho ',\n",
       " 'Madam briyani ke rice mai shahi jira hota hai',\n",
       " 'Hyderabadi biriyani ki koi jawab nehi koi uska samna nehi kar sakta ',\n",
       " 'I liked cooking time and heat precaution All best',\n",
       " 'How you recorded all videos with phone or camers',\n",
       " 'Hello kabita am try your chiken biryanee',\n",
       " 'Super',\n",
       " 'mam ye jo ate ko doug se isko dhakan ke charo taraf lagaya achhese set rakha ne lia ham kya pressure cooker use Nehi kar sakte aur non stick pan badal normal pan use karenge to chiken niche lagega to nehi na plz ans me mam',\n",
       " 'Mam bina kesar ni bn skta kya or ghee ki jagah oil use ho skta kya ',\n",
       " 'Thank you very much',\n",
       " 'Supop',\n",
       " 'we loved it ur GRT cook m big fan of urs',\n",
       " 'Chiken kacha dal dey gye is mai to smell aye gi chiken ki mujhy pasnd nai ayi',\n",
       " 'Kabita ji Chicken uncooked hi reh jayega chicken should be fried before placing it there ',\n",
       " 'mam how much cup is grams basmati rice and how many pieces will come grams chicken as you mentioned that you have cut the chicken pieces into large pieces means how many pieces will come in grams if cut it into large pieces',\n",
       " 'Khatta dahi add krna ya meetha dahi ',\n",
       " 'You are ossam mam',\n",
       " 'My Briyani got popular in my inlaws All credit goes to you dear thanku so much for sharing this kepp Rocking like this olys ',\n",
       " 'Isme konsa flavour ka lagta hai colour',\n",
       " 'i tried it very very yummm mam person liye chaawl chicken dahi piyaz kitna lage ga or kitna time cook krna pade ga',\n",
       " 'Maem ky hm ise pan jaga cooker n bna skte ',\n",
       " 'Please don tell us to use artificial colors in any food recipe',\n",
       " 'Hello aap sab recipe hm try krte he or sab bahut tasty banti he thank very much',\n",
       " 'Aap Ka Jawab Nahi',\n",
       " 'Mumma ne try Kiya tha',\n",
       " 'Best recipe mam ',\n",
       " 'Behan pyaz ko fry karna pehle seek lo plz biryani ka mazak mat maro ',\n",
       " 'Apne rose water or screw pine nhi dala ',\n",
       " 'Colour dalna complsary hai kya ',\n",
       " 'Mam aalu dalna hua to kaise dalenge ',\n",
       " 'Kabita mam ve been making chicken biryani following your recipe and always came out to be wonderful have question if just use same proportions curd will be almost gm for kg of chicken but it appears to me lot could you suggest how much curd and rice should consider for kg chicken ',\n",
       " 'This video got the views because of the red coloured rice',\n",
       " 'Naaam bada darshan chota not satisfied with this recipe lots of mistake',\n",
       " 'Nice video',\n",
       " 'I tried making this bt the bottom layer gets burned is there any tip to avoid this Please help',\n",
       " 'Please can you advise if can cook it in pressure cooker with lid covered instead of pan air locked with dough Can use the same heat timing while cooking in pressure cooker ',\n",
       " 'Mam aapki dish hameesha heh bahut aachchi rehti hai',\n",
       " 'badiya nice',\n",
       " 'I am biggest fan of your cooking kabita sister',\n",
       " 'Kabi mayri post ka bhi answer day dia karo dear sister',\n",
       " 'Kabita ji wan to try this recipe but chicken masala ready made shayad koi particular name ho haray han agar recipe hy to bata dain plz is masala ki plz waitinf',\n",
       " 'Which rice is using ',\n",
       " 'I try My hubby love it Thanks kabita ',\n",
       " 'Nice ',\n",
       " 'quantity jyada ho to dam krne ka tymng same rhega ya jyada ',\n",
       " 'very nice',\n",
       " 'wow tried it very very delicious thanks ma am',\n",
       " 'kikar thi biryani mai banaya',\n",
       " 'is tarike mujhe to nahi lagta masala aur chiken pak gaya hoga',\n",
       " 'Thank you so much it was really helpful ',\n",
       " 'Rrt ',\n",
       " 'Mam plzz make chicken chilli',\n",
       " 'Kabita Mam you nailed it Shukriya aise hi receipies upload karte rahiye',\n",
       " 'Can use pressure cooker when cooking the rice ',\n",
       " 'very tasty ',\n",
       " 'Can use cooker instead of pan ',\n",
       " 'aap log keser use karte hain karo lakin koi aap logo jaisa itna amir nahi hota ki itni mehengi sij kharid sake aap logo ko paisa milta hain hame kiya milega to meri gurajih hain ki simple tarike se khna bany usme jyada atcha hain to age se mehengi sij mat batay kyonki sab lob amir nahi hota',\n",
       " 'I try but chicken burn from down Too bad will try more',\n",
       " 'mam mene bhi banai thi ye but meri biryani niche se jal gai thi',\n",
       " 'What is shahi biryani masala ',\n",
       " 'Kitne log mare ye biryani kha Hehe',\n",
       " 'Mam we can do it in presure cooker ',\n",
       " 'I wish were my wife p',\n",
       " 'Sister Food color nt gd fa hlth ',\n",
       " 'You deserve subscribers mam',\n",
       " 'I really like your recipes bcz it so simple easy quick and tasty indeed but can use mace powder instead of whole mace ',\n",
       " 'nice',\n",
       " 'superb superb chicken biyrine',\n",
       " 'Kiti chaan banvali biryani',\n",
       " 'Wow',\n",
       " 'Awesome easy to prepare di',\n",
       " 'kya jada pyaj dalne se kuch problem hoga',\n",
       " 'Ag kesar nai dale to',\n",
       " 'One of the best outcome from Wht Ive made watching video jus follow Wht she says and done loved it kabita thanks for the recipe ',\n",
       " 'i will try to cook it tomorrow',\n",
       " 'Niche oil nay daala chicken toh niche jalega nay chicken ',\n",
       " 'Wow ',\n",
       " 'Are you eat this',\n",
       " 'Can show me how do cooking recording shooting at time Wo itna perfectly',\n",
       " 'This is not the way we cook m from Hyderabad',\n",
       " 'Your voice is too good',\n",
       " 'Ook',\n",
       " 'Vary nice ',\n",
       " 'Very nice recipe',\n",
       " 'mam layering kartr waqt bina kuchh ghee laga krne se niche nhi lag jayega kya chicken pieces ham ek layer chicken nek layer rice fie ek layer chicken then ek layer rice aise nhi kar sakte kya ',\n",
       " 'big fan of yours keep posting your recipes lots of love',\n",
       " 'Thank biryani me liye',\n",
       " 'Can we keep overnight in freeze fir marination',\n",
       " 'Why infreeze ',\n",
       " 'Good recipe',\n",
       " 'Can we make it without curd and shahi biryani masala',\n",
       " 'My husband says jadu agaya tumhre hatho me It all bcoz of ur receip thank so much mam Lots of love',\n",
       " 'Nice mam will try thanku itni acchi or easy resipes ko share kiya',\n",
       " 'Ma am Ek baat bataiye Maine suna hai ki non vej se dudh dahi ghi ko dur rakha jata hai Aur khane ke se ghante baad hi dudh dahi ghi khana chahiye Warna charm rog hota hai Aap to daal bhi rahi hain sath me Is bat me kaha tak sachchai hai Ma am ',\n",
       " 'Mam saffron important',\n",
       " 'Mam please app ne jo colour use Kia hae bo kaha milta hae or uska price kya hae bataeie',\n",
       " 'kabita mam ur the best',\n",
       " 'Kabita mam mai aap ki subscriber hu aur aap bahot achchi hai mujhe aap ke videos dekhna mujhe bahot pasant hai like kabitas kichan',\n",
       " 'very nice plzz telme chicken khucha to nai hoga kyunki meine suna tha chicken fry karna hota hai plzzz mera confusion dorr karoo',\n",
       " 'Ap ki sab recipe achi hi hote h',\n",
       " 'Mam m ur fan ',\n",
       " 'I love ur biryani made it twice and everyone loved it thank for ur wonderful recipe',\n",
       " 'mam aap ne oil use nhi kya or base bhi oil nhi Liya plz rep mam',\n",
       " ' times yummy than what get from out',\n",
       " 'After layer step if want ues microven for dum Toh mujha kya karni hogi Cz gas layer ka band mujha dare lagthi he jal na ka Plz help me Microwave me dum kaise karu ',\n",
       " 'description box ma lekhna nahi aata lekha kara nah',\n",
       " 'Tnx it was very tasty chicken poora pak gaya tnx again lovely',\n",
       " 'M doing will result baba ji pls meri birayani ban jaye thik thik ',\n",
       " 'according to me you are very good chef',\n",
       " 'Yummmmyyyyyyy',\n",
       " 'Chicken pakk gayaa hai puri tarah pls tell me mam',\n",
       " 'Aap ko Modi pakoda malum hai Anti jii',\n",
       " 'I love chicken Mam ap chiku ki aur recipes jarur bnaye and hame btaye ',\n",
       " 'oil use nhi kyea apna',\n",
       " 'Can we use pressure cooker instead and cover just at the top with dough ',\n",
       " 'niceeeeeee ',\n",
       " 'Nice try but best of Hyderabadi Biryani the world famous',\n",
       " 'thank you mam ',\n",
       " 'so easy mam will try it definitly ',\n",
       " 'Mam biryani me dahi skip kar sakte mere bacche ko dahi se allergy Biryani bina dahi ke ban sakti kya Ya dahi ka koi option ',\n",
       " 'Hi have tried the same way but little bit of steam is coming out it ok or have done something rong plz reply as m st time cook',\n",
       " 'superb',\n",
       " 'ok',\n",
       " 'Mam is tamatu and nibbu yuz nahi krte',\n",
       " 'Very good',\n",
       " 'Hi do we use sour curd food curd or normal sweet curd Sorry know nothing about cooking want to surprise my wife on our anniversary',\n",
       " 'Yummy ',\n",
       " 'madam mujhe aapki biryani bnane ki trick achhi lagi par is video ko kese download karuu',\n",
       " 'Ma am tried same process today it was very delicious bt the rice becom very dry Just wondering what els cud do to make the rice which is not dry plz suggest',\n",
       " 'The main thing is that you make your recipes look very easy ',\n",
       " 'ma am can we use ke ora water in this please reply ma am',\n",
       " 'My wife followed this recipe last night it came out so good that asked her to make it again tonight ',\n",
       " 'Kavita Madam maine toh exactly same kiya jaise aap dikhaye likh mera biryani jaal gaya aisa kiu hua ',\n",
       " 'So yummy',\n",
       " 'Mention all ingredients in description box please',\n",
       " 'today me and my mom gave it try but it went unsuccessful the rice was cooked very well just as it is shown in the video but chicken peices were completely burnt out chicken has turned out into coal we heated the biryani for the exact time and with exact flame as shown in the video But it spoiled our plan Maybe it wasn our day ',\n",
       " 'I tried this last month it was yummy but chicken got burnt how can avoid it ',\n",
       " 'Excellent presentation with clean cooking keep posting good luck ',\n",
       " 'delicious kabita ji thank soo much',\n",
       " 'Hi Kabita Today made chicken briyani as per ur video and it came out really very outstanding it was so yummy and my husband loved it so much made our day with ur delicious yummy tasty briyani loved it so much thnkuuu thnkuuu ',\n",
       " 'Is the time enough to make the chicken tender or is it more al dente type ',\n",
       " 'Marination main oil nahi add karna ',\n",
       " 'Madam ji chicken mix Karne ka tariqa wrong h',\n",
       " 'Hello kabita watched your videos your videos are really amazing and by way of cooking is really very appreciative keep it on and best of luck ',\n",
       " 'Superb am the fan of your cooking ',\n",
       " 'ghee badle oil use kar sakte hain kya ',\n",
       " 'Nice chicken biryani thank you is video ko bhejne ke liye Kavita',\n",
       " 'I love r cooking style',\n",
       " 'It was good biryani made by me today in your style',\n",
       " 'You are gem Much love ',\n",
       " 'Mem isme kesar used krna zruri he',\n",
       " 'kabita mam follow regularly ur dishes nvr fail to get me appreciaion from my mother',\n",
       " 'thanks for sharing mam',\n",
       " 'Pz mam rice ko boil krny ka time batin persent kitna time main boil hoga mra rice kbi ziyada kbi kam soft hota so pz batin rice kitna time main boil hoga',\n",
       " 'I am hungry Kabita ji',\n",
       " 'U make every dish so simple and makes me fall in love with cooking R Blessed ',\n",
       " 'Amazing ma am Will surely try But don have that tawa Can cook without that If so dn how much longer or increase in flame should be And will non stick pan will work ',\n",
       " 'agar kg above biryani banaye toh timing me change hoga ya same rahega',\n",
       " 'What can we add instead biryani masala ',\n",
       " 'Owowwo Nice one mam Madam parson Chiken biryani dum qanty ketna chiya ',\n",
       " 'Thank you for this recipe Just wondering if want to add potatoes what step should add them in ',\n",
       " 'Awesome',\n",
       " 'mam bataiye na ki biryani essence rose water kewra water marinade karthe waqt tsp aur rice ko banathe waqt tsp dal sakhti hu please mam mera doubt bataiye',\n",
       " 'wow mam very nice video thank you so much ',\n",
       " 'Mam freez me rakhna jaruri he kya ',\n",
       " 'Which basmati Rice used And rose water brand ',\n",
       " 'I definitely gonna try this one last time cooked it through slightly different recipe and added Kewra Rose water something went wrong the smell overpowered the aroma of Biryani itself Maybe misjudged the quantity of Rose water that added The Kewra water made it taste like agarbatti m not using rose kewra water essence again ',\n",
       " ' kuch oil nehi lagana chahiye Masala jal nehi jayega ',\n",
       " 'aapne konse brand ka Basmati rice use kiya hai ma am ',\n",
       " 'Kabita ma am r sch an amazing cook ',\n",
       " 'mam agar chicken ho toh kaisay bansakhtay hai aur agar zaida banai ho matlab ppl kay liye',\n",
       " 'Ye pak chuki hogi madam chicken pieces ',\n",
       " 'Hey kabita Aap kaunsa brnd ka pan aur vessel use krtihe ',\n",
       " 'Kya hum biryani ko pressure cooker bana sakte hai ',\n",
       " 'Chicken hasn cooked well Pretty sour in taste due to curd Tastes like shit',\n",
       " 'Nice ji',\n",
       " 'kabita Ji apki recipe dekhne she pehle like kr diye apki sari recipe achhi hoti h',\n",
       " 'nice preparation will try Nirmal',\n",
       " 'kabita mam just went through recipe of chicken dum briyani earlier and they added briyani essence kewra water and rose water in the briyani can add these and if can put how much we have to add while marinading and cooking rice',\n",
       " 'Hii Kabita didi meine aaj aapki yeh recipe try ki hai bohot sundar dikh rahi hai abhi todo ter mein ready ho jayegi fir taste karke aapko reply deti Happy Makar Sankranti ',\n",
       " 'if skip black cardamom will it change the tastr',\n",
       " 'yammmi ',\n",
       " 'Sara blood lga tha dhekhne bad hme chicken bireyani se nafarat ho gai',\n",
       " 'Mam apne chiken to dhoya ni',\n",
       " 'Thanku Di ',\n",
       " 'wowwwww super mam ll try this tomorrow',\n",
       " 'bhabhi mere liye ek plet parsal kardo please',\n",
       " 'Mam agar last mein rice mein thodi si kasar kani reh jaye mean kache reh jayein wat wud be the solution',\n",
       " 'Nice',\n",
       " 'aapki voice bohut achhi hai',\n",
       " 'Mam agar nonstick pan na ho tho chicken jalega na ',\n",
       " 'acha banaya apne madam',\n",
       " 'So cute',\n",
       " 'Very nice kabita ji',\n",
       " 'Zam zam biryani dikhaye na',\n",
       " 'Aise Banti he Biryani',\n",
       " 'Chicken Biryani recipe',\n",
       " 'Mam plz chicken corma ki recipe batye',\n",
       " 'Very nice',\n",
       " 'Yummmmyy',\n",
       " 'mine aaj banai biryani no',\n",
       " 'u tips really good ',\n",
       " 'Ma am link of the recipe please ',\n",
       " 'Mem agar kg biryani banaye to kitna kitna dalna padega sab chiz',\n",
       " 'mam kya mein biryani essence rose water kewra water sab tsp marinate karthe waqt aur rice banethe waqt tsp dal sakhti hu aur dhakad phool marinade karthe waqt aur rice banethe use kar sakhti hu aur agar use kar sakhti hu tho kina dhaakad phool use karu mam please reply',\n",
       " 'Mam always see ur recipes really like ur recipes ',\n",
       " 'Didi mera niche sab jal gya Aaj try ki di but jal gya sab',\n",
       " 'Mam ur chicken biryani is outstandig like ur recipis ',\n",
       " 'Were are the dislike comments ',\n",
       " 'Didi mujhe biryani ki dukan kholni Har baar chicken jal jata to aachi tarah seal karne ka tareeka batayein jisse bhaap bahar na nikle Please bhut zaroori h',\n",
       " ' gram chiken se jada nahi bana shaktya key ',\n",
       " 'K thanks mam',\n",
       " 'Welcome mam ',\n",
       " 'ye pressure cooker me ho skta Kya ',\n",
       " 'Hii mam ye biryani hum aluminim jarmal ke bhagone me bana sakte hai kya plz reply me ',\n",
       " 'Ye niche se chipkega nai',\n",
       " 'I tried recipe Everyone liked it Thanks Kabita',\n",
       " 'Hello mam aap ki har recipe bhut he bdhiya hoti hai ',\n",
       " 'Mam ek questions hei chicken ko cook nhi korna hei',\n",
       " 'Why infreeze cant wr keep at room temp ',\n",
       " 'thanks for the video the biryani was amazing did not expect this taste so guys plzzz watch this video while r preparing it ',\n",
       " 'gaavran chicken use kar sakte kya',\n",
       " 'Cooking the rice two times why think you do not need to cook rice before cooking because the chicken has not cooked yet do not know could somebody tell me why are you doing like that because maybe basmati rice has strong different smell anyway love pakistani food ',\n",
       " 'thank you so much for this video ',\n",
       " 'OMG This is the best recipe Me and my mom cooked this together following your recipe It turned out so good Finger liking good will make sure will share your channel to my friends and family Thank you very much for this recipe Please be uploading more video like this ',\n",
       " 'Kavita mam apne direct chicken marinate KAR biriyani banayi Isme chicken achha SE boil to hoga na AUR chawal JAL to Ni jayega ',\n",
       " 'Thanku mam Apke ai recipe bohot helpful hai Thanku',\n",
       " 'Aami ki ektu oil use korte pari',\n",
       " 'Ei biriyani tee kono oil use nei',\n",
       " 'ami ajk banacche ei ta',\n",
       " 'very very good',\n",
       " 'superb kabita',\n",
       " 'Wow',\n",
       " 'Wow when my mom will not at home will try this biryani',\n",
       " 'Why you don add black chilly',\n",
       " 'mam mu karithili je but pita lagila',\n",
       " 'Can we use aluminium foil instead of flour',\n",
       " 'Aaataa lagaane badle me agr biriyan coocker me dam ko rakhe tho kaisa hai',\n",
       " 'I like you and your cooking',\n",
       " 'please mam bataiye',\n",
       " 'mam isme curd Milana jruri hai',\n",
       " 'So yammi',\n",
       " 'Agar chicken pakaynge nhi to kacchha nhi lgega ',\n",
       " 'mam kya mein tsp tandoori chicken masala dal sakhti hu just for taste',\n",
       " 'this Christmas pakka me nd my sister will make this Biryani',\n",
       " 'Very',\n",
       " 'Nice video',\n",
       " 'Kabita you are just neat and perfect in recipes loved it Hope we get more such recipes Mainly Chicken Mutton egg and fish ',\n",
       " 'Kabita mem tanks me be aj try kiya ',\n",
       " 'Mam chicken niche lag jaati koi trick hain jisse wo neche lage nai',\n",
       " 'I don like your style',\n",
       " 'thankyou mam prepared this dish with my wife',\n",
       " 'Thank You aunty ',\n",
       " 'Nice recipe',\n",
       " 'Zaiqa yasmin is also good',\n",
       " 'Kya isme rose water dal sakte ',\n",
       " 'Nice',\n",
       " 'Kavita maine bhi try kiya mere family guests ko paasand ayi Maine ye recipe sab kay sath share kee ',\n",
       " 'Very nice thank you so much ',\n",
       " ' Good',\n",
       " 'What about the aata Kya vo waste ho jaega',\n",
       " 'Nice biryani mam ',\n",
       " 'mam shahi biryani masala ki jagah chicken biryani masala use kr sakti',\n",
       " 'mujhe questions puchna ha Aap kitna litre ka pot ma ye biryani banayi ha Mera pot ma cover karne ke liye Glass lid diya gaya ha Kya ma biryani ko dum dene ke liye Glass lid ko Aata se cover kar sakta hu Kya iss biryani ma pudina use nhi karne se chalega mean use nahi karne se taste kharab to nhi hoga na Kindly reply ma am ',\n",
       " 'Agar biriyani JAL jayaga to hum kaya kara',\n",
       " 'Superb ',\n",
       " 'Fridge means defridge ',\n",
       " 'mere pas pudinapatta nehi hein to koi Kuch dal sakti Hun to bataiyee kal morning mein banungi',\n",
       " 'Thank so much for the giving nice ideas to make Biryani',\n",
       " 'It a nice way to make dum Biryani',\n",
       " 'It a awesome made this dish today and it turned tasiter thanks lot',\n",
       " 'kabita mam kya mein black jeera tsp marinade karte waqt aur rice banate waqt tsp use kar sakhti hu',\n",
       " 'thanks advise liye age try karungi',\n",
       " 'good',\n",
       " 'Kesar kon wala eag kesar use kr skte kya',\n",
       " 'Tanks',\n",
       " 'So confusing',\n",
       " 'Mam rice ki quatity cups mai tell kary plz kitnay cup rice leay apnay and cup size plz',\n",
       " 'sorry kavita ji bura mat maniye jo mera experience he wo share kiya pura ghar pareshan ho gaya bhuk se abhi khayi to pura ghar dantne laga apne ye kya bana diya',\n",
       " 'pata ni kesi biryani he itna time lag gaya or biryani jal gayi niche se sari ki sari isme photo option ni he warna apko daal deta chicken to pata hi ni kaha gaya sara jal gaya',\n",
       " 'Wow',\n",
       " 'or steam nikla to ',\n",
       " 'Superrr mam ',\n",
       " 'Hello aunty please adopt me ',\n",
       " 'Looking so tasty will make it today',\n",
       " 'mam kya mein green chillies ka paste use kar sakhti hu',\n",
       " 'Nice one',\n",
       " 'Mam thand mosam bina freez rakhe marinate ho skta kya ',\n",
       " 'i like ur reciepi nd gud job di',\n",
       " 'Very nice',\n",
       " 'Kabita ji m ur small little fan',\n",
       " 'Superb',\n",
       " 'Behan piyaj kiya hota hao',\n",
       " 'Super Mam ',\n",
       " 'Can we use steel pan if yes how to stop the chicken getting burnt ',\n",
       " 'Mane banaya Tha habby huya Tha ',\n",
       " 'mam mene ek baar banaya but color konsa use karna hoga',\n",
       " 'nice',\n",
       " 'I hungry ',\n",
       " 'Hello me aap ki recipe follow Ker ti hu Me ye Briyani bani per meri briyani me chicken jal gya niche se time Asa hua time jo aap ne Batya hai wo hi Kiya tha',\n",
       " 'aap bht piyari lagti hai awr bht meetha bolti hain ',\n",
       " 'mam itni time main ey jalega toh nahy Na niche se',\n",
       " 'Good',\n",
       " 'v v good',\n",
       " 'Very nice thank you',\n",
       " 'I love yar',\n",
       " 'I didnt know we have to put ghee for the moisture of the rice ',\n",
       " 'Hydrabadi bryani me lemon juice daltey hai briyani dum denay she pahlay humloag',\n",
       " 'Pls write ingredients',\n",
       " 'Pagal ho kya aap kuch bhi bnati ho aap jb chiken kacha hai or rice pakka huwa hai to jb usko hum payenge tb chawal gal jayenga samjhi aap meri bahan ji',\n",
       " 'kavita mam kya ham khade masalo ko grinder me mix karke daal sakte hai ',\n",
       " 'can we marinate the chicken for overnight for more softness or the taste would be odd',\n",
       " 'just tried it',\n",
       " 'mujhe nhi aata tha kuch bana but apke is video se mai bahot ache se bana pai nice',\n",
       " 'food colour naaa',\n",
       " 'Majedar biryani definitely going to make it for sure love and thank very much mam',\n",
       " 'Nice recipe like it',\n",
       " 'So yummy try it',\n",
       " 'mam kya mein hours ke liye chicken ko marinade kar sakthi hu',\n",
       " 'hello mam aaj humne pehele bar ehi recipe banai thi really mam awsm yummy ',\n",
       " 'Meri maa ne kaha ki tel mat kharab kar GST ke baad mehga ho gaya hai ',\n",
       " 'Gajab ek no bani ',\n",
       " 'my favorite it perfect',\n",
       " 'Can cook it using pressure cooker Without whistle Will the chicken cook ',\n",
       " 'wow kabita mam it so tasty',\n",
       " 'I had to leave note of appreciation You biryani recipe is big hit in my home So much so that we have stopped ordering biryani from out look forward to your recipes',\n",
       " 'Hello kabita ma am you doing best job this recipe is perfect very good keep going best luck',\n",
       " 'nice',\n",
       " 'but jab me itni der tak paka Rahe he tab oil nahi or Pani Kuch vi nahi dya chicken aur rice niche to masala aur chicken jal nahi Jayega please reply ',\n",
       " 'mam ye biryani Jo apne banaya hain ye kitne logo keliye hain',\n",
       " 'I made this biryani yesterday but it did not turn out like urs Actually the masala in chicken was lot and cos of that it was like gravy Should use less dahi or more rice Pls tell',\n",
       " 'wow',\n",
       " 'Mei hostel me rhta hu to waha fridge ni to aisa jruri kya chiken ko marinate krne bad usko fridge me rkhna jruri plz let me know ',\n",
       " 'perfect ',\n",
       " 'Hiii mam meri biryani nichese jal gayi thi to kya kare means kya krne ka ',\n",
       " 'I will try tonight In your website link you have forgotten to add salt to the Chicken marination guess you will rectify it ',\n",
       " 'MashaAllah Bhot Umda ',\n",
       " 'Kabila Ji Great recipe thank you',\n",
       " 'Hello kabita mam how to prepare shahi biryani masala powder can we get it outside ',\n",
       " 'Thaq kabitha ji ',\n",
       " 'Salaam kabeta ma ne apko subscribe kyia thank you so much',\n",
       " 'bht hi zda taste bani thi bryni mai bi ap jaisa dikhaye waisa hi banayi thi mere hsbnd ko bht zda psnd ayi bht khush huwe mere hsbnd thnk so much di ',\n",
       " 'kabita mam kya mein chicken masala garam masala shahi biryani masala jeera powder coriander powder nutmeg powder ke saath black pepper powder add kar sakthe hain kyunki mujhe best hyderabadi style chicken dum biryani ka flavour chahiye please mam reply',\n",
       " 'Meri biryani hamesa niche se jaljata hai kyu plz reply',\n",
       " 'Chiken mai dahi dalne se kya hota hai aunty',\n",
       " 'Nice voice ',\n",
       " 'you are best mam Million Views and still counting Keep it up Mam ',\n",
       " 'Chan',\n",
       " 'I want to try dis',\n",
       " 'Ghee Kon sa deshi ',\n",
       " 'hi kabita nice recipe can you please tell which brand kadai you are using for frying onion like its design ',\n",
       " 'Kabita mam is it important to keep it on tava Can we can keep it on stove top for low flame plz reply',\n",
       " 'Mam zruri to ni hy na shahi biryani masala dalna agar na ho to',\n",
       " 'For the st time was able to make yummy chicken dum biryani earlier made several unsuccessful attempt Thank you very much ',\n",
       " 'So nice ',\n",
       " 'thanxx mam mei try krugi',\n",
       " 'mam kesar compulsory hai kya',\n",
       " 'I made this biryani it was awesome and everyone at home liked it really so much Thank you so much Keep posting ',\n",
       " 'Nice',\n",
       " 'nice',\n",
       " 'Its was horrible tried bt hmko pasnd nhi ayi chiken ws not cooked as it get cooked in oil dont like it Apki saro recipe bshut acchi hoti bt yeh wali try krne bad feel soch smjh banaye ',\n",
       " 'Plz reply me',\n",
       " 'Hmm the biryani is looking yummy ',\n",
       " 'Fb par ka name ha',\n",
       " 'Kavita mam agar rice chicken ki quantity zada le to dum lie time kitna dena hoga ',\n",
       " 'Mujhe aap ki recipe both achi lagi hai FB par kya naam hai',\n",
       " 'kabita mam marinade karthe waqt kitna spoon salt add karna hain',\n",
       " 'Nice',\n",
       " 'Hi',\n",
       " 'I tried this biryani recipe Kabita ji really appreciate your hard work ',\n",
       " 'nice',\n",
       " 'di ye chicken biyani bhagole me bana sakte plz give me ans',\n",
       " 'mam hyderabadi recipe mein thoda sa lime juice dalthe hain tho for hyderabadi flavour mein thoda sa lime juice tho dal sakthi hu mam bataiye na please ki kitna spoon lime juice dal sakhti hu kindly reply bahut important doubt hain kabita mam',\n",
       " 'thanku mam aap good ho',\n",
       " 'mam spoons ghee matlab tblspns or tsp',\n",
       " 'kabita mam can we put bay leaf while marinading',\n",
       " 'tho marinade karthe waqt chicken ginger garlicpaste pudina coriander leaves black elichi green elichi cinnamon cloves javitri curd green chillies salt haldi chilli powder garam masala coriander powder jeera powder shahi biryani masala tsp nutmeg powder ke saath spoons ghee aur onions dalthi hu',\n",
       " 'kabita mam mein kitna spoon ghee dalu marinate karthe waqt aur kitne onions dalu marinate karthe waqt',\n",
       " 'r sure chicken paak jayega ussay rice ki tarha pehlay thoda pakkanay ki jarurat toh nahi hai',\n",
       " 'kabita mam superb recipe clear video clearly explained is this the original Hyderabadi biryani recipe',\n",
       " 'mam mein kitna spoon nutmeg powder add karu please bataiye',\n",
       " 'nic',\n",
       " 'mam kya hum thoda sa nutmeg powder dal sakthe hain matlab apka opinion kya hain matlab coriander powder garam masala powder aur jeera powder ke saath acha lagega ya taste spoil hoga apka opinion kya hain',\n",
       " 'Biryani Masala kaise bnaate hai market me kbhi mila nhi',\n",
       " 'Hi Mme what kind of water do use to make dough cold or warm',\n",
       " 'Hello Mme how u very nice briani can ask something if don mind didn put water for cooking it won stick in the pan without water',\n",
       " 'apne is video me bht hi detail se sab btaya hai',\n",
       " 'yummy',\n",
       " 'Super mam ',\n",
       " 'WOw great recipe thanks for video',\n",
       " ' kilo biryani ke liye masala kitna lage ga',\n",
       " 'mam tho mein coriander powder jeera powder garam masala powder Sab tsp dalu please bataiye',\n",
       " 'mam aur jyada matlab tsp chalega mam apka opinion kya kitne spoon dalu please bataiye',\n",
       " 'mam apne ghee tblspn use kiya har layer mein tho mein tsp use karu matlab apne bola na ki aada quantity use kijiye tho tsp dalu',\n",
       " 'mam mein patanjali cow ghee use kar sakthi hu',\n",
       " 'mam kya hum cow ka ghee ghar per bana sakthe hain kyunki bahar ka quality acha nahin hain',\n",
       " 'Seal karne cooker blast hoga to kon zimmedaar hoga ',\n",
       " 'I am trying this right now wish me luck ',\n",
       " 'dewsi ghee means cow ghee',\n",
       " 'Doodh mein kesar full night tk bhigoke rkhna hai yaa instant',\n",
       " 'How to make shahi biryaani masala ',\n",
       " 'Kouc test nai hai wats video',\n",
       " 'kya ghee important hain',\n",
       " 'Perfect receipe ',\n",
       " 'waaaw tasty biryani myney aaj banaya hey it taste yummmm ',\n",
       " 'I AM sorry for this comment',\n",
       " 'Asy to chicken kachi rhygi',\n",
       " 'Apny chicken to pakya ni',\n",
       " 'chicken andar kaccha nehi raheha ',\n",
       " 'Good',\n",
       " 'kounsa chawal achha rahegaa matlab long grain rice ka name jo aap ',\n",
       " 'Awesome recipe',\n",
       " 'mujhe aap ki help chahiye mam mujhe yeh biriyani persons liye banana hai pls batayenge sare ingredients ka kitna kitna measurements rahega iss dushera me guests aayenge ghar pe plss bataiyeh kaise yeh jyada achha banega',\n",
       " 'kewra water aur rose water add karne ke baadh mein saffron milk aur orange colour add kar sakthi hu please bataiye kabita mam kyunki kewra water aur colour ka chemical reaction tho nahin hoga',\n",
       " 'aur hame kitna spoon coriander powder aur jeera powder aur garam masala powder add karna hain',\n",
       " 'kya hum normal rice use kar sakte mam please bataiya kyunki hame apke recipe ko dekhkar sabse best Christmas dish banana hain',\n",
       " 'kya mein coriander powder jeera powder ke saath garam masala bhi add kar sakthi hu marinade karthe waqt please bataiye kabita mam',\n",
       " 'i like your cooking ',\n",
       " 'Thank God for subtitles This looks pretty easy Thank you ',\n",
       " 'hi mam saw same your recipe on channel name Dark Moon Entertainment so thought to tell u',\n",
       " 'ooh ok',\n",
       " 'aap non veg dishes mat banaya kro only veg because veg jayada tasty hota hai',\n",
       " 'kya mein dhania powder aur jeera powder marinade karne ke liya use kar sakte hun ya biryani ka taste spoil hoga',\n",
       " 'Awesome biryani mam ',\n",
       " 'Great resipi',\n",
       " 'bakwash',\n",
       " 'nice',\n",
       " 'Iam doing it now After it done we will enjoy it ',\n",
       " 'Thank you Kavita for sharing dis yummy recipe made it today it was made so delicious thank you once again ',\n",
       " 'Nice',\n",
       " 'Bt great Video ',\n",
       " 'Mujhe sirf khaane maza Aata hai',\n",
       " 'Agar pudina patta na ho to uski jagah kya use karna hai kyuki humare yaha ye easily market may nai milta hai plz advice',\n",
       " 'This is first time ever m cooking biryani this as treat for my mom ve followed everything said what cooked was the best Biryani ve ever tasted thanks for the perfect recepie and instructions ',\n",
       " 'Competitively taste me ye briyani achi hai ya appki pressure cooker wali achi hai plz reply fast muje Sunday ko banani hai ',\n",
       " 'kya badi elichi important hain kyunki yaha shop mein available nahi hain',\n",
       " 'Kabita love it biriyani thank for this idea',\n",
       " 'Hello Kavita Mam have tried your recipe and followed ur step by step instructions biriyani turned out awesome Thanks for wonderful recipe in detail',\n",
       " 'Woow maam this was what needed thanks lot ye bahot asan lg tha ab ll definitely try ',\n",
       " 'wow so tasty',\n",
       " 'Realy its awesome very testy tha biriyani Thanks lot mam ',\n",
       " 'Osmmmm ',\n",
       " 'I will definitely try it',\n",
       " 'Wow so nice ur explanation made it more easy maam do we need to fry the chicken or can directly put the marinated chicken ',\n",
       " 'Thank you Madam ',\n",
       " 'nice',\n",
       " 'I love cooking and finding best chef on youtube trust r best chef among all chef',\n",
       " ' Super Duper ',\n",
       " 'Thanks ji',\n",
       " 'Hn saari biryaani jala di dikh rha hai vo nikalte time ',\n",
       " 'Madam don use plastic stainer or any plastic tool for hot food',\n",
       " 'What if use double the dose of saffron and skip the orange colorant Also can stand fresh coriander leaves they make me sick and taste to me like stink bugs can use parsley ',\n",
       " 'kabita di aapki bhut bdi fan hu aapse milna chahti hu Kolkata me v Kolkata se hi hu di',\n",
       " 'nice',\n",
       " 'Aap koun si chawal use kartehain mam ',\n",
       " 'Maine try kiya tha ',\n",
       " 'Thxz kavita mam im frm punjan india ll try definetly try thxz fr the video ',\n",
       " 'Hi kavita today try ur biryani recipe it really very yummy thanks',\n",
       " 'Very nice and yummy',\n",
       " 'normal flame chicken kaise paka madam tumhara bet chicken paka hi nahi hogaa tumhara',\n",
       " 'Ok ty mam',\n",
       " ' like your dishes ',\n",
       " 'I have been cooking biryani since long and after seeing your recepie tried that too but unfortunately in all them chicken or the bottom most layer is getting burnt did stick to all your steps but still am not able to over come this issue Could you please suggest where exactly may be going wrong ',\n",
       " 'Very very nice recipe mam very tasty ',\n",
       " 'which company basmati rice did you use ',\n",
       " 'Thank you for actually showing recipe that is Dum style most people mix the rice and chicken fully before cooking and call it Dum Biryani ',\n",
       " 'I will try it soon',\n",
       " 'ghee se zyada moisture hogya tha oil dalne se kam hota kya ',\n",
       " 'Freeze me chicken ni rkhe to kya kr skte uske jgh Plz say',\n",
       " 'Ok kavita ji thank you so much',\n",
       " 'kuch samajh nahi aya',\n",
       " 'khala ap ne aloo tu dalay hi ni',\n",
       " 'Kavita ji main saudi main hu ye sari cheeze main kaha se lao jo aap ne batayi hai',\n",
       " 'Thank mam',\n",
       " 'chhota and bada chamach ka size house to house differ karta to plz aap quantity jab batate tab spoon size ko dikha digiye video me',\n",
       " 'Mujhe khana hai ye biryani par mujhe banane nahi aata',\n",
       " 'Profi Thank you for information',\n",
       " 'Can we marinate chicken at night and keep in the fridge ',\n",
       " 'Mam only biriyani hi hoto iski serving kiyni hongi ',\n",
       " 'How much quantity if you only want to make for one person ',\n",
       " 'I have tried and my son is asking this every Sunday',\n",
       " 'Made this And it taste awsm Gr and easy recipy',\n",
       " 'Is color mandatory ',\n",
       " 'Hi Kabita tried your recipe today and it turned out to be awesome everyone in my family liked it Thank you ',\n",
       " 'vry nice',\n",
       " ' please make video on zam zam pulao am searching tasty zam zam pulao recipes from so many days but didn get any suitable recipe ll wait for your zam zam pulao recipe mam ',\n",
       " 'your house is veryyyyyyyyyyyyyyyyyyyyyyyy beautiful',\n",
       " ' kg ka bane se itna hi time me ho ga',\n",
       " 'agr isme potato bhi add krna ho to usko chicken ke saath marinate krke dalenge plz btaye',\n",
       " 'The last part with the dough on the cap was OD like literally don need to do that part',\n",
       " 'chiii mene try ki ghr pr biryani ki naam ki insult ye plzz guys koi try mt krna ghr pr',\n",
       " 'I have cook today chicken dum biryani have cook fast time it awesome thinks for help this wapside',\n",
       " 'plz mem shahi paneer or daal makhni bna sakte ho Kya',\n",
       " 'mam is me ham kaleji deal sakte h',\n",
       " 'I also try this recipe it was very nice ',\n",
       " 'meri birayani achhi bani thanks kabita nice recipe',\n",
       " 'main abhi bana rahi hun',\n",
       " 'I cooking it today ',\n",
       " 'Very eg yummy rcp mam Thanks ',\n",
       " 'tasty like it',\n",
       " 'mam want to try this but chicken kchcha to ni rhega ya koi smell to ni aaegi plz tell me',\n",
       " 'Thanks madam ji',\n",
       " 'mashaallah',\n",
       " 'why didn you use coriander powder in the biryani is it not required ',\n",
       " 'aapne jo rd stage main layer main kya mujhe ghee ya oil dalna hain chicken daalne se pehle because apne nahi daala so im confused please can you help',\n",
       " 'Hey Tried it It was super se upar Thanx ton Keep shining ',\n",
       " 'Very good video but sorry to say this is not hyderabadi chicken biryani',\n",
       " 'What is the javtree',\n",
       " 'Actually ek doubt Yahan pe chicken achese to pakta nhi hoga kyun ki marinate bad direct rice dal rahe ho app Can please explain mam',\n",
       " 'Nice and Real video ',\n",
       " 'Yu good mam apki recepi ko explain krne way bhot acha hai',\n",
       " 'Nice very tasty recepie',\n",
       " 'your dishes are awsome',\n",
       " 'Mene aaj banai It was awesome really very tasty ',\n",
       " 'it was very nice',\n",
       " 'Sorry but you are so sweet',\n",
       " 'Good',\n",
       " 'Am looking for yakhni biryani recipe can find it',\n",
       " 'I don like this biriyani',\n",
       " 'bina pani ka to jal jayega',\n",
       " 'Yummmmmy',\n",
       " 'ok biriyani ka jo atar mitha Atar hota hai usko to ap nahi diya jisme se bgiriyani ka orginal cent atehai ',\n",
       " 'agar fridge na ho to kese banayenge',\n",
       " 'kukar ka istemal kr skte hai kya',\n",
       " 'mam curd sour lena hai please reaply ans mam ',\n",
       " 'tooooo yummmmmmmmmyyyyyyyyyy',\n",
       " 'awesome',\n",
       " 'Aap ne oil tho dala hi nahi',\n",
       " 'Lolllll Yeh biryani Hai ya sabji Ese Todhi na Banti Hai pagal biryani',\n",
       " 'I watching it in the middle of night Mcdonalds is the only option now guess',\n",
       " 'kesar is necessary and food colour',\n",
       " 'Ingredients uses are high as compare to Briyani made Not good',\n",
       " 'Mast mam will try today',\n",
       " 'nice one ',\n",
       " 'V nice',\n",
       " 'maine aaj try ki bohot tasty bani thi thanks alot',\n",
       " 'maine try kiya ye last Friday Ko it was delicious awsm ',\n",
       " 'Kabita ji aapne khosboo liye kuch use nahi kiya ',\n",
       " 'Kabita ji want to try it Please aap mujhe batayenge chawal long aur fluffy kaise banega Main jitna bhi high quality Ka basmati rice Liya magar wo restaurant jaisa long and fluffy nahi banta ha Please reply ',\n",
       " 'Thankyou kabita kitchen ',\n",
       " ' kg chicken ke liye aur kitni quantity masale add Karna padega aur rice bhi kitni quantity badani padegi ',\n",
       " 'Very easy process mam thanks',\n",
       " 'Owsome',\n",
       " 'very nice biryani',\n",
       " 'Maza aagaya kasam se sanjita',\n",
       " 'I will surelly try this but after shraavan',\n",
       " 'Mam boneless chicken use karna ho to kitni der pakana hai kyun ki who to bahut jaldi gal Basra hai',\n",
       " 'my fridge is vegetarian then what do',\n",
       " 'Hello Kabita mam which ghee Vanaspati or Pure Ghee Please reply quickly ',\n",
       " 'I love kabita aunty kitchen',\n",
       " 'muze aisi biwi chahiye jo sirf khana achcha banane wali ho baki me samhal lunga ',\n",
       " 'mam please kg biryani ke liye video banao',\n",
       " 'mam chahwal ko bhogona he adha ghntta ya sirf ubalna he',\n",
       " 'hai',\n",
       " 'it was helpful thanks for the recipe cooked it today and it was yummi',\n",
       " 'very nice mam thank u',\n",
       " 'u can make khichda plz for me',\n",
       " 'very nice',\n",
       " 'Mam Bas hr marinate krke nd fir bas dum pe chadha chicken pakk jayega Kachha reh gya to ',\n",
       " 'ma am vo jo chicken badhey pieces vo jalte ni proper cook ho jate h',\n",
       " 'mam your chicken biryani will taste of coriander biryani will not take risk your RECIPE is not Hydrabadi ',\n",
       " 'Kabita ji kya is me dahi dalna zrori he',\n",
       " 'javitri matlab',\n",
       " 'Ohhhhhhhhhhhhhh Nice',\n",
       " 'aap cooking bahut acchi karti hai aap apna naam bataye kyuki mujhe aapse biryi sikni hai',\n",
       " 'Bahut Bariki Se Aapne Batya Hai Mam ',\n",
       " 'Hi Kabita Today tried this chicken biryani recipie of your Its the first time in my life that cooked your recipie and have to tell you that it was absolutely fantastic shocjed myself Wish you could taste it Thank You for this wonderful recipie Tc and gd bless ',\n",
       " 'osm',\n",
       " 'Thanks lot for the recipe Never knew that the first try would be so successful ',\n",
       " 'My first Briyani and trust me it was more than awesome big thanks to Kabita Kitchen ',\n",
       " 'i jst cooked this biryani trust me guys its really good jst follow the process step by step as it is told and ll end up having super tasty lip smacking biryani kabita didi ur the best thank so much',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4941ea8e",
   "metadata": {},
   "source": [
    "### getting word embedding using XLM transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b8b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10f9abab58e48d583a81351d68e3f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff65af8392ce44139941b8fee55f1219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/852 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d30bdfb6974711b2bb14d813cf0d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb1fceaacf040918f6044c15752a9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8fb7e5894d4b43bcf7e2d9205a2aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\xlm-roberta-large-finetuned-conll03-english. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90814894 0.8668213  0.38120833 ... 1.1636729  0.46106726 0.99468267]\n",
      " [1.6373361  0.25821534 0.8477912  ... 1.5591197  0.94069386 1.1253723 ]\n",
      " [1.8738445  1.1038636  0.51972157 ... 1.4362766  0.6611838  1.1790228 ]\n",
      " ...\n",
      " [1.1534717  0.95411134 0.9098582  ... 0.6285218  0.1377453  0.842537  ]\n",
      " [1.5148952  2.0001512  0.8409624  ... 0.79109806 1.0929217  0.6296201 ]\n",
      " [1.1275318  1.0432392  0.21929723 ... 1.1178541  1.1075363  1.4357535 ]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/stsb-xlm-r-multilingual')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7770b78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.908149</td>\n",
       "      <td>0.866821</td>\n",
       "      <td>0.381208</td>\n",
       "      <td>-1.171949</td>\n",
       "      <td>0.679888</td>\n",
       "      <td>0.094042</td>\n",
       "      <td>1.037212</td>\n",
       "      <td>-1.304330</td>\n",
       "      <td>-1.316941</td>\n",
       "      <td>0.481992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563855</td>\n",
       "      <td>-0.453248</td>\n",
       "      <td>-0.931863</td>\n",
       "      <td>-0.090244</td>\n",
       "      <td>1.601125</td>\n",
       "      <td>-0.138336</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>1.163673</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.994683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.637336</td>\n",
       "      <td>0.258215</td>\n",
       "      <td>0.847791</td>\n",
       "      <td>-1.552886</td>\n",
       "      <td>0.917667</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.736332</td>\n",
       "      <td>-0.863348</td>\n",
       "      <td>-1.348940</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313697</td>\n",
       "      <td>-0.773354</td>\n",
       "      <td>-1.025097</td>\n",
       "      <td>-0.181964</td>\n",
       "      <td>1.172557</td>\n",
       "      <td>-0.518694</td>\n",
       "      <td>0.128625</td>\n",
       "      <td>1.559120</td>\n",
       "      <td>0.940694</td>\n",
       "      <td>1.125372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.873845</td>\n",
       "      <td>1.103864</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>-1.696880</td>\n",
       "      <td>1.124637</td>\n",
       "      <td>0.481473</td>\n",
       "      <td>0.839816</td>\n",
       "      <td>-0.711462</td>\n",
       "      <td>-1.288883</td>\n",
       "      <td>-0.021840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.113249</td>\n",
       "      <td>-1.426260</td>\n",
       "      <td>-0.333346</td>\n",
       "      <td>1.776007</td>\n",
       "      <td>-0.326367</td>\n",
       "      <td>-0.058917</td>\n",
       "      <td>1.436277</td>\n",
       "      <td>0.661184</td>\n",
       "      <td>1.179023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.742430</td>\n",
       "      <td>1.221065</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>-1.381089</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>0.724774</td>\n",
       "      <td>0.978957</td>\n",
       "      <td>-0.874197</td>\n",
       "      <td>-1.347417</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>-1.252430</td>\n",
       "      <td>-0.124312</td>\n",
       "      <td>1.506073</td>\n",
       "      <td>-0.501876</td>\n",
       "      <td>-0.026798</td>\n",
       "      <td>1.468845</td>\n",
       "      <td>0.956655</td>\n",
       "      <td>1.427986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.879655</td>\n",
       "      <td>1.094084</td>\n",
       "      <td>0.322569</td>\n",
       "      <td>-1.465367</td>\n",
       "      <td>1.338802</td>\n",
       "      <td>0.313120</td>\n",
       "      <td>0.857127</td>\n",
       "      <td>-0.859403</td>\n",
       "      <td>-1.760325</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107808</td>\n",
       "      <td>-0.199703</td>\n",
       "      <td>-0.908525</td>\n",
       "      <td>-0.446286</td>\n",
       "      <td>1.555095</td>\n",
       "      <td>-0.312443</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>1.464481</td>\n",
       "      <td>0.482065</td>\n",
       "      <td>1.265778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>1.562536</td>\n",
       "      <td>1.120078</td>\n",
       "      <td>0.550967</td>\n",
       "      <td>-1.501385</td>\n",
       "      <td>1.051930</td>\n",
       "      <td>0.436489</td>\n",
       "      <td>0.922615</td>\n",
       "      <td>-0.587428</td>\n",
       "      <td>-1.368847</td>\n",
       "      <td>-0.198501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>-1.140427</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>1.234556</td>\n",
       "      <td>-0.231955</td>\n",
       "      <td>0.113495</td>\n",
       "      <td>1.458837</td>\n",
       "      <td>0.758282</td>\n",
       "      <td>1.424268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>1.892254</td>\n",
       "      <td>1.567004</td>\n",
       "      <td>0.436474</td>\n",
       "      <td>-1.498352</td>\n",
       "      <td>0.779637</td>\n",
       "      <td>0.265388</td>\n",
       "      <td>0.590138</td>\n",
       "      <td>-0.854081</td>\n",
       "      <td>-1.527283</td>\n",
       "      <td>0.591723</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078518</td>\n",
       "      <td>-0.242890</td>\n",
       "      <td>-0.695586</td>\n",
       "      <td>-0.514579</td>\n",
       "      <td>1.447915</td>\n",
       "      <td>-0.568910</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>1.111905</td>\n",
       "      <td>0.705450</td>\n",
       "      <td>1.240279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1.153472</td>\n",
       "      <td>0.954111</td>\n",
       "      <td>0.909858</td>\n",
       "      <td>-1.358361</td>\n",
       "      <td>0.642103</td>\n",
       "      <td>0.447320</td>\n",
       "      <td>0.448849</td>\n",
       "      <td>-1.093608</td>\n",
       "      <td>-1.168495</td>\n",
       "      <td>1.049327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>-0.726597</td>\n",
       "      <td>0.060931</td>\n",
       "      <td>-0.033440</td>\n",
       "      <td>1.149598</td>\n",
       "      <td>-0.266424</td>\n",
       "      <td>0.089222</td>\n",
       "      <td>0.628522</td>\n",
       "      <td>0.137745</td>\n",
       "      <td>0.842537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>1.514895</td>\n",
       "      <td>2.000151</td>\n",
       "      <td>0.840962</td>\n",
       "      <td>-0.970145</td>\n",
       "      <td>0.517247</td>\n",
       "      <td>0.919590</td>\n",
       "      <td>1.211363</td>\n",
       "      <td>-0.465556</td>\n",
       "      <td>-1.019368</td>\n",
       "      <td>0.551206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119512</td>\n",
       "      <td>-0.220480</td>\n",
       "      <td>-0.720605</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.770486</td>\n",
       "      <td>-0.406182</td>\n",
       "      <td>-0.072025</td>\n",
       "      <td>0.791098</td>\n",
       "      <td>1.092922</td>\n",
       "      <td>0.629620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>1.127532</td>\n",
       "      <td>1.043239</td>\n",
       "      <td>0.219297</td>\n",
       "      <td>-1.321965</td>\n",
       "      <td>1.272423</td>\n",
       "      <td>0.320794</td>\n",
       "      <td>1.132734</td>\n",
       "      <td>-1.186425</td>\n",
       "      <td>-1.437765</td>\n",
       "      <td>0.284373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>-0.339550</td>\n",
       "      <td>-1.140969</td>\n",
       "      <td>-0.271293</td>\n",
       "      <td>1.655919</td>\n",
       "      <td>-0.523468</td>\n",
       "      <td>-0.029664</td>\n",
       "      <td>1.117854</td>\n",
       "      <td>1.107536</td>\n",
       "      <td>1.435753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.908149  0.866821  0.381208 -1.171949  0.679888  0.094042  1.037212   \n",
       "1     1.637336  0.258215  0.847791 -1.552886  0.917667  0.033248  0.736332   \n",
       "2     1.873845  1.103864  0.519722 -1.696880  1.124637  0.481473  0.839816   \n",
       "3     1.742430  1.221065  0.453000 -1.381089  1.137504  0.724774  0.978957   \n",
       "4     1.879655  1.094084  0.322569 -1.465367  1.338802  0.313120  0.857127   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895  1.562536  1.120078  0.550967 -1.501385  1.051930  0.436489  0.922615   \n",
       "4896  1.892254  1.567004  0.436474 -1.498352  0.779637  0.265388  0.590138   \n",
       "4897  1.153472  0.954111  0.909858 -1.358361  0.642103  0.447320  0.448849   \n",
       "4898  1.514895  2.000151  0.840962 -0.970145  0.517247  0.919590  1.211363   \n",
       "4899  1.127532  1.043239  0.219297 -1.321965  1.272423  0.320794  1.132734   \n",
       "\n",
       "          7         8         9     ...      1014      1015      1016  \\\n",
       "0    -1.304330 -1.316941  0.481992  ...  0.563855 -0.453248 -0.931863   \n",
       "1    -0.863348 -1.348940  0.267578  ... -0.313697 -0.773354 -1.025097   \n",
       "2    -0.711462 -1.288883 -0.021840  ...  0.006631  0.113249 -1.426260   \n",
       "3    -0.874197 -1.347417  0.056060  ...  0.034906 -0.067300 -1.252430   \n",
       "4    -0.859403 -1.760325 -0.010340  ...  0.107808 -0.199703 -0.908525   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895 -0.587428 -1.368847 -0.198501  ...  0.031206  0.013468 -1.140427   \n",
       "4896 -0.854081 -1.527283  0.591723  ... -1.078518 -0.242890 -0.695586   \n",
       "4897 -1.093608 -1.168495  1.049327  ...  0.055114 -0.726597  0.060931   \n",
       "4898 -0.465556 -1.019368  0.551206  ... -0.119512 -0.220480 -0.720605   \n",
       "4899 -1.186425 -1.437765  0.284373  ...  0.147171 -0.339550 -1.140969   \n",
       "\n",
       "          1017      1018      1019      1020      1021      1022      1023  \n",
       "0    -0.090244  1.601125 -0.138336  0.036671  1.163673  0.461067  0.994683  \n",
       "1    -0.181964  1.172557 -0.518694  0.128625  1.559120  0.940694  1.125372  \n",
       "2    -0.333346  1.776007 -0.326367 -0.058917  1.436277  0.661184  1.179023  \n",
       "3    -0.124312  1.506073 -0.501876 -0.026798  1.468845  0.956655  1.427986  \n",
       "4    -0.446286  1.555095 -0.312443  0.046493  1.464481  0.482065  1.265778  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895  0.019620  1.234556 -0.231955  0.113495  1.458837  0.758282  1.424268  \n",
       "4896 -0.514579  1.447915 -0.568910  0.015116  1.111905  0.705450  1.240279  \n",
       "4897 -0.033440  1.149598 -0.266424  0.089222  0.628522  0.137745  0.842537  \n",
       "4898  0.079692  0.770486 -0.406182 -0.072025  0.791098  1.092922  0.629620  \n",
       "4899 -0.271293  1.655919 -0.523468 -0.029664  1.117854  1.107536  1.435753  \n",
       "\n",
       "[4900 rows x 1024 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm_df = pd.DataFrame(embeddings)\n",
    "xlm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79120209",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//xlm_vectorized_kabita_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730aa05",
   "metadata": {},
   "source": [
    "### getting word embedding using BERT transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a74afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9b0d15eebd4b099aeba32caf359fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c468cb16441f4b37addd53b896281552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da75da2a4da4e9fb42d1b20d6248386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8aa3f5ebdd4803ba1faf103388713b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/81.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989d90254e0e4cf78cff8d8e65fad1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897d1cd024e2403192eeb38c0341ce43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4160aac193046dd9bd28fc45cc2a454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\distilbert-base-uncased-finetuned-sst-2-english. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05298047  0.46460846  0.12857121 ... -0.1776662  -0.2401006\n",
      "   0.7487494 ]\n",
      " [-0.15316881  0.18237548  0.03625543 ...  0.00860855 -0.18200834\n",
      "   0.11966123]\n",
      " [ 0.00299541  0.13435863  0.3798864  ...  0.16871294  0.93646514\n",
      "  -0.02715036]\n",
      " ...\n",
      " [ 0.77477777  0.25367314  0.5707963  ...  0.59725314  0.7919525\n",
      "  -0.44885904]\n",
      " [ 0.77499753  0.06850544  0.51571363 ...  0.26755524  0.7783724\n",
      "  -0.7538733 ]\n",
      " [ 0.01760843  0.5953062   0.55248594 ... -0.14397418  0.2595101\n",
      "   0.40717518]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0823f8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>-0.773359</td>\n",
       "      <td>-0.310828</td>\n",
       "      <td>0.213925</td>\n",
       "      <td>0.347751</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>0.229023</td>\n",
       "      <td>-0.062887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>-0.180135</td>\n",
       "      <td>-0.281728</td>\n",
       "      <td>-0.697744</td>\n",
       "      <td>0.389690</td>\n",
       "      <td>-0.373868</td>\n",
       "      <td>0.276626</td>\n",
       "      <td>-0.177666</td>\n",
       "      <td>-0.240101</td>\n",
       "      <td>0.748749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.153169</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>-0.678261</td>\n",
       "      <td>-0.595770</td>\n",
       "      <td>0.311767</td>\n",
       "      <td>0.664820</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>0.100217</td>\n",
       "      <td>0.041971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248056</td>\n",
       "      <td>-0.950148</td>\n",
       "      <td>-0.332988</td>\n",
       "      <td>-0.313372</td>\n",
       "      <td>-0.098595</td>\n",
       "      <td>-0.669988</td>\n",
       "      <td>0.389401</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>-0.182008</td>\n",
       "      <td>0.119661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.134359</td>\n",
       "      <td>0.379886</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.810262</td>\n",
       "      <td>-0.561807</td>\n",
       "      <td>0.054050</td>\n",
       "      <td>0.446251</td>\n",
       "      <td>-0.433633</td>\n",
       "      <td>-0.608689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902700</td>\n",
       "      <td>-0.633872</td>\n",
       "      <td>-0.026738</td>\n",
       "      <td>-0.624753</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>-0.199141</td>\n",
       "      <td>0.358618</td>\n",
       "      <td>0.168713</td>\n",
       "      <td>0.936465</td>\n",
       "      <td>-0.027150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408438</td>\n",
       "      <td>0.134771</td>\n",
       "      <td>0.424775</td>\n",
       "      <td>0.162323</td>\n",
       "      <td>0.901796</td>\n",
       "      <td>-0.331613</td>\n",
       "      <td>-0.590608</td>\n",
       "      <td>0.234335</td>\n",
       "      <td>-0.373686</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932575</td>\n",
       "      <td>-0.397624</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>-0.314324</td>\n",
       "      <td>0.129691</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.466237</td>\n",
       "      <td>0.188901</td>\n",
       "      <td>0.762330</td>\n",
       "      <td>-0.299992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321177</td>\n",
       "      <td>0.313907</td>\n",
       "      <td>-0.078572</td>\n",
       "      <td>-0.779463</td>\n",
       "      <td>0.284209</td>\n",
       "      <td>-0.172351</td>\n",
       "      <td>0.586432</td>\n",
       "      <td>-0.190680</td>\n",
       "      <td>0.230872</td>\n",
       "      <td>-0.009547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>-1.198481</td>\n",
       "      <td>-0.262158</td>\n",
       "      <td>-0.957886</td>\n",
       "      <td>0.052870</td>\n",
       "      <td>-0.738266</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.067607</td>\n",
       "      <td>0.319365</td>\n",
       "      <td>0.498241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.235953</td>\n",
       "      <td>0.404553</td>\n",
       "      <td>0.466617</td>\n",
       "      <td>0.136132</td>\n",
       "      <td>0.728176</td>\n",
       "      <td>-0.703223</td>\n",
       "      <td>-0.249281</td>\n",
       "      <td>0.608803</td>\n",
       "      <td>-0.853866</td>\n",
       "      <td>-0.209945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.572246</td>\n",
       "      <td>-0.510898</td>\n",
       "      <td>-0.032700</td>\n",
       "      <td>-0.517305</td>\n",
       "      <td>0.172465</td>\n",
       "      <td>-0.221193</td>\n",
       "      <td>0.278372</td>\n",
       "      <td>0.273908</td>\n",
       "      <td>0.840953</td>\n",
       "      <td>-0.286667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.033628</td>\n",
       "      <td>0.499263</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>-0.235870</td>\n",
       "      <td>0.275344</td>\n",
       "      <td>0.030766</td>\n",
       "      <td>0.312375</td>\n",
       "      <td>0.212204</td>\n",
       "      <td>-0.600025</td>\n",
       "      <td>-0.052594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>-0.162915</td>\n",
       "      <td>-0.512258</td>\n",
       "      <td>-0.829277</td>\n",
       "      <td>0.194307</td>\n",
       "      <td>-0.496164</td>\n",
       "      <td>0.155986</td>\n",
       "      <td>-0.075254</td>\n",
       "      <td>-0.034164</td>\n",
       "      <td>0.195268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.774778</td>\n",
       "      <td>0.253673</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.168029</td>\n",
       "      <td>0.699086</td>\n",
       "      <td>-0.617626</td>\n",
       "      <td>-0.219746</td>\n",
       "      <td>0.632238</td>\n",
       "      <td>-0.810447</td>\n",
       "      <td>0.288463</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.182119</td>\n",
       "      <td>-0.465108</td>\n",
       "      <td>-0.127879</td>\n",
       "      <td>-0.543055</td>\n",
       "      <td>0.486032</td>\n",
       "      <td>-0.267128</td>\n",
       "      <td>-0.369808</td>\n",
       "      <td>0.597253</td>\n",
       "      <td>0.791952</td>\n",
       "      <td>-0.448859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>0.774998</td>\n",
       "      <td>0.068505</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.090659</td>\n",
       "      <td>0.806777</td>\n",
       "      <td>-0.372340</td>\n",
       "      <td>-0.101753</td>\n",
       "      <td>0.422783</td>\n",
       "      <td>-0.808106</td>\n",
       "      <td>0.088662</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.382397</td>\n",
       "      <td>-0.131801</td>\n",
       "      <td>-0.055117</td>\n",
       "      <td>-0.382125</td>\n",
       "      <td>-0.111573</td>\n",
       "      <td>-0.779869</td>\n",
       "      <td>-0.177176</td>\n",
       "      <td>0.267555</td>\n",
       "      <td>0.778372</td>\n",
       "      <td>-0.753873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>0.017608</td>\n",
       "      <td>0.595306</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>-0.290990</td>\n",
       "      <td>0.161085</td>\n",
       "      <td>-0.239604</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.308880</td>\n",
       "      <td>0.271420</td>\n",
       "      <td>-0.167172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471527</td>\n",
       "      <td>-0.298686</td>\n",
       "      <td>-0.161100</td>\n",
       "      <td>-0.865123</td>\n",
       "      <td>0.180132</td>\n",
       "      <td>-0.359675</td>\n",
       "      <td>0.466941</td>\n",
       "      <td>-0.143974</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.407175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.052980  0.464608  0.128571 -0.773359 -0.310828  0.213925  0.347751   \n",
       "1    -0.153169  0.182375  0.036255 -0.678261 -0.595770  0.311767  0.664820   \n",
       "2     0.002995  0.134359  0.379886  0.063746  0.810262 -0.561807  0.054050   \n",
       "3     0.408438  0.134771  0.424775  0.162323  0.901796 -0.331613 -0.590608   \n",
       "4     0.321177  0.313907 -0.078572 -0.779463  0.284209 -0.172351  0.586432   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895  0.235953  0.404553  0.466617  0.136132  0.728176 -0.703223 -0.249281   \n",
       "4896  0.033628  0.499263  0.033876 -0.235870  0.275344  0.030766  0.312375   \n",
       "4897  0.774778  0.253673  0.570796  0.168029  0.699086 -0.617626 -0.219746   \n",
       "4898  0.774998  0.068505  0.515714  0.090659  0.806777 -0.372340 -0.101753   \n",
       "4899  0.017608  0.595306  0.552486 -0.290990  0.161085 -0.239604  0.343301   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     0.750556  0.229023 -0.062887  ...  0.350102 -0.180135 -0.281728   \n",
       "1     0.089929  0.100217  0.041971  ...  0.248056 -0.950148 -0.332988   \n",
       "2     0.446251 -0.433633 -0.608689  ... -0.902700 -0.633872 -0.026738   \n",
       "3     0.234335 -0.373686 -0.427458  ... -0.932575 -0.397624  0.008478   \n",
       "4    -0.190680  0.230872 -0.009547  ...  0.167952 -1.198481 -0.262158   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895  0.608803 -0.853866 -0.209945  ... -0.572246 -0.510898 -0.032700   \n",
       "4896  0.212204 -0.600025 -0.052594  ...  0.006622 -0.162915 -0.512258   \n",
       "4897  0.632238 -0.810447  0.288463  ... -1.182119 -0.465108 -0.127879   \n",
       "4898  0.422783 -0.808106  0.088662  ... -1.382397 -0.131801 -0.055117   \n",
       "4899  0.308880  0.271420 -0.167172  ...  0.471527 -0.298686 -0.161100   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.697744  0.389690 -0.373868  0.276626 -0.177666 -0.240101  0.748749  \n",
       "1    -0.313372 -0.098595 -0.669988  0.389401  0.008609 -0.182008  0.119661  \n",
       "2    -0.624753  0.156098 -0.199141  0.358618  0.168713  0.936465 -0.027150  \n",
       "3    -0.314324  0.129691  0.004359  0.466237  0.188901  0.762330 -0.299992  \n",
       "4    -0.957886  0.052870 -0.738266  0.593514  0.067607  0.319365  0.498241  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895 -0.517305  0.172465 -0.221193  0.278372  0.273908  0.840953 -0.286667  \n",
       "4896 -0.829277  0.194307 -0.496164  0.155986 -0.075254 -0.034164  0.195268  \n",
       "4897 -0.543055  0.486032 -0.267128 -0.369808  0.597253  0.791952 -0.448859  \n",
       "4898 -0.382125 -0.111573 -0.779869 -0.177176  0.267555  0.778372 -0.753873  \n",
       "4899 -0.865123  0.180132 -0.359675  0.466941 -0.143974  0.259510  0.407175  \n",
       "\n",
       "[4900 rows x 768 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_df = pd.DataFrame(embeddings)\n",
    "bert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2ecaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38295f48",
   "metadata": {},
   "source": [
    "### getting word embedding using GPT transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37ab7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21197382  1.2708888  -0.17546438 ...  0.47423732  0.3117013\n",
      "   0.04553512]\n",
      " [-0.47618312  0.51628345 -0.31600535 ... -0.03314586  0.44915622\n",
      "   0.2643302 ]\n",
      " [ 0.5446054   0.18246505  0.46532094 ... -0.10930318 -0.46502393\n",
      "   1.9669464 ]\n",
      " ...\n",
      " [-0.12365481  0.35453427  0.17537709 ... -0.4073924  -0.31537446\n",
      "   0.36904633]\n",
      " [ 0.34711048  0.64370155  0.38642314 ...  0.14911652 -0.03114069\n",
      "   0.27657574]\n",
      " [-0.39712918  0.09698448  0.14887026 ...  0.35229373  0.34684494\n",
      "   0.17913266]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('Muennighoff/SGPT-125M-mean-nli')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df0b62e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211974</td>\n",
       "      <td>1.270889</td>\n",
       "      <td>-0.175464</td>\n",
       "      <td>-0.056867</td>\n",
       "      <td>0.267969</td>\n",
       "      <td>1.777547</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>1.326541</td>\n",
       "      <td>0.068738</td>\n",
       "      <td>-0.262352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336537</td>\n",
       "      <td>1.118200</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.328713</td>\n",
       "      <td>-0.092587</td>\n",
       "      <td>-0.201130</td>\n",
       "      <td>-0.181676</td>\n",
       "      <td>0.474237</td>\n",
       "      <td>0.311701</td>\n",
       "      <td>0.045535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.476183</td>\n",
       "      <td>0.516283</td>\n",
       "      <td>-0.316005</td>\n",
       "      <td>-0.168094</td>\n",
       "      <td>0.735854</td>\n",
       "      <td>0.865828</td>\n",
       "      <td>-0.611422</td>\n",
       "      <td>0.660393</td>\n",
       "      <td>-0.491673</td>\n",
       "      <td>0.045016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121701</td>\n",
       "      <td>-0.316118</td>\n",
       "      <td>-0.496502</td>\n",
       "      <td>-0.762571</td>\n",
       "      <td>0.359269</td>\n",
       "      <td>-1.755350</td>\n",
       "      <td>-0.304121</td>\n",
       "      <td>-0.033146</td>\n",
       "      <td>0.449156</td>\n",
       "      <td>0.264330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.544605</td>\n",
       "      <td>0.182465</td>\n",
       "      <td>0.465321</td>\n",
       "      <td>-1.052795</td>\n",
       "      <td>-0.554435</td>\n",
       "      <td>0.595691</td>\n",
       "      <td>0.380034</td>\n",
       "      <td>1.438977</td>\n",
       "      <td>-1.326972</td>\n",
       "      <td>-0.697750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481327</td>\n",
       "      <td>-0.635220</td>\n",
       "      <td>-0.296181</td>\n",
       "      <td>-0.392727</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>-0.589627</td>\n",
       "      <td>-1.169872</td>\n",
       "      <td>-0.109303</td>\n",
       "      <td>-0.465024</td>\n",
       "      <td>1.966946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386654</td>\n",
       "      <td>0.502101</td>\n",
       "      <td>0.522348</td>\n",
       "      <td>-1.459961</td>\n",
       "      <td>1.402257</td>\n",
       "      <td>-0.039568</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.053887</td>\n",
       "      <td>-1.418120</td>\n",
       "      <td>0.159173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>-0.107940</td>\n",
       "      <td>0.057398</td>\n",
       "      <td>-0.887733</td>\n",
       "      <td>-0.549139</td>\n",
       "      <td>0.488153</td>\n",
       "      <td>-1.022718</td>\n",
       "      <td>-0.353387</td>\n",
       "      <td>-0.189969</td>\n",
       "      <td>0.616283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>-0.527401</td>\n",
       "      <td>-0.329351</td>\n",
       "      <td>0.093132</td>\n",
       "      <td>-0.246717</td>\n",
       "      <td>-0.061068</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>0.131107</td>\n",
       "      <td>0.450785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202649</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>-0.589659</td>\n",
       "      <td>-0.805061</td>\n",
       "      <td>1.253467</td>\n",
       "      <td>-0.462865</td>\n",
       "      <td>-0.152428</td>\n",
       "      <td>0.444929</td>\n",
       "      <td>0.587048</td>\n",
       "      <td>0.106981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.340942</td>\n",
       "      <td>-0.222584</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>-0.618760</td>\n",
       "      <td>1.340927</td>\n",
       "      <td>0.759075</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>1.091592</td>\n",
       "      <td>0.165121</td>\n",
       "      <td>-0.055406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528208</td>\n",
       "      <td>-0.385468</td>\n",
       "      <td>0.077745</td>\n",
       "      <td>-0.748396</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>-0.881079</td>\n",
       "      <td>-0.134982</td>\n",
       "      <td>0.552665</td>\n",
       "      <td>0.067825</td>\n",
       "      <td>1.186216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>-0.044812</td>\n",
       "      <td>0.050046</td>\n",
       "      <td>0.120236</td>\n",
       "      <td>-0.086727</td>\n",
       "      <td>0.232654</td>\n",
       "      <td>-0.033159</td>\n",
       "      <td>-0.593683</td>\n",
       "      <td>1.125542</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183018</td>\n",
       "      <td>0.719590</td>\n",
       "      <td>-0.200128</td>\n",
       "      <td>-0.326415</td>\n",
       "      <td>0.513131</td>\n",
       "      <td>-1.007442</td>\n",
       "      <td>0.090349</td>\n",
       "      <td>0.518339</td>\n",
       "      <td>-0.087567</td>\n",
       "      <td>-0.622251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>-0.123655</td>\n",
       "      <td>0.354534</td>\n",
       "      <td>0.175377</td>\n",
       "      <td>-0.075972</td>\n",
       "      <td>0.438702</td>\n",
       "      <td>0.545708</td>\n",
       "      <td>-0.260574</td>\n",
       "      <td>-0.159305</td>\n",
       "      <td>0.232170</td>\n",
       "      <td>0.161077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494661</td>\n",
       "      <td>0.415942</td>\n",
       "      <td>-0.382951</td>\n",
       "      <td>0.108540</td>\n",
       "      <td>0.158021</td>\n",
       "      <td>-0.191864</td>\n",
       "      <td>-0.330703</td>\n",
       "      <td>-0.407392</td>\n",
       "      <td>-0.315374</td>\n",
       "      <td>0.369046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>0.347110</td>\n",
       "      <td>0.643702</td>\n",
       "      <td>0.386423</td>\n",
       "      <td>-0.389618</td>\n",
       "      <td>1.385095</td>\n",
       "      <td>0.485864</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>-0.572183</td>\n",
       "      <td>-0.455514</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192145</td>\n",
       "      <td>0.238542</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.066534</td>\n",
       "      <td>0.168229</td>\n",
       "      <td>-1.100379</td>\n",
       "      <td>-1.170902</td>\n",
       "      <td>0.149117</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0.276576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>-0.397129</td>\n",
       "      <td>0.096984</td>\n",
       "      <td>0.148870</td>\n",
       "      <td>-0.611734</td>\n",
       "      <td>0.368577</td>\n",
       "      <td>0.322632</td>\n",
       "      <td>-0.568928</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>-0.406499</td>\n",
       "      <td>0.255511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017053</td>\n",
       "      <td>0.647435</td>\n",
       "      <td>0.179804</td>\n",
       "      <td>-0.543546</td>\n",
       "      <td>0.548929</td>\n",
       "      <td>0.159491</td>\n",
       "      <td>-0.125520</td>\n",
       "      <td>0.352294</td>\n",
       "      <td>0.346845</td>\n",
       "      <td>0.179133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.211974  1.270889 -0.175464 -0.056867  0.267969  1.777547  0.052245   \n",
       "1    -0.476183  0.516283 -0.316005 -0.168094  0.735854  0.865828 -0.611422   \n",
       "2     0.544605  0.182465  0.465321 -1.052795 -0.554435  0.595691  0.380034   \n",
       "3     0.386654  0.502101  0.522348 -1.459961  1.402257 -0.039568  0.060267   \n",
       "4     0.009521  0.193356 -0.527401 -0.329351  0.093132 -0.246717 -0.061068   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895  0.340942 -0.222584  0.279221 -0.618760  1.340927  0.759075  0.068279   \n",
       "4896 -0.044812  0.050046  0.120236 -0.086727  0.232654 -0.033159 -0.593683   \n",
       "4897 -0.123655  0.354534  0.175377 -0.075972  0.438702  0.545708 -0.260574   \n",
       "4898  0.347110  0.643702  0.386423 -0.389618  1.385095  0.485864  0.034131   \n",
       "4899 -0.397129  0.096984  0.148870 -0.611734  0.368577  0.322632 -0.568928   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     1.326541  0.068738 -0.262352  ...  0.336537  1.118200  0.008726   \n",
       "1     0.660393 -0.491673  0.045016  ... -0.121701 -0.316118 -0.496502   \n",
       "2     1.438977 -1.326972 -0.697750  ... -0.481327 -0.635220 -0.296181   \n",
       "3     0.053887 -1.418120  0.159173  ...  0.014832 -0.107940  0.057398   \n",
       "4     0.575162  0.131107  0.450785  ... -0.202649  0.013554 -0.589659   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895  1.091592  0.165121 -0.055406  ... -0.528208 -0.385468  0.077745   \n",
       "4896  1.125542  0.106066  0.395994  ...  0.183018  0.719590 -0.200128   \n",
       "4897 -0.159305  0.232170  0.161077  ... -0.494661  0.415942 -0.382951   \n",
       "4898 -0.572183 -0.455514  0.259953  ...  0.192145  0.238542  0.584857   \n",
       "4899  0.012692 -0.406499  0.255511  ... -0.017053  0.647435  0.179804   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.328713 -0.092587 -0.201130 -0.181676  0.474237  0.311701  0.045535  \n",
       "1    -0.762571  0.359269 -1.755350 -0.304121 -0.033146  0.449156  0.264330  \n",
       "2    -0.392727  0.117460 -0.589627 -1.169872 -0.109303 -0.465024  1.966946  \n",
       "3    -0.887733 -0.549139  0.488153 -1.022718 -0.353387 -0.189969  0.616283  \n",
       "4    -0.805061  1.253467 -0.462865 -0.152428  0.444929  0.587048  0.106981  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895 -0.748396 -0.064917 -0.881079 -0.134982  0.552665  0.067825  1.186216  \n",
       "4896 -0.326415  0.513131 -1.007442  0.090349  0.518339 -0.087567 -0.622251  \n",
       "4897  0.108540  0.158021 -0.191864 -0.330703 -0.407392 -0.315374  0.369046  \n",
       "4898  0.066534  0.168229 -1.100379 -1.170902  0.149117 -0.031141  0.276576  \n",
       "4899 -0.543546  0.548929  0.159491 -0.125520  0.352294  0.346845  0.179133  \n",
       "\n",
       "[4900 rows x 768 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_df = pd.DataFrame(embeddings)\n",
    "gpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d63c6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//gpt_vectorized_kabita_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff61c9a",
   "metadata": {},
   "source": [
    "### getting word embedding using ganesh bert hinglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14b50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\ganeshkharad_gk-hinglish-sentiment. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\ganeshkharad_gk-hinglish-sentiment were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.6693873e-02  5.2116942e-02  3.1014347e-01 ... -3.7275133e-01\n",
      "  -1.1146526e-01 -6.9890535e-01]\n",
      " [ 3.2356799e-02 -8.3717555e-02 -4.5976270e-02 ...  1.8236525e-02\n",
      "   4.7608390e-02 -6.9385821e-01]\n",
      " [-4.2393919e-02 -7.3942594e-02  2.0427009e-01 ...  1.1003801e+00\n",
      "  -4.4019064e-01  3.9300606e-01]\n",
      " ...\n",
      " [ 1.8824412e-02  1.3753605e-01 -1.0980144e-03 ...  7.8933245e-01\n",
      "  -3.9935887e-01  1.6976456e-01]\n",
      " [-7.0332251e-02 -6.4943470e-02  1.9587953e-01 ...  1.1147084e+00\n",
      "  -4.3220869e-01  3.7572300e-01]\n",
      " [-7.6228129e-03  1.3220179e-01  2.3690033e-01 ... -3.1028238e-01\n",
      "  -9.2902817e-02 -7.1745396e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('ganeshkharad/gk-hinglish-sentiment')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617a875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.046694</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.310143</td>\n",
       "      <td>-0.937220</td>\n",
       "      <td>0.534607</td>\n",
       "      <td>-0.876761</td>\n",
       "      <td>-0.797576</td>\n",
       "      <td>0.204721</td>\n",
       "      <td>0.218969</td>\n",
       "      <td>-1.509958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886487</td>\n",
       "      <td>0.865031</td>\n",
       "      <td>-0.280166</td>\n",
       "      <td>-0.289375</td>\n",
       "      <td>1.507612</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>-0.443590</td>\n",
       "      <td>-0.372751</td>\n",
       "      <td>-0.111465</td>\n",
       "      <td>-0.698905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032357</td>\n",
       "      <td>-0.083718</td>\n",
       "      <td>-0.045976</td>\n",
       "      <td>-0.362558</td>\n",
       "      <td>-0.087163</td>\n",
       "      <td>-0.488820</td>\n",
       "      <td>-0.008291</td>\n",
       "      <td>-0.080647</td>\n",
       "      <td>0.518569</td>\n",
       "      <td>-1.234843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836472</td>\n",
       "      <td>0.509152</td>\n",
       "      <td>-0.060837</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>1.396114</td>\n",
       "      <td>0.709821</td>\n",
       "      <td>-0.464408</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>-0.693858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042394</td>\n",
       "      <td>-0.073943</td>\n",
       "      <td>0.204270</td>\n",
       "      <td>-0.241895</td>\n",
       "      <td>-0.917626</td>\n",
       "      <td>0.201630</td>\n",
       "      <td>-0.566796</td>\n",
       "      <td>-0.106995</td>\n",
       "      <td>-0.136753</td>\n",
       "      <td>0.652184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389642</td>\n",
       "      <td>-0.131217</td>\n",
       "      <td>-0.646135</td>\n",
       "      <td>-0.213125</td>\n",
       "      <td>-1.622547</td>\n",
       "      <td>-1.268149</td>\n",
       "      <td>-0.639556</td>\n",
       "      <td>1.100380</td>\n",
       "      <td>-0.440191</td>\n",
       "      <td>0.393006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.140079</td>\n",
       "      <td>-0.061068</td>\n",
       "      <td>0.135134</td>\n",
       "      <td>-0.380983</td>\n",
       "      <td>-0.826443</td>\n",
       "      <td>0.213372</td>\n",
       "      <td>-0.638237</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.035365</td>\n",
       "      <td>0.475120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331346</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>-0.689673</td>\n",
       "      <td>-0.409813</td>\n",
       "      <td>-1.434916</td>\n",
       "      <td>-1.157951</td>\n",
       "      <td>-0.636823</td>\n",
       "      <td>1.126686</td>\n",
       "      <td>-0.379717</td>\n",
       "      <td>0.293938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.109125</td>\n",
       "      <td>0.158773</td>\n",
       "      <td>0.096683</td>\n",
       "      <td>-0.648730</td>\n",
       "      <td>-0.081664</td>\n",
       "      <td>-1.052877</td>\n",
       "      <td>-0.395181</td>\n",
       "      <td>0.036152</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>-1.390344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854206</td>\n",
       "      <td>0.602549</td>\n",
       "      <td>-0.672070</td>\n",
       "      <td>-0.430902</td>\n",
       "      <td>1.355384</td>\n",
       "      <td>0.758812</td>\n",
       "      <td>-0.746309</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>0.110934</td>\n",
       "      <td>-0.735310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>-0.076107</td>\n",
       "      <td>-0.090647</td>\n",
       "      <td>0.221322</td>\n",
       "      <td>-0.257263</td>\n",
       "      <td>-0.870822</td>\n",
       "      <td>0.155469</td>\n",
       "      <td>-0.594669</td>\n",
       "      <td>-0.124210</td>\n",
       "      <td>-0.100103</td>\n",
       "      <td>0.614590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374438</td>\n",
       "      <td>-0.069833</td>\n",
       "      <td>-0.661995</td>\n",
       "      <td>-0.275930</td>\n",
       "      <td>-1.614532</td>\n",
       "      <td>-1.262784</td>\n",
       "      <td>-0.664122</td>\n",
       "      <td>1.110227</td>\n",
       "      <td>-0.440262</td>\n",
       "      <td>0.365384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.105774</td>\n",
       "      <td>-0.051178</td>\n",
       "      <td>-0.015522</td>\n",
       "      <td>-0.365665</td>\n",
       "      <td>-0.114606</td>\n",
       "      <td>-0.680374</td>\n",
       "      <td>-0.059640</td>\n",
       "      <td>-0.014550</td>\n",
       "      <td>0.426307</td>\n",
       "      <td>-1.159144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850179</td>\n",
       "      <td>0.557240</td>\n",
       "      <td>-0.182171</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>1.449013</td>\n",
       "      <td>0.640859</td>\n",
       "      <td>-0.567188</td>\n",
       "      <td>-0.053370</td>\n",
       "      <td>-0.031223</td>\n",
       "      <td>-0.753573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.137536</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.263536</td>\n",
       "      <td>-1.067132</td>\n",
       "      <td>0.515284</td>\n",
       "      <td>-0.414671</td>\n",
       "      <td>0.439292</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>0.548320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418193</td>\n",
       "      <td>-0.148909</td>\n",
       "      <td>-0.443660</td>\n",
       "      <td>-0.133807</td>\n",
       "      <td>-1.153851</td>\n",
       "      <td>-0.864886</td>\n",
       "      <td>-0.437835</td>\n",
       "      <td>0.789332</td>\n",
       "      <td>-0.399359</td>\n",
       "      <td>0.169765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>-0.070332</td>\n",
       "      <td>-0.064943</td>\n",
       "      <td>0.195880</td>\n",
       "      <td>-0.260227</td>\n",
       "      <td>-0.902869</td>\n",
       "      <td>0.191152</td>\n",
       "      <td>-0.574663</td>\n",
       "      <td>-0.122681</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>0.627523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.381732</td>\n",
       "      <td>-0.095545</td>\n",
       "      <td>-0.678748</td>\n",
       "      <td>-0.255552</td>\n",
       "      <td>-1.606399</td>\n",
       "      <td>-1.281051</td>\n",
       "      <td>-0.636737</td>\n",
       "      <td>1.114708</td>\n",
       "      <td>-0.432209</td>\n",
       "      <td>0.375723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>-0.007623</td>\n",
       "      <td>0.132202</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>-0.902729</td>\n",
       "      <td>0.478341</td>\n",
       "      <td>-0.859865</td>\n",
       "      <td>-0.793213</td>\n",
       "      <td>0.174142</td>\n",
       "      <td>0.218196</td>\n",
       "      <td>-1.565559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883769</td>\n",
       "      <td>0.828657</td>\n",
       "      <td>-0.360389</td>\n",
       "      <td>-0.284986</td>\n",
       "      <td>1.498465</td>\n",
       "      <td>0.164533</td>\n",
       "      <td>-0.506548</td>\n",
       "      <td>-0.310282</td>\n",
       "      <td>-0.092903</td>\n",
       "      <td>-0.717454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.046694  0.052117  0.310143 -0.937220  0.534607 -0.876761 -0.797576   \n",
       "1     0.032357 -0.083718 -0.045976 -0.362558 -0.087163 -0.488820 -0.008291   \n",
       "2    -0.042394 -0.073943  0.204270 -0.241895 -0.917626  0.201630 -0.566796   \n",
       "3    -0.140079 -0.061068  0.135134 -0.380983 -0.826443  0.213372 -0.638237   \n",
       "4    -0.109125  0.158773  0.096683 -0.648730 -0.081664 -1.052877 -0.395181   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895 -0.076107 -0.090647  0.221322 -0.257263 -0.870822  0.155469 -0.594669   \n",
       "4896  0.105774 -0.051178 -0.015522 -0.365665 -0.114606 -0.680374 -0.059640   \n",
       "4897  0.018824  0.137536 -0.001098 -0.263536 -1.067132  0.515284 -0.414671   \n",
       "4898 -0.070332 -0.064943  0.195880 -0.260227 -0.902869  0.191152 -0.574663   \n",
       "4899 -0.007623  0.132202  0.236900 -0.902729  0.478341 -0.859865 -0.793213   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     0.204721  0.218969 -1.509958  ...  0.886487  0.865031 -0.280166   \n",
       "1    -0.080647  0.518569 -1.234843  ...  0.836472  0.509152 -0.060837   \n",
       "2    -0.106995 -0.136753  0.652184  ... -0.389642 -0.131217 -0.646135   \n",
       "3     0.034409  0.035365  0.475120  ... -0.331346  0.030983 -0.689673   \n",
       "4     0.036152  0.332100 -1.390344  ...  0.854206  0.602549 -0.672070   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895 -0.124210 -0.100103  0.614590  ... -0.374438 -0.069833 -0.661995   \n",
       "4896 -0.014550  0.426307 -1.159144  ...  0.850179  0.557240 -0.182171   \n",
       "4897  0.439292  0.012974  0.548320  ... -0.418193 -0.148909 -0.443660   \n",
       "4898 -0.122681 -0.108217  0.627523  ... -0.381732 -0.095545 -0.678748   \n",
       "4899  0.174142  0.218196 -1.565559  ...  0.883769  0.828657 -0.360389   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.289375  1.507612  0.048212 -0.443590 -0.372751 -0.111465 -0.698905  \n",
       "1     0.044570  1.396114  0.709821 -0.464408  0.018237  0.047608 -0.693858  \n",
       "2    -0.213125 -1.622547 -1.268149 -0.639556  1.100380 -0.440191  0.393006  \n",
       "3    -0.409813 -1.434916 -1.157951 -0.636823  1.126686 -0.379717  0.293938  \n",
       "4    -0.430902  1.355384  0.758812 -0.746309  0.063162  0.110934 -0.735310  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895 -0.275930 -1.614532 -1.262784 -0.664122  1.110227 -0.440262  0.365384  \n",
       "4896  0.065832  1.449013  0.640859 -0.567188 -0.053370 -0.031223 -0.753573  \n",
       "4897 -0.133807 -1.153851 -0.864886 -0.437835  0.789332 -0.399359  0.169765  \n",
       "4898 -0.255552 -1.606399 -1.281051 -0.636737  1.114708 -0.432209  0.375723  \n",
       "4899 -0.284986  1.498465  0.164533 -0.506548 -0.310282 -0.092903 -0.717454  \n",
       "\n",
       "[4900 rows x 768 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkb_df = pd.DataFrame(embeddings)\n",
    "gkb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkb_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_gkb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007bea2b",
   "metadata": {},
   "source": [
    "### getting word embedding using Narasimha distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9ab476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0aab794f7249fa9352fab9dce2a934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae03dff3bca04c9bbbf510350b23062f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6a84b06f2a4a8bbf0c2d0fae541f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/766 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033b001bab184a0f93fadf61ae5d588c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44656b0b08f4b63b52a1b3acddd0cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a52f1b06454951832e933ae3fc10a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1f65198b5a48489a3178d28c212bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\Narasimha_hinglish-distilbert. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\Narasimha_hinglish-distilbert were not used when initializing DistilBertModel: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13722275 -0.01972033 -0.47847056 ...  0.28230688 -0.08249642\n",
      "   0.06336703]\n",
      " [ 0.4560004   0.15157734 -0.5276784  ...  0.01539021 -0.01856013\n",
      "  -0.1705189 ]\n",
      " [-0.05272618  0.40503472 -0.03096675 ...  0.04041073  0.3597414\n",
      "   0.3411394 ]\n",
      " ...\n",
      " [ 0.19305713  0.2436279  -0.02663887 ... -0.14227663  0.04917855\n",
      "   0.25664514]\n",
      " [-0.6297865   0.28300866 -0.21831842 ...  0.1123183   0.26780385\n",
      "   0.3115868 ]\n",
      " [-0.25786126 -0.05184478  0.10363649 ... -0.6921844   0.40883148\n",
      "  -0.2601642 ]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('Narasimha/hinglish-distilbert')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55d18e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137223</td>\n",
       "      <td>-0.019720</td>\n",
       "      <td>-0.478471</td>\n",
       "      <td>0.476057</td>\n",
       "      <td>0.347398</td>\n",
       "      <td>-0.101113</td>\n",
       "      <td>-0.635758</td>\n",
       "      <td>1.005038</td>\n",
       "      <td>-0.215675</td>\n",
       "      <td>-0.168945</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039507</td>\n",
       "      <td>-0.357664</td>\n",
       "      <td>-0.534465</td>\n",
       "      <td>-1.473104</td>\n",
       "      <td>-0.508896</td>\n",
       "      <td>0.867599</td>\n",
       "      <td>-0.621728</td>\n",
       "      <td>0.282307</td>\n",
       "      <td>-0.082496</td>\n",
       "      <td>0.063367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.151577</td>\n",
       "      <td>-0.527678</td>\n",
       "      <td>0.391027</td>\n",
       "      <td>0.508552</td>\n",
       "      <td>-0.042728</td>\n",
       "      <td>-0.450655</td>\n",
       "      <td>0.304936</td>\n",
       "      <td>-0.212506</td>\n",
       "      <td>-0.311248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527213</td>\n",
       "      <td>-0.116362</td>\n",
       "      <td>-0.318642</td>\n",
       "      <td>-0.462651</td>\n",
       "      <td>-0.392239</td>\n",
       "      <td>0.654781</td>\n",
       "      <td>-0.149539</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>-0.018560</td>\n",
       "      <td>-0.170519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052726</td>\n",
       "      <td>0.405035</td>\n",
       "      <td>-0.030967</td>\n",
       "      <td>0.376237</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>0.382577</td>\n",
       "      <td>-0.021734</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>-0.448158</td>\n",
       "      <td>-0.079141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198286</td>\n",
       "      <td>0.543742</td>\n",
       "      <td>-1.094507</td>\n",
       "      <td>-0.193360</td>\n",
       "      <td>0.634670</td>\n",
       "      <td>-1.101146</td>\n",
       "      <td>0.095365</td>\n",
       "      <td>0.040411</td>\n",
       "      <td>0.359741</td>\n",
       "      <td>0.341139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040837</td>\n",
       "      <td>0.561041</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.465175</td>\n",
       "      <td>-0.145854</td>\n",
       "      <td>0.129894</td>\n",
       "      <td>-0.300052</td>\n",
       "      <td>0.113135</td>\n",
       "      <td>-0.016628</td>\n",
       "      <td>0.030632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466653</td>\n",
       "      <td>0.304022</td>\n",
       "      <td>-0.808179</td>\n",
       "      <td>-0.389821</td>\n",
       "      <td>0.690078</td>\n",
       "      <td>-0.314406</td>\n",
       "      <td>-0.247859</td>\n",
       "      <td>-0.581640</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>0.247721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.462983</td>\n",
       "      <td>0.568565</td>\n",
       "      <td>-0.676953</td>\n",
       "      <td>0.525879</td>\n",
       "      <td>0.148843</td>\n",
       "      <td>0.208573</td>\n",
       "      <td>-0.882397</td>\n",
       "      <td>-0.128143</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>-0.746219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354630</td>\n",
       "      <td>-0.056850</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>-0.224829</td>\n",
       "      <td>0.157627</td>\n",
       "      <td>0.967875</td>\n",
       "      <td>-0.216612</td>\n",
       "      <td>0.461950</td>\n",
       "      <td>-0.122146</td>\n",
       "      <td>-0.206698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.208239</td>\n",
       "      <td>-0.061394</td>\n",
       "      <td>0.250854</td>\n",
       "      <td>0.328988</td>\n",
       "      <td>0.374808</td>\n",
       "      <td>-0.210084</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>-0.051856</td>\n",
       "      <td>-0.223808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121603</td>\n",
       "      <td>0.264830</td>\n",
       "      <td>-0.996572</td>\n",
       "      <td>0.184805</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>-0.606314</td>\n",
       "      <td>0.056564</td>\n",
       "      <td>-0.308516</td>\n",
       "      <td>-0.120576</td>\n",
       "      <td>0.216924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>-0.192097</td>\n",
       "      <td>-0.100032</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.281847</td>\n",
       "      <td>-0.099357</td>\n",
       "      <td>0.152946</td>\n",
       "      <td>0.237209</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>0.319311</td>\n",
       "      <td>-1.015212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>-0.237929</td>\n",
       "      <td>-0.480227</td>\n",
       "      <td>-0.463899</td>\n",
       "      <td>0.318656</td>\n",
       "      <td>0.010885</td>\n",
       "      <td>0.424232</td>\n",
       "      <td>-0.229462</td>\n",
       "      <td>0.542778</td>\n",
       "      <td>-0.149082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.193057</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>0.270718</td>\n",
       "      <td>0.296509</td>\n",
       "      <td>0.269624</td>\n",
       "      <td>0.217128</td>\n",
       "      <td>0.453893</td>\n",
       "      <td>-0.251491</td>\n",
       "      <td>-0.256961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464829</td>\n",
       "      <td>0.509141</td>\n",
       "      <td>-1.127367</td>\n",
       "      <td>-0.287722</td>\n",
       "      <td>0.086263</td>\n",
       "      <td>-1.081937</td>\n",
       "      <td>0.171223</td>\n",
       "      <td>-0.142277</td>\n",
       "      <td>0.049179</td>\n",
       "      <td>0.256645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>-0.629786</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>-0.218318</td>\n",
       "      <td>0.298727</td>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.344451</td>\n",
       "      <td>0.735670</td>\n",
       "      <td>-0.066183</td>\n",
       "      <td>-0.378223</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373821</td>\n",
       "      <td>0.874357</td>\n",
       "      <td>-0.861604</td>\n",
       "      <td>-0.783554</td>\n",
       "      <td>0.096642</td>\n",
       "      <td>-0.776045</td>\n",
       "      <td>-0.340630</td>\n",
       "      <td>0.112318</td>\n",
       "      <td>0.267804</td>\n",
       "      <td>0.311587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>-0.257861</td>\n",
       "      <td>-0.051845</td>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.434432</td>\n",
       "      <td>0.347787</td>\n",
       "      <td>-0.282942</td>\n",
       "      <td>-0.328700</td>\n",
       "      <td>-0.049285</td>\n",
       "      <td>-0.126769</td>\n",
       "      <td>-0.567347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171329</td>\n",
       "      <td>-0.032467</td>\n",
       "      <td>-1.022539</td>\n",
       "      <td>-0.568692</td>\n",
       "      <td>0.401773</td>\n",
       "      <td>0.547740</td>\n",
       "      <td>-0.063256</td>\n",
       "      <td>-0.692184</td>\n",
       "      <td>0.408831</td>\n",
       "      <td>-0.260164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.137223 -0.019720 -0.478471  0.476057  0.347398 -0.101113 -0.635758   \n",
       "1     0.456000  0.151577 -0.527678  0.391027  0.508552 -0.042728 -0.450655   \n",
       "2    -0.052726  0.405035 -0.030967  0.376237 -0.016789  0.382577 -0.021734   \n",
       "3    -0.040837  0.561041  0.019263  0.465175 -0.145854  0.129894 -0.300052   \n",
       "4    -0.462983  0.568565 -0.676953  0.525879  0.148843  0.208573 -0.882397   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895  0.010682  0.208239 -0.061394  0.250854  0.328988  0.374808 -0.210084   \n",
       "4896 -0.192097 -0.100032  0.001034  0.281847 -0.099357  0.152946  0.237209   \n",
       "4897  0.193057  0.243628 -0.026639  0.270718  0.296509  0.269624  0.217128   \n",
       "4898 -0.629786  0.283009 -0.218318  0.298727  0.232805  0.344451  0.735670   \n",
       "4899 -0.257861 -0.051845  0.103636  0.434432  0.347787 -0.282942 -0.328700   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     1.005038 -0.215675 -0.168945  ...  1.039507 -0.357664 -0.534465   \n",
       "1     0.304936 -0.212506 -0.311248  ...  0.527213 -0.116362 -0.318642   \n",
       "2     0.040927 -0.448158 -0.079141  ...  0.198286  0.543742 -1.094507   \n",
       "3     0.113135 -0.016628  0.030632  ...  0.466653  0.304022 -0.808179   \n",
       "4    -0.128143  0.031789 -0.746219  ...  0.354630 -0.056850  0.065238   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895  0.495052 -0.051856 -0.223808  ... -0.121603  0.264830 -0.996572   \n",
       "4896 -0.153099  0.319311 -1.015212  ...  0.073842 -0.237929 -0.480227   \n",
       "4897  0.453893 -0.251491 -0.256961  ... -0.464829  0.509141 -1.127367   \n",
       "4898 -0.066183 -0.378223  0.048060  ... -0.373821  0.874357 -0.861604   \n",
       "4899 -0.049285 -0.126769 -0.567347  ...  0.171329 -0.032467 -1.022539   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -1.473104 -0.508896  0.867599 -0.621728  0.282307 -0.082496  0.063367  \n",
       "1    -0.462651 -0.392239  0.654781 -0.149539  0.015390 -0.018560 -0.170519  \n",
       "2    -0.193360  0.634670 -1.101146  0.095365  0.040411  0.359741  0.341139  \n",
       "3    -0.389821  0.690078 -0.314406 -0.247859 -0.581640  0.042835  0.247721  \n",
       "4    -0.224829  0.157627  0.967875 -0.216612  0.461950 -0.122146 -0.206698  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895  0.184805  0.410645 -0.606314  0.056564 -0.308516 -0.120576  0.216924  \n",
       "4896 -0.463899  0.318656  0.010885  0.424232 -0.229462  0.542778 -0.149082  \n",
       "4897 -0.287722  0.086263 -1.081937  0.171223 -0.142277  0.049179  0.256645  \n",
       "4898 -0.783554  0.096642 -0.776045 -0.340630  0.112318  0.267804  0.311587  \n",
       "4899 -0.568692  0.401773  0.547740 -0.063256 -0.692184  0.408831 -0.260164  \n",
       "\n",
       "[4900 rows x 768 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndisbert_df = pd.DataFrame(embeddings)\n",
    "ndisbert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8036bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndisbert_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_ndisbert.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc3ae9",
   "metadata": {},
   "source": [
    "### getting word embedding using verloop bert hinglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44b6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\murth/.cache\\torch\\sentence_transformers\\verloop_Hinglish-Bert. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\murth/.cache\\torch\\sentence_transformers\\verloop_Hinglish-Bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11584561 -0.29227522  0.33010978 ...  0.03631268 -0.3123245\n",
      "  -0.28774816]\n",
      " [ 0.05228913 -0.17867608  0.13050503 ... -0.19996816 -0.18237321\n",
      "  -0.38875505]\n",
      " [ 0.02842837 -0.19844387  0.42514235 ...  0.32444164 -0.3004589\n",
      "  -0.10044478]\n",
      " ...\n",
      " [ 0.10083683 -0.33762336  0.30313218 ... -0.24676909 -0.09788385\n",
      "  -0.21314874]\n",
      " [ 0.09362402 -0.3636186   0.1750762  ... -0.02483388 -0.42299798\n",
      "  -0.01988213]\n",
      " [-0.0390803  -0.15810029  0.47844988 ...  0.21425168 -0.2355762\n",
      "  -0.24541792]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('verloop/Hinglish-Bert')\n",
    "\n",
    "embeddings = model.encode(comments)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7190fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115846</td>\n",
       "      <td>-0.292275</td>\n",
       "      <td>0.330110</td>\n",
       "      <td>0.263350</td>\n",
       "      <td>0.274672</td>\n",
       "      <td>0.234417</td>\n",
       "      <td>0.038812</td>\n",
       "      <td>-0.079065</td>\n",
       "      <td>-0.018466</td>\n",
       "      <td>-0.208867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099472</td>\n",
       "      <td>0.338596</td>\n",
       "      <td>-0.356564</td>\n",
       "      <td>-0.425709</td>\n",
       "      <td>0.135493</td>\n",
       "      <td>-0.142280</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>-0.312324</td>\n",
       "      <td>-0.287748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052289</td>\n",
       "      <td>-0.178676</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>0.117048</td>\n",
       "      <td>0.192993</td>\n",
       "      <td>0.381340</td>\n",
       "      <td>-0.057105</td>\n",
       "      <td>-0.211232</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>-0.255149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024243</td>\n",
       "      <td>0.054705</td>\n",
       "      <td>-0.614297</td>\n",
       "      <td>-0.080857</td>\n",
       "      <td>0.189926</td>\n",
       "      <td>-0.070558</td>\n",
       "      <td>-0.202929</td>\n",
       "      <td>-0.199968</td>\n",
       "      <td>-0.182373</td>\n",
       "      <td>-0.388755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028428</td>\n",
       "      <td>-0.198444</td>\n",
       "      <td>0.425142</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.277188</td>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.133649</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>-0.016502</td>\n",
       "      <td>-0.253235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>-0.611705</td>\n",
       "      <td>-0.548746</td>\n",
       "      <td>-0.252724</td>\n",
       "      <td>-0.129241</td>\n",
       "      <td>0.022141</td>\n",
       "      <td>0.324442</td>\n",
       "      <td>-0.300459</td>\n",
       "      <td>-0.100445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012835</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.345215</td>\n",
       "      <td>0.226324</td>\n",
       "      <td>0.295794</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.218764</td>\n",
       "      <td>0.029665</td>\n",
       "      <td>0.032127</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342385</td>\n",
       "      <td>0.279868</td>\n",
       "      <td>-0.812611</td>\n",
       "      <td>-0.701904</td>\n",
       "      <td>-0.042348</td>\n",
       "      <td>-0.402175</td>\n",
       "      <td>0.134843</td>\n",
       "      <td>0.234461</td>\n",
       "      <td>-0.300016</td>\n",
       "      <td>-0.113239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.300236</td>\n",
       "      <td>-0.283039</td>\n",
       "      <td>0.491666</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.112831</td>\n",
       "      <td>-0.283521</td>\n",
       "      <td>-0.053808</td>\n",
       "      <td>-0.308912</td>\n",
       "      <td>-0.211875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147477</td>\n",
       "      <td>0.308497</td>\n",
       "      <td>-0.700146</td>\n",
       "      <td>-0.275767</td>\n",
       "      <td>0.319104</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>0.052044</td>\n",
       "      <td>0.083720</td>\n",
       "      <td>-0.187988</td>\n",
       "      <td>-0.364426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.012975</td>\n",
       "      <td>-0.174404</td>\n",
       "      <td>-0.022871</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.205036</td>\n",
       "      <td>0.333147</td>\n",
       "      <td>-0.082464</td>\n",
       "      <td>-0.034707</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>-0.077230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.263959</td>\n",
       "      <td>-0.517110</td>\n",
       "      <td>-0.683427</td>\n",
       "      <td>-0.063511</td>\n",
       "      <td>-0.425357</td>\n",
       "      <td>-0.067547</td>\n",
       "      <td>0.225885</td>\n",
       "      <td>-0.469595</td>\n",
       "      <td>-0.088932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.003448</td>\n",
       "      <td>-0.138556</td>\n",
       "      <td>0.511338</td>\n",
       "      <td>0.351750</td>\n",
       "      <td>0.242733</td>\n",
       "      <td>0.279066</td>\n",
       "      <td>0.118047</td>\n",
       "      <td>-0.087117</td>\n",
       "      <td>0.578195</td>\n",
       "      <td>-0.135462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109254</td>\n",
       "      <td>0.232787</td>\n",
       "      <td>-0.837105</td>\n",
       "      <td>-0.376031</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.106360</td>\n",
       "      <td>-0.390289</td>\n",
       "      <td>-0.187391</td>\n",
       "      <td>-0.188957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.100837</td>\n",
       "      <td>-0.337623</td>\n",
       "      <td>0.303132</td>\n",
       "      <td>0.107986</td>\n",
       "      <td>0.202801</td>\n",
       "      <td>0.417735</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>0.171820</td>\n",
       "      <td>0.151172</td>\n",
       "      <td>-0.358495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088168</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>-0.678994</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>-0.257862</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.432885</td>\n",
       "      <td>-0.246769</td>\n",
       "      <td>-0.097884</td>\n",
       "      <td>-0.213149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>0.093624</td>\n",
       "      <td>-0.363619</td>\n",
       "      <td>0.175076</td>\n",
       "      <td>0.246180</td>\n",
       "      <td>0.154058</td>\n",
       "      <td>0.282483</td>\n",
       "      <td>-0.038285</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.089153</td>\n",
       "      <td>0.381018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252751</td>\n",
       "      <td>0.166417</td>\n",
       "      <td>-0.728267</td>\n",
       "      <td>-0.421095</td>\n",
       "      <td>-0.202008</td>\n",
       "      <td>-0.414759</td>\n",
       "      <td>0.370569</td>\n",
       "      <td>-0.024834</td>\n",
       "      <td>-0.422998</td>\n",
       "      <td>-0.019882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>-0.039080</td>\n",
       "      <td>-0.158100</td>\n",
       "      <td>0.478450</td>\n",
       "      <td>0.329450</td>\n",
       "      <td>0.316591</td>\n",
       "      <td>0.402963</td>\n",
       "      <td>0.024674</td>\n",
       "      <td>-0.102414</td>\n",
       "      <td>0.170791</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.436142</td>\n",
       "      <td>-0.528162</td>\n",
       "      <td>-0.433925</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>-0.180696</td>\n",
       "      <td>-0.188184</td>\n",
       "      <td>0.214252</td>\n",
       "      <td>-0.235576</td>\n",
       "      <td>-0.245418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.115846 -0.292275  0.330110  0.263350  0.274672  0.234417  0.038812   \n",
       "1     0.052289 -0.178676  0.130505  0.117048  0.192993  0.381340 -0.057105   \n",
       "2     0.028428 -0.198444  0.425142  0.090820  0.277188  0.483221  0.133649   \n",
       "3    -0.012835  0.001553  0.345215  0.226324  0.295794  0.239040 -0.218764   \n",
       "4    -0.300236 -0.283039  0.491666 -0.015152  0.038212  0.112831 -0.283521   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4895  0.012975 -0.174404 -0.022871  0.177107  0.205036  0.333147 -0.082464   \n",
       "4896  0.003448 -0.138556  0.511338  0.351750  0.242733  0.279066  0.118047   \n",
       "4897  0.100837 -0.337623  0.303132  0.107986  0.202801  0.417735  0.040584   \n",
       "4898  0.093624 -0.363619  0.175076  0.246180  0.154058  0.282483 -0.038285   \n",
       "4899 -0.039080 -0.158100  0.478450  0.329450  0.316591  0.402963  0.024674   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0    -0.079065 -0.018466 -0.208867  ...  0.099472  0.338596 -0.356564   \n",
       "1    -0.211232 -0.083050 -0.255149  ...  0.024243  0.054705 -0.614297   \n",
       "2     0.018982 -0.016502 -0.253235  ...  0.205292  0.090786 -0.611705   \n",
       "3     0.029665  0.032127  0.004946  ... -0.342385  0.279868 -0.812611   \n",
       "4    -0.053808 -0.308912 -0.211875  ...  0.147477  0.308497 -0.700146   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4895 -0.034707  0.012520 -0.077230  ...  0.004309  0.263959 -0.517110   \n",
       "4896 -0.087117  0.578195 -0.135462  ... -0.109254  0.232787 -0.837105   \n",
       "4897  0.171820  0.151172 -0.358495  ... -0.088168  0.085825 -0.678994   \n",
       "4898 -0.089598  0.089153  0.381018  ...  0.252751  0.166417 -0.728267   \n",
       "4899 -0.102414  0.170791  0.001735  ...  0.185784  0.436142 -0.528162   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.425709  0.135493 -0.142280 -0.260289  0.036313 -0.312324 -0.287748  \n",
       "1    -0.080857  0.189926 -0.070558 -0.202929 -0.199968 -0.182373 -0.388755  \n",
       "2    -0.548746 -0.252724 -0.129241  0.022141  0.324442 -0.300459 -0.100445  \n",
       "3    -0.701904 -0.042348 -0.402175  0.134843  0.234461 -0.300016 -0.113239  \n",
       "4    -0.275767  0.319104 -0.322622  0.052044  0.083720 -0.187988 -0.364426  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4895 -0.683427 -0.063511 -0.425357 -0.067547  0.225885 -0.469595 -0.088932  \n",
       "4896 -0.376031  0.022561 -0.006878 -0.106360 -0.390289 -0.187391 -0.188957  \n",
       "4897  0.041703 -0.257862 -0.000149 -0.432885 -0.246769 -0.097884 -0.213149  \n",
       "4898 -0.421095 -0.202008 -0.414759  0.370569 -0.024834 -0.422998 -0.019882  \n",
       "4899 -0.433925  0.149737 -0.180696 -0.188184  0.214252 -0.235576 -0.245418  \n",
       "\n",
       "[4900 rows x 768 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbert_df = pd.DataFrame(embeddings)\n",
    "vbert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54f2aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vbert_df.to_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_vbert.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b39087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c0153",
   "metadata": {},
   "source": [
    "### normal vectorization Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e2eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2708, -0.2844,  0.4581],\n",
      "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
      "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
      "         ...,\n",
      "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
      "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
      "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9377, -0.5043, -0.9799,  0.9030,  0.9329, -0.2438,  0.8926,  0.2288,\n",
      "         -0.9531, -1.0000, -0.8862,  0.9906,  0.9855,  0.7155,  0.9455, -0.8645,\n",
      "         -0.6035, -0.6666,  0.3020, -0.1587,  0.7455,  1.0000, -0.4022,  0.4261,\n",
      "          0.6151,  0.9996, -0.8773,  0.9594,  0.9585,  0.6950, -0.6718,  0.3325,\n",
      "         -0.9954, -0.2268, -0.9658, -0.9951,  0.6127, -0.7670,  0.0873,  0.0824,\n",
      "         -0.9518,  0.4713,  1.0000,  0.3299,  0.7583, -0.2670, -1.0000,  0.3166,\n",
      "         -0.9364,  0.9910,  0.9719,  0.9893,  0.2190,  0.6048,  0.5849, -0.4123,\n",
      "         -0.0063,  0.1719, -0.3988, -0.6190, -0.6603,  0.5069, -0.9757, -0.9039,\n",
      "          0.9926,  0.9323, -0.3687, -0.4869, -0.3143,  0.0499,  0.9129,  0.3396,\n",
      "         -0.1879, -0.9235,  0.8675,  0.3228, -0.6406,  1.0000, -0.7989, -0.9931,\n",
      "          0.9629,  0.9124,  0.4827, -0.7276,  0.5996, -1.0000,  0.7548, -0.1600,\n",
      "         -0.9941,  0.3386,  0.8394, -0.4158,  0.2943,  0.6111, -0.5745, -0.7185,\n",
      "         -0.4768, -0.9681, -0.4327, -0.6732,  0.1248, -0.2093, -0.5882, -0.4186,\n",
      "          0.5447, -0.6125, -0.6138,  0.4712,  0.4779,  0.7633,  0.3974, -0.4148,\n",
      "          0.7063, -0.9680,  0.7389, -0.4270, -0.9948, -0.6019, -0.9950,  0.7459,\n",
      "         -0.6343, -0.2753,  0.9522, -0.5724,  0.6218, -0.1295, -0.9905, -1.0000,\n",
      "         -0.8710, -0.7506, -0.5008, -0.4827, -0.9872, -0.9847,  0.7214,  0.9694,\n",
      "          0.3013,  1.0000, -0.4427,  0.9699, -0.5431, -0.8189,  0.9180, -0.5132,\n",
      "          0.9026,  0.5274, -0.5940,  0.2928, -0.6933,  0.7179, -0.9318, -0.2776,\n",
      "         -0.9160, -0.9457, -0.3287,  0.9556, -0.7927, -0.9860, -0.1904, -0.2760,\n",
      "         -0.6062,  0.9005,  0.9266,  0.4353, -0.6858,  0.4720,  0.2851,  0.7685,\n",
      "         -0.8647, -0.5626,  0.5127, -0.5468, -0.9490, -0.9907, -0.5809,  0.7146,\n",
      "          0.9948,  0.7981,  0.3463,  0.9349, -0.4238,  0.9333, -0.9754,  0.9936,\n",
      "         -0.2597,  0.4665, -0.5400,  0.4947, -0.8723,  0.0034,  0.8378, -0.9134,\n",
      "         -0.8432, -0.2516, -0.5177, -0.4687, -0.9491,  0.5691, -0.4856, -0.4857,\n",
      "         -0.2245,  0.9609,  0.9823,  0.7496,  0.6256,  0.8552, -0.9073, -0.5802,\n",
      "          0.2874,  0.3017,  0.3016,  0.9974, -0.8503, -0.2108, -0.9261, -0.9907,\n",
      "         -0.0252, -0.9488, -0.3972, -0.8097,  0.8707, -0.7512,  0.8107,  0.5488,\n",
      "         -0.9830, -0.8569,  0.4852, -0.6156,  0.4846, -0.2893,  0.9647,  0.9858,\n",
      "         -0.7064,  0.7120,  0.9593, -0.9590, -0.8708,  0.7893, -0.3561,  0.8603,\n",
      "         -0.7243,  0.9882,  0.9876,  0.9282, -0.9547, -0.8329, -0.7993, -0.8398,\n",
      "         -0.2333,  0.2315,  0.9712,  0.6055,  0.6388,  0.2429, -0.7884,  0.9981,\n",
      "         -0.9448, -0.9804, -0.8184, -0.3534, -0.9951,  0.9729,  0.4165,  0.8094,\n",
      "         -0.6227, -0.8183, -0.9817,  0.8532,  0.1242,  0.9826, -0.6376, -0.9450,\n",
      "         -0.8094, -0.9748,  0.0412, -0.3097, -0.8153, -0.0306, -0.9255,  0.5677,\n",
      "          0.6217,  0.6652, -0.9682,  0.9997,  1.0000,  0.9826,  0.9013,  0.8950,\n",
      "         -1.0000, -0.8081,  1.0000, -0.9995, -1.0000, -0.9361, -0.8200,  0.4755,\n",
      "         -1.0000, -0.2698, -0.0111, -0.9297,  0.8492,  0.9879,  0.9950, -1.0000,\n",
      "          0.8653,  0.9513, -0.5679,  0.9966, -0.6713,  0.9815,  0.6008,  0.7414,\n",
      "         -0.3265,  0.5574, -0.9801, -0.8956, -0.8082, -0.9267,  0.9999,  0.2542,\n",
      "         -0.7970, -0.8854,  0.7831, -0.1391, -0.0060, -0.9786, -0.4503,  0.8895,\n",
      "          0.9021,  0.3021,  0.2650, -0.5750,  0.5099,  0.1216,  0.1170,  0.6484,\n",
      "         -0.9505, -0.3889, -0.6938,  0.2508, -0.7526, -0.9831,  0.9646, -0.2742,\n",
      "          0.9865,  1.0000,  0.3756, -0.9045,  0.8847,  0.4860, -0.5515,  1.0000,\n",
      "          0.9092, -0.9904, -0.4959,  0.7900, -0.7156, -0.8280,  0.9999, -0.4197,\n",
      "         -0.9282, -0.7733,  0.9945, -0.9956,  0.9998, -0.8985, -0.9838,  0.9735,\n",
      "          0.9655, -0.8103, -0.8325,  0.1020, -0.6722,  0.4561, -0.9412,  0.8396,\n",
      "          0.6979, -0.1201,  0.9288, -0.8345, -0.6312,  0.4356, -0.8901, -0.4565,\n",
      "          0.9874,  0.5709, -0.2111, -0.0206, -0.4182, -0.9116, -0.9781,  0.8246,\n",
      "          1.0000, -0.4229,  0.9489, -0.5226, -0.0986,  0.2202,  0.7459,  0.7152,\n",
      "         -0.3528, -0.8800,  0.9299, -0.9716, -0.9949,  0.7278,  0.2206, -0.4944,\n",
      "          1.0000,  0.6285,  0.3795,  0.7228,  0.9993,  0.0301,  0.5936,  0.9816,\n",
      "          0.9914, -0.3465,  0.5882,  0.8365, -0.9824, -0.4488, -0.7612,  0.1331,\n",
      "         -0.9479, -0.0559, -0.9697,  0.9846,  0.9960,  0.5818,  0.3121,  0.8577,\n",
      "          1.0000, -0.9274,  0.6693, -0.1365,  0.8035, -1.0000, -0.8057, -0.4504,\n",
      "         -0.1711, -0.9512, -0.5899,  0.3991, -0.9754,  0.9563,  0.8806, -0.9937,\n",
      "         -0.9923, -0.4979,  0.8853,  0.1439, -0.9994, -0.8986, -0.6272,  0.8385,\n",
      "         -0.3239, -0.9470, -0.7009, -0.4768,  0.5742, -0.2216,  0.5665,  0.9667,\n",
      "          0.7935, -0.9401, -0.6746, -0.1753, -0.9163,  0.9409, -0.8701, -0.9894,\n",
      "         -0.2514,  1.0000, -0.4087,  0.9385,  0.6050,  0.8219, -0.2712,  0.3326,\n",
      "          0.9827,  0.3613, -0.8314, -0.9850, -0.2861, -0.5398,  0.8254,  0.8414,\n",
      "          0.7590,  0.9412,  0.9627,  0.2765, -0.0737,  0.0399,  0.9998, -0.3095,\n",
      "         -0.1933, -0.4689, -0.2511, -0.4629, -0.2914,  1.0000,  0.3963,  0.7777,\n",
      "         -0.9950, -0.9808, -0.9303,  1.0000,  0.8822, -0.6848,  0.8124,  0.6242,\n",
      "         -0.2551,  0.8266, -0.2791, -0.3167,  0.2294,  0.1682,  0.9627, -0.6738,\n",
      "         -0.9904, -0.7910,  0.7099, -0.9770,  1.0000, -0.7030, -0.3960, -0.5981,\n",
      "         -0.6683, -0.2727, -0.0183, -0.9882, -0.3841,  0.5605,  0.9745,  0.3505,\n",
      "         -0.4898, -0.9298,  0.9578,  0.9533, -0.9859, -0.9597,  0.9777, -0.9784,\n",
      "          0.7551,  1.0000,  0.3446,  0.6786,  0.3947, -0.5349,  0.5541, -0.6754,\n",
      "          0.8078, -0.9595, -0.4484, -0.3901,  0.3983, -0.1319, -0.2896,  0.7860,\n",
      "          0.3500, -0.5530, -0.7294, -0.2361,  0.4663,  0.9332, -0.3048, -0.1916,\n",
      "          0.2318, -0.3230, -0.9323, -0.4672, -0.6315, -1.0000,  0.8068, -1.0000,\n",
      "          0.8035,  0.4066, -0.3700,  0.8760,  0.7829,  0.8298, -0.8628, -0.9795,\n",
      "          0.1322,  0.8529, -0.5029, -0.9057, -0.6918,  0.5017, -0.2052,  0.1564,\n",
      "         -0.7397,  0.8156, -0.3414,  1.0000,  0.2659, -0.8292, -0.9821,  0.2491,\n",
      "         -0.3009,  1.0000, -0.8952, -0.9832,  0.3330, -0.9180, -0.8493,  0.5868,\n",
      "          0.1653, -0.8522, -0.9961,  0.9220,  0.8661, -0.6477,  0.7927, -0.3991,\n",
      "         -0.7691,  0.1512,  0.9868,  0.9924,  0.7317,  0.9083, -0.1227, -0.5258,\n",
      "          0.9840,  0.4009, -0.0436,  0.1361,  1.0000,  0.4004, -0.9497, -0.1309,\n",
      "         -0.9788, -0.3522, -0.9551,  0.3755,  0.3099,  0.9195, -0.4460,  0.9738,\n",
      "         -0.9714,  0.1901, -0.8894, -0.7863,  0.4757, -0.9463, -0.9892, -0.9938,\n",
      "          0.8142, -0.4077, -0.1895,  0.2102,  0.1715,  0.6322,  0.5566, -1.0000,\n",
      "          0.9642,  0.6150,  0.9768,  0.9768,  0.9115,  0.8108,  0.3251, -0.9920,\n",
      "         -0.9910, -0.5438, -0.3567,  0.7960,  0.7648,  0.8900,  0.6470, -0.4875,\n",
      "         -0.4792, -0.7756, -0.8423, -0.9972,  0.5961, -0.8679, -0.9678,  0.9718,\n",
      "         -0.3461, -0.1534, -0.2139, -0.9586,  0.9321,  0.7627,  0.4636,  0.0862,\n",
      "          0.5071,  0.9170,  0.9597,  0.9882, -0.9231,  0.8555, -0.9196,  0.6712,\n",
      "          0.9381, -0.9606,  0.2335,  0.8301, -0.5560,  0.3696, -0.4752, -0.9740,\n",
      "          0.8174, -0.4268,  0.7773, -0.4798,  0.0639, -0.4718, -0.2607, -0.7624,\n",
      "         -0.8742,  0.6576,  0.6207,  0.9219,  0.9360, -0.0496, -0.8942, -0.3701,\n",
      "         -0.8944, -0.9526,  0.9536, -0.0851, -0.2961,  0.9031,  0.1321,  0.9324,\n",
      "          0.4289, -0.4989, -0.4174, -0.7639,  0.8887, -0.7894, -0.7639, -0.7093,\n",
      "          0.8105,  0.3595,  1.0000, -0.9188, -0.9878, -0.8268, -0.6012,  0.4992,\n",
      "         -0.7880, -1.0000,  0.3609, -0.8314,  0.8524, -0.9398,  0.9500, -0.9339,\n",
      "         -0.9851, -0.3495,  0.8436,  0.9375, -0.5159, -0.8989,  0.5196, -0.8797,\n",
      "          0.9979,  0.8753, -0.8277, -0.0012,  0.6013, -0.9184, -0.7398,  0.9228]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bf7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "for x in output[1]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5afd11",
   "metadata": {},
   "source": [
    "### normal vectorization GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb081dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.1629, -0.2166, -0.1410,  ..., -0.2619, -0.0819,  0.0092],\n",
      "         [ 0.4628,  0.0248, -0.0785,  ..., -0.0859,  0.5122, -0.3939],\n",
      "         [-0.0644,  0.1551, -0.6306,  ...,  0.2488,  0.3691,  0.0833],\n",
      "         ...,\n",
      "         [-0.5591, -0.4490, -1.4540,  ...,  0.1650, -0.1302, -0.3740],\n",
      "         [ 0.1400, -0.3875, -0.7916,  ..., -0.1780,  0.1824,  0.2185],\n",
      "         [ 0.1721, -0.2420, -0.1124,  ..., -0.1068,  0.1205, -0.3213]]],\n",
      "       grad_fn=<ViewBackward0>), past_key_values=((tensor([[[[-1.0719,  2.4170,  0.9660,  ..., -0.4787, -0.3316,  1.7925],\n",
      "          [-2.2897,  2.5424,  0.8317,  ..., -0.5299, -2.4828,  1.3537],\n",
      "          [-2.2856,  2.7125,  2.4725,  ..., -1.4911, -1.8427,  1.6493],\n",
      "          ...,\n",
      "          [-3.3203,  2.3325,  2.7061,  ..., -1.1569, -1.5586,  2.4076],\n",
      "          [-2.9917,  2.2701,  2.1742,  ..., -0.8670, -1.6410,  1.9237],\n",
      "          [-2.5066,  2.6140,  2.1347,  ..., -0.0627, -2.0542,  1.6568]],\n",
      "\n",
      "         [[ 0.4796, -0.1131, -1.4854,  ...,  1.1607,  1.8412,  1.3682],\n",
      "          [-0.7273, -1.1362, -1.0850,  ..., -0.6736,  3.2618,  0.2099],\n",
      "          [-1.4441, -3.0647, -4.1612,  ..., -1.4788,  3.2718, -0.2803],\n",
      "          ...,\n",
      "          [ 0.8515, -0.1599,  0.1157,  ..., -0.8959,  4.1178,  0.7133],\n",
      "          [-0.0769, -1.7673, -1.1207,  ..., -1.6276,  3.1095,  1.0237],\n",
      "          [-0.9118, -0.3267, -2.0409,  ..., -0.3527,  1.1626,  0.3733]],\n",
      "\n",
      "         [[-0.2338, -0.8688,  1.6542,  ..., -1.5964, -1.5636,  1.0931],\n",
      "          [ 0.3698,  0.4929,  1.4155,  ..., -2.0162, -1.0246,  1.9822],\n",
      "          [ 0.4509,  1.0144,  0.1189,  ..., -3.1880,  0.4529,  1.3746],\n",
      "          ...,\n",
      "          [ 0.3303,  0.8695, -0.6507,  ..., -2.7196,  0.2950,  1.9827],\n",
      "          [ 0.5777,  0.4363,  1.1029,  ..., -3.2317,  0.9627,  2.1703],\n",
      "          [-0.2861, -0.2032,  0.7289,  ..., -2.3039,  1.2637,  1.9519]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4012, -0.0278, -0.1031,  ...,  0.2614,  0.9767,  0.5994],\n",
      "          [ 0.2222,  0.3167, -0.2024,  ...,  0.9616,  0.3658,  1.0162],\n",
      "          [ 0.3276,  0.0629,  0.1905,  ...,  1.0855,  0.8707,  0.0940],\n",
      "          ...,\n",
      "          [ 0.2403, -0.0951,  0.1646,  ...,  0.3345,  0.2687,  0.2159],\n",
      "          [ 0.2873,  0.0887, -0.0544,  ...,  1.0306,  0.3196,  0.5268],\n",
      "          [-0.0552, -0.0461,  0.0765,  ...,  1.0465,  0.2690,  0.4687]],\n",
      "\n",
      "         [[ 0.9759,  1.3121, -0.6612,  ..., -0.3228,  1.1476, -1.2349],\n",
      "          [ 1.0862,  0.3406, -0.6767,  ..., -1.0748,  1.4611,  0.6789],\n",
      "          [ 0.6566,  0.1325, -0.5036,  ..., -1.9292,  1.4180,  0.0719],\n",
      "          ...,\n",
      "          [ 1.1746, -0.0249, -1.0666,  ..., -0.9283,  1.2044, -0.7485],\n",
      "          [ 1.2952,  0.0145, -0.4903,  ..., -1.0618,  0.9241,  0.0928],\n",
      "          [ 0.9810,  0.0274, -0.2624,  ..., -0.8447,  0.3484, -0.2251]],\n",
      "\n",
      "         [[ 0.6922,  0.4421,  0.2786,  ..., -0.2213,  0.2488,  1.8778],\n",
      "          [-0.1203, -0.2795, -0.0287,  ..., -0.2255,  0.5681,  1.2821],\n",
      "          [ 0.3923,  0.6569,  0.0967,  ..., -0.0928,  0.2676,  2.2244],\n",
      "          ...,\n",
      "          [ 0.4983, -0.2781,  0.9789,  ...,  0.5424,  1.0169,  1.1159],\n",
      "          [-0.8550,  0.5215, -0.2168,  ..., -0.1893,  0.9473,  0.7673],\n",
      "          [-0.9623,  0.1968,  1.1720,  ..., -0.4878,  0.9685, -0.6823]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.5844e-02,  4.5047e-02, -3.2349e-02,  ...,  1.1302e-01,\n",
      "            3.4111e-03, -7.3823e-02],\n",
      "          [ 2.4216e-02, -2.3168e-01,  7.9895e-02,  ..., -3.9604e-02,\n",
      "            1.3466e-01, -8.8950e-02],\n",
      "          [ 1.3182e-01,  4.2661e-02,  7.7161e-03,  ...,  1.1645e-01,\n",
      "            1.4362e-01, -3.0297e-02],\n",
      "          ...,\n",
      "          [ 5.1271e-02, -1.0683e-02,  1.3832e-01,  ...,  4.6392e-02,\n",
      "           -7.1929e-02,  3.3192e-01],\n",
      "          [ 4.0427e-02,  3.1326e-02,  7.5804e-03,  ...,  6.6739e-02,\n",
      "           -9.5121e-02,  2.2703e-02],\n",
      "          [-2.5431e-01,  9.7892e-02, -3.1401e-01,  ..., -5.9719e-02,\n",
      "            8.7119e-02, -1.5292e-01]],\n",
      "\n",
      "         [[ 4.6511e-01,  2.9299e-01, -2.6004e-01,  ..., -4.8896e-01,\n",
      "           -3.9832e-01,  5.1992e-02],\n",
      "          [ 3.6216e-01, -2.1008e-01,  2.3111e-01,  ...,  1.2695e-02,\n",
      "           -9.8509e-03, -1.9051e-01],\n",
      "          [ 5.0594e-01, -2.8700e-01, -3.7256e-02,  ...,  1.3379e-01,\n",
      "            1.4818e-01, -7.0381e-02],\n",
      "          ...,\n",
      "          [ 4.5519e-01,  2.2482e-01,  2.7037e-02,  ..., -7.6202e-02,\n",
      "            1.3018e-01,  1.1114e-01],\n",
      "          [ 4.3946e-01,  5.6358e-02, -2.8075e-01,  ...,  3.8331e-02,\n",
      "            2.8041e-01, -1.0264e-01],\n",
      "          [ 5.5593e-01, -7.1407e-02,  8.1585e-03,  ...,  7.4966e-02,\n",
      "            5.5887e-01, -1.0753e-01]],\n",
      "\n",
      "         [[-3.5264e-02,  5.7019e-02, -7.3887e-02,  ..., -1.2185e-02,\n",
      "           -8.9059e-02, -1.0759e-01],\n",
      "          [-1.4517e-01, -1.1093e-01, -3.1237e-01,  ...,  7.9633e-03,\n",
      "            1.0515e-01, -6.8206e-02],\n",
      "          [-2.9723e-01, -1.0871e-01, -3.7647e-01,  ..., -4.4998e-01,\n",
      "           -3.9353e-01, -5.8729e-02],\n",
      "          ...,\n",
      "          [ 3.6986e-01,  3.6383e-01,  8.8384e-02,  ..., -2.8474e-01,\n",
      "           -2.1211e-01, -4.2789e-01],\n",
      "          [ 5.1485e-01,  1.4955e-02,  1.9848e-01,  ...,  1.8763e-03,\n",
      "           -4.4840e-02, -1.9523e-01],\n",
      "          [-3.1557e-01, -7.7205e-02,  1.2237e-01,  ..., -9.9081e-03,\n",
      "           -9.1467e-02, -1.1786e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6929e-01, -1.6863e-01, -1.3075e-01,  ..., -4.5507e-02,\n",
      "            1.6489e-02, -4.9244e-03],\n",
      "          [-1.8289e-01, -7.3011e-02,  8.9083e-02,  ...,  2.8579e-01,\n",
      "            1.6520e-01,  3.9901e-01],\n",
      "          [ 1.8149e-02,  1.4864e-01,  1.3995e-01,  ..., -2.0186e-01,\n",
      "           -3.1164e-01,  1.8832e-01],\n",
      "          ...,\n",
      "          [ 1.8829e-01,  3.7086e-01,  2.2190e-02,  ..., -4.3816e-01,\n",
      "           -4.5873e-02, -2.3247e-01],\n",
      "          [-6.9325e-02,  2.2089e-01, -5.2158e-02,  ..., -5.8077e-05,\n",
      "           -4.4377e-02, -2.3630e-02],\n",
      "          [-1.4491e-01, -7.6687e-01, -1.0080e-02,  ...,  1.4490e-01,\n",
      "           -1.4273e-01,  1.1995e-02]],\n",
      "\n",
      "         [[ 1.1663e-01, -9.5174e-02, -8.0097e-02,  ...,  1.1799e-01,\n",
      "            1.4442e-01,  8.0563e-02],\n",
      "          [-4.0979e-01,  1.7985e-01,  6.2053e-02,  ..., -4.6011e-01,\n",
      "           -1.5909e-01,  1.6538e-01],\n",
      "          [ 1.0707e-01, -1.4439e-01, -3.8615e-02,  ..., -3.1468e-01,\n",
      "           -1.1422e-01,  1.1694e-01],\n",
      "          ...,\n",
      "          [-8.9047e-02, -5.7536e-02, -1.4755e-01,  ..., -4.0699e-01,\n",
      "           -1.5711e-01, -2.4647e-01],\n",
      "          [-5.0915e-02,  8.4827e-02,  5.0269e-02,  ..., -2.7516e-02,\n",
      "           -2.4682e-01, -1.2400e-01],\n",
      "          [-4.0786e-02, -6.3005e-02, -5.9178e-02,  ...,  1.9072e-01,\n",
      "            2.5695e-01,  1.3483e-01]],\n",
      "\n",
      "         [[-1.4032e-01, -2.1724e-01,  2.1163e-01,  ...,  1.1325e-02,\n",
      "           -1.6940e-01, -5.6700e-02],\n",
      "          [ 1.6501e-01,  1.4751e-01,  1.2316e-01,  ...,  5.2810e-01,\n",
      "            3.7520e-01,  5.6596e-02],\n",
      "          [-1.6167e-01, -9.5173e-02, -3.0007e-01,  ..., -1.3899e-01,\n",
      "            7.6265e-02,  1.5000e-01],\n",
      "          ...,\n",
      "          [ 1.9036e-02, -4.1325e-01, -5.3456e-02,  ...,  1.0850e-01,\n",
      "            3.1322e-01,  7.4104e-02],\n",
      "          [ 4.7433e-02,  8.3881e-02, -5.8630e-02,  ...,  5.6656e-02,\n",
      "           -1.4553e-01,  1.3967e-01],\n",
      "          [ 1.1568e-01, -1.1512e-01, -3.7184e-02,  ...,  9.3072e-02,\n",
      "            9.4981e-02,  5.2496e-03]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3234e-01,  1.7469e+00, -1.3506e+00,  ...,  1.3035e+00,\n",
      "           -1.1436e+00,  1.3027e+00],\n",
      "          [ 3.7144e-01,  1.5962e+00, -9.8959e-01,  ..., -3.7702e-01,\n",
      "           -1.6238e+00,  4.9728e-01],\n",
      "          [ 1.5475e+00,  1.7371e+00, -1.1542e+00,  ...,  2.6363e-02,\n",
      "           -2.4185e+00,  6.0650e-02],\n",
      "          ...,\n",
      "          [ 1.1640e+00,  2.7594e-01, -3.8811e-01,  ...,  9.9817e-01,\n",
      "           -2.4461e-01, -2.2513e+00],\n",
      "          [ 9.1530e-02,  1.3589e+00,  5.4383e-02,  ...,  9.0260e-01,\n",
      "           -2.1145e+00, -1.0515e+00],\n",
      "          [-2.3758e-01,  4.2933e-01,  2.5328e-01,  ...,  6.8149e-01,\n",
      "           -7.0189e-01, -1.3681e-01]],\n",
      "\n",
      "         [[-1.4716e+00, -7.0062e-01, -8.4053e-01,  ..., -3.4795e-01,\n",
      "            9.0868e-01, -5.7943e-01],\n",
      "          [-6.7887e-01, -8.5541e-01, -1.9801e+00,  ..., -1.3131e+00,\n",
      "           -2.7207e-01,  1.9432e-01],\n",
      "          [-8.6449e-01,  1.6246e-02, -1.5927e+00,  ..., -1.5577e-01,\n",
      "            4.3638e-01,  3.4525e-01],\n",
      "          ...,\n",
      "          [-8.9806e-01,  3.8958e-01, -1.8324e+00,  ..., -3.9667e-01,\n",
      "           -9.1773e-01, -5.6276e-01],\n",
      "          [-5.7540e-01,  9.9297e-01, -1.6385e+00,  ..., -2.2806e-01,\n",
      "            3.7440e-01, -1.2218e+00],\n",
      "          [-5.3996e-01,  1.2337e+00, -1.4777e+00,  ..., -1.9484e-01,\n",
      "           -7.1104e-01, -6.1031e-01]],\n",
      "\n",
      "         [[ 3.3298e-01,  1.1988e-01, -2.9469e-02,  ..., -1.2560e+00,\n",
      "            1.5321e-01, -2.1866e-01],\n",
      "          [ 3.3311e-01,  6.0987e-01, -3.2191e-01,  ..., -1.2439e+00,\n",
      "           -7.9251e-02,  7.9440e-02],\n",
      "          [-1.3959e-01,  2.9871e-01, -1.1090e-01,  ..., -8.7817e-01,\n",
      "           -2.1968e-01,  5.7344e-01],\n",
      "          ...,\n",
      "          [-1.1917e-01, -1.2050e-01,  8.8956e-02,  ..., -1.0531e+00,\n",
      "            2.7097e-01,  2.8109e-01],\n",
      "          [-1.6320e-01, -2.1190e-01, -2.8066e-01,  ..., -1.1110e+00,\n",
      "           -1.1413e-01,  3.4103e-01],\n",
      "          [-1.9088e-01, -2.2637e-01, -1.9520e-01,  ..., -1.3609e+00,\n",
      "            7.7478e-03,  5.4753e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1961e-01, -5.4149e-01, -6.5129e-01,  ..., -1.3049e-01,\n",
      "            6.4293e-01, -1.0648e+00],\n",
      "          [-1.1139e+00,  1.7472e+00,  1.9236e+00,  ..., -5.2888e-01,\n",
      "           -8.8113e-01, -1.1274e+00],\n",
      "          [-3.5029e-02,  1.6498e+00,  1.5704e+00,  ...,  1.8705e+00,\n",
      "            4.4842e-01,  1.7473e-01],\n",
      "          ...,\n",
      "          [ 2.8044e-02,  1.5038e+00,  1.7172e+00,  ..., -1.5435e-01,\n",
      "           -7.6511e-01, -8.1489e-01],\n",
      "          [-6.5315e-01,  1.2453e+00,  1.9217e+00,  ...,  6.9396e-01,\n",
      "           -1.3474e+00, -1.1424e+00],\n",
      "          [-4.9458e-01,  1.4317e+00,  1.6529e+00,  ...,  5.9429e-01,\n",
      "           -1.7269e+00, -3.5413e-01]],\n",
      "\n",
      "         [[-1.2016e+00, -2.7812e+00,  1.2903e-01,  ...,  1.6795e+00,\n",
      "            1.5993e+00, -1.5680e+00],\n",
      "          [-2.4824e-01,  9.6243e-01, -6.0818e-01,  ..., -6.4028e-01,\n",
      "            7.3015e-01,  1.6933e-03],\n",
      "          [ 3.7342e-01,  7.0263e-01, -5.0011e-01,  ..., -6.0883e-01,\n",
      "            4.8429e-01, -9.1718e-02],\n",
      "          ...,\n",
      "          [-2.1023e-01, -1.1352e-01, -8.6533e-01,  ..., -4.3357e-01,\n",
      "            1.0432e+00,  2.3951e-01],\n",
      "          [-3.5406e-01,  3.6508e-01, -7.0875e-01,  ..., -1.5285e-01,\n",
      "            9.8004e-01,  3.0699e-01],\n",
      "          [-3.1061e-01,  2.6206e-01, -7.0317e-01,  ..., -3.8614e-01,\n",
      "            7.4612e-01, -1.0789e-01]],\n",
      "\n",
      "         [[ 1.2471e+00,  1.8337e+00,  1.4891e+00,  ..., -2.7984e-01,\n",
      "            8.3699e-02, -4.6373e-01],\n",
      "          [-7.5646e-03,  2.5955e+00,  5.7040e-01,  ...,  1.0415e+00,\n",
      "           -1.6044e-01, -3.6244e-01],\n",
      "          [ 7.7531e-02,  2.8104e+00,  1.5624e+00,  ...,  1.5091e+00,\n",
      "           -1.8090e-02, -1.2300e+00],\n",
      "          ...,\n",
      "          [-4.7830e-01,  2.4190e+00,  2.3556e+00,  ...,  1.7733e+00,\n",
      "           -1.6757e+00, -2.5219e+00],\n",
      "          [ 9.0539e-02,  3.3119e+00, -3.6678e-01,  ...,  2.4436e+00,\n",
      "           -1.6148e+00, -2.1822e+00],\n",
      "          [ 5.6891e-01,  1.7215e+00,  7.9348e-01,  ..., -6.3631e-01,\n",
      "           -4.2486e-01,  1.1763e-02]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 1.8121e-01, -1.3411e-01, -2.1478e-01,  ...,  7.0410e-02,\n",
      "            2.1432e-01, -4.1736e-01],\n",
      "          [-3.4722e-01, -2.4165e-01, -3.5845e-01,  ..., -4.0396e-03,\n",
      "            6.8928e-01,  6.3408e-01],\n",
      "          [ 1.8921e-01,  1.1412e-01, -3.7454e-01,  ..., -6.1886e-01,\n",
      "            1.5584e-01, -3.3977e-01],\n",
      "          ...,\n",
      "          [-9.8094e-01, -3.1039e-01, -4.3409e-02,  ...,  8.2431e-01,\n",
      "            1.2980e-02,  3.8811e-03],\n",
      "          [ 3.3090e-01, -8.1123e-02,  1.0761e-01,  ..., -2.8871e-01,\n",
      "            4.1475e-01,  4.9912e-01],\n",
      "          [ 6.5354e-01,  1.7933e-01,  9.7152e-02,  ..., -9.8650e-02,\n",
      "           -1.9800e-01, -7.1576e-02]],\n",
      "\n",
      "         [[-1.2948e-01, -1.3113e-01,  3.0471e-01,  ..., -9.5208e-02,\n",
      "           -5.2637e-01,  2.0390e-02],\n",
      "          [-5.2768e-01, -2.4699e-01, -1.2828e-01,  ..., -1.3858e-01,\n",
      "            1.6376e-01,  3.1491e-01],\n",
      "          [ 3.4299e-02,  2.9798e-01, -1.8136e-01,  ...,  3.7112e-01,\n",
      "           -1.1525e-02, -2.1673e-01],\n",
      "          ...,\n",
      "          [-8.4666e-03, -1.8613e-01,  2.7562e-01,  ...,  4.4664e-01,\n",
      "           -1.5165e-01, -5.9345e-01],\n",
      "          [ 2.7736e-01, -5.3698e-01,  1.0314e+00,  ...,  1.0592e-01,\n",
      "           -1.0284e-01, -2.0281e-01],\n",
      "          [ 3.6434e-01, -1.9135e-02,  1.0105e-01,  ...,  1.8952e-01,\n",
      "            2.6101e-01, -4.4438e-02]],\n",
      "\n",
      "         [[ 4.5340e-02, -4.0817e-01,  5.3539e-02,  ..., -4.7963e-01,\n",
      "           -2.8298e-01,  2.7899e-02],\n",
      "          [ 8.4529e-01,  9.4444e-02,  2.4181e-02,  ..., -7.5536e-01,\n",
      "           -4.6340e-02,  1.8064e-01],\n",
      "          [ 8.0320e-01,  1.4924e-01,  5.8457e-01,  ..., -8.3811e-01,\n",
      "            1.0063e-01,  2.5599e-01],\n",
      "          ...,\n",
      "          [ 9.6557e-01, -9.7738e-02,  2.9158e-02,  ..., -3.4948e-01,\n",
      "            1.6999e-01, -1.4430e-01],\n",
      "          [ 8.1042e-01, -2.8220e-02, -1.2203e-01,  ..., -3.2469e-01,\n",
      "           -2.2869e-01,  4.6458e-01],\n",
      "          [ 4.8326e-01,  1.9731e-01,  2.5365e-01,  ..., -9.5573e-02,\n",
      "           -1.1013e-01, -3.0431e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4653e-01,  6.2398e-01, -1.6506e-01,  ...,  1.2628e-01,\n",
      "           -9.4077e-01, -1.0024e-01],\n",
      "          [ 8.5481e-02, -3.7416e-01,  6.1154e-02,  ...,  2.1396e-01,\n",
      "           -6.8561e-01, -1.3296e-01],\n",
      "          [-2.7189e-01,  7.6011e-02,  5.0749e-01,  ...,  6.4782e-02,\n",
      "           -6.3529e-01, -3.4742e-01],\n",
      "          ...,\n",
      "          [-1.5075e-01,  1.6193e-01,  4.4225e-01,  ...,  5.5478e-01,\n",
      "            9.6686e-02,  1.3932e-02],\n",
      "          [ 2.9651e-02, -3.2289e-01, -3.7855e-01,  ...,  2.1001e-01,\n",
      "           -5.2798e-01,  7.2306e-01],\n",
      "          [ 5.7424e-02, -8.9264e-01,  3.6512e-01,  ...,  2.4724e-01,\n",
      "           -7.7394e-01, -2.8834e-01]],\n",
      "\n",
      "         [[ 1.9841e-01, -1.6214e-01,  8.8751e-02,  ...,  3.8060e-01,\n",
      "           -3.5175e+00, -4.8737e-02],\n",
      "          [ 4.8521e-02, -4.2689e-01,  2.9562e-03,  ...,  4.1736e-01,\n",
      "            3.3646e-02, -1.3576e-01],\n",
      "          [-2.3386e-01,  4.3437e-02,  1.9538e-01,  ...,  2.6902e-02,\n",
      "            7.1384e-02,  8.4704e-02],\n",
      "          ...,\n",
      "          [-1.4847e-03,  1.7191e-01, -5.1814e-01,  ...,  2.2445e-01,\n",
      "           -1.5839e-01,  1.5118e-01],\n",
      "          [ 1.7462e-02, -2.2361e-03,  4.6600e-01,  ...,  6.4923e-02,\n",
      "            3.4853e-02,  1.8072e-01],\n",
      "          [ 4.1400e-01,  1.7019e-01,  2.7337e-02,  ...,  1.4136e-01,\n",
      "           -1.5423e-01,  7.8442e-02]],\n",
      "\n",
      "         [[-5.0851e-02, -5.9927e-02, -5.6215e-02,  ..., -2.0252e-01,\n",
      "            1.2368e-01, -3.3855e-02],\n",
      "          [-1.1510e-02, -7.6934e-02,  2.3691e-01,  ...,  6.5874e-02,\n",
      "            1.5217e-02,  1.8671e-01],\n",
      "          [ 1.5296e-01, -1.3156e-01,  1.3923e-01,  ...,  1.8831e-01,\n",
      "           -8.2086e-02,  1.2744e-01],\n",
      "          ...,\n",
      "          [ 3.9660e-02,  2.4684e-01,  1.9528e-01,  ..., -9.5808e-02,\n",
      "            1.7549e-01, -6.6851e-03],\n",
      "          [ 8.3237e-02,  1.1592e-01, -5.2513e-02,  ..., -3.2532e-02,\n",
      "            2.5978e-01,  1.4565e-01],\n",
      "          [ 1.2383e-01, -1.1883e-02,  5.0095e-01,  ..., -1.0736e-02,\n",
      "            1.1066e-01,  1.8190e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1322, -1.1527,  0.3087,  ..., -0.6205, -0.1060, -0.0181],\n",
      "          [ 0.5456, -2.5518, -0.2942,  ..., -1.2907,  0.0803,  0.1253],\n",
      "          [ 0.9459, -2.5900,  0.3366,  ...,  0.2387,  0.0244, -0.0984],\n",
      "          ...,\n",
      "          [-1.4713, -1.8862, -0.5822,  ..., -0.4205, -0.2317, -0.3811],\n",
      "          [-0.4795, -1.7547,  0.5800,  ...,  1.0587,  0.7753, -1.0023],\n",
      "          [-0.2153, -2.2462, -0.5551,  ...,  1.7418,  0.0601, -0.8750]],\n",
      "\n",
      "         [[-0.4981,  0.4839, -0.4288,  ...,  1.2952, -0.4981, -0.4568],\n",
      "          [-1.4536, -0.2465, -0.9163,  ...,  0.4530,  0.6458,  0.4874],\n",
      "          [-1.6652, -0.9680, -1.0875,  ..., -0.0277,  1.3271, -0.3510],\n",
      "          ...,\n",
      "          [-2.1762, -0.6636, -1.8135,  ..., -0.9017,  1.3285,  0.1540],\n",
      "          [-1.3590, -1.9787, -1.5488,  ..., -1.1410,  1.3344, -0.2104],\n",
      "          [-1.4276, -0.6944, -0.5667,  ...,  1.1990,  0.8454, -0.3241]],\n",
      "\n",
      "         [[ 1.3747,  3.0648,  3.7658,  ...,  0.6805,  1.6251, -0.7113],\n",
      "          [-3.6194,  2.6739, -2.5109,  ..., -3.2047,  2.9450, -0.3144],\n",
      "          [-3.1928,  1.5469, -3.1628,  ..., -2.9214,  3.4801,  1.2360],\n",
      "          ...,\n",
      "          [-4.6832, -1.4904, -4.8171,  ..., -3.4247,  1.8220,  0.7462],\n",
      "          [-4.9916, -1.4019, -5.5591,  ..., -3.7371,  2.9422,  0.6384],\n",
      "          [-3.3272, -1.9141, -4.6821,  ..., -3.4394,  3.4462,  0.7966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3571, -2.6940, -2.5864,  ...,  0.9747,  0.4724,  2.7245],\n",
      "          [-3.2790,  1.4895,  0.4607,  ...,  0.6635, -1.8444, -0.3443],\n",
      "          [-3.4600,  2.6956,  1.3558,  ..., -0.1266, -2.7145,  0.0972],\n",
      "          ...,\n",
      "          [-3.1993,  4.0702,  1.9383,  ..., -0.9552, -3.1067, -1.4688],\n",
      "          [-3.8521,  4.6710,  2.9112,  ..., -2.2364, -3.9045, -1.5241],\n",
      "          [-3.5332,  4.3554,  2.3162,  ..., -0.6138, -2.1636, -1.3958]],\n",
      "\n",
      "         [[ 1.7131,  0.4496,  0.9466,  ...,  0.0104, -0.9866, -0.3256],\n",
      "          [ 2.1683,  0.8876,  1.4803,  ...,  0.1768, -1.8011, -1.9908],\n",
      "          [ 2.0806,  1.0288,  1.1972,  ..., -0.0733, -1.5057, -1.4346],\n",
      "          ...,\n",
      "          [ 1.9361,  0.8342,  1.0479,  ..., -0.0835, -1.9249, -1.2110],\n",
      "          [ 2.2447,  0.3010,  1.0368,  ..., -0.2990, -1.8205, -1.2766],\n",
      "          [ 1.7111,  0.2756,  0.7408,  ...,  0.0539, -1.9953, -0.9998]],\n",
      "\n",
      "         [[-0.2538,  0.1160, -0.5586,  ...,  0.2681,  0.2844,  0.1296],\n",
      "          [-0.2222,  0.8479, -0.4422,  ..., -0.2732,  0.8777,  0.8108],\n",
      "          [-0.6727,  0.5071,  0.0572,  ...,  0.0786,  0.3229,  0.3834],\n",
      "          ...,\n",
      "          [ 0.2167, -0.1937, -1.1421,  ..., -0.4700,  0.8094, -0.1040],\n",
      "          [-0.4399,  0.3740,  0.0801,  ..., -0.2625,  0.2348, -0.2820],\n",
      "          [-0.7647, -0.3623, -0.5461,  ...,  0.6692,  0.6866,  0.8584]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-2.6110e-02, -6.3370e-03, -1.2897e-01,  ..., -2.7515e-02,\n",
      "            3.0886e-02, -5.4642e-01],\n",
      "          [ 2.8421e-01, -8.6539e-01, -2.9025e-01,  ...,  2.3311e-01,\n",
      "           -8.4891e-01,  1.3338e+00],\n",
      "          [ 2.4186e-01, -2.5358e-01, -8.4709e-01,  ..., -4.7114e-01,\n",
      "           -4.3807e-01,  8.2508e-01],\n",
      "          ...,\n",
      "          [ 5.8147e-01, -8.3756e-01,  1.4187e-02,  ...,  6.5366e-01,\n",
      "            3.2311e-01,  1.0884e+00],\n",
      "          [ 2.4318e-02, -4.3096e-01, -1.3149e-01,  ..., -2.2943e-01,\n",
      "            4.7279e-01,  6.5808e-01],\n",
      "          [ 1.6472e-01,  1.1389e+00, -1.3656e+00,  ...,  3.6690e-01,\n",
      "            5.6864e-01, -9.9857e-01]],\n",
      "\n",
      "         [[ 3.3488e-02, -2.1709e-02,  3.1775e-02,  ..., -3.6363e-02,\n",
      "           -2.0804e-02,  7.0153e-02],\n",
      "          [-2.9799e-02,  6.2118e-01, -3.6438e-01,  ...,  4.9335e-02,\n",
      "           -1.8000e-01,  3.8404e-01],\n",
      "          [-4.7976e-01,  1.9054e-02, -1.4230e+00,  ..., -4.2935e-01,\n",
      "            4.5856e-01,  1.0601e-01],\n",
      "          ...,\n",
      "          [-1.1260e+00, -6.7430e-02, -1.2505e+00,  ...,  9.8989e-01,\n",
      "            2.0997e-01,  6.6872e-01],\n",
      "          [-3.0780e-01, -2.7036e-02,  7.3606e-01,  ..., -1.8043e-01,\n",
      "           -6.6421e-02, -4.7701e-01],\n",
      "          [-5.7836e-02, -1.4135e-02,  2.8287e-01,  ..., -1.8417e-01,\n",
      "           -1.4725e-01,  1.0323e-01]],\n",
      "\n",
      "         [[ 6.9997e-03, -7.2047e-01, -1.4875e-02,  ...,  5.4531e-02,\n",
      "            3.6829e-02, -1.3042e-02],\n",
      "          [ 7.3096e-01, -1.3004e+00,  2.5491e-02,  ..., -2.0688e-01,\n",
      "            2.1388e-01, -1.9886e-01],\n",
      "          [-5.9057e-01, -1.3042e+00,  1.9017e-01,  ..., -1.8207e-01,\n",
      "           -3.5320e-03,  3.4668e-01],\n",
      "          ...,\n",
      "          [ 4.1662e-01, -4.3040e-01,  4.1711e-01,  ..., -7.3938e-01,\n",
      "           -1.8402e-01, -3.6389e-01],\n",
      "          [-1.5218e-02, -1.5639e+00, -5.2417e-01,  ..., -2.4254e-01,\n",
      "           -2.1577e-01,  3.0141e-01],\n",
      "          [ 1.0562e-01, -1.4539e+00, -1.0584e-01,  ..., -1.0705e-01,\n",
      "            3.9389e-02, -1.4812e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0108e-02, -5.6756e-02,  1.3052e+00,  ...,  1.0925e-03,\n",
      "            1.9278e-01, -2.0602e-03],\n",
      "          [-2.6232e-02,  3.2866e-01,  1.9221e+00,  ...,  1.4766e-01,\n",
      "           -6.7259e-02,  2.4187e-01],\n",
      "          [-4.8278e-01, -4.2951e-01,  1.8054e+00,  ...,  3.6253e-01,\n",
      "           -3.1257e-01,  3.7770e-01],\n",
      "          ...,\n",
      "          [-1.0864e+00, -7.8481e-01,  2.2155e+00,  ..., -2.1905e-01,\n",
      "            1.4895e-01,  3.9424e-02],\n",
      "          [ 1.1841e-01, -5.9558e-01,  1.9721e+00,  ...,  4.6364e-01,\n",
      "           -2.0958e-01,  1.8704e-01],\n",
      "          [ 8.8032e-02, -3.0378e-01,  2.5235e+00,  ..., -1.3628e-01,\n",
      "            2.6798e-01,  3.4488e-01]],\n",
      "\n",
      "         [[-1.5290e-02, -6.3416e-02, -1.4310e-01,  ...,  1.6105e-01,\n",
      "            1.1368e-01,  1.8954e-01],\n",
      "          [-9.1473e-01,  2.2297e-01,  1.4207e-01,  ...,  3.7582e-02,\n",
      "           -3.2340e-01, -1.5199e-01],\n",
      "          [ 3.7227e-01, -4.9001e-01,  1.7333e-01,  ..., -1.4885e-01,\n",
      "           -6.3321e-01, -2.0094e-01],\n",
      "          ...,\n",
      "          [-4.8509e-01,  2.7552e-01,  4.1076e-01,  ...,  7.9583e-02,\n",
      "           -1.2452e-02, -6.0336e-01],\n",
      "          [ 1.9530e-01,  2.1733e-01,  3.4654e-01,  ...,  3.8038e-01,\n",
      "           -1.0907e+00, -8.6067e-02],\n",
      "          [ 6.8279e-01,  6.9183e-01,  2.1597e-01,  ...,  2.1290e-01,\n",
      "           -1.1599e-01,  4.2206e-01]],\n",
      "\n",
      "         [[ 2.3022e-02,  2.4736e-02,  1.4599e-02,  ..., -1.3392e-02,\n",
      "            2.2758e-01, -6.3206e-03],\n",
      "          [ 4.9218e-02,  5.3240e-01,  9.0467e-01,  ...,  1.1255e-01,\n",
      "           -2.0287e+00,  9.8514e-01],\n",
      "          [-4.7997e-01, -7.5514e-02, -1.9737e-01,  ..., -6.4949e-02,\n",
      "           -1.9641e+00,  1.0550e-01],\n",
      "          ...,\n",
      "          [ 5.7662e-01,  1.3777e-01,  3.1310e-02,  ...,  1.8253e-01,\n",
      "           -2.1296e+00, -1.7676e-01],\n",
      "          [ 2.4730e-01,  8.7524e-02, -3.3989e-01,  ...,  8.7951e-02,\n",
      "           -2.2735e+00, -1.8762e-01],\n",
      "          [ 3.9984e-01, -2.0190e-01,  1.6420e-02,  ..., -2.5319e-01,\n",
      "           -1.3256e+00, -2.3872e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.1605e-03, -1.8791e-01,  1.4746e-01,  ..., -8.8068e-01,\n",
      "            7.5894e-01, -1.1973e+00],\n",
      "          [-2.5677e+00,  1.7679e+00, -3.9106e+00,  ...,  1.2833e+00,\n",
      "           -1.2259e+00,  2.1156e+00],\n",
      "          [-1.6822e+00, -3.9114e-01, -1.4672e+00,  ..., -1.2825e-01,\n",
      "            5.9892e-01,  4.3526e-01],\n",
      "          ...,\n",
      "          [-1.5596e+00, -3.2881e-02,  6.3978e-01,  ...,  1.7795e+00,\n",
      "           -1.6521e+00,  2.0406e+00],\n",
      "          [-6.5270e-01, -5.5162e-01,  1.0236e+00,  ..., -5.6010e-01,\n",
      "           -1.9103e+00,  1.2966e+00],\n",
      "          [-1.0920e-01, -8.7920e-01,  1.5120e-02,  ...,  6.2073e-01,\n",
      "           -2.7510e-01,  2.1425e-01]],\n",
      "\n",
      "         [[ 8.0498e-01,  2.0352e-01,  1.7896e-02,  ..., -1.6228e-01,\n",
      "           -1.0867e+00, -2.0632e-01],\n",
      "          [ 6.3069e-01, -1.4465e+00,  5.0411e-01,  ...,  3.4637e-01,\n",
      "            5.0468e+00,  2.1150e+00],\n",
      "          [-1.1162e+00, -1.3258e+00,  6.3189e-01,  ...,  1.2063e+00,\n",
      "            4.4761e+00,  1.0679e+00],\n",
      "          ...,\n",
      "          [ 2.2878e-01, -2.3659e+00,  7.8082e-01,  ...,  1.5353e+00,\n",
      "            4.7206e+00,  1.8281e+00],\n",
      "          [-4.8325e-01, -2.4448e+00,  2.4398e-01,  ..., -2.1931e-01,\n",
      "            4.3510e+00,  2.2534e+00],\n",
      "          [-1.7464e+00, -2.7802e-02, -1.4060e+00,  ..., -8.7865e-02,\n",
      "            4.2460e+00,  1.9398e+00]],\n",
      "\n",
      "         [[ 3.3238e-01, -3.5263e-01, -3.3511e-01,  ...,  3.3173e-01,\n",
      "            1.4302e+00,  2.7422e-01],\n",
      "          [-3.7069e-01, -6.1829e+00, -2.2466e+00,  ..., -3.6439e+00,\n",
      "           -2.1060e+00, -7.4567e+00],\n",
      "          [-4.5127e-01, -5.9982e+00, -2.4673e+00,  ..., -4.1265e+00,\n",
      "           -3.8545e+00, -6.1227e+00],\n",
      "          ...,\n",
      "          [-2.1317e+00, -6.2376e+00, -4.9529e+00,  ..., -3.5573e+00,\n",
      "           -2.2995e+00, -4.4041e+00],\n",
      "          [-2.2614e+00, -7.2026e+00, -3.0679e+00,  ..., -2.5467e+00,\n",
      "           -3.5838e+00, -3.2058e+00],\n",
      "          [-3.0414e+00, -6.8481e+00, -1.5457e+00,  ..., -3.4928e+00,\n",
      "           -2.2893e+00, -5.9958e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3405e-01,  1.8003e+00,  5.3820e-01,  ...,  2.6242e-01,\n",
      "            4.4860e-01, -1.6709e+00],\n",
      "          [ 1.3520e+00, -5.1191e+00,  2.9198e+00,  ..., -8.6180e-01,\n",
      "           -1.6337e+00,  5.9583e+00],\n",
      "          [-8.9198e-02, -6.2376e+00,  4.5249e-01,  ..., -1.8860e+00,\n",
      "           -2.1434e+00,  7.1481e+00],\n",
      "          ...,\n",
      "          [ 3.8247e-01, -7.7788e+00,  2.1529e+00,  ..., -2.9409e+00,\n",
      "           -1.4936e+00,  6.4806e+00],\n",
      "          [ 5.7257e-01, -6.5320e+00,  3.4520e-01,  ..., -4.8911e+00,\n",
      "           -1.1043e+00,  6.2615e+00],\n",
      "          [ 2.3120e-02, -7.1271e+00,  1.8783e+00,  ..., -2.4430e+00,\n",
      "           -1.0648e+00,  5.3935e+00]],\n",
      "\n",
      "         [[ 7.0162e-02, -5.0270e-02,  1.6436e-01,  ..., -8.4555e-02,\n",
      "           -8.5299e-02, -1.4128e-01],\n",
      "          [ 4.7663e-01, -5.4246e-01,  6.5545e-01,  ...,  4.4172e-01,\n",
      "           -1.1501e+00, -1.4259e+00],\n",
      "          [ 1.6341e+00, -1.9560e+00, -1.2453e+00,  ..., -1.1005e+00,\n",
      "           -1.0474e-01, -3.4483e-01],\n",
      "          ...,\n",
      "          [-1.4072e-01, -1.0868e+00, -9.5866e-02,  ...,  9.9929e-01,\n",
      "            1.2154e+00,  1.0204e+00],\n",
      "          [-5.3142e-01, -5.1684e-01, -7.8924e-01,  ..., -4.3379e-01,\n",
      "           -5.0606e-01, -1.4453e-01],\n",
      "          [-1.6270e-01, -6.7944e-01,  3.7796e-02,  ..., -8.0383e-02,\n",
      "           -2.0414e-01,  3.0041e-01]],\n",
      "\n",
      "         [[ 4.0545e-01, -3.8652e-02,  1.8953e+00,  ..., -2.2527e-01,\n",
      "           -1.9901e-01, -9.9290e-01],\n",
      "          [ 3.7929e+00,  9.7979e-01, -1.5706e+00,  ...,  8.7371e-01,\n",
      "            1.3123e+00,  4.0946e+00],\n",
      "          [ 2.6437e+00,  2.8533e+00, -1.1851e+00,  ...,  1.4979e+00,\n",
      "            1.7340e+00,  2.7878e+00],\n",
      "          ...,\n",
      "          [ 3.7213e+00,  4.2312e-01, -4.0639e+00,  ...,  3.0060e+00,\n",
      "            1.1026e+00,  4.5419e+00],\n",
      "          [ 4.2811e+00,  3.5972e-01, -3.0493e+00,  ...,  3.7985e+00,\n",
      "            1.4962e+00,  5.2126e+00],\n",
      "          [ 2.6493e+00,  1.5411e+00, -3.0109e+00,  ..., -5.3203e-01,\n",
      "            6.5990e-01,  4.2414e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 3.9765e-02,  6.3191e-02,  6.3377e-04,  ...,  1.9104e-02,\n",
      "            9.9082e-02,  3.4521e-02],\n",
      "          [ 1.1378e+00, -1.2861e+00, -1.2908e-01,  ..., -3.3004e-01,\n",
      "           -1.3635e+00, -2.2904e+00],\n",
      "          [-8.1626e-02,  9.3745e-02, -2.8481e-01,  ...,  2.1468e-01,\n",
      "           -9.6816e-01,  2.9894e-01],\n",
      "          ...,\n",
      "          [ 2.1699e-01, -1.8662e-01,  3.1800e-01,  ...,  7.8087e-02,\n",
      "           -1.3018e+00,  2.1320e-01],\n",
      "          [ 7.9638e-01,  2.0152e-01,  1.0130e-01,  ...,  2.5974e-01,\n",
      "           -7.7726e-01, -7.3525e-01],\n",
      "          [-2.1013e-01, -6.6706e-01,  1.7082e-01,  ...,  4.4624e-02,\n",
      "           -2.1095e-01,  1.0726e+00]],\n",
      "\n",
      "         [[-4.9772e-02,  4.5371e-03,  8.2704e-02,  ..., -5.1366e-02,\n",
      "           -3.5350e-02, -4.1695e-02],\n",
      "          [ 9.3125e-01,  4.8477e-01,  1.2721e-02,  ...,  2.5011e-01,\n",
      "            5.0911e-01,  7.7029e-02],\n",
      "          [ 5.3607e-01,  3.6337e-01,  5.9256e-01,  ...,  1.3317e-01,\n",
      "            2.4218e-01,  5.0219e-01],\n",
      "          ...,\n",
      "          [ 9.9435e-01,  8.4733e-01, -1.4116e-02,  ..., -2.2738e-01,\n",
      "           -3.3423e-01,  7.2092e-01],\n",
      "          [ 7.0013e-01,  4.3564e-02,  9.8745e-02,  ..., -4.9008e-01,\n",
      "           -1.1142e-01,  2.7808e-01],\n",
      "          [-2.6422e-01,  3.3482e-02,  4.0394e-02,  ...,  2.1468e-01,\n",
      "            2.0354e-01, -5.8808e-02]],\n",
      "\n",
      "         [[ 2.8733e-02, -1.1324e-01, -6.5474e-02,  ..., -2.8632e-02,\n",
      "            7.8444e-02, -1.6102e-01],\n",
      "          [-4.5820e-01,  4.7828e-01,  7.0547e-02,  ...,  5.3585e-01,\n",
      "           -4.5617e-01, -2.3535e-01],\n",
      "          [-3.3742e-01, -4.2131e-02,  5.9882e-01,  ...,  2.5610e-01,\n",
      "            7.7897e-02, -4.0960e-01],\n",
      "          ...,\n",
      "          [ 7.5842e-01, -5.6218e-02, -7.4135e-01,  ...,  5.3671e-02,\n",
      "           -4.3988e-01,  1.1196e+00],\n",
      "          [-8.5638e-01,  1.0162e+00, -1.6276e+00,  ..., -5.2393e-01,\n",
      "           -5.1775e-01,  2.8000e-01],\n",
      "          [ 3.0931e-01,  9.2681e-02, -5.2069e-01,  ..., -2.1601e-01,\n",
      "           -2.4954e-01, -6.8193e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0445e-02,  1.2575e-01, -8.2247e-03,  ..., -3.0457e-02,\n",
      "            6.6124e-02, -3.3832e-02],\n",
      "          [-7.7384e-01,  4.6625e-01, -8.6402e-01,  ...,  1.1561e+00,\n",
      "            1.9820e-01, -3.0625e-01],\n",
      "          [-2.7734e-04,  6.3935e-01, -1.8950e-01,  ...,  2.0117e-01,\n",
      "           -1.7873e-02,  5.5499e-01],\n",
      "          ...,\n",
      "          [ 7.8662e-01, -5.6376e-02,  4.7865e-01,  ..., -4.2434e-01,\n",
      "           -1.5718e-01, -4.8276e-01],\n",
      "          [ 6.4126e-01, -9.5627e-02, -9.7530e-03,  ...,  1.4783e-02,\n",
      "            3.4626e-01,  1.4248e-01],\n",
      "          [ 1.3236e-01,  2.3395e-01,  8.1249e-02,  ...,  4.1129e-01,\n",
      "            2.2832e-01,  5.4297e-02]],\n",
      "\n",
      "         [[-1.7626e-01, -1.0919e-01, -8.4360e-02,  ..., -2.3040e-01,\n",
      "           -1.7456e-02, -4.5445e-02],\n",
      "          [-7.3267e-01,  3.0908e-01, -6.8270e-01,  ...,  1.1911e+00,\n",
      "            6.0792e-01, -5.9669e-01],\n",
      "          [ 3.2711e-01, -8.1702e-01, -6.7690e-01,  ..., -1.4106e-01,\n",
      "            5.1631e-01,  1.7033e+00],\n",
      "          ...,\n",
      "          [ 6.9877e-01,  2.1668e-01,  2.2550e+00,  ...,  7.3070e-01,\n",
      "            1.5383e-01, -1.6586e-01],\n",
      "          [-1.2518e-01,  2.8476e-03,  1.7571e-01,  ...,  1.3301e-01,\n",
      "            1.5198e-01, -2.0102e-02],\n",
      "          [ 3.2786e-01,  4.0679e-01,  6.3502e-01,  ..., -9.9532e-01,\n",
      "            2.8010e-01,  1.7276e-01]],\n",
      "\n",
      "         [[ 1.2476e-01, -6.5556e-02, -2.6808e-02,  ..., -8.9693e-03,\n",
      "           -9.2486e-02, -8.6446e-02],\n",
      "          [-3.6288e-01, -4.0901e-01,  4.7382e-02,  ...,  7.5869e-01,\n",
      "            2.6507e-01, -2.3738e-01],\n",
      "          [-3.1819e-01,  4.7386e-01,  2.4661e-01,  ...,  1.0665e-02,\n",
      "            2.0598e-01, -6.8917e-01],\n",
      "          ...,\n",
      "          [-5.9656e-02,  5.2958e-01, -5.8517e-01,  ...,  2.4241e-01,\n",
      "            7.2702e-02,  4.3875e-01],\n",
      "          [-2.8286e-01, -2.9105e-01, -5.9394e-01,  ..., -1.3986e-01,\n",
      "            3.1039e-01, -5.7179e-01],\n",
      "          [ 4.7208e-01, -1.1132e-01,  2.8570e-02,  ..., -8.4544e-02,\n",
      "           -4.1679e-01,  1.1348e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-8.9410e-01, -1.4102e-01,  3.3448e-01,  ..., -9.8900e-01,\n",
      "            2.4201e-02, -2.9690e+00],\n",
      "          [ 2.0739e+00, -6.6276e-01, -9.6401e-01,  ..., -2.2700e+00,\n",
      "           -2.5282e+00,  5.5307e+00],\n",
      "          [ 1.4538e+00,  9.1335e-01, -1.2821e+00,  ..., -1.7829e+00,\n",
      "           -2.5922e+00,  7.0503e+00],\n",
      "          ...,\n",
      "          [-7.4860e-02, -1.2873e+00, -4.2342e+00,  ..., -1.1139e+00,\n",
      "           -4.1929e-01,  7.9390e+00],\n",
      "          [ 6.1465e-01,  1.4598e+00, -3.6137e+00,  ...,  1.9781e-01,\n",
      "           -5.2970e-01,  7.9857e+00],\n",
      "          [ 4.4373e-01, -2.1877e-01, -2.2024e+00,  ..., -2.1846e+00,\n",
      "           -1.8394e+00,  8.6313e+00]],\n",
      "\n",
      "         [[ 3.3228e-01, -5.2100e-02,  4.4828e-01,  ..., -1.3505e-01,\n",
      "           -6.7878e-02, -2.2125e+00],\n",
      "          [-1.9308e+00,  1.9479e-01,  3.7004e+00,  ..., -7.5413e-01,\n",
      "           -1.4453e+00,  5.9218e+00],\n",
      "          [-2.3695e+00,  6.8371e-01,  3.6881e+00,  ...,  4.3966e-01,\n",
      "           -1.1369e+00,  6.4070e+00],\n",
      "          ...,\n",
      "          [-1.4517e+00,  3.6522e-01,  2.4737e+00,  ..., -7.0429e-01,\n",
      "           -9.3994e-01,  6.8221e+00],\n",
      "          [-2.4442e+00,  5.6834e-01,  2.1406e+00,  ..., -1.6726e-02,\n",
      "           -2.8341e+00,  6.6074e+00],\n",
      "          [-1.7411e+00,  1.0740e-01,  2.9581e+00,  ..., -5.2872e-01,\n",
      "           -4.2821e-01,  6.4365e+00]],\n",
      "\n",
      "         [[ 1.3868e-01, -6.5963e-01, -2.3258e-01,  ...,  1.4861e-01,\n",
      "            2.7447e-01, -1.6060e-01],\n",
      "          [ 8.7127e-02,  1.5625e+00,  8.7948e-01,  ..., -5.6050e-02,\n",
      "            6.4114e-01, -2.2402e-02],\n",
      "          [-1.3730e+00,  1.8783e+00,  1.0146e+00,  ..., -7.2353e-01,\n",
      "           -1.0071e+00, -1.1916e-01],\n",
      "          ...,\n",
      "          [-1.4432e+00,  2.3373e+00, -7.6811e-02,  ...,  1.3016e-01,\n",
      "           -3.4882e-01,  1.0060e+00],\n",
      "          [ 3.4654e-01,  2.0433e+00,  1.0946e+00,  ..., -1.9423e-01,\n",
      "            5.6170e-01,  8.5613e-01],\n",
      "          [ 3.7556e-01,  2.7165e+00,  1.5422e+00,  ..., -6.2141e-01,\n",
      "            2.8909e-01, -1.2470e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8548e-01,  3.3657e-02, -8.6122e-04,  ...,  1.2389e+00,\n",
      "            4.4031e-02,  1.7787e+00],\n",
      "          [-3.3900e-01, -1.1665e+00, -1.6126e+00,  ..., -2.2094e+00,\n",
      "           -1.2286e+00, -8.3999e-01],\n",
      "          [ 1.1457e+00, -1.9595e+00, -2.7776e+00,  ..., -2.5459e+00,\n",
      "           -2.1862e+00, -6.8518e-01],\n",
      "          ...,\n",
      "          [ 2.7297e+00, -5.4906e-01,  6.4908e-01,  ..., -2.9931e+00,\n",
      "           -1.2364e+00, -2.9284e+00],\n",
      "          [ 9.0714e-01, -2.5425e-01,  1.0949e+00,  ..., -4.2778e+00,\n",
      "           -7.9689e-01, -2.4453e+00],\n",
      "          [ 5.2888e-01, -4.7623e-01, -1.0388e+00,  ..., -4.2955e+00,\n",
      "           -1.3179e+00, -6.7411e-01]],\n",
      "\n",
      "         [[-3.5278e-01, -1.6115e-01,  2.2002e-01,  ...,  2.5153e-01,\n",
      "           -2.5440e-02,  2.5464e-02],\n",
      "          [-5.8535e-01, -1.6797e+00, -9.7090e-02,  ...,  1.3156e+00,\n",
      "           -4.3526e-01, -3.6301e-01],\n",
      "          [-1.4276e+00, -4.4909e-01,  4.2122e-01,  ...,  8.0923e-01,\n",
      "            2.0564e+00,  5.5882e-01],\n",
      "          ...,\n",
      "          [ 2.3271e+00,  3.7035e-01, -1.2498e-01,  ...,  1.6023e+00,\n",
      "            7.8902e-01,  8.7364e-01],\n",
      "          [ 1.0688e+00,  6.8914e-01,  1.0407e+00,  ...,  1.1552e+00,\n",
      "           -4.6404e-01,  5.0676e-01],\n",
      "          [-5.4183e-01,  2.2367e-01,  1.1283e+00,  ...,  4.9600e-01,\n",
      "            4.4041e-01,  1.2166e+00]],\n",
      "\n",
      "         [[ 3.4287e+00,  2.1075e+00, -2.1753e+00,  ..., -2.8384e+00,\n",
      "           -3.9170e+00, -1.1987e+00],\n",
      "          [-2.3681e+00,  6.4387e-01,  2.7032e+00,  ...,  9.6174e-01,\n",
      "            5.6489e+00, -3.8173e+00],\n",
      "          [-1.7256e+00, -6.4346e-01,  3.3742e+00,  ...,  1.0354e-01,\n",
      "            1.0917e+01, -2.0007e+00],\n",
      "          ...,\n",
      "          [-2.4372e+00, -3.5694e+00,  5.2531e+00,  ..., -2.7536e+00,\n",
      "            1.4675e+01,  2.3681e+00],\n",
      "          [-5.4329e+00, -3.3473e+00,  6.1980e+00,  ..., -1.9572e+00,\n",
      "            1.3900e+01,  2.5586e+00],\n",
      "          [-5.6755e+00, -3.2005e+00,  9.5993e+00,  ..., -1.9898e-01,\n",
      "            1.4622e+01, -1.6569e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-9.6101e-04, -5.7273e-02,  1.4961e-02,  ...,  5.1007e-02,\n",
      "            2.4101e-02,  6.1853e-02],\n",
      "          [ 8.1719e-01,  3.1389e-01,  4.9729e-01,  ..., -4.4034e-01,\n",
      "           -5.6994e-01,  1.1864e+00],\n",
      "          [ 9.6673e-03, -1.2195e-01,  9.2736e-02,  ..., -8.4646e-01,\n",
      "            1.8833e-01, -2.2715e-02],\n",
      "          ...,\n",
      "          [-8.3899e-02, -1.7438e-01,  8.2991e-01,  ...,  4.0479e-01,\n",
      "           -5.2889e-01, -1.2070e+00],\n",
      "          [ 3.9354e-01,  4.8802e-02,  1.7574e-01,  ...,  1.7612e-01,\n",
      "            3.2382e-01, -6.9690e-01],\n",
      "          [-4.1270e-01,  1.0351e-01,  1.8573e-02,  ...,  6.5982e-02,\n",
      "           -2.0056e-01, -4.9836e-02]],\n",
      "\n",
      "         [[-5.8025e-02, -2.3602e-02, -1.3654e-01,  ..., -3.6943e-02,\n",
      "            4.6139e-02, -3.2083e-04],\n",
      "          [ 5.3729e-01,  2.3709e-01,  3.6851e-01,  ...,  3.0927e-01,\n",
      "           -7.5684e-01,  6.9841e-01],\n",
      "          [ 8.7619e-02, -3.0468e-01, -4.1744e-01,  ...,  4.6823e-01,\n",
      "           -5.7566e-01,  6.2960e-01],\n",
      "          ...,\n",
      "          [ 4.8862e-01,  6.7331e-01, -1.3201e-01,  ..., -4.5718e-01,\n",
      "            4.0848e-01,  3.6935e-01],\n",
      "          [ 1.3514e-01,  3.2320e-02, -1.7488e-01,  ...,  2.5361e-01,\n",
      "            6.0363e-01,  3.6989e-01],\n",
      "          [-3.1217e-01,  6.9660e-02, -1.0854e-01,  ..., -3.3014e-01,\n",
      "           -1.8350e-01,  1.7417e-01]],\n",
      "\n",
      "         [[ 5.9868e-02,  9.4087e-02,  8.9803e-02,  ...,  1.8044e-02,\n",
      "           -8.2018e-02, -7.6688e-03],\n",
      "          [ 4.6111e-03, -1.3464e-01,  5.5771e-01,  ..., -1.0991e+00,\n",
      "           -1.0160e-01, -4.8283e-01],\n",
      "          [-5.1055e-01, -3.0271e-01, -7.6251e-01,  ..., -5.6934e-02,\n",
      "           -4.8848e-01,  6.0690e-02],\n",
      "          ...,\n",
      "          [-5.6406e-01, -3.3250e-01,  5.2524e-01,  ...,  3.8864e-01,\n",
      "            6.4106e-01,  2.6505e-02],\n",
      "          [-2.4166e-01,  6.7879e-01, -5.6899e-01,  ...,  5.1277e-01,\n",
      "            8.9496e-01, -3.2001e-01],\n",
      "          [ 1.9636e-01, -1.2071e-01, -1.2509e-01,  ..., -2.6019e-01,\n",
      "           -2.9595e-01,  3.1048e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9281e-03,  8.4553e-02, -7.0813e-02,  ...,  4.7959e-02,\n",
      "            4.0231e-02, -1.3932e-01],\n",
      "          [-6.4524e-02, -1.8763e-01, -5.0959e-01,  ...,  1.2312e-01,\n",
      "            9.9802e-01, -5.4559e-01],\n",
      "          [ 2.7483e-01,  5.9988e-01, -8.3259e-01,  ...,  2.9060e-01,\n",
      "           -1.6327e-01,  5.9452e-01],\n",
      "          ...,\n",
      "          [ 1.1946e+00,  3.1072e-01, -2.8942e-01,  ...,  4.8221e-01,\n",
      "            1.0371e+00, -1.0225e+00],\n",
      "          [ 5.3250e-01, -1.2834e+00, -4.2687e-01,  ...,  1.3547e+00,\n",
      "           -1.9294e-01,  4.6109e-01],\n",
      "          [-2.1219e-01,  5.5494e-01, -4.9708e-01,  ...,  1.8992e-01,\n",
      "           -1.3037e-01, -9.2226e-01]],\n",
      "\n",
      "         [[-1.4771e-01, -5.4743e-02,  1.0354e-01,  ..., -6.4467e-02,\n",
      "            5.0235e-02, -4.7105e-03],\n",
      "          [ 2.0542e-01,  7.5674e-01, -3.8195e-01,  ...,  7.9123e-01,\n",
      "            3.3666e-01,  3.1182e-01],\n",
      "          [ 1.7716e-02, -2.9456e-01, -4.1132e-01,  ..., -3.7351e-02,\n",
      "           -5.0875e-01,  7.6014e-01],\n",
      "          ...,\n",
      "          [ 4.6112e-01,  1.3695e+00,  4.5065e-01,  ..., -6.2355e-01,\n",
      "            2.1478e-01,  1.1362e+00],\n",
      "          [-4.8439e-02,  1.9277e-02, -2.2616e-01,  ...,  6.6443e-02,\n",
      "           -1.4004e-01,  1.5982e-02],\n",
      "          [ 3.6793e-01, -4.4020e-01,  3.2716e-01,  ...,  5.6387e-01,\n",
      "            6.9215e-01,  6.9415e-02]],\n",
      "\n",
      "         [[-1.8205e-02, -3.0886e-03, -1.9086e-02,  ..., -2.5844e-02,\n",
      "            8.7407e-03, -1.7466e-02],\n",
      "          [-7.2502e-01, -4.0966e-01, -5.0877e-02,  ...,  7.9444e-01,\n",
      "           -4.2704e-01, -3.8911e-01],\n",
      "          [-2.3777e-01,  1.8286e-01, -1.1924e-01,  ...,  3.9828e-01,\n",
      "           -9.7823e-02, -7.2584e-01],\n",
      "          ...,\n",
      "          [-4.2147e-01, -4.4072e-01,  1.3276e-01,  ..., -3.9426e-01,\n",
      "            5.9784e-01, -5.9402e-01],\n",
      "          [-1.1911e+00, -2.2353e-01, -5.2611e-01,  ..., -6.8117e-01,\n",
      "            4.3145e-01, -6.0661e-01],\n",
      "          [ 5.7201e-01, -2.1513e-01, -2.0821e-02,  ..., -2.6662e-01,\n",
      "            4.3591e-01,  9.3393e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.7386e-02, -2.9366e-01,  2.2930e-01,  ...,  1.6992e+00,\n",
      "           -2.1956e-01, -6.9672e-02],\n",
      "          [ 1.3258e+00,  4.3530e-03, -4.5178e-01,  ..., -3.3861e+00,\n",
      "            6.0935e-01, -9.7996e-02],\n",
      "          [-3.8398e-03,  6.8534e-01, -4.5098e-01,  ..., -3.5777e+00,\n",
      "            4.3510e-01, -1.0692e+00],\n",
      "          ...,\n",
      "          [ 1.0944e+00, -1.3281e-01, -8.4927e-01,  ..., -4.4945e+00,\n",
      "           -8.8708e-01, -7.0987e-01],\n",
      "          [-4.0466e-01,  1.8280e-01,  7.3278e-02,  ..., -3.9964e+00,\n",
      "            5.3101e-01, -8.9631e-01],\n",
      "          [-2.8022e-01,  2.4591e-01, -9.5407e-01,  ..., -3.1422e+00,\n",
      "            5.9489e-01, -6.9650e-01]],\n",
      "\n",
      "         [[ 1.4856e-01,  9.7933e-01, -1.4228e+00,  ..., -1.2427e-01,\n",
      "            2.7183e-01,  9.2512e-01],\n",
      "          [-4.5280e+00, -5.5021e+00,  7.7566e-01,  ...,  3.7732e-02,\n",
      "            2.0070e+00, -6.6960e-01],\n",
      "          [-1.8428e+00, -5.4617e+00, -1.5096e+00,  ..., -1.3806e-01,\n",
      "           -1.6786e+00, -1.6976e+00],\n",
      "          ...,\n",
      "          [-1.0155e+00, -4.1935e+00,  9.1143e-01,  ..., -6.7730e-01,\n",
      "            8.5889e-01, -2.9881e+00],\n",
      "          [ 3.6602e-01, -2.7849e+00,  1.7301e+00,  ...,  8.3982e-01,\n",
      "            1.8913e+00, -1.8723e+00],\n",
      "          [ 1.8487e-01, -2.9940e+00,  3.7968e-01,  ..., -6.0796e-01,\n",
      "            1.2830e+00, -1.7956e+00]],\n",
      "\n",
      "         [[-6.7567e-01,  2.5791e-01, -4.4622e-02,  ...,  1.8188e-01,\n",
      "            3.5410e-02, -2.7977e-01],\n",
      "          [ 7.9076e-01, -6.6335e-01, -1.7585e+00,  ..., -1.6750e+00,\n",
      "           -1.0765e+00, -1.3595e+00],\n",
      "          [ 2.1679e+00, -6.9918e-02,  4.3477e-01,  ...,  1.2724e-01,\n",
      "           -4.9424e-01, -1.1511e+00],\n",
      "          ...,\n",
      "          [ 1.8131e+00, -2.6902e-01,  1.9496e-01,  ..., -7.7712e-02,\n",
      "           -1.8967e+00,  9.0248e-02],\n",
      "          [ 1.1712e+00, -1.0126e+00, -8.9855e-01,  ..., -8.4999e-01,\n",
      "           -1.0316e+00, -2.0615e+00],\n",
      "          [ 6.7570e-01,  3.8597e-01, -3.9110e-01,  ..., -8.8803e-02,\n",
      "           -3.7925e-01,  9.4493e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6750e-02,  1.1317e-01,  1.4411e-01,  ..., -9.5337e-02,\n",
      "            2.8758e-02,  1.7906e-01],\n",
      "          [ 5.2997e-01, -2.4246e-01, -8.6437e-03,  ...,  1.7977e+00,\n",
      "           -1.2685e+00,  6.6170e-01],\n",
      "          [ 1.3688e+00, -5.8446e-01, -1.0249e+00,  ...,  6.1781e-01,\n",
      "           -1.2555e+00,  1.8549e-01],\n",
      "          ...,\n",
      "          [-4.0208e-01, -3.9943e-01,  9.0350e-01,  ..., -8.4164e-02,\n",
      "            2.9849e-01,  1.3064e+00],\n",
      "          [ 8.7521e-01, -5.4618e-01,  6.0006e-01,  ..., -4.2599e-01,\n",
      "            9.5319e-01,  4.6231e-02],\n",
      "          [ 6.7025e-01, -2.4473e-02,  6.4640e-01,  ...,  9.7068e-01,\n",
      "            5.1276e-01,  1.2734e-01]],\n",
      "\n",
      "         [[-3.0175e+00,  3.9929e-01, -3.6378e-02,  ..., -4.7122e-01,\n",
      "           -3.4804e-01,  1.2437e+00],\n",
      "          [ 5.1598e+00, -6.4113e-01, -1.2113e+00,  ..., -5.4299e-01,\n",
      "           -6.3423e-01, -2.7112e+00],\n",
      "          [ 3.9647e+00, -4.5005e-01, -8.1767e-01,  ...,  1.3302e+00,\n",
      "            1.0222e+00, -3.6523e-01],\n",
      "          ...,\n",
      "          [ 6.9698e+00,  1.0402e-01, -1.2673e+00,  ...,  1.4771e+00,\n",
      "           -3.9453e-01, -1.3275e+00],\n",
      "          [ 5.9740e+00, -3.1729e-01, -3.0472e-01,  ..., -1.6971e+00,\n",
      "            1.9964e+00, -5.9248e-01],\n",
      "          [ 4.3904e+00,  3.9197e-01, -6.1715e-01,  ..., -1.7761e+00,\n",
      "            3.8099e-01,  9.8361e-02]],\n",
      "\n",
      "         [[-1.4068e-02, -2.3846e-01,  2.5290e-02,  ..., -1.6074e-01,\n",
      "            3.3649e-01,  8.6691e-02],\n",
      "          [ 2.8667e-02, -2.1868e+00,  1.7570e-01,  ...,  3.2765e-01,\n",
      "            3.8849e-01, -1.7206e+00],\n",
      "          [-2.3774e-02, -1.9333e+00, -1.1854e-01,  ..., -5.0054e-01,\n",
      "            1.4996e+00, -2.0566e-01],\n",
      "          ...,\n",
      "          [-1.6754e-01, -7.2157e-01,  6.8358e-01,  ...,  2.4385e-01,\n",
      "            1.1955e+00, -2.1362e+00],\n",
      "          [-1.7204e-01, -1.5373e+00,  4.9301e-01,  ...,  1.1556e-01,\n",
      "            1.8178e+00, -1.0164e+00],\n",
      "          [ 2.1786e-01, -1.8928e+00,  4.4174e-01,  ...,  4.2819e-01,\n",
      "            1.5182e-01, -2.0864e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0283, -0.0237, -0.0065,  ..., -0.0032, -0.0248,  0.3515],\n",
      "          [ 0.8264,  0.2939, -0.5176,  ..., -0.2927, -0.2171,  0.0181],\n",
      "          [ 1.9226, -0.7101,  0.3985,  ...,  0.1594,  0.7347, -0.2097],\n",
      "          ...,\n",
      "          [ 0.3205, -0.6643,  0.0532,  ..., -0.3513, -0.3939, -1.5316],\n",
      "          [ 0.0561, -0.2875, -0.6101,  ...,  1.2166,  0.5898, -1.2971],\n",
      "          [ 0.1016,  0.4254, -0.1121,  ...,  0.1045,  0.3800, -1.0232]],\n",
      "\n",
      "         [[ 0.0052, -0.0295,  0.0151,  ..., -0.0267,  0.0140,  0.0122],\n",
      "          [-0.5628, -0.9254,  0.9794,  ..., -0.2008,  1.3605, -0.3241],\n",
      "          [ 0.7993,  0.5138, -0.2952,  ..., -0.7700,  0.4493, -0.8436],\n",
      "          ...,\n",
      "          [-0.0907,  0.4751,  1.4920,  ..., -0.6118,  0.6339, -0.4834],\n",
      "          [ 1.1835, -0.9603,  1.0771,  ..., -0.7290,  0.1659, -1.8319],\n",
      "          [-0.7705,  0.0071, -1.1086,  ..., -0.2116,  1.5475, -1.0844]],\n",
      "\n",
      "         [[-0.0587,  0.0065, -0.0385,  ..., -0.0367,  0.0108, -0.0737],\n",
      "          [-0.3782,  0.4603, -0.0197,  ..., -0.0948, -0.1734, -0.0478],\n",
      "          [-1.0508, -0.9034, -0.1986,  ...,  0.7021,  0.1026,  0.6465],\n",
      "          ...,\n",
      "          [ 0.6918, -0.7151,  0.4399,  ..., -0.5258,  0.4609,  0.3265],\n",
      "          [-0.5982, -0.3842, -0.2050,  ..., -0.3919, -0.2597, -0.3368],\n",
      "          [-0.2127,  0.2818,  1.1315,  ..., -0.4063,  0.3917,  0.4088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3268, -0.1926, -0.0725,  ..., -0.4884,  0.2164,  0.0924],\n",
      "          [ 2.4077, -2.1106,  0.0814,  ...,  2.1166,  0.7840, -0.3542],\n",
      "          [ 0.7914, -2.0034, -1.2725,  ...,  0.1668,  0.2048, -0.0149],\n",
      "          ...,\n",
      "          [ 0.1624,  0.0656,  0.3339,  ...,  1.6880,  0.5858, -0.4577],\n",
      "          [ 0.3699, -2.1781, -0.6363,  ...,  1.6692, -0.0237,  0.6235],\n",
      "          [ 1.1835, -1.2606, -0.3178,  ...,  0.8860, -0.2557, -1.0126]],\n",
      "\n",
      "         [[-0.0743, -0.1376, -0.0477,  ..., -0.1892, -0.1411,  0.1259],\n",
      "          [-0.8208, -0.8386,  0.6731,  ...,  0.6332,  0.0199, -0.7615],\n",
      "          [ 0.2827,  0.3740, -0.2432,  ...,  0.1827, -0.3376,  0.5142],\n",
      "          ...,\n",
      "          [ 0.9158,  0.1738,  0.1931,  ..., -0.3132, -0.0828,  0.6322],\n",
      "          [-1.2725,  0.6167, -0.2177,  ..., -0.5662, -0.9483,  0.7020],\n",
      "          [-0.4237, -0.4396, -0.7444,  ..., -0.1120, -0.1108,  0.0457]],\n",
      "\n",
      "         [[-0.0376, -0.0407,  0.1040,  ...,  0.0808, -0.0425,  0.0137],\n",
      "          [ 0.1663, -0.5093,  0.4754,  ..., -0.8001, -0.2647, -0.0260],\n",
      "          [ 0.8517, -0.0424,  0.2084,  ..., -0.4614, -0.3543, -0.4421],\n",
      "          ...,\n",
      "          [ 0.8837, -0.2089, -1.3849,  ...,  0.0321,  0.3742,  0.3700],\n",
      "          [ 1.5021,  0.3024, -1.6816,  ...,  0.2755, -0.4314,  1.2684],\n",
      "          [ 0.8986, -0.4031, -0.7551,  ...,  0.2049,  0.5642,  0.3766]]]],\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-3.4242e-01,  8.8585e-01, -1.5804e-01,  ...,  1.1261e+00,\n",
      "           -1.9518e-01,  1.4177e-01],\n",
      "          [-1.9220e+00, -3.5766e+00,  1.0735e+00,  ..., -2.9989e+00,\n",
      "            2.4456e-01,  1.6964e+00],\n",
      "          [ 2.0634e-01, -4.5545e+00, -3.9479e-01,  ..., -2.3682e+00,\n",
      "            7.5262e-01,  1.9643e+00],\n",
      "          ...,\n",
      "          [ 4.1849e-02, -3.6175e+00, -3.7537e-01,  ..., -3.7409e+00,\n",
      "           -2.5598e+00,  1.3602e+00],\n",
      "          [ 9.7942e-01, -4.3081e+00, -8.1837e-01,  ..., -3.9368e+00,\n",
      "           -3.5577e-01,  6.4095e-01],\n",
      "          [-1.1241e+00, -4.2882e+00,  9.7364e-01,  ..., -3.9289e+00,\n",
      "            3.2482e-01,  1.0470e+00]],\n",
      "\n",
      "         [[ 4.3837e-02,  8.5526e-01, -6.5018e-01,  ..., -4.8066e-02,\n",
      "            2.9846e-01,  1.3144e-02],\n",
      "          [ 1.8581e+00, -8.6762e-01,  1.1911e-01,  ...,  1.4102e+00,\n",
      "           -1.5516e+00, -8.9818e-01],\n",
      "          [ 3.9744e-01, -7.4263e-01, -8.7026e-01,  ...,  2.1461e+00,\n",
      "            6.7020e-01, -5.7750e-01],\n",
      "          ...,\n",
      "          [-1.8549e+00,  4.0110e-01,  1.0519e+00,  ..., -6.1303e-01,\n",
      "            1.0524e+00, -1.9586e+00],\n",
      "          [-1.6497e+00,  1.7422e+00,  2.8445e+00,  ..., -4.2254e-01,\n",
      "            1.4167e+00,  2.2799e-02],\n",
      "          [ 3.9260e-01,  5.7385e-01,  6.0346e-01,  ...,  1.8517e+00,\n",
      "            1.6710e-01, -8.4129e-03]],\n",
      "\n",
      "         [[-3.0691e-01,  1.4184e-01, -9.7711e-01,  ..., -3.5239e-01,\n",
      "           -6.5329e-02, -1.5691e-01],\n",
      "          [ 5.4449e-01,  2.6089e-01,  3.3700e+00,  ...,  5.8992e-01,\n",
      "            3.0752e-01,  1.6272e-01],\n",
      "          [ 1.8183e-01, -4.2966e-01,  3.6656e+00,  ...,  6.5348e-01,\n",
      "            1.6247e-01,  1.1807e+00],\n",
      "          ...,\n",
      "          [ 6.0342e-01, -2.8374e-02,  4.0457e+00,  ...,  1.4485e-01,\n",
      "           -3.0530e-01, -1.8585e-02],\n",
      "          [ 8.4563e-01, -6.5223e-02,  3.8245e+00,  ...,  4.2786e-02,\n",
      "            8.7348e-01,  8.6994e-01],\n",
      "          [-4.1459e-01,  9.7909e-01,  2.9803e+00,  ..., -3.9050e-01,\n",
      "           -1.2682e-01,  4.7122e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7623e-01,  8.8415e-02, -6.9547e-02,  ..., -4.7736e-02,\n",
      "            2.2840e-01,  1.9032e-02],\n",
      "          [ 7.1144e-01,  1.8763e-01, -3.9937e-01,  ..., -4.9091e-01,\n",
      "           -1.2776e+00,  6.4044e-01],\n",
      "          [-3.3112e-01,  1.5726e+00, -1.1475e-01,  ...,  1.2293e+00,\n",
      "           -3.2792e-01,  1.3483e+00],\n",
      "          ...,\n",
      "          [-1.2218e+00,  1.0106e+00,  1.5841e+00,  ...,  2.4095e-01,\n",
      "            1.8157e+00,  2.5420e-01],\n",
      "          [-7.0075e-01, -2.0352e+00,  3.5377e-01,  ..., -2.1764e-01,\n",
      "            1.2933e+00,  3.9608e-01],\n",
      "          [-1.2331e+00, -2.5181e-01,  9.9036e-01,  ..., -7.5640e-02,\n",
      "            1.3286e+00,  6.3743e-01]],\n",
      "\n",
      "         [[ 1.9031e-01,  5.9438e-02,  3.3524e-01,  ...,  4.2277e-01,\n",
      "            1.9400e-02,  2.2399e-01],\n",
      "          [ 5.9327e-01,  2.8811e-01, -1.4083e-01,  ..., -1.5039e+00,\n",
      "           -2.3323e-01,  3.1527e-01],\n",
      "          [ 1.1468e+00, -2.1674e-01,  1.2189e+00,  ..., -4.9551e-01,\n",
      "            2.9952e-01,  4.2660e-01],\n",
      "          ...,\n",
      "          [ 1.2327e+00,  1.9132e-01,  9.7667e-01,  ..., -3.9745e-01,\n",
      "           -8.6595e-01,  1.6085e-01],\n",
      "          [ 1.5555e+00,  1.2640e-01,  1.5087e+00,  ..., -2.6383e-01,\n",
      "           -1.4203e+00, -3.3963e-01],\n",
      "          [ 2.5104e+00, -4.2117e-01,  9.7205e-01,  ...,  7.9409e-02,\n",
      "           -1.9639e+00,  1.2759e+00]],\n",
      "\n",
      "         [[-3.0269e+00,  5.5620e-01,  5.7562e-01,  ..., -9.3499e-01,\n",
      "            3.1438e-01,  1.8537e-01],\n",
      "          [ 6.4035e+00, -2.6481e-01, -1.7831e+00,  ...,  9.5199e-01,\n",
      "           -1.3967e+00, -1.9982e-02],\n",
      "          [ 6.5658e+00, -5.8532e-01, -3.0053e+00,  ...,  1.1486e+00,\n",
      "           -8.4129e-01, -1.1981e+00],\n",
      "          ...,\n",
      "          [ 8.7470e+00,  4.9102e-01, -8.1829e-01,  ...,  9.2144e-01,\n",
      "           -1.9827e-01, -2.1748e+00],\n",
      "          [ 8.8249e+00,  7.7651e-01, -9.9607e-01,  ...,  1.0463e-01,\n",
      "           -8.5052e-01, -1.0812e+00],\n",
      "          [ 9.4365e+00, -1.1869e+00, -5.3457e-01,  ...,  2.5683e+00,\n",
      "            4.1110e-01, -7.9529e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 4.2588e-02, -5.0356e-02,  8.1064e-03,  ..., -7.2504e-02,\n",
      "            9.6370e-03, -9.2134e-02],\n",
      "          [-4.3344e-01,  1.3342e-01, -4.7552e-02,  ...,  4.4079e-01,\n",
      "            2.6153e-01,  1.0634e+00],\n",
      "          [ 3.0987e-01, -1.2253e-01, -8.2554e-01,  ..., -5.1116e-01,\n",
      "           -7.1061e-01,  9.2578e-01],\n",
      "          ...,\n",
      "          [-8.3976e-01,  2.3753e-01,  2.7464e-01,  ...,  2.1087e-01,\n",
      "            2.5150e-01,  4.4114e-01],\n",
      "          [-1.1380e+00,  2.7989e-01, -2.8601e-01,  ..., -3.8907e-02,\n",
      "            6.6291e-01, -1.5787e-01],\n",
      "          [ 2.5615e-01, -1.8164e-01,  3.2558e-01,  ..., -7.4514e-02,\n",
      "            1.2012e-01, -5.7117e-01]],\n",
      "\n",
      "         [[ 7.9494e-02,  1.9629e-02, -1.4942e-02,  ..., -3.9482e-02,\n",
      "            2.1056e-02, -1.7007e-02],\n",
      "          [ 4.6344e-01, -1.4725e-01,  8.2258e-01,  ...,  3.4143e-01,\n",
      "            6.6488e-02, -1.0046e+00],\n",
      "          [ 4.0348e-01, -8.7195e-01, -1.1793e+00,  ...,  1.0580e+00,\n",
      "            5.7153e-01,  5.3592e-01],\n",
      "          ...,\n",
      "          [-6.6896e-01,  1.4602e-01,  1.4269e+00,  ..., -1.1985e-01,\n",
      "            1.1612e+00,  2.0802e+00],\n",
      "          [-2.0435e-01,  2.5427e-01,  8.5200e-01,  ..., -8.8234e-01,\n",
      "            9.5405e-01,  4.8340e-01],\n",
      "          [ 8.2470e-01,  1.2348e-01, -1.8963e-02,  ..., -2.7635e-01,\n",
      "            3.8721e-01,  7.9089e-01]],\n",
      "\n",
      "         [[ 6.5061e-02,  1.7394e-02, -1.3197e-02,  ...,  1.9595e-02,\n",
      "           -6.2144e-02, -6.3763e-02],\n",
      "          [-1.1359e-02,  6.8293e-01, -8.8521e-01,  ..., -8.8195e-01,\n",
      "           -9.2533e-01,  1.0995e+00],\n",
      "          [ 7.2526e-01, -6.4550e-01, -1.0321e-01,  ..., -6.4715e-01,\n",
      "           -5.5848e-01,  1.3314e+00],\n",
      "          ...,\n",
      "          [-6.7675e-01, -1.5009e-01, -6.6685e-01,  ..., -4.3112e-01,\n",
      "           -8.0608e-01, -2.0868e-01],\n",
      "          [-6.1433e-01, -2.4865e-01, -3.9539e-01,  ..., -1.8268e+00,\n",
      "            3.9165e-01, -1.5418e+00],\n",
      "          [-3.6172e-01, -6.2750e-01, -3.1816e-01,  ..., -9.2306e-02,\n",
      "            2.7719e-01,  3.6233e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2369e-03,  2.0590e-02,  1.8059e-02,  ..., -6.7566e-02,\n",
      "           -2.1130e-02,  1.0344e-02],\n",
      "          [-2.6505e-01,  6.8229e-02, -5.8064e-01,  ...,  2.0919e+00,\n",
      "           -2.0487e-01, -6.2631e-02],\n",
      "          [-1.1090e+00, -4.0114e-01,  6.4974e-01,  ...,  1.8533e+00,\n",
      "           -5.9498e-01, -1.5189e+00],\n",
      "          ...,\n",
      "          [-1.7999e-01, -1.3203e+00, -4.0722e-01,  ...,  5.0378e-01,\n",
      "           -6.4837e-01,  2.0433e-01],\n",
      "          [ 1.6616e-01, -6.4843e-02,  4.4673e-01,  ..., -1.3760e+00,\n",
      "           -1.5886e+00,  1.6740e+00],\n",
      "          [-2.3218e-01, -1.0700e+00, -2.0870e-01,  ...,  4.2789e-01,\n",
      "            1.3457e-01,  4.9070e-01]],\n",
      "\n",
      "         [[ 4.5884e-02, -1.3652e-02,  3.3538e-02,  ...,  4.2297e-02,\n",
      "           -1.0651e-02,  1.3725e-02],\n",
      "          [ 6.7968e-01, -6.1345e-01, -5.1771e-01,  ...,  3.9566e-01,\n",
      "           -6.3267e-01, -7.4087e-01],\n",
      "          [ 3.2293e-01, -5.0785e-01, -2.0837e+00,  ...,  1.2406e+00,\n",
      "            3.0909e-01,  7.6786e-01],\n",
      "          ...,\n",
      "          [ 6.6215e-01,  1.4883e+00, -1.3764e+00,  ..., -8.5867e-01,\n",
      "           -9.7664e-01,  7.5940e-02],\n",
      "          [-3.7327e-01,  1.0781e+00, -1.1749e+00,  ...,  1.5869e-02,\n",
      "           -8.2584e-01, -8.5889e-01],\n",
      "          [-1.0721e-01, -2.9212e-01, -1.0636e+00,  ...,  4.9721e-01,\n",
      "           -3.1657e-02, -7.9183e-02]],\n",
      "\n",
      "         [[ 7.6791e-02, -2.0113e-01, -8.1943e-02,  ..., -2.3764e-02,\n",
      "            2.0464e-01, -5.6837e-02],\n",
      "          [ 9.9647e-02, -2.1344e+00,  4.2548e-02,  ...,  4.3812e-01,\n",
      "           -7.9336e-01,  4.1660e-01],\n",
      "          [-1.0473e-01, -8.4764e-01, -1.0118e-01,  ...,  7.0098e-01,\n",
      "           -6.8366e-02, -1.1925e-01],\n",
      "          ...,\n",
      "          [ 8.6353e-02,  2.0148e+00, -7.8215e-01,  ...,  1.2433e+00,\n",
      "           -1.2465e+00,  8.4485e-02],\n",
      "          [ 2.1874e-01,  1.7080e+00, -7.7510e-01,  ...,  2.0696e-01,\n",
      "            1.1354e-02,  1.2248e-01],\n",
      "          [-9.0595e-01, -7.8929e-01,  2.8046e-02,  ...,  1.5975e-01,\n",
      "           -3.9888e-01,  8.6554e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0446, -0.2861, -0.1417,  ...,  0.6163,  0.7392, -0.3206],\n",
      "          [-3.9079, -2.3097,  2.2869,  ..., -1.0490, -3.9810,  0.3166],\n",
      "          [-4.8613, -0.9516,  2.6062,  ..., -0.0303, -3.9882, -0.5383],\n",
      "          ...,\n",
      "          [-3.5567, -2.6193,  0.7828,  ...,  0.6872, -4.4898, -0.6281],\n",
      "          [-4.2590, -1.7552,  2.8268,  ..., -0.6523, -4.0929, -0.2955],\n",
      "          [-4.9762, -1.9708,  0.0080,  ..., -0.3365, -3.7900, -0.1139]],\n",
      "\n",
      "         [[-0.1387, -0.0569,  0.1582,  ..., -0.0465, -0.8847, -0.2043],\n",
      "          [-0.5542, -0.0729, -0.3130,  ..., -0.0560, -0.7031,  1.6099],\n",
      "          [-1.3839,  1.4181, -0.2936,  ...,  1.3373, -1.0466,  1.9511],\n",
      "          ...,\n",
      "          [-1.8806,  0.3803, -1.2217,  ...,  1.7803,  0.9103,  0.4690],\n",
      "          [-1.2040,  1.6865, -0.4972,  ...,  0.5542, -0.4544,  1.0700],\n",
      "          [-2.2268,  0.3460, -1.5116,  ...,  0.5357, -0.8997,  0.5252]],\n",
      "\n",
      "         [[ 0.1924,  0.3075,  1.1360,  ..., -0.4682,  0.4283, -0.5042],\n",
      "          [ 1.1163, -0.8514, -1.3363,  ..., -0.5048, -2.3173,  1.4079],\n",
      "          [-0.4352, -0.6518, -1.4657,  ...,  0.3762, -3.2430,  2.4583],\n",
      "          ...,\n",
      "          [-1.2546, -1.4138, -1.6076,  ..., -2.2605, -1.6244, -0.5993],\n",
      "          [-0.4396, -2.4026, -0.8960,  ..., -1.1734, -1.3114,  0.8956],\n",
      "          [ 0.6041, -1.4925, -0.8934,  ..., -1.4043, -2.3182,  1.5456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1552,  0.0680, -0.2229,  ..., -0.0112,  0.1523,  0.0379],\n",
      "          [-1.4715, -0.2699, -1.0010,  ...,  0.9816, -0.0131, -0.5940],\n",
      "          [-2.8031, -0.0749, -0.5765,  ...,  1.4030,  0.5713, -0.3813],\n",
      "          ...,\n",
      "          [-0.7421,  0.1682,  1.1091,  ...,  0.2662, -1.0974, -1.7564],\n",
      "          [ 0.5485,  0.4741,  1.4970,  ..., -0.3822, -0.6439, -1.4745],\n",
      "          [-1.9331,  1.2431, -0.7142,  ...,  0.8943, -0.3290, -0.2887]],\n",
      "\n",
      "         [[-0.3520, -2.1820,  0.1305,  ..., -0.0781, -0.0452,  0.9126],\n",
      "          [-0.1676,  0.7424,  0.8457,  ..., -0.0430, -0.6897,  0.9972],\n",
      "          [-1.0619,  3.2376,  2.5831,  ...,  0.4896,  0.5569,  1.1650],\n",
      "          ...,\n",
      "          [ 0.1921,  4.7669, -0.9619,  ...,  0.1920,  0.0281, -1.6348],\n",
      "          [-0.3346,  4.0043,  0.8320,  ...,  1.9739,  0.4835,  0.2861],\n",
      "          [-0.4076,  1.6655, -1.2985,  ...,  1.3795, -0.0910,  1.3841]],\n",
      "\n",
      "         [[ 0.3705,  0.0804, -0.1422,  ...,  0.6539,  0.1286,  0.2599],\n",
      "          [ 0.2785, -0.1845, -0.7767,  ..., -0.6425,  0.7165, -1.3394],\n",
      "          [-0.0426, -1.2866, -0.2084,  ...,  0.4318,  1.4718,  0.1445],\n",
      "          ...,\n",
      "          [-2.9565, -2.3736, -1.0456,  ...,  0.5869, -0.2452, -0.1996],\n",
      "          [-2.0673, -1.9636,  0.6297,  ..., -1.2112, -0.6369,  2.2856],\n",
      "          [-1.5174, -0.1974,  1.0155,  ...,  0.1546,  0.5188,  1.0438]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-3.2128e-02,  4.2769e-02, -6.2959e-02,  ..., -2.4990e-02,\n",
      "           -5.5757e-04,  1.9665e-02],\n",
      "          [ 5.3965e-01,  1.5681e-02, -8.6195e-01,  ..., -6.3801e-01,\n",
      "            3.3483e-02,  2.0060e-01],\n",
      "          [-2.2824e-02,  1.7671e-01, -1.9057e-01,  ..., -6.8474e-01,\n",
      "           -7.3559e-01,  5.6330e-01],\n",
      "          ...,\n",
      "          [-5.3655e-01, -6.8140e-01, -2.7338e-01,  ..., -8.9929e-01,\n",
      "            6.7783e-01, -7.7594e-02],\n",
      "          [-6.6499e-02, -2.1919e-01,  7.2967e-01,  ...,  3.1051e-01,\n",
      "           -9.1984e-01,  1.6034e+00],\n",
      "          [-4.6004e-02,  1.7540e-01, -1.4991e-01,  ..., -3.8299e-01,\n",
      "           -1.2224e-01,  3.0644e-01]],\n",
      "\n",
      "         [[ 8.2082e-03, -2.1715e-02,  3.5759e-02,  ...,  2.5118e-02,\n",
      "           -4.6394e-02,  1.3449e-02],\n",
      "          [-5.6013e-01, -4.7913e-01, -7.3465e-01,  ...,  2.4955e-01,\n",
      "           -2.2302e-01,  1.7230e-02],\n",
      "          [-2.6670e-01, -5.7562e-02, -1.0933e+00,  ...,  6.9102e-01,\n",
      "            8.8651e-01,  2.3363e-01],\n",
      "          ...,\n",
      "          [ 1.4549e+00,  6.2701e-01,  3.4483e-01,  ..., -2.6119e-01,\n",
      "           -1.8188e-01,  2.0104e-01],\n",
      "          [ 9.1125e-01, -5.0901e-01,  1.7518e-01,  ...,  4.0393e-02,\n",
      "           -8.2194e-03, -6.1320e-01],\n",
      "          [-3.7897e-01, -1.3483e-01,  9.1876e-02,  ...,  3.8443e-01,\n",
      "            4.2697e-01, -3.3593e-01]],\n",
      "\n",
      "         [[ 5.1188e-02, -3.5194e-02,  2.7533e-02,  ...,  1.4181e-02,\n",
      "           -6.4940e-03,  2.2787e-02],\n",
      "          [ 5.1446e-01, -1.3208e+00, -1.0446e+00,  ...,  1.7527e-02,\n",
      "            1.7641e+00, -3.5737e-01],\n",
      "          [-2.7716e-01,  6.2414e-02, -1.8526e+00,  ..., -4.1313e-01,\n",
      "           -5.6179e-01,  1.0078e+00],\n",
      "          ...,\n",
      "          [ 4.1809e-01, -5.0762e-02, -3.4584e-01,  ..., -1.2960e+00,\n",
      "           -5.4343e-01, -1.4812e-01],\n",
      "          [ 1.5966e-01, -1.5908e-01, -2.6502e-01,  ..., -2.6891e-01,\n",
      "            1.3304e+00, -6.3225e-01],\n",
      "          [ 4.6884e-01, -2.5218e-01, -6.3545e-01,  ..., -2.6028e+00,\n",
      "            3.5557e-02, -2.5807e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8817e-01,  7.5630e-02,  5.1482e-02,  ...,  6.3044e-02,\n",
      "            4.5983e-02, -1.2272e-01],\n",
      "          [-4.8166e-01, -8.0081e-01,  4.7553e-01,  ...,  9.2073e-01,\n",
      "            1.4889e+00, -4.9100e-01],\n",
      "          [ 3.1190e-01, -1.7164e+00, -6.4195e-01,  ..., -3.0160e-01,\n",
      "            9.8333e-01, -1.3910e+00],\n",
      "          ...,\n",
      "          [ 2.6294e-01,  1.7654e-01, -2.2927e-01,  ..., -5.6709e-01,\n",
      "           -4.2601e-01,  1.8268e-01],\n",
      "          [-1.2287e+00, -8.8129e-01, -4.9618e-01,  ...,  5.7656e-01,\n",
      "           -9.3972e-02,  9.1813e-01],\n",
      "          [-5.2435e-01, -5.0482e-01, -6.5543e-01,  ..., -9.4711e-02,\n",
      "            2.7462e-01, -4.3348e-01]],\n",
      "\n",
      "         [[-5.8365e-01, -2.0280e-02,  4.3795e-02,  ..., -1.2728e-02,\n",
      "            1.4847e-02, -1.1488e-02],\n",
      "          [ 2.1189e-01,  6.3309e-01, -8.5212e-01,  ...,  1.7115e-02,\n",
      "           -1.6814e-01,  3.3735e-01],\n",
      "          [-5.0398e-01,  1.2201e-01, -9.9508e-01,  ...,  1.0425e+00,\n",
      "            5.1320e-01,  8.6971e-01],\n",
      "          ...,\n",
      "          [-1.4073e+00,  4.5373e-01, -1.8494e-01,  ...,  1.0106e-01,\n",
      "            1.1485e+00, -5.4966e-02],\n",
      "          [-7.8669e-01, -4.6794e-01,  8.1497e-02,  ..., -6.6191e-01,\n",
      "            9.3902e-01, -4.7145e-01],\n",
      "          [-2.6530e+00, -1.3969e-01,  2.4383e-01,  ..., -2.2311e-01,\n",
      "            4.6452e-01,  3.6028e-01]],\n",
      "\n",
      "         [[ 1.8879e-02,  8.3848e-02, -5.0716e-02,  ...,  5.5664e-02,\n",
      "            2.9355e-02, -4.1400e-02],\n",
      "          [-3.1205e-01,  3.7567e-01,  3.4224e-01,  ...,  7.1520e-01,\n",
      "            7.5321e-01, -1.1299e-01],\n",
      "          [-1.0119e+00,  3.3448e-01, -1.2705e+00,  ..., -8.8392e-01,\n",
      "           -2.3355e+00, -2.2953e-01],\n",
      "          ...,\n",
      "          [ 1.9421e-01,  1.2625e+00,  6.1021e-01,  ...,  1.0141e+00,\n",
      "           -1.3892e-01, -3.8717e-01],\n",
      "          [-1.6888e+00,  1.0561e+00,  6.2911e-01,  ..., -7.9248e-01,\n",
      "           -1.2793e+00,  2.5451e-02],\n",
      "          [-6.8985e-01,  3.8036e-01,  1.1172e+00,  ..., -3.2168e-01,\n",
      "           -9.4463e-01,  8.1670e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-3.0739e-02, -2.3328e+00,  1.6444e-01,  ..., -2.4874e-01,\n",
      "           -2.1955e-01,  6.7818e-02],\n",
      "          [ 6.6502e-01,  3.8897e+00,  2.5626e-01,  ..., -1.2447e+00,\n",
      "           -5.1476e-01,  1.7492e-01],\n",
      "          [ 2.3555e-01,  4.3144e+00,  1.5203e+00,  ..., -1.0305e+00,\n",
      "           -2.7401e-01, -2.9700e-01],\n",
      "          ...,\n",
      "          [-7.4795e-01,  6.0315e+00,  1.4481e+00,  ..., -1.7219e+00,\n",
      "            1.5043e-01,  3.6442e-02],\n",
      "          [-1.1906e+00,  6.0815e+00,  7.5815e-01,  ...,  7.6926e-03,\n",
      "            1.6461e+00, -4.0052e-01],\n",
      "          [-7.7746e-01,  4.0435e+00,  8.6778e-01,  ..., -1.0730e+00,\n",
      "            3.5681e-01, -7.8313e-01]],\n",
      "\n",
      "         [[-8.1230e-01,  2.0313e-01,  4.6825e-01,  ..., -5.1517e-01,\n",
      "            1.0709e+00,  1.1254e+00],\n",
      "          [ 1.9943e-01,  7.3408e-02,  1.8181e+00,  ..., -3.0854e-01,\n",
      "            1.3158e+00,  6.8892e-02],\n",
      "          [ 3.2874e-01, -6.4358e-01,  2.3493e+00,  ..., -1.5555e-01,\n",
      "            2.4417e+00,  1.8911e-01],\n",
      "          ...,\n",
      "          [ 6.9652e-01,  1.3289e+00, -4.7835e-01,  ..., -1.1337e+00,\n",
      "            6.5288e-01, -2.0380e+00],\n",
      "          [ 2.1073e-01,  1.0003e+00,  1.2394e+00,  ..., -6.3918e-01,\n",
      "            8.0475e-01, -1.5733e+00],\n",
      "          [ 3.1132e-01,  2.8403e-01,  2.9093e-01,  ..., -1.5865e+00,\n",
      "            3.1738e+00, -7.4550e-01]],\n",
      "\n",
      "         [[-8.3052e-01,  4.9202e-01,  1.5700e-02,  ...,  5.0540e-01,\n",
      "           -2.3221e-01,  1.1760e+00],\n",
      "          [ 1.8285e+00, -1.1218e+00, -6.0110e-01,  ...,  1.7362e-01,\n",
      "            1.3459e+00,  1.1774e-01],\n",
      "          [ 1.6429e+00, -2.1772e+00,  1.7248e+00,  ...,  3.0036e-01,\n",
      "            7.7876e-01,  9.9058e-01],\n",
      "          ...,\n",
      "          [ 1.0010e+00, -1.7313e+00,  1.9045e+00,  ...,  8.0702e-01,\n",
      "            5.2974e-01, -6.8052e-01],\n",
      "          [ 1.5992e+00, -2.7915e+00,  1.0877e+00,  ...,  7.4602e-01,\n",
      "            3.0332e-02, -1.3237e+00],\n",
      "          [ 1.6438e+00, -9.9109e-01,  9.2324e-01,  ...,  1.1409e+00,\n",
      "            5.9684e-01, -3.3017e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0107e-01, -1.1655e-01,  1.3441e-01,  ...,  1.8965e-01,\n",
      "            1.7320e+00, -2.8680e+00],\n",
      "          [ 1.9154e+00,  1.2091e+00,  2.8645e-01,  ...,  1.3748e-01,\n",
      "           -3.8644e+00,  3.9812e+00],\n",
      "          [ 9.2973e-01, -1.0160e-01, -1.3099e-02,  ..., -3.6517e-01,\n",
      "           -4.1451e+00,  4.7426e+00],\n",
      "          ...,\n",
      "          [ 5.7876e-01, -5.6903e-01, -9.7981e-01,  ..., -1.5678e+00,\n",
      "           -5.4191e+00,  5.7578e+00],\n",
      "          [-1.9895e-01, -5.5637e-01, -4.0058e-01,  ..., -1.3523e+00,\n",
      "           -5.3991e+00,  5.7263e+00],\n",
      "          [ 1.0074e-01,  9.1534e-01,  5.5960e-01,  ..., -1.0116e+00,\n",
      "           -5.7379e+00,  5.5124e+00]],\n",
      "\n",
      "         [[ 1.8309e-01,  3.5898e-01,  2.1865e-01,  ..., -2.1976e-01,\n",
      "            3.2432e-02, -1.3621e-01],\n",
      "          [-1.1902e+00,  2.5967e-01,  1.3770e+00,  ...,  1.6082e+00,\n",
      "            5.3296e-01,  1.0141e-01],\n",
      "          [-1.6201e+00,  3.1865e-01,  5.4789e-01,  ...,  7.9333e-01,\n",
      "            4.1223e-01, -9.2892e-01],\n",
      "          ...,\n",
      "          [-1.7144e+00,  2.9198e-01, -6.5764e-01,  ...,  1.4415e+00,\n",
      "           -4.7544e-02,  6.2226e-01],\n",
      "          [-1.0669e+00,  9.0313e-01, -9.0603e-01,  ...,  1.4476e+00,\n",
      "           -3.0205e-01, -8.2349e-01],\n",
      "          [-6.1682e-01,  4.0207e-01, -2.7279e-01,  ...,  1.9482e+00,\n",
      "           -5.3192e-01, -1.6915e-01]],\n",
      "\n",
      "         [[ 3.8544e-01,  1.1505e-01,  6.3900e-01,  ...,  5.3104e-01,\n",
      "            5.7931e-01, -3.3185e-01],\n",
      "          [ 4.0666e-01, -9.3643e-01, -1.0314e+00,  ..., -6.5106e-01,\n",
      "           -3.1251e+00, -3.6746e-01],\n",
      "          [ 9.7926e-01, -9.1059e-01,  2.0969e-01,  ..., -1.8782e+00,\n",
      "           -3.4683e+00,  2.0600e-01],\n",
      "          ...,\n",
      "          [-1.4226e-01, -9.7476e-01, -5.4240e-01,  ..., -2.8039e+00,\n",
      "           -4.1771e+00,  1.9208e+00],\n",
      "          [-7.5886e-01, -6.7514e-01, -4.4395e-02,  ..., -2.4649e+00,\n",
      "           -4.5963e+00,  6.7639e-01],\n",
      "          [-6.9450e-01,  4.6577e-01, -7.3801e-01,  ..., -2.1795e+00,\n",
      "           -4.2150e+00,  2.8132e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 5.3734e-02, -1.4238e-02, -3.5810e-02,  ...,  1.2174e-01,\n",
      "           -5.9948e-02, -4.3049e-02],\n",
      "          [-4.0712e-01,  2.3952e-01, -1.4630e-01,  ..., -4.0966e-01,\n",
      "            8.4789e-01, -2.2644e-01],\n",
      "          [-1.4474e+00, -8.4849e-01, -9.8838e-02,  ..., -2.0224e-01,\n",
      "            6.6301e-01,  7.1867e-01],\n",
      "          ...,\n",
      "          [-6.3025e-01, -9.1939e-01,  1.5612e+00,  ...,  6.4965e-01,\n",
      "            2.6919e+00,  8.4095e-01],\n",
      "          [-5.2483e-01, -1.3637e+00,  1.8403e+00,  ...,  3.8219e-01,\n",
      "            1.4497e+00,  1.0683e-03],\n",
      "          [-2.9674e-02,  1.7135e-01, -7.6390e-01,  ..., -3.9354e-01,\n",
      "            4.4974e-01, -9.9768e-01]],\n",
      "\n",
      "         [[ 1.7320e-02,  2.3816e-02,  4.7974e-02,  ..., -4.7309e-03,\n",
      "           -6.8243e-03,  3.2884e-03],\n",
      "          [ 5.4060e-01,  1.3387e+00,  1.0772e+00,  ..., -4.1182e-01,\n",
      "           -7.2695e-02,  7.3047e-01],\n",
      "          [ 1.6604e+00, -1.0405e+00, -4.6418e-02,  ..., -1.5549e-01,\n",
      "            4.8930e-01,  2.6706e-01],\n",
      "          ...,\n",
      "          [-2.6609e-02,  1.4448e+00, -9.6231e-02,  ...,  1.4043e+00,\n",
      "           -2.1171e-01,  6.2546e-01],\n",
      "          [ 1.7877e+00, -7.9523e-01,  3.4070e-01,  ..., -1.0215e+00,\n",
      "            5.2032e-01, -7.5460e-01],\n",
      "          [-6.6356e-01,  7.8232e-01,  8.1055e-01,  ..., -6.7723e-01,\n",
      "           -5.3982e-01, -7.7323e-01]],\n",
      "\n",
      "         [[ 5.1727e-02, -3.2729e-02,  6.2676e-02,  ...,  3.5751e-02,\n",
      "           -7.1613e-02, -5.9328e-02],\n",
      "          [-3.5343e-01,  7.5885e-01, -4.1293e-02,  ...,  2.4424e-01,\n",
      "           -6.9912e-01, -5.4976e-01],\n",
      "          [ 7.8512e-02, -4.0856e-01,  5.3512e-01,  ..., -8.2215e-01,\n",
      "            1.6102e-03, -5.0301e-01],\n",
      "          ...,\n",
      "          [-7.4352e-01,  2.1682e-01,  5.4941e-01,  ..., -7.3409e-01,\n",
      "            5.1859e-01,  4.1631e-02],\n",
      "          [-3.8653e-01,  1.1920e+00, -2.0321e-01,  ..., -1.3420e-01,\n",
      "           -2.3149e-01, -1.5669e-01],\n",
      "          [-6.5035e-01,  1.6409e-01, -2.7168e-01,  ..., -5.6859e-02,\n",
      "            3.0424e-01,  6.7128e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5711e-02, -3.3712e-02,  3.5806e-02,  ..., -9.8101e-02,\n",
      "            3.3037e-02,  2.1276e-02],\n",
      "          [-1.0548e+00,  1.0086e+00,  3.5336e-01,  ...,  1.4173e-01,\n",
      "            1.1533e+00, -5.7750e-01],\n",
      "          [ 3.0501e-01,  3.8879e-01,  1.4593e+00,  ..., -1.5761e+00,\n",
      "            6.6029e-01, -2.4784e+00],\n",
      "          ...,\n",
      "          [ 2.1433e-01,  3.0902e-01, -1.5677e-01,  ..., -1.4376e+00,\n",
      "            3.1234e-01, -1.5930e-01],\n",
      "          [ 9.2111e-02,  1.3849e+00, -3.5478e-01,  ..., -2.0249e+00,\n",
      "            1.7484e+00,  1.5088e+00],\n",
      "          [ 1.0588e+00,  5.0693e-02,  1.6493e-02,  ..., -3.3869e-01,\n",
      "            6.8473e-01,  6.6574e-02]],\n",
      "\n",
      "         [[ 1.5089e-01, -6.4248e-02,  1.3481e-01,  ...,  7.3110e-02,\n",
      "            4.8974e-03, -1.2889e-01],\n",
      "          [ 6.8720e-01,  5.7470e-02, -1.7870e-01,  ..., -1.1156e+00,\n",
      "           -1.2297e+00,  1.5927e-02],\n",
      "          [ 4.6848e-01,  6.8089e-01,  4.5960e-01,  ..., -3.4666e-01,\n",
      "           -8.2155e-01,  7.9260e-01],\n",
      "          ...,\n",
      "          [-6.8295e-01, -4.1632e-01, -3.1648e-01,  ..., -1.0120e+00,\n",
      "           -1.2630e+00,  4.1550e-01],\n",
      "          [ 3.2675e-02, -5.2766e-01, -1.6868e+00,  ..., -9.0995e-01,\n",
      "           -2.2853e-01,  1.4612e+00],\n",
      "          [ 2.0993e-01, -2.2174e-01,  1.0833e+00,  ..., -6.0768e-01,\n",
      "            6.2882e-01,  8.7863e-02]],\n",
      "\n",
      "         [[ 2.1724e-01, -6.2232e-02, -5.5712e-02,  ...,  2.1461e-02,\n",
      "            4.3089e-02,  3.7415e-02],\n",
      "          [ 1.3125e+00, -4.4910e-01, -7.5738e-01,  ...,  3.2747e-01,\n",
      "           -9.8980e-02, -8.0641e-02],\n",
      "          [-1.6063e-01, -7.7957e-01, -1.6312e-01,  ..., -4.8402e-01,\n",
      "            8.7137e-01, -2.5966e-01],\n",
      "          ...,\n",
      "          [-3.6798e-01,  5.0565e-01,  2.8998e-01,  ...,  2.5920e-01,\n",
      "           -1.9344e+00,  7.5728e-01],\n",
      "          [ 4.9460e-02, -4.9568e-01,  8.4527e-01,  ..., -3.3127e-01,\n",
      "            6.4243e-01, -3.5335e-01],\n",
      "          [ 1.1826e-01, -1.5026e-01,  9.7509e-01,  ...,  4.7500e-01,\n",
      "           -8.4105e-01,  6.5077e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.3000e-02, -2.4427e-01, -4.4500e-01,  ...,  3.0083e-01,\n",
      "            3.2684e-01,  3.6586e-01],\n",
      "          [-3.1921e-01,  1.1035e+00, -8.1620e-01,  ..., -1.0129e+00,\n",
      "           -1.0356e-01, -3.4720e-01],\n",
      "          [ 1.2050e-01,  8.5493e-01, -4.7644e-01,  ...,  2.5663e-01,\n",
      "           -7.2198e-01,  7.0494e-01],\n",
      "          ...,\n",
      "          [-3.0341e-01,  2.8500e-03,  4.0952e-01,  ...,  2.3109e+00,\n",
      "           -8.2102e-01, -3.8004e-01],\n",
      "          [-3.2070e-03,  2.9617e-01, -1.1834e-01,  ...,  3.1173e+00,\n",
      "            4.8563e-01,  1.0006e+00],\n",
      "          [ 4.6373e-01, -9.1019e-02, -9.6269e-01,  ...,  6.1472e-01,\n",
      "           -6.0768e-01,  9.6789e-01]],\n",
      "\n",
      "         [[-2.7947e-01,  1.5264e-01,  1.2265e-01,  ...,  6.3868e-02,\n",
      "           -1.1406e+00, -1.3803e-01],\n",
      "          [ 7.5798e-01,  7.3406e-01,  2.4232e+00,  ..., -1.7083e-01,\n",
      "           -1.2876e+00,  6.4982e-01],\n",
      "          [ 5.9163e-01, -2.5393e-01,  9.1644e-01,  ...,  1.4073e+00,\n",
      "           -9.9605e-01,  1.3304e+00],\n",
      "          ...,\n",
      "          [ 2.9273e-01, -3.5705e-01,  1.8072e+00,  ...,  5.2217e-01,\n",
      "           -1.9019e+00, -1.5490e+00],\n",
      "          [-3.1270e-02,  1.4249e-01,  1.4840e+00,  ...,  4.6309e-01,\n",
      "           -1.1398e+00, -3.6930e-01],\n",
      "          [-1.5090e-01,  1.7000e+00,  1.0501e+00,  ...,  4.5167e-01,\n",
      "            8.9898e-01,  2.7553e-01]],\n",
      "\n",
      "         [[-1.2364e+00, -1.0861e-01,  5.7612e-01,  ..., -6.5710e-01,\n",
      "            4.6449e-01, -2.9151e-01],\n",
      "          [ 5.4201e-01,  4.5983e-01, -1.3218e-01,  ...,  6.8797e-01,\n",
      "            3.7853e-01,  7.0103e-01],\n",
      "          [ 1.0557e+00,  3.7951e-01,  9.9993e-02,  ...,  1.0149e+00,\n",
      "           -8.0008e-02,  3.1117e-01],\n",
      "          ...,\n",
      "          [ 2.7617e+00,  9.2056e-01,  2.5572e+00,  ..., -2.7046e-01,\n",
      "           -2.6544e-01,  4.2675e-01],\n",
      "          [ 3.2526e+00,  2.6460e+00,  1.0609e+00,  ...,  4.3606e-01,\n",
      "           -1.4836e-01,  5.3355e-01],\n",
      "          [ 1.2066e+00,  2.9331e+00,  7.7203e-03,  ...,  6.1325e-01,\n",
      "           -1.2444e+00,  4.3294e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8954e-01, -9.0881e-01, -3.9374e-01,  ..., -1.0515e+00,\n",
      "           -4.3844e-01,  4.8402e-01],\n",
      "          [ 1.0609e+00, -1.1448e+00, -7.7389e-01,  ..., -4.1185e-01,\n",
      "           -8.2883e-01, -6.0351e-01],\n",
      "          [ 5.0185e-01, -6.5958e-01, -5.7256e-02,  ..., -1.2351e+00,\n",
      "           -6.1601e-01, -5.3572e-01],\n",
      "          ...,\n",
      "          [ 2.8482e-01,  9.0139e-01, -4.6546e-01,  ..., -1.0758e+00,\n",
      "            5.9336e-01, -1.4398e+00],\n",
      "          [-1.4410e+00,  1.8157e+00, -1.4097e-01,  ..., -1.1282e+00,\n",
      "            1.1474e+00, -1.1473e+00],\n",
      "          [ 9.0526e-01,  2.4593e-01, -1.1596e+00,  ...,  3.7836e-01,\n",
      "           -1.2631e+00, -4.5477e-01]],\n",
      "\n",
      "         [[-9.2652e-01,  2.5459e+00,  3.0600e-01,  ...,  3.4490e-01,\n",
      "            1.9553e+00, -5.4894e-01],\n",
      "          [ 4.5858e-01, -2.1932e+00,  1.7457e-01,  ...,  1.7436e+00,\n",
      "           -2.5849e+00,  2.2585e+00],\n",
      "          [ 1.7932e-02, -2.7316e+00,  2.1564e-01,  ...,  6.8611e-01,\n",
      "           -4.1920e+00,  1.6138e+00],\n",
      "          ...,\n",
      "          [ 2.3517e-01, -6.8795e+00,  2.4382e+00,  ...,  1.0712e+00,\n",
      "           -3.7377e+00,  2.1150e+00],\n",
      "          [-5.6485e-01, -5.2606e+00,  1.9043e+00,  ...,  6.5478e-01,\n",
      "           -4.0746e+00,  7.2067e-01],\n",
      "          [-4.5100e-02, -3.6478e+00,  1.7280e-01,  ..., -7.5855e-01,\n",
      "           -4.0225e+00,  1.6237e+00]],\n",
      "\n",
      "         [[-2.0252e+00, -3.5049e-01, -1.1153e+00,  ..., -3.9788e-01,\n",
      "            6.0882e-02,  2.5314e-01],\n",
      "          [ 2.0696e+00, -4.9512e-01,  1.0584e+00,  ...,  7.4010e-01,\n",
      "            4.9070e-01,  5.7455e-01],\n",
      "          [ 2.5638e+00,  1.1148e+00, -5.5302e-01,  ...,  1.2067e-01,\n",
      "            3.6514e-01, -1.7264e-01],\n",
      "          ...,\n",
      "          [ 4.7496e+00, -1.1327e+00,  3.4154e+00,  ...,  1.0882e+00,\n",
      "            5.4831e-01, -2.3920e-01],\n",
      "          [ 3.7342e+00, -7.3702e-01,  2.6068e+00,  ...,  3.8731e-01,\n",
      "           -4.0681e-01, -8.3097e-01],\n",
      "          [ 2.0753e+00,  1.0187e+00,  2.0027e+00,  ...,  5.9608e-01,\n",
      "           -1.2866e-01, -3.3631e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.9407e-02, -8.5679e-02,  1.7006e-02,  ...,  1.0696e-01,\n",
      "           -2.7256e-02,  1.2712e-02],\n",
      "          [-1.1028e-01, -2.6695e-01, -2.7972e-01,  ...,  7.3320e-02,\n",
      "            8.1304e-02,  9.9563e-01],\n",
      "          [ 2.2058e-01,  5.5391e-01, -1.4877e+00,  ..., -2.8705e-01,\n",
      "            3.1862e-01,  8.9564e-01],\n",
      "          ...,\n",
      "          [-2.2597e+00,  4.0054e-01,  3.5313e-01,  ..., -3.1097e-01,\n",
      "           -6.2333e-01,  6.2798e-02],\n",
      "          [-4.0290e-01,  4.4471e-01, -5.3869e-01,  ...,  3.8806e-01,\n",
      "            7.7051e-01, -8.9604e-02],\n",
      "          [-6.9789e-02,  9.6001e-01, -1.9557e-01,  ...,  1.2244e+00,\n",
      "           -4.5771e-01, -4.4116e-01]],\n",
      "\n",
      "         [[ 1.9984e-02,  9.9455e-03, -1.8535e-02,  ...,  2.8180e-02,\n",
      "            3.0411e-02,  5.3315e-02],\n",
      "          [ 5.9644e-01,  5.1996e-01, -1.2417e+00,  ..., -7.3599e-02,\n",
      "            1.1116e+00,  4.7235e-01],\n",
      "          [ 9.7821e-01, -1.1090e+00, -1.6003e-01,  ...,  1.1247e+00,\n",
      "           -1.9147e-01,  2.4299e-01],\n",
      "          ...,\n",
      "          [-2.4673e+00,  2.1871e+00,  1.5703e+00,  ..., -4.3629e-01,\n",
      "           -1.2542e-01, -6.9803e-01],\n",
      "          [ 2.0128e-01,  7.3901e-01, -9.9507e-01,  ..., -1.5172e+00,\n",
      "           -4.1022e-01, -5.7266e-01],\n",
      "          [ 2.5452e-02,  8.2747e-01, -5.4466e-01,  ..., -5.8290e-01,\n",
      "           -9.6744e-01, -4.3227e-01]],\n",
      "\n",
      "         [[ 3.0771e-02,  3.3925e-02, -9.5088e-02,  ...,  2.0078e-02,\n",
      "           -1.8055e-03,  3.6985e-03],\n",
      "          [-7.0360e-01,  1.2550e-01,  2.7324e-01,  ...,  2.4933e-01,\n",
      "           -1.0440e+00,  2.5170e+00],\n",
      "          [-3.4458e-01, -8.2069e-01, -4.0843e-01,  ..., -7.7839e-01,\n",
      "           -7.3081e-01, -2.8720e-01],\n",
      "          ...,\n",
      "          [-6.4247e-01,  2.9498e-01, -1.6238e+00,  ...,  1.0017e+00,\n",
      "           -4.7254e-01,  3.8370e-01],\n",
      "          [ 1.0750e-01,  5.6388e-01, -1.1467e+00,  ...,  4.9151e-01,\n",
      "            4.4171e-01,  4.7236e-01],\n",
      "          [-5.2674e-01,  6.2729e-01, -7.3630e-01,  ..., -9.5472e-02,\n",
      "           -3.0964e-01, -9.4150e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2988e-02,  1.8975e-02, -2.9906e-03,  ..., -2.4180e-03,\n",
      "           -7.7688e-04,  3.6506e-02],\n",
      "          [ 1.0896e+00, -5.7907e-01,  2.7873e-01,  ...,  5.9871e-01,\n",
      "            2.0423e+00, -1.8796e-01],\n",
      "          [ 1.1956e+00, -2.4500e-01,  9.7125e-01,  ...,  7.4841e-01,\n",
      "           -1.6449e-01, -7.1359e-01],\n",
      "          ...,\n",
      "          [-1.2320e+00,  2.2416e+00,  1.4954e+00,  ...,  3.9171e-01,\n",
      "           -3.1156e-01, -1.0704e+00],\n",
      "          [-9.0054e-01,  2.1070e-01, -2.4055e-01,  ..., -2.8735e-01,\n",
      "           -2.5012e-01, -2.8542e-01],\n",
      "          [ 1.7678e-01,  9.9594e-01, -1.2952e-01,  ...,  3.1505e-01,\n",
      "            1.0217e+00, -2.8011e-01]],\n",
      "\n",
      "         [[-6.6889e-02, -4.6806e-02,  1.3993e-02,  ...,  1.3800e-02,\n",
      "           -6.0449e-02, -1.0146e-01],\n",
      "          [-1.2984e-01, -3.9512e-01,  9.2746e-02,  ...,  2.9088e-01,\n",
      "            1.8776e-01, -2.5012e-02],\n",
      "          [ 1.4572e+00, -1.4012e-01,  1.1444e-01,  ...,  2.8305e-01,\n",
      "           -3.2234e-01, -1.2569e-01],\n",
      "          ...,\n",
      "          [ 7.1413e-01, -1.7208e+00,  6.2938e-02,  ..., -6.0424e-01,\n",
      "            3.3152e-01, -1.3289e+00],\n",
      "          [ 8.2656e-02, -8.4586e-02, -1.6153e+00,  ..., -2.1428e-01,\n",
      "           -1.4150e-01,  1.0627e+00],\n",
      "          [ 6.7371e-01, -6.1994e-01, -2.5474e-01,  ...,  3.9961e-01,\n",
      "            4.5265e-01,  4.9732e-01]],\n",
      "\n",
      "         [[-1.5357e-02,  3.5532e-02, -6.0959e-02,  ..., -2.2750e-02,\n",
      "            4.1216e-03,  3.3249e-03],\n",
      "          [-4.9697e-01, -9.3557e-01, -6.3136e-02,  ...,  6.6151e-01,\n",
      "            4.0965e-01, -7.5030e-02],\n",
      "          [-4.4716e-02, -6.6199e-01, -9.2861e-01,  ...,  5.9766e-01,\n",
      "            2.3181e-01, -2.1284e-01],\n",
      "          ...,\n",
      "          [ 9.3537e-01,  2.7058e-01,  1.1165e+00,  ..., -6.2206e-01,\n",
      "            2.9264e-01,  1.3320e+00],\n",
      "          [ 7.5008e-01,  1.0221e+00, -3.0353e-02,  ...,  1.3531e-01,\n",
      "            1.1982e+00,  1.2872e-02],\n",
      "          [-1.1730e+00, -6.0364e-01,  1.8613e-01,  ...,  4.8842e-01,\n",
      "           -8.2276e-02,  3.5773e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5168,  0.5003, -0.8527,  ..., -1.0179, -1.3143,  0.2035],\n",
      "          [ 0.5839,  0.4706, -0.0539,  ...,  0.7804, -0.5336, -0.4840],\n",
      "          [ 0.6194, -0.1866,  0.5777,  ...,  1.4978, -0.3987, -1.0123],\n",
      "          ...,\n",
      "          [ 1.3470,  0.3720, -0.5412,  ...,  1.6907, -0.3261, -0.6066],\n",
      "          [ 1.6338, -0.9301,  0.1403,  ...,  1.6979,  0.9465, -1.1397],\n",
      "          [ 1.0263, -0.0312,  0.4805,  ...,  1.9947, -0.4926, -1.0369]],\n",
      "\n",
      "         [[ 0.8600, -2.0708,  0.1513,  ...,  0.2453, -2.4785, -0.4229],\n",
      "          [ 1.3937, -0.5899,  1.3122,  ...,  1.7829, -0.9209,  0.0461],\n",
      "          [ 1.2642,  1.6078,  0.4370,  ...,  0.8510,  0.5742, -0.4311],\n",
      "          ...,\n",
      "          [-0.2522,  3.1486, -0.0085,  ...,  0.1856,  3.6584, -0.8100],\n",
      "          [ 0.7939,  1.4203,  0.2039,  ...,  0.5636,  2.3544, -1.3126],\n",
      "          [ 0.5796,  1.1935, -0.4128,  ..., -0.0242,  2.9575, -1.5629]],\n",
      "\n",
      "         [[ 1.0033,  0.3818, -0.1770,  ..., -0.8112, -1.4041, -0.3646],\n",
      "          [-0.8060, -0.2143, -1.7062,  ...,  1.3577, -0.0913,  0.3456],\n",
      "          [-0.1113, -0.4196, -1.3489,  ...,  1.2174,  0.0079,  0.0536],\n",
      "          ...,\n",
      "          [-3.3497, -0.2660,  0.2152,  ...,  1.4347,  0.1310,  1.4777],\n",
      "          [-1.0710, -0.9403, -2.2382,  ...,  1.8840, -0.8573,  0.6312],\n",
      "          [ 0.1759, -0.5456, -0.7188,  ...,  1.3544, -0.2407, -0.2945]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2209, -0.5819,  0.4830,  ..., -0.6500,  1.0846,  0.2841],\n",
      "          [-0.4176, -0.2444, -0.1033,  ..., -1.9155, -1.5817,  0.6707],\n",
      "          [-1.1385,  1.7267, -2.5488,  ..., -2.3843, -1.3253,  0.6908],\n",
      "          ...,\n",
      "          [-1.5273,  1.4584, -2.7749,  ..., -1.0319, -2.3548,  1.2913],\n",
      "          [-0.4061,  2.5040, -2.4008,  ..., -1.3577, -1.8418,  1.6940],\n",
      "          [-0.3213,  0.4250, -1.2700,  ..., -3.8195, -0.4979,  1.6445]],\n",
      "\n",
      "         [[ 0.2557,  0.5515,  0.5423,  ...,  0.7245,  0.0758,  0.8386],\n",
      "          [ 0.0373,  1.1293, -0.8812,  ...,  1.3053,  0.1991,  1.0668],\n",
      "          [ 0.1955,  1.5928, -0.9004,  ...,  0.8965, -0.3034, -0.3748],\n",
      "          ...,\n",
      "          [-0.0899,  2.2438, -0.5928,  ...,  0.3604, -1.3797, -0.0256],\n",
      "          [ 1.0178,  2.0922, -0.1509,  ...,  1.3384, -1.0962, -0.1963],\n",
      "          [ 1.6399,  1.9349,  1.2059,  ..., -0.5345, -1.0859,  0.4052]],\n",
      "\n",
      "         [[-0.7103,  0.3011, -1.5822,  ..., -0.4242,  0.2360, -1.3157],\n",
      "          [ 0.0054,  1.0721,  1.2615,  ...,  0.6028, -0.2910,  0.4983],\n",
      "          [-0.3964,  0.6106, -0.1719,  ...,  1.1167, -0.9742,  1.4335],\n",
      "          ...,\n",
      "          [ 1.7506,  0.9744,  1.3645,  ...,  1.5455,  0.3070,  1.9734],\n",
      "          [-0.9912,  0.5391,  1.5399,  ...,  0.9224,  0.0180,  3.2051],\n",
      "          [-0.3301,  0.1262,  2.0273,  ...,  2.3883,  0.8853, -0.5951]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-6.0669e-03,  4.1580e-02, -6.0121e-02,  ...,  5.8650e-02,\n",
      "           -5.0545e-02, -7.4066e-02],\n",
      "          [-1.3468e+00,  1.2899e-01,  1.0814e+00,  ..., -3.7751e-01,\n",
      "           -3.3316e-01, -2.1959e-01],\n",
      "          [-5.5962e-01,  5.0996e-01,  1.2739e+00,  ..., -3.0219e-01,\n",
      "            1.1735e-01,  8.0562e-01],\n",
      "          ...,\n",
      "          [ 4.0354e-01, -1.3779e+00, -1.7089e-01,  ..., -7.0931e-01,\n",
      "           -1.5366e+00,  4.9889e-01],\n",
      "          [-1.0464e-01,  6.3718e-01,  1.1747e+00,  ...,  3.1930e-01,\n",
      "           -1.4733e+00,  2.9720e-01],\n",
      "          [ 4.8980e-01, -3.8611e-02,  1.0899e+00,  ...,  3.5262e-01,\n",
      "           -1.5532e+00, -7.8569e-01]],\n",
      "\n",
      "         [[ 5.0298e-02, -3.1198e-03,  2.3202e-02,  ..., -2.5890e-02,\n",
      "           -1.5499e-02, -2.3228e-02],\n",
      "          [-1.0113e+00,  5.7627e-01,  4.9574e-01,  ..., -3.2675e-01,\n",
      "            1.8657e-01,  8.2123e-01],\n",
      "          [ 1.4849e-01,  7.7403e-01, -1.0155e+00,  ...,  3.1667e-01,\n",
      "           -1.8597e-01,  4.8591e-01],\n",
      "          ...,\n",
      "          [-1.2798e-01, -5.1137e-01,  1.0950e+00,  ...,  3.6580e+00,\n",
      "            2.7942e-02, -6.0400e-01],\n",
      "          [ 5.0271e-01, -1.6136e+00, -1.8023e-01,  ..., -5.1402e-02,\n",
      "            9.7688e-01, -1.7705e-01],\n",
      "          [-5.7576e-01,  2.3451e-01, -5.6927e-02,  ...,  1.7268e-01,\n",
      "            5.6935e-02,  1.5519e+00]],\n",
      "\n",
      "         [[-2.1214e-02,  3.3352e-02, -8.7513e-02,  ..., -8.9314e-03,\n",
      "            3.0822e-02,  3.8786e-02],\n",
      "          [-5.2402e-01, -2.6213e-01, -2.3345e-01,  ...,  3.4806e-01,\n",
      "            1.7069e-01, -2.4676e-04],\n",
      "          [-4.9386e-01,  4.8865e-01, -4.3231e-01,  ...,  7.6064e-01,\n",
      "           -2.9904e-02,  1.8609e-01],\n",
      "          ...,\n",
      "          [-1.5463e-01,  3.1104e+00, -7.4308e-01,  ..., -2.0623e-01,\n",
      "           -7.7929e-01,  9.4195e-01],\n",
      "          [-7.9531e-01,  1.3734e+00, -4.3312e-01,  ..., -4.4867e-01,\n",
      "            1.8048e-01,  6.7477e-02],\n",
      "          [-7.1460e-01,  5.9888e-01,  1.0618e+00,  ...,  5.3553e-01,\n",
      "           -7.6815e-01, -2.0368e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0483e-01,  3.7457e-02, -1.1568e-03,  ..., -4.4700e-02,\n",
      "           -8.8917e-03,  1.7837e-02],\n",
      "          [ 8.6269e-01, -1.4697e-01,  3.6745e-01,  ...,  3.1546e-01,\n",
      "            3.5175e-02, -3.0443e-01],\n",
      "          [ 5.1551e-01,  2.5198e-01,  1.5730e-01,  ...,  1.4892e+00,\n",
      "           -5.0922e-01,  2.0167e+00],\n",
      "          ...,\n",
      "          [-8.4730e-01, -4.3078e-01,  5.2054e-01,  ..., -9.0685e-02,\n",
      "            2.3514e-01, -9.9466e-02],\n",
      "          [-6.5803e-01, -7.2872e-01, -3.5988e-02,  ...,  1.0229e+00,\n",
      "           -7.1774e-01,  9.4541e-01],\n",
      "          [-8.0607e-01, -7.0931e-01,  7.0981e-01,  ...,  9.3563e-02,\n",
      "           -8.5871e-01,  1.3432e-01]],\n",
      "\n",
      "         [[ 9.2671e-02,  1.3452e-02,  5.3226e-02,  ...,  3.1511e-03,\n",
      "            4.3145e-02,  1.1899e-02],\n",
      "          [-1.5642e-01,  1.9026e-01,  7.6595e-01,  ..., -1.3407e-01,\n",
      "            2.6676e-01, -5.0297e-01],\n",
      "          [ 6.1654e-01,  8.3766e-01,  1.0002e+00,  ...,  1.2987e-01,\n",
      "            1.4224e+00, -4.2694e-01],\n",
      "          ...,\n",
      "          [-3.0885e-02,  1.5424e+00,  6.3994e-01,  ..., -7.0803e-01,\n",
      "            2.7368e+00,  1.4347e+00],\n",
      "          [ 1.9045e-01,  2.8000e+00, -1.0230e+00,  ..., -9.5444e-02,\n",
      "            6.7177e-01,  5.6665e-02],\n",
      "          [-2.2475e-01,  9.7459e-01,  2.7916e+00,  ..., -2.6344e-01,\n",
      "            6.6847e-01, -1.8378e+00]],\n",
      "\n",
      "         [[-1.0774e-01,  2.8406e-02, -5.5795e-02,  ..., -8.4050e-02,\n",
      "            6.1122e-02, -6.3834e-03],\n",
      "          [ 2.9482e-01, -4.6036e-01, -5.0067e-01,  ..., -4.2501e-01,\n",
      "            1.4048e+00,  3.5766e-02],\n",
      "          [-7.1402e-01, -6.3282e-01, -6.3516e-01,  ..., -1.0530e+00,\n",
      "            4.5487e-01, -1.2223e+00],\n",
      "          ...,\n",
      "          [-3.1074e-01, -1.3114e-01,  6.1908e-01,  ..., -1.1282e+00,\n",
      "            9.6892e-01,  1.1984e-01],\n",
      "          [-9.2515e-01,  1.1405e-01,  1.4297e-01,  ...,  2.4873e-01,\n",
      "           -2.8435e-01,  3.1334e-01],\n",
      "          [-4.7070e-01, -2.1283e-01,  1.8143e-01,  ..., -6.6503e-01,\n",
      "           -9.3209e-01,  8.6370e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7151, -0.3351, -0.2937,  ...,  0.1779,  0.3182, -0.4845],\n",
      "          [-0.0573, -0.2968, -0.2792,  ...,  1.8097, -0.9933, -0.0485],\n",
      "          [ 0.4551,  0.2350, -0.5202,  ...,  1.4073, -1.1556, -0.5031],\n",
      "          ...,\n",
      "          [ 0.4398,  0.2872, -1.3292,  ...,  1.0791, -0.5067, -0.6926],\n",
      "          [ 1.4281,  0.7992, -0.5960,  ...,  0.2981, -0.7968, -0.0723],\n",
      "          [ 1.4787,  0.0107, -0.4716,  ...,  0.5184, -2.1060, -0.5924]],\n",
      "\n",
      "         [[ 0.1182, -0.0641,  2.3043,  ...,  0.2435,  0.0934, -0.1985],\n",
      "          [ 0.3078, -0.7078, -0.0229,  ..., -0.1684,  0.3255,  0.4997],\n",
      "          [-0.0072, -1.4351, -0.3262,  ..., -0.0116, -0.4237, -1.0236],\n",
      "          ...,\n",
      "          [ 0.0789,  1.0277, -0.1959,  ..., -0.3314, -0.0123,  0.1554],\n",
      "          [-0.1221, -0.4109, -0.2510,  ..., -0.1642,  0.4183, -1.1042],\n",
      "          [ 0.3249, -0.0160, -1.2672,  ...,  0.3571,  0.7415, -0.0222]],\n",
      "\n",
      "         [[-0.1897,  1.0560,  0.4685,  ..., -0.5601,  0.3216, -0.1095],\n",
      "          [-1.2898,  0.1961,  0.3851,  ...,  0.0611, -0.4468, -0.4500],\n",
      "          [-1.2418, -0.5390, -0.3550,  ...,  1.1175,  0.2285, -0.6764],\n",
      "          ...,\n",
      "          [-1.7289, -1.8670, -0.2395,  ...,  0.8597,  0.1823,  0.1264],\n",
      "          [-1.4579, -1.1564,  0.1421,  ...,  1.1056, -0.7289, -0.9327],\n",
      "          [-0.5909,  0.2044, -0.4299,  ...,  1.1715,  0.5954, -0.7546]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5702,  0.9629, -0.8822,  ..., -0.7408,  0.6916,  0.8577],\n",
      "          [ 1.1006,  1.7073, -1.6259,  ..., -0.9801, -0.5523,  0.2173],\n",
      "          [ 0.6847,  1.8472, -0.7955,  ..., -0.5540, -0.5932,  0.3027],\n",
      "          ...,\n",
      "          [-1.6889,  0.1444,  0.2351,  ..., -0.8126, -1.4681, -0.2635],\n",
      "          [ 0.2845,  1.1499, -0.4750,  ..., -0.8172, -0.8146,  0.3588],\n",
      "          [ 0.0874, -0.2214, -0.0856,  ..., -0.7394, -1.2066,  0.1715]],\n",
      "\n",
      "         [[-0.4207,  0.3802,  0.3173,  ...,  0.7072,  0.0623, -0.0753],\n",
      "          [-0.9885,  1.0626, -0.9565,  ..., -0.0961, -0.5346, -1.2537],\n",
      "          [-0.8144,  1.0409, -0.3393,  ...,  0.7575, -0.7873, -0.3033],\n",
      "          ...,\n",
      "          [ 0.7162,  0.5353,  0.5786,  ...,  1.2553, -0.3931,  0.5719],\n",
      "          [-0.4955,  0.3584, -0.4676,  ...,  0.7423, -0.1553,  0.4724],\n",
      "          [-1.1989,  0.5740, -1.4242,  ..., -0.1654, -0.2418, -1.2209]],\n",
      "\n",
      "         [[-0.7356, -0.0250,  0.4452,  ..., -0.0942,  0.0330, -0.0571],\n",
      "          [ 0.1039, -0.4520,  1.6473,  ...,  0.0384, -0.3122,  0.2989],\n",
      "          [ 0.0984, -1.1736,  1.5161,  ...,  0.2563, -0.7524, -0.1577],\n",
      "          ...,\n",
      "          [ 0.3700,  0.0524,  0.3323,  ..., -0.1997, -1.8872,  0.6791],\n",
      "          [ 0.1144, -0.8560,  1.3444,  ..., -0.9688, -0.0111,  0.6124],\n",
      "          [ 0.3719, -1.1888,  2.9866,  ...,  1.5564,  1.0569,  1.0004]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0627, -0.1041, -0.1861,  ..., -0.2973,  0.2617, -0.1300],\n",
      "          [ 0.9190, -0.4094,  0.9732,  ...,  0.7065, -1.3206,  1.6103],\n",
      "          [-0.3314,  0.7099,  0.8130,  ...,  1.2446, -1.0029,  1.6824],\n",
      "          ...,\n",
      "          [ 0.3073, -0.1798,  2.0175,  ...,  3.8588, -1.2389,  0.9518],\n",
      "          [-1.0282,  0.0810,  1.8490,  ...,  2.1276, -0.6254,  0.2580],\n",
      "          [-2.1301,  0.1848,  0.6389,  ...,  0.8497, -2.1894,  2.4372]],\n",
      "\n",
      "         [[ 0.0701, -0.0366,  0.0433,  ..., -0.0205, -0.1226,  0.1881],\n",
      "          [-0.4828,  0.0397,  0.1133,  ...,  0.6646, -0.4122, -0.4976],\n",
      "          [-0.0560,  0.5185, -0.3796,  ..., -0.0358, -1.7324, -0.5987],\n",
      "          ...,\n",
      "          [ 0.3621, -1.0770,  0.8416,  ..., -1.0863, -1.4621,  1.3165],\n",
      "          [-0.4170, -0.1856, -0.2208,  ...,  0.6679,  0.2648, -0.7330],\n",
      "          [ 0.9327,  0.1231, -0.2568,  ...,  0.0206, -0.5632, -0.0348]],\n",
      "\n",
      "         [[ 0.0102,  0.0407, -0.0427,  ...,  0.0176,  0.0324,  0.0545],\n",
      "          [-0.8474, -0.1339,  0.6198,  ..., -1.1320, -0.1028,  0.0237],\n",
      "          [-0.3179,  0.2617, -0.2293,  ..., -0.3102, -0.2109,  0.9155],\n",
      "          ...,\n",
      "          [-1.1459,  0.6247, -0.4677,  ...,  0.4716,  0.2258,  1.9537],\n",
      "          [ 0.3159, -0.4951,  0.3948,  ...,  0.0583,  0.3305,  2.0492],\n",
      "          [ 0.5957, -0.2422, -0.1601,  ...,  0.0871,  0.6242,  0.0631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0194, -0.0276,  0.0886,  ...,  0.0796, -0.0209,  0.0248],\n",
      "          [-0.7218,  0.9741,  0.7868,  ..., -0.1377, -0.3252, -1.0529],\n",
      "          [ 0.0102,  0.0130,  0.1943,  ...,  1.0051,  0.9481, -0.4571],\n",
      "          ...,\n",
      "          [-1.2697,  1.1965,  1.8222,  ...,  1.2815,  1.1525, -0.2608],\n",
      "          [-0.9059, -0.1876, -0.2131,  ...,  0.1001,  0.5176, -0.7554],\n",
      "          [-0.2481,  0.0416, -0.7926,  ...,  0.2645, -0.6107, -0.3649]],\n",
      "\n",
      "         [[-0.1515, -0.0920,  0.0492,  ..., -0.0616,  0.0336, -0.0914],\n",
      "          [ 0.1947,  0.3574,  0.4865,  ..., -0.0827, -0.0695,  0.1024],\n",
      "          [ 0.0617, -0.4696,  0.1419,  ..., -0.5913, -0.3143,  0.7776],\n",
      "          ...,\n",
      "          [-0.4784,  1.0185, -0.0705,  ...,  0.2748, -0.4973,  1.3698],\n",
      "          [-0.8326,  0.6881,  0.1242,  ..., -0.5708,  0.6708,  0.8386],\n",
      "          [-1.0543, -0.0815,  0.9794,  ...,  0.3561,  0.6065,  0.8012]],\n",
      "\n",
      "         [[ 0.1127, -0.1414,  0.0995,  ..., -0.1078,  0.0248, -0.1947],\n",
      "          [ 0.3453, -0.7535,  0.9195,  ...,  0.1146, -0.0401,  0.5830],\n",
      "          [-0.6160, -0.7786,  1.2499,  ..., -1.0763,  0.0126, -0.6472],\n",
      "          ...,\n",
      "          [-1.0815,  0.2212,  0.6810,  ..., -1.4694, -0.5813,  0.5124],\n",
      "          [-0.5673, -0.7975, -0.1831,  ...,  0.2839,  0.3034,  0.0535],\n",
      "          [-0.9700,  0.6698, -0.1582,  ...,  0.8679, -0.3234,  1.0039]]]],\n",
      "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1c173c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[[[-1.0719,  2.4170,  0.9660,  ..., -0.4787, -0.3316,  1.7925],\n",
      "          [-2.2897,  2.5424,  0.8317,  ..., -0.5299, -2.4828,  1.3537],\n",
      "          [-2.2856,  2.7125,  2.4725,  ..., -1.4911, -1.8427,  1.6493],\n",
      "          ...,\n",
      "          [-3.3203,  2.3325,  2.7061,  ..., -1.1569, -1.5586,  2.4076],\n",
      "          [-2.9917,  2.2701,  2.1742,  ..., -0.8670, -1.6410,  1.9237],\n",
      "          [-2.5066,  2.6140,  2.1347,  ..., -0.0627, -2.0542,  1.6568]],\n",
      "\n",
      "         [[ 0.4796, -0.1131, -1.4854,  ...,  1.1607,  1.8412,  1.3682],\n",
      "          [-0.7273, -1.1362, -1.0850,  ..., -0.6736,  3.2618,  0.2099],\n",
      "          [-1.4441, -3.0647, -4.1612,  ..., -1.4788,  3.2718, -0.2803],\n",
      "          ...,\n",
      "          [ 0.8515, -0.1599,  0.1157,  ..., -0.8959,  4.1178,  0.7133],\n",
      "          [-0.0769, -1.7673, -1.1207,  ..., -1.6276,  3.1095,  1.0237],\n",
      "          [-0.9118, -0.3267, -2.0409,  ..., -0.3527,  1.1626,  0.3733]],\n",
      "\n",
      "         [[-0.2338, -0.8688,  1.6542,  ..., -1.5964, -1.5636,  1.0931],\n",
      "          [ 0.3698,  0.4929,  1.4155,  ..., -2.0162, -1.0246,  1.9822],\n",
      "          [ 0.4509,  1.0144,  0.1189,  ..., -3.1880,  0.4529,  1.3746],\n",
      "          ...,\n",
      "          [ 0.3303,  0.8695, -0.6507,  ..., -2.7196,  0.2950,  1.9827],\n",
      "          [ 0.5777,  0.4363,  1.1029,  ..., -3.2317,  0.9627,  2.1703],\n",
      "          [-0.2861, -0.2032,  0.7289,  ..., -2.3039,  1.2637,  1.9519]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4012, -0.0278, -0.1031,  ...,  0.2614,  0.9767,  0.5994],\n",
      "          [ 0.2222,  0.3167, -0.2024,  ...,  0.9616,  0.3658,  1.0162],\n",
      "          [ 0.3276,  0.0629,  0.1905,  ...,  1.0855,  0.8707,  0.0940],\n",
      "          ...,\n",
      "          [ 0.2403, -0.0951,  0.1646,  ...,  0.3345,  0.2687,  0.2159],\n",
      "          [ 0.2873,  0.0887, -0.0544,  ...,  1.0306,  0.3196,  0.5268],\n",
      "          [-0.0552, -0.0461,  0.0765,  ...,  1.0465,  0.2690,  0.4687]],\n",
      "\n",
      "         [[ 0.9759,  1.3121, -0.6612,  ..., -0.3228,  1.1476, -1.2349],\n",
      "          [ 1.0862,  0.3406, -0.6767,  ..., -1.0748,  1.4611,  0.6789],\n",
      "          [ 0.6566,  0.1325, -0.5036,  ..., -1.9292,  1.4180,  0.0719],\n",
      "          ...,\n",
      "          [ 1.1746, -0.0249, -1.0666,  ..., -0.9283,  1.2044, -0.7485],\n",
      "          [ 1.2952,  0.0145, -0.4903,  ..., -1.0618,  0.9241,  0.0928],\n",
      "          [ 0.9810,  0.0274, -0.2624,  ..., -0.8447,  0.3484, -0.2251]],\n",
      "\n",
      "         [[ 0.6922,  0.4421,  0.2786,  ..., -0.2213,  0.2488,  1.8778],\n",
      "          [-0.1203, -0.2795, -0.0287,  ..., -0.2255,  0.5681,  1.2821],\n",
      "          [ 0.3923,  0.6569,  0.0967,  ..., -0.0928,  0.2676,  2.2244],\n",
      "          ...,\n",
      "          [ 0.4983, -0.2781,  0.9789,  ...,  0.5424,  1.0169,  1.1159],\n",
      "          [-0.8550,  0.5215, -0.2168,  ..., -0.1893,  0.9473,  0.7673],\n",
      "          [-0.9623,  0.1968,  1.1720,  ..., -0.4878,  0.9685, -0.6823]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.5844e-02,  4.5047e-02, -3.2349e-02,  ...,  1.1302e-01,\n",
      "            3.4111e-03, -7.3823e-02],\n",
      "          [ 2.4216e-02, -2.3168e-01,  7.9895e-02,  ..., -3.9604e-02,\n",
      "            1.3466e-01, -8.8950e-02],\n",
      "          [ 1.3182e-01,  4.2661e-02,  7.7161e-03,  ...,  1.1645e-01,\n",
      "            1.4362e-01, -3.0297e-02],\n",
      "          ...,\n",
      "          [ 5.1271e-02, -1.0683e-02,  1.3832e-01,  ...,  4.6392e-02,\n",
      "           -7.1929e-02,  3.3192e-01],\n",
      "          [ 4.0427e-02,  3.1326e-02,  7.5804e-03,  ...,  6.6739e-02,\n",
      "           -9.5121e-02,  2.2703e-02],\n",
      "          [-2.5431e-01,  9.7892e-02, -3.1401e-01,  ..., -5.9719e-02,\n",
      "            8.7119e-02, -1.5292e-01]],\n",
      "\n",
      "         [[ 4.6511e-01,  2.9299e-01, -2.6004e-01,  ..., -4.8896e-01,\n",
      "           -3.9832e-01,  5.1992e-02],\n",
      "          [ 3.6216e-01, -2.1008e-01,  2.3111e-01,  ...,  1.2695e-02,\n",
      "           -9.8509e-03, -1.9051e-01],\n",
      "          [ 5.0594e-01, -2.8700e-01, -3.7256e-02,  ...,  1.3379e-01,\n",
      "            1.4818e-01, -7.0381e-02],\n",
      "          ...,\n",
      "          [ 4.5519e-01,  2.2482e-01,  2.7037e-02,  ..., -7.6202e-02,\n",
      "            1.3018e-01,  1.1114e-01],\n",
      "          [ 4.3946e-01,  5.6358e-02, -2.8075e-01,  ...,  3.8331e-02,\n",
      "            2.8041e-01, -1.0264e-01],\n",
      "          [ 5.5593e-01, -7.1407e-02,  8.1585e-03,  ...,  7.4966e-02,\n",
      "            5.5887e-01, -1.0753e-01]],\n",
      "\n",
      "         [[-3.5264e-02,  5.7019e-02, -7.3887e-02,  ..., -1.2185e-02,\n",
      "           -8.9059e-02, -1.0759e-01],\n",
      "          [-1.4517e-01, -1.1093e-01, -3.1237e-01,  ...,  7.9633e-03,\n",
      "            1.0515e-01, -6.8206e-02],\n",
      "          [-2.9723e-01, -1.0871e-01, -3.7647e-01,  ..., -4.4998e-01,\n",
      "           -3.9353e-01, -5.8729e-02],\n",
      "          ...,\n",
      "          [ 3.6986e-01,  3.6383e-01,  8.8384e-02,  ..., -2.8474e-01,\n",
      "           -2.1211e-01, -4.2789e-01],\n",
      "          [ 5.1485e-01,  1.4955e-02,  1.9848e-01,  ...,  1.8763e-03,\n",
      "           -4.4840e-02, -1.9523e-01],\n",
      "          [-3.1557e-01, -7.7205e-02,  1.2237e-01,  ..., -9.9081e-03,\n",
      "           -9.1467e-02, -1.1786e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6929e-01, -1.6863e-01, -1.3075e-01,  ..., -4.5507e-02,\n",
      "            1.6489e-02, -4.9244e-03],\n",
      "          [-1.8289e-01, -7.3011e-02,  8.9083e-02,  ...,  2.8579e-01,\n",
      "            1.6520e-01,  3.9901e-01],\n",
      "          [ 1.8149e-02,  1.4864e-01,  1.3995e-01,  ..., -2.0186e-01,\n",
      "           -3.1164e-01,  1.8832e-01],\n",
      "          ...,\n",
      "          [ 1.8829e-01,  3.7086e-01,  2.2190e-02,  ..., -4.3816e-01,\n",
      "           -4.5873e-02, -2.3247e-01],\n",
      "          [-6.9325e-02,  2.2089e-01, -5.2158e-02,  ..., -5.8077e-05,\n",
      "           -4.4377e-02, -2.3630e-02],\n",
      "          [-1.4491e-01, -7.6687e-01, -1.0080e-02,  ...,  1.4490e-01,\n",
      "           -1.4273e-01,  1.1995e-02]],\n",
      "\n",
      "         [[ 1.1663e-01, -9.5174e-02, -8.0097e-02,  ...,  1.1799e-01,\n",
      "            1.4442e-01,  8.0563e-02],\n",
      "          [-4.0979e-01,  1.7985e-01,  6.2053e-02,  ..., -4.6011e-01,\n",
      "           -1.5909e-01,  1.6538e-01],\n",
      "          [ 1.0707e-01, -1.4439e-01, -3.8615e-02,  ..., -3.1468e-01,\n",
      "           -1.1422e-01,  1.1694e-01],\n",
      "          ...,\n",
      "          [-8.9047e-02, -5.7536e-02, -1.4755e-01,  ..., -4.0699e-01,\n",
      "           -1.5711e-01, -2.4647e-01],\n",
      "          [-5.0915e-02,  8.4827e-02,  5.0269e-02,  ..., -2.7516e-02,\n",
      "           -2.4682e-01, -1.2400e-01],\n",
      "          [-4.0786e-02, -6.3005e-02, -5.9178e-02,  ...,  1.9072e-01,\n",
      "            2.5695e-01,  1.3483e-01]],\n",
      "\n",
      "         [[-1.4032e-01, -2.1724e-01,  2.1163e-01,  ...,  1.1325e-02,\n",
      "           -1.6940e-01, -5.6700e-02],\n",
      "          [ 1.6501e-01,  1.4751e-01,  1.2316e-01,  ...,  5.2810e-01,\n",
      "            3.7520e-01,  5.6596e-02],\n",
      "          [-1.6167e-01, -9.5173e-02, -3.0007e-01,  ..., -1.3899e-01,\n",
      "            7.6265e-02,  1.5000e-01],\n",
      "          ...,\n",
      "          [ 1.9036e-02, -4.1325e-01, -5.3456e-02,  ...,  1.0850e-01,\n",
      "            3.1322e-01,  7.4104e-02],\n",
      "          [ 4.7433e-02,  8.3881e-02, -5.8630e-02,  ...,  5.6656e-02,\n",
      "           -1.4553e-01,  1.3967e-01],\n",
      "          [ 1.1568e-01, -1.1512e-01, -3.7184e-02,  ...,  9.3072e-02,\n",
      "            9.4981e-02,  5.2496e-03]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3234e-01,  1.7469e+00, -1.3506e+00,  ...,  1.3035e+00,\n",
      "           -1.1436e+00,  1.3027e+00],\n",
      "          [ 3.7144e-01,  1.5962e+00, -9.8959e-01,  ..., -3.7702e-01,\n",
      "           -1.6238e+00,  4.9728e-01],\n",
      "          [ 1.5475e+00,  1.7371e+00, -1.1542e+00,  ...,  2.6363e-02,\n",
      "           -2.4185e+00,  6.0650e-02],\n",
      "          ...,\n",
      "          [ 1.1640e+00,  2.7594e-01, -3.8811e-01,  ...,  9.9817e-01,\n",
      "           -2.4461e-01, -2.2513e+00],\n",
      "          [ 9.1530e-02,  1.3589e+00,  5.4383e-02,  ...,  9.0260e-01,\n",
      "           -2.1145e+00, -1.0515e+00],\n",
      "          [-2.3758e-01,  4.2933e-01,  2.5328e-01,  ...,  6.8149e-01,\n",
      "           -7.0189e-01, -1.3681e-01]],\n",
      "\n",
      "         [[-1.4716e+00, -7.0062e-01, -8.4053e-01,  ..., -3.4795e-01,\n",
      "            9.0868e-01, -5.7943e-01],\n",
      "          [-6.7887e-01, -8.5541e-01, -1.9801e+00,  ..., -1.3131e+00,\n",
      "           -2.7207e-01,  1.9432e-01],\n",
      "          [-8.6449e-01,  1.6246e-02, -1.5927e+00,  ..., -1.5577e-01,\n",
      "            4.3638e-01,  3.4525e-01],\n",
      "          ...,\n",
      "          [-8.9806e-01,  3.8958e-01, -1.8324e+00,  ..., -3.9667e-01,\n",
      "           -9.1773e-01, -5.6276e-01],\n",
      "          [-5.7540e-01,  9.9297e-01, -1.6385e+00,  ..., -2.2806e-01,\n",
      "            3.7440e-01, -1.2218e+00],\n",
      "          [-5.3996e-01,  1.2337e+00, -1.4777e+00,  ..., -1.9484e-01,\n",
      "           -7.1104e-01, -6.1031e-01]],\n",
      "\n",
      "         [[ 3.3298e-01,  1.1988e-01, -2.9469e-02,  ..., -1.2560e+00,\n",
      "            1.5321e-01, -2.1866e-01],\n",
      "          [ 3.3311e-01,  6.0987e-01, -3.2191e-01,  ..., -1.2439e+00,\n",
      "           -7.9251e-02,  7.9440e-02],\n",
      "          [-1.3959e-01,  2.9871e-01, -1.1090e-01,  ..., -8.7817e-01,\n",
      "           -2.1968e-01,  5.7344e-01],\n",
      "          ...,\n",
      "          [-1.1917e-01, -1.2050e-01,  8.8956e-02,  ..., -1.0531e+00,\n",
      "            2.7097e-01,  2.8109e-01],\n",
      "          [-1.6320e-01, -2.1190e-01, -2.8066e-01,  ..., -1.1110e+00,\n",
      "           -1.1413e-01,  3.4103e-01],\n",
      "          [-1.9088e-01, -2.2637e-01, -1.9520e-01,  ..., -1.3609e+00,\n",
      "            7.7478e-03,  5.4753e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1961e-01, -5.4149e-01, -6.5129e-01,  ..., -1.3049e-01,\n",
      "            6.4293e-01, -1.0648e+00],\n",
      "          [-1.1139e+00,  1.7472e+00,  1.9236e+00,  ..., -5.2888e-01,\n",
      "           -8.8113e-01, -1.1274e+00],\n",
      "          [-3.5029e-02,  1.6498e+00,  1.5704e+00,  ...,  1.8705e+00,\n",
      "            4.4842e-01,  1.7473e-01],\n",
      "          ...,\n",
      "          [ 2.8044e-02,  1.5038e+00,  1.7172e+00,  ..., -1.5435e-01,\n",
      "           -7.6511e-01, -8.1489e-01],\n",
      "          [-6.5315e-01,  1.2453e+00,  1.9217e+00,  ...,  6.9396e-01,\n",
      "           -1.3474e+00, -1.1424e+00],\n",
      "          [-4.9458e-01,  1.4317e+00,  1.6529e+00,  ...,  5.9429e-01,\n",
      "           -1.7269e+00, -3.5413e-01]],\n",
      "\n",
      "         [[-1.2016e+00, -2.7812e+00,  1.2903e-01,  ...,  1.6795e+00,\n",
      "            1.5993e+00, -1.5680e+00],\n",
      "          [-2.4824e-01,  9.6243e-01, -6.0818e-01,  ..., -6.4028e-01,\n",
      "            7.3015e-01,  1.6933e-03],\n",
      "          [ 3.7342e-01,  7.0263e-01, -5.0011e-01,  ..., -6.0883e-01,\n",
      "            4.8429e-01, -9.1718e-02],\n",
      "          ...,\n",
      "          [-2.1023e-01, -1.1352e-01, -8.6533e-01,  ..., -4.3357e-01,\n",
      "            1.0432e+00,  2.3951e-01],\n",
      "          [-3.5406e-01,  3.6508e-01, -7.0875e-01,  ..., -1.5285e-01,\n",
      "            9.8004e-01,  3.0699e-01],\n",
      "          [-3.1061e-01,  2.6206e-01, -7.0317e-01,  ..., -3.8614e-01,\n",
      "            7.4612e-01, -1.0789e-01]],\n",
      "\n",
      "         [[ 1.2471e+00,  1.8337e+00,  1.4891e+00,  ..., -2.7984e-01,\n",
      "            8.3699e-02, -4.6373e-01],\n",
      "          [-7.5646e-03,  2.5955e+00,  5.7040e-01,  ...,  1.0415e+00,\n",
      "           -1.6044e-01, -3.6244e-01],\n",
      "          [ 7.7531e-02,  2.8104e+00,  1.5624e+00,  ...,  1.5091e+00,\n",
      "           -1.8090e-02, -1.2300e+00],\n",
      "          ...,\n",
      "          [-4.7830e-01,  2.4190e+00,  2.3556e+00,  ...,  1.7733e+00,\n",
      "           -1.6757e+00, -2.5219e+00],\n",
      "          [ 9.0539e-02,  3.3119e+00, -3.6678e-01,  ...,  2.4436e+00,\n",
      "           -1.6148e+00, -2.1822e+00],\n",
      "          [ 5.6891e-01,  1.7215e+00,  7.9348e-01,  ..., -6.3631e-01,\n",
      "           -4.2486e-01,  1.1763e-02]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 1.8121e-01, -1.3411e-01, -2.1478e-01,  ...,  7.0410e-02,\n",
      "            2.1432e-01, -4.1736e-01],\n",
      "          [-3.4722e-01, -2.4165e-01, -3.5845e-01,  ..., -4.0396e-03,\n",
      "            6.8928e-01,  6.3408e-01],\n",
      "          [ 1.8921e-01,  1.1412e-01, -3.7454e-01,  ..., -6.1886e-01,\n",
      "            1.5584e-01, -3.3977e-01],\n",
      "          ...,\n",
      "          [-9.8094e-01, -3.1039e-01, -4.3409e-02,  ...,  8.2431e-01,\n",
      "            1.2980e-02,  3.8811e-03],\n",
      "          [ 3.3090e-01, -8.1123e-02,  1.0761e-01,  ..., -2.8871e-01,\n",
      "            4.1475e-01,  4.9912e-01],\n",
      "          [ 6.5354e-01,  1.7933e-01,  9.7152e-02,  ..., -9.8650e-02,\n",
      "           -1.9800e-01, -7.1576e-02]],\n",
      "\n",
      "         [[-1.2948e-01, -1.3113e-01,  3.0471e-01,  ..., -9.5208e-02,\n",
      "           -5.2637e-01,  2.0390e-02],\n",
      "          [-5.2768e-01, -2.4699e-01, -1.2828e-01,  ..., -1.3858e-01,\n",
      "            1.6376e-01,  3.1491e-01],\n",
      "          [ 3.4299e-02,  2.9798e-01, -1.8136e-01,  ...,  3.7112e-01,\n",
      "           -1.1525e-02, -2.1673e-01],\n",
      "          ...,\n",
      "          [-8.4666e-03, -1.8613e-01,  2.7562e-01,  ...,  4.4664e-01,\n",
      "           -1.5165e-01, -5.9345e-01],\n",
      "          [ 2.7736e-01, -5.3698e-01,  1.0314e+00,  ...,  1.0592e-01,\n",
      "           -1.0284e-01, -2.0281e-01],\n",
      "          [ 3.6434e-01, -1.9135e-02,  1.0105e-01,  ...,  1.8952e-01,\n",
      "            2.6101e-01, -4.4438e-02]],\n",
      "\n",
      "         [[ 4.5340e-02, -4.0817e-01,  5.3539e-02,  ..., -4.7963e-01,\n",
      "           -2.8298e-01,  2.7899e-02],\n",
      "          [ 8.4529e-01,  9.4444e-02,  2.4181e-02,  ..., -7.5536e-01,\n",
      "           -4.6340e-02,  1.8064e-01],\n",
      "          [ 8.0320e-01,  1.4924e-01,  5.8457e-01,  ..., -8.3811e-01,\n",
      "            1.0063e-01,  2.5599e-01],\n",
      "          ...,\n",
      "          [ 9.6557e-01, -9.7738e-02,  2.9158e-02,  ..., -3.4948e-01,\n",
      "            1.6999e-01, -1.4430e-01],\n",
      "          [ 8.1042e-01, -2.8220e-02, -1.2203e-01,  ..., -3.2469e-01,\n",
      "           -2.2869e-01,  4.6458e-01],\n",
      "          [ 4.8326e-01,  1.9731e-01,  2.5365e-01,  ..., -9.5573e-02,\n",
      "           -1.1013e-01, -3.0431e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4653e-01,  6.2398e-01, -1.6506e-01,  ...,  1.2628e-01,\n",
      "           -9.4077e-01, -1.0024e-01],\n",
      "          [ 8.5481e-02, -3.7416e-01,  6.1154e-02,  ...,  2.1396e-01,\n",
      "           -6.8561e-01, -1.3296e-01],\n",
      "          [-2.7189e-01,  7.6011e-02,  5.0749e-01,  ...,  6.4782e-02,\n",
      "           -6.3529e-01, -3.4742e-01],\n",
      "          ...,\n",
      "          [-1.5075e-01,  1.6193e-01,  4.4225e-01,  ...,  5.5478e-01,\n",
      "            9.6686e-02,  1.3932e-02],\n",
      "          [ 2.9651e-02, -3.2289e-01, -3.7855e-01,  ...,  2.1001e-01,\n",
      "           -5.2798e-01,  7.2306e-01],\n",
      "          [ 5.7424e-02, -8.9264e-01,  3.6512e-01,  ...,  2.4724e-01,\n",
      "           -7.7394e-01, -2.8834e-01]],\n",
      "\n",
      "         [[ 1.9841e-01, -1.6214e-01,  8.8751e-02,  ...,  3.8060e-01,\n",
      "           -3.5175e+00, -4.8737e-02],\n",
      "          [ 4.8521e-02, -4.2689e-01,  2.9562e-03,  ...,  4.1736e-01,\n",
      "            3.3646e-02, -1.3576e-01],\n",
      "          [-2.3386e-01,  4.3437e-02,  1.9538e-01,  ...,  2.6902e-02,\n",
      "            7.1384e-02,  8.4704e-02],\n",
      "          ...,\n",
      "          [-1.4847e-03,  1.7191e-01, -5.1814e-01,  ...,  2.2445e-01,\n",
      "           -1.5839e-01,  1.5118e-01],\n",
      "          [ 1.7462e-02, -2.2361e-03,  4.6600e-01,  ...,  6.4923e-02,\n",
      "            3.4853e-02,  1.8072e-01],\n",
      "          [ 4.1400e-01,  1.7019e-01,  2.7337e-02,  ...,  1.4136e-01,\n",
      "           -1.5423e-01,  7.8442e-02]],\n",
      "\n",
      "         [[-5.0851e-02, -5.9927e-02, -5.6215e-02,  ..., -2.0252e-01,\n",
      "            1.2368e-01, -3.3855e-02],\n",
      "          [-1.1510e-02, -7.6934e-02,  2.3691e-01,  ...,  6.5874e-02,\n",
      "            1.5217e-02,  1.8671e-01],\n",
      "          [ 1.5296e-01, -1.3156e-01,  1.3923e-01,  ...,  1.8831e-01,\n",
      "           -8.2086e-02,  1.2744e-01],\n",
      "          ...,\n",
      "          [ 3.9660e-02,  2.4684e-01,  1.9528e-01,  ..., -9.5808e-02,\n",
      "            1.7549e-01, -6.6851e-03],\n",
      "          [ 8.3237e-02,  1.1592e-01, -5.2513e-02,  ..., -3.2532e-02,\n",
      "            2.5978e-01,  1.4565e-01],\n",
      "          [ 1.2383e-01, -1.1883e-02,  5.0095e-01,  ..., -1.0736e-02,\n",
      "            1.1066e-01,  1.8190e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1322, -1.1527,  0.3087,  ..., -0.6205, -0.1060, -0.0181],\n",
      "          [ 0.5456, -2.5518, -0.2942,  ..., -1.2907,  0.0803,  0.1253],\n",
      "          [ 0.9459, -2.5900,  0.3366,  ...,  0.2387,  0.0244, -0.0984],\n",
      "          ...,\n",
      "          [-1.4713, -1.8862, -0.5822,  ..., -0.4205, -0.2317, -0.3811],\n",
      "          [-0.4795, -1.7547,  0.5800,  ...,  1.0587,  0.7753, -1.0023],\n",
      "          [-0.2153, -2.2462, -0.5551,  ...,  1.7418,  0.0601, -0.8750]],\n",
      "\n",
      "         [[-0.4981,  0.4839, -0.4288,  ...,  1.2952, -0.4981, -0.4568],\n",
      "          [-1.4536, -0.2465, -0.9163,  ...,  0.4530,  0.6458,  0.4874],\n",
      "          [-1.6652, -0.9680, -1.0875,  ..., -0.0277,  1.3271, -0.3510],\n",
      "          ...,\n",
      "          [-2.1762, -0.6636, -1.8135,  ..., -0.9017,  1.3285,  0.1540],\n",
      "          [-1.3590, -1.9787, -1.5488,  ..., -1.1410,  1.3344, -0.2104],\n",
      "          [-1.4276, -0.6944, -0.5667,  ...,  1.1990,  0.8454, -0.3241]],\n",
      "\n",
      "         [[ 1.3747,  3.0648,  3.7658,  ...,  0.6805,  1.6251, -0.7113],\n",
      "          [-3.6194,  2.6739, -2.5109,  ..., -3.2047,  2.9450, -0.3144],\n",
      "          [-3.1928,  1.5469, -3.1628,  ..., -2.9214,  3.4801,  1.2360],\n",
      "          ...,\n",
      "          [-4.6832, -1.4904, -4.8171,  ..., -3.4247,  1.8220,  0.7462],\n",
      "          [-4.9916, -1.4019, -5.5591,  ..., -3.7371,  2.9422,  0.6384],\n",
      "          [-3.3272, -1.9141, -4.6821,  ..., -3.4394,  3.4462,  0.7966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3571, -2.6940, -2.5864,  ...,  0.9747,  0.4724,  2.7245],\n",
      "          [-3.2790,  1.4895,  0.4607,  ...,  0.6635, -1.8444, -0.3443],\n",
      "          [-3.4600,  2.6956,  1.3558,  ..., -0.1266, -2.7145,  0.0972],\n",
      "          ...,\n",
      "          [-3.1993,  4.0702,  1.9383,  ..., -0.9552, -3.1067, -1.4688],\n",
      "          [-3.8521,  4.6710,  2.9112,  ..., -2.2364, -3.9045, -1.5241],\n",
      "          [-3.5332,  4.3554,  2.3162,  ..., -0.6138, -2.1636, -1.3958]],\n",
      "\n",
      "         [[ 1.7131,  0.4496,  0.9466,  ...,  0.0104, -0.9866, -0.3256],\n",
      "          [ 2.1683,  0.8876,  1.4803,  ...,  0.1768, -1.8011, -1.9908],\n",
      "          [ 2.0806,  1.0288,  1.1972,  ..., -0.0733, -1.5057, -1.4346],\n",
      "          ...,\n",
      "          [ 1.9361,  0.8342,  1.0479,  ..., -0.0835, -1.9249, -1.2110],\n",
      "          [ 2.2447,  0.3010,  1.0368,  ..., -0.2990, -1.8205, -1.2766],\n",
      "          [ 1.7111,  0.2756,  0.7408,  ...,  0.0539, -1.9953, -0.9998]],\n",
      "\n",
      "         [[-0.2538,  0.1160, -0.5586,  ...,  0.2681,  0.2844,  0.1296],\n",
      "          [-0.2222,  0.8479, -0.4422,  ..., -0.2732,  0.8777,  0.8108],\n",
      "          [-0.6727,  0.5071,  0.0572,  ...,  0.0786,  0.3229,  0.3834],\n",
      "          ...,\n",
      "          [ 0.2167, -0.1937, -1.1421,  ..., -0.4700,  0.8094, -0.1040],\n",
      "          [-0.4399,  0.3740,  0.0801,  ..., -0.2625,  0.2348, -0.2820],\n",
      "          [-0.7647, -0.3623, -0.5461,  ...,  0.6692,  0.6866,  0.8584]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-2.6110e-02, -6.3370e-03, -1.2897e-01,  ..., -2.7515e-02,\n",
      "            3.0886e-02, -5.4642e-01],\n",
      "          [ 2.8421e-01, -8.6539e-01, -2.9025e-01,  ...,  2.3311e-01,\n",
      "           -8.4891e-01,  1.3338e+00],\n",
      "          [ 2.4186e-01, -2.5358e-01, -8.4709e-01,  ..., -4.7114e-01,\n",
      "           -4.3807e-01,  8.2508e-01],\n",
      "          ...,\n",
      "          [ 5.8147e-01, -8.3756e-01,  1.4187e-02,  ...,  6.5366e-01,\n",
      "            3.2311e-01,  1.0884e+00],\n",
      "          [ 2.4318e-02, -4.3096e-01, -1.3149e-01,  ..., -2.2943e-01,\n",
      "            4.7279e-01,  6.5808e-01],\n",
      "          [ 1.6472e-01,  1.1389e+00, -1.3656e+00,  ...,  3.6690e-01,\n",
      "            5.6864e-01, -9.9857e-01]],\n",
      "\n",
      "         [[ 3.3488e-02, -2.1709e-02,  3.1775e-02,  ..., -3.6363e-02,\n",
      "           -2.0804e-02,  7.0153e-02],\n",
      "          [-2.9799e-02,  6.2118e-01, -3.6438e-01,  ...,  4.9335e-02,\n",
      "           -1.8000e-01,  3.8404e-01],\n",
      "          [-4.7976e-01,  1.9054e-02, -1.4230e+00,  ..., -4.2935e-01,\n",
      "            4.5856e-01,  1.0601e-01],\n",
      "          ...,\n",
      "          [-1.1260e+00, -6.7430e-02, -1.2505e+00,  ...,  9.8989e-01,\n",
      "            2.0997e-01,  6.6872e-01],\n",
      "          [-3.0780e-01, -2.7036e-02,  7.3606e-01,  ..., -1.8043e-01,\n",
      "           -6.6421e-02, -4.7701e-01],\n",
      "          [-5.7836e-02, -1.4135e-02,  2.8287e-01,  ..., -1.8417e-01,\n",
      "           -1.4725e-01,  1.0323e-01]],\n",
      "\n",
      "         [[ 6.9997e-03, -7.2047e-01, -1.4875e-02,  ...,  5.4531e-02,\n",
      "            3.6829e-02, -1.3042e-02],\n",
      "          [ 7.3096e-01, -1.3004e+00,  2.5491e-02,  ..., -2.0688e-01,\n",
      "            2.1388e-01, -1.9886e-01],\n",
      "          [-5.9057e-01, -1.3042e+00,  1.9017e-01,  ..., -1.8207e-01,\n",
      "           -3.5320e-03,  3.4668e-01],\n",
      "          ...,\n",
      "          [ 4.1662e-01, -4.3040e-01,  4.1711e-01,  ..., -7.3938e-01,\n",
      "           -1.8402e-01, -3.6389e-01],\n",
      "          [-1.5218e-02, -1.5639e+00, -5.2417e-01,  ..., -2.4254e-01,\n",
      "           -2.1577e-01,  3.0141e-01],\n",
      "          [ 1.0562e-01, -1.4539e+00, -1.0584e-01,  ..., -1.0705e-01,\n",
      "            3.9389e-02, -1.4812e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0108e-02, -5.6756e-02,  1.3052e+00,  ...,  1.0925e-03,\n",
      "            1.9278e-01, -2.0602e-03],\n",
      "          [-2.6232e-02,  3.2866e-01,  1.9221e+00,  ...,  1.4766e-01,\n",
      "           -6.7259e-02,  2.4187e-01],\n",
      "          [-4.8278e-01, -4.2951e-01,  1.8054e+00,  ...,  3.6253e-01,\n",
      "           -3.1257e-01,  3.7770e-01],\n",
      "          ...,\n",
      "          [-1.0864e+00, -7.8481e-01,  2.2155e+00,  ..., -2.1905e-01,\n",
      "            1.4895e-01,  3.9424e-02],\n",
      "          [ 1.1841e-01, -5.9558e-01,  1.9721e+00,  ...,  4.6364e-01,\n",
      "           -2.0958e-01,  1.8704e-01],\n",
      "          [ 8.8032e-02, -3.0378e-01,  2.5235e+00,  ..., -1.3628e-01,\n",
      "            2.6798e-01,  3.4488e-01]],\n",
      "\n",
      "         [[-1.5290e-02, -6.3416e-02, -1.4310e-01,  ...,  1.6105e-01,\n",
      "            1.1368e-01,  1.8954e-01],\n",
      "          [-9.1473e-01,  2.2297e-01,  1.4207e-01,  ...,  3.7582e-02,\n",
      "           -3.2340e-01, -1.5199e-01],\n",
      "          [ 3.7227e-01, -4.9001e-01,  1.7333e-01,  ..., -1.4885e-01,\n",
      "           -6.3321e-01, -2.0094e-01],\n",
      "          ...,\n",
      "          [-4.8509e-01,  2.7552e-01,  4.1076e-01,  ...,  7.9583e-02,\n",
      "           -1.2452e-02, -6.0336e-01],\n",
      "          [ 1.9530e-01,  2.1733e-01,  3.4654e-01,  ...,  3.8038e-01,\n",
      "           -1.0907e+00, -8.6067e-02],\n",
      "          [ 6.8279e-01,  6.9183e-01,  2.1597e-01,  ...,  2.1290e-01,\n",
      "           -1.1599e-01,  4.2206e-01]],\n",
      "\n",
      "         [[ 2.3022e-02,  2.4736e-02,  1.4599e-02,  ..., -1.3392e-02,\n",
      "            2.2758e-01, -6.3206e-03],\n",
      "          [ 4.9218e-02,  5.3240e-01,  9.0467e-01,  ...,  1.1255e-01,\n",
      "           -2.0287e+00,  9.8514e-01],\n",
      "          [-4.7997e-01, -7.5514e-02, -1.9737e-01,  ..., -6.4949e-02,\n",
      "           -1.9641e+00,  1.0550e-01],\n",
      "          ...,\n",
      "          [ 5.7662e-01,  1.3777e-01,  3.1310e-02,  ...,  1.8253e-01,\n",
      "           -2.1296e+00, -1.7676e-01],\n",
      "          [ 2.4730e-01,  8.7524e-02, -3.3989e-01,  ...,  8.7951e-02,\n",
      "           -2.2735e+00, -1.8762e-01],\n",
      "          [ 3.9984e-01, -2.0190e-01,  1.6420e-02,  ..., -2.5319e-01,\n",
      "           -1.3256e+00, -2.3872e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.1605e-03, -1.8791e-01,  1.4746e-01,  ..., -8.8068e-01,\n",
      "            7.5894e-01, -1.1973e+00],\n",
      "          [-2.5677e+00,  1.7679e+00, -3.9106e+00,  ...,  1.2833e+00,\n",
      "           -1.2259e+00,  2.1156e+00],\n",
      "          [-1.6822e+00, -3.9114e-01, -1.4672e+00,  ..., -1.2825e-01,\n",
      "            5.9892e-01,  4.3526e-01],\n",
      "          ...,\n",
      "          [-1.5596e+00, -3.2881e-02,  6.3978e-01,  ...,  1.7795e+00,\n",
      "           -1.6521e+00,  2.0406e+00],\n",
      "          [-6.5270e-01, -5.5162e-01,  1.0236e+00,  ..., -5.6010e-01,\n",
      "           -1.9103e+00,  1.2966e+00],\n",
      "          [-1.0920e-01, -8.7920e-01,  1.5120e-02,  ...,  6.2073e-01,\n",
      "           -2.7510e-01,  2.1425e-01]],\n",
      "\n",
      "         [[ 8.0498e-01,  2.0352e-01,  1.7896e-02,  ..., -1.6228e-01,\n",
      "           -1.0867e+00, -2.0632e-01],\n",
      "          [ 6.3069e-01, -1.4465e+00,  5.0411e-01,  ...,  3.4637e-01,\n",
      "            5.0468e+00,  2.1150e+00],\n",
      "          [-1.1162e+00, -1.3258e+00,  6.3189e-01,  ...,  1.2063e+00,\n",
      "            4.4761e+00,  1.0679e+00],\n",
      "          ...,\n",
      "          [ 2.2878e-01, -2.3659e+00,  7.8082e-01,  ...,  1.5353e+00,\n",
      "            4.7206e+00,  1.8281e+00],\n",
      "          [-4.8325e-01, -2.4448e+00,  2.4398e-01,  ..., -2.1931e-01,\n",
      "            4.3510e+00,  2.2534e+00],\n",
      "          [-1.7464e+00, -2.7802e-02, -1.4060e+00,  ..., -8.7865e-02,\n",
      "            4.2460e+00,  1.9398e+00]],\n",
      "\n",
      "         [[ 3.3238e-01, -3.5263e-01, -3.3511e-01,  ...,  3.3173e-01,\n",
      "            1.4302e+00,  2.7422e-01],\n",
      "          [-3.7069e-01, -6.1829e+00, -2.2466e+00,  ..., -3.6439e+00,\n",
      "           -2.1060e+00, -7.4567e+00],\n",
      "          [-4.5127e-01, -5.9982e+00, -2.4673e+00,  ..., -4.1265e+00,\n",
      "           -3.8545e+00, -6.1227e+00],\n",
      "          ...,\n",
      "          [-2.1317e+00, -6.2376e+00, -4.9529e+00,  ..., -3.5573e+00,\n",
      "           -2.2995e+00, -4.4041e+00],\n",
      "          [-2.2614e+00, -7.2026e+00, -3.0679e+00,  ..., -2.5467e+00,\n",
      "           -3.5838e+00, -3.2058e+00],\n",
      "          [-3.0414e+00, -6.8481e+00, -1.5457e+00,  ..., -3.4928e+00,\n",
      "           -2.2893e+00, -5.9958e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3405e-01,  1.8003e+00,  5.3820e-01,  ...,  2.6242e-01,\n",
      "            4.4860e-01, -1.6709e+00],\n",
      "          [ 1.3520e+00, -5.1191e+00,  2.9198e+00,  ..., -8.6180e-01,\n",
      "           -1.6337e+00,  5.9583e+00],\n",
      "          [-8.9198e-02, -6.2376e+00,  4.5249e-01,  ..., -1.8860e+00,\n",
      "           -2.1434e+00,  7.1481e+00],\n",
      "          ...,\n",
      "          [ 3.8247e-01, -7.7788e+00,  2.1529e+00,  ..., -2.9409e+00,\n",
      "           -1.4936e+00,  6.4806e+00],\n",
      "          [ 5.7257e-01, -6.5320e+00,  3.4520e-01,  ..., -4.8911e+00,\n",
      "           -1.1043e+00,  6.2615e+00],\n",
      "          [ 2.3120e-02, -7.1271e+00,  1.8783e+00,  ..., -2.4430e+00,\n",
      "           -1.0648e+00,  5.3935e+00]],\n",
      "\n",
      "         [[ 7.0162e-02, -5.0270e-02,  1.6436e-01,  ..., -8.4555e-02,\n",
      "           -8.5299e-02, -1.4128e-01],\n",
      "          [ 4.7663e-01, -5.4246e-01,  6.5545e-01,  ...,  4.4172e-01,\n",
      "           -1.1501e+00, -1.4259e+00],\n",
      "          [ 1.6341e+00, -1.9560e+00, -1.2453e+00,  ..., -1.1005e+00,\n",
      "           -1.0474e-01, -3.4483e-01],\n",
      "          ...,\n",
      "          [-1.4072e-01, -1.0868e+00, -9.5866e-02,  ...,  9.9929e-01,\n",
      "            1.2154e+00,  1.0204e+00],\n",
      "          [-5.3142e-01, -5.1684e-01, -7.8924e-01,  ..., -4.3379e-01,\n",
      "           -5.0606e-01, -1.4453e-01],\n",
      "          [-1.6270e-01, -6.7944e-01,  3.7796e-02,  ..., -8.0383e-02,\n",
      "           -2.0414e-01,  3.0041e-01]],\n",
      "\n",
      "         [[ 4.0545e-01, -3.8652e-02,  1.8953e+00,  ..., -2.2527e-01,\n",
      "           -1.9901e-01, -9.9290e-01],\n",
      "          [ 3.7929e+00,  9.7979e-01, -1.5706e+00,  ...,  8.7371e-01,\n",
      "            1.3123e+00,  4.0946e+00],\n",
      "          [ 2.6437e+00,  2.8533e+00, -1.1851e+00,  ...,  1.4979e+00,\n",
      "            1.7340e+00,  2.7878e+00],\n",
      "          ...,\n",
      "          [ 3.7213e+00,  4.2312e-01, -4.0639e+00,  ...,  3.0060e+00,\n",
      "            1.1026e+00,  4.5419e+00],\n",
      "          [ 4.2811e+00,  3.5972e-01, -3.0493e+00,  ...,  3.7985e+00,\n",
      "            1.4962e+00,  5.2126e+00],\n",
      "          [ 2.6493e+00,  1.5411e+00, -3.0109e+00,  ..., -5.3203e-01,\n",
      "            6.5990e-01,  4.2414e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 3.9765e-02,  6.3191e-02,  6.3377e-04,  ...,  1.9104e-02,\n",
      "            9.9082e-02,  3.4521e-02],\n",
      "          [ 1.1378e+00, -1.2861e+00, -1.2908e-01,  ..., -3.3004e-01,\n",
      "           -1.3635e+00, -2.2904e+00],\n",
      "          [-8.1626e-02,  9.3745e-02, -2.8481e-01,  ...,  2.1468e-01,\n",
      "           -9.6816e-01,  2.9894e-01],\n",
      "          ...,\n",
      "          [ 2.1699e-01, -1.8662e-01,  3.1800e-01,  ...,  7.8087e-02,\n",
      "           -1.3018e+00,  2.1320e-01],\n",
      "          [ 7.9638e-01,  2.0152e-01,  1.0130e-01,  ...,  2.5974e-01,\n",
      "           -7.7726e-01, -7.3525e-01],\n",
      "          [-2.1013e-01, -6.6706e-01,  1.7082e-01,  ...,  4.4624e-02,\n",
      "           -2.1095e-01,  1.0726e+00]],\n",
      "\n",
      "         [[-4.9772e-02,  4.5371e-03,  8.2704e-02,  ..., -5.1366e-02,\n",
      "           -3.5350e-02, -4.1695e-02],\n",
      "          [ 9.3125e-01,  4.8477e-01,  1.2721e-02,  ...,  2.5011e-01,\n",
      "            5.0911e-01,  7.7029e-02],\n",
      "          [ 5.3607e-01,  3.6337e-01,  5.9256e-01,  ...,  1.3317e-01,\n",
      "            2.4218e-01,  5.0219e-01],\n",
      "          ...,\n",
      "          [ 9.9435e-01,  8.4733e-01, -1.4116e-02,  ..., -2.2738e-01,\n",
      "           -3.3423e-01,  7.2092e-01],\n",
      "          [ 7.0013e-01,  4.3564e-02,  9.8745e-02,  ..., -4.9008e-01,\n",
      "           -1.1142e-01,  2.7808e-01],\n",
      "          [-2.6422e-01,  3.3482e-02,  4.0394e-02,  ...,  2.1468e-01,\n",
      "            2.0354e-01, -5.8808e-02]],\n",
      "\n",
      "         [[ 2.8733e-02, -1.1324e-01, -6.5474e-02,  ..., -2.8632e-02,\n",
      "            7.8444e-02, -1.6102e-01],\n",
      "          [-4.5820e-01,  4.7828e-01,  7.0547e-02,  ...,  5.3585e-01,\n",
      "           -4.5617e-01, -2.3535e-01],\n",
      "          [-3.3742e-01, -4.2131e-02,  5.9882e-01,  ...,  2.5610e-01,\n",
      "            7.7897e-02, -4.0960e-01],\n",
      "          ...,\n",
      "          [ 7.5842e-01, -5.6218e-02, -7.4135e-01,  ...,  5.3671e-02,\n",
      "           -4.3988e-01,  1.1196e+00],\n",
      "          [-8.5638e-01,  1.0162e+00, -1.6276e+00,  ..., -5.2393e-01,\n",
      "           -5.1775e-01,  2.8000e-01],\n",
      "          [ 3.0931e-01,  9.2681e-02, -5.2069e-01,  ..., -2.1601e-01,\n",
      "           -2.4954e-01, -6.8193e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0445e-02,  1.2575e-01, -8.2247e-03,  ..., -3.0457e-02,\n",
      "            6.6124e-02, -3.3832e-02],\n",
      "          [-7.7384e-01,  4.6625e-01, -8.6402e-01,  ...,  1.1561e+00,\n",
      "            1.9820e-01, -3.0625e-01],\n",
      "          [-2.7734e-04,  6.3935e-01, -1.8950e-01,  ...,  2.0117e-01,\n",
      "           -1.7873e-02,  5.5499e-01],\n",
      "          ...,\n",
      "          [ 7.8662e-01, -5.6376e-02,  4.7865e-01,  ..., -4.2434e-01,\n",
      "           -1.5718e-01, -4.8276e-01],\n",
      "          [ 6.4126e-01, -9.5627e-02, -9.7530e-03,  ...,  1.4783e-02,\n",
      "            3.4626e-01,  1.4248e-01],\n",
      "          [ 1.3236e-01,  2.3395e-01,  8.1249e-02,  ...,  4.1129e-01,\n",
      "            2.2832e-01,  5.4297e-02]],\n",
      "\n",
      "         [[-1.7626e-01, -1.0919e-01, -8.4360e-02,  ..., -2.3040e-01,\n",
      "           -1.7456e-02, -4.5445e-02],\n",
      "          [-7.3267e-01,  3.0908e-01, -6.8270e-01,  ...,  1.1911e+00,\n",
      "            6.0792e-01, -5.9669e-01],\n",
      "          [ 3.2711e-01, -8.1702e-01, -6.7690e-01,  ..., -1.4106e-01,\n",
      "            5.1631e-01,  1.7033e+00],\n",
      "          ...,\n",
      "          [ 6.9877e-01,  2.1668e-01,  2.2550e+00,  ...,  7.3070e-01,\n",
      "            1.5383e-01, -1.6586e-01],\n",
      "          [-1.2518e-01,  2.8476e-03,  1.7571e-01,  ...,  1.3301e-01,\n",
      "            1.5198e-01, -2.0102e-02],\n",
      "          [ 3.2786e-01,  4.0679e-01,  6.3502e-01,  ..., -9.9532e-01,\n",
      "            2.8010e-01,  1.7276e-01]],\n",
      "\n",
      "         [[ 1.2476e-01, -6.5556e-02, -2.6808e-02,  ..., -8.9693e-03,\n",
      "           -9.2486e-02, -8.6446e-02],\n",
      "          [-3.6288e-01, -4.0901e-01,  4.7382e-02,  ...,  7.5869e-01,\n",
      "            2.6507e-01, -2.3738e-01],\n",
      "          [-3.1819e-01,  4.7386e-01,  2.4661e-01,  ...,  1.0665e-02,\n",
      "            2.0598e-01, -6.8917e-01],\n",
      "          ...,\n",
      "          [-5.9656e-02,  5.2958e-01, -5.8517e-01,  ...,  2.4241e-01,\n",
      "            7.2702e-02,  4.3875e-01],\n",
      "          [-2.8286e-01, -2.9105e-01, -5.9394e-01,  ..., -1.3986e-01,\n",
      "            3.1039e-01, -5.7179e-01],\n",
      "          [ 4.7208e-01, -1.1132e-01,  2.8570e-02,  ..., -8.4544e-02,\n",
      "           -4.1679e-01,  1.1348e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-8.9410e-01, -1.4102e-01,  3.3448e-01,  ..., -9.8900e-01,\n",
      "            2.4201e-02, -2.9690e+00],\n",
      "          [ 2.0739e+00, -6.6276e-01, -9.6401e-01,  ..., -2.2700e+00,\n",
      "           -2.5282e+00,  5.5307e+00],\n",
      "          [ 1.4538e+00,  9.1335e-01, -1.2821e+00,  ..., -1.7829e+00,\n",
      "           -2.5922e+00,  7.0503e+00],\n",
      "          ...,\n",
      "          [-7.4860e-02, -1.2873e+00, -4.2342e+00,  ..., -1.1139e+00,\n",
      "           -4.1929e-01,  7.9390e+00],\n",
      "          [ 6.1465e-01,  1.4598e+00, -3.6137e+00,  ...,  1.9781e-01,\n",
      "           -5.2970e-01,  7.9857e+00],\n",
      "          [ 4.4373e-01, -2.1877e-01, -2.2024e+00,  ..., -2.1846e+00,\n",
      "           -1.8394e+00,  8.6313e+00]],\n",
      "\n",
      "         [[ 3.3228e-01, -5.2100e-02,  4.4828e-01,  ..., -1.3505e-01,\n",
      "           -6.7878e-02, -2.2125e+00],\n",
      "          [-1.9308e+00,  1.9479e-01,  3.7004e+00,  ..., -7.5413e-01,\n",
      "           -1.4453e+00,  5.9218e+00],\n",
      "          [-2.3695e+00,  6.8371e-01,  3.6881e+00,  ...,  4.3966e-01,\n",
      "           -1.1369e+00,  6.4070e+00],\n",
      "          ...,\n",
      "          [-1.4517e+00,  3.6522e-01,  2.4737e+00,  ..., -7.0429e-01,\n",
      "           -9.3994e-01,  6.8221e+00],\n",
      "          [-2.4442e+00,  5.6834e-01,  2.1406e+00,  ..., -1.6726e-02,\n",
      "           -2.8341e+00,  6.6074e+00],\n",
      "          [-1.7411e+00,  1.0740e-01,  2.9581e+00,  ..., -5.2872e-01,\n",
      "           -4.2821e-01,  6.4365e+00]],\n",
      "\n",
      "         [[ 1.3868e-01, -6.5963e-01, -2.3258e-01,  ...,  1.4861e-01,\n",
      "            2.7447e-01, -1.6060e-01],\n",
      "          [ 8.7127e-02,  1.5625e+00,  8.7948e-01,  ..., -5.6050e-02,\n",
      "            6.4114e-01, -2.2402e-02],\n",
      "          [-1.3730e+00,  1.8783e+00,  1.0146e+00,  ..., -7.2353e-01,\n",
      "           -1.0071e+00, -1.1916e-01],\n",
      "          ...,\n",
      "          [-1.4432e+00,  2.3373e+00, -7.6811e-02,  ...,  1.3016e-01,\n",
      "           -3.4882e-01,  1.0060e+00],\n",
      "          [ 3.4654e-01,  2.0433e+00,  1.0946e+00,  ..., -1.9423e-01,\n",
      "            5.6170e-01,  8.5613e-01],\n",
      "          [ 3.7556e-01,  2.7165e+00,  1.5422e+00,  ..., -6.2141e-01,\n",
      "            2.8909e-01, -1.2470e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8548e-01,  3.3657e-02, -8.6122e-04,  ...,  1.2389e+00,\n",
      "            4.4031e-02,  1.7787e+00],\n",
      "          [-3.3900e-01, -1.1665e+00, -1.6126e+00,  ..., -2.2094e+00,\n",
      "           -1.2286e+00, -8.3999e-01],\n",
      "          [ 1.1457e+00, -1.9595e+00, -2.7776e+00,  ..., -2.5459e+00,\n",
      "           -2.1862e+00, -6.8518e-01],\n",
      "          ...,\n",
      "          [ 2.7297e+00, -5.4906e-01,  6.4908e-01,  ..., -2.9931e+00,\n",
      "           -1.2364e+00, -2.9284e+00],\n",
      "          [ 9.0714e-01, -2.5425e-01,  1.0949e+00,  ..., -4.2778e+00,\n",
      "           -7.9689e-01, -2.4453e+00],\n",
      "          [ 5.2888e-01, -4.7623e-01, -1.0388e+00,  ..., -4.2955e+00,\n",
      "           -1.3179e+00, -6.7411e-01]],\n",
      "\n",
      "         [[-3.5278e-01, -1.6115e-01,  2.2002e-01,  ...,  2.5153e-01,\n",
      "           -2.5440e-02,  2.5464e-02],\n",
      "          [-5.8535e-01, -1.6797e+00, -9.7090e-02,  ...,  1.3156e+00,\n",
      "           -4.3526e-01, -3.6301e-01],\n",
      "          [-1.4276e+00, -4.4909e-01,  4.2122e-01,  ...,  8.0923e-01,\n",
      "            2.0564e+00,  5.5882e-01],\n",
      "          ...,\n",
      "          [ 2.3271e+00,  3.7035e-01, -1.2498e-01,  ...,  1.6023e+00,\n",
      "            7.8902e-01,  8.7364e-01],\n",
      "          [ 1.0688e+00,  6.8914e-01,  1.0407e+00,  ...,  1.1552e+00,\n",
      "           -4.6404e-01,  5.0676e-01],\n",
      "          [-5.4183e-01,  2.2367e-01,  1.1283e+00,  ...,  4.9600e-01,\n",
      "            4.4041e-01,  1.2166e+00]],\n",
      "\n",
      "         [[ 3.4287e+00,  2.1075e+00, -2.1753e+00,  ..., -2.8384e+00,\n",
      "           -3.9170e+00, -1.1987e+00],\n",
      "          [-2.3681e+00,  6.4387e-01,  2.7032e+00,  ...,  9.6174e-01,\n",
      "            5.6489e+00, -3.8173e+00],\n",
      "          [-1.7256e+00, -6.4346e-01,  3.3742e+00,  ...,  1.0354e-01,\n",
      "            1.0917e+01, -2.0007e+00],\n",
      "          ...,\n",
      "          [-2.4372e+00, -3.5694e+00,  5.2531e+00,  ..., -2.7536e+00,\n",
      "            1.4675e+01,  2.3681e+00],\n",
      "          [-5.4329e+00, -3.3473e+00,  6.1980e+00,  ..., -1.9572e+00,\n",
      "            1.3900e+01,  2.5586e+00],\n",
      "          [-5.6755e+00, -3.2005e+00,  9.5993e+00,  ..., -1.9898e-01,\n",
      "            1.4622e+01, -1.6569e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-9.6101e-04, -5.7273e-02,  1.4961e-02,  ...,  5.1007e-02,\n",
      "            2.4101e-02,  6.1853e-02],\n",
      "          [ 8.1719e-01,  3.1389e-01,  4.9729e-01,  ..., -4.4034e-01,\n",
      "           -5.6994e-01,  1.1864e+00],\n",
      "          [ 9.6673e-03, -1.2195e-01,  9.2736e-02,  ..., -8.4646e-01,\n",
      "            1.8833e-01, -2.2715e-02],\n",
      "          ...,\n",
      "          [-8.3899e-02, -1.7438e-01,  8.2991e-01,  ...,  4.0479e-01,\n",
      "           -5.2889e-01, -1.2070e+00],\n",
      "          [ 3.9354e-01,  4.8802e-02,  1.7574e-01,  ...,  1.7612e-01,\n",
      "            3.2382e-01, -6.9690e-01],\n",
      "          [-4.1270e-01,  1.0351e-01,  1.8573e-02,  ...,  6.5982e-02,\n",
      "           -2.0056e-01, -4.9836e-02]],\n",
      "\n",
      "         [[-5.8025e-02, -2.3602e-02, -1.3654e-01,  ..., -3.6943e-02,\n",
      "            4.6139e-02, -3.2083e-04],\n",
      "          [ 5.3729e-01,  2.3709e-01,  3.6851e-01,  ...,  3.0927e-01,\n",
      "           -7.5684e-01,  6.9841e-01],\n",
      "          [ 8.7619e-02, -3.0468e-01, -4.1744e-01,  ...,  4.6823e-01,\n",
      "           -5.7566e-01,  6.2960e-01],\n",
      "          ...,\n",
      "          [ 4.8862e-01,  6.7331e-01, -1.3201e-01,  ..., -4.5718e-01,\n",
      "            4.0848e-01,  3.6935e-01],\n",
      "          [ 1.3514e-01,  3.2320e-02, -1.7488e-01,  ...,  2.5361e-01,\n",
      "            6.0363e-01,  3.6989e-01],\n",
      "          [-3.1217e-01,  6.9660e-02, -1.0854e-01,  ..., -3.3014e-01,\n",
      "           -1.8350e-01,  1.7417e-01]],\n",
      "\n",
      "         [[ 5.9868e-02,  9.4087e-02,  8.9803e-02,  ...,  1.8044e-02,\n",
      "           -8.2018e-02, -7.6688e-03],\n",
      "          [ 4.6111e-03, -1.3464e-01,  5.5771e-01,  ..., -1.0991e+00,\n",
      "           -1.0160e-01, -4.8283e-01],\n",
      "          [-5.1055e-01, -3.0271e-01, -7.6251e-01,  ..., -5.6934e-02,\n",
      "           -4.8848e-01,  6.0690e-02],\n",
      "          ...,\n",
      "          [-5.6406e-01, -3.3250e-01,  5.2524e-01,  ...,  3.8864e-01,\n",
      "            6.4106e-01,  2.6505e-02],\n",
      "          [-2.4166e-01,  6.7879e-01, -5.6899e-01,  ...,  5.1277e-01,\n",
      "            8.9496e-01, -3.2001e-01],\n",
      "          [ 1.9636e-01, -1.2071e-01, -1.2509e-01,  ..., -2.6019e-01,\n",
      "           -2.9595e-01,  3.1048e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9281e-03,  8.4553e-02, -7.0813e-02,  ...,  4.7959e-02,\n",
      "            4.0231e-02, -1.3932e-01],\n",
      "          [-6.4524e-02, -1.8763e-01, -5.0959e-01,  ...,  1.2312e-01,\n",
      "            9.9802e-01, -5.4559e-01],\n",
      "          [ 2.7483e-01,  5.9988e-01, -8.3259e-01,  ...,  2.9060e-01,\n",
      "           -1.6327e-01,  5.9452e-01],\n",
      "          ...,\n",
      "          [ 1.1946e+00,  3.1072e-01, -2.8942e-01,  ...,  4.8221e-01,\n",
      "            1.0371e+00, -1.0225e+00],\n",
      "          [ 5.3250e-01, -1.2834e+00, -4.2687e-01,  ...,  1.3547e+00,\n",
      "           -1.9294e-01,  4.6109e-01],\n",
      "          [-2.1219e-01,  5.5494e-01, -4.9708e-01,  ...,  1.8992e-01,\n",
      "           -1.3037e-01, -9.2226e-01]],\n",
      "\n",
      "         [[-1.4771e-01, -5.4743e-02,  1.0354e-01,  ..., -6.4467e-02,\n",
      "            5.0235e-02, -4.7105e-03],\n",
      "          [ 2.0542e-01,  7.5674e-01, -3.8195e-01,  ...,  7.9123e-01,\n",
      "            3.3666e-01,  3.1182e-01],\n",
      "          [ 1.7716e-02, -2.9456e-01, -4.1132e-01,  ..., -3.7351e-02,\n",
      "           -5.0875e-01,  7.6014e-01],\n",
      "          ...,\n",
      "          [ 4.6112e-01,  1.3695e+00,  4.5065e-01,  ..., -6.2355e-01,\n",
      "            2.1478e-01,  1.1362e+00],\n",
      "          [-4.8439e-02,  1.9277e-02, -2.2616e-01,  ...,  6.6443e-02,\n",
      "           -1.4004e-01,  1.5982e-02],\n",
      "          [ 3.6793e-01, -4.4020e-01,  3.2716e-01,  ...,  5.6387e-01,\n",
      "            6.9215e-01,  6.9415e-02]],\n",
      "\n",
      "         [[-1.8205e-02, -3.0886e-03, -1.9086e-02,  ..., -2.5844e-02,\n",
      "            8.7407e-03, -1.7466e-02],\n",
      "          [-7.2502e-01, -4.0966e-01, -5.0877e-02,  ...,  7.9444e-01,\n",
      "           -4.2704e-01, -3.8911e-01],\n",
      "          [-2.3777e-01,  1.8286e-01, -1.1924e-01,  ...,  3.9828e-01,\n",
      "           -9.7823e-02, -7.2584e-01],\n",
      "          ...,\n",
      "          [-4.2147e-01, -4.4072e-01,  1.3276e-01,  ..., -3.9426e-01,\n",
      "            5.9784e-01, -5.9402e-01],\n",
      "          [-1.1911e+00, -2.2353e-01, -5.2611e-01,  ..., -6.8117e-01,\n",
      "            4.3145e-01, -6.0661e-01],\n",
      "          [ 5.7201e-01, -2.1513e-01, -2.0821e-02,  ..., -2.6662e-01,\n",
      "            4.3591e-01,  9.3393e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.7386e-02, -2.9366e-01,  2.2930e-01,  ...,  1.6992e+00,\n",
      "           -2.1956e-01, -6.9672e-02],\n",
      "          [ 1.3258e+00,  4.3530e-03, -4.5178e-01,  ..., -3.3861e+00,\n",
      "            6.0935e-01, -9.7996e-02],\n",
      "          [-3.8398e-03,  6.8534e-01, -4.5098e-01,  ..., -3.5777e+00,\n",
      "            4.3510e-01, -1.0692e+00],\n",
      "          ...,\n",
      "          [ 1.0944e+00, -1.3281e-01, -8.4927e-01,  ..., -4.4945e+00,\n",
      "           -8.8708e-01, -7.0987e-01],\n",
      "          [-4.0466e-01,  1.8280e-01,  7.3278e-02,  ..., -3.9964e+00,\n",
      "            5.3101e-01, -8.9631e-01],\n",
      "          [-2.8022e-01,  2.4591e-01, -9.5407e-01,  ..., -3.1422e+00,\n",
      "            5.9489e-01, -6.9650e-01]],\n",
      "\n",
      "         [[ 1.4856e-01,  9.7933e-01, -1.4228e+00,  ..., -1.2427e-01,\n",
      "            2.7183e-01,  9.2512e-01],\n",
      "          [-4.5280e+00, -5.5021e+00,  7.7566e-01,  ...,  3.7732e-02,\n",
      "            2.0070e+00, -6.6960e-01],\n",
      "          [-1.8428e+00, -5.4617e+00, -1.5096e+00,  ..., -1.3806e-01,\n",
      "           -1.6786e+00, -1.6976e+00],\n",
      "          ...,\n",
      "          [-1.0155e+00, -4.1935e+00,  9.1143e-01,  ..., -6.7730e-01,\n",
      "            8.5889e-01, -2.9881e+00],\n",
      "          [ 3.6602e-01, -2.7849e+00,  1.7301e+00,  ...,  8.3982e-01,\n",
      "            1.8913e+00, -1.8723e+00],\n",
      "          [ 1.8487e-01, -2.9940e+00,  3.7968e-01,  ..., -6.0796e-01,\n",
      "            1.2830e+00, -1.7956e+00]],\n",
      "\n",
      "         [[-6.7567e-01,  2.5791e-01, -4.4622e-02,  ...,  1.8188e-01,\n",
      "            3.5410e-02, -2.7977e-01],\n",
      "          [ 7.9076e-01, -6.6335e-01, -1.7585e+00,  ..., -1.6750e+00,\n",
      "           -1.0765e+00, -1.3595e+00],\n",
      "          [ 2.1679e+00, -6.9918e-02,  4.3477e-01,  ...,  1.2724e-01,\n",
      "           -4.9424e-01, -1.1511e+00],\n",
      "          ...,\n",
      "          [ 1.8131e+00, -2.6902e-01,  1.9496e-01,  ..., -7.7712e-02,\n",
      "           -1.8967e+00,  9.0248e-02],\n",
      "          [ 1.1712e+00, -1.0126e+00, -8.9855e-01,  ..., -8.4999e-01,\n",
      "           -1.0316e+00, -2.0615e+00],\n",
      "          [ 6.7570e-01,  3.8597e-01, -3.9110e-01,  ..., -8.8803e-02,\n",
      "           -3.7925e-01,  9.4493e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6750e-02,  1.1317e-01,  1.4411e-01,  ..., -9.5337e-02,\n",
      "            2.8758e-02,  1.7906e-01],\n",
      "          [ 5.2997e-01, -2.4246e-01, -8.6437e-03,  ...,  1.7977e+00,\n",
      "           -1.2685e+00,  6.6170e-01],\n",
      "          [ 1.3688e+00, -5.8446e-01, -1.0249e+00,  ...,  6.1781e-01,\n",
      "           -1.2555e+00,  1.8549e-01],\n",
      "          ...,\n",
      "          [-4.0208e-01, -3.9943e-01,  9.0350e-01,  ..., -8.4164e-02,\n",
      "            2.9849e-01,  1.3064e+00],\n",
      "          [ 8.7521e-01, -5.4618e-01,  6.0006e-01,  ..., -4.2599e-01,\n",
      "            9.5319e-01,  4.6231e-02],\n",
      "          [ 6.7025e-01, -2.4473e-02,  6.4640e-01,  ...,  9.7068e-01,\n",
      "            5.1276e-01,  1.2734e-01]],\n",
      "\n",
      "         [[-3.0175e+00,  3.9929e-01, -3.6378e-02,  ..., -4.7122e-01,\n",
      "           -3.4804e-01,  1.2437e+00],\n",
      "          [ 5.1598e+00, -6.4113e-01, -1.2113e+00,  ..., -5.4299e-01,\n",
      "           -6.3423e-01, -2.7112e+00],\n",
      "          [ 3.9647e+00, -4.5005e-01, -8.1767e-01,  ...,  1.3302e+00,\n",
      "            1.0222e+00, -3.6523e-01],\n",
      "          ...,\n",
      "          [ 6.9698e+00,  1.0402e-01, -1.2673e+00,  ...,  1.4771e+00,\n",
      "           -3.9453e-01, -1.3275e+00],\n",
      "          [ 5.9740e+00, -3.1729e-01, -3.0472e-01,  ..., -1.6971e+00,\n",
      "            1.9964e+00, -5.9248e-01],\n",
      "          [ 4.3904e+00,  3.9197e-01, -6.1715e-01,  ..., -1.7761e+00,\n",
      "            3.8099e-01,  9.8361e-02]],\n",
      "\n",
      "         [[-1.4068e-02, -2.3846e-01,  2.5290e-02,  ..., -1.6074e-01,\n",
      "            3.3649e-01,  8.6691e-02],\n",
      "          [ 2.8667e-02, -2.1868e+00,  1.7570e-01,  ...,  3.2765e-01,\n",
      "            3.8849e-01, -1.7206e+00],\n",
      "          [-2.3774e-02, -1.9333e+00, -1.1854e-01,  ..., -5.0054e-01,\n",
      "            1.4996e+00, -2.0566e-01],\n",
      "          ...,\n",
      "          [-1.6754e-01, -7.2157e-01,  6.8358e-01,  ...,  2.4385e-01,\n",
      "            1.1955e+00, -2.1362e+00],\n",
      "          [-1.7204e-01, -1.5373e+00,  4.9301e-01,  ...,  1.1556e-01,\n",
      "            1.8178e+00, -1.0164e+00],\n",
      "          [ 2.1786e-01, -1.8928e+00,  4.4174e-01,  ...,  4.2819e-01,\n",
      "            1.5182e-01, -2.0864e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0283, -0.0237, -0.0065,  ..., -0.0032, -0.0248,  0.3515],\n",
      "          [ 0.8264,  0.2939, -0.5176,  ..., -0.2927, -0.2171,  0.0181],\n",
      "          [ 1.9226, -0.7101,  0.3985,  ...,  0.1594,  0.7347, -0.2097],\n",
      "          ...,\n",
      "          [ 0.3205, -0.6643,  0.0532,  ..., -0.3513, -0.3939, -1.5316],\n",
      "          [ 0.0561, -0.2875, -0.6101,  ...,  1.2166,  0.5898, -1.2971],\n",
      "          [ 0.1016,  0.4254, -0.1121,  ...,  0.1045,  0.3800, -1.0232]],\n",
      "\n",
      "         [[ 0.0052, -0.0295,  0.0151,  ..., -0.0267,  0.0140,  0.0122],\n",
      "          [-0.5628, -0.9254,  0.9794,  ..., -0.2008,  1.3605, -0.3241],\n",
      "          [ 0.7993,  0.5138, -0.2952,  ..., -0.7700,  0.4493, -0.8436],\n",
      "          ...,\n",
      "          [-0.0907,  0.4751,  1.4920,  ..., -0.6118,  0.6339, -0.4834],\n",
      "          [ 1.1835, -0.9603,  1.0771,  ..., -0.7290,  0.1659, -1.8319],\n",
      "          [-0.7705,  0.0071, -1.1086,  ..., -0.2116,  1.5475, -1.0844]],\n",
      "\n",
      "         [[-0.0587,  0.0065, -0.0385,  ..., -0.0367,  0.0108, -0.0737],\n",
      "          [-0.3782,  0.4603, -0.0197,  ..., -0.0948, -0.1734, -0.0478],\n",
      "          [-1.0508, -0.9034, -0.1986,  ...,  0.7021,  0.1026,  0.6465],\n",
      "          ...,\n",
      "          [ 0.6918, -0.7151,  0.4399,  ..., -0.5258,  0.4609,  0.3265],\n",
      "          [-0.5982, -0.3842, -0.2050,  ..., -0.3919, -0.2597, -0.3368],\n",
      "          [-0.2127,  0.2818,  1.1315,  ..., -0.4063,  0.3917,  0.4088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3268, -0.1926, -0.0725,  ..., -0.4884,  0.2164,  0.0924],\n",
      "          [ 2.4077, -2.1106,  0.0814,  ...,  2.1166,  0.7840, -0.3542],\n",
      "          [ 0.7914, -2.0034, -1.2725,  ...,  0.1668,  0.2048, -0.0149],\n",
      "          ...,\n",
      "          [ 0.1624,  0.0656,  0.3339,  ...,  1.6880,  0.5858, -0.4577],\n",
      "          [ 0.3699, -2.1781, -0.6363,  ...,  1.6692, -0.0237,  0.6235],\n",
      "          [ 1.1835, -1.2606, -0.3178,  ...,  0.8860, -0.2557, -1.0126]],\n",
      "\n",
      "         [[-0.0743, -0.1376, -0.0477,  ..., -0.1892, -0.1411,  0.1259],\n",
      "          [-0.8208, -0.8386,  0.6731,  ...,  0.6332,  0.0199, -0.7615],\n",
      "          [ 0.2827,  0.3740, -0.2432,  ...,  0.1827, -0.3376,  0.5142],\n",
      "          ...,\n",
      "          [ 0.9158,  0.1738,  0.1931,  ..., -0.3132, -0.0828,  0.6322],\n",
      "          [-1.2725,  0.6167, -0.2177,  ..., -0.5662, -0.9483,  0.7020],\n",
      "          [-0.4237, -0.4396, -0.7444,  ..., -0.1120, -0.1108,  0.0457]],\n",
      "\n",
      "         [[-0.0376, -0.0407,  0.1040,  ...,  0.0808, -0.0425,  0.0137],\n",
      "          [ 0.1663, -0.5093,  0.4754,  ..., -0.8001, -0.2647, -0.0260],\n",
      "          [ 0.8517, -0.0424,  0.2084,  ..., -0.4614, -0.3543, -0.4421],\n",
      "          ...,\n",
      "          [ 0.8837, -0.2089, -1.3849,  ...,  0.0321,  0.3742,  0.3700],\n",
      "          [ 1.5021,  0.3024, -1.6816,  ...,  0.2755, -0.4314,  1.2684],\n",
      "          [ 0.8986, -0.4031, -0.7551,  ...,  0.2049,  0.5642,  0.3766]]]],\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-3.4242e-01,  8.8585e-01, -1.5804e-01,  ...,  1.1261e+00,\n",
      "           -1.9518e-01,  1.4177e-01],\n",
      "          [-1.9220e+00, -3.5766e+00,  1.0735e+00,  ..., -2.9989e+00,\n",
      "            2.4456e-01,  1.6964e+00],\n",
      "          [ 2.0634e-01, -4.5545e+00, -3.9479e-01,  ..., -2.3682e+00,\n",
      "            7.5262e-01,  1.9643e+00],\n",
      "          ...,\n",
      "          [ 4.1849e-02, -3.6175e+00, -3.7537e-01,  ..., -3.7409e+00,\n",
      "           -2.5598e+00,  1.3602e+00],\n",
      "          [ 9.7942e-01, -4.3081e+00, -8.1837e-01,  ..., -3.9368e+00,\n",
      "           -3.5577e-01,  6.4095e-01],\n",
      "          [-1.1241e+00, -4.2882e+00,  9.7364e-01,  ..., -3.9289e+00,\n",
      "            3.2482e-01,  1.0470e+00]],\n",
      "\n",
      "         [[ 4.3837e-02,  8.5526e-01, -6.5018e-01,  ..., -4.8066e-02,\n",
      "            2.9846e-01,  1.3144e-02],\n",
      "          [ 1.8581e+00, -8.6762e-01,  1.1911e-01,  ...,  1.4102e+00,\n",
      "           -1.5516e+00, -8.9818e-01],\n",
      "          [ 3.9744e-01, -7.4263e-01, -8.7026e-01,  ...,  2.1461e+00,\n",
      "            6.7020e-01, -5.7750e-01],\n",
      "          ...,\n",
      "          [-1.8549e+00,  4.0110e-01,  1.0519e+00,  ..., -6.1303e-01,\n",
      "            1.0524e+00, -1.9586e+00],\n",
      "          [-1.6497e+00,  1.7422e+00,  2.8445e+00,  ..., -4.2254e-01,\n",
      "            1.4167e+00,  2.2799e-02],\n",
      "          [ 3.9260e-01,  5.7385e-01,  6.0346e-01,  ...,  1.8517e+00,\n",
      "            1.6710e-01, -8.4129e-03]],\n",
      "\n",
      "         [[-3.0691e-01,  1.4184e-01, -9.7711e-01,  ..., -3.5239e-01,\n",
      "           -6.5329e-02, -1.5691e-01],\n",
      "          [ 5.4449e-01,  2.6089e-01,  3.3700e+00,  ...,  5.8992e-01,\n",
      "            3.0752e-01,  1.6272e-01],\n",
      "          [ 1.8183e-01, -4.2966e-01,  3.6656e+00,  ...,  6.5348e-01,\n",
      "            1.6247e-01,  1.1807e+00],\n",
      "          ...,\n",
      "          [ 6.0342e-01, -2.8374e-02,  4.0457e+00,  ...,  1.4485e-01,\n",
      "           -3.0530e-01, -1.8585e-02],\n",
      "          [ 8.4563e-01, -6.5223e-02,  3.8245e+00,  ...,  4.2786e-02,\n",
      "            8.7348e-01,  8.6994e-01],\n",
      "          [-4.1459e-01,  9.7909e-01,  2.9803e+00,  ..., -3.9050e-01,\n",
      "           -1.2682e-01,  4.7122e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7623e-01,  8.8415e-02, -6.9547e-02,  ..., -4.7736e-02,\n",
      "            2.2840e-01,  1.9032e-02],\n",
      "          [ 7.1144e-01,  1.8763e-01, -3.9937e-01,  ..., -4.9091e-01,\n",
      "           -1.2776e+00,  6.4044e-01],\n",
      "          [-3.3112e-01,  1.5726e+00, -1.1475e-01,  ...,  1.2293e+00,\n",
      "           -3.2792e-01,  1.3483e+00],\n",
      "          ...,\n",
      "          [-1.2218e+00,  1.0106e+00,  1.5841e+00,  ...,  2.4095e-01,\n",
      "            1.8157e+00,  2.5420e-01],\n",
      "          [-7.0075e-01, -2.0352e+00,  3.5377e-01,  ..., -2.1764e-01,\n",
      "            1.2933e+00,  3.9608e-01],\n",
      "          [-1.2331e+00, -2.5181e-01,  9.9036e-01,  ..., -7.5640e-02,\n",
      "            1.3286e+00,  6.3743e-01]],\n",
      "\n",
      "         [[ 1.9031e-01,  5.9438e-02,  3.3524e-01,  ...,  4.2277e-01,\n",
      "            1.9400e-02,  2.2399e-01],\n",
      "          [ 5.9327e-01,  2.8811e-01, -1.4083e-01,  ..., -1.5039e+00,\n",
      "           -2.3323e-01,  3.1527e-01],\n",
      "          [ 1.1468e+00, -2.1674e-01,  1.2189e+00,  ..., -4.9551e-01,\n",
      "            2.9952e-01,  4.2660e-01],\n",
      "          ...,\n",
      "          [ 1.2327e+00,  1.9132e-01,  9.7667e-01,  ..., -3.9745e-01,\n",
      "           -8.6595e-01,  1.6085e-01],\n",
      "          [ 1.5555e+00,  1.2640e-01,  1.5087e+00,  ..., -2.6383e-01,\n",
      "           -1.4203e+00, -3.3963e-01],\n",
      "          [ 2.5104e+00, -4.2117e-01,  9.7205e-01,  ...,  7.9409e-02,\n",
      "           -1.9639e+00,  1.2759e+00]],\n",
      "\n",
      "         [[-3.0269e+00,  5.5620e-01,  5.7562e-01,  ..., -9.3499e-01,\n",
      "            3.1438e-01,  1.8537e-01],\n",
      "          [ 6.4035e+00, -2.6481e-01, -1.7831e+00,  ...,  9.5199e-01,\n",
      "           -1.3967e+00, -1.9982e-02],\n",
      "          [ 6.5658e+00, -5.8532e-01, -3.0053e+00,  ...,  1.1486e+00,\n",
      "           -8.4129e-01, -1.1981e+00],\n",
      "          ...,\n",
      "          [ 8.7470e+00,  4.9102e-01, -8.1829e-01,  ...,  9.2144e-01,\n",
      "           -1.9827e-01, -2.1748e+00],\n",
      "          [ 8.8249e+00,  7.7651e-01, -9.9607e-01,  ...,  1.0463e-01,\n",
      "           -8.5052e-01, -1.0812e+00],\n",
      "          [ 9.4365e+00, -1.1869e+00, -5.3457e-01,  ...,  2.5683e+00,\n",
      "            4.1110e-01, -7.9529e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 4.2588e-02, -5.0356e-02,  8.1064e-03,  ..., -7.2504e-02,\n",
      "            9.6370e-03, -9.2134e-02],\n",
      "          [-4.3344e-01,  1.3342e-01, -4.7552e-02,  ...,  4.4079e-01,\n",
      "            2.6153e-01,  1.0634e+00],\n",
      "          [ 3.0987e-01, -1.2253e-01, -8.2554e-01,  ..., -5.1116e-01,\n",
      "           -7.1061e-01,  9.2578e-01],\n",
      "          ...,\n",
      "          [-8.3976e-01,  2.3753e-01,  2.7464e-01,  ...,  2.1087e-01,\n",
      "            2.5150e-01,  4.4114e-01],\n",
      "          [-1.1380e+00,  2.7989e-01, -2.8601e-01,  ..., -3.8907e-02,\n",
      "            6.6291e-01, -1.5787e-01],\n",
      "          [ 2.5615e-01, -1.8164e-01,  3.2558e-01,  ..., -7.4514e-02,\n",
      "            1.2012e-01, -5.7117e-01]],\n",
      "\n",
      "         [[ 7.9494e-02,  1.9629e-02, -1.4942e-02,  ..., -3.9482e-02,\n",
      "            2.1056e-02, -1.7007e-02],\n",
      "          [ 4.6344e-01, -1.4725e-01,  8.2258e-01,  ...,  3.4143e-01,\n",
      "            6.6488e-02, -1.0046e+00],\n",
      "          [ 4.0348e-01, -8.7195e-01, -1.1793e+00,  ...,  1.0580e+00,\n",
      "            5.7153e-01,  5.3592e-01],\n",
      "          ...,\n",
      "          [-6.6896e-01,  1.4602e-01,  1.4269e+00,  ..., -1.1985e-01,\n",
      "            1.1612e+00,  2.0802e+00],\n",
      "          [-2.0435e-01,  2.5427e-01,  8.5200e-01,  ..., -8.8234e-01,\n",
      "            9.5405e-01,  4.8340e-01],\n",
      "          [ 8.2470e-01,  1.2348e-01, -1.8963e-02,  ..., -2.7635e-01,\n",
      "            3.8721e-01,  7.9089e-01]],\n",
      "\n",
      "         [[ 6.5061e-02,  1.7394e-02, -1.3197e-02,  ...,  1.9595e-02,\n",
      "           -6.2144e-02, -6.3763e-02],\n",
      "          [-1.1359e-02,  6.8293e-01, -8.8521e-01,  ..., -8.8195e-01,\n",
      "           -9.2533e-01,  1.0995e+00],\n",
      "          [ 7.2526e-01, -6.4550e-01, -1.0321e-01,  ..., -6.4715e-01,\n",
      "           -5.5848e-01,  1.3314e+00],\n",
      "          ...,\n",
      "          [-6.7675e-01, -1.5009e-01, -6.6685e-01,  ..., -4.3112e-01,\n",
      "           -8.0608e-01, -2.0868e-01],\n",
      "          [-6.1433e-01, -2.4865e-01, -3.9539e-01,  ..., -1.8268e+00,\n",
      "            3.9165e-01, -1.5418e+00],\n",
      "          [-3.6172e-01, -6.2750e-01, -3.1816e-01,  ..., -9.2306e-02,\n",
      "            2.7719e-01,  3.6233e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2369e-03,  2.0590e-02,  1.8059e-02,  ..., -6.7566e-02,\n",
      "           -2.1130e-02,  1.0344e-02],\n",
      "          [-2.6505e-01,  6.8229e-02, -5.8064e-01,  ...,  2.0919e+00,\n",
      "           -2.0487e-01, -6.2631e-02],\n",
      "          [-1.1090e+00, -4.0114e-01,  6.4974e-01,  ...,  1.8533e+00,\n",
      "           -5.9498e-01, -1.5189e+00],\n",
      "          ...,\n",
      "          [-1.7999e-01, -1.3203e+00, -4.0722e-01,  ...,  5.0378e-01,\n",
      "           -6.4837e-01,  2.0433e-01],\n",
      "          [ 1.6616e-01, -6.4843e-02,  4.4673e-01,  ..., -1.3760e+00,\n",
      "           -1.5886e+00,  1.6740e+00],\n",
      "          [-2.3218e-01, -1.0700e+00, -2.0870e-01,  ...,  4.2789e-01,\n",
      "            1.3457e-01,  4.9070e-01]],\n",
      "\n",
      "         [[ 4.5884e-02, -1.3652e-02,  3.3538e-02,  ...,  4.2297e-02,\n",
      "           -1.0651e-02,  1.3725e-02],\n",
      "          [ 6.7968e-01, -6.1345e-01, -5.1771e-01,  ...,  3.9566e-01,\n",
      "           -6.3267e-01, -7.4087e-01],\n",
      "          [ 3.2293e-01, -5.0785e-01, -2.0837e+00,  ...,  1.2406e+00,\n",
      "            3.0909e-01,  7.6786e-01],\n",
      "          ...,\n",
      "          [ 6.6215e-01,  1.4883e+00, -1.3764e+00,  ..., -8.5867e-01,\n",
      "           -9.7664e-01,  7.5940e-02],\n",
      "          [-3.7327e-01,  1.0781e+00, -1.1749e+00,  ...,  1.5869e-02,\n",
      "           -8.2584e-01, -8.5889e-01],\n",
      "          [-1.0721e-01, -2.9212e-01, -1.0636e+00,  ...,  4.9721e-01,\n",
      "           -3.1657e-02, -7.9183e-02]],\n",
      "\n",
      "         [[ 7.6791e-02, -2.0113e-01, -8.1943e-02,  ..., -2.3764e-02,\n",
      "            2.0464e-01, -5.6837e-02],\n",
      "          [ 9.9647e-02, -2.1344e+00,  4.2548e-02,  ...,  4.3812e-01,\n",
      "           -7.9336e-01,  4.1660e-01],\n",
      "          [-1.0473e-01, -8.4764e-01, -1.0118e-01,  ...,  7.0098e-01,\n",
      "           -6.8366e-02, -1.1925e-01],\n",
      "          ...,\n",
      "          [ 8.6353e-02,  2.0148e+00, -7.8215e-01,  ...,  1.2433e+00,\n",
      "           -1.2465e+00,  8.4485e-02],\n",
      "          [ 2.1874e-01,  1.7080e+00, -7.7510e-01,  ...,  2.0696e-01,\n",
      "            1.1354e-02,  1.2248e-01],\n",
      "          [-9.0595e-01, -7.8929e-01,  2.8046e-02,  ...,  1.5975e-01,\n",
      "           -3.9888e-01,  8.6554e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0446, -0.2861, -0.1417,  ...,  0.6163,  0.7392, -0.3206],\n",
      "          [-3.9079, -2.3097,  2.2869,  ..., -1.0490, -3.9810,  0.3166],\n",
      "          [-4.8613, -0.9516,  2.6062,  ..., -0.0303, -3.9882, -0.5383],\n",
      "          ...,\n",
      "          [-3.5567, -2.6193,  0.7828,  ...,  0.6872, -4.4898, -0.6281],\n",
      "          [-4.2590, -1.7552,  2.8268,  ..., -0.6523, -4.0929, -0.2955],\n",
      "          [-4.9762, -1.9708,  0.0080,  ..., -0.3365, -3.7900, -0.1139]],\n",
      "\n",
      "         [[-0.1387, -0.0569,  0.1582,  ..., -0.0465, -0.8847, -0.2043],\n",
      "          [-0.5542, -0.0729, -0.3130,  ..., -0.0560, -0.7031,  1.6099],\n",
      "          [-1.3839,  1.4181, -0.2936,  ...,  1.3373, -1.0466,  1.9511],\n",
      "          ...,\n",
      "          [-1.8806,  0.3803, -1.2217,  ...,  1.7803,  0.9103,  0.4690],\n",
      "          [-1.2040,  1.6865, -0.4972,  ...,  0.5542, -0.4544,  1.0700],\n",
      "          [-2.2268,  0.3460, -1.5116,  ...,  0.5357, -0.8997,  0.5252]],\n",
      "\n",
      "         [[ 0.1924,  0.3075,  1.1360,  ..., -0.4682,  0.4283, -0.5042],\n",
      "          [ 1.1163, -0.8514, -1.3363,  ..., -0.5048, -2.3173,  1.4079],\n",
      "          [-0.4352, -0.6518, -1.4657,  ...,  0.3762, -3.2430,  2.4583],\n",
      "          ...,\n",
      "          [-1.2546, -1.4138, -1.6076,  ..., -2.2605, -1.6244, -0.5993],\n",
      "          [-0.4396, -2.4026, -0.8960,  ..., -1.1734, -1.3114,  0.8956],\n",
      "          [ 0.6041, -1.4925, -0.8934,  ..., -1.4043, -2.3182,  1.5456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1552,  0.0680, -0.2229,  ..., -0.0112,  0.1523,  0.0379],\n",
      "          [-1.4715, -0.2699, -1.0010,  ...,  0.9816, -0.0131, -0.5940],\n",
      "          [-2.8031, -0.0749, -0.5765,  ...,  1.4030,  0.5713, -0.3813],\n",
      "          ...,\n",
      "          [-0.7421,  0.1682,  1.1091,  ...,  0.2662, -1.0974, -1.7564],\n",
      "          [ 0.5485,  0.4741,  1.4970,  ..., -0.3822, -0.6439, -1.4745],\n",
      "          [-1.9331,  1.2431, -0.7142,  ...,  0.8943, -0.3290, -0.2887]],\n",
      "\n",
      "         [[-0.3520, -2.1820,  0.1305,  ..., -0.0781, -0.0452,  0.9126],\n",
      "          [-0.1676,  0.7424,  0.8457,  ..., -0.0430, -0.6897,  0.9972],\n",
      "          [-1.0619,  3.2376,  2.5831,  ...,  0.4896,  0.5569,  1.1650],\n",
      "          ...,\n",
      "          [ 0.1921,  4.7669, -0.9619,  ...,  0.1920,  0.0281, -1.6348],\n",
      "          [-0.3346,  4.0043,  0.8320,  ...,  1.9739,  0.4835,  0.2861],\n",
      "          [-0.4076,  1.6655, -1.2985,  ...,  1.3795, -0.0910,  1.3841]],\n",
      "\n",
      "         [[ 0.3705,  0.0804, -0.1422,  ...,  0.6539,  0.1286,  0.2599],\n",
      "          [ 0.2785, -0.1845, -0.7767,  ..., -0.6425,  0.7165, -1.3394],\n",
      "          [-0.0426, -1.2866, -0.2084,  ...,  0.4318,  1.4718,  0.1445],\n",
      "          ...,\n",
      "          [-2.9565, -2.3736, -1.0456,  ...,  0.5869, -0.2452, -0.1996],\n",
      "          [-2.0673, -1.9636,  0.6297,  ..., -1.2112, -0.6369,  2.2856],\n",
      "          [-1.5174, -0.1974,  1.0155,  ...,  0.1546,  0.5188,  1.0438]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-3.2128e-02,  4.2769e-02, -6.2959e-02,  ..., -2.4990e-02,\n",
      "           -5.5757e-04,  1.9665e-02],\n",
      "          [ 5.3965e-01,  1.5681e-02, -8.6195e-01,  ..., -6.3801e-01,\n",
      "            3.3483e-02,  2.0060e-01],\n",
      "          [-2.2824e-02,  1.7671e-01, -1.9057e-01,  ..., -6.8474e-01,\n",
      "           -7.3559e-01,  5.6330e-01],\n",
      "          ...,\n",
      "          [-5.3655e-01, -6.8140e-01, -2.7338e-01,  ..., -8.9929e-01,\n",
      "            6.7783e-01, -7.7594e-02],\n",
      "          [-6.6499e-02, -2.1919e-01,  7.2967e-01,  ...,  3.1051e-01,\n",
      "           -9.1984e-01,  1.6034e+00],\n",
      "          [-4.6004e-02,  1.7540e-01, -1.4991e-01,  ..., -3.8299e-01,\n",
      "           -1.2224e-01,  3.0644e-01]],\n",
      "\n",
      "         [[ 8.2082e-03, -2.1715e-02,  3.5759e-02,  ...,  2.5118e-02,\n",
      "           -4.6394e-02,  1.3449e-02],\n",
      "          [-5.6013e-01, -4.7913e-01, -7.3465e-01,  ...,  2.4955e-01,\n",
      "           -2.2302e-01,  1.7230e-02],\n",
      "          [-2.6670e-01, -5.7562e-02, -1.0933e+00,  ...,  6.9102e-01,\n",
      "            8.8651e-01,  2.3363e-01],\n",
      "          ...,\n",
      "          [ 1.4549e+00,  6.2701e-01,  3.4483e-01,  ..., -2.6119e-01,\n",
      "           -1.8188e-01,  2.0104e-01],\n",
      "          [ 9.1125e-01, -5.0901e-01,  1.7518e-01,  ...,  4.0393e-02,\n",
      "           -8.2194e-03, -6.1320e-01],\n",
      "          [-3.7897e-01, -1.3483e-01,  9.1876e-02,  ...,  3.8443e-01,\n",
      "            4.2697e-01, -3.3593e-01]],\n",
      "\n",
      "         [[ 5.1188e-02, -3.5194e-02,  2.7533e-02,  ...,  1.4181e-02,\n",
      "           -6.4940e-03,  2.2787e-02],\n",
      "          [ 5.1446e-01, -1.3208e+00, -1.0446e+00,  ...,  1.7527e-02,\n",
      "            1.7641e+00, -3.5737e-01],\n",
      "          [-2.7716e-01,  6.2414e-02, -1.8526e+00,  ..., -4.1313e-01,\n",
      "           -5.6179e-01,  1.0078e+00],\n",
      "          ...,\n",
      "          [ 4.1809e-01, -5.0762e-02, -3.4584e-01,  ..., -1.2960e+00,\n",
      "           -5.4343e-01, -1.4812e-01],\n",
      "          [ 1.5966e-01, -1.5908e-01, -2.6502e-01,  ..., -2.6891e-01,\n",
      "            1.3304e+00, -6.3225e-01],\n",
      "          [ 4.6884e-01, -2.5218e-01, -6.3545e-01,  ..., -2.6028e+00,\n",
      "            3.5557e-02, -2.5807e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8817e-01,  7.5630e-02,  5.1482e-02,  ...,  6.3044e-02,\n",
      "            4.5983e-02, -1.2272e-01],\n",
      "          [-4.8166e-01, -8.0081e-01,  4.7553e-01,  ...,  9.2073e-01,\n",
      "            1.4889e+00, -4.9100e-01],\n",
      "          [ 3.1190e-01, -1.7164e+00, -6.4195e-01,  ..., -3.0160e-01,\n",
      "            9.8333e-01, -1.3910e+00],\n",
      "          ...,\n",
      "          [ 2.6294e-01,  1.7654e-01, -2.2927e-01,  ..., -5.6709e-01,\n",
      "           -4.2601e-01,  1.8268e-01],\n",
      "          [-1.2287e+00, -8.8129e-01, -4.9618e-01,  ...,  5.7656e-01,\n",
      "           -9.3972e-02,  9.1813e-01],\n",
      "          [-5.2435e-01, -5.0482e-01, -6.5543e-01,  ..., -9.4711e-02,\n",
      "            2.7462e-01, -4.3348e-01]],\n",
      "\n",
      "         [[-5.8365e-01, -2.0280e-02,  4.3795e-02,  ..., -1.2728e-02,\n",
      "            1.4847e-02, -1.1488e-02],\n",
      "          [ 2.1189e-01,  6.3309e-01, -8.5212e-01,  ...,  1.7115e-02,\n",
      "           -1.6814e-01,  3.3735e-01],\n",
      "          [-5.0398e-01,  1.2201e-01, -9.9508e-01,  ...,  1.0425e+00,\n",
      "            5.1320e-01,  8.6971e-01],\n",
      "          ...,\n",
      "          [-1.4073e+00,  4.5373e-01, -1.8494e-01,  ...,  1.0106e-01,\n",
      "            1.1485e+00, -5.4966e-02],\n",
      "          [-7.8669e-01, -4.6794e-01,  8.1497e-02,  ..., -6.6191e-01,\n",
      "            9.3902e-01, -4.7145e-01],\n",
      "          [-2.6530e+00, -1.3969e-01,  2.4383e-01,  ..., -2.2311e-01,\n",
      "            4.6452e-01,  3.6028e-01]],\n",
      "\n",
      "         [[ 1.8879e-02,  8.3848e-02, -5.0716e-02,  ...,  5.5664e-02,\n",
      "            2.9355e-02, -4.1400e-02],\n",
      "          [-3.1205e-01,  3.7567e-01,  3.4224e-01,  ...,  7.1520e-01,\n",
      "            7.5321e-01, -1.1299e-01],\n",
      "          [-1.0119e+00,  3.3448e-01, -1.2705e+00,  ..., -8.8392e-01,\n",
      "           -2.3355e+00, -2.2953e-01],\n",
      "          ...,\n",
      "          [ 1.9421e-01,  1.2625e+00,  6.1021e-01,  ...,  1.0141e+00,\n",
      "           -1.3892e-01, -3.8717e-01],\n",
      "          [-1.6888e+00,  1.0561e+00,  6.2911e-01,  ..., -7.9248e-01,\n",
      "           -1.2793e+00,  2.5451e-02],\n",
      "          [-6.8985e-01,  3.8036e-01,  1.1172e+00,  ..., -3.2168e-01,\n",
      "           -9.4463e-01,  8.1670e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-3.0739e-02, -2.3328e+00,  1.6444e-01,  ..., -2.4874e-01,\n",
      "           -2.1955e-01,  6.7818e-02],\n",
      "          [ 6.6502e-01,  3.8897e+00,  2.5626e-01,  ..., -1.2447e+00,\n",
      "           -5.1476e-01,  1.7492e-01],\n",
      "          [ 2.3555e-01,  4.3144e+00,  1.5203e+00,  ..., -1.0305e+00,\n",
      "           -2.7401e-01, -2.9700e-01],\n",
      "          ...,\n",
      "          [-7.4795e-01,  6.0315e+00,  1.4481e+00,  ..., -1.7219e+00,\n",
      "            1.5043e-01,  3.6442e-02],\n",
      "          [-1.1906e+00,  6.0815e+00,  7.5815e-01,  ...,  7.6926e-03,\n",
      "            1.6461e+00, -4.0052e-01],\n",
      "          [-7.7746e-01,  4.0435e+00,  8.6778e-01,  ..., -1.0730e+00,\n",
      "            3.5681e-01, -7.8313e-01]],\n",
      "\n",
      "         [[-8.1230e-01,  2.0313e-01,  4.6825e-01,  ..., -5.1517e-01,\n",
      "            1.0709e+00,  1.1254e+00],\n",
      "          [ 1.9943e-01,  7.3408e-02,  1.8181e+00,  ..., -3.0854e-01,\n",
      "            1.3158e+00,  6.8892e-02],\n",
      "          [ 3.2874e-01, -6.4358e-01,  2.3493e+00,  ..., -1.5555e-01,\n",
      "            2.4417e+00,  1.8911e-01],\n",
      "          ...,\n",
      "          [ 6.9652e-01,  1.3289e+00, -4.7835e-01,  ..., -1.1337e+00,\n",
      "            6.5288e-01, -2.0380e+00],\n",
      "          [ 2.1073e-01,  1.0003e+00,  1.2394e+00,  ..., -6.3918e-01,\n",
      "            8.0475e-01, -1.5733e+00],\n",
      "          [ 3.1132e-01,  2.8403e-01,  2.9093e-01,  ..., -1.5865e+00,\n",
      "            3.1738e+00, -7.4550e-01]],\n",
      "\n",
      "         [[-8.3052e-01,  4.9202e-01,  1.5700e-02,  ...,  5.0540e-01,\n",
      "           -2.3221e-01,  1.1760e+00],\n",
      "          [ 1.8285e+00, -1.1218e+00, -6.0110e-01,  ...,  1.7362e-01,\n",
      "            1.3459e+00,  1.1774e-01],\n",
      "          [ 1.6429e+00, -2.1772e+00,  1.7248e+00,  ...,  3.0036e-01,\n",
      "            7.7876e-01,  9.9058e-01],\n",
      "          ...,\n",
      "          [ 1.0010e+00, -1.7313e+00,  1.9045e+00,  ...,  8.0702e-01,\n",
      "            5.2974e-01, -6.8052e-01],\n",
      "          [ 1.5992e+00, -2.7915e+00,  1.0877e+00,  ...,  7.4602e-01,\n",
      "            3.0332e-02, -1.3237e+00],\n",
      "          [ 1.6438e+00, -9.9109e-01,  9.2324e-01,  ...,  1.1409e+00,\n",
      "            5.9684e-01, -3.3017e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0107e-01, -1.1655e-01,  1.3441e-01,  ...,  1.8965e-01,\n",
      "            1.7320e+00, -2.8680e+00],\n",
      "          [ 1.9154e+00,  1.2091e+00,  2.8645e-01,  ...,  1.3748e-01,\n",
      "           -3.8644e+00,  3.9812e+00],\n",
      "          [ 9.2973e-01, -1.0160e-01, -1.3099e-02,  ..., -3.6517e-01,\n",
      "           -4.1451e+00,  4.7426e+00],\n",
      "          ...,\n",
      "          [ 5.7876e-01, -5.6903e-01, -9.7981e-01,  ..., -1.5678e+00,\n",
      "           -5.4191e+00,  5.7578e+00],\n",
      "          [-1.9895e-01, -5.5637e-01, -4.0058e-01,  ..., -1.3523e+00,\n",
      "           -5.3991e+00,  5.7263e+00],\n",
      "          [ 1.0074e-01,  9.1534e-01,  5.5960e-01,  ..., -1.0116e+00,\n",
      "           -5.7379e+00,  5.5124e+00]],\n",
      "\n",
      "         [[ 1.8309e-01,  3.5898e-01,  2.1865e-01,  ..., -2.1976e-01,\n",
      "            3.2432e-02, -1.3621e-01],\n",
      "          [-1.1902e+00,  2.5967e-01,  1.3770e+00,  ...,  1.6082e+00,\n",
      "            5.3296e-01,  1.0141e-01],\n",
      "          [-1.6201e+00,  3.1865e-01,  5.4789e-01,  ...,  7.9333e-01,\n",
      "            4.1223e-01, -9.2892e-01],\n",
      "          ...,\n",
      "          [-1.7144e+00,  2.9198e-01, -6.5764e-01,  ...,  1.4415e+00,\n",
      "           -4.7544e-02,  6.2226e-01],\n",
      "          [-1.0669e+00,  9.0313e-01, -9.0603e-01,  ...,  1.4476e+00,\n",
      "           -3.0205e-01, -8.2349e-01],\n",
      "          [-6.1682e-01,  4.0207e-01, -2.7279e-01,  ...,  1.9482e+00,\n",
      "           -5.3192e-01, -1.6915e-01]],\n",
      "\n",
      "         [[ 3.8544e-01,  1.1505e-01,  6.3900e-01,  ...,  5.3104e-01,\n",
      "            5.7931e-01, -3.3185e-01],\n",
      "          [ 4.0666e-01, -9.3643e-01, -1.0314e+00,  ..., -6.5106e-01,\n",
      "           -3.1251e+00, -3.6746e-01],\n",
      "          [ 9.7926e-01, -9.1059e-01,  2.0969e-01,  ..., -1.8782e+00,\n",
      "           -3.4683e+00,  2.0600e-01],\n",
      "          ...,\n",
      "          [-1.4226e-01, -9.7476e-01, -5.4240e-01,  ..., -2.8039e+00,\n",
      "           -4.1771e+00,  1.9208e+00],\n",
      "          [-7.5886e-01, -6.7514e-01, -4.4395e-02,  ..., -2.4649e+00,\n",
      "           -4.5963e+00,  6.7639e-01],\n",
      "          [-6.9450e-01,  4.6577e-01, -7.3801e-01,  ..., -2.1795e+00,\n",
      "           -4.2150e+00,  2.8132e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 5.3734e-02, -1.4238e-02, -3.5810e-02,  ...,  1.2174e-01,\n",
      "           -5.9948e-02, -4.3049e-02],\n",
      "          [-4.0712e-01,  2.3952e-01, -1.4630e-01,  ..., -4.0966e-01,\n",
      "            8.4789e-01, -2.2644e-01],\n",
      "          [-1.4474e+00, -8.4849e-01, -9.8838e-02,  ..., -2.0224e-01,\n",
      "            6.6301e-01,  7.1867e-01],\n",
      "          ...,\n",
      "          [-6.3025e-01, -9.1939e-01,  1.5612e+00,  ...,  6.4965e-01,\n",
      "            2.6919e+00,  8.4095e-01],\n",
      "          [-5.2483e-01, -1.3637e+00,  1.8403e+00,  ...,  3.8219e-01,\n",
      "            1.4497e+00,  1.0683e-03],\n",
      "          [-2.9674e-02,  1.7135e-01, -7.6390e-01,  ..., -3.9354e-01,\n",
      "            4.4974e-01, -9.9768e-01]],\n",
      "\n",
      "         [[ 1.7320e-02,  2.3816e-02,  4.7974e-02,  ..., -4.7309e-03,\n",
      "           -6.8243e-03,  3.2884e-03],\n",
      "          [ 5.4060e-01,  1.3387e+00,  1.0772e+00,  ..., -4.1182e-01,\n",
      "           -7.2695e-02,  7.3047e-01],\n",
      "          [ 1.6604e+00, -1.0405e+00, -4.6418e-02,  ..., -1.5549e-01,\n",
      "            4.8930e-01,  2.6706e-01],\n",
      "          ...,\n",
      "          [-2.6609e-02,  1.4448e+00, -9.6231e-02,  ...,  1.4043e+00,\n",
      "           -2.1171e-01,  6.2546e-01],\n",
      "          [ 1.7877e+00, -7.9523e-01,  3.4070e-01,  ..., -1.0215e+00,\n",
      "            5.2032e-01, -7.5460e-01],\n",
      "          [-6.6356e-01,  7.8232e-01,  8.1055e-01,  ..., -6.7723e-01,\n",
      "           -5.3982e-01, -7.7323e-01]],\n",
      "\n",
      "         [[ 5.1727e-02, -3.2729e-02,  6.2676e-02,  ...,  3.5751e-02,\n",
      "           -7.1613e-02, -5.9328e-02],\n",
      "          [-3.5343e-01,  7.5885e-01, -4.1293e-02,  ...,  2.4424e-01,\n",
      "           -6.9912e-01, -5.4976e-01],\n",
      "          [ 7.8512e-02, -4.0856e-01,  5.3512e-01,  ..., -8.2215e-01,\n",
      "            1.6102e-03, -5.0301e-01],\n",
      "          ...,\n",
      "          [-7.4352e-01,  2.1682e-01,  5.4941e-01,  ..., -7.3409e-01,\n",
      "            5.1859e-01,  4.1631e-02],\n",
      "          [-3.8653e-01,  1.1920e+00, -2.0321e-01,  ..., -1.3420e-01,\n",
      "           -2.3149e-01, -1.5669e-01],\n",
      "          [-6.5035e-01,  1.6409e-01, -2.7168e-01,  ..., -5.6859e-02,\n",
      "            3.0424e-01,  6.7128e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5711e-02, -3.3712e-02,  3.5806e-02,  ..., -9.8101e-02,\n",
      "            3.3037e-02,  2.1276e-02],\n",
      "          [-1.0548e+00,  1.0086e+00,  3.5336e-01,  ...,  1.4173e-01,\n",
      "            1.1533e+00, -5.7750e-01],\n",
      "          [ 3.0501e-01,  3.8879e-01,  1.4593e+00,  ..., -1.5761e+00,\n",
      "            6.6029e-01, -2.4784e+00],\n",
      "          ...,\n",
      "          [ 2.1433e-01,  3.0902e-01, -1.5677e-01,  ..., -1.4376e+00,\n",
      "            3.1234e-01, -1.5930e-01],\n",
      "          [ 9.2111e-02,  1.3849e+00, -3.5478e-01,  ..., -2.0249e+00,\n",
      "            1.7484e+00,  1.5088e+00],\n",
      "          [ 1.0588e+00,  5.0693e-02,  1.6493e-02,  ..., -3.3869e-01,\n",
      "            6.8473e-01,  6.6574e-02]],\n",
      "\n",
      "         [[ 1.5089e-01, -6.4248e-02,  1.3481e-01,  ...,  7.3110e-02,\n",
      "            4.8974e-03, -1.2889e-01],\n",
      "          [ 6.8720e-01,  5.7470e-02, -1.7870e-01,  ..., -1.1156e+00,\n",
      "           -1.2297e+00,  1.5927e-02],\n",
      "          [ 4.6848e-01,  6.8089e-01,  4.5960e-01,  ..., -3.4666e-01,\n",
      "           -8.2155e-01,  7.9260e-01],\n",
      "          ...,\n",
      "          [-6.8295e-01, -4.1632e-01, -3.1648e-01,  ..., -1.0120e+00,\n",
      "           -1.2630e+00,  4.1550e-01],\n",
      "          [ 3.2675e-02, -5.2766e-01, -1.6868e+00,  ..., -9.0995e-01,\n",
      "           -2.2853e-01,  1.4612e+00],\n",
      "          [ 2.0993e-01, -2.2174e-01,  1.0833e+00,  ..., -6.0768e-01,\n",
      "            6.2882e-01,  8.7863e-02]],\n",
      "\n",
      "         [[ 2.1724e-01, -6.2232e-02, -5.5712e-02,  ...,  2.1461e-02,\n",
      "            4.3089e-02,  3.7415e-02],\n",
      "          [ 1.3125e+00, -4.4910e-01, -7.5738e-01,  ...,  3.2747e-01,\n",
      "           -9.8980e-02, -8.0641e-02],\n",
      "          [-1.6063e-01, -7.7957e-01, -1.6312e-01,  ..., -4.8402e-01,\n",
      "            8.7137e-01, -2.5966e-01],\n",
      "          ...,\n",
      "          [-3.6798e-01,  5.0565e-01,  2.8998e-01,  ...,  2.5920e-01,\n",
      "           -1.9344e+00,  7.5728e-01],\n",
      "          [ 4.9460e-02, -4.9568e-01,  8.4527e-01,  ..., -3.3127e-01,\n",
      "            6.4243e-01, -3.5335e-01],\n",
      "          [ 1.1826e-01, -1.5026e-01,  9.7509e-01,  ...,  4.7500e-01,\n",
      "           -8.4105e-01,  6.5077e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.3000e-02, -2.4427e-01, -4.4500e-01,  ...,  3.0083e-01,\n",
      "            3.2684e-01,  3.6586e-01],\n",
      "          [-3.1921e-01,  1.1035e+00, -8.1620e-01,  ..., -1.0129e+00,\n",
      "           -1.0356e-01, -3.4720e-01],\n",
      "          [ 1.2050e-01,  8.5493e-01, -4.7644e-01,  ...,  2.5663e-01,\n",
      "           -7.2198e-01,  7.0494e-01],\n",
      "          ...,\n",
      "          [-3.0341e-01,  2.8500e-03,  4.0952e-01,  ...,  2.3109e+00,\n",
      "           -8.2102e-01, -3.8004e-01],\n",
      "          [-3.2070e-03,  2.9617e-01, -1.1834e-01,  ...,  3.1173e+00,\n",
      "            4.8563e-01,  1.0006e+00],\n",
      "          [ 4.6373e-01, -9.1019e-02, -9.6269e-01,  ...,  6.1472e-01,\n",
      "           -6.0768e-01,  9.6789e-01]],\n",
      "\n",
      "         [[-2.7947e-01,  1.5264e-01,  1.2265e-01,  ...,  6.3868e-02,\n",
      "           -1.1406e+00, -1.3803e-01],\n",
      "          [ 7.5798e-01,  7.3406e-01,  2.4232e+00,  ..., -1.7083e-01,\n",
      "           -1.2876e+00,  6.4982e-01],\n",
      "          [ 5.9163e-01, -2.5393e-01,  9.1644e-01,  ...,  1.4073e+00,\n",
      "           -9.9605e-01,  1.3304e+00],\n",
      "          ...,\n",
      "          [ 2.9273e-01, -3.5705e-01,  1.8072e+00,  ...,  5.2217e-01,\n",
      "           -1.9019e+00, -1.5490e+00],\n",
      "          [-3.1270e-02,  1.4249e-01,  1.4840e+00,  ...,  4.6309e-01,\n",
      "           -1.1398e+00, -3.6930e-01],\n",
      "          [-1.5090e-01,  1.7000e+00,  1.0501e+00,  ...,  4.5167e-01,\n",
      "            8.9898e-01,  2.7553e-01]],\n",
      "\n",
      "         [[-1.2364e+00, -1.0861e-01,  5.7612e-01,  ..., -6.5710e-01,\n",
      "            4.6449e-01, -2.9151e-01],\n",
      "          [ 5.4201e-01,  4.5983e-01, -1.3218e-01,  ...,  6.8797e-01,\n",
      "            3.7853e-01,  7.0103e-01],\n",
      "          [ 1.0557e+00,  3.7951e-01,  9.9993e-02,  ...,  1.0149e+00,\n",
      "           -8.0008e-02,  3.1117e-01],\n",
      "          ...,\n",
      "          [ 2.7617e+00,  9.2056e-01,  2.5572e+00,  ..., -2.7046e-01,\n",
      "           -2.6544e-01,  4.2675e-01],\n",
      "          [ 3.2526e+00,  2.6460e+00,  1.0609e+00,  ...,  4.3606e-01,\n",
      "           -1.4836e-01,  5.3355e-01],\n",
      "          [ 1.2066e+00,  2.9331e+00,  7.7203e-03,  ...,  6.1325e-01,\n",
      "           -1.2444e+00,  4.3294e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8954e-01, -9.0881e-01, -3.9374e-01,  ..., -1.0515e+00,\n",
      "           -4.3844e-01,  4.8402e-01],\n",
      "          [ 1.0609e+00, -1.1448e+00, -7.7389e-01,  ..., -4.1185e-01,\n",
      "           -8.2883e-01, -6.0351e-01],\n",
      "          [ 5.0185e-01, -6.5958e-01, -5.7256e-02,  ..., -1.2351e+00,\n",
      "           -6.1601e-01, -5.3572e-01],\n",
      "          ...,\n",
      "          [ 2.8482e-01,  9.0139e-01, -4.6546e-01,  ..., -1.0758e+00,\n",
      "            5.9336e-01, -1.4398e+00],\n",
      "          [-1.4410e+00,  1.8157e+00, -1.4097e-01,  ..., -1.1282e+00,\n",
      "            1.1474e+00, -1.1473e+00],\n",
      "          [ 9.0526e-01,  2.4593e-01, -1.1596e+00,  ...,  3.7836e-01,\n",
      "           -1.2631e+00, -4.5477e-01]],\n",
      "\n",
      "         [[-9.2652e-01,  2.5459e+00,  3.0600e-01,  ...,  3.4490e-01,\n",
      "            1.9553e+00, -5.4894e-01],\n",
      "          [ 4.5858e-01, -2.1932e+00,  1.7457e-01,  ...,  1.7436e+00,\n",
      "           -2.5849e+00,  2.2585e+00],\n",
      "          [ 1.7932e-02, -2.7316e+00,  2.1564e-01,  ...,  6.8611e-01,\n",
      "           -4.1920e+00,  1.6138e+00],\n",
      "          ...,\n",
      "          [ 2.3517e-01, -6.8795e+00,  2.4382e+00,  ...,  1.0712e+00,\n",
      "           -3.7377e+00,  2.1150e+00],\n",
      "          [-5.6485e-01, -5.2606e+00,  1.9043e+00,  ...,  6.5478e-01,\n",
      "           -4.0746e+00,  7.2067e-01],\n",
      "          [-4.5100e-02, -3.6478e+00,  1.7280e-01,  ..., -7.5855e-01,\n",
      "           -4.0225e+00,  1.6237e+00]],\n",
      "\n",
      "         [[-2.0252e+00, -3.5049e-01, -1.1153e+00,  ..., -3.9788e-01,\n",
      "            6.0882e-02,  2.5314e-01],\n",
      "          [ 2.0696e+00, -4.9512e-01,  1.0584e+00,  ...,  7.4010e-01,\n",
      "            4.9070e-01,  5.7455e-01],\n",
      "          [ 2.5638e+00,  1.1148e+00, -5.5302e-01,  ...,  1.2067e-01,\n",
      "            3.6514e-01, -1.7264e-01],\n",
      "          ...,\n",
      "          [ 4.7496e+00, -1.1327e+00,  3.4154e+00,  ...,  1.0882e+00,\n",
      "            5.4831e-01, -2.3920e-01],\n",
      "          [ 3.7342e+00, -7.3702e-01,  2.6068e+00,  ...,  3.8731e-01,\n",
      "           -4.0681e-01, -8.3097e-01],\n",
      "          [ 2.0753e+00,  1.0187e+00,  2.0027e+00,  ...,  5.9608e-01,\n",
      "           -1.2866e-01, -3.3631e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.9407e-02, -8.5679e-02,  1.7006e-02,  ...,  1.0696e-01,\n",
      "           -2.7256e-02,  1.2712e-02],\n",
      "          [-1.1028e-01, -2.6695e-01, -2.7972e-01,  ...,  7.3320e-02,\n",
      "            8.1304e-02,  9.9563e-01],\n",
      "          [ 2.2058e-01,  5.5391e-01, -1.4877e+00,  ..., -2.8705e-01,\n",
      "            3.1862e-01,  8.9564e-01],\n",
      "          ...,\n",
      "          [-2.2597e+00,  4.0054e-01,  3.5313e-01,  ..., -3.1097e-01,\n",
      "           -6.2333e-01,  6.2798e-02],\n",
      "          [-4.0290e-01,  4.4471e-01, -5.3869e-01,  ...,  3.8806e-01,\n",
      "            7.7051e-01, -8.9604e-02],\n",
      "          [-6.9789e-02,  9.6001e-01, -1.9557e-01,  ...,  1.2244e+00,\n",
      "           -4.5771e-01, -4.4116e-01]],\n",
      "\n",
      "         [[ 1.9984e-02,  9.9455e-03, -1.8535e-02,  ...,  2.8180e-02,\n",
      "            3.0411e-02,  5.3315e-02],\n",
      "          [ 5.9644e-01,  5.1996e-01, -1.2417e+00,  ..., -7.3599e-02,\n",
      "            1.1116e+00,  4.7235e-01],\n",
      "          [ 9.7821e-01, -1.1090e+00, -1.6003e-01,  ...,  1.1247e+00,\n",
      "           -1.9147e-01,  2.4299e-01],\n",
      "          ...,\n",
      "          [-2.4673e+00,  2.1871e+00,  1.5703e+00,  ..., -4.3629e-01,\n",
      "           -1.2542e-01, -6.9803e-01],\n",
      "          [ 2.0128e-01,  7.3901e-01, -9.9507e-01,  ..., -1.5172e+00,\n",
      "           -4.1022e-01, -5.7266e-01],\n",
      "          [ 2.5452e-02,  8.2747e-01, -5.4466e-01,  ..., -5.8290e-01,\n",
      "           -9.6744e-01, -4.3227e-01]],\n",
      "\n",
      "         [[ 3.0771e-02,  3.3925e-02, -9.5088e-02,  ...,  2.0078e-02,\n",
      "           -1.8055e-03,  3.6985e-03],\n",
      "          [-7.0360e-01,  1.2550e-01,  2.7324e-01,  ...,  2.4933e-01,\n",
      "           -1.0440e+00,  2.5170e+00],\n",
      "          [-3.4458e-01, -8.2069e-01, -4.0843e-01,  ..., -7.7839e-01,\n",
      "           -7.3081e-01, -2.8720e-01],\n",
      "          ...,\n",
      "          [-6.4247e-01,  2.9498e-01, -1.6238e+00,  ...,  1.0017e+00,\n",
      "           -4.7254e-01,  3.8370e-01],\n",
      "          [ 1.0750e-01,  5.6388e-01, -1.1467e+00,  ...,  4.9151e-01,\n",
      "            4.4171e-01,  4.7236e-01],\n",
      "          [-5.2674e-01,  6.2729e-01, -7.3630e-01,  ..., -9.5472e-02,\n",
      "           -3.0964e-01, -9.4150e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2988e-02,  1.8975e-02, -2.9906e-03,  ..., -2.4180e-03,\n",
      "           -7.7688e-04,  3.6506e-02],\n",
      "          [ 1.0896e+00, -5.7907e-01,  2.7873e-01,  ...,  5.9871e-01,\n",
      "            2.0423e+00, -1.8796e-01],\n",
      "          [ 1.1956e+00, -2.4500e-01,  9.7125e-01,  ...,  7.4841e-01,\n",
      "           -1.6449e-01, -7.1359e-01],\n",
      "          ...,\n",
      "          [-1.2320e+00,  2.2416e+00,  1.4954e+00,  ...,  3.9171e-01,\n",
      "           -3.1156e-01, -1.0704e+00],\n",
      "          [-9.0054e-01,  2.1070e-01, -2.4055e-01,  ..., -2.8735e-01,\n",
      "           -2.5012e-01, -2.8542e-01],\n",
      "          [ 1.7678e-01,  9.9594e-01, -1.2952e-01,  ...,  3.1505e-01,\n",
      "            1.0217e+00, -2.8011e-01]],\n",
      "\n",
      "         [[-6.6889e-02, -4.6806e-02,  1.3993e-02,  ...,  1.3800e-02,\n",
      "           -6.0449e-02, -1.0146e-01],\n",
      "          [-1.2984e-01, -3.9512e-01,  9.2746e-02,  ...,  2.9088e-01,\n",
      "            1.8776e-01, -2.5012e-02],\n",
      "          [ 1.4572e+00, -1.4012e-01,  1.1444e-01,  ...,  2.8305e-01,\n",
      "           -3.2234e-01, -1.2569e-01],\n",
      "          ...,\n",
      "          [ 7.1413e-01, -1.7208e+00,  6.2938e-02,  ..., -6.0424e-01,\n",
      "            3.3152e-01, -1.3289e+00],\n",
      "          [ 8.2656e-02, -8.4586e-02, -1.6153e+00,  ..., -2.1428e-01,\n",
      "           -1.4150e-01,  1.0627e+00],\n",
      "          [ 6.7371e-01, -6.1994e-01, -2.5474e-01,  ...,  3.9961e-01,\n",
      "            4.5265e-01,  4.9732e-01]],\n",
      "\n",
      "         [[-1.5357e-02,  3.5532e-02, -6.0959e-02,  ..., -2.2750e-02,\n",
      "            4.1216e-03,  3.3249e-03],\n",
      "          [-4.9697e-01, -9.3557e-01, -6.3136e-02,  ...,  6.6151e-01,\n",
      "            4.0965e-01, -7.5030e-02],\n",
      "          [-4.4716e-02, -6.6199e-01, -9.2861e-01,  ...,  5.9766e-01,\n",
      "            2.3181e-01, -2.1284e-01],\n",
      "          ...,\n",
      "          [ 9.3537e-01,  2.7058e-01,  1.1165e+00,  ..., -6.2206e-01,\n",
      "            2.9264e-01,  1.3320e+00],\n",
      "          [ 7.5008e-01,  1.0221e+00, -3.0353e-02,  ...,  1.3531e-01,\n",
      "            1.1982e+00,  1.2872e-02],\n",
      "          [-1.1730e+00, -6.0364e-01,  1.8613e-01,  ...,  4.8842e-01,\n",
      "           -8.2276e-02,  3.5773e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5168,  0.5003, -0.8527,  ..., -1.0179, -1.3143,  0.2035],\n",
      "          [ 0.5839,  0.4706, -0.0539,  ...,  0.7804, -0.5336, -0.4840],\n",
      "          [ 0.6194, -0.1866,  0.5777,  ...,  1.4978, -0.3987, -1.0123],\n",
      "          ...,\n",
      "          [ 1.3470,  0.3720, -0.5412,  ...,  1.6907, -0.3261, -0.6066],\n",
      "          [ 1.6338, -0.9301,  0.1403,  ...,  1.6979,  0.9465, -1.1397],\n",
      "          [ 1.0263, -0.0312,  0.4805,  ...,  1.9947, -0.4926, -1.0369]],\n",
      "\n",
      "         [[ 0.8600, -2.0708,  0.1513,  ...,  0.2453, -2.4785, -0.4229],\n",
      "          [ 1.3937, -0.5899,  1.3122,  ...,  1.7829, -0.9209,  0.0461],\n",
      "          [ 1.2642,  1.6078,  0.4370,  ...,  0.8510,  0.5742, -0.4311],\n",
      "          ...,\n",
      "          [-0.2522,  3.1486, -0.0085,  ...,  0.1856,  3.6584, -0.8100],\n",
      "          [ 0.7939,  1.4203,  0.2039,  ...,  0.5636,  2.3544, -1.3126],\n",
      "          [ 0.5796,  1.1935, -0.4128,  ..., -0.0242,  2.9575, -1.5629]],\n",
      "\n",
      "         [[ 1.0033,  0.3818, -0.1770,  ..., -0.8112, -1.4041, -0.3646],\n",
      "          [-0.8060, -0.2143, -1.7062,  ...,  1.3577, -0.0913,  0.3456],\n",
      "          [-0.1113, -0.4196, -1.3489,  ...,  1.2174,  0.0079,  0.0536],\n",
      "          ...,\n",
      "          [-3.3497, -0.2660,  0.2152,  ...,  1.4347,  0.1310,  1.4777],\n",
      "          [-1.0710, -0.9403, -2.2382,  ...,  1.8840, -0.8573,  0.6312],\n",
      "          [ 0.1759, -0.5456, -0.7188,  ...,  1.3544, -0.2407, -0.2945]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2209, -0.5819,  0.4830,  ..., -0.6500,  1.0846,  0.2841],\n",
      "          [-0.4176, -0.2444, -0.1033,  ..., -1.9155, -1.5817,  0.6707],\n",
      "          [-1.1385,  1.7267, -2.5488,  ..., -2.3843, -1.3253,  0.6908],\n",
      "          ...,\n",
      "          [-1.5273,  1.4584, -2.7749,  ..., -1.0319, -2.3548,  1.2913],\n",
      "          [-0.4061,  2.5040, -2.4008,  ..., -1.3577, -1.8418,  1.6940],\n",
      "          [-0.3213,  0.4250, -1.2700,  ..., -3.8195, -0.4979,  1.6445]],\n",
      "\n",
      "         [[ 0.2557,  0.5515,  0.5423,  ...,  0.7245,  0.0758,  0.8386],\n",
      "          [ 0.0373,  1.1293, -0.8812,  ...,  1.3053,  0.1991,  1.0668],\n",
      "          [ 0.1955,  1.5928, -0.9004,  ...,  0.8965, -0.3034, -0.3748],\n",
      "          ...,\n",
      "          [-0.0899,  2.2438, -0.5928,  ...,  0.3604, -1.3797, -0.0256],\n",
      "          [ 1.0178,  2.0922, -0.1509,  ...,  1.3384, -1.0962, -0.1963],\n",
      "          [ 1.6399,  1.9349,  1.2059,  ..., -0.5345, -1.0859,  0.4052]],\n",
      "\n",
      "         [[-0.7103,  0.3011, -1.5822,  ..., -0.4242,  0.2360, -1.3157],\n",
      "          [ 0.0054,  1.0721,  1.2615,  ...,  0.6028, -0.2910,  0.4983],\n",
      "          [-0.3964,  0.6106, -0.1719,  ...,  1.1167, -0.9742,  1.4335],\n",
      "          ...,\n",
      "          [ 1.7506,  0.9744,  1.3645,  ...,  1.5455,  0.3070,  1.9734],\n",
      "          [-0.9912,  0.5391,  1.5399,  ...,  0.9224,  0.0180,  3.2051],\n",
      "          [-0.3301,  0.1262,  2.0273,  ...,  2.3883,  0.8853, -0.5951]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-6.0669e-03,  4.1580e-02, -6.0121e-02,  ...,  5.8650e-02,\n",
      "           -5.0545e-02, -7.4066e-02],\n",
      "          [-1.3468e+00,  1.2899e-01,  1.0814e+00,  ..., -3.7751e-01,\n",
      "           -3.3316e-01, -2.1959e-01],\n",
      "          [-5.5962e-01,  5.0996e-01,  1.2739e+00,  ..., -3.0219e-01,\n",
      "            1.1735e-01,  8.0562e-01],\n",
      "          ...,\n",
      "          [ 4.0354e-01, -1.3779e+00, -1.7089e-01,  ..., -7.0931e-01,\n",
      "           -1.5366e+00,  4.9889e-01],\n",
      "          [-1.0464e-01,  6.3718e-01,  1.1747e+00,  ...,  3.1930e-01,\n",
      "           -1.4733e+00,  2.9720e-01],\n",
      "          [ 4.8980e-01, -3.8611e-02,  1.0899e+00,  ...,  3.5262e-01,\n",
      "           -1.5532e+00, -7.8569e-01]],\n",
      "\n",
      "         [[ 5.0298e-02, -3.1198e-03,  2.3202e-02,  ..., -2.5890e-02,\n",
      "           -1.5499e-02, -2.3228e-02],\n",
      "          [-1.0113e+00,  5.7627e-01,  4.9574e-01,  ..., -3.2675e-01,\n",
      "            1.8657e-01,  8.2123e-01],\n",
      "          [ 1.4849e-01,  7.7403e-01, -1.0155e+00,  ...,  3.1667e-01,\n",
      "           -1.8597e-01,  4.8591e-01],\n",
      "          ...,\n",
      "          [-1.2798e-01, -5.1137e-01,  1.0950e+00,  ...,  3.6580e+00,\n",
      "            2.7942e-02, -6.0400e-01],\n",
      "          [ 5.0271e-01, -1.6136e+00, -1.8023e-01,  ..., -5.1402e-02,\n",
      "            9.7688e-01, -1.7705e-01],\n",
      "          [-5.7576e-01,  2.3451e-01, -5.6927e-02,  ...,  1.7268e-01,\n",
      "            5.6935e-02,  1.5519e+00]],\n",
      "\n",
      "         [[-2.1214e-02,  3.3352e-02, -8.7513e-02,  ..., -8.9314e-03,\n",
      "            3.0822e-02,  3.8786e-02],\n",
      "          [-5.2402e-01, -2.6213e-01, -2.3345e-01,  ...,  3.4806e-01,\n",
      "            1.7069e-01, -2.4676e-04],\n",
      "          [-4.9386e-01,  4.8865e-01, -4.3231e-01,  ...,  7.6064e-01,\n",
      "           -2.9904e-02,  1.8609e-01],\n",
      "          ...,\n",
      "          [-1.5463e-01,  3.1104e+00, -7.4308e-01,  ..., -2.0623e-01,\n",
      "           -7.7929e-01,  9.4195e-01],\n",
      "          [-7.9531e-01,  1.3734e+00, -4.3312e-01,  ..., -4.4867e-01,\n",
      "            1.8048e-01,  6.7477e-02],\n",
      "          [-7.1460e-01,  5.9888e-01,  1.0618e+00,  ...,  5.3553e-01,\n",
      "           -7.6815e-01, -2.0368e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0483e-01,  3.7457e-02, -1.1568e-03,  ..., -4.4700e-02,\n",
      "           -8.8917e-03,  1.7837e-02],\n",
      "          [ 8.6269e-01, -1.4697e-01,  3.6745e-01,  ...,  3.1546e-01,\n",
      "            3.5175e-02, -3.0443e-01],\n",
      "          [ 5.1551e-01,  2.5198e-01,  1.5730e-01,  ...,  1.4892e+00,\n",
      "           -5.0922e-01,  2.0167e+00],\n",
      "          ...,\n",
      "          [-8.4730e-01, -4.3078e-01,  5.2054e-01,  ..., -9.0685e-02,\n",
      "            2.3514e-01, -9.9466e-02],\n",
      "          [-6.5803e-01, -7.2872e-01, -3.5988e-02,  ...,  1.0229e+00,\n",
      "           -7.1774e-01,  9.4541e-01],\n",
      "          [-8.0607e-01, -7.0931e-01,  7.0981e-01,  ...,  9.3563e-02,\n",
      "           -8.5871e-01,  1.3432e-01]],\n",
      "\n",
      "         [[ 9.2671e-02,  1.3452e-02,  5.3226e-02,  ...,  3.1511e-03,\n",
      "            4.3145e-02,  1.1899e-02],\n",
      "          [-1.5642e-01,  1.9026e-01,  7.6595e-01,  ..., -1.3407e-01,\n",
      "            2.6676e-01, -5.0297e-01],\n",
      "          [ 6.1654e-01,  8.3766e-01,  1.0002e+00,  ...,  1.2987e-01,\n",
      "            1.4224e+00, -4.2694e-01],\n",
      "          ...,\n",
      "          [-3.0885e-02,  1.5424e+00,  6.3994e-01,  ..., -7.0803e-01,\n",
      "            2.7368e+00,  1.4347e+00],\n",
      "          [ 1.9045e-01,  2.8000e+00, -1.0230e+00,  ..., -9.5444e-02,\n",
      "            6.7177e-01,  5.6665e-02],\n",
      "          [-2.2475e-01,  9.7459e-01,  2.7916e+00,  ..., -2.6344e-01,\n",
      "            6.6847e-01, -1.8378e+00]],\n",
      "\n",
      "         [[-1.0774e-01,  2.8406e-02, -5.5795e-02,  ..., -8.4050e-02,\n",
      "            6.1122e-02, -6.3834e-03],\n",
      "          [ 2.9482e-01, -4.6036e-01, -5.0067e-01,  ..., -4.2501e-01,\n",
      "            1.4048e+00,  3.5766e-02],\n",
      "          [-7.1402e-01, -6.3282e-01, -6.3516e-01,  ..., -1.0530e+00,\n",
      "            4.5487e-01, -1.2223e+00],\n",
      "          ...,\n",
      "          [-3.1074e-01, -1.3114e-01,  6.1908e-01,  ..., -1.1282e+00,\n",
      "            9.6892e-01,  1.1984e-01],\n",
      "          [-9.2515e-01,  1.1405e-01,  1.4297e-01,  ...,  2.4873e-01,\n",
      "           -2.8435e-01,  3.1334e-01],\n",
      "          [-4.7070e-01, -2.1283e-01,  1.8143e-01,  ..., -6.6503e-01,\n",
      "           -9.3209e-01,  8.6370e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7151, -0.3351, -0.2937,  ...,  0.1779,  0.3182, -0.4845],\n",
      "          [-0.0573, -0.2968, -0.2792,  ...,  1.8097, -0.9933, -0.0485],\n",
      "          [ 0.4551,  0.2350, -0.5202,  ...,  1.4073, -1.1556, -0.5031],\n",
      "          ...,\n",
      "          [ 0.4398,  0.2872, -1.3292,  ...,  1.0791, -0.5067, -0.6926],\n",
      "          [ 1.4281,  0.7992, -0.5960,  ...,  0.2981, -0.7968, -0.0723],\n",
      "          [ 1.4787,  0.0107, -0.4716,  ...,  0.5184, -2.1060, -0.5924]],\n",
      "\n",
      "         [[ 0.1182, -0.0641,  2.3043,  ...,  0.2435,  0.0934, -0.1985],\n",
      "          [ 0.3078, -0.7078, -0.0229,  ..., -0.1684,  0.3255,  0.4997],\n",
      "          [-0.0072, -1.4351, -0.3262,  ..., -0.0116, -0.4237, -1.0236],\n",
      "          ...,\n",
      "          [ 0.0789,  1.0277, -0.1959,  ..., -0.3314, -0.0123,  0.1554],\n",
      "          [-0.1221, -0.4109, -0.2510,  ..., -0.1642,  0.4183, -1.1042],\n",
      "          [ 0.3249, -0.0160, -1.2672,  ...,  0.3571,  0.7415, -0.0222]],\n",
      "\n",
      "         [[-0.1897,  1.0560,  0.4685,  ..., -0.5601,  0.3216, -0.1095],\n",
      "          [-1.2898,  0.1961,  0.3851,  ...,  0.0611, -0.4468, -0.4500],\n",
      "          [-1.2418, -0.5390, -0.3550,  ...,  1.1175,  0.2285, -0.6764],\n",
      "          ...,\n",
      "          [-1.7289, -1.8670, -0.2395,  ...,  0.8597,  0.1823,  0.1264],\n",
      "          [-1.4579, -1.1564,  0.1421,  ...,  1.1056, -0.7289, -0.9327],\n",
      "          [-0.5909,  0.2044, -0.4299,  ...,  1.1715,  0.5954, -0.7546]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5702,  0.9629, -0.8822,  ..., -0.7408,  0.6916,  0.8577],\n",
      "          [ 1.1006,  1.7073, -1.6259,  ..., -0.9801, -0.5523,  0.2173],\n",
      "          [ 0.6847,  1.8472, -0.7955,  ..., -0.5540, -0.5932,  0.3027],\n",
      "          ...,\n",
      "          [-1.6889,  0.1444,  0.2351,  ..., -0.8126, -1.4681, -0.2635],\n",
      "          [ 0.2845,  1.1499, -0.4750,  ..., -0.8172, -0.8146,  0.3588],\n",
      "          [ 0.0874, -0.2214, -0.0856,  ..., -0.7394, -1.2066,  0.1715]],\n",
      "\n",
      "         [[-0.4207,  0.3802,  0.3173,  ...,  0.7072,  0.0623, -0.0753],\n",
      "          [-0.9885,  1.0626, -0.9565,  ..., -0.0961, -0.5346, -1.2537],\n",
      "          [-0.8144,  1.0409, -0.3393,  ...,  0.7575, -0.7873, -0.3033],\n",
      "          ...,\n",
      "          [ 0.7162,  0.5353,  0.5786,  ...,  1.2553, -0.3931,  0.5719],\n",
      "          [-0.4955,  0.3584, -0.4676,  ...,  0.7423, -0.1553,  0.4724],\n",
      "          [-1.1989,  0.5740, -1.4242,  ..., -0.1654, -0.2418, -1.2209]],\n",
      "\n",
      "         [[-0.7356, -0.0250,  0.4452,  ..., -0.0942,  0.0330, -0.0571],\n",
      "          [ 0.1039, -0.4520,  1.6473,  ...,  0.0384, -0.3122,  0.2989],\n",
      "          [ 0.0984, -1.1736,  1.5161,  ...,  0.2563, -0.7524, -0.1577],\n",
      "          ...,\n",
      "          [ 0.3700,  0.0524,  0.3323,  ..., -0.1997, -1.8872,  0.6791],\n",
      "          [ 0.1144, -0.8560,  1.3444,  ..., -0.9688, -0.0111,  0.6124],\n",
      "          [ 0.3719, -1.1888,  2.9866,  ...,  1.5564,  1.0569,  1.0004]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0627, -0.1041, -0.1861,  ..., -0.2973,  0.2617, -0.1300],\n",
      "          [ 0.9190, -0.4094,  0.9732,  ...,  0.7065, -1.3206,  1.6103],\n",
      "          [-0.3314,  0.7099,  0.8130,  ...,  1.2446, -1.0029,  1.6824],\n",
      "          ...,\n",
      "          [ 0.3073, -0.1798,  2.0175,  ...,  3.8588, -1.2389,  0.9518],\n",
      "          [-1.0282,  0.0810,  1.8490,  ...,  2.1276, -0.6254,  0.2580],\n",
      "          [-2.1301,  0.1848,  0.6389,  ...,  0.8497, -2.1894,  2.4372]],\n",
      "\n",
      "         [[ 0.0701, -0.0366,  0.0433,  ..., -0.0205, -0.1226,  0.1881],\n",
      "          [-0.4828,  0.0397,  0.1133,  ...,  0.6646, -0.4122, -0.4976],\n",
      "          [-0.0560,  0.5185, -0.3796,  ..., -0.0358, -1.7324, -0.5987],\n",
      "          ...,\n",
      "          [ 0.3621, -1.0770,  0.8416,  ..., -1.0863, -1.4621,  1.3165],\n",
      "          [-0.4170, -0.1856, -0.2208,  ...,  0.6679,  0.2648, -0.7330],\n",
      "          [ 0.9327,  0.1231, -0.2568,  ...,  0.0206, -0.5632, -0.0348]],\n",
      "\n",
      "         [[ 0.0102,  0.0407, -0.0427,  ...,  0.0176,  0.0324,  0.0545],\n",
      "          [-0.8474, -0.1339,  0.6198,  ..., -1.1320, -0.1028,  0.0237],\n",
      "          [-0.3179,  0.2617, -0.2293,  ..., -0.3102, -0.2109,  0.9155],\n",
      "          ...,\n",
      "          [-1.1459,  0.6247, -0.4677,  ...,  0.4716,  0.2258,  1.9537],\n",
      "          [ 0.3159, -0.4951,  0.3948,  ...,  0.0583,  0.3305,  2.0492],\n",
      "          [ 0.5957, -0.2422, -0.1601,  ...,  0.0871,  0.6242,  0.0631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0194, -0.0276,  0.0886,  ...,  0.0796, -0.0209,  0.0248],\n",
      "          [-0.7218,  0.9741,  0.7868,  ..., -0.1377, -0.3252, -1.0529],\n",
      "          [ 0.0102,  0.0130,  0.1943,  ...,  1.0051,  0.9481, -0.4571],\n",
      "          ...,\n",
      "          [-1.2697,  1.1965,  1.8222,  ...,  1.2815,  1.1525, -0.2608],\n",
      "          [-0.9059, -0.1876, -0.2131,  ...,  0.1001,  0.5176, -0.7554],\n",
      "          [-0.2481,  0.0416, -0.7926,  ...,  0.2645, -0.6107, -0.3649]],\n",
      "\n",
      "         [[-0.1515, -0.0920,  0.0492,  ..., -0.0616,  0.0336, -0.0914],\n",
      "          [ 0.1947,  0.3574,  0.4865,  ..., -0.0827, -0.0695,  0.1024],\n",
      "          [ 0.0617, -0.4696,  0.1419,  ..., -0.5913, -0.3143,  0.7776],\n",
      "          ...,\n",
      "          [-0.4784,  1.0185, -0.0705,  ...,  0.2748, -0.4973,  1.3698],\n",
      "          [-0.8326,  0.6881,  0.1242,  ..., -0.5708,  0.6708,  0.8386],\n",
      "          [-1.0543, -0.0815,  0.9794,  ...,  0.3561,  0.6065,  0.8012]],\n",
      "\n",
      "         [[ 0.1127, -0.1414,  0.0995,  ..., -0.1078,  0.0248, -0.1947],\n",
      "          [ 0.3453, -0.7535,  0.9195,  ...,  0.1146, -0.0401,  0.5830],\n",
      "          [-0.6160, -0.7786,  1.2499,  ..., -1.0763,  0.0126, -0.6472],\n",
      "          ...,\n",
      "          [-1.0815,  0.2212,  0.6810,  ..., -1.4694, -0.5813,  0.5124],\n",
      "          [-0.5673, -0.7975, -0.1831,  ...,  0.2839,  0.3034,  0.0535],\n",
      "          [-0.9700,  0.6698, -0.1582,  ...,  0.8679, -0.3234,  1.0039]]]],\n",
      "       grad_fn=<PermuteBackward0>)))\n"
     ]
    }
   ],
   "source": [
    "print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb9417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe9cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
