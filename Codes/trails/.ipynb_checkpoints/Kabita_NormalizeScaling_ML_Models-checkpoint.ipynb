{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//kabita_dataset_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b63a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of Train-test split, Normalize Scaling\n",
    "def normalize_scaling(x_data, y_data):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.30,random_state=21,stratify=y_data)\n",
    "    # Normalize scaling of train data\n",
    "    normalize_model = Normalizer()\n",
    "    np.set_printoptions(precision=3)\n",
    "    scaled_data_train = normalize_model.fit_transform(x_train)\n",
    "    # Normalize scaling of test data\n",
    "    scaled_data_test = normalize_model.fit_transform(x_test)\n",
    "    return scaled_data_train, scaled_data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" after Normalize Scaling is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.753061224489796\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[169   0   0   5  14  21   1]\n",
      " [  0 163  12   6   8  21   0]\n",
      " [  0   1 181  10   0  18   0]\n",
      " [  1   8  14 160   5  19   3]\n",
      " [ 23  13  16  21 129   2   6]\n",
      " [  1   4   4  24   2 139  36]\n",
      " [  0   2   0   4   1  37 166]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.80      0.84       210\n",
      "           2       0.85      0.78      0.81       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.70      0.76      0.73       210\n",
      "           5       0.81      0.61      0.70       210\n",
      "           6       0.54      0.66      0.60       210\n",
      "           7       0.78      0.79      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.76      1470\n",
      "weighted avg       0.76      0.75      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   6   3   9   7  50   0]\n",
      " [  7 149  20   6   6  22   0]\n",
      " [ 10   4 171   7   1  17   0]\n",
      " [ 25  13  18 106   0  46   2]\n",
      " [ 53  28  19  14  31  63   2]\n",
      " [ 17  14   6  17   1 131  24]\n",
      " [  2   6   0   6   1  96  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.64      0.59       210\n",
      "           2       0.68      0.71      0.69       210\n",
      "           3       0.72      0.81      0.77       210\n",
      "           4       0.64      0.50      0.57       210\n",
      "           5       0.66      0.15      0.24       210\n",
      "           6       0.31      0.62      0.41       210\n",
      "           7       0.78      0.47      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.62      0.56      0.55      1470\n",
      "weighted avg       0.62      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133   6   4  10   9  47   1]\n",
      " [  6 144  15   9   9  27   0]\n",
      " [  9   2 172  10   2  15   0]\n",
      " [ 19  17  18 112   1  40   3]\n",
      " [ 51  39  28  23  26  41   2]\n",
      " [ 15  15   7  18   1 134  20]\n",
      " [  2  16   1   7   0  90  94]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.60      0.69      0.64       210\n",
      "           3       0.70      0.82      0.76       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.54      0.12      0.20       210\n",
      "           6       0.34      0.64      0.44       210\n",
      "           7       0.78      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.54      1470\n",
      "weighted avg       0.59      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.545578231292517\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132  10   2   9  10  46   1]\n",
      " [  6 155  17   8   4  19   1]\n",
      " [  9  17 170  10   1   3   0]\n",
      " [ 13  20  22 117   0  35   3]\n",
      " [ 44  40  31  24  23  46   2]\n",
      " [ 10  34   7  23   1 117  18]\n",
      " [  2  20   4  13   0  83  88]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.63      0.62       210\n",
      "           2       0.52      0.74      0.61       210\n",
      "           3       0.67      0.81      0.73       210\n",
      "           4       0.57      0.56      0.57       210\n",
      "           5       0.59      0.11      0.18       210\n",
      "           6       0.34      0.56      0.42       210\n",
      "           7       0.78      0.42      0.54       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.58      0.55      0.53      1470\n",
      "weighted avg       0.58      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  10   5   8   6  52   0]\n",
      " [  7 155  18   8   3  18   1]\n",
      " [  7  18 172  10   1   2   0]\n",
      " [  8  25  21 115   0  41   0]\n",
      " [ 44  41  28  22  21  52   2]\n",
      " [  6  40   9  21   1 118  15]\n",
      " [  2  22   6   7   0  87  86]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.62       210\n",
      "           2       0.50      0.74      0.60       210\n",
      "           3       0.66      0.82      0.73       210\n",
      "           4       0.60      0.55      0.57       210\n",
      "           5       0.66      0.10      0.17       210\n",
      "           6       0.32      0.56      0.41       210\n",
      "           7       0.83      0.41      0.55       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.52      1470\n",
      "weighted avg       0.60      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  15   7   8   4  55   0]\n",
      " [  3 155  20   5   6  21   0]\n",
      " [  7  16 171  11   0   5   0]\n",
      " [ 11  22  21 113   2  41   0]\n",
      " [ 42  39  33  19  20  56   1]\n",
      " [  8  39   8  15   0 122  18]\n",
      " [  1  24   6   5   0  93  81]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.60       210\n",
      "           2       0.50      0.74      0.60       210\n",
      "           3       0.64      0.81      0.72       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.62      0.10      0.17       210\n",
      "           6       0.31      0.58      0.40       210\n",
      "           7       0.81      0.39      0.52       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.59      0.53      0.51      1470\n",
      "weighted avg       0.59      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  12   5   8   2  62   0]\n",
      " [  4 154  21   8   4  19   0]\n",
      " [  7  14 173  11   0   5   0]\n",
      " [  8  26  20 113   1  42   0]\n",
      " [ 37  37  31  20  19  65   1]\n",
      " [  5  37   6  11   0 137  14]\n",
      " [  1  21   4   4   0 109  71]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.51      0.73      0.60       210\n",
      "           3       0.67      0.82      0.74       210\n",
      "           4       0.65      0.54      0.59       210\n",
      "           5       0.73      0.09      0.16       210\n",
      "           6       0.31      0.65      0.42       210\n",
      "           7       0.83      0.34      0.48       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.51      1470\n",
      "weighted avg       0.62      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[153   2   8  20  21   4   2]\n",
      " [  9 122  66   7   3   2   1]\n",
      " [  5   6 193   5   0   0   1]\n",
      " [ 19  21  40 112   9   6   3]\n",
      " [ 75  13  13  44  56   6   3]\n",
      " [ 25  32  42  29   5  41  36]\n",
      " [ 11  13   4   4   0  24 154]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.73      0.60       210\n",
      "           2       0.58      0.58      0.58       210\n",
      "           3       0.53      0.92      0.67       210\n",
      "           4       0.51      0.53      0.52       210\n",
      "           5       0.60      0.27      0.37       210\n",
      "           6       0.49      0.20      0.28       210\n",
      "           7       0.77      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.54      1470\n",
      "weighted avg       0.57      0.57      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.7136054421768707\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   1  10   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  11  32 143   6   8   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  12  44  18   5  97  28]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       210\n",
      "           2       0.78      0.77      0.77       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.74      0.68      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.64      0.46      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7571428571428571\n",
      "Confusion Matrix of SVM is:\n",
      " [[170   1   1   5  18  14   1]\n",
      " [  0 169  10   9   2  20   0]\n",
      " [  0   5 179  10   0  16   0]\n",
      " [  0   9  15 158   3  22   3]\n",
      " [ 21  18  14  19 131   1   6]\n",
      " [  1   6   1  22   2 139  39]\n",
      " [  0   2   0   5   1  35 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.81      0.85       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.69      0.75      0.72       210\n",
      "           5       0.83      0.62      0.71       210\n",
      "           6       0.56      0.66      0.61       210\n",
      "           7       0.77      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of SVM is:\n",
      " [[121   0   0   8  28  51   2]\n",
      " [  1 141   8  12  18  29   1]\n",
      " [  5   2 172  10   3  18   0]\n",
      " [  7   6   9 141   7  37   3]\n",
      " [ 15   6   5  20 117  43   4]\n",
      " [  5   4   1  15   4 143  38]\n",
      " [  0   0   0   1   1  61 147]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.58      0.66       210\n",
      "           2       0.89      0.67      0.76       210\n",
      "           3       0.88      0.82      0.85       210\n",
      "           4       0.68      0.67      0.68       210\n",
      "           5       0.66      0.56      0.60       210\n",
      "           6       0.37      0.68      0.48       210\n",
      "           7       0.75      0.70      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.72      0.67      0.68      1470\n",
      "weighted avg       0.72      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.754421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   0   0   7  25  15   2]\n",
      " [  1 160   8  12   8  21   0]\n",
      " [  0   6 177  13   0  14   0]\n",
      " [  3   5   9 163   7  20   3]\n",
      " [ 16  13   8  26 138   3   6]\n",
      " [  6   5   1  24   1 131  42]\n",
      " [  0   1   0   4   1  25 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.77      0.81       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.87      0.84      0.86       210\n",
      "           4       0.65      0.78      0.71       210\n",
      "           5       0.77      0.66      0.71       210\n",
      "           6       0.57      0.62      0.60       210\n",
      "           7       0.77      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.76      1470\n",
      "weighted avg       0.76      0.75      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[173   1   0   6  14  14   2]\n",
      " [  0 161  19   9   4  17   0]\n",
      " [  0   1 181   9   0  19   0]\n",
      " [  0  10  18 152   2  22   6]\n",
      " [ 51  18  22  19  93   1   6]\n",
      " [  1   4   3  19   2 136  45]\n",
      " [  1   2   0   5   0  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.82      0.79       210\n",
      "           2       0.82      0.77      0.79       210\n",
      "           3       0.74      0.86      0.80       210\n",
      "           4       0.69      0.72      0.71       210\n",
      "           5       0.81      0.44      0.57       210\n",
      "           6       0.56      0.65      0.60       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.20748299319727892\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [115   0  95   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.16      0.21      0.13      1470\n",
      "weighted avg       0.16      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.2653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   2   0   0 153   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.25      0.27      0.20      1470\n",
      "weighted avg       0.25      0.27      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   0   0   0  43  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 78   0   2   0  42  88   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.53      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.20      0.28       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.25      1470\n",
      "weighted avg       0.32      0.31      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66   2   0   0  89   0  53]\n",
      " [  0  54   2   0   2   0 152]\n",
      " [  0   0  95   0   0   0 115]\n",
      " [  0   6   1   0   1   0 202]\n",
      " [ 13   4   2   0 107   0  84]\n",
      " [  0   3   0   0   0   0 207]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.31      0.46       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.53      0.51      0.52       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.99      0.34       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.47      0.36      0.33      1470\n",
      "weighted avg       0.47      0.36      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   2   0  53  46   0   0]\n",
      " [  0  54   2 152   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 40   4   2  81  80   0   3]\n",
      " [  0   3   0 203   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.52      0.61       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.21      0.96      0.34       210\n",
      "           5       0.62      0.38      0.47       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.39      1470\n",
      "weighted avg       0.59      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  53   0   0   0]\n",
      " [  0  83   2 123   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 82   9   2  75  39   1   2]\n",
      " [  0   2   0 203   0   1   4]\n",
      " [  2   1   0 162   0   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.74      0.69       210\n",
      "           2       0.81      0.40      0.53       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.22      0.96      0.35       210\n",
      "           5       0.95      0.19      0.31       210\n",
      "           6       0.50      0.00      0.01       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.71      0.42      0.41      1470\n",
      "weighted avg       0.71      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0   0   0  53   0]\n",
      " [  0 122   2   0   3  83   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   6   1   1   0 201   0]\n",
      " [ 74  20   2   0  47  65   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.74      0.70       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.94      0.22      0.36       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.78      0.45      0.44      1470\n",
      "weighted avg       0.78      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48095238095238096\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[136   2   0  53  19   0   0]\n",
      " [  0 122   2  83   3   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 200   0   0   2]\n",
      " [ 38  20   2  64  83   1   2]\n",
      " [  0   3   0 190   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.24      0.95      0.38       210\n",
      "           5       0.78      0.40      0.52       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.66      0.48      0.48      1470\n",
      "weighted avg       0.66      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   2   0  53  20   0   0]\n",
      " [  0 122   3  82   3   0   0]\n",
      " [  0   0 109 101   0   0   0]\n",
      " [  0   5   4 197   2   0   2]\n",
      " [ 35  18   3  63  88   1   2]\n",
      " [  0   3   1 189   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.81      0.58      0.68       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.24      0.94      0.38       210\n",
      "           5       0.77      0.42      0.54       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.66      0.49      0.49      1470\n",
      "weighted avg       0.66      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[126   3   0   0  29  52   0]\n",
      " [  0 141   3   0   3  63   0]\n",
      " [  0  37 109   0   0  64   0]\n",
      " [  0  21   4   1   2 180   2]\n",
      " [ 24  30   3   0 104  47   2]\n",
      " [  0   5   1   0   0 188  16]\n",
      " [  0   1   0   1   2 136  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.59      0.67      0.63       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.50      0.00      0.01       210\n",
      "           5       0.74      0.50      0.59       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.66      0.50      0.49      1470\n",
      "weighted avg       0.66      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   3   0  52  11   0   0]\n",
      " [  0 140   4  63   3   0   0]\n",
      " [  0  21 125  64   0   0   0]\n",
      " [  0  21   4 179   2   0   4]\n",
      " [ 51  29   5  45  76   1   3]\n",
      " [  0   5   1 183   0   1  20]\n",
      " [  2   1   0 111   0   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.69      0.71       210\n",
      "           2       0.64      0.67      0.65       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.26      0.85      0.39       210\n",
      "           5       0.83      0.36      0.50       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.64      0.52      0.51      1470\n",
      "weighted avg       0.64      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134   2   0  52  22   0   0]\n",
      " [  0 133   4  63  10   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 179  13   0   4]\n",
      " [ 30  13   5  45 113   1   3]\n",
      " [  0   3   1 179   2   1  24]\n",
      " [  0   1   0  96   2   1 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.74      0.63      0.68       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.26      0.85      0.40       210\n",
      "           5       0.68      0.54      0.60       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.65      0.54      0.54      1470\n",
      "weighted avg       0.65      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5476190476190477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   2   0  42  10   0   0]\n",
      " [  0 134   4  63   9   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 183   9   0   4]\n",
      " [ 53  12   5  43  96   1   0]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  2   1   0  96   0   1 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.74      0.64      0.69       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.27      0.87      0.42       210\n",
      "           5       0.74      0.46      0.56       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.65      0.55      0.54      1470\n",
      "weighted avg       0.65      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  42  11   0   0]\n",
      " [  0 136   5  63   6   0   0]\n",
      " [  0  13 138  55   4   0   0]\n",
      " [  0  10   4 182  10   0   4]\n",
      " [ 50  13   5  42  97   1   2]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  2   1   0  96   0   2 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.74       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.90      0.66      0.76       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.75      0.46      0.57       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.79      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.64      0.56      0.55      1470\n",
      "weighted avg       0.64      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0  42  27   0   0]\n",
      " [  0 136   6  62   6   0   0]\n",
      " [  0  13 144  49   4   0   0]\n",
      " [  1  10   5 182   8   0   4]\n",
      " [ 32  13   5  43 116   1   0]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  0   1   0  96   4   1 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.69      0.55      0.62       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.80      0.51      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.65      0.56      0.55      1470\n",
      "weighted avg       0.65      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0  43  16   0   0]\n",
      " [  0 134   7  61   8   0   0]\n",
      " [  0  10 152  44   4   0   0]\n",
      " [  0  10   6 180  10   0   4]\n",
      " [ 50  12   5  42  98   1   2]\n",
      " [  0   4   1 179   2   3  21]\n",
      " [  2   1   0  96   0   5 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.72      0.80       210\n",
      "           4       0.28      0.86      0.42       210\n",
      "           5       0.71      0.47      0.56       210\n",
      "           6       0.33      0.01      0.03       210\n",
      "           7       0.80      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.65      0.56      0.55      1470\n",
      "weighted avg       0.65      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0  43  17   0   0]\n",
      " [  0 135   6  62   7   0   0]\n",
      " [  0   9 153  44   4   0   0]\n",
      " [  0  10   6 181   9   0   4]\n",
      " [ 43  13   5  42 106   1   0]\n",
      " [  0   4   1 175   2   3  25]\n",
      " [  1   1   0  89   1  11 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.28      0.86      0.43       210\n",
      "           5       0.73      0.50      0.60       210\n",
      "           6       0.20      0.01      0.03       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.63      0.57      0.56      1470\n",
      "weighted avg       0.63      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   1  19  42   0]\n",
      " [  0 134   7   0   8  61   0]\n",
      " [  0   9 153   0   4  44   0]\n",
      " [  0  10   6  14   9 167   4]\n",
      " [ 45  13   5   0 104  43   0]\n",
      " [  0   4   1   0   2 180  23]\n",
      " [  1   1   0   1   1  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.88      0.07      0.12       210\n",
      "           5       0.71      0.50      0.58       210\n",
      "           6       0.28      0.86      0.43       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.73      0.57      0.57      1470\n",
      "weighted avg       0.73      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   1   0   2  22  42   0]\n",
      " [  0 133   7   0   9  61   0]\n",
      " [  0   8 154   1   4  43   0]\n",
      " [  0   9   8  33   9 147   4]\n",
      " [ 32  12   5   3 118  40   0]\n",
      " [  0   4   1   1   2 179  23]\n",
      " [  0   1   0   2   4  96 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.79      0.63      0.70       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.79      0.16      0.26       210\n",
      "           5       0.70      0.56      0.62       210\n",
      "           6       0.29      0.85      0.44       210\n",
      "           7       0.80      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.72      0.59      0.60      1470\n",
      "weighted avg       0.72      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   1   0   2  19  42   0]\n",
      " [  0 145   7   0   8  50   0]\n",
      " [  0   9 154   0   3  44   0]\n",
      " [  0   8   7  34   9 148   4]\n",
      " [ 41  18   5   3 107  36   0]\n",
      " [  0   4   1   1   2 178  24]\n",
      " [  1   1   0   2   1 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.73       210\n",
      "           2       0.78      0.69      0.73       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.81      0.16      0.27       210\n",
      "           5       0.72      0.51      0.60       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.72      0.59      0.60      1470\n",
      "weighted avg       0.72      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   3   0  19   5  19   8]\n",
      " [  1 111   7  13  35  43   0]\n",
      " [  0   0 151  23   0  35   1]\n",
      " [  0  12   7 123  11  50   7]\n",
      " [ 62  15   5  28  73  13  14]\n",
      " [  0   7   4  24   4 129  42]\n",
      " [  0   1   0  16   0  45 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.74      0.53      0.62       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.50      0.59      0.54       210\n",
      "           5       0.57      0.35      0.43       210\n",
      "           6       0.39      0.61      0.47       210\n",
      "           7       0.67      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   5   2  18   6  21   3]\n",
      " [  1 124   6  11  25  43   0]\n",
      " [  0   0 152  27   0  30   1]\n",
      " [  1   7   8 140   8  41   5]\n",
      " [ 60  17   5  25  73  14  16]\n",
      " [  0   2   4  20   4 139  41]\n",
      " [  0   0   1  14   0  45 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.80      0.59      0.68       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.55      0.67      0.60       210\n",
      "           5       0.63      0.35      0.45       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.69      0.71      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   0  18   5  21   1]\n",
      " [  0 130   9  10  18  43   0]\n",
      " [  0   0 156  17   0  36   1]\n",
      " [  1   7   8 140   4  43   7]\n",
      " [ 67  17   6  22  69  16  13]\n",
      " [  0   3   4  24   1 136  42]\n",
      " [  1   0   1  11   0  44 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73       210\n",
      "           2       0.81      0.62      0.70       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.58      0.67      0.62       210\n",
      "           5       0.71      0.33      0.45       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.64      1470\n",
      "weighted avg       0.68      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   7   0  16   5  22   2]\n",
      " [  0 132   9  11  19  39   0]\n",
      " [  0   0 156  17   0  36   1]\n",
      " [  1  11   7 141   9  37   4]\n",
      " [ 67  20   6  23  69  13  12]\n",
      " [  0   6   4  28   3 126  43]\n",
      " [  0   1   0  13   0  41 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.72       210\n",
      "           2       0.75      0.63      0.68       210\n",
      "           3       0.86      0.74      0.80       210\n",
      "           4       0.57      0.67      0.61       210\n",
      "           5       0.66      0.33      0.44       210\n",
      "           6       0.40      0.60      0.48       210\n",
      "           7       0.71      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   3   0  16   7  23   2]\n",
      " [  0 138  10  13  13  36   0]\n",
      " [  0   0 167  14   0  28   1]\n",
      " [  0   7   8 145   9  37   4]\n",
      " [ 56  15   6  26  81  13  13]\n",
      " [  0   3   4  27   3 131  42]\n",
      " [  0   0   0  14   0  39 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.83      0.66      0.73       210\n",
      "           3       0.86      0.80      0.82       210\n",
      "           4       0.57      0.69      0.62       210\n",
      "           5       0.72      0.39      0.50       210\n",
      "           6       0.43      0.62      0.51       210\n",
      "           7       0.72      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   3   0  18   9  22   1]\n",
      " [  0 137   9  12  15  37   0]\n",
      " [  0   0 158  15   0  36   1]\n",
      " [  0   9   8 149   3  37   4]\n",
      " [ 55  15   6  23  85  13  13]\n",
      " [  0   3   4  28   2 132  41]\n",
      " [  0   0   1  13   0  40 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.82      0.65      0.73       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.58      0.71      0.64       210\n",
      "           5       0.75      0.40      0.52       210\n",
      "           6       0.42      0.63      0.50       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  16   8  23   2]\n",
      " [  0 138  11  10  16  35   0]\n",
      " [  0   0 161  13   0  35   1]\n",
      " [  1   8   8 142   5  42   4]\n",
      " [ 55  16   6  25  80  16  12]\n",
      " [  0   4   4  22   3 136  41]\n",
      " [  0   0   1   9   0  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.82      0.66      0.73       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.71      0.38      0.50       210\n",
      "           6       0.41      0.65      0.50       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0  17  11  22   2]\n",
      " [  0 140   7  12  14  37   0]\n",
      " [  0   0 160  13   0  36   1]\n",
      " [  1   6   8 143   5  43   4]\n",
      " [ 45  17   6  22  94  15  11]\n",
      " [  0   3   4  17   3 142  41]\n",
      " [  0   0   1   9   0  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.76       210\n",
      "           2       0.83      0.67      0.74       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.61      0.68      0.65       210\n",
      "           5       0.74      0.45      0.56       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0  17  10  23   1]\n",
      " [  0 139   7  13  15  36   0]\n",
      " [  0   0 161  13   0  35   1]\n",
      " [  0   6   8 142   4  46   4]\n",
      " [ 50  16   6  21  89  17  11]\n",
      " [  0   4   4  17   2 142  41]\n",
      " [  0   0   0   8   1  46 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.75       210\n",
      "           2       0.83      0.66      0.74       210\n",
      "           3       0.87      0.77      0.81       210\n",
      "           4       0.61      0.68      0.64       210\n",
      "           5       0.74      0.42      0.54       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   9  12  31   0]\n",
      " [  0 141  11  10  11  37   0]\n",
      " [  0   1 167  14   0  27   1]\n",
      " [  0   6   9 132   4  55   4]\n",
      " [ 50  15   6  19  95  16   9]\n",
      " [  0   4   4  13   2 147  40]\n",
      " [  0   0   1   5   0  48 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.83      0.67      0.74       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.77      0.45      0.57       210\n",
      "           6       0.41      0.70      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   2   0  10   8  29   0]\n",
      " [  0 142   8   9  14  37   0]\n",
      " [  0   0 160  11   0  38   1]\n",
      " [  0   6   8 136   7  49   4]\n",
      " [ 54  15   6  18  90  17  10]\n",
      " [  0   3   4  15   3 145  40]\n",
      " [  1   0   0   6   1  47 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76       210\n",
      "           2       0.85      0.68      0.75       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.66      0.65      0.66       210\n",
      "           5       0.73      0.43      0.54       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0  12   9  27   0]\n",
      " [  0 139  11  10  16  34   0]\n",
      " [  0   0 166  13   0  30   1]\n",
      " [  0   6   9 140   4  47   4]\n",
      " [ 58  16   6  19  86  16   9]\n",
      " [  0   4   5  15   2 141  43]\n",
      " [  1   0   0   7   1  48 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       210\n",
      "           2       0.83      0.66      0.74       210\n",
      "           3       0.84      0.79      0.82       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.73      0.41      0.52       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0  12  10  28   1]\n",
      " [  0 143  10   9  11  37   0]\n",
      " [  0   0 167  12   0  30   1]\n",
      " [  0   6   9 139   3  49   4]\n",
      " [ 42  17   6  23  95  16  11]\n",
      " [  0   4   4  15   2 143  42]\n",
      " [  0   0   0   7   0  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.75      0.77       210\n",
      "           2       0.83      0.68      0.75       210\n",
      "           3       0.85      0.80      0.82       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.79      0.45      0.57       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  12   9  28   0]\n",
      " [  0 147  10   7  12  34   0]\n",
      " [  0   0 168  11   0  30   1]\n",
      " [  0   6   9 138   6  47   4]\n",
      " [ 46  15   6  21  95  17  10]\n",
      " [  0   5   3  14   2 143  43]\n",
      " [  0   0   0   5   1  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.84      0.70      0.76       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.76      0.45      0.57       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.69      1470\n",
      "weighted avg       0.72      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0  13   7  27   1]\n",
      " [  0 150   7   9  13  31   0]\n",
      " [  0   4 161   9   0  35   1]\n",
      " [  0   7   7 138   5  49   4]\n",
      " [ 39  14   6  19 107  15  10]\n",
      " [  0   3   2  16   2 146  41]\n",
      " [  0   0   0   7   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.76      0.78       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.65      0.66      0.66       210\n",
      "           5       0.79      0.51      0.62       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.73      0.69      0.70      1470\n",
      "weighted avg       0.73      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   0  11  14  28   0]\n",
      " [  0 149   9  11  12  29   0]\n",
      " [  0   4 169  10   1  25   1]\n",
      " [  0   8   9 139   6  44   4]\n",
      " [ 32  13   6  20 114  13  12]\n",
      " [  0   3   3  18   2 142  42]\n",
      " [  0   0   0   7   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.78       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.76      0.54      0.63       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   2   0  10  17  28   1]\n",
      " [  0 148   7   7  16  32   0]\n",
      " [  0   5 161  10   0  33   1]\n",
      " [  0   9   8 139   7  43   4]\n",
      " [ 31  14   6  21 113  15  10]\n",
      " [  0   3   4  14   2 145  42]\n",
      " [  0   0   0   5   2  45 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.72      0.77       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.87      0.77      0.81       210\n",
      "           4       0.67      0.66      0.67       210\n",
      "           5       0.72      0.54      0.62       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   2   0   9  17  29   1]\n",
      " [  0 152   8   8  12  30   0]\n",
      " [  0   3 170  11   0  25   1]\n",
      " [  0   8   9 141   5  43   4]\n",
      " [ 37  14   6  20 108  15  10]\n",
      " [  0   3   3  18   3 140  43]\n",
      " [  1   0   0   5   2  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.84      0.72      0.78       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.73      0.51      0.61       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7006802721088435\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   0   9  14  29   2]\n",
      " [  0 156   8   7   8  31   0]\n",
      " [  0   4 168  13   0  24   1]\n",
      " [  0   9   9 140   7  41   4]\n",
      " [ 34  13   6  22 110  15  10]\n",
      " [  0   5   3  17   3 142  40]\n",
      " [  0   0   0   5   2  43 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.73      0.77       210\n",
      "           2       0.83      0.74      0.78       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.66      0.67      0.66       210\n",
      "           5       0.76      0.52      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.71      1470\n",
      "weighted avg       0.73      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   3   0  10  14  27   1]\n",
      " [  0 153   7   8  11  31   0]\n",
      " [  0   3 170   9   0  27   1]\n",
      " [  0  10   9 138   6  43   4]\n",
      " [ 34  16   6  18 109  17  10]\n",
      " [  0   3   2  16   2 146  41]\n",
      " [  1   1   0   6   1  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.74      0.78       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.88      0.81      0.84       210\n",
      "           4       0.67      0.66      0.67       210\n",
      "           5       0.76      0.52      0.62       210\n",
      "           6       0.44      0.70      0.54       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.71      1470\n",
      "weighted avg       0.73      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[147   0   1   8  45   8   1]\n",
      " [ 13 150   9   9  21   8   0]\n",
      " [ 14   2 175  11   4   3   1]\n",
      " [ 19   4  13 145  13  12   4]\n",
      " [ 25  10  10  23 132   6   4]\n",
      " [ 38  10   3  22   6  90  41]\n",
      " [  4   3   0   4   0  21 178]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.70      0.63       210\n",
      "           2       0.84      0.71      0.77       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.65      0.69      0.67       210\n",
      "           5       0.60      0.63      0.61       210\n",
      "           6       0.61      0.43      0.50       210\n",
      "           7       0.78      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7496598639455783\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[165   3   1   9  15  15   2]\n",
      " [  0 163  15   6   6  20   0]\n",
      " [  0   1 181   9   0  19   0]\n",
      " [  1   9  17 162   2  16   3]\n",
      " [ 24  18  18  17 125   2   6]\n",
      " [  0   7   4  23   2 139  35]\n",
      " [  0   3   0   6   1  33 167]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.79      0.82       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.77      0.86      0.81       210\n",
      "           4       0.70      0.77      0.73       210\n",
      "           5       0.83      0.60      0.69       210\n",
      "           6       0.57      0.66      0.61       210\n",
      "           7       0.78      0.80      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   8   3   3  13  32   1]\n",
      " [  4 155  23   2   8  18   0]\n",
      " [  5   5 180   5   0  15   0]\n",
      " [ 16  19  23 104   5  43   0]\n",
      " [ 55  26  23  14  46  45   1]\n",
      " [ 13  14   4  12   0 151  16]\n",
      " [  5   3   0   4   1  95 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.71      0.66       210\n",
      "           2       0.67      0.74      0.70       210\n",
      "           3       0.70      0.86      0.77       210\n",
      "           4       0.72      0.50      0.59       210\n",
      "           5       0.63      0.22      0.33       210\n",
      "           6       0.38      0.72      0.50       210\n",
      "           7       0.85      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.65      0.60      0.59      1470\n",
      "weighted avg       0.65      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155  12   4   4   6  29   0]\n",
      " [  3 163  18   2   6  18   0]\n",
      " [  4   2 182   8   0  14   0]\n",
      " [ 15  22  34 108   2  29   0]\n",
      " [ 66  31  28  18  33  34   0]\n",
      " [  8  21   8  20   0 137  16]\n",
      " [  7  23   4   6   0  81  89]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66       210\n",
      "           2       0.59      0.78      0.67       210\n",
      "           3       0.65      0.87      0.75       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       0.70      0.16      0.26       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.85      0.42      0.57       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.57      1470\n",
      "weighted avg       0.64      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151  13  10   6   5  25   0]\n",
      " [  1 157  31   6   6   9   0]\n",
      " [  2   2 194   9   0   3   0]\n",
      " [ 10  16  33 110   1  40   0]\n",
      " [ 63  30  35  18  30  33   1]\n",
      " [  2  22  35  21   0 114  16]\n",
      " [  6  17   8   7   0  81  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.72      0.68       210\n",
      "           2       0.61      0.75      0.67       210\n",
      "           3       0.56      0.92      0.70       210\n",
      "           4       0.62      0.52      0.57       210\n",
      "           5       0.71      0.14      0.24       210\n",
      "           6       0.37      0.54      0.44       210\n",
      "           7       0.84      0.43      0.57       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.55      1470\n",
      "weighted avg       0.62      0.58      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5816326530612245\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156  13   4   3   3  31   0]\n",
      " [  0 159  22   4   4  21   0]\n",
      " [  2   3 181   9   0  15   0]\n",
      " [ 11  17  30 107   0  45   0]\n",
      " [ 66  32  32  18  25  36   1]\n",
      " [  6  19  10  15   0 143  17]\n",
      " [  5  13   6   9   0  93  84]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.74      0.68       210\n",
      "           2       0.62      0.76      0.68       210\n",
      "           3       0.64      0.86      0.73       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       0.78      0.12      0.21       210\n",
      "           6       0.37      0.68      0.48       210\n",
      "           7       0.82      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.65      0.58      0.56      1470\n",
      "weighted avg       0.65      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154  11   3   3   3  36   0]\n",
      " [  1 153  22   4   5  25   0]\n",
      " [  2   1 183   8   0  16   0]\n",
      " [ 12  16  31 109   0  42   0]\n",
      " [ 65  30  31  15  25  43   1]\n",
      " [  6  21   7  14   0 145  17]\n",
      " [  5  14   5   6   0  97  83]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.73      0.68       210\n",
      "           2       0.62      0.73      0.67       210\n",
      "           3       0.65      0.87      0.74       210\n",
      "           4       0.69      0.52      0.59       210\n",
      "           5       0.76      0.12      0.21       210\n",
      "           6       0.36      0.69      0.47       210\n",
      "           7       0.82      0.40      0.53       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.65      0.58      0.56      1470\n",
      "weighted avg       0.65      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   8   3   8   2  40   0]\n",
      " [  1 154  23   3   4  25   0]\n",
      " [  2   1 183   8   0  16   0]\n",
      " [ 13  15  29 104   0  49   0]\n",
      " [ 65  29  32  14  24  45   1]\n",
      " [  6  18   7  13   0 151  15]\n",
      " [  2  14   6   4   0 109  75]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.71      0.67       210\n",
      "           2       0.64      0.73      0.69       210\n",
      "           3       0.65      0.87      0.74       210\n",
      "           4       0.68      0.50      0.57       210\n",
      "           5       0.80      0.11      0.20       210\n",
      "           6       0.35      0.72      0.47       210\n",
      "           7       0.82      0.36      0.50       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.65      0.57      0.55      1470\n",
      "weighted avg       0.65      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[156   2   9  19  21   1   2]\n",
      " [  9  98  89   7   4   3   0]\n",
      " [  4   6 193   6   0   0   1]\n",
      " [ 19  18  41 119   9   4   0]\n",
      " [ 82  13  13  43  53   3   3]\n",
      " [ 19  33  47  31   3  41  36]\n",
      " [ 11  13   4   3   1  19 159]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.74      0.61       210\n",
      "           2       0.54      0.47      0.50       210\n",
      "           3       0.49      0.92      0.64       210\n",
      "           4       0.52      0.57      0.54       210\n",
      "           5       0.58      0.25      0.35       210\n",
      "           6       0.58      0.20      0.29       210\n",
      "           7       0.79      0.76      0.77       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.53      1470\n",
      "weighted avg       0.57      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7619047619047619\n",
      "Confusion Matrix of SVM is:\n",
      " [[174   1   0   4  13  16   2]\n",
      " [  0 173  11   7   2  17   0]\n",
      " [  0   1 183  10   0  16   0]\n",
      " [  0  12  18 150   2  24   4]\n",
      " [ 27  17  16  18 127   2   3]\n",
      " [  0   4   4  19   1 143  39]\n",
      " [  1   3   0   6   0  30 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.70      0.71      0.71       210\n",
      "           5       0.88      0.60      0.72       210\n",
      "           6       0.58      0.68      0.62       210\n",
      "           7       0.78      0.81      0.79       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   0   0   6  24  40   2]\n",
      " [  0 155   9  17   7  22   0]\n",
      " [  1   4 176   7   2  20   0]\n",
      " [  5   7   9 150   2  34   3]\n",
      " [ 14   9   7  28 118  30   4]\n",
      " [  5   6   1  13   1 148  36]\n",
      " [  0   0   0   2   1  58 149]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.74       210\n",
      "           2       0.86      0.74      0.79       210\n",
      "           3       0.87      0.84      0.85       210\n",
      "           4       0.67      0.71      0.69       210\n",
      "           5       0.76      0.56      0.65       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.77      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.74      0.70      0.71      1470\n",
      "weighted avg       0.74      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7625850340136054\n",
      "Confusion Matrix of SVM is:\n",
      " [[167   1   0   7  18  15   2]\n",
      " [  0 164  10  13   4  19   0]\n",
      " [  0   3 180  11   1  15   0]\n",
      " [  1   6   9 161   3  26   4]\n",
      " [ 20  15   9  23 134   4   5]\n",
      " [  1   6   1  20   2 140  40]\n",
      " [  0   2   0   5   1  27 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.80      0.84       210\n",
      "           2       0.83      0.78      0.81       210\n",
      "           3       0.86      0.86      0.86       210\n",
      "           4       0.67      0.77      0.72       210\n",
      "           5       0.82      0.64      0.72       210\n",
      "           6       0.57      0.67      0.61       210\n",
      "           7       0.77      0.83      0.80       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   2   0   5  27  14   4]\n",
      " [  1 155  21  12   4  17   0]\n",
      " [  0   1 160  30   0  19   0]\n",
      " [  0  11  19 150   2  20   8]\n",
      " [ 51  23  27  18  85   2   4]\n",
      " [  0   6   5  21   0 134  44]\n",
      " [  0   2   0   5   1  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.69      0.76      0.72       210\n",
      "           4       0.62      0.71      0.67       210\n",
      "           5       0.71      0.40      0.52       210\n",
      "           6       0.56      0.64      0.60       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.20136054421768707\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [124   0  86   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.16      0.20      0.12      1470\n",
      "weighted avg       0.16      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   1   0   0 154   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.25      0.26      0.19      1470\n",
      "weighted avg       0.25      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   0   0   0  55  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 68   0   1   0  52  89   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.52       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.25      0.33       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.25      1470\n",
      "weighted avg       0.32      0.30      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.354421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   0   0  55  77   0   0]\n",
      " [  0   0   2 206   2   0   0]\n",
      " [  0   0  86 124   0   0   0]\n",
      " [  0   0   1 208   1   0   0]\n",
      " [ 16   0   1  86 104   0   3]\n",
      " [  0   0   0 206   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.37      0.51       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.20      0.99      0.33       210\n",
      "           5       0.56      0.50      0.53       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.49      0.35      0.33      1470\n",
      "weighted avg       0.49      0.35      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  58   2   0   2 148   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 49   5   1   0  72  81   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   0   0   0   2 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.75      0.28      0.40       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.34      0.47       210\n",
      "           6       0.21      0.97      0.34       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.40      1470\n",
      "weighted avg       0.61      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  92   2   0   2 114   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 44  17   1   0  77  69   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.63      0.69       210\n",
      "           2       0.74      0.44      0.55       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.37      0.49       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.61      0.43      0.43      1470\n",
      "weighted avg       0.61      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   0   0  36  50   0]\n",
      " [  0 131   2   0   2  75   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   6   1   0   1 202   0]\n",
      " [ 34  22   1   0  87  64   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.68      0.41      0.51       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.61      0.46      0.45      1470\n",
      "weighted avg       0.61      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4884353741496599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   1   0  36  49   0]\n",
      " [  0 130  21   1   2  56   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   6  17   0   1 186   0]\n",
      " [ 29  22  19   0  92  46   2]\n",
      " [  0   3   2   0   0 201   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.26      0.96      0.41       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.59      0.49      0.47      1470\n",
      "weighted avg       0.59      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   0   0  36  49   0]\n",
      " [  0 147   3   1   3  56   0]\n",
      " [  0  31 101   0   0  78   0]\n",
      " [  0  22   1   0   1 184   2]\n",
      " [ 27  35   3   0  97  45   3]\n",
      " [  0   5   0   0   0 188  17]\n",
      " [  0   1   0   0   2 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.57      0.67       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.94      0.48      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.46      0.56       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.76      0.33      0.46       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.48      1470\n",
      "weighted avg       0.58      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   0  16  49   0]\n",
      " [  0 143   4   1   7  55   0]\n",
      " [  0  30 113   0   1  66   0]\n",
      " [  0  17   4   0   6 181   2]\n",
      " [ 58  29   3   0  72  46   2]\n",
      " [  0   4   1   0   1 187  17]\n",
      " [  2   1   0   0   0 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.68       210\n",
      "           2       0.62      0.68      0.65       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.34      0.46       210\n",
      "           6       0.26      0.89      0.40       210\n",
      "           7       0.77      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   5   0  49  36   0   0]\n",
      " [  0 143   4  56   7   0   0]\n",
      " [  0  30 113  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 31  26   3  46  99   1   4]\n",
      " [  0   4   1 182   1   1  21]\n",
      " [  0   1   0 111   2   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.26      0.87      0.40       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.62      0.51      0.50      1470\n",
      "weighted avg       0.62      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   5   0  50  46   0   0]\n",
      " [  0 131  15  56   8   0   0]\n",
      " [  0   0 143  66   1   0   0]\n",
      " [  0   7  11 182   6   0   4]\n",
      " [ 23  15  13  45 110   1   3]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   4   2 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.52      0.64       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.27      0.87      0.41       210\n",
      "           5       0.62      0.52      0.57       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.77      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.52      1470\n",
      "weighted avg       0.62      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   0  40  33   0   0]\n",
      " [  0 142   4  56   8   0   0]\n",
      " [  0  21 122  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 30  24   4  41 109   1   1]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   2   6 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.90      0.58      0.71       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.68      0.52      0.59       210\n",
      "           6       0.12      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   5   0  40  15   0   0]\n",
      " [  0 141   5  56   8   0   0]\n",
      " [  0  17 135  57   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 49  23   5  41  88   1   3]\n",
      " [  0   4   1 178   2   1  24]\n",
      " [  2   1   0  96   2   7 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.71      0.73       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.90      0.64      0.75       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.72      0.42      0.53       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.49      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.53      1470\n",
      "weighted avg       0.60      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   5   0  40  30   0   0]\n",
      " [  0 141   7  54   8   0   0]\n",
      " [  0  13 146  50   1   0   0]\n",
      " [  0  13   8 179   6   0   4]\n",
      " [ 36  23   5  40 104   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  0   1   0  96   5   7 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.87      0.70      0.77       210\n",
      "           4       0.28      0.85      0.42       210\n",
      "           5       0.67      0.50      0.57       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.48      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.54      1470\n",
      "weighted avg       0.60      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   5   0  40  20   0   0]\n",
      " [  0 140   8  53   9   0   0]\n",
      " [  0  13 151  45   1   0   0]\n",
      " [  0  13  11 176   6   0   4]\n",
      " [ 43  23   5  41  96   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  1   1   0  96   3   4 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.69      0.73       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.28      0.84      0.42       210\n",
      "           5       0.71      0.46      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.61      0.55      0.54      1470\n",
      "weighted avg       0.61      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   5   0  40  18   0   0]\n",
      " [  0 137   7  53  13   0   0]\n",
      " [  0   8 151  45   6   0   0]\n",
      " [  0  13   9 175   9   0   4]\n",
      " [ 43  17   5  40 100   1   4]\n",
      " [  0   5   1 173   2   1  28]\n",
      " [  1   1   0  88   5   4 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.70      0.73       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.29      0.83      0.42       210\n",
      "           5       0.65      0.48      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.76      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.61      0.56      0.55      1470\n",
      "weighted avg       0.61      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 138   8   1  11  52   0]\n",
      " [  0   8 153   0   4  45   0]\n",
      " [  0  13  10  13   8 162   4]\n",
      " [ 40  16   5   2 104  39   4]\n",
      " [  0   4   1   0   2 175  28]\n",
      " [  1   1   0   0   2  98 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.76      0.06      0.11       210\n",
      "           5       0.68      0.50      0.57       210\n",
      "           6       0.29      0.83      0.43       210\n",
      "           7       0.75      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.56      1470\n",
      "weighted avg       0.70      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 139   7   2  11  51   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 39  16   5   4 106  36   4]\n",
      " [  0   5   1   1   2 175  26]\n",
      " [  1   1   0   1   1  93 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.78      0.17      0.27       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.30      0.83      0.44       210\n",
      "           7       0.77      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   5   0   1  24  39   0]\n",
      " [  0 148   7   3  11  41   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 42  19   5   6 103  33   2]\n",
      " [  0   5   1   1   3 175  25]\n",
      " [  1   1   0   1   1  97 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.67      0.49      0.57       210\n",
      "           6       0.31      0.83      0.45       210\n",
      "           7       0.78      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   2  18   9  21   5]\n",
      " [  1 120  20  16   5  47   1]\n",
      " [  0   0 148  15   0  47   0]\n",
      " [  2   7  10 126   2  59   4]\n",
      " [ 62  28  13  31  47  15  14]\n",
      " [  0   4   4  35   0 129  38]\n",
      " [  0   1   0  17   0  45 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.73      0.57      0.64       210\n",
      "           3       0.75      0.70      0.73       210\n",
      "           4       0.49      0.60      0.54       210\n",
      "           5       0.75      0.22      0.34       210\n",
      "           6       0.36      0.61      0.45       210\n",
      "           7       0.70      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.59      1470\n",
      "weighted avg       0.64      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   5   3  19  10  21   5]\n",
      " [  1 130  16  10  15  37   1]\n",
      " [  0   0 157  13   0  40   0]\n",
      " [  1  10  13 124   4  54   4]\n",
      " [ 59  20   9  28  66  12  16]\n",
      " [  0   8   5  28   0 126  43]\n",
      " [  0   1   0  12   0  41 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70       210\n",
      "           2       0.75      0.62      0.68       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.69      0.31      0.43       210\n",
      "           6       0.38      0.60      0.47       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   1  16  11  22   5]\n",
      " [  0 128  17  13  15  36   1]\n",
      " [  0   0 160  14   0  36   0]\n",
      " [  1  12  11 130   6  46   4]\n",
      " [ 65  19  11  31  59  10  15]\n",
      " [  0   7   5  22   3 130  43]\n",
      " [  0   1   0   9   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.75      0.61      0.67       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.63      0.28      0.39       210\n",
      "           6       0.40      0.62      0.49       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0  10  12  28   3]\n",
      " [  0 133  16  12  12  36   1]\n",
      " [  0   0 162  12   0  36   0]\n",
      " [  1  11  11 121  10  52   4]\n",
      " [ 53  20   8  22  81  13  13]\n",
      " [  0   6   4  19   3 134  44]\n",
      " [  0   1   0   8   1  40 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.59      0.58      0.58       210\n",
      "           5       0.68      0.39      0.49       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0  11  13  27   4]\n",
      " [  0 129  17  14  16  33   1]\n",
      " [  0   0 163  13   0  34   0]\n",
      " [  1  11  10 123   8  53   4]\n",
      " [ 51  19   8  24  85  11  12]\n",
      " [  0   7   5  19   2 133  44]\n",
      " [  0   1   0   8   1  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.75      0.61      0.68       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.58      0.59      0.58       210\n",
      "           5       0.68      0.40      0.51       210\n",
      "           6       0.40      0.63      0.49       210\n",
      "           7       0.71      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0  15  14  24   2]\n",
      " [  1 134  15  11  14  35   0]\n",
      " [  0   0 161  14   0  35   0]\n",
      " [  0  11  10 136   9  41   3]\n",
      " [ 62  20   8  26  70  12  12]\n",
      " [  0   6   4  22   3 131  44]\n",
      " [  0   1   0   9   1  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.76      0.64      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.63      0.33      0.44       210\n",
      "           6       0.41      0.62      0.49       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  19  30   2]\n",
      " [  0 138  14  11  13  34   0]\n",
      " [  0   2 164  11   0  33   0]\n",
      " [  0  10  10 131   9  47   3]\n",
      " [ 55  18   8  18  84  16  11]\n",
      " [  0   6   5  16   3 135  45]\n",
      " [  0   2   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.69      0.71       210\n",
      "           2       0.76      0.66      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.65      0.40      0.50       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  13  30   2]\n",
      " [  0 138  15  11  14  32   0]\n",
      " [  0   0 166  12   0  32   0]\n",
      " [  0  13  10 132   8  44   3]\n",
      " [ 52  18   8  18  89  15  10]\n",
      " [  0   8   4  16   4 135  43]\n",
      " [  0   2   0   4   1  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.66      0.63      0.64       210\n",
      "           5       0.69      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  15  30   0]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   0 164  13   0  33   0]\n",
      " [  0  13  10 129  12  43   3]\n",
      " [ 49  18   8  18  91  16  10]\n",
      " [  0   8   4  17   3 134  44]\n",
      " [  0   1   0   5   1  42 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   5   0   9  22  30   1]\n",
      " [  0 138  15   9  15  33   0]\n",
      " [  0   0 167  12   0  31   0]\n",
      " [  0  12  10 134  10  41   3]\n",
      " [ 42  18   8  18  99  15  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   1   0   6   2  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.77      0.66      0.71       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.41      0.65      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   5   0   9  23  29   0]\n",
      " [  0 140  17  10  14  29   0]\n",
      " [  0   0 173  14   0  23   0]\n",
      " [  0  11  11 133  10  42   3]\n",
      " [ 41  15   9  19 104  12  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   0   0   5   2  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.69      0.73       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.66      0.50      0.57       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0   9  17  29   0]\n",
      " [  0 143  11  10  15  31   0]\n",
      " [  0   1 172  11   0  26   0]\n",
      " [  0   9   8 134   9  47   3]\n",
      " [ 41  17   8  18 105  12   9]\n",
      " [  0   7   1  16   4 141  41]\n",
      " [  1   0   0   5   2  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.75       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.86      0.82      0.84       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  21  29   1]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   4 174   9   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   8  17 112  13   9]\n",
      " [  0   5   3  16   4 140  42]\n",
      " [  0   1   0   6   2  43 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.69      0.75       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.82      0.83      0.82       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   0   9  14  29   0]\n",
      " [  0 141  14   9  16  30   0]\n",
      " [  0   1 175  11   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   7  16 114  13   9]\n",
      " [  0   4   3  16   5 138  44]\n",
      " [  1   1   0   5   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77       210\n",
      "           2       0.79      0.67      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.43      0.66      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   0   9  16  29   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   5 171  10   0  24   0]\n",
      " [  0  10  10 134  10  42   4]\n",
      " [ 38  18   7  20 109  10   8]\n",
      " [  0   5   3  14   5 142  41]\n",
      " [  1   1   0   5   1  43 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.44      0.68      0.54       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   5   0   9  25  29   0]\n",
      " [  0 141  15  12  13  29   0]\n",
      " [  0   1 175  10   0  24   0]\n",
      " [  0  10  10 133  11  42   4]\n",
      " [ 37  16   8  17 111  12   9]\n",
      " [  0   6   2  16   5 142  39]\n",
      " [  1   1   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.78      0.67      0.72       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   0   9  21  29   0]\n",
      " [  0 141  14  11  14  30   0]\n",
      " [  0   4 171  10   0  25   0]\n",
      " [  0   8   9 137  12  41   3]\n",
      " [ 31  17   7  20 115  11   9]\n",
      " [  0   4   1  14   7 146  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.75       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.67      0.55      0.60       210\n",
      "           6       0.45      0.70      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 146  14   9  11  30   0]\n",
      " [  0   4 175   7   0  24   0]\n",
      " [  0  11  11 134  10  41   3]\n",
      " [ 36  21   7  20 109   8   9]\n",
      " [  0   6   3  14   5 144  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.45      0.69      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   0   9  28  28   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   4 175   7   1  23   0]\n",
      " [  0   7  10 135  12  43   3]\n",
      " [ 29  20   7  16 118  11   9]\n",
      " [  0   5   2  13   6 144  40]\n",
      " [  1   1   0   5   3  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.65      0.56      0.60       210\n",
      "           6       0.45      0.69      0.54       210\n",
      "           7       0.75      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6979591836734694\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   5   0   8  20  29   0]\n",
      " [  0 150  12  10   8  30   0]\n",
      " [  0   2 176   8   0  24   0]\n",
      " [  0   9  10 135  11  42   3]\n",
      " [ 30  20   8  16 118  10   8]\n",
      " [  0   5   3  15   6 141  40]\n",
      " [  1   0   0   5   2  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.72      0.56      0.63       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.76      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[150   1   0   6  47   5   1]\n",
      " [ 12 150   9  10  25   4   0]\n",
      " [ 14   3 179  10   2   2   0]\n",
      " [ 18   6  12 149  11  10   4]\n",
      " [ 24  11  11  21 135   6   2]\n",
      " [ 36  12   1  22   6  93  40]\n",
      " [  4   2   0   2   1  22 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.71      0.64       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.68      0.71      0.69       210\n",
      "           5       0.59      0.64      0.62       210\n",
      "           6       0.65      0.44      0.53       210\n",
      "           7       0.79      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7496598639455783\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[165   3   1   9  15  15   2]\n",
      " [  0 163  15   6   6  20   0]\n",
      " [  0   1 181   9   0  19   0]\n",
      " [  1   9  17 162   2  16   3]\n",
      " [ 24  18  18  17 125   2   6]\n",
      " [  0   7   4  23   2 139  35]\n",
      " [  0   3   0   6   1  33 167]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.79      0.82       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.77      0.86      0.81       210\n",
      "           4       0.70      0.77      0.73       210\n",
      "           5       0.83      0.60      0.69       210\n",
      "           6       0.57      0.66      0.61       210\n",
      "           7       0.78      0.80      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6068027210884354\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   8   3   3  14  32   1]\n",
      " [  4 155  23   2   8  18   0]\n",
      " [  5   5 180   5   0  15   0]\n",
      " [ 16  19  23 104   5  43   0]\n",
      " [ 54  25  23  14  49  44   1]\n",
      " [ 13  14   4  12   0 150  17]\n",
      " [  5   3   0   4   1  92 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.71      0.65       210\n",
      "           2       0.68      0.74      0.71       210\n",
      "           3       0.70      0.86      0.77       210\n",
      "           4       0.72      0.50      0.59       210\n",
      "           5       0.64      0.23      0.34       210\n",
      "           6       0.38      0.71      0.50       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.65      0.61      0.60      1470\n",
      "weighted avg       0.65      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153  11   2   5   8  31   0]\n",
      " [  3 156  23   6   4  18   0]\n",
      " [  3   2 183   7   0  15   0]\n",
      " [ 12  21  31 108   3  35   0]\n",
      " [ 57  39  29  17  39  29   0]\n",
      " [  9  16   9  20   0 140  16]\n",
      " [ 12  15   5   5   0  74  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.73      0.67       210\n",
      "           2       0.60      0.74      0.66       210\n",
      "           3       0.65      0.87      0.74       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.72      0.19      0.30       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.86      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.58      1470\n",
      "weighted avg       0.64      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155  12   3   6   7  26   1]\n",
      " [  2 153  24   7   5  19   0]\n",
      " [  3   3 182   8   0  14   0]\n",
      " [ 10  16  30 114   1  39   0]\n",
      " [ 60  34  30  18  31  36   1]\n",
      " [  8  18   5  16   0 149  14]\n",
      " [  8  16   5   6   0  81  94]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.74      0.68       210\n",
      "           2       0.61      0.73      0.66       210\n",
      "           3       0.65      0.87      0.74       210\n",
      "           4       0.65      0.54      0.59       210\n",
      "           5       0.70      0.15      0.24       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.85      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.58      1470\n",
      "weighted avg       0.64      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5870748299319728\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   9   2   7   6  33   1]\n",
      " [  2 158  24   6   3  17   0]\n",
      " [  3   1 185   8   0  13   0]\n",
      " [ 13  13  30 112   0  42   0]\n",
      " [ 70  35  29  16  23  36   1]\n",
      " [  9  16   6  17   0 149  13]\n",
      " [  6  23   3   5   0  89  84]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.72      0.65       210\n",
      "           2       0.62      0.75      0.68       210\n",
      "           3       0.66      0.88      0.76       210\n",
      "           4       0.65      0.53      0.59       210\n",
      "           5       0.72      0.11      0.19       210\n",
      "           6       0.39      0.71      0.51       210\n",
      "           7       0.85      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.56      1470\n",
      "weighted avg       0.64      0.59      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.582312925170068\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151  10   3   5   3  37   1]\n",
      " [  2 153  25   7   3  20   0]\n",
      " [  2   1 184   9   0  14   0]\n",
      " [ 14  10  29 112   0  45   0]\n",
      " [ 68  35  27  13  25  41   1]\n",
      " [  8  17   5  16   0 146  18]\n",
      " [  5  19   5   7   0  89  85]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.72      0.66       210\n",
      "           2       0.62      0.73      0.67       210\n",
      "           3       0.66      0.88      0.75       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.81      0.12      0.21       210\n",
      "           6       0.37      0.70      0.49       210\n",
      "           7       0.81      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.65      0.58      0.56      1470\n",
      "weighted avg       0.65      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.580952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148  13   1   7   2  39   0]\n",
      " [  2 153  26   7   2  20   0]\n",
      " [  2   0 183   9   0  16   0]\n",
      " [  7  11  29 112   0  51   0]\n",
      " [ 62  31  30  15  24  47   1]\n",
      " [  4  19   4  14   0 156  13]\n",
      " [  4  17   7   5   0  99  78]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.70      0.67       210\n",
      "           2       0.63      0.73      0.67       210\n",
      "           3       0.65      0.87      0.75       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.86      0.11      0.20       210\n",
      "           6       0.36      0.74      0.49       210\n",
      "           7       0.85      0.37      0.52       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.67      0.58      0.56      1470\n",
      "weighted avg       0.67      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[156   2   9  19  21   1   2]\n",
      " [  9  98  89   7   4   3   0]\n",
      " [  4   6 193   6   0   0   1]\n",
      " [ 19  18  41 119   9   4   0]\n",
      " [ 82  13  13  43  53   3   3]\n",
      " [ 19  33  47  31   3  41  36]\n",
      " [ 11  13   4   3   1  19 159]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.74      0.61       210\n",
      "           2       0.54      0.47      0.50       210\n",
      "           3       0.49      0.92      0.64       210\n",
      "           4       0.52      0.57      0.54       210\n",
      "           5       0.58      0.25      0.35       210\n",
      "           6       0.58      0.20      0.29       210\n",
      "           7       0.79      0.76      0.77       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.53      1470\n",
      "weighted avg       0.57      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7619047619047619\n",
      "Confusion Matrix of SVM is:\n",
      " [[174   1   0   4  13  16   2]\n",
      " [  0 173  11   7   2  17   0]\n",
      " [  0   1 183  10   0  16   0]\n",
      " [  0  12  18 150   2  24   4]\n",
      " [ 27  17  16  18 127   2   3]\n",
      " [  0   4   4  19   1 143  39]\n",
      " [  1   3   0   6   0  30 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.70      0.71      0.71       210\n",
      "           5       0.88      0.60      0.72       210\n",
      "           6       0.58      0.68      0.62       210\n",
      "           7       0.78      0.81      0.79       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   0   0   6  24  40   2]\n",
      " [  0 155   9  17   7  22   0]\n",
      " [  1   4 176   7   2  20   0]\n",
      " [  5   7   9 150   2  34   3]\n",
      " [ 14   9   7  28 118  30   4]\n",
      " [  5   6   1  13   1 148  36]\n",
      " [  0   0   0   2   1  58 149]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.74       210\n",
      "           2       0.86      0.74      0.79       210\n",
      "           3       0.87      0.84      0.85       210\n",
      "           4       0.67      0.71      0.69       210\n",
      "           5       0.76      0.56      0.65       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.77      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.74      0.70      0.71      1470\n",
      "weighted avg       0.74      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7625850340136054\n",
      "Confusion Matrix of SVM is:\n",
      " [[167   1   0   7  18  15   2]\n",
      " [  0 164  10  13   4  19   0]\n",
      " [  0   3 180  11   1  15   0]\n",
      " [  1   6   9 161   3  26   4]\n",
      " [ 20  15   9  23 134   4   5]\n",
      " [  1   6   1  20   2 140  40]\n",
      " [  0   2   0   5   1  27 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.80      0.84       210\n",
      "           2       0.83      0.78      0.81       210\n",
      "           3       0.86      0.86      0.86       210\n",
      "           4       0.67      0.77      0.72       210\n",
      "           5       0.82      0.64      0.72       210\n",
      "           6       0.57      0.67      0.61       210\n",
      "           7       0.77      0.83      0.80       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   2   0   5  27  14   4]\n",
      " [  1 155  21  12   4  17   0]\n",
      " [  0   1 160  30   0  19   0]\n",
      " [  0  11  19 150   2  20   8]\n",
      " [ 51  22  27  19  85   2   4]\n",
      " [  0   6   5  22   0 133  44]\n",
      " [  0   2   0   5   1  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.69      0.76      0.72       210\n",
      "           4       0.62      0.71      0.66       210\n",
      "           5       0.71      0.40      0.52       210\n",
      "           6       0.56      0.63      0.59       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.20136054421768707\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [124   0  86   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.16      0.20      0.12      1470\n",
      "weighted avg       0.16      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   1   0   0 154   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.25      0.26      0.19      1470\n",
      "weighted avg       0.25      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   0   0   0  55  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 68   0   1   0  52  89   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.52       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.25      0.33       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.25      1470\n",
      "weighted avg       0.32      0.30      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.354421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   0   0  55  77   0   0]\n",
      " [  0   0   2 206   2   0   0]\n",
      " [  0   0  86 124   0   0   0]\n",
      " [  0   0   1 208   1   0   0]\n",
      " [ 16   0   1  86 104   0   3]\n",
      " [  0   0   0 206   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.37      0.51       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.20      0.99      0.33       210\n",
      "           5       0.56      0.50      0.53       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.49      0.35      0.33      1470\n",
      "weighted avg       0.49      0.35      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  58   2   0   2 148   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 49   5   1   0  72  81   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   0   0   0   2 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.75      0.28      0.40       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.34      0.47       210\n",
      "           6       0.21      0.97      0.34       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.40      1470\n",
      "weighted avg       0.61      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  92   2   0   2 114   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 44  17   1   0  77  69   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.63      0.69       210\n",
      "           2       0.74      0.44      0.55       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.37      0.49       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.61      0.43      0.43      1470\n",
      "weighted avg       0.61      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   0   0  36  50   0]\n",
      " [  0 131   2   0   2  75   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   6   1   0   1 202   0]\n",
      " [ 34  22   1   0  87  64   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.68      0.41      0.51       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.61      0.46      0.45      1470\n",
      "weighted avg       0.61      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   1   0  36  49   0]\n",
      " [  0 130  21   1   2  56   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   6  17   0   1 186   0]\n",
      " [ 29  22  19   0  92  46   2]\n",
      " [  0   3   2   0   0 201   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.26      0.96      0.41       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.59      0.49      0.47      1470\n",
      "weighted avg       0.59      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   0   0  36  49   0]\n",
      " [  0 147   3   1   3  56   0]\n",
      " [  0  31 101   0   0  78   0]\n",
      " [  0  22   1   0   1 184   2]\n",
      " [ 27  35   3   0  97  45   3]\n",
      " [  0   5   0   0   0 188  17]\n",
      " [  0   1   0   0   2 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.57      0.67       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.94      0.48      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.46      0.56       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.76      0.33      0.46       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.48      1470\n",
      "weighted avg       0.58      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   0  16  49   0]\n",
      " [  0 143   4   1   7  55   0]\n",
      " [  0  30 113   0   1  66   0]\n",
      " [  0  17   4   0   6 181   2]\n",
      " [ 58  29   3   0  72  46   2]\n",
      " [  0   4   1   0   1 187  17]\n",
      " [  2   1   0   0   0 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.68       210\n",
      "           2       0.62      0.68      0.65       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.34      0.46       210\n",
      "           6       0.26      0.89      0.40       210\n",
      "           7       0.77      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   5   0  49  36   0   0]\n",
      " [  0 143   4  56   7   0   0]\n",
      " [  0  30 113  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 31  26   3  46  99   1   4]\n",
      " [  0   4   1 182   1   1  21]\n",
      " [  0   1   0 111   2   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.26      0.87      0.40       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.62      0.51      0.50      1470\n",
      "weighted avg       0.62      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   5   0  50  46   0   0]\n",
      " [  0 131  15  56   8   0   0]\n",
      " [  0   0 143  66   1   0   0]\n",
      " [  0   7  11 182   6   0   4]\n",
      " [ 23  15  13  45 110   1   3]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   4   2 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.52      0.64       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.27      0.87      0.41       210\n",
      "           5       0.62      0.52      0.57       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.77      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.52      1470\n",
      "weighted avg       0.62      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   0  40  33   0   0]\n",
      " [  0 142   4  56   8   0   0]\n",
      " [  0  21 122  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 30  24   4  41 109   1   1]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   2   6 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.90      0.58      0.71       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.68      0.52      0.59       210\n",
      "           6       0.12      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   5   0  40  15   0   0]\n",
      " [  0 141   5  56   8   0   0]\n",
      " [  0  17 135  57   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 49  23   5  41  88   1   3]\n",
      " [  0   4   1 178   2   1  24]\n",
      " [  2   1   0  96   2   7 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.71      0.73       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.90      0.64      0.75       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.72      0.42      0.53       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.49      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.53      1470\n",
      "weighted avg       0.60      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   5   0  40  30   0   0]\n",
      " [  0 141   7  54   8   0   0]\n",
      " [  0  13 146  50   1   0   0]\n",
      " [  0  13   8 179   6   0   4]\n",
      " [ 36  23   5  40 104   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  0   1   0  96   5   7 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.87      0.70      0.77       210\n",
      "           4       0.28      0.85      0.42       210\n",
      "           5       0.67      0.50      0.57       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.48      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.54      1470\n",
      "weighted avg       0.60      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   5   0  40  20   0   0]\n",
      " [  0 140   8  53   9   0   0]\n",
      " [  0  13 151  45   1   0   0]\n",
      " [  0  13  11 176   6   0   4]\n",
      " [ 43  23   5  41  96   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  1   1   0  96   3   4 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.69      0.73       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.28      0.84      0.42       210\n",
      "           5       0.71      0.46      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.61      0.55      0.54      1470\n",
      "weighted avg       0.61      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   5   0  40  18   0   0]\n",
      " [  0 137   7  53  13   0   0]\n",
      " [  0   8 151  45   6   0   0]\n",
      " [  0  13   9 175   9   0   4]\n",
      " [ 43  17   5  40 100   1   4]\n",
      " [  0   5   1 173   2   1  28]\n",
      " [  1   1   0  88   5   4 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.70      0.73       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.29      0.83      0.42       210\n",
      "           5       0.65      0.48      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.76      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.61      0.56      0.55      1470\n",
      "weighted avg       0.61      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 138   8   1  11  52   0]\n",
      " [  0   8 153   0   4  45   0]\n",
      " [  0  13  10  13   8 162   4]\n",
      " [ 40  16   5   2 104  39   4]\n",
      " [  0   4   1   0   2 175  28]\n",
      " [  1   1   0   0   2  98 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.76      0.06      0.11       210\n",
      "           5       0.68      0.50      0.57       210\n",
      "           6       0.29      0.83      0.43       210\n",
      "           7       0.75      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.56      1470\n",
      "weighted avg       0.70      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 139   7   2  11  51   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 39  16   5   4 106  36   4]\n",
      " [  0   5   1   1   2 175  26]\n",
      " [  1   1   0   1   1  93 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.78      0.17      0.27       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.30      0.83      0.44       210\n",
      "           7       0.77      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   5   0   1  24  39   0]\n",
      " [  0 148   7   3  11  41   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 42  19   5   6 103  33   2]\n",
      " [  0   5   1   1   3 175  25]\n",
      " [  1   1   0   1   1  97 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.67      0.49      0.57       210\n",
      "           6       0.31      0.83      0.45       210\n",
      "           7       0.78      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   2  18   9  21   5]\n",
      " [  1 120  20  16   5  47   1]\n",
      " [  0   0 148  15   0  47   0]\n",
      " [  2   7  10 126   2  59   4]\n",
      " [ 62  28  13  31  47  15  14]\n",
      " [  0   4   4  35   0 129  38]\n",
      " [  0   1   0  17   0  45 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.73      0.57      0.64       210\n",
      "           3       0.75      0.70      0.73       210\n",
      "           4       0.49      0.60      0.54       210\n",
      "           5       0.75      0.22      0.34       210\n",
      "           6       0.36      0.61      0.45       210\n",
      "           7       0.70      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.59      1470\n",
      "weighted avg       0.64      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   5   3  19  10  21   5]\n",
      " [  1 130  16  10  15  37   1]\n",
      " [  0   0 157  13   0  40   0]\n",
      " [  1  10  13 124   4  54   4]\n",
      " [ 59  20   9  28  66  12  16]\n",
      " [  0   8   5  28   0 126  43]\n",
      " [  0   1   0  12   0  41 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70       210\n",
      "           2       0.75      0.62      0.68       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.69      0.31      0.43       210\n",
      "           6       0.38      0.60      0.47       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   1  16  11  22   5]\n",
      " [  0 128  17  13  15  36   1]\n",
      " [  0   0 160  14   0  36   0]\n",
      " [  1  12  11 130   6  46   4]\n",
      " [ 65  19  11  31  59  10  15]\n",
      " [  0   7   5  22   3 130  43]\n",
      " [  0   1   0   9   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.75      0.61      0.67       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.63      0.28      0.39       210\n",
      "           6       0.40      0.62      0.49       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0  10  12  28   3]\n",
      " [  0 133  16  12  12  36   1]\n",
      " [  0   0 162  12   0  36   0]\n",
      " [  1  11  11 121  10  52   4]\n",
      " [ 53  20   8  22  81  13  13]\n",
      " [  0   6   4  19   3 134  44]\n",
      " [  0   1   0   8   1  40 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.59      0.58      0.58       210\n",
      "           5       0.68      0.39      0.49       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0  11  13  27   4]\n",
      " [  0 129  17  14  16  33   1]\n",
      " [  0   0 163  13   0  34   0]\n",
      " [  1  11  10 123   8  53   4]\n",
      " [ 51  19   8  24  85  11  12]\n",
      " [  0   7   5  19   2 133  44]\n",
      " [  0   1   0   8   1  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.75      0.61      0.68       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.58      0.59      0.58       210\n",
      "           5       0.68      0.40      0.51       210\n",
      "           6       0.40      0.63      0.49       210\n",
      "           7       0.71      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0  15  14  24   2]\n",
      " [  1 134  15  11  14  35   0]\n",
      " [  0   0 161  14   0  35   0]\n",
      " [  0  11  10 136   9  41   3]\n",
      " [ 62  20   8  26  70  12  12]\n",
      " [  0   6   4  22   3 131  44]\n",
      " [  0   1   0   9   1  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.76      0.64      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.63      0.33      0.44       210\n",
      "           6       0.41      0.62      0.49       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  19  30   2]\n",
      " [  0 138  14  11  13  34   0]\n",
      " [  0   2 164  11   0  33   0]\n",
      " [  0  10  10 131   9  47   3]\n",
      " [ 55  18   8  18  84  16  11]\n",
      " [  0   6   5  16   3 135  45]\n",
      " [  0   2   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.69      0.71       210\n",
      "           2       0.76      0.66      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.65      0.40      0.50       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  13  30   2]\n",
      " [  0 138  15  11  14  32   0]\n",
      " [  0   0 166  12   0  32   0]\n",
      " [  0  13  10 132   8  44   3]\n",
      " [ 52  18   8  18  89  15  10]\n",
      " [  0   8   4  16   4 135  43]\n",
      " [  0   2   0   4   1  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.66      0.63      0.64       210\n",
      "           5       0.69      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  15  30   0]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   0 164  13   0  33   0]\n",
      " [  0  13  10 129  12  43   3]\n",
      " [ 49  18   8  18  91  16  10]\n",
      " [  0   8   4  17   3 134  44]\n",
      " [  0   1   0   5   1  42 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   5   0   9  22  30   1]\n",
      " [  0 138  15   9  15  33   0]\n",
      " [  0   0 167  12   0  31   0]\n",
      " [  0  12  10 134  10  41   3]\n",
      " [ 42  18   8  18  99  15  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   1   0   6   2  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.77      0.66      0.71       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.41      0.65      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   5   0   9  23  29   0]\n",
      " [  0 140  17  10  14  29   0]\n",
      " [  0   0 173  14   0  23   0]\n",
      " [  0  11  11 133  10  42   3]\n",
      " [ 41  15   9  19 104  12  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   0   0   5   2  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.69      0.73       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.66      0.50      0.57       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0   9  17  29   0]\n",
      " [  0 143  11  10  15  31   0]\n",
      " [  0   1 172  11   0  26   0]\n",
      " [  0   9   8 134   9  47   3]\n",
      " [ 41  17   8  18 105  12   9]\n",
      " [  0   7   1  16   4 141  41]\n",
      " [  1   0   0   5   2  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.75       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.86      0.82      0.84       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  21  29   1]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   4 174   9   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   8  17 112  13   9]\n",
      " [  0   5   3  16   4 140  42]\n",
      " [  0   1   0   6   2  43 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.69      0.75       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.82      0.83      0.82       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   0   9  14  29   0]\n",
      " [  0 141  14   9  16  30   0]\n",
      " [  0   1 175  11   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   7  16 114  13   9]\n",
      " [  0   4   3  16   5 138  44]\n",
      " [  1   1   0   5   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77       210\n",
      "           2       0.79      0.67      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.43      0.66      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   0   9  16  29   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   5 171  10   0  24   0]\n",
      " [  0  10  10 134  10  42   4]\n",
      " [ 38  18   7  20 109  10   8]\n",
      " [  0   5   3  14   5 142  41]\n",
      " [  1   1   0   5   1  43 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.44      0.68      0.54       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   5   0   9  25  29   0]\n",
      " [  0 141  15  12  13  29   0]\n",
      " [  0   1 175  10   0  24   0]\n",
      " [  0  10  10 133  11  42   4]\n",
      " [ 37  16   8  17 111  12   9]\n",
      " [  0   6   2  16   5 142  39]\n",
      " [  1   1   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.78      0.67      0.72       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   0   9  21  29   0]\n",
      " [  0 141  14  11  14  30   0]\n",
      " [  0   4 171  10   0  25   0]\n",
      " [  0   8   9 137  12  41   3]\n",
      " [ 31  17   7  20 115  11   9]\n",
      " [  0   4   1  14   7 146  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.75       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.67      0.55      0.60       210\n",
      "           6       0.45      0.70      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 146  14   9  11  30   0]\n",
      " [  0   4 175   7   0  24   0]\n",
      " [  0  11  11 134  10  41   3]\n",
      " [ 36  21   7  20 109   8   9]\n",
      " [  0   6   3  14   5 144  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.45      0.69      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   0   9  28  28   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   4 175   7   1  23   0]\n",
      " [  0   7  10 135  12  43   3]\n",
      " [ 29  20   7  16 118  11   9]\n",
      " [  0   5   2  13   6 144  40]\n",
      " [  1   1   0   5   3  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.65      0.56      0.60       210\n",
      "           6       0.45      0.69      0.54       210\n",
      "           7       0.75      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6979591836734694\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   5   0   8  20  29   0]\n",
      " [  0 150  12  10   8  30   0]\n",
      " [  0   2 176   8   0  24   0]\n",
      " [  0   9  10 135  11  42   3]\n",
      " [ 30  20   8  16 118  10   8]\n",
      " [  0   5   3  15   6 141  40]\n",
      " [  1   0   0   5   2  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.72      0.56      0.63       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.76      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[150   1   0   6  47   5   1]\n",
      " [ 12 150   9  10  25   4   0]\n",
      " [ 14   3 179  10   2   2   0]\n",
      " [ 18   6  12 149  11  10   4]\n",
      " [ 24  11  11  21 135   6   2]\n",
      " [ 36  12   1  22   6  93  40]\n",
      " [  4   2   0   2   1  22 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.71      0.64       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.68      0.71      0.69       210\n",
      "           5       0.59      0.64      0.62       210\n",
      "           6       0.65      0.44      0.53       210\n",
      "           7       0.79      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[147   2   1   8  29  20   3]\n",
      " [  2 160   8  12  13  13   2]\n",
      " [  1   2 192   6   2   7   0]\n",
      " [  5  11  23 112  19  25  15]\n",
      " [ 24  20   5   8 146   3   4]\n",
      " [ 12   7   7  14   4 104  62]\n",
      " [  2   1   0   3   1  28 175]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73       210\n",
      "           2       0.79      0.76      0.77       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.69      0.53      0.60       210\n",
      "           5       0.68      0.70      0.69       210\n",
      "           6       0.52      0.50      0.51       210\n",
      "           7       0.67      0.83      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   5   2   5  36  10   2]\n",
      " [  3 164   9  11  18   4   1]\n",
      " [  4   9 189   6   1   1   0]\n",
      " [ 19  22  15 124  18  10   2]\n",
      " [ 34  28   3  11 128   2   4]\n",
      " [ 28  19  11  21   8  77  46]\n",
      " [ 11   4   0  12   4  28 151]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.71      0.65       210\n",
      "           2       0.65      0.78      0.71       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.60      0.61      0.61       210\n",
      "           6       0.58      0.37      0.45       210\n",
      "           7       0.73      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   4   0   9  30  15   3]\n",
      " [  2 169   9  11  15   2   2]\n",
      " [  3   8 191   6   1   1   0]\n",
      " [ 11  17  17 129  20  15   1]\n",
      " [ 30  31   7  12 125   1   4]\n",
      " [ 25  14   8  16  10  96  41]\n",
      " [  7   4   0   8   4  44 143]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.71      0.68       210\n",
      "           2       0.68      0.80      0.74       210\n",
      "           3       0.82      0.91      0.86       210\n",
      "           4       0.68      0.61      0.64       210\n",
      "           5       0.61      0.60      0.60       210\n",
      "           6       0.55      0.46      0.50       210\n",
      "           7       0.74      0.68      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   2   1  10  32  14   2]\n",
      " [  1 164  12   9  20   2   2]\n",
      " [  3   6 190   7   0   4   0]\n",
      " [ 15  19  14 128  19  14   1]\n",
      " [ 28  27   8  11 132   2   2]\n",
      " [ 22  13   8  21  10  86  50]\n",
      " [  7   2   0  11   4  31 155]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.71      0.69       210\n",
      "           2       0.70      0.78      0.74       210\n",
      "           3       0.82      0.90      0.86       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.61      0.63      0.62       210\n",
      "           6       0.56      0.41      0.47       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6884353741496598\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   5   0   6  32  13   3]\n",
      " [  3 170  12   5  15   2   3]\n",
      " [  3   9 189   6   0   3   0]\n",
      " [ 16  16  16 123  27  11   1]\n",
      " [ 29  29   9   8 132   1   2]\n",
      " [ 17  15   8  17  10  94  49]\n",
      " [  6   2   0  10   8  31 153]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.69       210\n",
      "           2       0.69      0.81      0.75       210\n",
      "           3       0.81      0.90      0.85       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.61      0.45      0.52       210\n",
      "           7       0.73      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   4   1   7  33  13   3]\n",
      " [  3 161  13   5  24   2   2]\n",
      " [  3   7 191   6   0   3   0]\n",
      " [ 16  15  15 121  28  13   2]\n",
      " [ 29  25   9   8 136   0   3]\n",
      " [ 16  12   9  20  11  90  52]\n",
      " [  4   2   0  13   4  27 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.71      0.69       210\n",
      "           2       0.71      0.77      0.74       210\n",
      "           3       0.80      0.91      0.85       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.58      0.65      0.61       210\n",
      "           6       0.61      0.43      0.50       210\n",
      "           7       0.72      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   4   0   4  36  11   3]\n",
      " [  3 165  12   5  21   2   2]\n",
      " [  3   8 194   2   0   3   0]\n",
      " [ 19  13  19 116  30  11   2]\n",
      " [ 28  24  10   8 137   0   3]\n",
      " [ 17  14   9  18  12  85  55]\n",
      " [  2   3   0  11   6  30 158]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.71      0.79      0.75       210\n",
      "           3       0.80      0.92      0.85       210\n",
      "           4       0.71      0.55      0.62       210\n",
      "           5       0.57      0.65      0.61       210\n",
      "           6       0.60      0.40      0.48       210\n",
      "           7       0.71      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   2  15   6  48  32   7]\n",
      " [  2 113  31   8  28  26   2]\n",
      " [  1  11 175   5   0  18   0]\n",
      " [  5  15  29  40  58  45  18]\n",
      " [ 14  32   9   4 132   7  12]\n",
      " [  5   7   6  11  11 116  54]\n",
      " [  0   0   0   2   2  56 150]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.48      0.59       210\n",
      "           2       0.63      0.54      0.58       210\n",
      "           3       0.66      0.83      0.74       210\n",
      "           4       0.53      0.19      0.28       210\n",
      "           5       0.47      0.63      0.54       210\n",
      "           6       0.39      0.55      0.45       210\n",
      "           7       0.62      0.71      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 98   1  13   7  49  33   9]\n",
      " [  1 126  15   9  30  28   1]\n",
      " [  2  11 172   5   0  20   0]\n",
      " [  7  14  29  39  59  43  19]\n",
      " [ 15  33   6   8 128   6  14]\n",
      " [  5   5   9  15  11 112  53]\n",
      " [  0   0   0   1   4  61 144]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.47      0.58       210\n",
      "           2       0.66      0.60      0.63       210\n",
      "           3       0.70      0.82      0.76       210\n",
      "           4       0.46      0.19      0.27       210\n",
      "           5       0.46      0.61      0.52       210\n",
      "           6       0.37      0.53      0.44       210\n",
      "           7       0.60      0.69      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   0   0   6  30  19   1]\n",
      " [  1 157   9  16  15   9   3]\n",
      " [  1   6 189   5   2   7   0]\n",
      " [  3  10  20 121  16  30  10]\n",
      " [ 22  17   5   7 153   2   4]\n",
      " [  4   8   6  11   7 120  54]\n",
      " [  0   0   0   0   3  28 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.73      0.78       210\n",
      "           2       0.79      0.75      0.77       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.73      0.58      0.64       210\n",
      "           5       0.68      0.73      0.70       210\n",
      "           6       0.56      0.57      0.56       210\n",
      "           7       0.71      0.85      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7673469387755102\n",
      "Confusion Matrix of SVM is:\n",
      " [[157   0   0   8  27  17   1]\n",
      " [  1 167   7  10  14   9   2]\n",
      " [  1   3 196   2   2   6   0]\n",
      " [  5   6  10 151  14  18   6]\n",
      " [ 18  17   2  10 156   3   4]\n",
      " [  4   7   0  14   7 121  57]\n",
      " [  1   0   0   1   3  25 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.75      0.79       210\n",
      "           2       0.83      0.80      0.81       210\n",
      "           3       0.91      0.93      0.92       210\n",
      "           4       0.77      0.72      0.74       210\n",
      "           5       0.70      0.74      0.72       210\n",
      "           6       0.61      0.58      0.59       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7557823129251701\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   0   0   6  27  18   1]\n",
      " [  1 163   7  13  15   9   2]\n",
      " [  1   4 193   4   2   6   0]\n",
      " [  4   6  11 141  17  24   7]\n",
      " [ 19  17   3   9 155   3   4]\n",
      " [  5   7   1  15   6 122  54]\n",
      " [  0   0   0   1   3  27 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.75      0.79       210\n",
      "           2       0.83      0.78      0.80       210\n",
      "           3       0.90      0.92      0.91       210\n",
      "           4       0.75      0.67      0.71       210\n",
      "           5       0.69      0.74      0.71       210\n",
      "           6       0.58      0.58      0.58       210\n",
      "           7       0.72      0.85      0.78       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[150   1   2   4  32  17   4]\n",
      " [  2 147  15  16  18   7   5]\n",
      " [  1   6 190   5   2   6   0]\n",
      " [  3  16  25  99  21  28  18]\n",
      " [ 29  22   3   6 143   3   4]\n",
      " [ 10   7  11  14   8  81  79]\n",
      " [  1   0   0   3   5  18 183]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.77      0.90      0.83       210\n",
      "           4       0.67      0.47      0.55       210\n",
      "           5       0.62      0.68      0.65       210\n",
      "           6       0.51      0.39      0.44       210\n",
      "           7       0.62      0.87      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.24761904761904763\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   5   0   0   0 205]\n",
      " [  0   0  30   0   0   0 180]\n",
      " [  0   0 157   0   0   0  53]\n",
      " [  0   0  24   0   0   0 186]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0  15   0   0   0 195]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.66      0.75      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.99      0.29       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.12      0.25      0.14      1470\n",
      "weighted avg       0.12      0.25      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   5   0   0 169   0  36]\n",
      " [  0  25   5   0 155   0  25]\n",
      " [  0  12 145   0  41   0  12]\n",
      " [  0  10  14   0 132   0  54]\n",
      " [  0   2   1   0 192   0  15]\n",
      " [  0  10   5   0  47   0 148]\n",
      " [  0   0   3   0  12   0 195]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.39      0.12      0.18       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.26      0.91      0.40       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.93      0.56       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.27      0.38      0.27      1470\n",
      "weighted avg       0.27      0.38      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146  23   5   0   0  21  15]\n",
      " [  8 168   8   1   0  22   3]\n",
      " [  4  37 156   1   0  12   0]\n",
      " [ 23 109  15   9   0  27  27]\n",
      " [ 53 141   1   0   0   4  11]\n",
      " [ 21  26  12   3   0  64  84]\n",
      " [  7   5   2   1   0  25 170]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.70      0.62       210\n",
      "           2       0.33      0.80      0.47       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.60      0.04      0.08       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.55      0.81      0.65       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.46      0.49      0.42      1470\n",
      "weighted avg       0.46      0.49      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   4   5   0  19  26  10]\n",
      " [  8 129   5   3  39  25   1]\n",
      " [  4  32 158   0   5  11   0]\n",
      " [ 23  30  10  12  79  40  16]\n",
      " [ 53  22   2   0 118  10   5]\n",
      " [ 21   6   8   3  20  94  58]\n",
      " [  7   0   0   3   5  53 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.70      0.62       210\n",
      "           2       0.58      0.61      0.60       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.57      0.06      0.10       210\n",
      "           5       0.41      0.56      0.48       210\n",
      "           6       0.36      0.45      0.40       210\n",
      "           7       0.61      0.68      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.52      1470\n",
      "weighted avg       0.56      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   4   8  15  24  11]\n",
      " [  9 116   3  29  26  26   1]\n",
      " [  2   6 158  28   3  13   0]\n",
      " [ 23  19   9  79  23  39  18]\n",
      " [ 52   9   1  37  95   9   7]\n",
      " [ 16   7   6   7  15  95  64]\n",
      " [  3   2   0   1   5  41 158]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.64       210\n",
      "           2       0.73      0.55      0.63       210\n",
      "           3       0.87      0.75      0.81       210\n",
      "           4       0.42      0.38      0.40       210\n",
      "           5       0.52      0.45      0.48       210\n",
      "           6       0.38      0.45      0.42       210\n",
      "           7       0.61      0.75      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   2   2  14  20  25  17]\n",
      " [  7 122   8  26  20  10  17]\n",
      " [  2   8 177   9   2   8   4]\n",
      " [ 13  23   6  93  19  29  27]\n",
      " [ 40  19   7  36  93   9   6]\n",
      " [  9  10   4  17  14  80  76]\n",
      " [  4   1   0   3   6  31 165]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.62      0.63       210\n",
      "           2       0.66      0.58      0.62       210\n",
      "           3       0.87      0.84      0.86       210\n",
      "           4       0.47      0.44      0.46       210\n",
      "           5       0.53      0.44      0.48       210\n",
      "           6       0.42      0.38      0.40       210\n",
      "           7       0.53      0.79      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   2   1  17  34  21  16]\n",
      " [ 12 119   6  29  23  11  10]\n",
      " [  4   7 171  12   5   9   2]\n",
      " [ 10  16   3  98  28  29  26]\n",
      " [ 27  16   1  38 112   9   7]\n",
      " [  5   4   2  22  21  78  78]\n",
      " [  1   1   0   7  10  24 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.57      0.61       210\n",
      "           2       0.72      0.57      0.63       210\n",
      "           3       0.93      0.81      0.87       210\n",
      "           4       0.44      0.47      0.45       210\n",
      "           5       0.48      0.53      0.51       210\n",
      "           6       0.43      0.37      0.40       210\n",
      "           7       0.55      0.80      0.65       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5789115646258504\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  10   1  15  35  24  12]\n",
      " [  2 131   6  13  38  15   5]\n",
      " [  3   9 173   9   4  12   0]\n",
      " [ 12  18   5  84  47  26  18]\n",
      " [ 29  16   1  30 121  10   3]\n",
      " [ 14  11   1  25  15  82  62]\n",
      " [  4   3   0   8   9  39 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.54      0.58       210\n",
      "           2       0.66      0.62      0.64       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.46      0.40      0.43       210\n",
      "           5       0.45      0.58      0.51       210\n",
      "           6       0.39      0.39      0.39       210\n",
      "           7       0.60      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   6   1  16  37  18  12]\n",
      " [  8 134   7  13  25  18   5]\n",
      " [  4   8 176   8   2   6   6]\n",
      " [ 10  23   5  82  48  21  21]\n",
      " [ 35  26   1  20 115  10   3]\n",
      " [  9  16   2  26  23  79  55]\n",
      " [  1   4   0  10  16  33 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.57      0.60       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.47      0.39      0.43       210\n",
      "           5       0.43      0.55      0.48       210\n",
      "           6       0.43      0.38      0.40       210\n",
      "           7       0.59      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[126   5   0  16  32  24   7]\n",
      " [  5 133  11  17  22  18   4]\n",
      " [  4   5 177  12   4   8   0]\n",
      " [ 15  18  11  88  35  27  16]\n",
      " [ 42  21   3  22 111   8   3]\n",
      " [ 11  16   1  32  17  88  45]\n",
      " [  6   1   0  18   9  37 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60       210\n",
      "           2       0.67      0.63      0.65       210\n",
      "           3       0.87      0.84      0.86       210\n",
      "           4       0.43      0.42      0.42       210\n",
      "           5       0.48      0.53      0.50       210\n",
      "           6       0.42      0.42      0.42       210\n",
      "           7       0.65      0.66      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   4   1  16  34  25  10]\n",
      " [  3 136   7  19  25  15   5]\n",
      " [  6   7 182   7   2   6   0]\n",
      " [ 16  13   6  92  45  21  17]\n",
      " [ 31  28   1  23 111  12   4]\n",
      " [ 10  14   4  26  17  81  58]\n",
      " [  4   1   1  11  13  41 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.57      0.60       210\n",
      "           2       0.67      0.65      0.66       210\n",
      "           3       0.90      0.87      0.88       210\n",
      "           4       0.47      0.44      0.46       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.40      0.39      0.39       210\n",
      "           7       0.60      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   4   3  14  35  18  13]\n",
      " [  8 134   6  19  24  15   4]\n",
      " [  8   7 181   5   2   7   0]\n",
      " [ 18  23   8  86  33  23  19]\n",
      " [ 34  25   1  29 104  11   6]\n",
      " [ 15  14   4  28  19  71  59]\n",
      " [  6   2   0  13  10  51 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.59      0.58       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.89      0.86      0.88       210\n",
      "           4       0.44      0.41      0.43       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.36      0.34      0.35       210\n",
      "           7       0.56      0.61      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   6   3  11  32  17  11]\n",
      " [  7 134  11  20  20  14   4]\n",
      " [  7   6 181   6   1   9   0]\n",
      " [ 22  16  11  89  36  23  13]\n",
      " [ 34  30   4  22 105  11   4]\n",
      " [ 15  18   5  27  19  70  56]\n",
      " [  8   1   2  15  13  38 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.62      0.60       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.83      0.86      0.85       210\n",
      "           4       0.47      0.42      0.45       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.38      0.33      0.36       210\n",
      "           7       0.60      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   6   3  11  32  27   6]\n",
      " [  9 133  11  21  18  13   5]\n",
      " [  6   9 179   5   5   6   0]\n",
      " [ 23  14   9  91  41  18  14]\n",
      " [ 41  28   3  21 100  10   7]\n",
      " [ 15  16   5  35  21  67  51]\n",
      " [  7   4   2  16   9  41 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.60      0.57       210\n",
      "           2       0.63      0.63      0.63       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.46      0.43      0.44       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.37      0.32      0.34       210\n",
      "           7       0.61      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   5   1  19  32  22   8]\n",
      " [  8 139  10  17  17  13   6]\n",
      " [  7   4 181   9   3   6   0]\n",
      " [ 19  21  11  89  32  26  12]\n",
      " [ 38  32   3  23 103   8   3]\n",
      " [ 15  18   2  28  17  76  54]\n",
      " [  4   2   1  20  15  41 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.59      0.58       210\n",
      "           2       0.63      0.66      0.65       210\n",
      "           3       0.87      0.86      0.86       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.47      0.49      0.48       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   5   2  14  30  25   9]\n",
      " [  5 134   9  19  23  14   6]\n",
      " [  6   8 179   8   4   5   0]\n",
      " [ 22  17   8  94  35  22  12]\n",
      " [ 40  31   3  23  99   8   6]\n",
      " [ 13  19   3  28  18  78  51]\n",
      " [  4   3   1  20   6  43 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.60      0.59       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.46      0.45      0.45       210\n",
      "           5       0.46      0.47      0.47       210\n",
      "           6       0.40      0.37      0.39       210\n",
      "           7       0.61      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   4   3  14  36  22   8]\n",
      " [ 10 136   7  19  18  15   5]\n",
      " [  8   9 179   5   2   7   0]\n",
      " [ 19  15   8  92  41  23  12]\n",
      " [ 38  33   2  27  96  11   3]\n",
      " [ 19  18   2  28  16  77  50]\n",
      " [  6   4   1  19   7  45 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.59      0.57       210\n",
      "           2       0.62      0.65      0.63       210\n",
      "           3       0.89      0.85      0.87       210\n",
      "           4       0.45      0.44      0.44       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   4   4  18  31  23   6]\n",
      " [  8 138   7  15  18  19   5]\n",
      " [  7   5 179   7   2  10   0]\n",
      " [ 25  21   8  93  33  19  11]\n",
      " [ 43  31   2  26  94  10   4]\n",
      " [ 16  18   3  29  20  76  48]\n",
      " [  4   3   1  19   6  51 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.59      0.57       210\n",
      "           2       0.63      0.66      0.64       210\n",
      "           3       0.88      0.85      0.86       210\n",
      "           4       0.45      0.44      0.45       210\n",
      "           5       0.46      0.45      0.45       210\n",
      "           6       0.37      0.36      0.36       210\n",
      "           7       0.63      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   4   3  14  33  24   9]\n",
      " [  8 135  11  15  18  17   6]\n",
      " [  7   5 181   7   2   8   0]\n",
      " [ 22  16   5  92  37  23  15]\n",
      " [ 40  30   2  27  93  11   7]\n",
      " [ 14  18   2  29  19  80  48]\n",
      " [  5   5   1  19   5  46 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.59      0.57       210\n",
      "           2       0.63      0.64      0.64       210\n",
      "           3       0.88      0.86      0.87       210\n",
      "           4       0.45      0.44      0.45       210\n",
      "           5       0.45      0.44      0.45       210\n",
      "           6       0.38      0.38      0.38       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.573469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   8   3  16  28  23   9]\n",
      " [  6 138   5  18  24  15   4]\n",
      " [  7   8 179   7   2   7   0]\n",
      " [ 23  20   5  93  31  26  12]\n",
      " [ 36  25   2  27 102  13   5]\n",
      " [ 12  17   3  31  17  80  50]\n",
      " [  6   2   1  16   7  50 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.59      0.58       210\n",
      "           2       0.63      0.66      0.64       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.45      0.44      0.44       210\n",
      "           5       0.48      0.49      0.48       210\n",
      "           6       0.37      0.38      0.38       210\n",
      "           7       0.62      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 69   2  18   0  58   1  62]\n",
      " [  1  79  64   0  45   2  19]\n",
      " [  1  13 179   0   2   0  15]\n",
      " [  5  24  44   0  69   2  66]\n",
      " [  6  27  16   0 136   0  25]\n",
      " [  1   8  20   1  17   1 162]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.33      0.47       210\n",
      "           2       0.52      0.38      0.44       210\n",
      "           3       0.52      0.85      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.41      0.65      0.50       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.37      0.99      0.54       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.40      0.46      0.37      1470\n",
      "weighted avg       0.40      0.46      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   3   0   0  55   8  39]\n",
      " [  2 129  17   0  39   9  14]\n",
      " [  4  14 174   0   3  13   2]\n",
      " [ 13  24  32   0  78   6  57]\n",
      " [ 13  32   5   0 138   1  21]\n",
      " [  3  12  13   0  17  17 148]\n",
      " [  0   0   0   0   3   0 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.50      0.60       210\n",
      "           2       0.60      0.61      0.61       210\n",
      "           3       0.72      0.83      0.77       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.41      0.66      0.51       210\n",
      "           6       0.31      0.08      0.13       210\n",
      "           7       0.42      0.99      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.46      0.52      0.46      1470\n",
      "weighted avg       0.46      0.52      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.5680272108843537\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   2   1   0  43  15  20]\n",
      " [  3 147   6   1  30  16   7]\n",
      " [  4  21 168   0   4  13   0]\n",
      " [ 15  36  23   6  71  24  35]\n",
      " [ 17  36   3   0 136   2  16]\n",
      " [  8  14   9   2  12  46 119]\n",
      " [  0   0   0   0   3   4 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.61      0.67       210\n",
      "           2       0.57      0.70      0.63       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.67      0.03      0.05       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.38      0.22      0.28       210\n",
      "           7       0.51      0.97      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.52      1470\n",
      "weighted avg       0.59      0.57      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   1   0   3  43  21  13]\n",
      " [  1 145   4   3  37  15   5]\n",
      " [  3  18 167   2   3  17   0]\n",
      " [ 12  22  19  31  70  29  27]\n",
      " [ 20  30   3   2 136   4  15]\n",
      " [  6  11   0  10  13  77  93]\n",
      " [  0   0   0   0   4  13 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.61      0.68       210\n",
      "           2       0.64      0.69      0.66       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.61      0.15      0.24       210\n",
      "           5       0.44      0.65      0.53       210\n",
      "           6       0.44      0.37      0.40       210\n",
      "           7       0.56      0.92      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.58      1470\n",
      "weighted avg       0.62      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   1   0   7  41  24   8]\n",
      " [  1 142   6   5  32  21   3]\n",
      " [  2  17 176   2   3  10   0]\n",
      " [  7  12  10  71  51  42  17]\n",
      " [ 17  22   3   3 149   6  10]\n",
      " [  6   8   0   8  14  93  81]\n",
      " [  0   0   0   0   4  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.90      0.84      0.87       210\n",
      "           4       0.74      0.34      0.46       210\n",
      "           5       0.51      0.71      0.59       210\n",
      "           6       0.42      0.44      0.43       210\n",
      "           7       0.61      0.87      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   1   0   5  37  24   8]\n",
      " [  0 141   6   8  32  21   2]\n",
      " [  2   8 173   6   4  17   0]\n",
      " [  5   9   4  95  36  43  18]\n",
      " [ 17  20   0   6 154   5   8]\n",
      " [  3   5   0  13  12 102  75]\n",
      " [  0   0   0   0   4  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.73       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.71      0.45      0.55       210\n",
      "           5       0.55      0.73      0.63       210\n",
      "           6       0.43      0.49      0.46       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   1   0   7  32  26   7]\n",
      " [  2 146   6   7  30  16   3]\n",
      " [  1  11 181   2   4  11   0]\n",
      " [  7   5   4 116  29  31  18]\n",
      " [ 19  17   0  10 153   3   8]\n",
      " [  4   4   0  13   9 107  73]\n",
      " [  0   0   0   0   4  28 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.65      0.72       210\n",
      "           2       0.79      0.70      0.74       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.75      0.55      0.64       210\n",
      "           5       0.59      0.73      0.65       210\n",
      "           6       0.48      0.51      0.50       210\n",
      "           7       0.62      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   1   0   8  34  27   6]\n",
      " [  2 144   7  11  29  14   3]\n",
      " [  3  10 176   5   2  14   0]\n",
      " [  8   5   1 116  31  34  15]\n",
      " [ 17  17   0   9 158   3   6]\n",
      " [  4   4   0  13   9 108  72]\n",
      " [  0   0   0   0   5  26 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.64      0.71       210\n",
      "           2       0.80      0.69      0.74       210\n",
      "           3       0.96      0.84      0.89       210\n",
      "           4       0.72      0.55      0.62       210\n",
      "           5       0.59      0.75      0.66       210\n",
      "           6       0.48      0.51      0.50       210\n",
      "           7       0.64      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   1   0   5  35  27   6]\n",
      " [  2 149   6  12  25  13   3]\n",
      " [  3   5 182   6   5   9   0]\n",
      " [  5   6   1 123  29  33  13]\n",
      " [ 20  20   0  12 146   3   9]\n",
      " [  4   3   0  13   9 114  67]\n",
      " [  0   0   0   0   4  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.65      0.72       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.72      0.59      0.65       210\n",
      "           5       0.58      0.70      0.63       210\n",
      "           6       0.52      0.54      0.53       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   1   0   9  32  23   5]\n",
      " [  0 149   8  11  26  15   1]\n",
      " [  3   3 187   3   4  10   0]\n",
      " [  9   4   0 124  30  33  10]\n",
      " [ 21  18   0  13 148   3   7]\n",
      " [  4   3   0  17   8 111  67]\n",
      " [  1   0   0   0   3  28 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.67      0.72       210\n",
      "           2       0.84      0.71      0.77       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.59      0.70      0.64       210\n",
      "           6       0.50      0.53      0.51       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.7224489795918367\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   1   0   9  30  25   5]\n",
      " [  2 150   7   8  29  11   3]\n",
      " [  2   6 187   3   4   8   0]\n",
      " [  7   3   2 127  31  28  12]\n",
      " [ 19  16   0  13 150   4   8]\n",
      " [  3   2   0  12  11 126  56]\n",
      " [  0   0   0   1   3  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.84      0.71      0.77       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.73      0.60      0.66       210\n",
      "           5       0.58      0.71      0.64       210\n",
      "           6       0.56      0.60      0.58       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.72      1470\n",
      "weighted avg       0.74      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.719047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   1   0   6  32  24   5]\n",
      " [  2 150   7  14  23  13   1]\n",
      " [  2   5 185   5   3  10   0]\n",
      " [ 10   5   4 124  28  25  14]\n",
      " [ 16  17   0  12 154   5   6]\n",
      " [  4   3   0  15   8 118  62]\n",
      " [  1   0   0   0   3  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.73       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.94      0.88      0.91       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.61      0.73      0.67       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.68      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   0   7  28  26   4]\n",
      " [  2 152   7  10  26  12   1]\n",
      " [  4   3 186   3   5   9   0]\n",
      " [  3   4   1 128  27  33  14]\n",
      " [ 19  13   0  10 157   5   6]\n",
      " [  3   3   0  18   8 115  63]\n",
      " [  1   0   0   1   3  22 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.86      0.72      0.79       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.72      0.61      0.66       210\n",
      "           5       0.62      0.75      0.68       210\n",
      "           6       0.52      0.55      0.53       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.73      1470\n",
      "weighted avg       0.74      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   1   0   6  30  21   7]\n",
      " [  3 151   7  10  24  13   2]\n",
      " [  3   5 185   7   2   8   0]\n",
      " [  5   3   0 134  22  34  12]\n",
      " [ 19  14   0  13 155   4   5]\n",
      " [  5   3   0  15   6 119  62]\n",
      " [  0   0   0   2   4  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.69      0.74       210\n",
      "           2       0.85      0.72      0.78       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.72      0.64      0.68       210\n",
      "           5       0.64      0.74      0.68       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.719047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   1   0   7  28  21   8]\n",
      " [  3 150   7  12  25  11   2]\n",
      " [  3   4 185   5   4   9   0]\n",
      " [  7   4   2 135  23  28  11]\n",
      " [ 21  17   0  17 146   3   6]\n",
      " [  3   4   0  18   7 114  64]\n",
      " [  1   0   0   1   3  23 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.69      0.74       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.95      0.88      0.92       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.62      0.70      0.65       210\n",
      "           6       0.55      0.54      0.54       210\n",
      "           7       0.67      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   0   1   8  30  25   4]\n",
      " [  2 147   6  13  27  15   0]\n",
      " [  3   3 188   6   3   7   0]\n",
      " [  7   3   2 129  28  29  12]\n",
      " [ 20  17   0  15 147   4   7]\n",
      " [  3   3   0  17   7 120  60]\n",
      " [  1   0   0   2   4  26 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.73       210\n",
      "           2       0.85      0.70      0.77       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.68      0.61      0.65       210\n",
      "           5       0.60      0.70      0.64       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.72      1470\n",
      "weighted avg       0.73      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   3   0   9  30  19   7]\n",
      " [  2 148   7  14  26  11   2]\n",
      " [  3   7 184   4   4   8   0]\n",
      " [  6   4   2 126  23  33  16]\n",
      " [ 20  16   0  13 152   5   4]\n",
      " [  3   4   0  19   6 115  63]\n",
      " [  1   0   0   2   2  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.73       210\n",
      "           2       0.81      0.70      0.76       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.63      0.72      0.67       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   2   0   7  28  23   5]\n",
      " [  2 151   7  10  24  14   2]\n",
      " [  2   7 184   5   4   8   0]\n",
      " [  4   5   3 136  21  31  10]\n",
      " [ 19  15   0  15 152   4   5]\n",
      " [  1   4   0  17   7 116  65]\n",
      " [  0   0   0   3   3  32 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.69      0.76       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.64      0.72      0.68       210\n",
      "           6       0.51      0.55      0.53       210\n",
      "           7       0.66      0.82      0.73       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.7258503401360544\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   2   0   8  32  23   5]\n",
      " [  1 153   7  14  21  13   1]\n",
      " [  2   4 187   5   4   8   0]\n",
      " [  5   5   3 136  20  30  11]\n",
      " [ 14  19   0  15 152   5   5]\n",
      " [  3   6   0  17   3 120  61]\n",
      " [  1   0   0   2   2  26 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.69      0.65      0.67       210\n",
      "           5       0.65      0.72      0.68       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7224489795918367\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   2   1   6  30  21   8]\n",
      " [  2 150   7  13  24  13   1]\n",
      " [  1   3 186   6   4  10   0]\n",
      " [  3   6   2 141  20  27  11]\n",
      " [ 20  19   0  14 148   4   5]\n",
      " [  4   4   0  19   6 119  58]\n",
      " [  1   0   0   0   2  31 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.82      0.71      0.76       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.71      0.67      0.69       210\n",
      "           5       0.63      0.70      0.67       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 84   1  28   5  49  34   9]\n",
      " [  1 103  42   8  29  26   1]\n",
      " [  1   9 181   4   0  15   0]\n",
      " [  7  15  34  32  61  42  19]\n",
      " [ 14  31  15   4 126   6  14]\n",
      " [  6   9  12  10  10 107  56]\n",
      " [  0   0   0   1   4  61 144]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.40      0.52       210\n",
      "           2       0.61      0.49      0.54       210\n",
      "           3       0.58      0.86      0.69       210\n",
      "           4       0.50      0.15      0.23       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.37      0.51      0.43       210\n",
      "           7       0.59      0.69      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.51      1470\n",
      "weighted avg       0.55      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ab723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.3333333333333333\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 89   0  69   8   9  19  16]\n",
      " [ 25   0 121   5   8  26  25]\n",
      " [  9   0 179   6   1  15   0]\n",
      " [ 23   0 113  13  24  10  27]\n",
      " [ 23   0 131   8  16   9  23]\n",
      " [ 36   0  31   8   7  58  70]\n",
      " [ 25   0  10   7   0  33 135]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.42      0.40       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.27      0.85      0.41       210\n",
      "           4       0.24      0.06      0.10       210\n",
      "           5       0.25      0.08      0.12       210\n",
      "           6       0.34      0.28      0.31       210\n",
      "           7       0.46      0.64      0.53       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.28      0.33      0.27      1470\n",
      "weighted avg       0.28      0.33      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Model after Normalize Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  20   0  20  39   7   7]\n",
      " [ 29 121   7  16  28   3   6]\n",
      " [  6  26 161   6   7   4   0]\n",
      " [ 57  43  14  48  26   9  13]\n",
      " [ 45  39   1  24  86   4  11]\n",
      " [ 45  39   4  24  22  40  36]\n",
      " [ 25  28   4  19  17  31  86]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.56      0.44       210\n",
      "           2       0.38      0.58      0.46       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.31      0.23      0.26       210\n",
      "           5       0.38      0.41      0.40       210\n",
      "           6       0.41      0.19      0.26       210\n",
      "           7       0.54      0.41      0.47       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.44      1470\n",
      "weighted avg       0.46      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[113  14   0  17  43  13  10]\n",
      " [ 28 116   8  16  30   8   4]\n",
      " [  7  23 161   7   7   5   0]\n",
      " [ 53  30   7  53  39  11  17]\n",
      " [ 38  36   1  31  85   4  15]\n",
      " [ 44  28   4  19  17  51  47]\n",
      " [ 21  19   2  15  15  47  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.54      0.44       210\n",
      "           2       0.44      0.55      0.49       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.34      0.25      0.29       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.37      0.24      0.29       210\n",
      "           7       0.49      0.43      0.46       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[115  15   1  20  41   9   9]\n",
      " [ 25 116  11  17  26   8   7]\n",
      " [  6  21 166   5   6   5   1]\n",
      " [ 44  31  10  51  45  14  15]\n",
      " [ 39  29   2  31  87   5  17]\n",
      " [ 38  27   6  19  18  60  42]\n",
      " [ 18  18   3  10  19  54  88]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.55      0.46       210\n",
      "           2       0.45      0.55      0.50       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.33      0.24      0.28       210\n",
      "           5       0.36      0.41      0.38       210\n",
      "           6       0.39      0.29      0.33       210\n",
      "           7       0.49      0.42      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114  15   2  22  42   5  10]\n",
      " [ 24 117   9  17  27  12   4]\n",
      " [  8  23 165   4   5   5   0]\n",
      " [ 48  33  10  48  44  10  17]\n",
      " [ 39  35   3  24  90   3  16]\n",
      " [ 37  22   5  22  18  57  49]\n",
      " [ 19  18   2  12  21  47  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.54      0.46       210\n",
      "           2       0.44      0.56      0.49       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.32      0.23      0.27       210\n",
      "           5       0.36      0.43      0.39       210\n",
      "           6       0.41      0.27      0.33       210\n",
      "           7       0.49      0.43      0.46       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[116  13   2  23  40   5  11]\n",
      " [ 25 116  16  17  22   9   5]\n",
      " [  8  29 160   5   3   5   0]\n",
      " [ 49  30   8  51  47   7  18]\n",
      " [ 36  37   3  27  87   2  18]\n",
      " [ 40  23   7  20  14  55  51]\n",
      " [ 23  16   4  11  18  45  93]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.55      0.46       210\n",
      "           2       0.44      0.55      0.49       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.33      0.24      0.28       210\n",
      "           5       0.38      0.41      0.39       210\n",
      "           6       0.43      0.26      0.33       210\n",
      "           7       0.47      0.44      0.46       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  11   2  20  45   3  12]\n",
      " [ 22 111  16  16  27  11   7]\n",
      " [ 10  24 163   4   2   6   1]\n",
      " [ 46  31   9  50  47   9  18]\n",
      " [ 37  35   5  23  91   4  15]\n",
      " [ 38  22   4  19  17  56  54]\n",
      " [ 19  16   4   7  16  43 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.56      0.47       210\n",
      "           2       0.44      0.53      0.48       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.36      0.24      0.29       210\n",
      "           5       0.37      0.43      0.40       210\n",
      "           6       0.42      0.27      0.33       210\n",
      "           7       0.50      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.27687074829931974\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 26   0  87   9  17  18  53]\n",
      " [  6   0 131   9   8   2  54]\n",
      " [  1   0 177   3   2  23   4]\n",
      " [  6   0 146   6   9  11  32]\n",
      " [  9   0 153   4  11   4  29]\n",
      " [ 17   0  44   6   4  40  99]\n",
      " [ 12   0  10   9   2  30 147]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.12      0.18       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.24      0.84      0.37       210\n",
      "           4       0.13      0.03      0.05       210\n",
      "           5       0.21      0.05      0.08       210\n",
      "           6       0.31      0.19      0.24       210\n",
      "           7       0.35      0.70      0.47       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.23      0.28      0.20      1470\n",
      "weighted avg       0.23      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 31   0  79  12  16  20  52]\n",
      " [ 13   0 123   7  11   3  53]\n",
      " [  1   0 174   4   4  23   4]\n",
      " [  7   0 134   7  19  11  32]\n",
      " [  8   0 149   8  11   5  29]\n",
      " [ 22   0  39   5   6  40  98]\n",
      " [ 11   0  10   9   3  32 145]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.15      0.20       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.25      0.83      0.38       210\n",
      "           4       0.13      0.03      0.05       210\n",
      "           5       0.16      0.05      0.08       210\n",
      "           6       0.30      0.19      0.23       210\n",
      "           7       0.35      0.69      0.47       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.22      0.28      0.20      1470\n",
      "weighted avg       0.22      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.3149659863945578\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 85   0  80   3   5   8  29]\n",
      " [ 26   0 129   1   3   1  50]\n",
      " [ 10   0 184   0   1  13   2]\n",
      " [ 30   0 142   2   3   4  29]\n",
      " [ 21   0 149   1   7   4  28]\n",
      " [ 37   0  42   1   2  46  82]\n",
      " [ 31   0   9   1   1  29 139]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.40      0.38       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.25      0.88      0.39       210\n",
      "           4       0.22      0.01      0.02       210\n",
      "           5       0.32      0.03      0.06       210\n",
      "           6       0.44      0.22      0.29       210\n",
      "           7       0.39      0.66      0.49       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.28      0.31      0.23      1470\n",
      "weighted avg       0.28      0.31      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.3292517006802721\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 90   0  75   3   5  19  18]\n",
      " [ 26   0 122   7   3  28  24]\n",
      " [  8   0 181   4   1  16   0]\n",
      " [ 26   0 131  12   7   8  26]\n",
      " [ 20   0 144   8   6   8  24]\n",
      " [ 35   0  35   6   5  61  68]\n",
      " [ 27   0   8   3   1  37 134]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.43      0.41       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.26      0.86      0.40       210\n",
      "           4       0.28      0.06      0.09       210\n",
      "           5       0.21      0.03      0.05       210\n",
      "           6       0.34      0.29      0.32       210\n",
      "           7       0.46      0.64      0.53       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.28      0.33      0.26      1470\n",
      "weighted avg       0.28      0.33      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.3251700680272109\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 89   0  77   3   4  18  19]\n",
      " [ 26   0 122   3   7  14  38]\n",
      " [  8   0 181   4   1  16   0]\n",
      " [ 27   0 137   7   5   6  28]\n",
      " [ 20   0 145   6   7   7  25]\n",
      " [ 37   0  40   2   3  57  71]\n",
      " [ 29   0   9   2   0  33 137]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.42      0.40       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.25      0.86      0.39       210\n",
      "           4       0.26      0.03      0.06       210\n",
      "           5       0.26      0.03      0.06       210\n",
      "           6       0.38      0.27      0.32       210\n",
      "           7       0.43      0.65      0.52       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.28      0.33      0.25      1470\n",
      "weighted avg       0.28      0.33      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.28095238095238095\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 52   1  83  30   5  18  21]\n",
      " [ 24   1 133   5   1   1  45]\n",
      " [  5   0 185   0   2  17   1]\n",
      " [ 25   0 143   9   1   7  25]\n",
      " [ 21   2 153   4   1   4  25]\n",
      " [ 27   3  45  12   1  42  80]\n",
      " [ 29   1  14  14   0  29 123]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.25      0.26       210\n",
      "           2       0.12      0.00      0.01       210\n",
      "           3       0.24      0.88      0.38       210\n",
      "           4       0.12      0.04      0.06       210\n",
      "           5       0.09      0.00      0.01       210\n",
      "           6       0.36      0.20      0.26       210\n",
      "           7       0.38      0.59      0.46       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.23      0.28      0.21      1470\n",
      "weighted avg       0.23      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.21224489795918366\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3   0   0   0 207]\n",
      " [  0   0   7   0   0   0 203]\n",
      " [  0   0 103   0   0   0 107]\n",
      " [  0   0   2   0   0   0 208]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.87      0.49      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.15      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.15      0.21      0.13      1470\n",
      "weighted avg       0.15      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3040816326530612\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   3   0   0 168   0  39]\n",
      " [  0   6   1   0 150   0  53]\n",
      " [  0   2 101   0  91   0  16]\n",
      " [  0   0   2   0 176   0  32]\n",
      " [  0   1   0   0 178   0  31]\n",
      " [  0   1   0   0  84   0 125]\n",
      " [  0   1   0   0  47   0 162]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.43      0.03      0.05       210\n",
      "           3       0.97      0.48      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.20      0.85      0.32       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.77      0.49       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.28      0.30      0.21      1470\n",
      "weighted avg       0.28      0.30      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   1   2   0  74  27  12]\n",
      " [ 29   2   5   0 121  42  11]\n",
      " [ 19   0 103   0  72   4  12]\n",
      " [ 36   0   2   0 140  11  21]\n",
      " [ 26   1   0   0 152  13  18]\n",
      " [ 44   1   0   0  40  52  73]\n",
      " [ 33   0   1   0  14  38 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.45      0.38       210\n",
      "           2       0.40      0.01      0.02       210\n",
      "           3       0.91      0.49      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.25      0.72      0.37       210\n",
      "           6       0.28      0.25      0.26       210\n",
      "           7       0.46      0.59      0.52       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.31      1470\n",
      "weighted avg       0.38      0.36      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  17   0   0  67  20  12]\n",
      " [ 29  98   0   0  64   8  11]\n",
      " [  8  51 122   0  24   3   2]\n",
      " [ 36  27   2   0 116   8  21]\n",
      " [ 26  33   0   0 128   5  18]\n",
      " [ 44  28   0   0  36  29  73]\n",
      " [ 33  20   1   0  14  18 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.45      0.39       210\n",
      "           2       0.36      0.47      0.40       210\n",
      "           3       0.98      0.58      0.73       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.29      0.61      0.39       210\n",
      "           6       0.32      0.14      0.19       210\n",
      "           7       0.48      0.59      0.53       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.39      0.40      0.38      1470\n",
      "weighted avg       0.39      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45782312925170066\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  12   0  25  42  25  11]\n",
      " [ 30  90   3  27  37  14   9]\n",
      " [  9  23 147  14  10   6   1]\n",
      " [ 36  15  12  65  51  11  20]\n",
      " [ 26  25   5  27 101  13  13]\n",
      " [ 44  13   2  17  19  73  42]\n",
      " [ 33   4   1   8   6  56 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.45      0.39       210\n",
      "           2       0.49      0.43      0.46       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.36      0.31      0.33       210\n",
      "           5       0.38      0.48      0.42       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.52      0.49      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.463265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  19   5  29  30  33  11]\n",
      " [ 27 106   9  29  15  15   9]\n",
      " [  9  19 156  18   3   5   0]\n",
      " [ 29  34  10  73  28  18  18]\n",
      " [ 23  36  12  29  81  12  17]\n",
      " [ 28  21   2  22  10  72  55]\n",
      " [ 21   7   1  11   3  57 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.40      0.39       210\n",
      "           2       0.44      0.50      0.47       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.35      0.35      0.35       210\n",
      "           5       0.48      0.39      0.43       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45782312925170066\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  13   2  26  43  25  18]\n",
      " [ 27  89   3  26  39  15  11]\n",
      " [  9  17 152  17   9   6   0]\n",
      " [ 28  13   7  68  52  22  20]\n",
      " [ 21  21   3  31 107   8  19]\n",
      " [ 22  11   2  24  25  67  59]\n",
      " [ 19   4   1  10   7  62 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.40      0.40       210\n",
      "           2       0.53      0.42      0.47       210\n",
      "           3       0.89      0.72      0.80       210\n",
      "           4       0.34      0.32      0.33       210\n",
      "           5       0.38      0.51      0.43       210\n",
      "           6       0.33      0.32      0.32       210\n",
      "           7       0.46      0.51      0.48       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  13   2  19  59  25  13]\n",
      " [ 19  93   5  21  51  12   9]\n",
      " [  3  20 153  12  15   7   0]\n",
      " [ 21  17   7  64  60  19  22]\n",
      " [ 24  19   3  29 112   6  17]\n",
      " [ 28   9   0  17  36  64  56]\n",
      " [ 14   1   2   7  20  55 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.38      0.40       210\n",
      "           2       0.54      0.44      0.49       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.38      0.30      0.34       210\n",
      "           5       0.32      0.53      0.40       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.49      0.53      0.51       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 89  12   1  31  42  21  14]\n",
      " [ 29  92   7  23  35  13  11]\n",
      " [ 13  15 154  14  10   4   0]\n",
      " [ 24  13   6  71  55  19  22]\n",
      " [ 24  13   1  37 109   8  18]\n",
      " [ 24  15   3  22  25  69  52]\n",
      " [ 19   1   3   8  17  59 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.42      0.41       210\n",
      "           2       0.57      0.44      0.50       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.34      0.34      0.34       210\n",
      "           5       0.37      0.52      0.43       210\n",
      "           6       0.36      0.33      0.34       210\n",
      "           7       0.47      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.46802721088435373\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  19   3  25  34  26  12]\n",
      " [ 30  95   8  21  34  13   9]\n",
      " [ 12  15 156  12  10   5   0]\n",
      " [ 25  15  10  69  45  28  18]\n",
      " [ 28  17   5  31 102   8  19]\n",
      " [ 26  16   7  20  24  69  48]\n",
      " [ 19   7   4  12  16  46 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.43      0.41       210\n",
      "           2       0.52      0.45      0.48       210\n",
      "           3       0.81      0.74      0.77       210\n",
      "           4       0.36      0.33      0.35       210\n",
      "           5       0.38      0.49      0.43       210\n",
      "           6       0.35      0.33      0.34       210\n",
      "           7       0.50      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  13   2  25  44  22  13]\n",
      " [ 22  97   8  22  39  14   8]\n",
      " [  9   8 164  16  10   3   0]\n",
      " [ 42  16  12  40  57  19  24]\n",
      " [ 33  18   3  24 106  10  16]\n",
      " [ 30  25   4   9  30  63  49]\n",
      " [ 12   4   2  19  17  54 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.43      0.41       210\n",
      "           2       0.54      0.46      0.50       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.26      0.19      0.22       210\n",
      "           5       0.35      0.50      0.41       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.48      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  20   4  28  29  21  15]\n",
      " [ 11 107   9  30  33  10  10]\n",
      " [  4  13 166  14   9   4   0]\n",
      " [ 26  27   7  59  44  23  24]\n",
      " [ 36  18   4  23  97  12  20]\n",
      " [ 21  24   5  21  25  66  48]\n",
      " [ 15  14   4  16  19  48  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.44      0.45       210\n",
      "           2       0.48      0.51      0.49       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.31      0.28      0.29       210\n",
      "           5       0.38      0.46      0.42       210\n",
      "           6       0.36      0.31      0.34       210\n",
      "           7       0.45      0.45      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88  16   3  33  32  25  13]\n",
      " [ 20 100  10  27  32  14   7]\n",
      " [  6  14 166  12   8   3   1]\n",
      " [ 28  25  12  60  36  23  26]\n",
      " [ 35  17   3  28  94  15  18]\n",
      " [ 21  25   2  26  25  62  49]\n",
      " [ 14   9   2  20  13  60  92]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.42      0.42       210\n",
      "           2       0.49      0.48      0.48       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.39      0.45      0.42       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.45      0.44      0.44       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  24   4  29  32  23  14]\n",
      " [ 17 105   8  30  31  15   4]\n",
      " [  6  16 164  13   6   5   0]\n",
      " [ 24  28  12  64  39  21  22]\n",
      " [ 29  26   5  30  91  13  16]\n",
      " [ 18  28   9  29  21  57  48]\n",
      " [ 17  10   5  18  15  47  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.40      0.41       210\n",
      "           2       0.44      0.50      0.47       210\n",
      "           3       0.79      0.78      0.79       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.39      0.43      0.41       210\n",
      "           6       0.31      0.27      0.29       210\n",
      "           7       0.49      0.47      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.454421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  19   0  37  30  27  16]\n",
      " [ 10 103  12  32  31  14   8]\n",
      " [  2  15 168  15   5   4   1]\n",
      " [ 17  20  14  65  45  24  25]\n",
      " [ 19  21   4  38  93  13  22]\n",
      " [ 13  28   5  32  21  64  47]\n",
      " [ 16   9   2  14  23  52  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.39      0.44       210\n",
      "           2       0.48      0.49      0.48       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.28      0.31      0.29       210\n",
      "           5       0.38      0.44      0.41       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.44      0.45      0.44       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.46      1470\n",
      "weighted avg       0.46      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4496598639455782\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  16   3  33  31  29  18]\n",
      " [  7 105  11  30  31  17   9]\n",
      " [  6  13 167  14   6   3   1]\n",
      " [ 22  26  13  54  44  28  23]\n",
      " [ 25  23   9  30  89  12  22]\n",
      " [ 14  20   7  29  23  65  52]\n",
      " [ 13   4   5  18  19  50 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.38      0.42       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.26      0.26      0.26       210\n",
      "           5       0.37      0.42      0.39       210\n",
      "           6       0.32      0.31      0.31       210\n",
      "           7       0.45      0.48      0.46       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  19   3  33  32  24  15]\n",
      " [ 11 105  12  26  33  17   6]\n",
      " [  4  13 171  12   7   3   0]\n",
      " [ 22  29   7  61  37  31  23]\n",
      " [ 27  24   4  31  90  15  19]\n",
      " [ 19  26   9  31  15  57  53]\n",
      " [ 17  10   4  14  23  44  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.40      0.43       210\n",
      "           2       0.46      0.50      0.48       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.38      0.43      0.40       210\n",
      "           6       0.30      0.27      0.28       210\n",
      "           7       0.46      0.47      0.46       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  20   4  32  32  22  14]\n",
      " [  6 110  12  27  28  17  10]\n",
      " [  2   9 169  16   8   6   0]\n",
      " [ 21  32  13  64  34  23  23]\n",
      " [ 22  26   6  32  89  14  21]\n",
      " [ 17  23   7  33  19  61  50]\n",
      " [ 18   9   3  13  17  45 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.41      0.45       210\n",
      "           2       0.48      0.52      0.50       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.29      0.30      0.30       210\n",
      "           5       0.39      0.42      0.41       210\n",
      "           6       0.32      0.29      0.31       210\n",
      "           7       0.47      0.50      0.48       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.454421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88  18   4  31  32  23  14]\n",
      " [ 11 108  12  29  27  17   6]\n",
      " [  4  13 168  12   8   5   0]\n",
      " [ 22  25  12  59  39  27  26]\n",
      " [ 26  23   6  31  88  13  23]\n",
      " [ 13  25   6  33  23  62  48]\n",
      " [ 15  12   4  19  24  41  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.42      0.45       210\n",
      "           2       0.48      0.51      0.50       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.28      0.28      0.28       210\n",
      "           5       0.37      0.42      0.39       210\n",
      "           6       0.33      0.30      0.31       210\n",
      "           7       0.45      0.45      0.45       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  21   4  32  37  24  16]\n",
      " [ 11  99  10  30  35  18   7]\n",
      " [  5  10 170  12   8   5   0]\n",
      " [ 19  28  10  60  35  32  26]\n",
      " [ 28  25   5  31  81  13  27]\n",
      " [ 17  22   8  32  17  59  55]\n",
      " [ 21   9   4  13  18  49  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.36      0.39       210\n",
      "           2       0.46      0.47      0.47       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.35      0.39      0.37       210\n",
      "           6       0.29      0.28      0.29       210\n",
      "           7       0.42      0.46      0.44       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.44      1470\n",
      "weighted avg       0.44      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.3442176870748299\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  5   3  10   3 110   0  79]\n",
      " [  3  12  48   7  84   0  56]\n",
      " [  0   6 152   4  21   0  27]\n",
      " [  2   3  31   4 126   0  44]\n",
      " [  2   2  20   0 150   0  36]\n",
      " [  3   0  15   1  43   0 148]\n",
      " [  4   0   1   0  22   0 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.02      0.04       210\n",
      "           2       0.46      0.06      0.10       210\n",
      "           3       0.55      0.72      0.62       210\n",
      "           4       0.21      0.02      0.03       210\n",
      "           5       0.27      0.71      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.87      0.47       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.30      0.34      0.24      1470\n",
      "weighted avg       0.30      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.37210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 46   2   2   0 119   1  40]\n",
      " [  6  28  20   0 102   1  53]\n",
      " [  0  14 127   1  41   0  27]\n",
      " [  6   5   7   4 147   0  41]\n",
      " [  8   2   1   0 167   0  32]\n",
      " [ 16   5   5   1  48   0 135]\n",
      " [ 13   0   0   1  21   0 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.22      0.30       210\n",
      "           2       0.50      0.13      0.21       210\n",
      "           3       0.78      0.60      0.68       210\n",
      "           4       0.57      0.02      0.04       210\n",
      "           5       0.26      0.80      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.83      0.49       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.42      0.37      0.30      1470\n",
      "weighted avg       0.42      0.37      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  11   0   1  57  10  27]\n",
      " [ 41  76   8   0  33   7  45]\n",
      " [ 13  42 127   3   7   3  15]\n",
      " [ 45  31   4   6  86   3  35]\n",
      " [ 33  23   0   2 120   4  28]\n",
      " [ 50   8   1   2  21  12 116]\n",
      " [ 29   3   0   0   5   6 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.50      0.40       210\n",
      "           2       0.39      0.36      0.38       210\n",
      "           3       0.91      0.60      0.73       210\n",
      "           4       0.43      0.03      0.05       210\n",
      "           5       0.36      0.57      0.45       210\n",
      "           6       0.27      0.06      0.09       210\n",
      "           7       0.39      0.80      0.52       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.37      1470\n",
      "weighted avg       0.44      0.42      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   9   0  12  51  23  15]\n",
      " [ 34  81   4   9  30  34  18]\n",
      " [ 11  28 140   6   8   2  15]\n",
      " [ 38  30   2  28  74   6  32]\n",
      " [ 31  20   0   9 118   7  25]\n",
      " [ 45   5   1   8  21  31  99]\n",
      " [ 27   2   0   4   4  12 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.48      0.40       210\n",
      "           2       0.46      0.39      0.42       210\n",
      "           3       0.95      0.67      0.78       210\n",
      "           4       0.37      0.13      0.20       210\n",
      "           5       0.39      0.56      0.46       210\n",
      "           6       0.27      0.15      0.19       210\n",
      "           7       0.44      0.77      0.56       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.43      1470\n",
      "weighted avg       0.46      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   9   0  20  44  25  13]\n",
      " [ 31  94   6  17  28  20  14]\n",
      " [ 10  23 154  11   5   4   3]\n",
      " [ 35  26   1  51  59  13  25]\n",
      " [ 29  17   0  17 116   7  24]\n",
      " [ 40   3   1  16  18  50  82]\n",
      " [ 27   1   0   4   5  33 140]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.47      0.41       210\n",
      "           2       0.54      0.45      0.49       210\n",
      "           3       0.95      0.73      0.83       210\n",
      "           4       0.38      0.24      0.29       210\n",
      "           5       0.42      0.55      0.48       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.47      0.67      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.48      1470\n",
      "weighted avg       0.49      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   6   0  20  44  26  12]\n",
      " [ 30 102   5  17  28  17  11]\n",
      " [  9  20 159  11   4   4   3]\n",
      " [ 32  20   3  67  50  16  22]\n",
      " [ 28  17   1  26 107   8  23]\n",
      " [ 39   4   1  19  15  59  73]\n",
      " [ 24   1   0   8   3  43 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.49      0.43       210\n",
      "           2       0.60      0.49      0.54       210\n",
      "           3       0.94      0.76      0.84       210\n",
      "           4       0.40      0.32      0.35       210\n",
      "           5       0.43      0.51      0.46       210\n",
      "           6       0.34      0.28      0.31       210\n",
      "           7       0.48      0.62      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.51      0.49      0.50      1470\n",
      "weighted avg       0.51      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   7   0  23  38  25  13]\n",
      " [ 29 103   8  16  27  16  11]\n",
      " [  7  19 159  12   6   6   1]\n",
      " [ 27  16   3  83  44  15  22]\n",
      " [ 28  16   2  23 110   8  23]\n",
      " [ 29   4   1  22  17  70  67]\n",
      " [ 19   1   0  11   3  43 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.50      0.46       210\n",
      "           2       0.62      0.49      0.55       210\n",
      "           3       0.92      0.76      0.83       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.45      0.52      0.48       210\n",
      "           6       0.38      0.33      0.36       210\n",
      "           7       0.49      0.63      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111   4   1  22  39  22  11]\n",
      " [ 26 105   7  18  28  14  12]\n",
      " [  8  19 159  12   5   6   1]\n",
      " [ 28  15   3  79  48  15  22]\n",
      " [ 29  15   0  22 113   7  24]\n",
      " [ 33   3   1  25  10  68  70]\n",
      " [ 19   3   0   7   2  46 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.53      0.48       210\n",
      "           2       0.64      0.50      0.56       210\n",
      "           3       0.93      0.76      0.83       210\n",
      "           4       0.43      0.38      0.40       210\n",
      "           5       0.46      0.54      0.50       210\n",
      "           6       0.38      0.32      0.35       210\n",
      "           7       0.49      0.63      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.52      1470\n",
      "weighted avg       0.54      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   4   1  22  41  22  11]\n",
      " [ 23 104   6  19  30  18  10]\n",
      " [  3  17 165  14   4   6   1]\n",
      " [ 24  15   3  87  44  12  25]\n",
      " [ 26  13   0  22 118   6  25]\n",
      " [ 29   2   1  25  15  74  64]\n",
      " [ 17   0   0  10   6  40 137]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.52      0.49       210\n",
      "           2       0.67      0.50      0.57       210\n",
      "           3       0.94      0.79      0.85       210\n",
      "           4       0.44      0.41      0.43       210\n",
      "           5       0.46      0.56      0.50       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.50      0.65      0.57       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   4   1  20  42  22  11]\n",
      " [ 21 106   8  19  30  17   9]\n",
      " [  3  15 169  12   4   6   1]\n",
      " [ 27  17   5  79  46  15  21]\n",
      " [ 28  14   0  23 115   6  24]\n",
      " [ 26   5   1  23  14  72  69]\n",
      " [ 17   1   0  10   4  46 132]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.52      0.50       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.92      0.80      0.86       210\n",
      "           4       0.42      0.38      0.40       210\n",
      "           5       0.45      0.55      0.49       210\n",
      "           6       0.39      0.34      0.37       210\n",
      "           7       0.49      0.63      0.55       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112   8   0  21  41  18  10]\n",
      " [ 15 108   8  25  31  12  11]\n",
      " [  3  16 167   9   8   6   1]\n",
      " [ 17  14   2  92  48  12  25]\n",
      " [ 24  10   1  24 123   5  23]\n",
      " [ 24   4   1  28  12  74  67]\n",
      " [ 13   1   0  13   6  39 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.54       210\n",
      "           2       0.67      0.51      0.58       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.43      0.44      0.44       210\n",
      "           5       0.46      0.59      0.51       210\n",
      "           6       0.45      0.35      0.39       210\n",
      "           7       0.50      0.66      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.56      1470\n",
      "weighted avg       0.57      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   2   0  25  47  16  11]\n",
      " [ 14 109   7  25  32  13  10]\n",
      " [  2  18 167  11   5   5   2]\n",
      " [ 18  12   3  90  50  12  25]\n",
      " [ 21  13   0  29 116   6  25]\n",
      " [ 25   4   1  20  19  75  66]\n",
      " [ 16   1   0   9   7  39 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.52      0.53       210\n",
      "           2       0.69      0.52      0.59       210\n",
      "           3       0.94      0.80      0.86       210\n",
      "           4       0.43      0.43      0.43       210\n",
      "           5       0.42      0.55      0.48       210\n",
      "           6       0.45      0.36      0.40       210\n",
      "           7       0.50      0.66      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.55      1470\n",
      "weighted avg       0.57      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   1   0  26  46  20  12]\n",
      " [ 14 108   8  25  30  17   8]\n",
      " [  3  14 170  10   6   6   1]\n",
      " [ 18  19   3  87  46  13  24]\n",
      " [ 22  15   0  25 121   5  22]\n",
      " [ 23   2   1  24  16  78  66]\n",
      " [ 12   2   0   6   7  46 137]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.50      0.52       210\n",
      "           2       0.67      0.51      0.58       210\n",
      "           3       0.93      0.81      0.87       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.44      0.58      0.50       210\n",
      "           6       0.42      0.37      0.39       210\n",
      "           7       0.51      0.65      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   5   0  26  38  21  11]\n",
      " [ 16 110   6  23  32  13  10]\n",
      " [  3  15 168  13   4   6   1]\n",
      " [ 19  14   4  91  43  15  24]\n",
      " [ 20   8   0  22 129  11  20]\n",
      " [ 21   7   1  25  14  74  68]\n",
      " [ 14   1   0   8   5  46 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53       210\n",
      "           2       0.69      0.52      0.59       210\n",
      "           3       0.94      0.80      0.86       210\n",
      "           4       0.44      0.43      0.44       210\n",
      "           5       0.49      0.61      0.54       210\n",
      "           6       0.40      0.35      0.37       210\n",
      "           7       0.50      0.65      0.57       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.545578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   4   0  29  42  19  11]\n",
      " [ 12 114   9  26  27  14   8]\n",
      " [  2  15 169  11   6   6   1]\n",
      " [ 19  12   5  90  48  11  25]\n",
      " [ 24  10   1  23 122   6  24]\n",
      " [ 19   4   1  25  15  72  74]\n",
      " [ 11   2   0   6   8  53 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.50      0.52       210\n",
      "           2       0.71      0.54      0.61       210\n",
      "           3       0.91      0.80      0.86       210\n",
      "           4       0.43      0.43      0.43       210\n",
      "           5       0.46      0.58      0.51       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.48      0.62      0.54       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   5   0  22  42  20  11]\n",
      " [ 17 110   7  23  27  15  11]\n",
      " [  3  15 169  11   5   6   1]\n",
      " [ 19  13   3  88  50  17  20]\n",
      " [ 19  11   0  26 125   7  22]\n",
      " [ 22   9   1  26  13  68  71]\n",
      " [ 13   0   0   8   7  51 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53       210\n",
      "           2       0.67      0.52      0.59       210\n",
      "           3       0.94      0.80      0.87       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.46      0.60      0.52       210\n",
      "           6       0.37      0.32      0.35       210\n",
      "           7       0.49      0.62      0.55       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.55      1470\n",
      "weighted avg       0.56      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111   6   0  19  46  18  10]\n",
      " [ 14 110   9  22  31  16   8]\n",
      " [  1  17 168  12   5   6   1]\n",
      " [ 19  16   3  83  49  15  25]\n",
      " [ 18  16   0  27 121   6  22]\n",
      " [ 18   8   1  20  19  67  77]\n",
      " [ 13   2   0   7   7  45 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.53      0.55       210\n",
      "           2       0.63      0.52      0.57       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.44      0.58      0.50       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.49      0.65      0.56       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   4   1  23  46  19  13]\n",
      " [  9 112   9  27  31  13   9]\n",
      " [  1  15 169  10   8   6   1]\n",
      " [ 17  15   2  89  48  14  25]\n",
      " [ 20  12   1  20 127   7  23]\n",
      " [ 15   5   3  25  18  71  73]\n",
      " [ 12   4   1   8   4  46 135]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.50      0.54       210\n",
      "           2       0.67      0.53      0.59       210\n",
      "           3       0.91      0.80      0.85       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.48      0.64      0.55       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   4   0  20  40  19  12]\n",
      " [  9 113   7  26  31  13  11]\n",
      " [  3  15 168  11   6   6   1]\n",
      " [ 17  15   4  91  46  15  22]\n",
      " [ 21  16   0  25 118   6  24]\n",
      " [ 14   9   1  24  19  71  72]\n",
      " [ 12   1   0  10   6  46 135]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.55      0.57       210\n",
      "           2       0.65      0.54      0.59       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.44      0.43      0.44       210\n",
      "           5       0.44      0.56      0.50       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.49      0.64      0.55       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.55      1470\n",
      "weighted avg       0.57      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   7   0  23  41  17  12]\n",
      " [ 16 111   8  23  30  13   9]\n",
      " [  2  15 170  11   4   7   1]\n",
      " [ 15  22   3  84  45  14  27]\n",
      " [ 21  13   1  26 118   8  23]\n",
      " [ 22   6   1  25  17  72  67]\n",
      " [ 13   0   0  11   5  47 134]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.54       210\n",
      "           2       0.64      0.53      0.58       210\n",
      "           3       0.93      0.81      0.87       210\n",
      "           4       0.41      0.40      0.41       210\n",
      "           5       0.45      0.56      0.50       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.49      0.64      0.55       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.55      1470\n",
      "weighted avg       0.55      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.27346938775510204\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 22   0  87  11  17  20  53]\n",
      " [  7   0 132   8   8   1  54]\n",
      " [  1   0 178   3   1  14  13]\n",
      " [  5   0 149   5   9  10  32]\n",
      " [  5   0 155   5  10   6  29]\n",
      " [ 17   0  46   4   3  42  98]\n",
      " [  7   0  13   6   4  35 145]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.10      0.16       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.23      0.85      0.37       210\n",
      "           4       0.12      0.02      0.04       210\n",
      "           5       0.19      0.05      0.08       210\n",
      "           6       0.33      0.20      0.25       210\n",
      "           7       0.34      0.69      0.46       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.22      0.27      0.19      1470\n",
      "weighted avg       0.22      0.27      0.19      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_gkb.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[143   4   2  10  33  15   3]\n",
      " [  4 141  16  13  21  13   2]\n",
      " [  4   5 182  12   5   2   0]\n",
      " [  9   6  22 132  23  13   5]\n",
      " [ 24   7  10  12 140  10   7]\n",
      " [ 13   9   6  21   4  98  59]\n",
      " [  1   2   0   0   3  16 188]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.68      0.70       210\n",
      "           2       0.81      0.67      0.73       210\n",
      "           3       0.76      0.87      0.81       210\n",
      "           4       0.66      0.63      0.64       210\n",
      "           5       0.61      0.67      0.64       210\n",
      "           6       0.59      0.47      0.52       210\n",
      "           7       0.71      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133   3   2   8  57   4   3]\n",
      " [ 11 157  11   7  17   6   1]\n",
      " [  7   6 183   7   7   0   0]\n",
      " [ 34  12  17 100  37   6   4]\n",
      " [ 40  17   7  11 126   1   8]\n",
      " [ 44  11   4  13  11  61  66]\n",
      " [  2   5   0   1   9  16 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.63      0.55       210\n",
      "           2       0.74      0.75      0.75       210\n",
      "           3       0.82      0.87      0.84       210\n",
      "           4       0.68      0.48      0.56       210\n",
      "           5       0.48      0.60      0.53       210\n",
      "           6       0.65      0.29      0.40       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   2   3   7  53   6   3]\n",
      " [  9 156  12   7  20   5   1]\n",
      " [  9   5 181   8   7   0   0]\n",
      " [ 26  11  18 104  39   7   5]\n",
      " [ 35  16   8  16 126   2   7]\n",
      " [ 32   9   3  14  11  83  58]\n",
      " [  2   2   0   0   6  25 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.65      0.59       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.67      0.50      0.57       210\n",
      "           5       0.48      0.60      0.53       210\n",
      "           6       0.65      0.40      0.49       210\n",
      "           7       0.70      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   2   7  10  49   4   4]\n",
      " [  4 150  15   9  24   4   4]\n",
      " [  8   6 180   8   8   0   0]\n",
      " [ 20  10  18 109  40   7   6]\n",
      " [ 32  13   4  14 136   2   9]\n",
      " [ 29  10   2  16  16  69  68]\n",
      " [  2   1   0   0   6  20 181]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.64      0.61       210\n",
      "           2       0.78      0.71      0.75       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.66      0.52      0.58       210\n",
      "           5       0.49      0.65      0.56       210\n",
      "           6       0.65      0.33      0.44       210\n",
      "           7       0.67      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   2   6  10  51   3   4]\n",
      " [  6 157  12   8  18   4   5]\n",
      " [  8   5 182   7   8   0   0]\n",
      " [ 20  10  22 105  41   6   6]\n",
      " [ 28  11   6  11 142   2  10]\n",
      " [ 32   8   2  16  15  69  68]\n",
      " [  3   1   0   0   4  17 185]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.64      0.61       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.67      0.50      0.57       210\n",
      "           5       0.51      0.68      0.58       210\n",
      "           6       0.68      0.33      0.44       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6571428571428571\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132   2   5   8  56   3   4]\n",
      " [  3 153  13   9  24   5   3]\n",
      " [  6   4 183   7  10   0   0]\n",
      " [ 22  10  21 100  45   6   6]\n",
      " [ 27   9   6  10 147   2   9]\n",
      " [ 30   7   2  17  18  62  74]\n",
      " [  3   1   0   1   5  11 189]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.82      0.73      0.77       210\n",
      "           3       0.80      0.87      0.83       210\n",
      "           4       0.66      0.48      0.55       210\n",
      "           5       0.48      0.70      0.57       210\n",
      "           6       0.70      0.30      0.41       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   2   5   7  51   4   4]\n",
      " [  5 153  11  10  22   4   5]\n",
      " [  7   4 181   7  11   0   0]\n",
      " [ 21   8  20 104  45   6   6]\n",
      " [ 29   9   8   8 145   1  10]\n",
      " [ 25   8   1  18  20  64  74]\n",
      " [  3   0   0   0   4  16 187]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.65      0.63       210\n",
      "           2       0.83      0.73      0.78       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.68      0.50      0.57       210\n",
      "           5       0.49      0.69      0.57       210\n",
      "           6       0.67      0.30      0.42       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.65      1470\n",
      "weighted avg       0.68      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 97   5  12   5  57  29   5]\n",
      " [  5 103  22   8  43  21   8]\n",
      " [ 15  13 155   4   9  14   0]\n",
      " [ 16   7  33  57  58  33   6]\n",
      " [ 16  11  20  14 122  21   6]\n",
      " [ 12  12   1  13   5  83  84]\n",
      " [  0   2   0   0   1  30 177]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.46      0.52       210\n",
      "           2       0.67      0.49      0.57       210\n",
      "           3       0.64      0.74      0.68       210\n",
      "           4       0.56      0.27      0.37       210\n",
      "           5       0.41      0.58      0.48       210\n",
      "           6       0.36      0.40      0.38       210\n",
      "           7       0.62      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[103   6  13   9  45  28   6]\n",
      " [  6 102  20  11  43  20   8]\n",
      " [ 23  15 143  10   9  10   0]\n",
      " [ 13   8  28  79  45  29   8]\n",
      " [ 23  13  17  18 114  21   4]\n",
      " [ 12  13   0  20   3  82  80]\n",
      " [  0   3   0   0   0  35 172]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.49      0.53       210\n",
      "           2       0.64      0.49      0.55       210\n",
      "           3       0.65      0.68      0.66       210\n",
      "           4       0.54      0.38      0.44       210\n",
      "           5       0.44      0.54      0.49       210\n",
      "           6       0.36      0.39      0.38       210\n",
      "           7       0.62      0.82      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7278911564625851\n",
      "Confusion Matrix of SVM is:\n",
      " [[146   3   3  10  35  12   1]\n",
      " [  3 153   8  12  18  14   2]\n",
      " [  2   6 180  10  10   2   0]\n",
      " [  4   7  12 146  24  14   3]\n",
      " [ 17   5   7  12 153   9   7]\n",
      " [ 14   5   6  20   3 100  62]\n",
      " [  1   0   0   1   2  14 192]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74       210\n",
      "           2       0.85      0.73      0.79       210\n",
      "           3       0.83      0.86      0.85       210\n",
      "           4       0.69      0.70      0.69       210\n",
      "           5       0.62      0.73      0.67       210\n",
      "           6       0.61      0.48      0.53       210\n",
      "           7       0.72      0.91      0.81       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.72      1470\n",
      "weighted avg       0.73      0.73      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7557823129251701\n",
      "Confusion Matrix of SVM is:\n",
      " [[155   3   1   6  31  14   0]\n",
      " [  0 157   9  15  13  14   2]\n",
      " [  0   4 187   9   7   3   0]\n",
      " [  2   5   9 153  24  13   4]\n",
      " [ 20   8   6   8 154   8   6]\n",
      " [  9   2   4  18   3 117  57]\n",
      " [  2   0   0   0   3  17 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.74      0.78       210\n",
      "           2       0.88      0.75      0.81       210\n",
      "           3       0.87      0.89      0.88       210\n",
      "           4       0.73      0.73      0.73       210\n",
      "           5       0.66      0.73      0.69       210\n",
      "           6       0.63      0.56      0.59       210\n",
      "           7       0.73      0.90      0.81       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.75      1470\n",
      "weighted avg       0.76      0.76      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7489795918367347\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   3   2   7  31  14   0]\n",
      " [  3 157   8  10  14  16   2]\n",
      " [  1   4 184  10   8   3   0]\n",
      " [  3   5   9 150  25  14   4]\n",
      " [ 17   6   4  11 156   9   7]\n",
      " [ 10   3   5  21   3 110  58]\n",
      " [  2   0   0   0   2  15 191]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77       210\n",
      "           2       0.88      0.75      0.81       210\n",
      "           3       0.87      0.88      0.87       210\n",
      "           4       0.72      0.71      0.72       210\n",
      "           5       0.65      0.74      0.69       210\n",
      "           6       0.61      0.52      0.56       210\n",
      "           7       0.73      0.91      0.81       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of SVM is:\n",
      " [[136   3   2  12  43  12   2]\n",
      " [  3 136  14  11  29  13   4]\n",
      " [  5   3 184  10   6   2   0]\n",
      " [  8   5  21 136  22  12   6]\n",
      " [ 26   8  11  17 133   7   8]\n",
      " [ 18   8  10  17   5  82  70]\n",
      " [  1   1   0   0   2   9 197]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67       210\n",
      "           2       0.83      0.65      0.73       210\n",
      "           3       0.76      0.88      0.81       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.55      0.63      0.59       210\n",
      "           6       0.60      0.39      0.47       210\n",
      "           7       0.69      0.94      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.28095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0 189   0   0   0  21]\n",
      " [  0   0 176   0   0   0  34]\n",
      " [  0   0 210   0   0   0   0]\n",
      " [  0   0 187   0   0   0  23]\n",
      " [  0   0 188   0   0   0  22]\n",
      " [  0   0  79   0   0   0 131]\n",
      " [  0   0   7   0   0   0 203]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.20      1.00      0.34       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.47      0.97      0.63       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.10      0.28      0.14      1470\n",
      "weighted avg       0.10      0.28      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[186   0   3   0   0  17   4]\n",
      " [174   0   2   0   0  26   8]\n",
      " [107   0 103   0   0   0   0]\n",
      " [173   0  14   0   0  14   9]\n",
      " [183   0   5   0   0  18   4]\n",
      " [ 74   0   5   0   0  63  68]\n",
      " [  7   0   0   0   0  42 161]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.89      0.33       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.78      0.49      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.63      0.77      0.69       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.28      0.35      0.28      1470\n",
      "weighted avg       0.28      0.35      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   0   1  58   0   7  14]\n",
      " [ 20   0   0 156   0   3  31]\n",
      " [ 25   0  94  91   0   0   0]\n",
      " [ 22   0   4 161   0   4  19]\n",
      " [ 33   0   1 154   0   7  15]\n",
      " [ 37   0   0  42   0  33  98]\n",
      " [  6   0   0   1   0   9 194]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.62      0.54       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.94      0.45      0.61       210\n",
      "           4       0.24      0.77      0.37       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.52      0.16      0.24       210\n",
      "           7       0.52      0.92      0.67       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.39      0.42      0.35      1470\n",
      "weighted avg       0.39      0.42      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45850340136054424\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   9   1  56   0   7   7]\n",
      " [ 20  93   0  84   0   8   5]\n",
      " [ 25  13  94  78   0   0   0]\n",
      " [ 22  15   4 152   0   8   9]\n",
      " [ 33  15   1 147   0   7   7]\n",
      " [ 37  27   0  34   0  47  65]\n",
      " [  6  15   0   0   0  31 158]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.62      0.54       210\n",
      "           2       0.50      0.44      0.47       210\n",
      "           3       0.94      0.45      0.61       210\n",
      "           4       0.28      0.72      0.40       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.44      0.22      0.30       210\n",
      "           7       0.63      0.75      0.69       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.43      1470\n",
      "weighted avg       0.46      0.46      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   2   9  58  12   5]\n",
      " [ 19  75   1   8  76  27   4]\n",
      " [  8   7 114  12  69   0   0]\n",
      " [ 19   8   7  60  94  18   4]\n",
      " [ 34   5   3  10 141  11   6]\n",
      " [ 35   5  11  10  26  64  59]\n",
      " [  9   2   0   0   0  43 156]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.59      0.54       210\n",
      "           2       0.74      0.36      0.48       210\n",
      "           3       0.83      0.54      0.66       210\n",
      "           4       0.55      0.29      0.38       210\n",
      "           5       0.30      0.67      0.42       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.67      0.74      0.70       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.50      1470\n",
      "weighted avg       0.56      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5244897959183673\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   2   6  11  49  13   5]\n",
      " [  6  82   7   8  73  32   2]\n",
      " [ 11   4 141  13  40   1   0]\n",
      " [ 15   7  10  65  89  22   2]\n",
      " [ 28   5   9  14 134  15   5]\n",
      " [ 20   8   8  13  27  79  55]\n",
      " [  4   6   3   1   1  49 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.59      0.59       210\n",
      "           2       0.72      0.39      0.51       210\n",
      "           3       0.77      0.67      0.72       210\n",
      "           4       0.52      0.31      0.39       210\n",
      "           5       0.32      0.64      0.43       210\n",
      "           6       0.37      0.38      0.38       210\n",
      "           7       0.68      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.57      0.52      0.53      1470\n",
      "weighted avg       0.57      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  16   6  14  46  10   4]\n",
      " [  2 117   3  16  33  34   5]\n",
      " [  5  16 140  13  31   5   0]\n",
      " [ 13  29   9  68  66  21   4]\n",
      " [ 21  24   4  22 121  12   6]\n",
      " [ 21  22   5  16  16  86  44]\n",
      " [  4   4   1   5   3  52 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.54      0.58       210\n",
      "           2       0.51      0.56      0.53       210\n",
      "           3       0.83      0.67      0.74       210\n",
      "           4       0.44      0.32      0.37       210\n",
      "           5       0.38      0.58      0.46       210\n",
      "           6       0.39      0.41      0.40       210\n",
      "           7       0.69      0.67      0.68       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  16   9  23  37   5   5]\n",
      " [  5 115   6  36  27  17   4]\n",
      " [ 13  11 139  18  25   4   0]\n",
      " [ 15  29  10  98  42  13   3]\n",
      " [ 25  23   7  25 118   8   4]\n",
      " [ 15  24   7  33  12  76  43]\n",
      " [  4   6   4   7   3  52 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.55      0.57       210\n",
      "           2       0.51      0.55      0.53       210\n",
      "           3       0.76      0.66      0.71       210\n",
      "           4       0.41      0.47      0.44       210\n",
      "           5       0.45      0.56      0.50       210\n",
      "           6       0.43      0.36      0.39       210\n",
      "           7       0.69      0.64      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  12   6  22  45   7   5]\n",
      " [  5 117   5  21  43  17   2]\n",
      " [  9   3 156  18  22   2   0]\n",
      " [ 15  18  10  96  56  12   3]\n",
      " [ 28  10   6  24 130   6   6]\n",
      " [ 22  20   8  20  23  73  44]\n",
      " [  5   3   4   8   6  54 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.54      0.56       210\n",
      "           2       0.64      0.56      0.60       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.40      0.62      0.49       210\n",
      "           6       0.43      0.35      0.38       210\n",
      "           7       0.68      0.62      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.56      1470\n",
      "weighted avg       0.57      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   9   6  13  42  17   4]\n",
      " [  8 113   6  20  37  25   1]\n",
      " [  6   1 156  18  15  14   0]\n",
      " [ 13  15  13  89  48  29   3]\n",
      " [ 24  12   5  22 130  13   4]\n",
      " [ 18  18   7  21  15  94  37]\n",
      " [  9   3   2   5   6  58 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.57      0.58       210\n",
      "           2       0.66      0.54      0.59       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.47      0.42      0.45       210\n",
      "           5       0.44      0.62      0.52       210\n",
      "           6       0.38      0.45      0.41       210\n",
      "           7       0.72      0.60      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.57      1470\n",
      "weighted avg       0.58      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   7   5  16  41  14   8]\n",
      " [ 10 107   7  28  33  23   2]\n",
      " [  7   1 163  15  17   7   0]\n",
      " [ 17  11  16 103  33  26   4]\n",
      " [ 27  10   4  33 117  14   5]\n",
      " [ 22  13  11  18  14  91  41]\n",
      " [  3   5   4   4   2  59 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.57      0.57       210\n",
      "           2       0.69      0.51      0.59       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.47      0.49      0.48       210\n",
      "           5       0.46      0.56      0.50       210\n",
      "           6       0.39      0.43      0.41       210\n",
      "           7       0.69      0.63      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  12   5  18  41  10   6]\n",
      " [ 11 121   5  23  27  20   3]\n",
      " [  8   3 163  14  13   9   0]\n",
      " [ 26  11  13 105  33  18   4]\n",
      " [ 28  20   6  31 108  13   4]\n",
      " [ 25  13   9  19  16  85  43]\n",
      " [  6   8   2   0  10  60 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.56      0.55       210\n",
      "           2       0.64      0.58      0.61       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.50      0.50      0.50       210\n",
      "           5       0.44      0.51      0.47       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.67      0.59      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  10   5  18  39  12   5]\n",
      " [  7 125   6  23  29  17   3]\n",
      " [ 10   5 164  17  11   3   0]\n",
      " [ 19  15  14 102  34  20   6]\n",
      " [ 28  23   5  32 107  10   5]\n",
      " [ 22  26  11  16  14  84  37]\n",
      " [  6   5   1   7   9  53 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.58      0.57       210\n",
      "           2       0.60      0.60      0.60       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.47      0.49      0.48       210\n",
      "           5       0.44      0.51      0.47       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.70      0.61      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  13   7  14  43  17   3]\n",
      " [  5 116  11  25  28  18   7]\n",
      " [  7   4 166  13  12   8   0]\n",
      " [ 23  11  18  91  37  25   5]\n",
      " [ 26  18   9  28 112  12   5]\n",
      " [ 23  22   9  22   9  85  40]\n",
      " [  5   2   1   3   7  64 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.54      0.55       210\n",
      "           2       0.62      0.55      0.59       210\n",
      "           3       0.75      0.79      0.77       210\n",
      "           4       0.46      0.43      0.45       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.37      0.40      0.39       210\n",
      "           7       0.68      0.61      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  11   6  14  40  13  10]\n",
      " [ 10 123   8  22  23  19   5]\n",
      " [ 12   2 164  13  13   6   0]\n",
      " [ 20  25  16  93  29  23   4]\n",
      " [ 34  21  10  26  98  14   7]\n",
      " [ 20  16  11  18  15  90  40]\n",
      " [  3   8   2   4   7  57 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.55      0.55       210\n",
      "           2       0.60      0.59      0.59       210\n",
      "           3       0.76      0.78      0.77       210\n",
      "           4       0.49      0.44      0.47       210\n",
      "           5       0.44      0.47      0.45       210\n",
      "           6       0.41      0.43      0.42       210\n",
      "           7       0.66      0.61      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  12   5  20  37  16   9]\n",
      " [  5 129   7  24  23  19   3]\n",
      " [  7   6 162  12  14   9   0]\n",
      " [ 20  20  15  95  39  18   3]\n",
      " [ 35  21   6  29 100  14   5]\n",
      " [ 18  22   8  16  12  90  44]\n",
      " [  3   8   2   3   4  61 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.53      0.54       210\n",
      "           2       0.59      0.61      0.60       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.48      0.45      0.46       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.40      0.43      0.41       210\n",
      "           7       0.67      0.61      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  10   8  19  37  15   5]\n",
      " [ 10 122  10  20  26  18   4]\n",
      " [  6   6 163  14  12   9   0]\n",
      " [ 20  13  15  95  35  25   7]\n",
      " [ 29  18   7  38  99  13   6]\n",
      " [ 18  24   8  19  10  88  43]\n",
      " [  5   5   1   6   4  62 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.55      0.56       210\n",
      "           2       0.62      0.58      0.60       210\n",
      "           3       0.77      0.78      0.77       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.44      0.47      0.46       210\n",
      "           6       0.38      0.42      0.40       210\n",
      "           7       0.66      0.60      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   5  10  19  40  18   5]\n",
      " [  6 123   8  25  22  22   4]\n",
      " [  9   3 165  14  14   3   2]\n",
      " [ 17  15  15  97  38  24   4]\n",
      " [ 35  24  10  30  87  17   7]\n",
      " [ 17  17  12  20   9  90  45]\n",
      " [  4   3   2   5   8  63 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.54      0.55       210\n",
      "           2       0.65      0.59      0.61       210\n",
      "           3       0.74      0.79      0.76       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.40      0.41      0.41       210\n",
      "           6       0.38      0.43      0.40       210\n",
      "           7       0.65      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.55      1470\n",
      "weighted avg       0.55      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  12   9  22  30  18   5]\n",
      " [  7 125   7  22  24  20   5]\n",
      " [  8   4 166  15  11   5   1]\n",
      " [ 19  15  14  94  37  25   6]\n",
      " [ 29  24   8  41  84  19   5]\n",
      " [ 21  19   9  16   9  94  42]\n",
      " [  5   5   2   5   4  65 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.54      0.55       210\n",
      "           2       0.61      0.60      0.60       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.44      0.45      0.44       210\n",
      "           5       0.42      0.40      0.41       210\n",
      "           6       0.38      0.45      0.41       210\n",
      "           7       0.66      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.55      1470\n",
      "weighted avg       0.55      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   9   8  21  35  20   5]\n",
      " [  8 117   7  24  19  28   7]\n",
      " [  7   4 167  14  11   7   0]\n",
      " [ 23  15  13  98  34  25   2]\n",
      " [ 35  21  10  36  87  13   8]\n",
      " [ 21  20   9  20   8  92  40]\n",
      " [  4   6   5   4   3  66 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       210\n",
      "           2       0.61      0.56      0.58       210\n",
      "           3       0.76      0.80      0.78       210\n",
      "           4       0.45      0.47      0.46       210\n",
      "           5       0.44      0.41      0.43       210\n",
      "           6       0.37      0.44      0.40       210\n",
      "           7       0.66      0.58      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.29183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  7   1 171   1   1   2  27]\n",
      " [  1   9 133   0  12   5  50]\n",
      " [  1   0 199   0   0   0  10]\n",
      " [  3   1 168   0   2   0  36]\n",
      " [  5   2 171   0   7   0  25]\n",
      " [  5   1  36   0   4   1 163]\n",
      " [  1   0   0   0   1   2 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.03      0.06       210\n",
      "           2       0.64      0.04      0.08       210\n",
      "           3       0.23      0.95      0.37       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.26      0.03      0.06       210\n",
      "           6       0.10      0.00      0.01       210\n",
      "           7       0.40      0.98      0.57       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.28      0.29      0.16      1470\n",
      "weighted avg       0.28      0.29      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 71   5  29   0  79  15  11]\n",
      " [  7  96  28   1  47  16  15]\n",
      " [ 13   6 168   1  15   5   2]\n",
      " [ 12  14  44   5 103  18  14]\n",
      " [ 17  10  13   1 147   9  13]\n",
      " [  8   8  13   0  19  44 118]\n",
      " [  0   1   0   0   2   9 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.34      0.42       210\n",
      "           2       0.69      0.46      0.55       210\n",
      "           3       0.57      0.80      0.67       210\n",
      "           4       0.62      0.02      0.05       210\n",
      "           5       0.36      0.70      0.47       210\n",
      "           6       0.38      0.21      0.27       210\n",
      "           7       0.53      0.94      0.68       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.44      1470\n",
      "weighted avg       0.53      0.50      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   7   1   7  37  20   7]\n",
      " [  8 137   6   4  31  14  10]\n",
      " [ 31  17 146   4   5   7   0]\n",
      " [ 32  18  26  31  69  24  10]\n",
      " [ 34  22   6   6 121  12   9]\n",
      " [ 18  15   5   5   9  56 102]\n",
      " [  0   2   0   0   1  13 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.62      0.56       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.77      0.70      0.73       210\n",
      "           4       0.54      0.15      0.23       210\n",
      "           5       0.44      0.58      0.50       210\n",
      "           6       0.38      0.27      0.31       210\n",
      "           7       0.58      0.92      0.72       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.53      1470\n",
      "weighted avg       0.55      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   7   1   7  38  24   5]\n",
      " [  4 138   5  12  28  18   5]\n",
      " [ 25   8 155  10   4   8   0]\n",
      " [ 15  16  16  89  38  27   9]\n",
      " [ 32  18   5  19 115  13   8]\n",
      " [ 19  10   0   9   7  75  90]\n",
      " [  1   0   0   0   1  18 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.61      0.59       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.61      0.42      0.50       210\n",
      "           5       0.50      0.55      0.52       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.62      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   4   2  12  37  24   3]\n",
      " [  2 134   4  13  33  17   7]\n",
      " [ 14   7 155  19  10   5   0]\n",
      " [ 12  13  12 103  38  25   7]\n",
      " [ 28  16   3  22 121  15   5]\n",
      " [ 16   5   0  16   5  89  79]\n",
      " [  1   0   0   0   1  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.62       210\n",
      "           2       0.75      0.64      0.69       210\n",
      "           3       0.88      0.74      0.80       210\n",
      "           4       0.56      0.49      0.52       210\n",
      "           5       0.49      0.58      0.53       210\n",
      "           6       0.45      0.42      0.44       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   5   1   6  37  24   3]\n",
      " [  3 139   4  11  32  15   6]\n",
      " [  8   7 161  17  11   6   0]\n",
      " [  9  11   8 115  34  27   6]\n",
      " [ 23  13   3  20 129  15   7]\n",
      " [ 12   4   0  16  10  93  75]\n",
      " [  1   0   0   0   1  20 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       210\n",
      "           2       0.78      0.66      0.71       210\n",
      "           3       0.91      0.77      0.83       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.51      0.61      0.56       210\n",
      "           6       0.47      0.44      0.45       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   3   1  13  38  26   3]\n",
      " [  3 132   4  14  35  15   7]\n",
      " [  8   5 170  11  11   5   0]\n",
      " [  5  10   8 121  33  27   6]\n",
      " [ 21  11   2  23 130  16   7]\n",
      " [ 12   6   0  18   7  99  68]\n",
      " [  1   0   0   0   1  23 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.60      0.65       210\n",
      "           2       0.79      0.63      0.70       210\n",
      "           3       0.92      0.81      0.86       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   0  11  33  24   4]\n",
      " [  1 135   4  17  29  19   5]\n",
      " [  9   5 166  15  10   5   0]\n",
      " [  6  10   5 126  31  26   6]\n",
      " [ 18  10   2  27 132  14   7]\n",
      " [  9   7   0  23   5  98  68]\n",
      " [  1   0   0   0   2  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.64      0.69       210\n",
      "           2       0.79      0.64      0.71       210\n",
      "           3       0.94      0.79      0.86       210\n",
      "           4       0.58      0.60      0.59       210\n",
      "           5       0.55      0.63      0.58       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   2  11  36  20   3]\n",
      " [  2 134   5  21  29  17   2]\n",
      " [  9   5 167  14  10   5   0]\n",
      " [  9   8   2 130  32  24   5]\n",
      " [ 19   9   3  23 137  11   8]\n",
      " [  9   5   0  20   7  97  72]\n",
      " [  0   0   0   0   4  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.64      0.68       210\n",
      "           2       0.81      0.64      0.71       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.59      0.62      0.61       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.50      0.46      0.48       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   3   0  12  39  22   2]\n",
      " [  2 136   4  16  30  19   3]\n",
      " [  8   7 170  12   6   7   0]\n",
      " [  6   5   2 129  35  29   4]\n",
      " [ 18   9   3  24 138   9   9]\n",
      " [ 13   8   0  20   4  92  73]\n",
      " [  2   0   0   0   2  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.81      0.65      0.72       210\n",
      "           3       0.95      0.81      0.87       210\n",
      "           4       0.61      0.61      0.61       210\n",
      "           5       0.54      0.66      0.59       210\n",
      "           6       0.46      0.44      0.45       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   1  11  38  21   3]\n",
      " [  3 138   5  13  30  17   4]\n",
      " [  3   6 173  11  12   5   0]\n",
      " [  7   6   5 137  28  20   7]\n",
      " [ 19   7   3  22 140  14   5]\n",
      " [ 10   5   0  25   3  93  74]\n",
      " [  0   0   0   2   3  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.62      0.68       210\n",
      "           2       0.83      0.66      0.73       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.62      0.65      0.64       210\n",
      "           5       0.55      0.67      0.60       210\n",
      "           6       0.49      0.44      0.47       210\n",
      "           7       0.67      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6884353741496598\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   3   0  10  37  21   4]\n",
      " [  0 140   5  15  28  19   3]\n",
      " [  7   4 172  15   5   7   0]\n",
      " [ 10   7   3 136  26  22   6]\n",
      " [ 20   9   2  17 141  15   6]\n",
      " [ 13   7   0  17   5 107  61]\n",
      " [  1   0   0   0   1  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.64      0.68       210\n",
      "           2       0.82      0.67      0.74       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.65      0.65      0.65       210\n",
      "           5       0.58      0.67      0.62       210\n",
      "           6       0.49      0.51      0.50       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   5   0  14  31  19   3]\n",
      " [  2 140   4  12  30  19   3]\n",
      " [  5   7 170  14   9   5   0]\n",
      " [  9   6   3 135  29  23   5]\n",
      " [ 22   9   3  24 128  17   7]\n",
      " [  9   7   1  20   5 106  62]\n",
      " [  1   0   0   0   2  20 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.66      0.70       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.94      0.81      0.87       210\n",
      "           4       0.62      0.64      0.63       210\n",
      "           5       0.55      0.61      0.58       210\n",
      "           6       0.51      0.50      0.51       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   4   1  13  29  21   2]\n",
      " [  0 147   5  15  24  17   2]\n",
      " [  4   6 170  18   6   6   0]\n",
      " [  6   5   7 134  29  25   4]\n",
      " [ 23   9   2  19 136  16   5]\n",
      " [ 11   7   1  23   2 102  64]\n",
      " [  1   0   0   0   3  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.67      0.71       210\n",
      "           2       0.83      0.70      0.76       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.60      0.64      0.62       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.71      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   5   0   9  36  22   2]\n",
      " [  0 145   6  13  24  19   3]\n",
      " [  8   7 169  13   8   5   0]\n",
      " [  6   4   3 141  26  25   5]\n",
      " [ 22   7   3  24 132  18   4]\n",
      " [ 13   5   0  21   3 107  61]\n",
      " [  0   0   0   0   2  25 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.65      0.69       210\n",
      "           2       0.84      0.69      0.76       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.64      0.67      0.65       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.48      0.51      0.50       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   3   0  12  31  20   4]\n",
      " [  2 145   4  14  23  18   4]\n",
      " [  5   5 173  12   8   7   0]\n",
      " [  6   7   6 136  27  24   4]\n",
      " [ 14   6   3  23 143  17   4]\n",
      " [ 11   6   0  24   3  99  67]\n",
      " [  2   0   0   0   2  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.84      0.69      0.76       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.62      0.65      0.63       210\n",
      "           5       0.60      0.68      0.64       210\n",
      "           6       0.48      0.47      0.47       210\n",
      "           7       0.69      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   3   1  12  34  22   3]\n",
      " [  1 148   5  17  19  17   3]\n",
      " [  4   7 174  11   6   8   0]\n",
      " [  3   7   6 140  28  22   4]\n",
      " [ 22  12   2  26 128  13   7]\n",
      " [ 11   6   1  20   5 103  64]\n",
      " [  1   0   0   0   1  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.64      0.70       210\n",
      "           2       0.81      0.70      0.75       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.62      0.67      0.64       210\n",
      "           5       0.58      0.61      0.59       210\n",
      "           6       0.50      0.49      0.49       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   1  12  33  22   4]\n",
      " [  0 148   2  18  20  16   6]\n",
      " [  3   6 172  15   8   6   0]\n",
      " [  5  10   3 140  24  23   5]\n",
      " [ 22  10   4  26 129  13   6]\n",
      " [ 13   6   0  23   2 100  66]\n",
      " [  1   0   0   0   2  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.65      0.70       210\n",
      "           2       0.81      0.70      0.76       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.60      0.67      0.63       210\n",
      "           5       0.59      0.61      0.60       210\n",
      "           6       0.49      0.48      0.48       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   3   0  14  32  23   2]\n",
      " [  0 148   2  19  21  16   4]\n",
      " [  3   7 174  13   7   6   0]\n",
      " [  5   8   6 141  23  22   5]\n",
      " [ 21   8   5  23 131  13   9]\n",
      " [ 14   7   0  19   3 104  63]\n",
      " [  1   0   0   0   2  21 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.65      0.70       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.62      0.67      0.64       210\n",
      "           5       0.60      0.62      0.61       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.69      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   4   0  13  31  18   2]\n",
      " [  1 149   3  15  20  18   4]\n",
      " [  5   6 172  15   7   5   0]\n",
      " [  6   8   6 137  23  24   6]\n",
      " [ 23   9   3  20 134  14   7]\n",
      " [ 12   8   0  23   3 103  61]\n",
      " [  1   0   0   0   3  30 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.68      0.71       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.61      0.64      0.62       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 91   6  35   8  36  29   5]\n",
      " [  7  96  45   5  21  28   8]\n",
      " [ 14  18 165   4   1   8   0]\n",
      " [ 28  10  58  44  30  30  10]\n",
      " [ 23  14  50  18  75  25   5]\n",
      " [ 16  13   8   7   3  78  85]\n",
      " [  0   2   0   0   0  33 175]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.43      0.47       210\n",
      "           2       0.60      0.46      0.52       210\n",
      "           3       0.46      0.79      0.58       210\n",
      "           4       0.51      0.21      0.30       210\n",
      "           5       0.45      0.36      0.40       210\n",
      "           6       0.34      0.37      0.35       210\n",
      "           7       0.61      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.47      1470\n",
      "weighted avg       0.50      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_ndisbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80480feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7537414965986394\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[149   2   0   0  44  12   3]\n",
      " [  0 156   9  10  19  14   2]\n",
      " [  1   2 189   7   6   4   1]\n",
      " [  4   4  17 145  23  10   7]\n",
      " [ 10   7   3  14 160   5  11]\n",
      " [  1   7  14  13   4 125  46]\n",
      " [  0   0   0   1   1  24 184]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.71      0.79       210\n",
      "           2       0.88      0.74      0.80       210\n",
      "           3       0.81      0.90      0.86       210\n",
      "           4       0.76      0.69      0.72       210\n",
      "           5       0.62      0.76      0.69       210\n",
      "           6       0.64      0.60      0.62       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   2   1   3  41   5   5]\n",
      " [  5 158  10   7  23   7   0]\n",
      " [  6  11 184   2   2   4   1]\n",
      " [ 20   6  13 127  34   8   2]\n",
      " [ 32  18  10  12 134   1   3]\n",
      " [ 33  23  10  24  16  58  46]\n",
      " [  4   0   0   3  17  11 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.73      0.66       210\n",
      "           2       0.72      0.75      0.74       210\n",
      "           3       0.81      0.88      0.84       210\n",
      "           4       0.71      0.60      0.65       210\n",
      "           5       0.50      0.64      0.56       210\n",
      "           6       0.62      0.28      0.38       210\n",
      "           7       0.75      0.83      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   2   2   2  33   4   6]\n",
      " [  4 160  10   7  23   6   0]\n",
      " [  4   8 186   4   4   3   1]\n",
      " [ 18  11  14 128  31   5   3]\n",
      " [ 32  21   9  16 125   2   5]\n",
      " [ 31  17   7  25  14  64  52]\n",
      " [  2   0   0   1  16  15 176]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.77      0.70       210\n",
      "           2       0.73      0.76      0.75       210\n",
      "           3       0.82      0.89      0.85       210\n",
      "           4       0.70      0.61      0.65       210\n",
      "           5       0.51      0.60      0.55       210\n",
      "           6       0.65      0.30      0.41       210\n",
      "           7       0.72      0.84      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   2   1   2  45   3   6]\n",
      " [  2 161  11   8  23   4   1]\n",
      " [  6  10 185   2   4   2   1]\n",
      " [ 13   9  15 130  36   4   3]\n",
      " [ 25  15   9  15 140   1   5]\n",
      " [ 24  16   6  26  21  65  52]\n",
      " [  2   1   0   2  19  11 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.75      0.77      0.76       210\n",
      "           3       0.81      0.88      0.85       210\n",
      "           4       0.70      0.62      0.66       210\n",
      "           5       0.49      0.67      0.56       210\n",
      "           6       0.72      0.31      0.43       210\n",
      "           7       0.72      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[162   2   1   1  37   2   5]\n",
      " [  3 163  12   7  21   3   1]\n",
      " [  2  10 189   1   6   1   1]\n",
      " [ 12   8  18 125  39   4   4]\n",
      " [ 28  16  13  11 134   2   6]\n",
      " [ 17  17   8  25  23  59  61]\n",
      " [  3   1   0   2  16   9 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.77      0.74       210\n",
      "           2       0.75      0.78      0.76       210\n",
      "           3       0.78      0.90      0.84       210\n",
      "           4       0.73      0.60      0.65       210\n",
      "           5       0.49      0.64      0.55       210\n",
      "           6       0.74      0.28      0.41       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.67      1470\n",
      "weighted avg       0.70      0.69      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.680952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   4   1   1  49   2   6]\n",
      " [  1 159  11   7  26   6   0]\n",
      " [  1   8 192   1   5   2   1]\n",
      " [ 10   7  20 129  36   4   4]\n",
      " [ 25  16  12  12 137   2   6]\n",
      " [ 16  17   9  29  22  53  64]\n",
      " [  2   0   0   1  18   5 184]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.70      0.71       210\n",
      "           2       0.75      0.76      0.76       210\n",
      "           3       0.78      0.91      0.84       210\n",
      "           4       0.72      0.61      0.66       210\n",
      "           5       0.47      0.65      0.54       210\n",
      "           6       0.72      0.25      0.37       210\n",
      "           7       0.69      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   4   1   0  47   2   5]\n",
      " [  1 159  11   8  25   5   1]\n",
      " [  2   8 191   1   4   3   1]\n",
      " [  9   7  21 127  39   5   2]\n",
      " [ 21  17  12  11 141   1   7]\n",
      " [ 16  14  14  26  20  55  65]\n",
      " [  3   1   0   1  16   4 185]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.76      0.76      0.76       210\n",
      "           3       0.76      0.91      0.83       210\n",
      "           4       0.73      0.60      0.66       210\n",
      "           5       0.48      0.67      0.56       210\n",
      "           6       0.73      0.26      0.39       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.67      1470\n",
      "weighted avg       0.70      0.69      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 90   5   5   4  62  19  25]\n",
      " [  0 131  15   7  40  11   6]\n",
      " [  5   9 172   7   9   7   1]\n",
      " [  3   6  23  74  51  21  32]\n",
      " [  9  19   1  13 130   4  34]\n",
      " [  2   5  19  16  16  69  83]\n",
      " [  0   1   0   5  11  30 163]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.43      0.56       210\n",
      "           2       0.74      0.62      0.68       210\n",
      "           3       0.73      0.82      0.77       210\n",
      "           4       0.59      0.35      0.44       210\n",
      "           5       0.41      0.62      0.49       210\n",
      "           6       0.43      0.33      0.37       210\n",
      "           7       0.47      0.78      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.60      0.56      0.56      1470\n",
      "weighted avg       0.60      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 96   5   7   1  58  22  21]\n",
      " [  1 129  19   7  40   9   5]\n",
      " [  5  11 172   7   8   6   1]\n",
      " [  4   7  23  68  52  26  30]\n",
      " [ 16  17   0  11 129   5  32]\n",
      " [  3   6  23  20  15  69  74]\n",
      " [  0   2   0   7   9  39 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.57       210\n",
      "           2       0.73      0.61      0.67       210\n",
      "           3       0.70      0.82      0.76       210\n",
      "           4       0.56      0.32      0.41       210\n",
      "           5       0.41      0.61      0.50       210\n",
      "           6       0.39      0.33      0.36       210\n",
      "           7       0.48      0.73      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7687074829931972\n",
      "Confusion Matrix of SVM is:\n",
      " [[144   2   0   2  47  13   2]\n",
      " [  0 162   8  14  13  12   1]\n",
      " [  0   3 190   7   5   4   1]\n",
      " [  3   5  16 145  22  13   6]\n",
      " [ 12  11   2   9 161   7   8]\n",
      " [  3   4   9  13   3 139  39]\n",
      " [  0   0   0   0   1  20 189]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.69      0.77       210\n",
      "           2       0.87      0.77      0.82       210\n",
      "           3       0.84      0.90      0.87       210\n",
      "           4       0.76      0.69      0.72       210\n",
      "           5       0.64      0.77      0.70       210\n",
      "           6       0.67      0.66      0.67       210\n",
      "           7       0.77      0.90      0.83       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.78      0.77      0.77      1470\n",
      "weighted avg       0.78      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7952380952380952\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   2   0   2  35  13   2]\n",
      " [  0 165   9   7  13  15   1]\n",
      " [  0   2 193   4   5   5   1]\n",
      " [  4   5   7 156  20  15   3]\n",
      " [ 14   8   2  11 166   2   7]\n",
      " [  9   6   6  11   2 141  35]\n",
      " [  0   0   0   0   1  17 192]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.74      0.79       210\n",
      "           2       0.88      0.79      0.83       210\n",
      "           3       0.89      0.92      0.90       210\n",
      "           4       0.82      0.74      0.78       210\n",
      "           5       0.69      0.79      0.73       210\n",
      "           6       0.68      0.67      0.67       210\n",
      "           7       0.80      0.91      0.85       210\n",
      "\n",
      "    accuracy                           0.80      1470\n",
      "   macro avg       0.80      0.80      0.80      1470\n",
      "weighted avg       0.80      0.80      0.80      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7843537414965986\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   2   0   2  40  12   2]\n",
      " [  0 160   9   9  16  15   1]\n",
      " [  0   2 191   5   6   5   1]\n",
      " [  3   3  11 152  23  12   6]\n",
      " [ 14   9   3  10 164   2   8]\n",
      " [  8   5   7   9   2 142  37]\n",
      " [  0   0   0   0   1  17 192]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.72      0.79       210\n",
      "           2       0.88      0.76      0.82       210\n",
      "           3       0.86      0.91      0.89       210\n",
      "           4       0.81      0.72      0.77       210\n",
      "           5       0.65      0.78      0.71       210\n",
      "           6       0.69      0.68      0.68       210\n",
      "           7       0.78      0.91      0.84       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.79      0.78      0.78      1470\n",
      "weighted avg       0.79      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7380952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   2   0   0  55  16   3]\n",
      " [  0 157  10  10  18  13   2]\n",
      " [  2   3 187  10   4   3   1]\n",
      " [  3   4  15 143  26  12   7]\n",
      " [ 12  11   2   8 161   6  10]\n",
      " [  7   6  12  15   5 112  53]\n",
      " [  0   0   0   0   1  18 191]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.64      0.73       210\n",
      "           2       0.86      0.75      0.80       210\n",
      "           3       0.83      0.89      0.86       210\n",
      "           4       0.77      0.68      0.72       210\n",
      "           5       0.60      0.77      0.67       210\n",
      "           6       0.62      0.53      0.57       210\n",
      "           7       0.72      0.91      0.80       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.75      0.74      0.74      1470\n",
      "weighted avg       0.75      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.24421768707482994\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3   0   0   0 207]\n",
      " [  0   0  35   0   0   0 175]\n",
      " [  0   0 152   0   0   0  58]\n",
      " [  0   0  38   0   0   0 172]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0  19   0   0   0 191]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.59      0.72      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.99      0.29       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.11      0.24      0.13      1470\n",
      "weighted avg       0.11      0.24      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[188   2   1   0   0   0  19]\n",
      " [157  27   8   0   0   0  18]\n",
      " [ 52  17 135   0   0   0   6]\n",
      " [157  23  15   0   0   0  15]\n",
      " [195   5   1   0   0   0   9]\n",
      " [ 92  11   8   0   0   0  99]\n",
      " [ 55   2   1   0   0   0 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.90      0.34       210\n",
      "           2       0.31      0.13      0.18       210\n",
      "           3       0.80      0.64      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.48      0.72      0.58       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.26      0.34      0.26      1470\n",
      "weighted avg       0.26      0.34      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   0   1   2 121  13   6]\n",
      " [  7  25   5   2 150  19   2]\n",
      " [  7   2 126  15  45  14   1]\n",
      " [ 11   3  12  20 146  12   6]\n",
      " [ 11   1   1   4 184   3   6]\n",
      " [ 10   3   1   8  82  65  41]\n",
      " [  0   2   0   0  55  43 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.32      0.41       210\n",
      "           2       0.69      0.12      0.20       210\n",
      "           3       0.86      0.60      0.71       210\n",
      "           4       0.39      0.10      0.15       210\n",
      "           5       0.23      0.88      0.37       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.64      0.52      0.58       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.54      0.41      0.40      1470\n",
      "weighted avg       0.54      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.46598639455782315\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 64  20   3   0 102  17   4]\n",
      " [  0 127   8   1  52  20   2]\n",
      " [  4  28 148   1  19   9   1]\n",
      " [  7  30  27   8 119  14   5]\n",
      " [  7  26   4   1 161   5   6]\n",
      " [  5  34   9   2  56  72  32]\n",
      " [  0  12   0   1  48  44 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.30      0.43       210\n",
      "           2       0.46      0.60      0.52       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.57      0.04      0.07       210\n",
      "           5       0.29      0.77      0.42       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.68      0.50      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.55      0.47      0.44      1470\n",
      "weighted avg       0.55      0.47      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.47959183673469385\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57   5   2  57  71  11   7]\n",
      " [  0 103   5  61  26  14   1]\n",
      " [  1   7 145  36  13   6   2]\n",
      " [  1   4  17 124  44  14   6]\n",
      " [  3  12   2  78 105   5   5]\n",
      " [  3  11   5  79   9  58  45]\n",
      " [  0   3   0  53   5  36 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.27      0.41       210\n",
      "           2       0.71      0.49      0.58       210\n",
      "           3       0.82      0.69      0.75       210\n",
      "           4       0.25      0.59      0.36       210\n",
      "           5       0.38      0.50      0.43       210\n",
      "           6       0.40      0.28      0.33       210\n",
      "           7       0.63      0.54      0.58       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.58      0.48      0.49      1470\n",
      "weighted avg       0.58      0.48      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83   3   1  64  40  14   5]\n",
      " [  6 102   4  56  25  12   5]\n",
      " [  5   5 158  26  10   4   2]\n",
      " [  9   3  12 134  32  15   5]\n",
      " [ 27  13   0  80  78   6   6]\n",
      " [  7   9   3  76   5  69  41]\n",
      " [  0   3   0  51   5  42 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.40      0.48       210\n",
      "           2       0.74      0.49      0.59       210\n",
      "           3       0.89      0.75      0.81       210\n",
      "           4       0.28      0.64      0.38       210\n",
      "           5       0.40      0.37      0.39       210\n",
      "           6       0.43      0.33      0.37       210\n",
      "           7       0.63      0.52      0.57       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.57      0.50      0.51      1470\n",
      "weighted avg       0.57      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   2   1  52  34   8  16]\n",
      " [  8  98   6  68  14  10   6]\n",
      " [  2   5 158  30   8   4   3]\n",
      " [ 12   4   7 129  30  10  18]\n",
      " [ 33   8   1  78  63   5  22]\n",
      " [ 10  11   3  70   7  53  56]\n",
      " [  0   1   0  27   5  41 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.46      0.52       210\n",
      "           2       0.76      0.47      0.58       210\n",
      "           3       0.90      0.75      0.82       210\n",
      "           4       0.28      0.61      0.39       210\n",
      "           5       0.39      0.30      0.34       210\n",
      "           6       0.40      0.25      0.31       210\n",
      "           7       0.53      0.65      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.51      1470\n",
      "weighted avg       0.55      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107   8   1  35  34  19   6]\n",
      " [  8 114   6  56  12   8   6]\n",
      " [  3   9 157  30   5   5   1]\n",
      " [ 13   7  11 120  27  25   7]\n",
      " [ 42  10   1  70  63  16   8]\n",
      " [ 15  23   7  50  10  60  45]\n",
      " [ 10  11   0  16   4  52 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.52       210\n",
      "           2       0.63      0.54      0.58       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.32      0.57      0.41       210\n",
      "           5       0.41      0.30      0.35       210\n",
      "           6       0.32      0.29      0.30       210\n",
      "           7       0.62      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.51      1470\n",
      "weighted avg       0.53      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   5   2  24  51  26   5]\n",
      " [  8 112   5  43  22  14   6]\n",
      " [  1   4 160  24   9   8   4]\n",
      " [ 11   8   8 113  37  25   8]\n",
      " [ 26  11   0  53  91  19  10]\n",
      " [ 17  15   6  44   8  78  42]\n",
      " [  6   4   1  17   8  43 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.46      0.52       210\n",
      "           2       0.70      0.53      0.61       210\n",
      "           3       0.88      0.76      0.82       210\n",
      "           4       0.36      0.54      0.43       210\n",
      "           5       0.40      0.43      0.42       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.64      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.56      0.53      0.54      1470\n",
      "weighted avg       0.56      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  12   3  19  47  21   4]\n",
      " [  6 132   5  20  25  17   5]\n",
      " [  4  12 162  13   9   9   1]\n",
      " [ 16  28  10  93  32  23   8]\n",
      " [ 27  23   1  45  89  17   8]\n",
      " [ 23  20  13  33   8  65  48]\n",
      " [  9   7   4  14  19  37 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.50      0.52       210\n",
      "           2       0.56      0.63      0.59       210\n",
      "           3       0.82      0.77      0.79       210\n",
      "           4       0.39      0.44      0.42       210\n",
      "           5       0.39      0.42      0.41       210\n",
      "           6       0.34      0.31      0.33       210\n",
      "           7       0.62      0.57      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   7   1  24  41  23   5]\n",
      " [  8 125   5  26  23  16   7]\n",
      " [  2  10 163  23   7   4   1]\n",
      " [ 22  14   8 105  31  22   8]\n",
      " [ 34  24   1  42  86  14   9]\n",
      " [ 21  15   6  35  18  67  48]\n",
      " [  7   7   3  12  16  43 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53       210\n",
      "           2       0.62      0.60      0.61       210\n",
      "           3       0.87      0.78      0.82       210\n",
      "           4       0.39      0.50      0.44       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.35      0.32      0.34       210\n",
      "           7       0.61      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106   6   2  19  54  17   6]\n",
      " [ 12 124   6  14  33  16   5]\n",
      " [  4   6 167  11  14   5   3]\n",
      " [ 13  19   9  74  61  26   8]\n",
      " [ 29  18   4  32 101  13  13]\n",
      " [ 18  16  12  26  29  59  50]\n",
      " [  8   4   2  11  14  42 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53       210\n",
      "           2       0.64      0.59      0.62       210\n",
      "           3       0.83      0.80      0.81       210\n",
      "           4       0.40      0.35      0.37       210\n",
      "           5       0.33      0.48      0.39       210\n",
      "           6       0.33      0.28      0.30       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  10   6  10  48  17   6]\n",
      " [ 14 127  15  12  22  14   6]\n",
      " [  2   9 175   8   9   5   2]\n",
      " [ 19  17  12  68  55  27  12]\n",
      " [ 39  18   7  28  95  14   9]\n",
      " [ 24  17   9  23  24  66  47]\n",
      " [  8   4   4   7  18  51 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53       210\n",
      "           2       0.63      0.60      0.62       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.44      0.32      0.37       210\n",
      "           5       0.35      0.45      0.40       210\n",
      "           6       0.34      0.31      0.33       210\n",
      "           7       0.59      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   8   3  19  42  23   4]\n",
      " [  7 128  12  16  25  14   8]\n",
      " [  2   6 172  13   7   8   2]\n",
      " [ 23  17   8  86  41  27   8]\n",
      " [ 37  18   4  25 101  14  11]\n",
      " [ 25  15   9  35  14  66  46]\n",
      " [ 11   6   2  14  16  40 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.53      0.52       210\n",
      "           2       0.65      0.61      0.63       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.41      0.48      0.44       210\n",
      "           6       0.34      0.31      0.33       210\n",
      "           7       0.60      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107   6   2  17  47  24   7]\n",
      " [  8 131  11  15  26  13   6]\n",
      " [  0   6 171  16   7   7   3]\n",
      " [ 21  18  10  79  37  35  10]\n",
      " [ 33  22   6  32  91  15  11]\n",
      " [ 19  20   8  29  15  71  48]\n",
      " [  7   8   4  14  19  33 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.51      0.53       210\n",
      "           2       0.62      0.62      0.62       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.39      0.38      0.38       210\n",
      "           5       0.38      0.43      0.40       210\n",
      "           6       0.36      0.34      0.35       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   7   5  14  43  25   5]\n",
      " [ 10 128  11  13  24  17   7]\n",
      " [  2   6 173  13   8   7   1]\n",
      " [ 20  22  11  79  42  25  11]\n",
      " [ 34  19   5  34  84  19  15]\n",
      " [ 20  15  11  23  18  79  44]\n",
      " [ 12   7   0  10  15  42 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       210\n",
      "           2       0.63      0.61      0.62       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.42      0.38      0.40       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.37      0.38      0.37       210\n",
      "           7       0.60      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   9   5  20  41  18   7]\n",
      " [ 10 127  10  15  24  14  10]\n",
      " [  1   7 175  12   8   4   3]\n",
      " [ 22  18  11  77  43  30   9]\n",
      " [ 35  23   8  32  87  14  11]\n",
      " [ 21  23  10  27  15  59  55]\n",
      " [  5  11   2  13  20  39 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.79      0.83      0.81       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.37      0.41      0.39       210\n",
      "           6       0.33      0.28      0.30       210\n",
      "           7       0.56      0.57      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  12   3  12  49  23   7]\n",
      " [ 10 129   8  15  22  16  10]\n",
      " [  2   7 175  14   6   4   2]\n",
      " [ 25  17  10  73  45  29  11]\n",
      " [ 37  20   7  28  89  17  12]\n",
      " [ 28  20   7  32  11  69  43]\n",
      " [  7   5   3  13  21  39 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.61      0.61      0.61       210\n",
      "           3       0.82      0.83      0.83       210\n",
      "           4       0.39      0.35      0.37       210\n",
      "           5       0.37      0.42      0.39       210\n",
      "           6       0.35      0.33      0.34       210\n",
      "           7       0.59      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   8   4  18  45  22  11]\n",
      " [ 14 130  10  17  22  11   6]\n",
      " [  1   8 178  12   5   4   2]\n",
      " [ 25  22  11  82  35  25  10]\n",
      " [ 35  25   9  30  81  16  14]\n",
      " [ 23  22   9  33  17  61  45]\n",
      " [  9   5   1   9  15  51 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.49      0.49       210\n",
      "           2       0.59      0.62      0.60       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.37      0.39      0.38       210\n",
      "           6       0.32      0.29      0.31       210\n",
      "           7       0.58      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   8   5  19  43  21  12]\n",
      " [ 13 130   9  14  22  12  10]\n",
      " [  1   8 177  13   7   3   1]\n",
      " [ 24  20   8  82  35  31  10]\n",
      " [ 34  26   9  30  82  16  13]\n",
      " [ 23  20  10  28  15  69  45]\n",
      " [  9   5   1  12  20  47 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.49      0.49       210\n",
      "           2       0.60      0.62      0.61       210\n",
      "           3       0.81      0.84      0.83       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.37      0.39      0.38       210\n",
      "           6       0.35      0.33      0.34       210\n",
      "           7       0.56      0.55      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.51      0.52      0.51      1470\n",
      "weighted avg       0.51      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 12   1  33   0 142   0  22]\n",
      " [  1  24  55   0 106   0  24]\n",
      " [  2   9 166   3  27   0   3]\n",
      " [  0   7  32   2 128   0  41]\n",
      " [  1   7   2   0 176   0  24]\n",
      " [  2   1  27   0  56   0 124]\n",
      " [  0   0   4   0  29   0 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.06      0.11       210\n",
      "           2       0.49      0.11      0.19       210\n",
      "           3       0.52      0.79      0.63       210\n",
      "           4       0.40      0.01      0.02       210\n",
      "           5       0.27      0.84      0.40       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.84      0.57       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.40      0.38      0.27      1470\n",
      "weighted avg       0.40      0.38      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 66   5   3   0  95   0  41]\n",
      " [  2  98  18   0  70   0  22]\n",
      " [  0  15 163   0  29   0   3]\n",
      " [  5  16  28  15  86   0  60]\n",
      " [  2  18   0   0 145   0  45]\n",
      " [  4   3  24   4  22   3 150]\n",
      " [  1   3   2   0   2   0 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.31      0.46       210\n",
      "           2       0.62      0.47      0.53       210\n",
      "           3       0.68      0.78      0.73       210\n",
      "           4       0.79      0.07      0.13       210\n",
      "           5       0.32      0.69      0.44       210\n",
      "           6       1.00      0.01      0.03       210\n",
      "           7       0.39      0.96      0.55       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.66      0.47      0.41      1470\n",
      "weighted avg       0.66      0.47      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98   8   2   0  70   2  30]\n",
      " [  0 142  12   2  39   0  15]\n",
      " [  2  23 160   4  20   1   0]\n",
      " [  6  20  24  43  73   4  40]\n",
      " [ 11  19   0   3 146   1  30]\n",
      " [  5  10  20   8  19  14 134]\n",
      " [  0   5   0   0   7   1 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.47      0.59       210\n",
      "           2       0.63      0.68      0.65       210\n",
      "           3       0.73      0.76      0.75       210\n",
      "           4       0.72      0.20      0.32       210\n",
      "           5       0.39      0.70      0.50       210\n",
      "           6       0.61      0.07      0.12       210\n",
      "           7       0.44      0.94      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.50      1470\n",
      "weighted avg       0.62      0.54      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   7   1   2  70   6  23]\n",
      " [  0 145  10   4  34   7  10]\n",
      " [  2  15 162   9  19   2   1]\n",
      " [  7  17  22  71  54  11  28]\n",
      " [ 11  22   0   3 142   2  30]\n",
      " [  4   6  15  12  17  35 121]\n",
      " [  0   1   0   3   7   6 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.48      0.60       210\n",
      "           2       0.68      0.69      0.69       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.68      0.34      0.45       210\n",
      "           5       0.41      0.68      0.51       210\n",
      "           6       0.51      0.17      0.25       210\n",
      "           7       0.48      0.92      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.56      1470\n",
      "weighted avg       0.62      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   7   1   4  58  12  18]\n",
      " [  1 147   8  12  26  12   4]\n",
      " [  1   9 172  11  13   3   1]\n",
      " [  4   9  12 104  51  12  18]\n",
      " [ 11  14   0  10 149   5  21]\n",
      " [  5   8  14  16  12  50 105]\n",
      " [  0   1   0   1   6  10 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.52      0.64       210\n",
      "           2       0.75      0.70      0.73       210\n",
      "           3       0.83      0.82      0.82       210\n",
      "           4       0.66      0.50      0.57       210\n",
      "           5       0.47      0.71      0.57       210\n",
      "           6       0.48      0.24      0.32       210\n",
      "           7       0.53      0.91      0.67       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.62      1470\n",
      "weighted avg       0.65      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   5   1   4  60  18  15]\n",
      " [  0 147   9   9  27  13   5]\n",
      " [  1  10 174  13   8   3   1]\n",
      " [  3   3  10 116  48  17  13]\n",
      " [  8  14   1  10 152   8  17]\n",
      " [  2   6  13  19  11  70  89]\n",
      " [  0   1   0   3   5   7 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.51      0.65       210\n",
      "           2       0.79      0.70      0.74       210\n",
      "           3       0.84      0.83      0.83       210\n",
      "           4       0.67      0.55      0.60       210\n",
      "           5       0.49      0.72      0.58       210\n",
      "           6       0.51      0.33      0.40       210\n",
      "           7       0.58      0.92      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   5   1   5  58  18  13]\n",
      " [  0 148   7  13  26  12   4]\n",
      " [  2   6 176  12   8   6   0]\n",
      " [  3   5   9 129  35  16  13]\n",
      " [ 12  14   0  16 148   4  16]\n",
      " [  2   7  10  14  10  83  84]\n",
      " [  0   0   0   3   5   9 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.52      0.65       210\n",
      "           2       0.80      0.70      0.75       210\n",
      "           3       0.87      0.84      0.85       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.51      0.70      0.59       210\n",
      "           6       0.56      0.40      0.46       210\n",
      "           7       0.60      0.92      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   5   1   6  54  19   9]\n",
      " [  0 152   8   8  27  12   3]\n",
      " [  1   4 178   8  11   8   0]\n",
      " [  5   4   6 131  40  15   9]\n",
      " [  6  14   0  15 153   7  15]\n",
      " [  2   4   9  12  12  97  74]\n",
      " [  0   0   0   3   4  13 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.55      0.68       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.88      0.85      0.86       210\n",
      "           4       0.72      0.62      0.67       210\n",
      "           5       0.51      0.73      0.60       210\n",
      "           6       0.57      0.46      0.51       210\n",
      "           7       0.63      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.69      1470\n",
      "weighted avg       0.72      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   3   1   6  55  18   6]\n",
      " [  0 153   7  11  26  10   3]\n",
      " [  1   3 179  14   8   5   0]\n",
      " [  5   3   7 136  32  17  10]\n",
      " [  6  15   0  12 158   5  14]\n",
      " [  1   8   5  19   9  99  69]\n",
      " [  0   1   0   2   3  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.58      0.70       210\n",
      "           2       0.82      0.73      0.77       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.68      0.65      0.66       210\n",
      "           5       0.54      0.75      0.63       210\n",
      "           6       0.58      0.47      0.52       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   3   0   6  54  19   7]\n",
      " [  0 156   7  11  19  14   3]\n",
      " [  2   3 177  13  10   5   0]\n",
      " [  6   5   6 139  29  16   9]\n",
      " [  8  13   1  16 150  10  12]\n",
      " [  4   4   9  16  10 102  65]\n",
      " [  0   0   0   3   4  10 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.85      0.74      0.79       210\n",
      "           3       0.89      0.84      0.86       210\n",
      "           4       0.68      0.66      0.67       210\n",
      "           5       0.54      0.71      0.62       210\n",
      "           6       0.58      0.49      0.53       210\n",
      "           7       0.67      0.92      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   2   0   8  48  23   4]\n",
      " [  0 146  10  10  29  14   1]\n",
      " [  1   2 184   8   9   6   0]\n",
      " [  3   5   6 143  31  16   6]\n",
      " [ 11  14   1  13 150   7  14]\n",
      " [  3   6   6  13  10 109  63]\n",
      " [  0   0   0   3   5  18 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.60      0.71       210\n",
      "           2       0.83      0.70      0.76       210\n",
      "           3       0.89      0.88      0.88       210\n",
      "           4       0.72      0.68      0.70       210\n",
      "           5       0.53      0.71      0.61       210\n",
      "           6       0.56      0.52      0.54       210\n",
      "           7       0.68      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   5   0  11  45  17   8]\n",
      " [  1 157   9  12  17  11   3]\n",
      " [  2   4 178   6  11   8   1]\n",
      " [  7   3   5 147  28  12   8]\n",
      " [ 10  14   1  15 150   7  13]\n",
      " [  0   7   8  19   9 107  60]\n",
      " [  0   0   0   2   3  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.83      0.75      0.79       210\n",
      "           3       0.89      0.85      0.87       210\n",
      "           4       0.69      0.70      0.70       210\n",
      "           5       0.57      0.71      0.63       210\n",
      "           6       0.57      0.51      0.54       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   4   0   6  49  18   6]\n",
      " [  0 151   5  12  26  15   1]\n",
      " [  2   2 180  12   7   7   0]\n",
      " [  5   2   6 142  33  14   8]\n",
      " [  9  16   0  19 148   5  13]\n",
      " [  1   3   7  17   7 116  59]\n",
      " [  0   0   0   1   6  19 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.60      0.72       210\n",
      "           2       0.85      0.72      0.78       210\n",
      "           3       0.91      0.86      0.88       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.54      0.70      0.61       210\n",
      "           6       0.60      0.55      0.57       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   3   0   6  49  21   7]\n",
      " [  0 155   8  12  20  13   2]\n",
      " [  2   4 180   7   9   8   0]\n",
      " [  2   5   8 139  30  17   9]\n",
      " [ 11  18   0  15 146   7  13]\n",
      " [  5   4   6  14   6 109  66]\n",
      " [  0   2   0   3   4  18 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.81      0.74      0.77       210\n",
      "           3       0.89      0.86      0.87       210\n",
      "           4       0.71      0.66      0.68       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.56      0.52      0.54       210\n",
      "           7       0.65      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   4   0   7  47  21   5]\n",
      " [  1 150   9  14  22  13   1]\n",
      " [  2   2 183  10   7   6   0]\n",
      " [  7   4   5 140  28  19   7]\n",
      " [ 16  14   0  15 145   6  14]\n",
      " [  4   3   6  15  11 116  55]\n",
      " [  0   0   0   3   2  15 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.85      0.71      0.78       210\n",
      "           3       0.90      0.87      0.89       210\n",
      "           4       0.69      0.67      0.68       210\n",
      "           5       0.55      0.69      0.61       210\n",
      "           6       0.59      0.55      0.57       210\n",
      "           7       0.70      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   3   0   5  49  24   2]\n",
      " [  0 159   6  14  17  10   4]\n",
      " [  1   3 183  11   6   5   1]\n",
      " [ 11   1   5 145  26  16   6]\n",
      " [ 16  13   1  19 142   6  13]\n",
      " [  1   5   8  15   8 115  58]\n",
      " [  0   0   0   1   4  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.86      0.76      0.81       210\n",
      "           3       0.90      0.87      0.89       210\n",
      "           4       0.69      0.69      0.69       210\n",
      "           5       0.56      0.68      0.61       210\n",
      "           6       0.59      0.55      0.57       210\n",
      "           7       0.69      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   1   0   7  48  20   4]\n",
      " [  0 152   9   9  26  13   1]\n",
      " [  2   2 182   8   7   7   2]\n",
      " [  3   6   8 142  26  15  10]\n",
      " [ 12  15   0  21 143   7  12]\n",
      " [  2   4   8  26   6 107  57]\n",
      " [  0   2   0   2   2  22 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.62      0.72       210\n",
      "           2       0.84      0.72      0.78       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.66      0.68      0.67       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.56      0.51      0.53       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.717687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   2   1   4  48  19   6]\n",
      " [  0 153   9  11  22  13   2]\n",
      " [  2   2 186   9   5   6   0]\n",
      " [  2   1   7 142  33  18   7]\n",
      " [ 14  15   0  23 142   5  11]\n",
      " [  5   5   8  13   8 118  53]\n",
      " [  0   1   0   3   3  19 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.62      0.72       210\n",
      "           2       0.85      0.73      0.79       210\n",
      "           3       0.88      0.89      0.88       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.54      0.68      0.60       210\n",
      "           6       0.60      0.56      0.58       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   2   0   4  42  20   5]\n",
      " [  0 153   9  16  18  12   2]\n",
      " [  2   3 184   7  10   4   0]\n",
      " [  6   3   8 138  31  16   8]\n",
      " [ 14  19   1  21 137   5  13]\n",
      " [  5   3   6  14  10 112  60]\n",
      " [  0   1   0   2   3  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.65      0.73       210\n",
      "           2       0.83      0.73      0.78       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.68      0.66      0.67       210\n",
      "           5       0.55      0.65      0.59       210\n",
      "           6       0.58      0.53      0.56       210\n",
      "           7       0.67      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   3   0   4  49  18   6]\n",
      " [  0 153  10  16  18  11   2]\n",
      " [  2   4 187   5   8   4   0]\n",
      " [  6   2   7 136  31  22   6]\n",
      " [ 15  16   1  20 140   4  14]\n",
      " [  7   5   6  17   7 112  56]\n",
      " [  1   1   0   1   3  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.62      0.70       210\n",
      "           2       0.83      0.73      0.78       210\n",
      "           3       0.89      0.89      0.89       210\n",
      "           4       0.68      0.65      0.67       210\n",
      "           5       0.55      0.67      0.60       210\n",
      "           6       0.57      0.53      0.55       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 94   4  10   1  55  28  18]\n",
      " [  0 119  26   6  41  13   5]\n",
      " [ 13   9 165   8   9   5   1]\n",
      " [  6   8  26  61  52  29  28]\n",
      " [ 18  19   0   5 125   8  35]\n",
      " [  4   9  23  12  15  68  79]\n",
      " [  0   4   1   4   7  22 172]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.45      0.54       210\n",
      "           2       0.69      0.57      0.62       210\n",
      "           3       0.66      0.79      0.72       210\n",
      "           4       0.63      0.29      0.40       210\n",
      "           5       0.41      0.60      0.49       210\n",
      "           6       0.39      0.32      0.36       210\n",
      "           7       0.51      0.82      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.54      1470\n",
      "weighted avg       0.57      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_vbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[148   2   0   7  32  13   8]\n",
      " [  1 160  15   9  15   9   1]\n",
      " [  2   2 188   9   3   6   0]\n",
      " [  3   5  10 152  13  16  11]\n",
      " [ 21  18   0  20 131   9  11]\n",
      " [ 10  13  10  17   4 104  52]\n",
      " [  1   1   0   1   4  26 177]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.70      0.75       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.84      0.90      0.87       210\n",
      "           4       0.71      0.72      0.72       210\n",
      "           5       0.65      0.62      0.64       210\n",
      "           6       0.57      0.50      0.53       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   7   2   7  38   7   3]\n",
      " [  6 171   8   8  13   2   2]\n",
      " [ 12   3 190   4   0   1   0]\n",
      " [ 21  18  11 135  18   3   4]\n",
      " [ 38  38   4  17 104   1   8]\n",
      " [ 40  26  12  16   9  61  46]\n",
      " [ 11   9   3  16   2  16 153]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.70      0.60       210\n",
      "           2       0.63      0.81      0.71       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.57      0.50      0.53       210\n",
      "           6       0.67      0.29      0.41       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   7   1   7  34  10   4]\n",
      " [  3 177   8   5  14   1   2]\n",
      " [ 11   2 192   3   1   1   0]\n",
      " [ 17  15  17 134  16   7   4]\n",
      " [ 37  39   7  20  99   0   8]\n",
      " [ 31  25  11  17   8  71  47]\n",
      " [  9  11   1   7   2  26 154]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.63       210\n",
      "           2       0.64      0.84      0.73       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.57      0.47      0.52       210\n",
      "           6       0.61      0.34      0.44       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.672108843537415\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   5   3   6  42   9   5]\n",
      " [  2 176   9   4  17   1   1]\n",
      " [  8   3 187   6   2   4   0]\n",
      " [ 14  13  14 143  15   3   8]\n",
      " [ 26  35   7  22 112   0   8]\n",
      " [ 28  22  13  17  13  71  46]\n",
      " [  8  10   2   4   4  23 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.67      0.64       210\n",
      "           2       0.67      0.84      0.74       210\n",
      "           3       0.80      0.89      0.84       210\n",
      "           4       0.71      0.68      0.69       210\n",
      "           5       0.55      0.53      0.54       210\n",
      "           6       0.64      0.34      0.44       210\n",
      "           7       0.70      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   5   3   5  39   7   4]\n",
      " [  2 180  11   4  11   1   1]\n",
      " [  9   4 187   4   2   4   0]\n",
      " [ 15  14  18 136  15   5   7]\n",
      " [ 35  37   8  20 100   0  10]\n",
      " [ 27  19  13  20  10  74  47]\n",
      " [  5  10   2   5   6  21 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.70      0.65       210\n",
      "           2       0.67      0.86      0.75       210\n",
      "           3       0.77      0.89      0.83       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.55      0.48      0.51       210\n",
      "           6       0.66      0.35      0.46       210\n",
      "           7       0.70      0.77      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   4   3   4  43   6   8]\n",
      " [  1 173  12   5  17   1   1]\n",
      " [  7   4 187   6   2   4   0]\n",
      " [ 13  19  18 135  17   1   7]\n",
      " [ 30  30   8  22 111   1   8]\n",
      " [ 28  20  15  20   8  70  49]\n",
      " [  2   9   2   5   5  22 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.68      0.66       210\n",
      "           2       0.67      0.82      0.74       210\n",
      "           3       0.76      0.89      0.82       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.55      0.53      0.54       210\n",
      "           6       0.67      0.33      0.44       210\n",
      "           7       0.69      0.79      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   5   3   4  42   8   7]\n",
      " [  0 179  10   5  14   1   1]\n",
      " [  7   4 187   7   1   4   0]\n",
      " [ 15  14  23 128  18   4   8]\n",
      " [ 35  34   8  17 105   1  10]\n",
      " [ 23  21  18  16   6  67  59]\n",
      " [  4   9   2   4   8  18 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.67      0.65       210\n",
      "           2       0.67      0.85      0.75       210\n",
      "           3       0.75      0.89      0.81       210\n",
      "           4       0.71      0.61      0.65       210\n",
      "           5       0.54      0.50      0.52       210\n",
      "           6       0.65      0.32      0.43       210\n",
      "           7       0.66      0.79      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 90   2  12   9  45  22  30]\n",
      " [  0 131  10  13  29  21   6]\n",
      " [  7   3 161  12   8  17   2]\n",
      " [  3   5  14 100  21  26  41]\n",
      " [ 15  15   1  28 107   9  35]\n",
      " [  4   9  10  21   5  78  83]\n",
      " [  0   2   0   3   2  38 165]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.43      0.55       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.54      0.48      0.51       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.46      0.79      0.58       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 83   2  12  10  47  22  34]\n",
      " [  1 120  13  12  34  23   7]\n",
      " [ 10   5 161  12   4  13   5]\n",
      " [  6   6  17  92  22  24  43]\n",
      " [ 17  15   0  23 110  10  35]\n",
      " [  5   9  14  20   9  70  83]\n",
      " [  0   2   0   3   2  38 165]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.40      0.50       210\n",
      "           2       0.75      0.57      0.65       210\n",
      "           3       0.74      0.77      0.75       210\n",
      "           4       0.53      0.44      0.48       210\n",
      "           5       0.48      0.52      0.50       210\n",
      "           6       0.35      0.33      0.34       210\n",
      "           7       0.44      0.79      0.57       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.54      1470\n",
      "weighted avg       0.57      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   1   0   8  30  17   6]\n",
      " [  0 162  11  10  14  12   1]\n",
      " [  1   2 191   7   1   8   0]\n",
      " [  3   4   9 152  14  19   9]\n",
      " [ 24  19   1  21 129   7   9]\n",
      " [  9  12  12  15   2 111  49]\n",
      " [  2   0   0   1   6  25 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.70      0.75       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.85      0.91      0.88       210\n",
      "           4       0.71      0.72      0.72       210\n",
      "           5       0.66      0.61      0.64       210\n",
      "           6       0.56      0.53      0.54       210\n",
      "           7       0.70      0.84      0.77       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7612244897959184\n",
      "Confusion Matrix of SVM is:\n",
      " [[149   2   0   7  31  19   2]\n",
      " [  0 173   7  13  11   5   1]\n",
      " [  2   0 194   7   2   5   0]\n",
      " [  2   3   7 163  12  16   7]\n",
      " [ 27  14   0  17 137   7   8]\n",
      " [  5   9   4  15   2 135  40]\n",
      " [  1   0   0   0   5  36 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.71      0.75       210\n",
      "           2       0.86      0.82      0.84       210\n",
      "           3       0.92      0.92      0.92       210\n",
      "           4       0.73      0.78      0.75       210\n",
      "           5       0.69      0.65      0.67       210\n",
      "           6       0.61      0.64      0.62       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7523809523809524\n",
      "Confusion Matrix of SVM is:\n",
      " [[149   2   0   8  31  17   3]\n",
      " [  0 173   8  10  12   6   1]\n",
      " [  2   1 192   8   1   6   0]\n",
      " [  2   3   7 161  13  16   8]\n",
      " [ 27  16   1  19 132   6   9]\n",
      " [  5  11   5  16   3 128  42]\n",
      " [  1   0   0   0   5  33 171]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.71      0.75       210\n",
      "           2       0.84      0.82      0.83       210\n",
      "           3       0.90      0.91      0.91       210\n",
      "           4       0.73      0.77      0.75       210\n",
      "           5       0.67      0.63      0.65       210\n",
      "           6       0.60      0.61      0.61       210\n",
      "           7       0.73      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   1   0   6  27  18   7]\n",
      " [  0 151  20  11  14  13   1]\n",
      " [  1   4 187   8   1   9   0]\n",
      " [  4  10  13 143  10  22   8]\n",
      " [ 25  18   1  25 124   8   9]\n",
      " [ 13  13   9  14   3 100  58]\n",
      " [  3   1   0   0   4  23 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.74       210\n",
      "           2       0.76      0.72      0.74       210\n",
      "           3       0.81      0.89      0.85       210\n",
      "           4       0.69      0.68      0.69       210\n",
      "           5       0.68      0.59      0.63       210\n",
      "           6       0.52      0.48      0.50       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.23537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0   0   0 200]\n",
      " [  0   0  16   0   0   0 194]\n",
      " [  0   0 143   0   0   0  67]\n",
      " [  0   0  26   0   0   0 184]\n",
      " [  0   0   4   0   0   0 206]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0   7   0   0   0 203]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.63      0.68      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.97      0.28       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.11      0.24      0.13      1470\n",
      "weighted avg       0.11      0.24      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0  87   0 113]\n",
      " [  0   0  16   0 153   0  41]\n",
      " [  0   0 143   0  34   0  33]\n",
      " [  0   0  26   0 100   0  84]\n",
      " [  0   0   4   0 161   0  45]\n",
      " [  0   0  20   0  48   0 142]\n",
      " [  0   0   7   0  36   0 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.63      0.68      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.26      0.77      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.27      0.80      0.40       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.17      0.32      0.21      1470\n",
      "weighted avg       0.17      0.32      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.408843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 53   8   6   0  79   0  64]\n",
      " [ 14 108  15   0  45   0  28]\n",
      " [ 22  20 141   0  14   0  13]\n",
      " [  3  29  25   0  71   0  82]\n",
      " [  1  27   4   0 134   0  44]\n",
      " [ 19  10  20   0  38   0 123]\n",
      " [  3   7   6   0  29   0 165]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.25      0.33       210\n",
      "           2       0.52      0.51      0.52       210\n",
      "           3       0.65      0.67      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.33      0.64      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.79      0.45       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.32      0.41      0.34      1470\n",
      "weighted avg       0.32      0.41      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 53   3   1  50  34  60   9]\n",
      " [ 14  88   8  34  31  29   6]\n",
      " [ 20   2 140  28   6  14   0]\n",
      " [  3   5  22  64  33  77   6]\n",
      " [  1  19   4  48  94  36   8]\n",
      " [ 19   4   8  28  16 106  29]\n",
      " [  3   6   3  20  10  95  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.25      0.33       210\n",
      "           2       0.69      0.42      0.52       210\n",
      "           3       0.75      0.67      0.71       210\n",
      "           4       0.24      0.30      0.27       210\n",
      "           5       0.42      0.45      0.43       210\n",
      "           6       0.25      0.50      0.34       210\n",
      "           7       0.56      0.35      0.43       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.43      1470\n",
      "weighted avg       0.48      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.45510204081632655\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79   3   4  24  35  56   9]\n",
      " [ 10  91  15  17  44  24   9]\n",
      " [  8  19 146   9   6  21   1]\n",
      " [  3   9   6  58  35  90   9]\n",
      " [  9  16   1  34 103  36  11]\n",
      " [ 15   6  12  25  16  97  39]\n",
      " [  4   6   3  20  10  72  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.38      0.47       210\n",
      "           2       0.61      0.43      0.51       210\n",
      "           3       0.78      0.70      0.74       210\n",
      "           4       0.31      0.28      0.29       210\n",
      "           5       0.41      0.49      0.45       210\n",
      "           6       0.24      0.46      0.32       210\n",
      "           7       0.55      0.45      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.50      0.46      0.47      1470\n",
      "weighted avg       0.50      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48095238095238096\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  16   4  18  43  53   6]\n",
      " [  2 131   7  18  25  24   3]\n",
      " [  3  11 154  12  13  16   1]\n",
      " [  2  22  10  71  32  64   9]\n",
      " [  5  43   2  34  95  21  10]\n",
      " [  6  28   9  18  20  97  32]\n",
      " [  1  16   3   4  20  77  89]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.33      0.47       210\n",
      "           2       0.49      0.62      0.55       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.41      0.34      0.37       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.28      0.46      0.35       210\n",
      "           7       0.59      0.42      0.49       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.54      0.48      0.49      1470\n",
      "weighted avg       0.54      0.48      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   9   1  22  53  29  29]\n",
      " [  2 117  10  12  46   6  17]\n",
      " [  5   6 153  13  14  12   7]\n",
      " [  3   5   8  72  38  46  38]\n",
      " [  4  25   0  26 114  13  28]\n",
      " [  8  22   2  21  20  67  70]\n",
      " [  4   9   2   3  14  46 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.32      0.44       210\n",
      "           2       0.61      0.56      0.58       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.43      0.34      0.38       210\n",
      "           5       0.38      0.54      0.45       210\n",
      "           6       0.31      0.32      0.31       210\n",
      "           7       0.41      0.63      0.50       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.53      0.49      0.49      1470\n",
      "weighted avg       0.53      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95   7   0  21  49  31   7]\n",
      " [ 19 113   9  17  42   8   2]\n",
      " [  5   3 161  14   7  18   2]\n",
      " [ 25   4   7  84  33  46  11]\n",
      " [ 25  20   0  40  98  11  16]\n",
      " [ 27  14   5  23  24  71  46]\n",
      " [ 26   5   2   3  16  51 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.45      0.44       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.42      0.40      0.41       210\n",
      "           5       0.36      0.47      0.41       210\n",
      "           6       0.30      0.34      0.32       210\n",
      "           7       0.56      0.51      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.50      1470\n",
      "weighted avg       0.52      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.501360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   8   2  23  35  32   9]\n",
      " [ 21 116  11  14  34   7   7]\n",
      " [  5   9 160  12   7  15   2]\n",
      " [ 12  13   7  81  35  46  16]\n",
      " [ 29  32   2  35  88  10  14]\n",
      " [ 15  20   6  32  13  74  50]\n",
      " [ 18   7   2   9  10  47 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.48      0.49       210\n",
      "           2       0.57      0.55      0.56       210\n",
      "           3       0.84      0.76      0.80       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.32      0.35      0.34       210\n",
      "           7       0.54      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.508843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   9   0  17  31  33   8]\n",
      " [ 22 120   9  14  31   8   6]\n",
      " [  8   7 160  13   4  16   2]\n",
      " [ 12  17  11  81  30  43  16]\n",
      " [ 27  33   3  30  88  14  15]\n",
      " [ 24  13   8  22  16  77  50]\n",
      " [ 15   8   3   9  13  52 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.53      0.52       210\n",
      "           2       0.58      0.57      0.58       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.44      0.39      0.41       210\n",
      "           5       0.41      0.42      0.42       210\n",
      "           6       0.32      0.37      0.34       210\n",
      "           7       0.53      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.507482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   8   3  18  31  26   9]\n",
      " [ 17 121  10  12  36  10   4]\n",
      " [  5   6 164  10   4  17   4]\n",
      " [ 23  14  11  72  31  47  12]\n",
      " [ 26  31   6  29  92  12  14]\n",
      " [ 23  16   7  25  17  78  44]\n",
      " [ 22   7   4  11  11  51 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.55      0.52       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.41      0.34      0.37       210\n",
      "           5       0.41      0.44      0.43       210\n",
      "           6       0.32      0.37      0.35       210\n",
      "           7       0.54      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107   8   5  18  38  25   9]\n",
      " [ 14 122  11  11  37  11   4]\n",
      " [  9   6 163   9   4  15   4]\n",
      " [ 11  11   9  80  36  43  20]\n",
      " [ 31  27   4  28  93  13  14]\n",
      " [ 22  23   7  21  19  73  45]\n",
      " [ 15   8   5  12  12  47 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.51      0.51       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.45      0.38      0.41       210\n",
      "           5       0.39      0.44      0.41       210\n",
      "           6       0.32      0.35      0.33       210\n",
      "           7       0.54      0.53      0.53       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   8   3  15  36  30   9]\n",
      " [ 17 125  12  11  31   9   5]\n",
      " [  9  10 164   8   2  15   2]\n",
      " [ 11  14  11  94  27  39  14]\n",
      " [ 33  33   2  30  85  16  11]\n",
      " [ 22  21   4  30  20  67  46]\n",
      " [ 14  11   5  16   9  42 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.52      0.51       210\n",
      "           2       0.56      0.60      0.58       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.46      0.45      0.45       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.31      0.32      0.31       210\n",
      "           7       0.56      0.54      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.52      1470\n",
      "weighted avg       0.52      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  12   3  16  33  27   9]\n",
      " [ 14 124  12  11  34   8   7]\n",
      " [  7   9 166   8   2  15   3]\n",
      " [ 12  18  12  89  28  34  17]\n",
      " [ 32  30   6  31  87  12  12]\n",
      " [ 19  17   6  29  26  65  48]\n",
      " [ 13  12   3  21   7  39 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.52      0.53       210\n",
      "           2       0.56      0.59      0.57       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.40      0.41      0.41       210\n",
      "           6       0.33      0.31      0.32       210\n",
      "           7       0.55      0.55      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  10   3  16  31  32  13]\n",
      " [ 18 121  10  11  33   9   8]\n",
      " [  8   7 165   7   3  16   4]\n",
      " [ 11  13  10  90  31  36  19]\n",
      " [ 31  28   5  29  85  15  17]\n",
      " [ 26  19   4  29  15  66  51]\n",
      " [ 16  15   3  15  13  41 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.57      0.58      0.57       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.46      0.43      0.44       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.49      0.51      0.50       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  11   4  16  35  26  12]\n",
      " [ 12 123  10  11  39  12   3]\n",
      " [  5   6 168   8   5  12   6]\n",
      " [ 13  15  10  90  28  40  14]\n",
      " [ 31  31   5  27  88  14  14]\n",
      " [ 21  18  13  30  16  66  46]\n",
      " [ 12   9   5  17  18  41 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.50      0.52       210\n",
      "           2       0.58      0.59      0.58       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.45      0.43      0.44       210\n",
      "           5       0.38      0.42      0.40       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.53      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   6   2  16  39  29  10]\n",
      " [ 13 126   9  12  39   7   4]\n",
      " [  7   9 168   6   4  13   3]\n",
      " [ 12  16  12  90  24  40  16]\n",
      " [ 26  25   6  26  94  18  15]\n",
      " [ 23  21  11  30  26  58  41]\n",
      " [ 10  12   3  20  22  38 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.53       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.45      0.43      0.44       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.29      0.28      0.28       210\n",
      "           7       0.54      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   5   2  18  35  29  11]\n",
      " [ 13 127  10  10  37   7   6]\n",
      " [  9   7 167   6   5  14   2]\n",
      " [ 12  19  13  88  26  38  14]\n",
      " [ 27  27   5  25  92  19  15]\n",
      " [ 25  23   9  25  24  60  44]\n",
      " [  8  14   2  13  23  43 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53       210\n",
      "           2       0.57      0.60      0.59       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.48      0.42      0.45       210\n",
      "           5       0.38      0.44      0.41       210\n",
      "           6       0.29      0.29      0.29       210\n",
      "           7       0.54      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   6   4  17  35  25  11]\n",
      " [ 13 127  10  12  37   7   4]\n",
      " [  9   8 166   9   4  12   2]\n",
      " [ 10  18  13  94  24  37  14]\n",
      " [ 28  24   5  28  92  20  13]\n",
      " [ 24  21  12  32  20  61  40]\n",
      " [ 12  13   3  18  23  42  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.54       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.78      0.79      0.78       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.39      0.44      0.41       210\n",
      "           6       0.30      0.29      0.29       210\n",
      "           7       0.54      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   6   1  15  35  28   8]\n",
      " [ 11 125  11  12  39   6   6]\n",
      " [  7   5 166  10   5  15   2]\n",
      " [ 12  16  13  89  25  40  15]\n",
      " [ 26  25   5  28  92  20  14]\n",
      " [ 23  19  10  26  24  65  43]\n",
      " [ 13  12   4  15  23  38 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.56      0.56       210\n",
      "           2       0.60      0.60      0.60       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.46      0.42      0.44       210\n",
      "           5       0.38      0.44      0.41       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.54      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.4272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 36   1  18   0  89   1  65]\n",
      " [  7  54  46   0  82   2  19]\n",
      " [  5   0 184   0   7   0  14]\n",
      " [  4   6  36   6  89   1  68]\n",
      " [  3   2   8   2 151   0  44]\n",
      " [  7   7  29   1  42   2 122]\n",
      " [  0   1   3   0  10   1 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.17      0.26       210\n",
      "           2       0.76      0.26      0.38       210\n",
      "           3       0.57      0.88      0.69       210\n",
      "           4       0.67      0.03      0.05       210\n",
      "           5       0.32      0.72      0.44       210\n",
      "           6       0.29      0.01      0.02       210\n",
      "           7       0.37      0.93      0.53       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.51      0.43      0.34      1470\n",
      "weighted avg       0.51      0.43      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98   2   0   0  55   2  53]\n",
      " [  1 131  20   0  27   6  25]\n",
      " [  8   9 163   0  11   2  17]\n",
      " [ 22  16  23  10  62   3  74]\n",
      " [ 13  23   1   2 121   1  49]\n",
      " [ 16  15  13   3  18   9 136]\n",
      " [  0   2   1   0   3   1 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.47      0.53       210\n",
      "           2       0.66      0.62      0.64       210\n",
      "           3       0.74      0.78      0.76       210\n",
      "           4       0.67      0.05      0.09       210\n",
      "           5       0.41      0.58      0.48       210\n",
      "           6       0.38      0.04      0.08       210\n",
      "           7       0.36      0.97      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.44      1470\n",
      "weighted avg       0.55      0.50      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   2   0   2  40   3  45]\n",
      " [  4 150   3   4  24  10  15]\n",
      " [  7   7 163   7   9   6  11]\n",
      " [ 28  13  12  30  57   7  63]\n",
      " [ 31  29   0   3 108   2  37]\n",
      " [ 18  22   9   4  10  21 126]\n",
      " [  0   3   0   1   3   2 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.56      0.57       210\n",
      "           2       0.66      0.71      0.69       210\n",
      "           3       0.87      0.78      0.82       210\n",
      "           4       0.59      0.14      0.23       210\n",
      "           5       0.43      0.51      0.47       210\n",
      "           6       0.41      0.10      0.16       210\n",
      "           7       0.40      0.96      0.57       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.50      1470\n",
      "weighted avg       0.56      0.54      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   2   0   5  40  10  34]\n",
      " [  1 152   4   6  25  11  11]\n",
      " [  7   4 168  11   7  10   3]\n",
      " [ 14  11  10  75  37  10  53]\n",
      " [ 33  26   0   8 104   1  38]\n",
      " [ 16  15   9  15   9  25 121]\n",
      " [  0   3   0   1   2   3 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.57      0.59       210\n",
      "           2       0.71      0.72      0.72       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.62      0.36      0.45       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.36      0.12      0.18       210\n",
      "           7       0.44      0.96      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.55      1470\n",
      "weighted avg       0.59      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6081632653061224\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   0   0   5  35  19  28]\n",
      " [  0 148   5   6  28  17   6]\n",
      " [  3   4 169  13   8  12   1]\n",
      " [ 13   8   8 102  27  16  36]\n",
      " [ 24  22   0  17 107   9  31]\n",
      " [ 12  12   6  13  10  45 112]\n",
      " [  0   0   0   1   3   6 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.90      0.80      0.85       210\n",
      "           4       0.65      0.49      0.56       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.36      0.21      0.27       210\n",
      "           7       0.48      0.95      0.64       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   2   0   7  42  20  22]\n",
      " [  0 147   5   8  30  12   8]\n",
      " [  5   3 173  10   4  15   0]\n",
      " [  5   7   5 120  21  27  25]\n",
      " [ 22  17   0  27 106   9  29]\n",
      " [  5  10   4  18   8  74  91]\n",
      " [  0   0   0   1   2  16 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.56      0.64       210\n",
      "           2       0.79      0.70      0.74       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.50      0.50      0.50       210\n",
      "           6       0.43      0.35      0.39       210\n",
      "           7       0.52      0.91      0.66       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   2   0   5  42  18  18]\n",
      " [  0 158   5   8  24  11   4]\n",
      " [  3   2 177  11   4  13   0]\n",
      " [  6   5   4 133  16  20  26]\n",
      " [ 21  19   0  18 114  11  27]\n",
      " [ 10  12   4  15   9  74  86]\n",
      " [  0   0   0   0   4  14 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.60      0.67       210\n",
      "           2       0.80      0.75      0.77       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.70      0.63      0.67       210\n",
      "           5       0.54      0.54      0.54       210\n",
      "           6       0.46      0.35      0.40       210\n",
      "           7       0.54      0.91      0.68       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   2   0   7  43  21  18]\n",
      " [  0 148   7  11  29  11   4]\n",
      " [  3   2 177  10   4  14   0]\n",
      " [  4   4   3 145  13  17  24]\n",
      " [ 17  16   1  20 121  13  22]\n",
      " [  7   9   5  12  10  95  72]\n",
      " [  0   1   0   0   4  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.81      0.70      0.76       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.71      0.69      0.70       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.50      0.45      0.48       210\n",
      "           7       0.57      0.89      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   3   0  10  42  20  18]\n",
      " [  1 151   4  11  27  11   5]\n",
      " [  2   3 179   9   4  13   0]\n",
      " [  1   6   5 135  21  21  21]\n",
      " [ 22  16   0  18 122  12  20]\n",
      " [  4   7   3  16  13  95  72]\n",
      " [  0   1   0   1   2  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.56      0.66       210\n",
      "           2       0.81      0.72      0.76       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.53      0.58      0.55       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.57      0.88      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   1   0  10  38  21  15]\n",
      " [  0 155   6   9  26  11   3]\n",
      " [  5   1 180   7   6  11   0]\n",
      " [  6  10   4 134  18  18  20]\n",
      " [ 19  17   0  17 124  14  19]\n",
      " [  5   9   6  17   7  93  73]\n",
      " [  0   0   0   2   3  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.60      0.68       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.56      0.59      0.57       210\n",
      "           6       0.50      0.44      0.47       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   3   0  11  37  27  10]\n",
      " [  1 156   5  12  22  12   2]\n",
      " [  5   4 178   8   4  11   0]\n",
      " [  2   6   4 145  15  20  18]\n",
      " [ 21  15   0  22 123  10  19]\n",
      " [  3   9   1  13  12 111  61]\n",
      " [  0   1   0   2   4  20 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.58      0.67       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.95      0.85      0.89       210\n",
      "           4       0.68      0.69      0.69       210\n",
      "           5       0.57      0.59      0.58       210\n",
      "           6       0.53      0.53      0.53       210\n",
      "           7       0.62      0.87      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   9  40  18  16]\n",
      " [  0 155   6  12  22  13   2]\n",
      " [  4   1 180   8   5  12   0]\n",
      " [  5   7   5 138  16  19  20]\n",
      " [ 17  17   1  21 120   9  25]\n",
      " [  4  10   3  17   6 105  65]\n",
      " [  0   0   0   2   2  27 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.81      0.74      0.77       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.67      0.66      0.66       210\n",
      "           5       0.57      0.57      0.57       210\n",
      "           6       0.52      0.50      0.51       210\n",
      "           7       0.58      0.85      0.69       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   2   0  10  42  22  14]\n",
      " [  1 153   5  12  28   9   2]\n",
      " [  1   4 180  10   5  10   0]\n",
      " [  3   2   6 149  15  19  16]\n",
      " [ 21  18   0  21 119  11  20]\n",
      " [  4  14   3  13   9  92  75]\n",
      " [  0   4   0   1   2  24 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.67       210\n",
      "           2       0.78      0.73      0.75       210\n",
      "           3       0.93      0.86      0.89       210\n",
      "           4       0.69      0.71      0.70       210\n",
      "           5       0.54      0.57      0.55       210\n",
      "           6       0.49      0.44      0.46       210\n",
      "           7       0.58      0.85      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   2   0   6  41  26  11]\n",
      " [  0 150   6  14  26  12   2]\n",
      " [  3   4 180   8   5  10   0]\n",
      " [  4   3   5 141  16  25  16]\n",
      " [ 16  15   0  19 126  12  22]\n",
      " [  7   7   4  18   7 103  64]\n",
      " [  0   1   0   2   2  24 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.59      0.68       210\n",
      "           2       0.82      0.71      0.77       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.68      0.67      0.67       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.61      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   2   0  11  39  26   9]\n",
      " [  0 161   5  10  21  10   3]\n",
      " [  4   4 180   9   4   9   0]\n",
      " [  2   5   5 148  17  17  16]\n",
      " [ 20  13   0  30 121   8  18]\n",
      " [  7   6   2  19   9 103  64]\n",
      " [  0   2   0   1   2  30 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.59      0.67       210\n",
      "           2       0.83      0.77      0.80       210\n",
      "           3       0.94      0.86      0.90       210\n",
      "           4       0.65      0.70      0.68       210\n",
      "           5       0.57      0.58      0.57       210\n",
      "           6       0.51      0.49      0.50       210\n",
      "           7       0.61      0.83      0.71       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   2   0   8  39  30   8]\n",
      " [  0 160   6  12  24   6   2]\n",
      " [  4   3 181  10   2   9   1]\n",
      " [  5   6   3 141  21  19  15]\n",
      " [ 19  18   0  15 129  13  16]\n",
      " [  8   8   2  20  10 103  59]\n",
      " [  0   1   0   2   4  31 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.59      0.67       210\n",
      "           2       0.81      0.76      0.78       210\n",
      "           3       0.94      0.86      0.90       210\n",
      "           4       0.68      0.67      0.67       210\n",
      "           5       0.56      0.61      0.59       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.63      0.82      0.71       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   2   0   6  42  22  11]\n",
      " [  0 159   6  11  21  11   2]\n",
      " [  3   4 176   9   4  14   0]\n",
      " [  4   4   5 151  14  13  19]\n",
      " [ 17  17   0  19 129   8  20]\n",
      " [  6   8   1  20   9 100  66]\n",
      " [  1   1   0   0   3  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.60      0.69       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.94      0.84      0.88       210\n",
      "           4       0.70      0.72      0.71       210\n",
      "           5       0.58      0.61      0.60       210\n",
      "           6       0.52      0.48      0.50       210\n",
      "           7       0.60      0.86      0.71       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   3   0  10  40  26  11]\n",
      " [  0 152   8  12  24  11   3]\n",
      " [  4   4 180  10   4   6   2]\n",
      " [  3   6   5 151  11  19  15]\n",
      " [ 22  16   1  20 126   7  18]\n",
      " [  5   9   3  17   7 109  60]\n",
      " [  2   1   0   2   3  22 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.57      0.66       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.91      0.86      0.88       210\n",
      "           4       0.68      0.72      0.70       210\n",
      "           5       0.59      0.60      0.59       210\n",
      "           6       0.55      0.52      0.53       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   1   0   7  42  26  10]\n",
      " [  0 155   6  15  24   8   2]\n",
      " [  5   2 181   9   3   8   2]\n",
      " [  3   4   5 148  13  21  16]\n",
      " [ 20  19   0  25 122   8  16]\n",
      " [  4  11   3  17   7 105  63]\n",
      " [  0   3   0   5   3  28 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.59      0.68       210\n",
      "           2       0.79      0.74      0.77       210\n",
      "           3       0.93      0.86      0.89       210\n",
      "           4       0.65      0.70      0.68       210\n",
      "           5       0.57      0.58      0.58       210\n",
      "           6       0.51      0.50      0.51       210\n",
      "           7       0.61      0.81      0.70       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   0   9  40  19  14]\n",
      " [  0 158   6  15  21   7   3]\n",
      " [  4   2 182  11   3   8   0]\n",
      " [  2   3   5 147  17  23  13]\n",
      " [ 19  18   0  20 125   8  20]\n",
      " [  5  14   3  15   8 105  60]\n",
      " [  1   2   0   2   2  27 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.60      0.69       210\n",
      "           2       0.80      0.75      0.77       210\n",
      "           3       0.93      0.87      0.90       210\n",
      "           4       0.67      0.70      0.69       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.53      0.50      0.52       210\n",
      "           7       0.62      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 84   3  14   9  49  30  21]\n",
      " [  1 127  19   9  32  16   6]\n",
      " [  6   7 168   8   5  15   1]\n",
      " [  6   8  23  81  27  25  40]\n",
      " [ 16  24   0  15 113  13  29]\n",
      " [  7  21  17  14   9  60  82]\n",
      " [  0  11   0   3   2  27 167]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.40      0.51       210\n",
      "           2       0.63      0.60      0.62       210\n",
      "           3       0.70      0.80      0.75       210\n",
      "           4       0.58      0.39      0.46       210\n",
      "           5       0.48      0.54      0.51       210\n",
      "           6       0.32      0.29      0.30       210\n",
      "           7       0.48      0.80      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//gpt_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.7380952380952381\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[149   0   0   9  28  21   3]\n",
      " [  0 167   9  13  10  11   0]\n",
      " [  0   7 184   5   4   9   1]\n",
      " [  3   8  15 143  12  23   6]\n",
      " [ 27  21   2   9 145   3   3]\n",
      " [  5   8   4  17   4 117  55]\n",
      " [  0   2   0   5   2  21 180]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.71      0.76       210\n",
      "           2       0.78      0.80      0.79       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.71      0.68      0.70       210\n",
      "           5       0.71      0.69      0.70       210\n",
      "           6       0.57      0.56      0.56       210\n",
      "           7       0.73      0.86      0.79       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.682312925170068\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   2   1   6  36   9   2]\n",
      " [  3 167  10  10  17   2   1]\n",
      " [  6   6 189   6   1   2   0]\n",
      " [ 16  20  11 131  21   8   3]\n",
      " [ 25  33   8  13 129   0   2]\n",
      " [ 19  21  11  24   7  77  51]\n",
      " [ 10  11   0  18   5  10 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.73      0.70       210\n",
      "           2       0.64      0.80      0.71       210\n",
      "           3       0.82      0.90      0.86       210\n",
      "           4       0.63      0.62      0.63       210\n",
      "           5       0.60      0.61      0.61       210\n",
      "           6       0.71      0.37      0.48       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158   2   2   6  31   8   3]\n",
      " [  2 169   8  11  15   3   2]\n",
      " [  3   5 194   2   3   3   0]\n",
      " [ 13  19  13 128  20  14   3]\n",
      " [ 33  31   8  12 123   0   3]\n",
      " [ 16  18  10  20   9  83  54]\n",
      " [  6   4   0  10   7  29 154]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.72       210\n",
      "           2       0.68      0.80      0.74       210\n",
      "           3       0.83      0.92      0.87       210\n",
      "           4       0.68      0.61      0.64       210\n",
      "           5       0.59      0.59      0.59       210\n",
      "           6       0.59      0.40      0.47       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   2   2   3  34   8   4]\n",
      " [  3 164   9  10  17   5   2]\n",
      " [  2   6 193   2   4   3   0]\n",
      " [  7  21  14 126  23  17   2]\n",
      " [ 27  28   9  12 133   0   1]\n",
      " [  9  16  11  23  11  81  59]\n",
      " [  1   5   0   8   6  31 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.75       210\n",
      "           2       0.68      0.78      0.73       210\n",
      "           3       0.81      0.92      0.86       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.58      0.63      0.61       210\n",
      "           6       0.56      0.39      0.46       210\n",
      "           7       0.70      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[160   1   2   5  31   8   3]\n",
      " [  2 169   9  10  14   6   0]\n",
      " [  1   5 197   2   2   2   1]\n",
      " [ 14  19  15 120  22  16   4]\n",
      " [ 37  29   8   7 128   0   1]\n",
      " [  7  13  12  27  14  83  54]\n",
      " [  1   6   0  10   6  25 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.76      0.74       210\n",
      "           2       0.70      0.80      0.75       210\n",
      "           3       0.81      0.94      0.87       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.59      0.61      0.60       210\n",
      "           6       0.59      0.40      0.47       210\n",
      "           7       0.72      0.77      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   1   2   7  33   8   4]\n",
      " [  3 167  10  10  17   3   0]\n",
      " [  2   5 194   4   2   3   0]\n",
      " [ 14  16  19 116  27  14   4]\n",
      " [ 29  27   9   7 136   0   2]\n",
      " [  9  13  10  30  14  81  53]\n",
      " [  1   4   0   9   6  26 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.72      0.80      0.75       210\n",
      "           3       0.80      0.92      0.85       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.58      0.65      0.61       210\n",
      "           6       0.60      0.39      0.47       210\n",
      "           7       0.72      0.78      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.691156462585034\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   1   2   7  32   7   6]\n",
      " [  2 172  10   8  13   5   0]\n",
      " [  3   5 194   2   3   3   0]\n",
      " [ 13  17  21 114  25  14   6]\n",
      " [ 35  28   9   5 131   0   2]\n",
      " [ 10  15  11  24  14  81  55]\n",
      " [  1   3   0   8   5  24 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.71      0.82      0.76       210\n",
      "           3       0.79      0.92      0.85       210\n",
      "           4       0.68      0.54      0.60       210\n",
      "           5       0.59      0.62      0.61       210\n",
      "           6       0.60      0.39      0.47       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[116   0   1   7  50  28   8]\n",
      " [  1 139  12  15  19  23   1]\n",
      " [ 10   5 164  11   1  19   0]\n",
      " [  7  12  25  72  34  40  20]\n",
      " [ 24  29   6   9 126   5  11]\n",
      " [  3   6   2  12   6 115  66]\n",
      " [  0   0   0   3   0  30 177]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.55      0.63       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.56      0.34      0.42       210\n",
      "           5       0.53      0.60      0.57       210\n",
      "           6       0.44      0.55      0.49       210\n",
      "           7       0.63      0.84      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.61      1470\n",
      "weighted avg       0.63      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[118   0   1   6  50  28   7]\n",
      " [  2 138  10  16  21  21   2]\n",
      " [ 13   7 159  11   1  19   0]\n",
      " [  8  14  24  70  34  42  18]\n",
      " [ 24  24   4  12 127   5  14]\n",
      " [  3   6   2  15   8 113  63]\n",
      " [  0   0   0   2   0  37 171]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.56      0.62       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.53      0.33      0.41       210\n",
      "           5       0.53      0.60      0.56       210\n",
      "           6       0.43      0.54      0.48       210\n",
      "           7       0.62      0.81      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.7653061224489796\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   0   0   6  29  19   3]\n",
      " [  1 169   7  13  11   9   0]\n",
      " [  0   6 187   2   4  11   0]\n",
      " [  2   9  15 150  10  21   3]\n",
      " [ 21  20   3   7 154   3   2]\n",
      " [  3   7   3  17   3 126  51]\n",
      " [  0   1   0   2   1  20 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.73      0.78       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.87      0.89      0.88       210\n",
      "           4       0.76      0.71      0.74       210\n",
      "           5       0.73      0.73      0.73       210\n",
      "           6       0.60      0.60      0.60       210\n",
      "           7       0.76      0.89      0.82       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.76      1470\n",
      "weighted avg       0.77      0.77      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7850340136054422\n",
      "Confusion Matrix of SVM is:\n",
      " [[159   0   0   7  22  21   1]\n",
      " [  1 172  11  12   7   7   0]\n",
      " [  0   0 199   3   3   5   0]\n",
      " [  0   8   6 166   7  22   1]\n",
      " [ 21  23   2  12 148   2   2]\n",
      " [  2   4   2  24   1 128  49]\n",
      " [  0   1   0   3   2  22 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.76      0.81       210\n",
      "           2       0.83      0.82      0.82       210\n",
      "           3       0.90      0.95      0.93       210\n",
      "           4       0.73      0.79      0.76       210\n",
      "           5       0.78      0.70      0.74       210\n",
      "           6       0.62      0.61      0.61       210\n",
      "           7       0.77      0.87      0.82       210\n",
      "\n",
      "    accuracy                           0.79      1470\n",
      "   macro avg       0.79      0.79      0.78      1470\n",
      "weighted avg       0.79      0.79      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.780952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   0   0   6  25  21   2]\n",
      " [  1 172  10  11  10   6   0]\n",
      " [  0   1 195   2   3   9   0]\n",
      " [  0   8   6 166   7  22   1]\n",
      " [ 22  24   3   8 147   3   3]\n",
      " [  3   5   2  19   1 129  51]\n",
      " [  0   1   0   2   1  23 183]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.74      0.80       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.90      0.93      0.92       210\n",
      "           4       0.78      0.79      0.78       210\n",
      "           5       0.76      0.70      0.73       210\n",
      "           6       0.61      0.61      0.61       210\n",
      "           7       0.76      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.78      0.78      0.78      1470\n",
      "weighted avg       0.78      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.7115646258503401\n",
      "Confusion Matrix of SVM is:\n",
      " [[144   0   2   8  37  17   2]\n",
      " [  1 164  12  13  12   8   0]\n",
      " [  0   7 182   5   4  12   0]\n",
      " [  4  12  16 134  10  25   9]\n",
      " [ 30  24   2   7 141   3   3]\n",
      " [  8  10   5  14   2 100  71]\n",
      " [  0   1   0   3   2  23 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.69      0.73       210\n",
      "           2       0.75      0.78      0.77       210\n",
      "           3       0.83      0.87      0.85       210\n",
      "           4       0.73      0.64      0.68       210\n",
      "           5       0.68      0.67      0.67       210\n",
      "           6       0.53      0.48      0.50       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.23265306122448978\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[205   0   5   0   0   0   0]\n",
      " [200   0  10   0   0   0   0]\n",
      " [ 73   0 137   0   0   0   0]\n",
      " [195   0  15   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [201   0   9   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.98      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.76      0.65      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.14      1470\n",
      "weighted avg       0.13      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.34965986394557824\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   5   0 172   0  33]\n",
      " [  0   0  10   0 174   0  26]\n",
      " [  0   0 137   0  56   0  17]\n",
      " [  0   0  15   0 148   0  47]\n",
      " [  0   0   3   0 189   0  18]\n",
      " [  0   0   9   0  49   0 152]\n",
      " [  0   0   2   0  20   0 188]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.76      0.65      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.90      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.90      0.54       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.20      0.35      0.23      1470\n",
      "weighted avg       0.20      0.35      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4775510204081633\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[162  10   3   2   0  24   9]\n",
      " [ 15 159   9   1   0  18   8]\n",
      " [ 15  41 137   0   0  16   1]\n",
      " [ 58  90   7   8   0  40   7]\n",
      " [124  65   1   2   0   6  12]\n",
      " [ 23  26   9   0   0  91  61]\n",
      " [ 14   6   2   0   0  43 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.77      0.52       210\n",
      "           2       0.40      0.76      0.52       210\n",
      "           3       0.82      0.65      0.72       210\n",
      "           4       0.62      0.04      0.07       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.38      0.43      0.41       210\n",
      "           7       0.60      0.69      0.64       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.46      0.48      0.41      1470\n",
      "weighted avg       0.46      0.48      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5231292517006803\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 87   1   0  10  76  32   4]\n",
      " [  2 128   5  32  13  28   2]\n",
      " [  2  11 127  32  13  25   0]\n",
      " [  2  26   0  72  56  48   6]\n",
      " [ 13  29   0  36 113  11   8]\n",
      " [  1   9   1  17  22 118  42]\n",
      " [  0   0   1   6  14  65 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.41      0.55       210\n",
      "           2       0.63      0.61      0.62       210\n",
      "           3       0.95      0.60      0.74       210\n",
      "           4       0.35      0.34      0.35       210\n",
      "           5       0.37      0.54      0.44       210\n",
      "           6       0.36      0.56      0.44       210\n",
      "           7       0.67      0.59      0.63       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.59      0.52      0.54      1470\n",
      "weighted avg       0.59      0.52      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84   0   3  48  47  25   3]\n",
      " [  2 101   6  66  15  18   2]\n",
      " [  2   4 155  32   1  16   0]\n",
      " [  2   6   7 137  17  35   6]\n",
      " [  8  15   0  90  88   7   2]\n",
      " [  1   6   5  44   6 107  41]\n",
      " [  0   0   1  24  10  55 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.40      0.54       210\n",
      "           2       0.77      0.48      0.59       210\n",
      "           3       0.88      0.74      0.80       210\n",
      "           4       0.31      0.65      0.42       210\n",
      "           5       0.48      0.42      0.45       210\n",
      "           6       0.41      0.51      0.45       210\n",
      "           7       0.69      0.57      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.55      1470\n",
      "weighted avg       0.62      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   8   3  11  52  20   3]\n",
      " [  7 147  12  22  12   6   4]\n",
      " [  6  18 160  10  14   2   0]\n",
      " [  9  31   5 104  31  24   6]\n",
      " [ 21  46   0  29 104   5   5]\n",
      " [ 13  14   8  25  21  80  49]\n",
      " [  2   8   1  11  12  42 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.54      0.59       210\n",
      "           2       0.54      0.70      0.61       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.49      0.50      0.49       210\n",
      "           5       0.42      0.50      0.46       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.67      0.64      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104   3   2  11  63  17  10]\n",
      " [  7 143  10  17  18  12   3]\n",
      " [  2  21 168   5   7   7   0]\n",
      " [  7  22   3  95  38  34  11]\n",
      " [ 19  24   1  29 123   9   5]\n",
      " [  6  12   5  18  22  82  65]\n",
      " [  3   4   1   3  13  39 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.50      0.58       210\n",
      "           2       0.62      0.68      0.65       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.53      0.45      0.49       210\n",
      "           5       0.43      0.59      0.50       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.61      0.70      0.65       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   1   2  11  53  18   7]\n",
      " [  7 136  15  18  22  10   2]\n",
      " [  3  16 172   3  10   6   0]\n",
      " [ 12  16   8  92  44  26  12]\n",
      " [ 23  26   6  19 126   4   6]\n",
      " [ 12  12   5  16  23  90  52]\n",
      " [  3   3   1   8  12  51 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.56      0.61       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.55      0.44      0.49       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.44      0.43      0.43       210\n",
      "           7       0.63      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5870748299319728\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   3   2  11  54  15  17]\n",
      " [  9 137  12  18  18  13   3]\n",
      " [  1  13 172   7  10   7   0]\n",
      " [  7  19   4 102  37  28  13]\n",
      " [ 28  24   4  27 116   3   8]\n",
      " [  8  17   4  17  15  75  74]\n",
      " [  5   4   0   8   6  34 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.51      0.57       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.87      0.82      0.84       210\n",
      "           4       0.54      0.49      0.51       210\n",
      "           5       0.45      0.55      0.50       210\n",
      "           6       0.43      0.36      0.39       210\n",
      "           7       0.57      0.73      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   6   2  14  46  13   7]\n",
      " [ 12 146  12  14  16   8   2]\n",
      " [  2  14 176   5   6   7   0]\n",
      " [ 13  23   8  99  26  33   8]\n",
      " [ 35  29   7  29 102   4   4]\n",
      " [ 28  18   5  17   9  82  51]\n",
      " [ 14   5   1  10   8  39 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.83      0.84      0.84       210\n",
      "           4       0.53      0.47      0.50       210\n",
      "           5       0.48      0.49      0.48       210\n",
      "           6       0.44      0.39      0.41       210\n",
      "           7       0.65      0.63      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.58      0.59      0.58      1470\n",
      "weighted avg       0.58      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   7   3  10  50  16   4]\n",
      " [ 10 139  12  17  22   8   2]\n",
      " [  2  14 174  10   5   4   1]\n",
      " [ 19  21   8  99  28  27   8]\n",
      " [ 38  33   5  27  98   4   5]\n",
      " [ 25  13   6  26   7  76  57]\n",
      " [ 12   5   3  13   6  42 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.57      0.55       210\n",
      "           2       0.60      0.66      0.63       210\n",
      "           3       0.82      0.83      0.83       210\n",
      "           4       0.49      0.47      0.48       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.43      0.36      0.39       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.57      1470\n",
      "weighted avg       0.56      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   8   2  17  50  16   4]\n",
      " [  5 140  13  16  21   9   6]\n",
      " [  4  13 173  11   2   5   2]\n",
      " [ 12  17   8 102  32  26  13]\n",
      " [ 26  31   7  33 102   5   6]\n",
      " [ 16  13   7  23  17  85  49]\n",
      " [  9   4   1  12  13  41 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.54      0.57       210\n",
      "           2       0.62      0.67      0.64       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.48      0.49      0.48       210\n",
      "           5       0.43      0.49      0.46       210\n",
      "           6       0.45      0.40      0.43       210\n",
      "           7       0.62      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   7   6  19  40  17   5]\n",
      " [  8 137  10  18  21  13   3]\n",
      " [  2  13 174  12   1   7   1]\n",
      " [ 10  20   6 104  29  31  10]\n",
      " [ 30  31   6  35  96   9   3]\n",
      " [ 12  11   6  24  10  91  56]\n",
      " [  5   5   1  11   7  49 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.55      0.59       210\n",
      "           2       0.61      0.65      0.63       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.47      0.50      0.48       210\n",
      "           5       0.47      0.46      0.46       210\n",
      "           6       0.42      0.43      0.43       210\n",
      "           7       0.63      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  10   5  15  38  19   7]\n",
      " [  8 140  14  16  21   8   3]\n",
      " [  3  17 171   9   2   6   2]\n",
      " [  6  15   9 101  30  37  12]\n",
      " [ 26  33   5  31  94   8  13]\n",
      " [  9  14   6  24   9  97  51]\n",
      " [  7   4   3  15   8  42 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.55      0.60       210\n",
      "           2       0.60      0.67      0.63       210\n",
      "           3       0.80      0.81      0.81       210\n",
      "           4       0.48      0.48      0.48       210\n",
      "           5       0.47      0.45      0.46       210\n",
      "           6       0.45      0.46      0.45       210\n",
      "           7       0.60      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   6   4  14  40  22   6]\n",
      " [  8 134  12  21  18  11   6]\n",
      " [  2  15 171  10   4   5   3]\n",
      " [  8  13   9 107  34  32   7]\n",
      " [ 26  24   6  31 105   9   9]\n",
      " [ 13  11   7  23  11  91  54]\n",
      " [  7   8   3  12   4  41 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.56      0.60       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.49      0.51      0.50       210\n",
      "           5       0.49      0.50      0.49       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.61      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125  13   2  15  33  18   4]\n",
      " [  8 140  12  14  24   8   4]\n",
      " [  4  15 172   9   3   4   3]\n",
      " [  6  24   8 102  29  33   8]\n",
      " [ 30  34   4  29  97   9   7]\n",
      " [ 13  16   4  22  14  86  55]\n",
      " [  7   8   1  11   9  48 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.60      0.62       210\n",
      "           2       0.56      0.67      0.61       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.50      0.49      0.50       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.42      0.41      0.41       210\n",
      "           7       0.61      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   8   5  16  37  20   4]\n",
      " [ 12 136  12  16  21   8   5]\n",
      " [  4  12 174   9   2   6   3]\n",
      " [ 14  15  13  98  28  33   9]\n",
      " [ 30  26   8  36  95  10   5]\n",
      " [ 11  14   4  22  13  91  55]\n",
      " [ 10   5   4  11   6  50 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.57      0.58       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.79      0.83      0.81       210\n",
      "           4       0.47      0.47      0.47       210\n",
      "           5       0.47      0.45      0.46       210\n",
      "           6       0.42      0.43      0.43       210\n",
      "           7       0.60      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   9   2  16  38  19   7]\n",
      " [  6 134  13  15  26  13   3]\n",
      " [  3  15 174  10   3   4   1]\n",
      " [  7  21  10 101  31  31   9]\n",
      " [ 25  27   8  31 103  10   6]\n",
      " [ 13  11   5  22  11  91  57]\n",
      " [  8   6   2  11   7  49 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.61       210\n",
      "           2       0.60      0.64      0.62       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.49      0.48      0.49       210\n",
      "           5       0.47      0.49      0.48       210\n",
      "           6       0.42      0.43      0.43       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   4  15  42  21   3]\n",
      " [  6 138  11  22  20  11   2]\n",
      " [  3  14 173  10   3   6   1]\n",
      " [ 11  20  10 101  24  30  14]\n",
      " [ 28  29   9  34  97   7   6]\n",
      " [ 12  12   4  22   6  94  60]\n",
      " [  7   6   1  15   9  47 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.57      0.60       210\n",
      "           2       0.61      0.66      0.63       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.46      0.48      0.47       210\n",
      "           5       0.48      0.46      0.47       210\n",
      "           6       0.44      0.45      0.44       210\n",
      "           7       0.59      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   9   4  12  40  19   6]\n",
      " [  7 133  12  20  23  11   4]\n",
      " [  4  14 174   9   1   6   2]\n",
      " [ 11  17  13 105  27  26  11]\n",
      " [ 35  35   4  27  96   9   4]\n",
      " [ 12  17   5  23   6  87  60]\n",
      " [  6   5   1  10   9  50 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.57      0.59       210\n",
      "           2       0.58      0.63      0.60       210\n",
      "           3       0.82      0.83      0.82       210\n",
      "           4       0.51      0.50      0.50       210\n",
      "           5       0.48      0.46      0.47       210\n",
      "           6       0.42      0.41      0.42       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79   2  13   0  67   1  48]\n",
      " [  2 113  33   2  37   0  23]\n",
      " [  2   8 179   0   9   1  11]\n",
      " [  9  24  46   1  65   2  63]\n",
      " [ 11  25  11   0 132   0  31]\n",
      " [  2   6  25   0  11   2 164]\n",
      " [  0   0   2   0   1   1 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.38      0.50       210\n",
      "           2       0.63      0.54      0.58       210\n",
      "           3       0.58      0.85      0.69       210\n",
      "           4       0.33      0.00      0.01       210\n",
      "           5       0.41      0.63      0.50       210\n",
      "           6       0.29      0.01      0.02       210\n",
      "           7       0.38      0.98      0.54       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.41      1470\n",
      "weighted avg       0.48      0.48      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   0   3   0  40   7  30]\n",
      " [  1 143  15   0  29   9  13]\n",
      " [  6  17 167   0   5  11   4]\n",
      " [ 12  41  30   3  56  11  57]\n",
      " [ 29  36   3   0 119   1  22]\n",
      " [  4  12   9   0   9  35 141]\n",
      " [  0   0   0   0   1   5 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.62      0.66       210\n",
      "           2       0.57      0.68      0.62       210\n",
      "           3       0.74      0.80      0.76       210\n",
      "           4       1.00      0.01      0.03       210\n",
      "           5       0.46      0.57      0.51       210\n",
      "           6       0.44      0.17      0.24       210\n",
      "           7       0.43      0.97      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.49      1470\n",
      "weighted avg       0.62      0.54      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   0   1   1  42  19  18]\n",
      " [  1 162   5   3  19  15   5]\n",
      " [  7  21 163   2   4  12   1]\n",
      " [  9  48  19  24  48  25  37]\n",
      " [ 29  40   1   1 118   1  20]\n",
      " [  5  19   4   4  10  48 120]\n",
      " [  0   0   0   0   0   8 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.61      0.66       210\n",
      "           2       0.56      0.77      0.65       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.69      0.11      0.20       210\n",
      "           5       0.49      0.56      0.52       210\n",
      "           6       0.38      0.23      0.28       210\n",
      "           7       0.50      0.96      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.54      1470\n",
      "weighted avg       0.60      0.58      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   0   0   2  44  21  16]\n",
      " [  0 154   4   5  23  21   3]\n",
      " [  1  16 160   4  12  16   1]\n",
      " [  2  22   9  68  49  34  26]\n",
      " [ 20  34   1   5 134   3  13]\n",
      " [  4  10   1  10   8  73 104]\n",
      " [  0   0   0   0   1  16 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.65      0.73      0.69       210\n",
      "           3       0.91      0.76      0.83       210\n",
      "           4       0.72      0.32      0.45       210\n",
      "           5       0.49      0.64      0.56       210\n",
      "           6       0.40      0.35      0.37       210\n",
      "           7       0.54      0.92      0.68       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.61      1470\n",
      "weighted avg       0.65      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   0   0   5  44  26  11]\n",
      " [  1 152   4  12  19  21   1]\n",
      " [  1   9 171   9   8  12   0]\n",
      " [  0  12   6  98  37  33  24]\n",
      " [ 17  30   0  10 139   3  11]\n",
      " [  1   5   1  17   7  90  89]\n",
      " [  0   0   0   1   0  22 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.73      0.72      0.73       210\n",
      "           3       0.94      0.81      0.87       210\n",
      "           4       0.64      0.47      0.54       210\n",
      "           5       0.55      0.66      0.60       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.58      0.89      0.70       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   0   0   4  47  27   8]\n",
      " [  1 151   5  14  21  17   1]\n",
      " [  1   8 175  10   4  12   0]\n",
      " [  2   6   3 114  33  33  19]\n",
      " [ 14  28   0   9 143   5  11]\n",
      " [  2   5   1  13   8  94  87]\n",
      " [  0   0   0   1   3  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.59      0.70       210\n",
      "           2       0.76      0.72      0.74       210\n",
      "           3       0.95      0.83      0.89       210\n",
      "           4       0.69      0.54      0.61       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.45      0.45      0.45       210\n",
      "           7       0.60      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   0   0   4  43  25  12]\n",
      " [  1 153   4  16  16  19   1]\n",
      " [  2   4 177   8   5  14   0]\n",
      " [  2   6   2 129  21  34  16]\n",
      " [ 18  26   0  14 140   4   8]\n",
      " [  3   3   1  16   7 110  70]\n",
      " [  0   0   0   2   2  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.70       210\n",
      "           2       0.80      0.73      0.76       210\n",
      "           3       0.96      0.84      0.90       210\n",
      "           4       0.68      0.61      0.65       210\n",
      "           5       0.60      0.67      0.63       210\n",
      "           6       0.47      0.52      0.50       210\n",
      "           7       0.63      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.7027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   0   0   5  42  22  13]\n",
      " [  1 153   5  18  18  14   1]\n",
      " [  0   4 177  10   6  13   0]\n",
      " [  1   5   2 132  23  32  15]\n",
      " [ 18  23   0  11 147   3   8]\n",
      " [  2   4   1  13   8 109  73]\n",
      " [  0   0   0   2   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.61      0.71       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.96      0.84      0.90       210\n",
      "           4       0.69      0.63      0.66       210\n",
      "           5       0.60      0.70      0.64       210\n",
      "           6       0.51      0.52      0.52       210\n",
      "           7       0.63      0.89      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   0   0   8  41  23   6]\n",
      " [  0 157   5  15  21  12   0]\n",
      " [  0   7 180   7   4  11   1]\n",
      " [  1   8   3 124  21  38  15]\n",
      " [ 15  25   0  15 144   3   8]\n",
      " [  0   4   1  16   4 118  67]\n",
      " [  0   0   0   3   2  23 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.63      0.74       210\n",
      "           2       0.78      0.75      0.76       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.61      0.69      0.64       210\n",
      "           6       0.52      0.56      0.54       210\n",
      "           7       0.65      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.717687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   0   0   6  38  22   9]\n",
      " [  2 160   5  18  14   9   2]\n",
      " [  1   5 181  10   3   9   1]\n",
      " [  1   5   3 131  24  29  17]\n",
      " [ 18  24   0  14 142   3   9]\n",
      " [  0   4   1  15   5 120  65]\n",
      " [  0   0   0   1   1  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.64      0.74       210\n",
      "           2       0.81      0.76      0.78       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.67      0.62      0.65       210\n",
      "           5       0.63      0.68      0.65       210\n",
      "           6       0.56      0.57      0.57       210\n",
      "           7       0.64      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   0   0   4  37  25   7]\n",
      " [  2 156   6  18  20   6   2]\n",
      " [  0   2 185  10   3  10   0]\n",
      " [  1   6   2 136  21  29  15]\n",
      " [ 19  21   1  14 144   4   7]\n",
      " [  2   3   1  17   6 113  68]\n",
      " [  0   0   0   3   2  23 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.65      0.74       210\n",
      "           2       0.83      0.74      0.78       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.62      0.69      0.65       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.65      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7292517006802721\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   0   0   6  32  24   7]\n",
      " [  2 160   6  15  18   9   0]\n",
      " [  0   3 186  10   3   8   0]\n",
      " [  1   4   1 139  21  29  15]\n",
      " [ 19  19   0  14 147   2   9]\n",
      " [  2   3   1  16   5 118  65]\n",
      " [  0   0   0   2   0  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.67      0.75       210\n",
      "           2       0.85      0.76      0.80       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.69      0.66      0.67       210\n",
      "           5       0.65      0.70      0.67       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.65      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   0   0   6  40  20  10]\n",
      " [  2 160   4  17  17  10   0]\n",
      " [  1   2 185  10   4   7   1]\n",
      " [  2   7   1 139  20  27  14]\n",
      " [ 20  18   0  15 148   2   7]\n",
      " [  2   3   0  15   6 113  71]\n",
      " [  0   0   0   3   1  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.72       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.97      0.88      0.93       210\n",
      "           4       0.68      0.66      0.67       210\n",
      "           5       0.63      0.70      0.66       210\n",
      "           6       0.56      0.54      0.55       210\n",
      "           7       0.64      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.72      1470\n",
      "weighted avg       0.74      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7197278911564626\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   0   0   6  38  24   7]\n",
      " [  1 161   4  15  19   8   2]\n",
      " [  0   2 186   9   3  10   0]\n",
      " [  2   7   2 135  19  33  12]\n",
      " [ 19  17   1  17 146   5   5]\n",
      " [  1   2   1  17   6 115  68]\n",
      " [  0   0   0   3   0  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.64      0.73       210\n",
      "           2       0.85      0.77      0.81       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.67      0.64      0.66       210\n",
      "           5       0.63      0.70      0.66       210\n",
      "           6       0.52      0.55      0.53       210\n",
      "           7       0.66      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   0   0   7  39  21   7]\n",
      " [  2 160   7  17  15   8   1]\n",
      " [  0   2 186   9   4   9   0]\n",
      " [  1   5   3 148  19  25   9]\n",
      " [ 13  21   0  19 147   5   5]\n",
      " [  4   4   0  18   4 111  69]\n",
      " [  0   0   0   2   2  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.65      0.74       210\n",
      "           2       0.83      0.76      0.80       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.67      0.70      0.69       210\n",
      "           5       0.64      0.70      0.67       210\n",
      "           6       0.54      0.53      0.53       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.7319727891156462\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   0   0   9  32  24   6]\n",
      " [  1 161   6  19  16   7   0]\n",
      " [  0   3 186  10   2   8   1]\n",
      " [  4   4   1 146  16  29  10]\n",
      " [ 19  21   0  14 145   6   5]\n",
      " [  3   4   2  17   5 122  57]\n",
      " [  0   0   0   0   1  32 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.83      0.77      0.80       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.68      0.70      0.69       210\n",
      "           5       0.67      0.69      0.68       210\n",
      "           6       0.54      0.58      0.56       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7231292517006803\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   0   0  10  33  20   8]\n",
      " [  1 159   5  18  18   9   0]\n",
      " [  0   3 186  11   2   8   0]\n",
      " [  2   3   0 146  19  28  12]\n",
      " [ 21  21   1  18 137   4   8]\n",
      " [  2   3   1  18   4 115  67]\n",
      " [  0   0   0   3   1  25 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.65      0.70      0.67       210\n",
      "           5       0.64      0.65      0.65       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.66      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.72      1470\n",
      "weighted avg       0.74      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7258503401360544\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   0   0   7  38  21   5]\n",
      " [  0 163   5  17  14  11   0]\n",
      " [  0   5 184   8   4   8   1]\n",
      " [  2   5   2 142  20  27  12]\n",
      " [ 19  22   1  14 143   5   6]\n",
      " [  4   4   1  15   6 118  62]\n",
      " [  0   0   0   4   2  26 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.74       210\n",
      "           2       0.82      0.78      0.80       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.63      0.68      0.65       210\n",
      "           6       0.55      0.56      0.55       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   0   0   6  37  22   5]\n",
      " [  1 159   5  17  18   9   1]\n",
      " [  0   4 185  10   3   7   1]\n",
      " [  2   4   0 142  22  28  12]\n",
      " [ 22  22   0  12 144   6   4]\n",
      " [  2   4   1  16   7 120  60]\n",
      " [  0   0   0   4   1  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.97      0.88      0.92       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.62      0.69      0.65       210\n",
      "           6       0.55      0.57      0.56       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.7244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   0   0   7  36  25   4]\n",
      " [  1 162   5  17  14  10   1]\n",
      " [  0   6 185   9   3   7   0]\n",
      " [  2   6   3 135  22  30  12]\n",
      " [ 19  21   0  12 146   6   6]\n",
      " [  2   5   1  15   6 120  61]\n",
      " [  0   0   0   4   2  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.74       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.95      0.88      0.92       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.64      0.70      0.67       210\n",
      "           6       0.54      0.57      0.55       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.73      1470\n",
      "weighted avg       0.74      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.6006802721088436\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[119   1   2   7  49  25   7]\n",
      " [  1 131  21  14  21  20   2]\n",
      " [ 10   1 176   9   1  13   0]\n",
      " [  7  11  31  71  33  41  16]\n",
      " [ 31  30   7  10 113   3  16]\n",
      " [  4   4  11  12   6 106  67]\n",
      " [  0   0   0   2   0  41 167]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.57      0.62       210\n",
      "           2       0.74      0.62      0.68       210\n",
      "           3       0.71      0.84      0.77       210\n",
      "           4       0.57      0.34      0.42       210\n",
      "           5       0.51      0.54      0.52       210\n",
      "           6       0.43      0.50      0.46       210\n",
      "           7       0.61      0.80      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//xlm_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[129   6   0  10  42  12  11]\n",
      " [  2 157  15   8  19   5   4]\n",
      " [  4  14 171   6   5   8   2]\n",
      " [  8   8  16 105  24  33  16]\n",
      " [ 21  17   3   9 144   2  14]\n",
      " [  8  11  12  19  10  82  68]\n",
      " [  4   3   0   4   5  32 162]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.61      0.67       210\n",
      "           2       0.73      0.75      0.74       210\n",
      "           3       0.79      0.81      0.80       210\n",
      "           4       0.65      0.50      0.57       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.47      0.39      0.43       210\n",
      "           7       0.58      0.77      0.67       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.545578231292517\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  13   2   9  41   9   7]\n",
      " [ 12 147  10  10  28   1   2]\n",
      " [ 11  19 166   5   7   2   0]\n",
      " [ 36   9  11  97  29  15  13]\n",
      " [ 52  16   3  19 104   5  11]\n",
      " [ 41  25   7  34  19  44  40]\n",
      " [ 24  10   1  25  16  19 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.61      0.50       210\n",
      "           2       0.62      0.70      0.65       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.49      0.46      0.47       210\n",
      "           5       0.43      0.50      0.46       210\n",
      "           6       0.46      0.21      0.29       210\n",
      "           7       0.61      0.55      0.58       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132   7   1  11  39  12   8]\n",
      " [ 13 141  11   9  30   3   3]\n",
      " [  8  14 168   5  10   4   1]\n",
      " [ 29  11   7 101  30  17  15]\n",
      " [ 43  17   3  18 112   8   9]\n",
      " [ 36  16   7  33  16  58  44]\n",
      " [ 16  11   0  17  13  34 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.63      0.54       210\n",
      "           2       0.65      0.67      0.66       210\n",
      "           3       0.85      0.80      0.83       210\n",
      "           4       0.52      0.48      0.50       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.43      0.28      0.34       210\n",
      "           7       0.60      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120   7   1  14  45  11  12]\n",
      " [  7 139  15   8  35   3   3]\n",
      " [  6  20 169   4   8   2   1]\n",
      " [ 25  15   4  94  38  17  17]\n",
      " [ 33  19   3  16 120   8  11]\n",
      " [ 28  17   7  28  17  67  46]\n",
      " [  9   1   0  21  19  33 127]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.57      0.55       210\n",
      "           2       0.64      0.66      0.65       210\n",
      "           3       0.85      0.80      0.83       210\n",
      "           4       0.51      0.45      0.48       210\n",
      "           5       0.43      0.57      0.49       210\n",
      "           6       0.48      0.32      0.38       210\n",
      "           7       0.59      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[118   6   1  16  49  10  10]\n",
      " [  7 134  16  11  38   2   2]\n",
      " [  7  21 167   3   8   3   1]\n",
      " [ 19  10   5 101  36  21  18]\n",
      " [ 35  24   2  12 121   4  12]\n",
      " [ 27  13   8  29  24  65  44]\n",
      " [  9   3   0  22  18  28 130]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.56      0.55       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.52      0.48      0.50       210\n",
      "           5       0.41      0.58      0.48       210\n",
      "           6       0.49      0.31      0.38       210\n",
      "           7       0.60      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[115   7   2  21  45   9  11]\n",
      " [  4 134  14  11  43   2   2]\n",
      " [  6  19 167   6   9   3   0]\n",
      " [ 19  10   8  99  35  20  19]\n",
      " [ 35  24   5  10 122   3  11]\n",
      " [ 28  14   7  30  23  59  49]\n",
      " [ 10   2   0  20  17  21 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.64      0.64      0.64       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.50      0.47      0.49       210\n",
      "           5       0.41      0.58      0.48       210\n",
      "           6       0.50      0.28      0.36       210\n",
      "           7       0.60      0.67      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117   7   2  13  47  12  12]\n",
      " [  7 136  14   8  41   2   2]\n",
      " [  5  21 166   6   7   5   0]\n",
      " [ 18  11   8  91  41  21  20]\n",
      " [ 29  22   2   8 129   6  14]\n",
      " [ 28  13   6  27  27  58  51]\n",
      " [ 10   0   0  19  16  24 141]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.55       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.53      0.43      0.48       210\n",
      "           5       0.42      0.61      0.50       210\n",
      "           6       0.45      0.28      0.34       210\n",
      "           7       0.59      0.67      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 77   3   2  11  63  11  43]\n",
      " [  0 133   8   9  49   5   6]\n",
      " [  3  46 137   2   8  11   3]\n",
      " [  5  24   9  51  47  17  57]\n",
      " [  7  25   2   8 124   3  41]\n",
      " [  8  24   9  20  28  43  78]\n",
      " [  3   8   1  13  23  23 139]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.37      0.49       210\n",
      "           2       0.51      0.63      0.56       210\n",
      "           3       0.82      0.65      0.72       210\n",
      "           4       0.45      0.24      0.31       210\n",
      "           5       0.36      0.59      0.45       210\n",
      "           6       0.38      0.20      0.27       210\n",
      "           7       0.38      0.66      0.48       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.52      0.48      0.47      1470\n",
      "weighted avg       0.52      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 75   7   5  10  61  13  39]\n",
      " [  1 134   8  13  43   4   7]\n",
      " [  5  47 135   5   5  10   3]\n",
      " [  5  27   9  52  49  17  51]\n",
      " [ 10  25   1  10 125   2  37]\n",
      " [  6  29   9  27  26  35  78]\n",
      " [  4   9   1  16  27  25 128]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.36      0.47       210\n",
      "           2       0.48      0.64      0.55       210\n",
      "           3       0.80      0.64      0.71       210\n",
      "           4       0.39      0.25      0.30       210\n",
      "           5       0.37      0.60      0.46       210\n",
      "           6       0.33      0.17      0.22       210\n",
      "           7       0.37      0.61      0.46       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.45      1470\n",
      "weighted avg       0.49      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   4   0   8  39  14  11]\n",
      " [  2 163   8   9  18   6   4]\n",
      " [  2  14 169   8   8   9   0]\n",
      " [  8   8  10 109  23  33  19]\n",
      " [ 18  19   3   8 144   3  15]\n",
      " [  7   7   9  19  11  86  71]\n",
      " [  1   2   0   4   7  33 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.64      0.70       210\n",
      "           2       0.75      0.78      0.76       210\n",
      "           3       0.85      0.80      0.83       210\n",
      "           4       0.66      0.52      0.58       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.47      0.41      0.44       210\n",
      "           7       0.58      0.78      0.66       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of SVM is:\n",
      " [[142   3   0   4  35  18   8]\n",
      " [  1 166   8   7  18   8   2]\n",
      " [  3  13 175   6   3   9   1]\n",
      " [  6   7   6 132  19  33   7]\n",
      " [ 23  19   2   9 146   3   8]\n",
      " [  7   6   7  20  10  97  63]\n",
      " [  1   1   0   3   7  32 166]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.72       210\n",
      "           2       0.77      0.79      0.78       210\n",
      "           3       0.88      0.83      0.86       210\n",
      "           4       0.73      0.63      0.68       210\n",
      "           5       0.61      0.70      0.65       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.65      0.79      0.71       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of SVM is:\n",
      " [[139   3   0   5  37  17   9]\n",
      " [  1 166   7   7  19   8   2]\n",
      " [  2  13 173   6   5  11   0]\n",
      " [  6   6   7 128  20  32  11]\n",
      " [ 23  21   1   9 143   2  11]\n",
      " [  7   7   7  20  11  92  66]\n",
      " [  1   0   0   3   8  30 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.71       210\n",
      "           2       0.77      0.79      0.78       210\n",
      "           3       0.89      0.82      0.85       210\n",
      "           4       0.72      0.61      0.66       210\n",
      "           5       0.59      0.68      0.63       210\n",
      "           6       0.48      0.44      0.46       210\n",
      "           7       0.63      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of SVM is:\n",
      " [[129   5   0   7  42  13  14]\n",
      " [  2 146  16   9  24   9   4]\n",
      " [  5  13 168   6   6  12   0]\n",
      " [  7   7  12 100  28  28  28]\n",
      " [ 16  20   2   9 140   3  20]\n",
      " [  9   8  10  20  12  76  75]\n",
      " [  2   2   2   4   6  26 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.61      0.68       210\n",
      "           2       0.73      0.70      0.71       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.65      0.48      0.55       210\n",
      "           5       0.54      0.67      0.60       210\n",
      "           6       0.46      0.36      0.40       210\n",
      "           7       0.54      0.80      0.65       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.21904761904761905\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0   0   0 197]\n",
      " [  0   0  11   0   0   0 199]\n",
      " [  0   0 113   0   0   0  97]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   2   0   0   0 208]\n",
      " [  0   0  10   0   0   0 200]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.54      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.2979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 13 115   0   0   0   0  82]\n",
      " [  2 170   9   0   0   0  29]\n",
      " [  0  68 113   0   0   0  29]\n",
      " [  0 135   3   0   0   0  72]\n",
      " [  1 153   1   0   0   0  55]\n",
      " [  4 102   6   0   0   0  98]\n",
      " [  1  67   0   0   0   0 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.06      0.11       210\n",
      "           2       0.21      0.81      0.33       210\n",
      "           3       0.86      0.54      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.28      0.68      0.40       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.28      0.30      0.21      1470\n",
      "weighted avg       0.28      0.30      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68   7   0   0 110   0  25]\n",
      " [ 21  62   4   0 115   0   8]\n",
      " [ 25  10 112   0  59   0   4]\n",
      " [ 39  10   3   0 125   0  33]\n",
      " [ 25  14   0   0 141   0  30]\n",
      " [ 37   8   4   0 100   0  61]\n",
      " [ 35   2   0   0  66   0 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.32      0.30       210\n",
      "           2       0.55      0.30      0.38       210\n",
      "           3       0.91      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.20      0.67      0.30       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.51      0.45       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.33      0.33      0.30      1470\n",
      "weighted avg       0.33      0.33      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.35034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68   7   0  83  27   0  25]\n",
      " [ 21  62   2  99  16   2   8]\n",
      " [ 12  10 123  56   3   2   4]\n",
      " [ 39  10   3 111  14   0  33]\n",
      " [ 25  14   0  99  42   0  30]\n",
      " [ 37   5   4  96   5   2  61]\n",
      " [ 35   1   0  60   6   1 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.32      0.30       210\n",
      "           2       0.57      0.30      0.39       210\n",
      "           3       0.93      0.59      0.72       210\n",
      "           4       0.18      0.53      0.27       210\n",
      "           5       0.37      0.20      0.26       210\n",
      "           6       0.29      0.01      0.02       210\n",
      "           7       0.40      0.51      0.45       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.43      0.35      0.34      1470\n",
      "weighted avg       0.43      0.35      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  36   0   1  21  29  25]\n",
      " [ 33 137   1   1  10  21   7]\n",
      " [ 23  47 123   0   1  12   4]\n",
      " [ 76  55   1   2   9  36  31]\n",
      " [ 47  68   1   1  40  23  30]\n",
      " [ 58  52   2   2   3  34  59]\n",
      " [ 50  22   0   1   3  28 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.47      0.33       210\n",
      "           2       0.33      0.65      0.44       210\n",
      "           3       0.96      0.59      0.73       210\n",
      "           4       0.25      0.01      0.02       210\n",
      "           5       0.46      0.19      0.27       210\n",
      "           6       0.19      0.16      0.17       210\n",
      "           7       0.40      0.50      0.45       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.34      1470\n",
      "weighted avg       0.41      0.37      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  28   0  50  21  18  11]\n",
      " [ 25 129   3  28  10  12   3]\n",
      " [ 12  37 129  17   2  11   2]\n",
      " [ 39  49   2  64   9  31  16]\n",
      " [ 22  67   0  38  41  30  12]\n",
      " [ 22  48   3  51   3  55  28]\n",
      " [ 30  19   0  43   3  43  72]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.39      0.37       210\n",
      "           2       0.34      0.61      0.44       210\n",
      "           3       0.94      0.61      0.74       210\n",
      "           4       0.22      0.30      0.26       210\n",
      "           5       0.46      0.20      0.27       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.50      0.34      0.41       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.44      0.39      0.39      1470\n",
      "weighted avg       0.44      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60   8   1  95  28   7  11]\n",
      " [ 14  94   2  68  24   5   3]\n",
      " [  8  15 133  38  11   3   2]\n",
      " [ 18  15   2 121  27  13  14]\n",
      " [ 19  25   1  87  55  11  12]\n",
      " [ 11  14   2 109  15  32  27]\n",
      " [  9   4   0  84  15  25  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.29      0.34       210\n",
      "           2       0.54      0.45      0.49       210\n",
      "           3       0.94      0.63      0.76       210\n",
      "           4       0.20      0.58      0.30       210\n",
      "           5       0.31      0.26      0.29       210\n",
      "           6       0.33      0.15      0.21       210\n",
      "           7       0.51      0.35      0.41       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.47      0.39      0.40      1470\n",
      "weighted avg       0.47      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  10   2  60  29  18  18]\n",
      " [ 16  91   2  50  24  15  12]\n",
      " [  8  13 135  27  13   6   8]\n",
      " [ 34  11   2  79  25  35  24]\n",
      " [ 21  18   3  59  66  28  15]\n",
      " [ 30  13   2  55  14  54  42]\n",
      " [ 27   4   1  39  12  36  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.35      0.35       210\n",
      "           2       0.57      0.43      0.49       210\n",
      "           3       0.92      0.64      0.76       210\n",
      "           4       0.21      0.38      0.27       210\n",
      "           5       0.36      0.31      0.34       210\n",
      "           6       0.28      0.26      0.27       210\n",
      "           7       0.43      0.43      0.43       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.45      0.40      0.42      1470\n",
      "weighted avg       0.45      0.40      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  12   3  38  33  37  17]\n",
      " [ 16  93   5  48  21  17  10]\n",
      " [  8  12 146  20   8  14   2]\n",
      " [ 25  12   3  76  30  47  17]\n",
      " [ 20  13   5  60  70  33   9]\n",
      " [ 16  16   5  49  30  70  24]\n",
      " [ 12   5   1  38  24  55  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.33      0.37       210\n",
      "           2       0.57      0.44      0.50       210\n",
      "           3       0.87      0.70      0.77       210\n",
      "           4       0.23      0.36      0.28       210\n",
      "           5       0.32      0.33      0.33       210\n",
      "           6       0.26      0.33      0.29       210\n",
      "           7       0.49      0.36      0.41       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.45      0.41      0.42      1470\n",
      "weighted avg       0.45      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70   8   2  39  37  40  14]\n",
      " [ 18  88   5  34  36  20   9]\n",
      " [ 10  12 143  16  16  12   1]\n",
      " [ 26  12   3  71  44  38  16]\n",
      " [ 27  10   2  36 101  27   7]\n",
      " [ 17  13   3  47  34  64  32]\n",
      " [ 11   6   2  31  31  49  80]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.33      0.36       210\n",
      "           2       0.59      0.42      0.49       210\n",
      "           3       0.89      0.68      0.77       210\n",
      "           4       0.26      0.34      0.29       210\n",
      "           5       0.34      0.48      0.40       210\n",
      "           6       0.26      0.30      0.28       210\n",
      "           7       0.50      0.38      0.43       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.46      0.42      0.43      1470\n",
      "weighted avg       0.46      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88  12   2  35  30  27  16]\n",
      " [ 20 101   3  31  33  12  10]\n",
      " [ 19  15 145  16   7   8   0]\n",
      " [ 39  15   5  78  24  34  15]\n",
      " [ 34  27   3  35  74  29   8]\n",
      " [ 26  25   6  48  20  61  24]\n",
      " [ 26  10   0  38  21  44  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.42      0.38       210\n",
      "           2       0.49      0.48      0.49       210\n",
      "           3       0.88      0.69      0.78       210\n",
      "           4       0.28      0.37      0.32       210\n",
      "           5       0.35      0.35      0.35       210\n",
      "           6       0.28      0.29      0.29       210\n",
      "           7       0.49      0.34      0.40       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.45      0.42      0.43      1470\n",
      "weighted avg       0.45      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.42925170068027213\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  14   3  32  37  28  17]\n",
      " [ 16 100   6  37  27  14  10]\n",
      " [ 12  19 145  12  11  10   1]\n",
      " [ 21  16   7  82  29  37  18]\n",
      " [ 28  16   4  39  91  19  13]\n",
      " [ 16  22   6  42  30  56  38]\n",
      " [ 18  14   1  34  19  46  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.38      0.40       210\n",
      "           2       0.50      0.48      0.49       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.29      0.39      0.34       210\n",
      "           5       0.37      0.43      0.40       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.45      0.37      0.41       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.44      1470\n",
      "weighted avg       0.45      0.43      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  15   9  27  34  28  21]\n",
      " [ 16 111  10  21  25  18   9]\n",
      " [  9  20 149  11   8  11   2]\n",
      " [ 29  17   7  69  32  36  20]\n",
      " [ 30  20   8  39  78  18  17]\n",
      " [ 21  25   6  37  26  56  39]\n",
      " [ 25  11   3  31  21  41  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.36      0.37       210\n",
      "           2       0.51      0.53      0.52       210\n",
      "           3       0.78      0.71      0.74       210\n",
      "           4       0.29      0.33      0.31       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.42      0.37      0.39       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.41360544217687073\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  25   8  24  33  24  21]\n",
      " [ 15 110   6  22  23  17  17]\n",
      " [ 11  17 155  12   5   9   1]\n",
      " [ 25  23   8  63  36  35  20]\n",
      " [ 36  28   7  34  71  19  15]\n",
      " [ 24  27   9  35  22  58  35]\n",
      " [ 23  15   5  32  19  40  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.36      0.36       210\n",
      "           2       0.45      0.52      0.48       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.34      0.34      0.34       210\n",
      "           6       0.29      0.28      0.28       210\n",
      "           7       0.41      0.36      0.38       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  19   9  24  33  25  18]\n",
      " [ 15 111   7  28  22  15  12]\n",
      " [ 12  15 155  10   7  10   1]\n",
      " [ 30  20  10  68  32  37  13]\n",
      " [ 29  30   9  41  74  16  11]\n",
      " [ 26  27  11  35  22  56  33]\n",
      " [ 29  13   3  27  30  37  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.39      0.38       210\n",
      "           2       0.47      0.53      0.50       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.29      0.32      0.31       210\n",
      "           5       0.34      0.35      0.34       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.45      0.34      0.38       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  14   8  26  30  30  22]\n",
      " [ 14 108   9  27  27  18   7]\n",
      " [ 12  14 155   9   7  12   1]\n",
      " [ 29  19  11  64  29  37  21]\n",
      " [ 29  21  10  42  76  18  14]\n",
      " [ 24  23   7  42  23  59  32]\n",
      " [ 21  12   3  28  27  41  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38       210\n",
      "           2       0.51      0.51      0.51       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.27      0.30      0.29       210\n",
      "           5       0.35      0.36      0.35       210\n",
      "           6       0.27      0.28      0.28       210\n",
      "           7       0.45      0.37      0.41       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.42517006802721086\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  19   6  29  31  23  18]\n",
      " [ 13 108  10  20  31  15  13]\n",
      " [ 11  13 158   8   7  11   2]\n",
      " [ 28  26   7  63  37  30  19]\n",
      " [ 33  28   8  33  79  17  12]\n",
      " [ 28  21  10  34  24  56  37]\n",
      " [ 27  12   3  24  27  40  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.40      0.39       210\n",
      "           2       0.48      0.51      0.49       210\n",
      "           3       0.78      0.75      0.77       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.33      0.38      0.35       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.43      0.37      0.40       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.43      1470\n",
      "weighted avg       0.43      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.42857142857142855\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  20   8  30  32  22  15]\n",
      " [ 19 100   8  29  21  19  14]\n",
      " [  8  12 159  12   7  10   2]\n",
      " [ 27  17   9  72  28  39  18]\n",
      " [ 26  28  11  40  75  17  13]\n",
      " [ 20  21   8  34  24  62  41]\n",
      " [ 23  11   1  31  25  40  79]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.40      0.40       210\n",
      "           2       0.48      0.48      0.48       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.29      0.34      0.31       210\n",
      "           5       0.35      0.36      0.36       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.43      0.38      0.40       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.43      1470\n",
      "weighted avg       0.43      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.42925170068027213\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  17   4  24  32  30  20]\n",
      " [ 17 107  10  20  24  19  13]\n",
      " [  9  12 159  12   8   8   2]\n",
      " [ 26  18   7  68  31  40  20]\n",
      " [ 29  25  13  33  76  19  15]\n",
      " [ 23  19  11  39  19  59  40]\n",
      " [ 24  12   3  28  29  35  79]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.39       210\n",
      "           2       0.51      0.51      0.51       210\n",
      "           3       0.77      0.76      0.76       210\n",
      "           4       0.30      0.32      0.31       210\n",
      "           5       0.35      0.36      0.35       210\n",
      "           6       0.28      0.28      0.28       210\n",
      "           7       0.42      0.38      0.40       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.43      1470\n",
      "weighted avg       0.43      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  25   7  26  32  24  17]\n",
      " [ 17 102   8  29  24  17  13]\n",
      " [ 11  12 160   9   7   8   3]\n",
      " [ 26  17  14  61  30  39  23]\n",
      " [ 26  27  12  29  75  22  19]\n",
      " [ 25  19  10  38  29  59  30]\n",
      " [ 22  10   6  28  26  36  82]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38       210\n",
      "           2       0.48      0.49      0.48       210\n",
      "           3       0.74      0.76      0.75       210\n",
      "           4       0.28      0.29      0.28       210\n",
      "           5       0.34      0.36      0.35       210\n",
      "           6       0.29      0.28      0.28       210\n",
      "           7       0.44      0.39      0.41       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.2802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  1  18  27   4  16   1 143]\n",
      " [  1  49  42  12  21   2  83]\n",
      " [  3  13 155   5  12   2  20]\n",
      " [  3   7  30   2  16   2 150]\n",
      " [  5   7   8   5  16   0 169]\n",
      " [  1  10  22   4   4   0 169]\n",
      " [  1   7   5   4   3   1 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.00      0.01       210\n",
      "           2       0.44      0.23      0.31       210\n",
      "           3       0.54      0.74      0.62       210\n",
      "           4       0.06      0.01      0.02       210\n",
      "           5       0.18      0.08      0.11       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.90      0.33       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.21      0.28      0.20      1470\n",
      "weighted avg       0.21      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 42  35   4   2  55   0  72]\n",
      " [  0 137  13   0  44   1  15]\n",
      " [  3  45 148   1   4   0   9]\n",
      " [  5  48  14   8  35   3  97]\n",
      " [  3  30   5   0 114   0  58]\n",
      " [  3  43  13   0  23   4 124]\n",
      " [  1  10   3   2  11   2 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.20      0.31       210\n",
      "           2       0.39      0.65      0.49       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.62      0.04      0.07       210\n",
      "           5       0.40      0.54      0.46       210\n",
      "           6       0.40      0.02      0.04       210\n",
      "           7       0.33      0.86      0.47       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.52      0.43      0.37      1470\n",
      "weighted avg       0.52      0.43      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 56  23   2   3  65   1  60]\n",
      " [  2 149   3   1  42   2  11]\n",
      " [  3  52 142   1   4   0   8]\n",
      " [  7  44   9   9  54   7  80]\n",
      " [  2  35   3   1 116   0  53]\n",
      " [  6  41   7   4  33   4 115]\n",
      " [  4  10   0   3  13   4 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.27      0.39       210\n",
      "           2       0.42      0.71      0.53       210\n",
      "           3       0.86      0.68      0.76       210\n",
      "           4       0.41      0.04      0.08       210\n",
      "           5       0.35      0.55      0.43       210\n",
      "           6       0.22      0.02      0.04       210\n",
      "           7       0.35      0.84      0.49       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.39      1470\n",
      "weighted avg       0.47      0.44      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.47619047619047616\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 66  12   1   6  70   5  50]\n",
      " [  2 146   4   3  41   2  12]\n",
      " [  2  41 149   1   6   4   7]\n",
      " [  6  32   6  25  64   5  72]\n",
      " [  4  26   1   1 134   0  44]\n",
      " [  7  31   7   6  42  14 103]\n",
      " [  2   8   0   8  19   7 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.31      0.44       210\n",
      "           2       0.49      0.70      0.58       210\n",
      "           3       0.89      0.71      0.79       210\n",
      "           4       0.50      0.12      0.19       210\n",
      "           5       0.36      0.64      0.46       210\n",
      "           6       0.38      0.07      0.11       210\n",
      "           7       0.37      0.79      0.50       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.53      0.48      0.44      1470\n",
      "weighted avg       0.53      0.48      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 82   5   0   9  67   3  44]\n",
      " [  1 134   4  10  48   7   6]\n",
      " [  8  31 152   6   5   4   4]\n",
      " [  5  28   4  50  53  10  60]\n",
      " [  7  25   0   5 135   1  37]\n",
      " [  4  27   4  16  36  30  93]\n",
      " [  4   6   1  10  22   8 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.39      0.51       210\n",
      "           2       0.52      0.64      0.58       210\n",
      "           3       0.92      0.72      0.81       210\n",
      "           4       0.47      0.24      0.32       210\n",
      "           5       0.37      0.64      0.47       210\n",
      "           6       0.48      0.14      0.22       210\n",
      "           7       0.39      0.76      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.49      1470\n",
      "weighted avg       0.56      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 84   3   0  10  69   8  36]\n",
      " [  0 138   3  10  47   6   6]\n",
      " [  3  26 156   4   9   9   3]\n",
      " [  7  23   4  59  45  18  54]\n",
      " [  6  20   2   7 138   2  35]\n",
      " [  5  20   4  24  29  39  89]\n",
      " [  3   6   0  10  15  13 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.40      0.53       210\n",
      "           2       0.58      0.66      0.62       210\n",
      "           3       0.92      0.74      0.82       210\n",
      "           4       0.48      0.28      0.35       210\n",
      "           5       0.39      0.66      0.49       210\n",
      "           6       0.41      0.19      0.26       210\n",
      "           7       0.42      0.78      0.55       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.57      0.53      0.52      1470\n",
      "weighted avg       0.57      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 85   6   0   7  70   7  35]\n",
      " [  2 134   4  12  41  11   6]\n",
      " [  3  24 159   8   6   7   3]\n",
      " [  6  22   5  64  43  20  50]\n",
      " [ 10  22   1   8 132   4  33]\n",
      " [  7  20   4  23  29  51  76]\n",
      " [  2   4   0  12  15  18 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.40      0.52       210\n",
      "           2       0.58      0.64      0.61       210\n",
      "           3       0.92      0.76      0.83       210\n",
      "           4       0.48      0.30      0.37       210\n",
      "           5       0.39      0.63      0.48       210\n",
      "           6       0.43      0.24      0.31       210\n",
      "           7       0.44      0.76      0.56       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.57      0.53      0.53      1470\n",
      "weighted avg       0.57      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 91   2   0  11  64  14  28]\n",
      " [  1 134   4  19  38   7   7]\n",
      " [  1  21 164   7   7   5   5]\n",
      " [  5  14   6  70  39  35  41]\n",
      " [ 10  18   2  11 135   2  32]\n",
      " [  5  19   2  24  28  55  77]\n",
      " [  2   7   0   6  14  16 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.43      0.56       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.92      0.78      0.85       210\n",
      "           4       0.47      0.33      0.39       210\n",
      "           5       0.42      0.64      0.50       210\n",
      "           6       0.41      0.26      0.32       210\n",
      "           7       0.46      0.79      0.58       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.55      1470\n",
      "weighted avg       0.59      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94   4   1  11  62  13  25]\n",
      " [  1 135   5  16  34  14   5]\n",
      " [  2  19 163   9   5   9   3]\n",
      " [  2  16   4  70  44  37  37]\n",
      " [ 11  15   2  13 138   2  29]\n",
      " [  8  13   6  25  20  68  70]\n",
      " [  2   3   0   8  13  31 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.45      0.57       210\n",
      "           2       0.66      0.64      0.65       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.46      0.33      0.39       210\n",
      "           5       0.44      0.66      0.52       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.48      0.73      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.56      1470\n",
      "weighted avg       0.59      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94   3   0  12  57  17  27]\n",
      " [  1 140   5  13  37   7   7]\n",
      " [  6  16 161  10   5   8   4]\n",
      " [  2   9   3  84  42  33  37]\n",
      " [ 14  16   2   8 136   4  30]\n",
      " [  5  16   3  25  19  67  75]\n",
      " [  3   3   0  15   8  25 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.45      0.56       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.93      0.77      0.84       210\n",
      "           4       0.50      0.40      0.45       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.42      0.32      0.36       210\n",
      "           7       0.46      0.74      0.57       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94   2   0  12  62  15  25]\n",
      " [  3 139   2  19  36   8   3]\n",
      " [  1  17 161   8   8  14   1]\n",
      " [  4  13   3  78  38  39  35]\n",
      " [ 14  17   1   8 139   2  29]\n",
      " [ 10  15   4  22  20  63  76]\n",
      " [  0   1   0   8  11  36 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.45      0.56       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.94      0.77      0.85       210\n",
      "           4       0.50      0.37      0.43       210\n",
      "           5       0.44      0.66      0.53       210\n",
      "           6       0.36      0.30      0.33       210\n",
      "           7       0.48      0.73      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.56      1470\n",
      "weighted avg       0.59      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   1   1  16  53  18  19]\n",
      " [  2 135   4  24  32   8   5]\n",
      " [  3  22 164   7   5   6   3]\n",
      " [  3   9   3  96  38  30  31]\n",
      " [ 13  17   1   9 141   4  25]\n",
      " [ 13  10   4  27  14  74  68]\n",
      " [  1   6   0  11  10  29 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.49      0.59       210\n",
      "           2       0.68      0.64      0.66       210\n",
      "           3       0.93      0.78      0.85       210\n",
      "           4       0.51      0.46      0.48       210\n",
      "           5       0.48      0.67      0.56       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.50      0.73      0.60       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   1   0  11  59  16  22]\n",
      " [  3 136   4  18  35  10   4]\n",
      " [  4  17 159  11   7  10   2]\n",
      " [  5   7   3  90  38  38  29]\n",
      " [ 17  17   2  12 132   1  29]\n",
      " [  6  12   2  19  19  81  71]\n",
      " [  1   6   0   8  12  33 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.48      0.58       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.94      0.76      0.84       210\n",
      "           4       0.53      0.43      0.47       210\n",
      "           5       0.44      0.63      0.52       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.49      0.71      0.58       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.58      1470\n",
      "weighted avg       0.61      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   1   0   8  60  13  27]\n",
      " [  3 143   4  16  31   7   6]\n",
      " [  6  18 164  10   4   7   1]\n",
      " [  5  12   2  90  35  38  28]\n",
      " [ 11  20   0  12 136   7  24]\n",
      " [ 10  10   3  28  21  66  72]\n",
      " [  0   6   0  10   9  27 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.48      0.58       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.95      0.78      0.86       210\n",
      "           4       0.52      0.43      0.47       210\n",
      "           5       0.46      0.65      0.54       210\n",
      "           6       0.40      0.31      0.35       210\n",
      "           7       0.50      0.75      0.60       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.58      1470\n",
      "weighted avg       0.61      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98   3   0  10  59  17  23]\n",
      " [  1 138   5  10  40  12   4]\n",
      " [  7  23 159   7   3   9   2]\n",
      " [ 10   8   2  93  37  32  28]\n",
      " [ 16  17   1   6 139   3  28]\n",
      " [  9  17   1  16  19  86  62]\n",
      " [  1   2   0   9  11  38 149]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.47      0.56       210\n",
      "           2       0.66      0.66      0.66       210\n",
      "           3       0.95      0.76      0.84       210\n",
      "           4       0.62      0.44      0.52       210\n",
      "           5       0.45      0.66      0.54       210\n",
      "           6       0.44      0.41      0.42       210\n",
      "           7       0.50      0.71      0.59       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   3   0  13  53  24  20]\n",
      " [  4 133   4  10  36  15   8]\n",
      " [  5  15 163   7  10  10   0]\n",
      " [  6  12   3  90  35  32  32]\n",
      " [  9  22   0  11 135   5  28]\n",
      " [  9  14   3  24  18  72  70]\n",
      " [  1   3   0  11  15  33 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.46      0.57       210\n",
      "           2       0.66      0.63      0.65       210\n",
      "           3       0.94      0.78      0.85       210\n",
      "           4       0.54      0.43      0.48       210\n",
      "           5       0.45      0.64      0.53       210\n",
      "           6       0.38      0.34      0.36       210\n",
      "           7       0.48      0.70      0.57       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   4   0  15  55  20  19]\n",
      " [  2 136   5  18  33  11   5]\n",
      " [  5  19 163   7   4  11   1]\n",
      " [  7   8   4  90  42  37  22]\n",
      " [ 13  17   1  16 133   2  28]\n",
      " [ 10  14   1  33  18  64  70]\n",
      " [  0   7   0   7  12  30 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.46      0.56       210\n",
      "           2       0.66      0.65      0.66       210\n",
      "           3       0.94      0.78      0.85       210\n",
      "           4       0.48      0.43      0.45       210\n",
      "           5       0.45      0.63      0.52       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.52      0.73      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   4   0  10  57  18  20]\n",
      " [  2 136   5  15  33  12   7]\n",
      " [  6  15 161  10   7   9   2]\n",
      " [  7   9   5  86  43  35  25]\n",
      " [ 19  17   1   9 135   6  23]\n",
      " [  4  14   3  26  15  80  68]\n",
      " [  2   7   0   9  15  27 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.48      0.58       210\n",
      "           2       0.67      0.65      0.66       210\n",
      "           3       0.92      0.77      0.84       210\n",
      "           4       0.52      0.41      0.46       210\n",
      "           5       0.44      0.64      0.52       210\n",
      "           6       0.43      0.38      0.40       210\n",
      "           7       0.51      0.71      0.59       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5829931972789115\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   1   0  17  59  16  20]\n",
      " [  3 138   3  15  34  13   4]\n",
      " [  4  21 164   9   3   7   2]\n",
      " [  5  12   5  93  40  29  26]\n",
      " [ 17  16   1  13 138   1  24]\n",
      " [  9  12   2  29  15  74  69]\n",
      " [  2   4   0  10  12  29 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.46      0.56       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.94      0.78      0.85       210\n",
      "           4       0.50      0.44      0.47       210\n",
      "           5       0.46      0.66      0.54       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.51      0.73      0.60       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   4   0  13  57  15  22]\n",
      " [  1 136   6  12  38  12   5]\n",
      " [  2  22 163   6   6  10   1]\n",
      " [  8   9   3  96  41  34  19]\n",
      " [ 13  23   0  11 134   5  24]\n",
      " [ 11  17   2  24  17  78  61]\n",
      " [  1   2   1  11  10  26 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57       210\n",
      "           2       0.64      0.65      0.64       210\n",
      "           3       0.93      0.78      0.85       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.44      0.64      0.52       210\n",
      "           6       0.43      0.37      0.40       210\n",
      "           7       0.55      0.76      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.454421768707483\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 69   2  17  12  59  12  39]\n",
      " [  5 124  14   8  46   7   6]\n",
      " [  7  47 125   8  13   8   2]\n",
      " [  6  25   9  53  48  17  52]\n",
      " [  9  25   2   9 123   3  39]\n",
      " [ 13  21   9  22  29  41  75]\n",
      " [  5   7   1  17  24  23 133]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.33      0.43       210\n",
      "           2       0.49      0.59      0.54       210\n",
      "           3       0.71      0.60      0.65       210\n",
      "           4       0.41      0.25      0.31       210\n",
      "           5       0.36      0.59      0.45       210\n",
      "           6       0.37      0.20      0.26       210\n",
      "           7       0.38      0.63      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.48      0.45      0.44      1470\n",
      "weighted avg       0.48      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//bert_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[107  11   9  14  50  16   3]\n",
      " [  2 159   4  11  21   9   4]\n",
      " [ 10   5 174  10   8   3   0]\n",
      " [ 16   4  11 129  27  19   4]\n",
      " [ 13  10   8  13 148   5  13]\n",
      " [ 16  15  11  15  11  92  50]\n",
      " [  1   4   1   1   4  28 171]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.51      0.57       210\n",
      "           2       0.76      0.76      0.76       210\n",
      "           3       0.80      0.83      0.81       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.53      0.44      0.48       210\n",
      "           7       0.70      0.81      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5993197278911565\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121   9   4  15  51   6   4]\n",
      " [  6 161   6   6  27   2   2]\n",
      " [ 16   8 170   7   5   4   0]\n",
      " [ 36  16   6  91  50   6   5]\n",
      " [ 36  17   6  17 123   2   9]\n",
      " [ 43  21   6  12  15  57  56]\n",
      " [ 17  10   0   6   7  12 158]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.58      0.50       210\n",
      "           2       0.67      0.77      0.71       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.59      0.43      0.50       210\n",
      "           5       0.44      0.59      0.50       210\n",
      "           6       0.64      0.27      0.38       210\n",
      "           7       0.68      0.75      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.59      1470\n",
      "weighted avg       0.62      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[113   9   4  22  50   7   5]\n",
      " [  4 167   5   6  22   4   2]\n",
      " [ 13   5 170  12   4   6   0]\n",
      " [ 29  10   8 106  43   8   6]\n",
      " [ 31  21   5  23 117   2  11]\n",
      " [ 36  20   4   8  14  66  62]\n",
      " [ 11   8   1   1   3  27 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.54      0.51       210\n",
      "           2       0.70      0.80      0.74       210\n",
      "           3       0.86      0.81      0.84       210\n",
      "           4       0.60      0.50      0.55       210\n",
      "           5       0.46      0.56      0.51       210\n",
      "           6       0.55      0.31      0.40       210\n",
      "           7       0.65      0.76      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  10   5  17  51   6   4]\n",
      " [  6 163   6   7  20   4   4]\n",
      " [ 12   5 171  12   3   7   0]\n",
      " [ 21  10   9 100  57   7   6]\n",
      " [ 25  16   6  20 127   2  14]\n",
      " [ 28  27   3  10  17  64  61]\n",
      " [ 11   6   0   3   6  20 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.56      0.54       210\n",
      "           2       0.69      0.78      0.73       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.59      0.48      0.53       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.58      0.30      0.40       210\n",
      "           7       0.65      0.78      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[113  11   4  21  51   5   5]\n",
      " [  5 163   5   6  25   2   4]\n",
      " [ 12   5 173  10   5   5   0]\n",
      " [ 24   9   9 105  50   7   6]\n",
      " [ 22  17   4  18 134   2  13]\n",
      " [ 34  28   4  11  14  58  61]\n",
      " [ 14   6   0   2   5  23 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52       210\n",
      "           2       0.68      0.78      0.73       210\n",
      "           3       0.87      0.82      0.85       210\n",
      "           4       0.61      0.50      0.55       210\n",
      "           5       0.47      0.64      0.54       210\n",
      "           6       0.57      0.28      0.37       210\n",
      "           7       0.64      0.76      0.70       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[110  11   4  18  56   5   6]\n",
      " [  8 160   5   5  26   1   5]\n",
      " [ 14   4 169  14   4   5   0]\n",
      " [ 23  13   7  97  56   7   7]\n",
      " [ 20  17   5  16 136   3  13]\n",
      " [ 34  24   3  11  14  60  64]\n",
      " [ 13   7   0   1   3  18 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.52      0.51       210\n",
      "           2       0.68      0.76      0.72       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.60      0.46      0.52       210\n",
      "           5       0.46      0.65      0.54       210\n",
      "           6       0.61      0.29      0.39       210\n",
      "           7       0.64      0.80      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.6081632653061224\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[104  13   6  20  53   5   9]\n",
      " [  7 167   5   5  21   1   4]\n",
      " [ 14   7 165  12   8   4   0]\n",
      " [ 23  15   7  93  59   7   6]\n",
      " [ 19  18   4  16 138   3  12]\n",
      " [ 34  21   4  10  13  61  67]\n",
      " [ 11   8   0   1   3  21 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.67      0.80      0.73       210\n",
      "           3       0.86      0.79      0.82       210\n",
      "           4       0.59      0.44      0.51       210\n",
      "           5       0.47      0.66      0.55       210\n",
      "           6       0.60      0.29      0.39       210\n",
      "           7       0.63      0.79      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 54  22   3   6  87  32   6]\n",
      " [  4 119   0   3  53  17  14]\n",
      " [  9   5  98  12  68  18   0]\n",
      " [ 14   8   5  26 112  35  10]\n",
      " [  4  13   0   4 157  16  16]\n",
      " [  9  19   6  11  16  63  86]\n",
      " [  1   6   0   1   2  24 176]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.26      0.35       210\n",
      "           2       0.62      0.57      0.59       210\n",
      "           3       0.88      0.47      0.61       210\n",
      "           4       0.41      0.12      0.19       210\n",
      "           5       0.32      0.75      0.45       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.57      0.84      0.68       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.52      0.47      0.45      1470\n",
      "weighted avg       0.52      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.463265306122449\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 46  25   3  13  81  34   8]\n",
      " [  6 112   0   5  53  21  13]\n",
      " [ 10   8  96  13  65  18   0]\n",
      " [ 18   7   6  37 101  31  10]\n",
      " [  6  18   0   3 153  13  17]\n",
      " [ 12  18   6  13  13  65  83]\n",
      " [  1   7   0   1   2  27 172]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.22      0.30       210\n",
      "           2       0.57      0.53      0.55       210\n",
      "           3       0.86      0.46      0.60       210\n",
      "           4       0.44      0.18      0.25       210\n",
      "           5       0.33      0.73      0.45       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.57      0.82      0.67       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.51      0.46      0.45      1470\n",
      "weighted avg       0.51      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.672108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[111   6   4  16  55  15   3]\n",
      " [  3 157   4   8  23  12   3]\n",
      " [  9   4 174   9   8   6   0]\n",
      " [ 14   1  10 125  39  18   3]\n",
      " [ 15   9   4  13 151   6  12]\n",
      " [ 11  18  10  14  11  95  51]\n",
      " [  2   4   0   2   5  22 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.53      0.59       210\n",
      "           2       0.79      0.75      0.77       210\n",
      "           3       0.84      0.83      0.84       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.52      0.72      0.60       210\n",
      "           6       0.55      0.45      0.49       210\n",
      "           7       0.71      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6979591836734694\n",
      "Confusion Matrix of SVM is:\n",
      " [[120   5   3  14  47  18   3]\n",
      " [  1 163   3   7  21  12   3]\n",
      " [  5   1 180  11   7   6   0]\n",
      " [ 13   1  12 131  32  18   3]\n",
      " [ 16   8   5  12 149   9  11]\n",
      " [ 11  13   9  12   9 110  46]\n",
      " [  2   2   0   2   4  27 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.57      0.63       210\n",
      "           2       0.84      0.78      0.81       210\n",
      "           3       0.85      0.86      0.85       210\n",
      "           4       0.69      0.62      0.66       210\n",
      "           5       0.55      0.71      0.62       210\n",
      "           6       0.55      0.52      0.54       210\n",
      "           7       0.72      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of SVM is:\n",
      " [[117   5   4  13  49  18   4]\n",
      " [  1 160   4   9  22  11   3]\n",
      " [  5   1 181  10   7   6   0]\n",
      " [ 14   1  10 129  36  17   3]\n",
      " [ 13   9   5  17 145   9  12]\n",
      " [ 12  15  10  14   9  98  52]\n",
      " [  2   2   0   1   3  27 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.56      0.63       210\n",
      "           2       0.83      0.76      0.79       210\n",
      "           3       0.85      0.86      0.85       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.54      0.69      0.60       210\n",
      "           6       0.53      0.47      0.49       210\n",
      "           7       0.70      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 83  15  11  22  59  17   3]\n",
      " [  3 138   7  11  33  14   4]\n",
      " [  9   5 171  12   7   6   0]\n",
      " [ 13   7  11 110  43  21   5]\n",
      " [ 11   9   5  10 158   5  12]\n",
      " [ 21  15  13  12  14  81  54]\n",
      " [  4   8   1   0   5  20 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.40      0.47       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.78      0.81      0.80       210\n",
      "           4       0.62      0.52      0.57       210\n",
      "           5       0.50      0.75      0.60       210\n",
      "           6       0.49      0.39      0.43       210\n",
      "           7       0.69      0.82      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.23129251700680273\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0 201   0   0]\n",
      " [  0   0   9   0 201   0   0]\n",
      " [  0   0 130   0  80   0   0]\n",
      " [  0   0   9   0 201   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   8   0 202   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.79      0.62      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.28       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.14      0.23      0.14      1470\n",
      "weighted avg       0.14      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3360544217687075\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  7   0   2   0 189   0  12]\n",
      " [  3   0   6   0 173   0  28]\n",
      " [  0   0 130   0  78   0   2]\n",
      " [  0   0   9   0 186   0  15]\n",
      " [  0   0   0   0 191   0  19]\n",
      " [  1   0   7   0 101   0 101]\n",
      " [  0   0   0   0  44   0 166]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.03      0.06       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.84      0.62      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.20      0.91      0.33       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.48      0.79      0.60       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.31      0.34      0.24      1470\n",
      "weighted avg       0.31      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  7 107   2   0  82   6   6]\n",
      " [  0 151   6   0  25  21   7]\n",
      " [  0  50 130   0  28   2   0]\n",
      " [  0  85   9   0 101  13   2]\n",
      " [  0  60   0   0 131   5  14]\n",
      " [  1  87   7   0  14  50  51]\n",
      " [  0  40   0   0   4  47 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.03      0.06       210\n",
      "           2       0.26      0.72      0.38       210\n",
      "           3       0.84      0.62      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.34      0.62      0.44       210\n",
      "           6       0.35      0.24      0.28       210\n",
      "           7       0.60      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.47      0.40      0.35      1470\n",
      "weighted avg       0.47      0.40      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4170068027210884\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  11   0  47  35   8   5]\n",
      " [ 88  78   6   7  18   8   5]\n",
      " [ 48   3 127  22   6   4   0]\n",
      " [ 77  10   4  67  34  16   2]\n",
      " [ 54   6   0  48  83  10   9]\n",
      " [ 84  17   4   7   7  44  47]\n",
      " [ 39  10   0   2   2  47 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.50      0.30       210\n",
      "           2       0.58      0.37      0.45       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.34      0.32      0.33       210\n",
      "           5       0.45      0.40      0.42       210\n",
      "           6       0.32      0.21      0.25       210\n",
      "           7       0.62      0.52      0.57       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.49      0.42      0.43      1470\n",
      "weighted avg       0.49      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 45   7   0  12  75  64   7]\n",
      " [  8  68   5   5  26  90   8]\n",
      " [ 30   3 126  19  10  21   1]\n",
      " [ 15   9   2  32  72  69  11]\n",
      " [ 12   6   0  11 123  47  11]\n",
      " [ 11  14   3   5  12  93  72]\n",
      " [  1  15   0   0   5  56 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.21      0.27       210\n",
      "           2       0.56      0.32      0.41       210\n",
      "           3       0.93      0.60      0.73       210\n",
      "           4       0.38      0.15      0.22       210\n",
      "           5       0.38      0.59      0.46       210\n",
      "           6       0.21      0.44      0.29       210\n",
      "           7       0.55      0.63      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.42      1470\n",
      "weighted avg       0.48      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.47687074829931975\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57  19   7  14  54  53   6]\n",
      " [ 15 123   6   4  20  35   7]\n",
      " [ 11  11 160   8   6  13   1]\n",
      " [ 20  20   4  39  58  65   4]\n",
      " [ 20  19   6  14 107  34  10]\n",
      " [ 14  27   4   6   9  98  52]\n",
      " [  2  15   0   0   6  70 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.27      0.33       210\n",
      "           2       0.53      0.59      0.55       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.46      0.19      0.26       210\n",
      "           5       0.41      0.51      0.46       210\n",
      "           6       0.27      0.47      0.34       210\n",
      "           7       0.59      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.47      1470\n",
      "weighted avg       0.50      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  15   2  59  49  14   6]\n",
      " [ 11 121   5  33  21  15   4]\n",
      " [ 10  12 156  20   6   5   1]\n",
      " [ 23   9   3 107  39  25   4]\n",
      " [ 16  17   5  52 101   9  10]\n",
      " [ 15  27   2  51   6  56  53]\n",
      " [  4  19   0  16   5  47 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.31      0.37       210\n",
      "           2       0.55      0.58      0.56       210\n",
      "           3       0.90      0.74      0.81       210\n",
      "           4       0.32      0.51      0.39       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.33      0.27      0.29       210\n",
      "           7       0.60      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.51      0.49      0.50      1470\n",
      "weighted avg       0.51      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48367346938775513\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60  12   2  54  53  19  10]\n",
      " [ 17 112   7  30  19  18   7]\n",
      " [ 18   3 157  17   7   7   1]\n",
      " [ 17   5   4 106  44  24  10]\n",
      " [ 20  15   6  51  96   8  14]\n",
      " [ 25  15   5  42   5  59  59]\n",
      " [  8   9   1  15   5  51 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.29      0.32       210\n",
      "           2       0.65      0.53      0.59       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.34      0.50      0.40       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.32      0.28      0.30       210\n",
      "           7       0.55      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.49      1470\n",
      "weighted avg       0.50      0.48      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  15   4  30  47  22   7]\n",
      " [ 18 120  12  18  20  16   6]\n",
      " [ 15   7 164  11   6   6   1]\n",
      " [ 30  10   4  92  43  25   6]\n",
      " [ 31  18   8  35  95  10  13]\n",
      " [ 29  19   8  32  12  57  53]\n",
      " [ 12  11   1  14   3  51 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.40       210\n",
      "           2       0.60      0.57      0.59       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.40      0.44      0.42       210\n",
      "           5       0.42      0.45      0.44       210\n",
      "           6       0.30      0.27      0.29       210\n",
      "           7       0.58      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  11   2  35  53  24   9]\n",
      " [ 14 115  10  18  32  14   7]\n",
      " [ 12   6 164   9  11   6   2]\n",
      " [ 30  10   8  90  43  23   6]\n",
      " [ 26  17   6  32 106  11  12]\n",
      " [ 25  24   9  25  14  56  57]\n",
      " [ 16  11   1  11   6  45 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.36      0.37       210\n",
      "           2       0.59      0.55      0.57       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.40      0.50      0.45       210\n",
      "           6       0.31      0.27      0.29       210\n",
      "           7       0.56      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.49      1470\n",
      "weighted avg       0.50      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48707482993197276\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   8   5  27  45  31  14]\n",
      " [ 16 113  10  22  26  17   6]\n",
      " [ 12   5 166  13   6   6   2]\n",
      " [ 30  13  10  85  36  31   5]\n",
      " [ 25  14   7  30  98  26  10]\n",
      " [ 23  28  10  24  16  55  54]\n",
      " [ 11  11   1  16   8  44 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.38      0.39       210\n",
      "           2       0.59      0.54      0.56       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.39      0.40      0.40       210\n",
      "           5       0.42      0.47      0.44       210\n",
      "           6       0.26      0.26      0.26       210\n",
      "           7       0.57      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49183673469387756\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76   8   7  36  41  28  14]\n",
      " [ 12 115  10  22  27  16   8]\n",
      " [ 11   5 167  14   5   6   2]\n",
      " [ 36   8  10  88  35  28   5]\n",
      " [ 25  10   8  33 104  18  12]\n",
      " [ 27  22  10  20  12  55  64]\n",
      " [ 25  13   2   7   6  39 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.36      0.36       210\n",
      "           2       0.64      0.55      0.59       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.40      0.42      0.41       210\n",
      "           5       0.45      0.50      0.47       210\n",
      "           6       0.29      0.26      0.28       210\n",
      "           7       0.53      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  17   8  29  37  31  10]\n",
      " [ 13 117   9  20  27  16   8]\n",
      " [ 10   5 168  13   6   4   4]\n",
      " [ 37  20  10  82  31  24   6]\n",
      " [ 31  12   9  26  98  14  20]\n",
      " [ 22  27  17  27  13  52  52]\n",
      " [ 24  11   4   7   6  41 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.37      0.37       210\n",
      "           2       0.56      0.56      0.56       210\n",
      "           3       0.75      0.80      0.77       210\n",
      "           4       0.40      0.39      0.40       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.29      0.25      0.27       210\n",
      "           7       0.54      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  14  13  30  41  25  11]\n",
      " [ 13 118  12  12  32  16   7]\n",
      " [ 13   5 166  12   7   4   3]\n",
      " [ 30  11   7  86  35  31  10]\n",
      " [ 34  12   8  25  94  23  14]\n",
      " [ 23  28  12  19  18  57  53]\n",
      " [ 27  14   1   8   5  40 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.36      0.36       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.76      0.79      0.77       210\n",
      "           4       0.45      0.41      0.43       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.54      0.55      0.54       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  15   8  32  39  26  10]\n",
      " [ 19 111  13  15  25  17  10]\n",
      " [ 10   6 169   7  10   5   3]\n",
      " [ 32  13  17  83  29  28   8]\n",
      " [ 29  17   7  32  93  19  13]\n",
      " [ 21  23  17  21  16  59  53]\n",
      " [ 11  14   5  10   8  45 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.38      0.39       210\n",
      "           2       0.56      0.53      0.54       210\n",
      "           3       0.72      0.80      0.76       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.30      0.28      0.29       210\n",
      "           7       0.55      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  15   9  25  45  28  14]\n",
      " [ 15 116  13  12  29  17   8]\n",
      " [ 11   6 170  10   5   5   3]\n",
      " [ 38  18  18  76  33  19   8]\n",
      " [ 38  21   8  27  86  17  13]\n",
      " [ 21  20  17  23  16  55  58]\n",
      " [ 20  12   4  12   6  37 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.35       210\n",
      "           2       0.56      0.55      0.56       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.41      0.36      0.38       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.53      0.57      0.55       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.47      1470\n",
      "weighted avg       0.46      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.47687074829931975\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  14  10  31  43  25  11]\n",
      " [ 15 110   9  19  30  18   9]\n",
      " [ 11   9 168   9   5   4   4]\n",
      " [ 30  13  14  90  30  25   8]\n",
      " [ 35  21   9  32  89  12  12]\n",
      " [ 22  24  14  23  17  50  60]\n",
      " [ 18  12   4   9  10  39 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.36      0.36       210\n",
      "           2       0.54      0.52      0.53       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.29      0.24      0.26       210\n",
      "           7       0.53      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.47      0.48      0.47      1470\n",
      "weighted avg       0.47      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  14  11  31  37  26  14]\n",
      " [ 15 123  10  14  26  15   7]\n",
      " [  9   9 169   9   9   3   2]\n",
      " [ 32   9  13  86  42  18  10]\n",
      " [ 38  22   8  28  88  11  15]\n",
      " [ 18  24  18  23  12  60  55]\n",
      " [ 18  12   3  10   7  39 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.37      0.37       210\n",
      "           2       0.58      0.59      0.58       210\n",
      "           3       0.73      0.80      0.76       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.35      0.29      0.31       210\n",
      "           7       0.54      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.49      1470\n",
      "weighted avg       0.48      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  14  13  28  38  25  14]\n",
      " [ 16 116   9  13  30  20   6]\n",
      " [  8   7 168  12   9   5   1]\n",
      " [ 30  13  16  79  39  23  10]\n",
      " [ 38  19   8  30  84  13  18]\n",
      " [ 21  17  10  29  18  53  62]\n",
      " [ 16  11   4  12   8  41 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.37      0.37       210\n",
      "           2       0.59      0.55      0.57       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.39      0.38      0.38       210\n",
      "           5       0.37      0.40      0.39       210\n",
      "           6       0.29      0.25      0.27       210\n",
      "           7       0.52      0.56      0.54       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  14   9  29  36  24  17]\n",
      " [ 15 122  12  13  26  15   7]\n",
      " [ 12   6 172  10   3   5   2]\n",
      " [ 40  17   7  86  30  19  11]\n",
      " [ 28  18   6  36  87  19  16]\n",
      " [ 21  24  15  22  14  53  61]\n",
      " [ 16  11   4  12   9  37 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.39      0.38       210\n",
      "           2       0.58      0.58      0.58       210\n",
      "           3       0.76      0.82      0.79       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.42      0.41      0.42       210\n",
      "           6       0.31      0.25      0.28       210\n",
      "           7       0.51      0.58      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.49      1470\n",
      "weighted avg       0.48      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.3904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  2  14  14   2 116   0  62]\n",
      " [  1  41  10   0  76   0  82]\n",
      " [  2   2 154   1  39   1  11]\n",
      " [  2   4  11   4 144   0  45]\n",
      " [  0   7   2   0 169   0  32]\n",
      " [  1  12  15   2  33   0 147]\n",
      " [  1   2   1   0   2   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.01      0.02       210\n",
      "           2       0.50      0.20      0.28       210\n",
      "           3       0.74      0.73      0.74       210\n",
      "           4       0.44      0.02      0.04       210\n",
      "           5       0.29      0.80      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.97      0.51       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.36      0.39      0.29      1470\n",
      "weighted avg       0.36      0.39      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20  24   9   0 117   3  37]\n",
      " [  0  90  12   0  68   0  40]\n",
      " [  0   9 158   0  39   1   3]\n",
      " [  2  21  12   3 140   2  30]\n",
      " [  0  11   1   0 172   0  26]\n",
      " [  1  23  16   0  34   5 131]\n",
      " [  1   6   1   0   3   0 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.10      0.17       210\n",
      "           2       0.49      0.43      0.46       210\n",
      "           3       0.76      0.75      0.75       210\n",
      "           4       1.00      0.01      0.03       210\n",
      "           5       0.30      0.82      0.44       210\n",
      "           6       0.45      0.02      0.05       210\n",
      "           7       0.43      0.95      0.59       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.61      0.44      0.35      1470\n",
      "weighted avg       0.61      0.44      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.48299319727891155\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 30  45   3  10  92  12  18]\n",
      " [  1 136   4   0  48   0  21]\n",
      " [  2  20 149   7  31   0   1]\n",
      " [  3  32   9  22 114  13  17]\n",
      " [  2  21   1   2 158   2  24]\n",
      " [  7  39   9   6  19  22 108]\n",
      " [  0  12   1   1   1   2 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.14      0.24       210\n",
      "           2       0.45      0.65      0.53       210\n",
      "           3       0.85      0.71      0.77       210\n",
      "           4       0.46      0.10      0.17       210\n",
      "           5       0.34      0.75      0.47       210\n",
      "           6       0.43      0.10      0.17       210\n",
      "           7       0.51      0.92      0.65       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.53      0.48      0.43      1470\n",
      "weighted avg       0.53      0.48      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 54  25   2  20  76  23  10]\n",
      " [  2 138   3  11  34   8  14]\n",
      " [ 11   8 154  22  11   4   0]\n",
      " [ 14  15   9  65  71  24  12]\n",
      " [  4  18   1   9 150   9  19]\n",
      " [ 13  28   9  11  13  38  98]\n",
      " [  0  11   1   1   3   7 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.26      0.35       210\n",
      "           2       0.57      0.66      0.61       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.47      0.31      0.37       210\n",
      "           5       0.42      0.71      0.53       210\n",
      "           6       0.34      0.18      0.24       210\n",
      "           7       0.55      0.89      0.68       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.51      1470\n",
      "weighted avg       0.54      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 62  22   1  25  66  26   8]\n",
      " [  1 140   1  14  27  15  12]\n",
      " [ 11   7 158  17   9   7   1]\n",
      " [ 14   8   8  83  57  30  10]\n",
      " [  8  17   1  14 143   8  19]\n",
      " [ 12  22   6  13   9  58  90]\n",
      " [  0   7   0   1   3  20 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.30      0.39       210\n",
      "           2       0.63      0.67      0.65       210\n",
      "           3       0.90      0.75      0.82       210\n",
      "           4       0.50      0.40      0.44       210\n",
      "           5       0.46      0.68      0.55       210\n",
      "           6       0.35      0.28      0.31       210\n",
      "           7       0.56      0.85      0.68       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5850340136054422\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77  18   0  21  62  26   6]\n",
      " [  2 141   2  15  25  18   7]\n",
      " [ 11   4 164  19   6   5   1]\n",
      " [ 18   8   7  91  46  31   9]\n",
      " [ 12  18   2  11 140   9  18]\n",
      " [ 13  22   4  14   7  70  80]\n",
      " [  0   6   0   1   3  23 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.37      0.45       210\n",
      "           2       0.65      0.67      0.66       210\n",
      "           3       0.92      0.78      0.84       210\n",
      "           4       0.53      0.43      0.48       210\n",
      "           5       0.48      0.67      0.56       210\n",
      "           6       0.38      0.33      0.36       210\n",
      "           7       0.59      0.84      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  16   1  21  59  26   4]\n",
      " [  4 139   3  12  26  14  12]\n",
      " [ 12   4 166  14   6   8   0]\n",
      " [ 14   7   2 103  42  33   9]\n",
      " [ 10  16   2  11 145   9  17]\n",
      " [ 14  25   3  12   8  66  82]\n",
      " [  1   7   0   2   2  18 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.65      0.66      0.66       210\n",
      "           3       0.94      0.79      0.86       210\n",
      "           4       0.59      0.49      0.54       210\n",
      "           5       0.50      0.69      0.58       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.59      0.86      0.70       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6074829931972789\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89  14   0  21  55  24   7]\n",
      " [  0 144   3  14  22  19   8]\n",
      " [ 10   1 166  15   9   8   1]\n",
      " [ 14   3   0 104  47  35   7]\n",
      " [ 15  15   1  17 135   9  18]\n",
      " [ 14  20   4  13   6  76  77]\n",
      " [  3   3   0   1   2  22 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.42      0.50       210\n",
      "           2       0.72      0.69      0.70       210\n",
      "           3       0.95      0.79      0.86       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.49      0.64      0.56       210\n",
      "           6       0.39      0.36      0.38       210\n",
      "           7       0.60      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  10   0  20  57  27   6]\n",
      " [  0 146   2  13  26  14   9]\n",
      " [ 10   3 166  15   5  11   0]\n",
      " [ 11   5   1 116  39  31   7]\n",
      " [  9  12   3  21 137  11  17]\n",
      " [ 11  19   3  13   9  83  72]\n",
      " [  0   4   0   2   2  26 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.43      0.53       210\n",
      "           2       0.73      0.70      0.71       210\n",
      "           3       0.95      0.79      0.86       210\n",
      "           4       0.58      0.55      0.57       210\n",
      "           5       0.50      0.65      0.56       210\n",
      "           6       0.41      0.40      0.40       210\n",
      "           7       0.61      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94   8   1  16  55  27   9]\n",
      " [  2 147   3  10  23  19   6]\n",
      " [  9   4 170  12   5  10   0]\n",
      " [ 20   5   0 107  40  27  11]\n",
      " [ 13  14   3  16 136   9  19]\n",
      " [  9  18   4  14   7  79  79]\n",
      " [  3   4   0   1   2  23 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.45      0.52       210\n",
      "           2       0.73      0.70      0.72       210\n",
      "           3       0.94      0.81      0.87       210\n",
      "           4       0.61      0.51      0.55       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.41      0.38      0.39       210\n",
      "           7       0.59      0.84      0.69       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  12   0  15  58  25   8]\n",
      " [  2 147   3  13  24  12   9]\n",
      " [  8   1 168  12   8  12   1]\n",
      " [ 17   3   4 112  39  26   9]\n",
      " [ 15  11   3  10 143  13  15]\n",
      " [ 10  19   2  13  11  87  68]\n",
      " [  3   2   0   2   2  24 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.44      0.52       210\n",
      "           2       0.75      0.70      0.73       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.63      0.53      0.58       210\n",
      "           5       0.50      0.68      0.58       210\n",
      "           6       0.44      0.41      0.43       210\n",
      "           7       0.62      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  11   1  18  59  23   5]\n",
      " [  2 148   6   9  23  15   7]\n",
      " [  8   5 166  12   6  13   0]\n",
      " [ 18   5   3 114  35  26   9]\n",
      " [ 10  11   3  22 136  11  17]\n",
      " [ 14  19   3  15   7  74  78]\n",
      " [  2   2   0   2   2  27 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.44      0.52       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.91      0.79      0.85       210\n",
      "           4       0.59      0.54      0.57       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.39      0.35      0.37       210\n",
      "           7       0.60      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.61      1470\n",
      "weighted avg       0.63      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  12   2  21  53  26   4]\n",
      " [  2 151   3  12  17  18   7]\n",
      " [  9   3 174   9   6   8   1]\n",
      " [ 17   4   2 120  36  23   8]\n",
      " [ 17  11   3  14 137  12  16]\n",
      " [ 12  18   3  13  12  72  80]\n",
      " [  1   3   0   1   2  28 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.44      0.51       210\n",
      "           2       0.75      0.72      0.73       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.52      0.65      0.58       210\n",
      "           6       0.39      0.34      0.36       210\n",
      "           7       0.60      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   8   0  19  53  21   6]\n",
      " [  4 148   2  11  21  18   6]\n",
      " [ 10   6 168  10   5  11   0]\n",
      " [ 16   2   3 120  36  27   6]\n",
      " [ 15  13   3  21 134   6  18]\n",
      " [ 16  10   4  12  12  85  71]\n",
      " [  3   3   0   0   2  30 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.49      0.55       210\n",
      "           2       0.78      0.70      0.74       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.51      0.64      0.57       210\n",
      "           6       0.43      0.40      0.42       210\n",
      "           7       0.62      0.82      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   6   1  16  52  27   4]\n",
      " [  0 152   2  10  19  20   7]\n",
      " [ 11   2 172   9   7   9   0]\n",
      " [ 16   2   2 123  34  24   9]\n",
      " [ 15   9   3  20 136  10  17]\n",
      " [  8  19   3  14  10  91  65]\n",
      " [  3   4   0   1   1  29 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.50      0.57       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.94      0.82      0.88       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.53      0.65      0.58       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.63      0.82      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94  13   0  20  52  23   8]\n",
      " [  3 150   4  13  18  15   7]\n",
      " [  7   3 168  12   5  14   1]\n",
      " [ 18   6   4 114  38  23   7]\n",
      " [ 13  12   3  24 128  14  16]\n",
      " [ 16  17   3  16  10  77  71]\n",
      " [  2   5   0   0   3  30 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.45      0.52       210\n",
      "           2       0.73      0.71      0.72       210\n",
      "           3       0.92      0.80      0.86       210\n",
      "           4       0.57      0.54      0.56       210\n",
      "           5       0.50      0.61      0.55       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.61      0.81      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   8   0  19  52  21   6]\n",
      " [  1 143   4  17  18  22   5]\n",
      " [  8   5 172  10   4  10   1]\n",
      " [ 16   4   3 121  31  27   8]\n",
      " [ 19  11   4  13 136  10  17]\n",
      " [  9  20   3  16  10  81  71]\n",
      " [  2   5   0   2   2  25 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.50      0.56       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.61      0.58      0.59       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.62      0.83      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   9   1  20  52  23   5]\n",
      " [  1 150   3   7  26  19   4]\n",
      " [  9   1 171  12   5  12   0]\n",
      " [ 14   2   5 118  37  24  10]\n",
      " [ 21  12   2  16 132  11  16]\n",
      " [ 14  16   4  11  11  86  68]\n",
      " [  1   5   0   3   2  28 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.77      0.71      0.74       210\n",
      "           3       0.92      0.81      0.86       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.50      0.63      0.56       210\n",
      "           6       0.42      0.41      0.42       210\n",
      "           7       0.62      0.81      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6319727891156462\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   8   1  18  50  27   6]\n",
      " [  2 142   3  13  25  17   8]\n",
      " [ 11   2 173  12   3   9   0]\n",
      " [ 15   5   3 126  30  22   9]\n",
      " [ 14  11   3  20 135  13  14]\n",
      " [ 12  19   4  15   9  82  69]\n",
      " [  2   5   1   3   2  26 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.48      0.55       210\n",
      "           2       0.74      0.68      0.71       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.53      0.64      0.58       210\n",
      "           6       0.42      0.39      0.40       210\n",
      "           7       0.62      0.81      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6319727891156462\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   7   0  19  52  26   6]\n",
      " [  2 147   4  12  24  15   6]\n",
      " [ 10   1 172  11   5  10   1]\n",
      " [ 16   4   3 117  35  25  10]\n",
      " [ 18  12   3  18 134   8  17]\n",
      " [ 13  15   4  16   7  86  69]\n",
      " [  1   5   0   2   3  26 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.44      0.41      0.42       210\n",
      "           7       0.61      0.82      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 44  25   4  16  82  32   7]\n",
      " [  5 118   4   6  51  10  16]\n",
      " [ 11   6  99  16  63  15   0]\n",
      " [ 17  11   7  43  95  28   9]\n",
      " [  5  17   0   6 154  11  17]\n",
      " [  8  24   8  11  18  58  83]\n",
      " [  1   7   0   1   2  25 174]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.21      0.29       210\n",
      "           2       0.57      0.56      0.56       210\n",
      "           3       0.81      0.47      0.60       210\n",
      "           4       0.43      0.20      0.28       210\n",
      "           5       0.33      0.73      0.46       210\n",
      "           6       0.32      0.28      0.30       210\n",
      "           7       0.57      0.83      0.67       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.50      0.47      0.45      1470\n",
      "weighted avg       0.50      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.3707482993197279\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 83   2  20   1  54   8  42]\n",
      " [ 21  78  18   1  57  10  25]\n",
      " [ 19  34 120   0  15  10  12]\n",
      " [ 23  12  10   6  79  10  70]\n",
      " [ 31   4   1   1 107   3  63]\n",
      " [ 20  10  10   2  46  12 110]\n",
      " [  1   7   0   1  56   6 139]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.40      0.41       210\n",
      "           2       0.53      0.37      0.44       210\n",
      "           3       0.67      0.57      0.62       210\n",
      "           4       0.50      0.03      0.05       210\n",
      "           5       0.26      0.51      0.34       210\n",
      "           6       0.20      0.06      0.09       210\n",
      "           7       0.30      0.66      0.41       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.34      1470\n",
      "weighted avg       0.41      0.37      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   3   3  13  44   6   2]\n",
      " [ 25 120  14  17  30   2   2]\n",
      " [ 16  13 165   4   8   4   0]\n",
      " [ 41  17  11  94  31   8   8]\n",
      " [ 55  10   0  21 110   5   9]\n",
      " [ 47  27   4  40  15  38  39]\n",
      " [ 24  18   2  26  28  13  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.66      0.50       210\n",
      "           2       0.58      0.57      0.57       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.44      0.45      0.44       210\n",
      "           5       0.41      0.52      0.46       210\n",
      "           6       0.50      0.18      0.27       210\n",
      "           7       0.62      0.47      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.51      1470\n",
      "weighted avg       0.54      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129   4   3  19  41  10   4]\n",
      " [ 20 123  11  13  31   3   9]\n",
      " [ 16  12 163   5  11   3   0]\n",
      " [ 35  13  11  89  38   8  16]\n",
      " [ 54   6   1  25 104   5  15]\n",
      " [ 42  16   6  35  19  43  49]\n",
      " [ 21  14   1  15  29  25 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.61      0.49       210\n",
      "           2       0.65      0.59      0.62       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.38      0.50      0.43       210\n",
      "           6       0.44      0.20      0.28       210\n",
      "           7       0.53      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.51      1470\n",
      "weighted avg       0.53      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[116   3   1  17  56  10   7]\n",
      " [ 19 113  13  17  33   4  11]\n",
      " [ 16  11 166   3  11   3   0]\n",
      " [ 31  12  10  95  37  10  15]\n",
      " [ 43   8   2  22 115   4  16]\n",
      " [ 37  12   7  42  24  37  51]\n",
      " [ 15   7   0  14  30  36 108]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.55      0.48       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.38      0.55      0.45       210\n",
      "           6       0.36      0.18      0.24       210\n",
      "           7       0.52      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120   3   1  13  52   9  12]\n",
      " [ 23 110  12  15  35   6   9]\n",
      " [ 18  11 164   5   9   2   1]\n",
      " [ 36  14   7  90  39   9  15]\n",
      " [ 40  10   2  25 114   5  14]\n",
      " [ 32  11   7  41  34  33  52]\n",
      " [ 10   6   0  17  29  32 116]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.57      0.49       210\n",
      "           2       0.67      0.52      0.59       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.44      0.43      0.43       210\n",
      "           5       0.37      0.54      0.44       210\n",
      "           6       0.34      0.16      0.22       210\n",
      "           7       0.53      0.55      0.54       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120   3   1  12  50   9  15]\n",
      " [ 18 115  11  14  38   5   9]\n",
      " [ 17  11 162   6   9   4   1]\n",
      " [ 31  11   7  90  44  11  16]\n",
      " [ 37  10   2  23 119   3  16]\n",
      " [ 27  10   7  44  31  36  55]\n",
      " [  8   5   0  17  29  29 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.57      0.51       210\n",
      "           2       0.70      0.55      0.61       210\n",
      "           3       0.85      0.77      0.81       210\n",
      "           4       0.44      0.43      0.43       210\n",
      "           5       0.37      0.57      0.45       210\n",
      "           6       0.37      0.17      0.23       210\n",
      "           7       0.52      0.58      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.51      1470\n",
      "weighted avg       0.53      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117   2   1  10  55  10  15]\n",
      " [ 20 112  11  15  37   5  10]\n",
      " [ 19  15 157   6   9   3   1]\n",
      " [ 34   8   9  85  46  12  16]\n",
      " [ 35   8   2  22 117   4  22]\n",
      " [ 29   9   7  41  30  35  59]\n",
      " [  7   5   0  15  28  27 128]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.56      0.50       210\n",
      "           2       0.70      0.53      0.61       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.36      0.56      0.44       210\n",
      "           6       0.36      0.17      0.23       210\n",
      "           7       0.51      0.61      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 63   2  11   9  72  12  41]\n",
      " [  0 141   2   8  41   7  11]\n",
      " [  3  32 148  10   6   8   3]\n",
      " [  4  14  13  68  40   6  65]\n",
      " [ 14  14   1  10 124   1  46]\n",
      " [  7  14  11  27  23  29  99]\n",
      " [  0   8   0  13  14  19 156]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.30      0.42       210\n",
      "           2       0.63      0.67      0.65       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.47      0.32      0.38       210\n",
      "           5       0.39      0.59      0.47       210\n",
      "           6       0.35      0.14      0.20       210\n",
      "           7       0.37      0.74      0.49       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.48      1470\n",
      "weighted avg       0.53      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.4993197278911565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 85   5  12   9  46  17  36]\n",
      " [  1 148   6   6  32   7  10]\n",
      " [  5  17 155  16   4   9   4]\n",
      " [  7  19  16  75  23  15  55]\n",
      " [ 27  20   0   9 108   2  44]\n",
      " [ 15  26  12  27  13  32  85]\n",
      " [  0  16   0  23  10  30 131]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.40      0.49       210\n",
      "           2       0.59      0.70      0.64       210\n",
      "           3       0.77      0.74      0.75       210\n",
      "           4       0.45      0.36      0.40       210\n",
      "           5       0.46      0.51      0.48       210\n",
      "           6       0.29      0.15      0.20       210\n",
      "           7       0.36      0.62      0.46       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.3013605442176871\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 61   2  12   0  76   5  54]\n",
      " [  5  32   0   0  99  32  42]\n",
      " [ 13   2  86   0  66  20  23]\n",
      " [  9   4   2   1 104   8  82]\n",
      " [  6   0   0   0 116  10  78]\n",
      " [  8   5   6   0  63   7 121]\n",
      " [  1   0   0   0  69   0 140]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.29      0.39       210\n",
      "           2       0.71      0.15      0.25       210\n",
      "           3       0.81      0.41      0.54       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.20      0.55      0.29       210\n",
      "           6       0.09      0.03      0.05       210\n",
      "           7       0.26      0.67      0.37       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.52      0.30      0.27      1470\n",
      "weighted avg       0.52      0.30      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.3693877551020408\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 70   3  11   2  68  14  42]\n",
      " [  7  88   0   1  75  17  22]\n",
      " [ 18  39  97  10  22  13  11]\n",
      " [ 10  13   2   7  90  22  66]\n",
      " [ 18   3   0   1 132   6  50]\n",
      " [  9  10   6   2  57  13 113]\n",
      " [  0   2   0   4  64   4 136]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.33      0.41       210\n",
      "           2       0.56      0.42      0.48       210\n",
      "           3       0.84      0.46      0.60       210\n",
      "           4       0.26      0.03      0.06       210\n",
      "           5       0.26      0.63      0.37       210\n",
      "           6       0.15      0.06      0.09       210\n",
      "           7       0.31      0.65      0.42       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.34      1470\n",
      "weighted avg       0.41      0.37      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.3299319727891156\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 57   3  11   1  71  21  46]\n",
      " [  9  73   0   0  87  16  25]\n",
      " [ 21  29  88  12  31  12  17]\n",
      " [  8  16   2   0  94  18  72]\n",
      " [ 12   3   0   0 123  12  60]\n",
      " [  9  10   6   0  63   8 114]\n",
      " [  0   1   0   0  70   3 136]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.27      0.35       210\n",
      "           2       0.54      0.35      0.42       210\n",
      "           3       0.82      0.42      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.59      0.33       210\n",
      "           6       0.09      0.04      0.05       210\n",
      "           7       0.29      0.65      0.40       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.35      0.33      0.30      1470\n",
      "weighted avg       0.35      0.33      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.254421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 35   0  12   0  71   2  90]\n",
      " [  0   6   0   1 108  12  83]\n",
      " [  5   0  88   0  61  11  45]\n",
      " [  0   0   2   3  88   2 115]\n",
      " [  2   0   0   3  79   3 123]\n",
      " [  2   0   7   4  46   3 148]\n",
      " [  0   0   0   0  50   0 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.17      0.28       210\n",
      "           2       1.00      0.03      0.06       210\n",
      "           3       0.81      0.42      0.55       210\n",
      "           4       0.27      0.01      0.03       210\n",
      "           5       0.16      0.38      0.22       210\n",
      "           6       0.09      0.01      0.02       210\n",
      "           7       0.21      0.76      0.33       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.48      0.25      0.21      1470\n",
      "weighted avg       0.48      0.25      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.23605442176870747\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0   0   0 197]\n",
      " [  0   0  18   0   0   0 192]\n",
      " [  0   0 137   0   0   0  73]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   7   0   0   0 203]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.65      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.13      0.24      0.14      1470\n",
      "weighted avg       0.13      0.24      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.32108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 12 168   1   0   0   0  29]\n",
      " [ 10 179   8   0   0   0  13]\n",
      " [  1  68 136   0   0   0   5]\n",
      " [  2 148   3   0   0   0  57]\n",
      " [  1 163   4   0   0   0  42]\n",
      " [  2 113   5   0   0   0  90]\n",
      " [  0  65   0   0   0   0 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.06      0.10       210\n",
      "           2       0.20      0.85      0.32       210\n",
      "           3       0.87      0.65      0.74       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.69      0.49       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.27      0.32      0.24      1470\n",
      "weighted avg       0.27      0.32      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[176   4   1   0   0  19  10]\n",
      " [116  77   4   0   0   9   4]\n",
      " [ 65   8 132   0   0   1   4]\n",
      " [141  10   2   0   0  31  26]\n",
      " [161   4   3   0   0  18  24]\n",
      " [106  10   4   0   0  28  62]\n",
      " [ 62   3   0   0   0  30 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.84      0.34       210\n",
      "           2       0.66      0.37      0.47       210\n",
      "           3       0.90      0.63      0.74       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.21      0.13      0.16       210\n",
      "           7       0.47      0.55      0.51       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.35      0.36      0.32      1470\n",
      "weighted avg       0.35      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.39931972789115644\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   3   1  79   0  18  11]\n",
      " [ 12  77   4 104   0   8   5]\n",
      " [ 25   8 132  40   0   1   4]\n",
      " [  6   8   2 137   0  31  26]\n",
      " [ 50   4   2 111   0  17  26]\n",
      " [  9   7   4  99   0  24  67]\n",
      " [  1   3   0  61   0  26 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.47      0.48       210\n",
      "           2       0.70      0.37      0.48       210\n",
      "           3       0.91      0.63      0.74       210\n",
      "           4       0.22      0.65      0.33       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.19      0.11      0.14       210\n",
      "           7       0.46      0.57      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.38      1470\n",
      "weighted avg       0.42      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93   2   6  48  37  16   8]\n",
      " [  5  71  13  53  55   8   5]\n",
      " [  3   5 153  34  10   2   3]\n",
      " [  4   4   4 114  39  26  19]\n",
      " [ 41   3  11  49  68  19  19]\n",
      " [  6   5   7  82  20  37  53]\n",
      " [  1   3   0  38  28  32 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.44      0.51       210\n",
      "           2       0.76      0.34      0.47       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.27      0.54      0.36       210\n",
      "           5       0.26      0.32      0.29       210\n",
      "           6       0.26      0.18      0.21       210\n",
      "           7       0.50      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.49      0.44      0.44      1470\n",
      "weighted avg       0.49      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65   2   3  15  65  52   8]\n",
      " [  0  78   5  18  58  48   3]\n",
      " [  0   6 144  17  21  20   2]\n",
      " [  2   3   2  86  34  72  11]\n",
      " [  9   6   1  13 106  61  14]\n",
      " [  3  10   7  24  16 104  46]\n",
      " [  0  10   0  19  20  62  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.31      0.45       210\n",
      "           2       0.68      0.37      0.48       210\n",
      "           3       0.89      0.69      0.77       210\n",
      "           4       0.45      0.41      0.43       210\n",
      "           5       0.33      0.50      0.40       210\n",
      "           6       0.25      0.50      0.33       210\n",
      "           7       0.54      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.57      0.46      0.48      1470\n",
      "weighted avg       0.57      0.46      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48367346938775513\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   5   7   9  37  25   9]\n",
      " [ 28  82   7   9  51  28   5]\n",
      " [ 13  12 158   5  10  11   1]\n",
      " [ 42   6  10  74  26  40  12]\n",
      " [ 43  11   6   6  98  32  14]\n",
      " [ 28   5  12  16  14  94  41]\n",
      " [ 15  10   1  13  21  63  87]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.56      0.47       210\n",
      "           2       0.63      0.39      0.48       210\n",
      "           3       0.79      0.75      0.77       210\n",
      "           4       0.56      0.35      0.43       210\n",
      "           5       0.38      0.47      0.42       210\n",
      "           6       0.32      0.45      0.37       210\n",
      "           7       0.51      0.41      0.46       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.51      0.48      0.49      1470\n",
      "weighted avg       0.51      0.48      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.501360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106   6   4  27  36  22   9]\n",
      " [  7  99   5  41  36  16   6]\n",
      " [  4  14 153  17   8   8   6]\n",
      " [ 21  14   3 104  17  34  17]\n",
      " [ 32  12   2  28  97  26  13]\n",
      " [ 11  12   6  56   9  72  44]\n",
      " [  2  18   0  30   9  45 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.50      0.54       210\n",
      "           2       0.57      0.47      0.51       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.34      0.50      0.41       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.53      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.51      1470\n",
      "weighted avg       0.53      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   5   4  28  49  21   9]\n",
      " [  7 110   9  39  21  19   5]\n",
      " [  4  13 158  14   7   9   5]\n",
      " [ 11  12   6 111  22  32  16]\n",
      " [ 25  19   5  30  95  22  14]\n",
      " [  6  10  11  54  13  64  52]\n",
      " [  7   8   2  31  10  50 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.45      0.52       210\n",
      "           2       0.62      0.52      0.57       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.36      0.53      0.43       210\n",
      "           5       0.44      0.45      0.44       210\n",
      "           6       0.29      0.30      0.30       210\n",
      "           7       0.50      0.49      0.49       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.50      1470\n",
      "weighted avg       0.52      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.508843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103  10   6  16  41  22  12]\n",
      " [  9 107   7  33  25  24   5]\n",
      " [  4  10 161  13   8  12   2]\n",
      " [ 15  17   5  89  31  41  12]\n",
      " [ 20   7   7  24 113  26  13]\n",
      " [ 19  11   8  34  13  71  54]\n",
      " [  6   8   2  29  11  50 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.49      0.53       210\n",
      "           2       0.63      0.51      0.56       210\n",
      "           3       0.82      0.77      0.79       210\n",
      "           4       0.37      0.42      0.40       210\n",
      "           5       0.47      0.54      0.50       210\n",
      "           6       0.29      0.34      0.31       210\n",
      "           7       0.51      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.51      1470\n",
      "weighted avg       0.53      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   4  10  12  45  28  10]\n",
      " [  5 114   8  12  25  39   7]\n",
      " [  1  10 162  11   6  15   5]\n",
      " [ 17  12   8  84  23  52  14]\n",
      " [ 26  14   5  18 103  29  15]\n",
      " [ 19  14   9  21  14  81  52]\n",
      " [  8   9   3  17  10  59 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.48      0.52       210\n",
      "           2       0.64      0.54      0.59       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.48      0.40      0.44       210\n",
      "           5       0.46      0.49      0.47       210\n",
      "           6       0.27      0.39      0.32       210\n",
      "           7       0.50      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.52      1470\n",
      "weighted avg       0.53      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   5   4  17  47  28  13]\n",
      " [  5 121   6  18  29  23   8]\n",
      " [  3  13 163   9   7  11   4]\n",
      " [ 13  12   5  92  32  41  15]\n",
      " [ 24  15   6  24 103  21  17]\n",
      " [ 14  14   9  27  16  67  63]\n",
      " [  8   8   1  16  18  54 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.46      0.51       210\n",
      "           2       0.64      0.58      0.61       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.45      0.44      0.45       210\n",
      "           5       0.41      0.49      0.45       210\n",
      "           6       0.27      0.32      0.29       210\n",
      "           7       0.47      0.50      0.48       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   8   7  16  44  29   9]\n",
      " [  6 116   8  20  28  22  10]\n",
      " [  0  14 163  10   8  11   4]\n",
      " [ 19  12   5  89  28  35  22]\n",
      " [ 33  17   5  23  90  20  22]\n",
      " [ 17  19  14  20  18  68  54]\n",
      " [  9  11   4  19  14  46 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.46      0.50       210\n",
      "           2       0.59      0.55      0.57       210\n",
      "           3       0.79      0.78      0.78       210\n",
      "           4       0.45      0.42      0.44       210\n",
      "           5       0.39      0.43      0.41       210\n",
      "           6       0.29      0.32      0.31       210\n",
      "           7       0.47      0.51      0.49       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   9   6  19  40  27   8]\n",
      " [  4 114   5  18  36  21  12]\n",
      " [  2  13 163  15   7   7   3]\n",
      " [ 22  16   6  81  29  34  22]\n",
      " [ 32  17   6  20  96  23  16]\n",
      " [ 15  17  13  21  18  70  56]\n",
      " [  7  10   3  18  19  50 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.48      0.51       210\n",
      "           2       0.58      0.54      0.56       210\n",
      "           3       0.81      0.78      0.79       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.39      0.46      0.42       210\n",
      "           6       0.30      0.33      0.32       210\n",
      "           7       0.47      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49795918367346936\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103   6   7  14  43  26  11]\n",
      " [  9 119   6  23  28  14  11]\n",
      " [  0  16 164  13   8   7   2]\n",
      " [ 15  14   8  92  27  32  22]\n",
      " [ 28  22   5  23  90  21  21]\n",
      " [ 12  16  16  26  17  62  61]\n",
      " [  8  12   3  18  16  51 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.49      0.54       210\n",
      "           2       0.58      0.57      0.57       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.39      0.43      0.41       210\n",
      "           6       0.29      0.30      0.29       210\n",
      "           7       0.44      0.49      0.46       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   5   6  13  47  25  12]\n",
      " [  8 118  10  26  22  16  10]\n",
      " [  2  16 165  13   5   6   3]\n",
      " [ 20  10   6  96  25  32  21]\n",
      " [ 31  23   6  28  82  19  21]\n",
      " [ 19  17  15  24  16  62  57]\n",
      " [  9  12   6  23  10  36 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.49      0.51       210\n",
      "           2       0.59      0.56      0.57       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.43      0.46      0.44       210\n",
      "           5       0.40      0.39      0.39       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.48      0.54      0.51       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   7   5  15  43  27  14]\n",
      " [  3 121   8  17  27  20  14]\n",
      " [  0  14 164  11  11   6   4]\n",
      " [ 23  13   5  88  25  32  24]\n",
      " [ 37  19   5  22  86  21  20]\n",
      " [ 10  17  18  26  13  69  57]\n",
      " [ 14   7   6  20  14  43 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.47      0.50       210\n",
      "           2       0.61      0.58      0.59       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.32      0.33      0.32       210\n",
      "           7       0.44      0.50      0.47       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49047619047619045\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   8   5  12  43  31  14]\n",
      " [  3 121   6  19  29  18  14]\n",
      " [  0  14 163  13  10   7   3]\n",
      " [ 19  13  11  83  25  39  20]\n",
      " [ 30  22   9  24  88  17  20]\n",
      " [ 11  19  17  22  14  62  65]\n",
      " [  6  12   6  21  14  44 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.46      0.52       210\n",
      "           2       0.58      0.58      0.58       210\n",
      "           3       0.75      0.78      0.76       210\n",
      "           4       0.43      0.40      0.41       210\n",
      "           5       0.39      0.42      0.41       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.44      0.51      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.501360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   6   6  14  44  28  14]\n",
      " [  8 126   8  16  25  15  12]\n",
      " [  2  13 163  16   7   6   3]\n",
      " [ 17  15   8  91  22  37  20]\n",
      " [ 32  21   5  21  89  23  19]\n",
      " [ 14  20  14  27  14  61  60]\n",
      " [  8  13   2  19  11  48 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.47      0.50       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.79      0.78      0.78       210\n",
      "           4       0.45      0.43      0.44       210\n",
      "           5       0.42      0.42      0.42       210\n",
      "           6       0.28      0.29      0.29       210\n",
      "           7       0.46      0.52      0.49       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   7   6  16  43  22  14]\n",
      " [  4 121   8  18  29  21   9]\n",
      " [  1  14 163  13   9   8   2]\n",
      " [ 18  11   6  94  26  34  21]\n",
      " [ 30  17   5  33  83  16  26]\n",
      " [ 13  18  18  22  14  62  63]\n",
      " [ 13   9   3  23  14  40 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.49      0.52       210\n",
      "           2       0.61      0.58      0.59       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.43      0.45      0.44       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.44      0.51      0.48       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.3\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 25   3  30   1   7   0 144]\n",
      " [  2  20  84   4   8   0  92]\n",
      " [  0   5 175   3   5   0  22]\n",
      " [  2   5  26   5   2   0 170]\n",
      " [  5   5  10   0   9   0 181]\n",
      " [  2   5  19   2   2   0 180]\n",
      " [  1   2   0   0   0   0 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.12      0.20       210\n",
      "           2       0.44      0.10      0.16       210\n",
      "           3       0.51      0.83      0.63       210\n",
      "           4       0.33      0.02      0.04       210\n",
      "           5       0.27      0.04      0.07       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      0.99      0.34       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.35      0.30      0.21      1470\n",
      "weighted avg       0.35      0.30      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.46802721088435373\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 60  12   0   2  86   1  49]\n",
      " [  2 123  12   2  56   0  15]\n",
      " [  4  14 167   2  14   0   9]\n",
      " [  3  19  19  21  64   0  84]\n",
      " [  9  15   1   1 133   0  51]\n",
      " [  2  13  16   8  43   0 128]\n",
      " [  0   5   0   6  14   1 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.29      0.41       210\n",
      "           2       0.61      0.59      0.60       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.50      0.10      0.17       210\n",
      "           5       0.32      0.63      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.88      0.50       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.41      1470\n",
      "weighted avg       0.47      0.47      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93   8   0   8  57   4  40]\n",
      " [  0 141   4   6  45   0  14]\n",
      " [  0  22 164   3  13   1   7]\n",
      " [  6  24  17  48  38   1  76]\n",
      " [ 19  14   1   2 127   0  47]\n",
      " [  6  17  12  19  26   6 124]\n",
      " [  0   6   0   3  11   1 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.44      0.56       210\n",
      "           2       0.61      0.67      0.64       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.54      0.23      0.32       210\n",
      "           5       0.40      0.60      0.48       210\n",
      "           6       0.46      0.03      0.05       210\n",
      "           7       0.38      0.90      0.53       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.57      0.52      0.48      1470\n",
      "weighted avg       0.57      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   3   0  11  50   7  36]\n",
      " [  1 143   3   6  44   1  12]\n",
      " [  2  22 163   7   8   4   4]\n",
      " [  6  17  17  74  32   8  56]\n",
      " [ 22  16   1  10 119   0  42]\n",
      " [ 11  14  13  37  17  13 105]\n",
      " [  0   5   0  13  13   2 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.49      0.58       210\n",
      "           2       0.65      0.68      0.67       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.47      0.35      0.40       210\n",
      "           5       0.42      0.57      0.48       210\n",
      "           6       0.37      0.06      0.11       210\n",
      "           7       0.41      0.84      0.55       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.51      1470\n",
      "weighted avg       0.55      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   3   0  15  52  10  33]\n",
      " [  0 140   4   8  45   4   9]\n",
      " [  2   8 170  16   8   5   1]\n",
      " [  5  10  10 106  18  13  48]\n",
      " [ 22  14   1   9 122   1  41]\n",
      " [  6  12  10  28  17  27 110]\n",
      " [  0   3   0  11   6   5 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.46      0.57       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.55      0.50      0.53       210\n",
      "           5       0.46      0.58      0.51       210\n",
      "           6       0.42      0.13      0.20       210\n",
      "           7       0.43      0.88      0.58       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.56      1470\n",
      "weighted avg       0.60      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   4   0  15  46  14  29]\n",
      " [  0 139   3  10  43   5  10]\n",
      " [  1   7 171  14   7  10   0]\n",
      " [  5  10  11 103  21  24  36]\n",
      " [ 22  13   1  15 119   3  37]\n",
      " [  9  13   6  29   7  43 103]\n",
      " [  0   4   0   8   7  10 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.49      0.58       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.89      0.81      0.85       210\n",
      "           4       0.53      0.49      0.51       210\n",
      "           5       0.48      0.57      0.52       210\n",
      "           6       0.39      0.20      0.27       210\n",
      "           7       0.46      0.86      0.60       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.57      1470\n",
      "weighted avg       0.60      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   1   0  11  50  16  25]\n",
      " [  1 148   3  13  35   6   4]\n",
      " [  2   9 171  14   7   6   1]\n",
      " [  5   9   6 116  18  27  29]\n",
      " [ 20  12   1  16 121   4  36]\n",
      " [  8  15   5  26  12  54  90]\n",
      " [  0   2   0   7   7  15 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.51      0.61       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.92      0.81      0.86       210\n",
      "           4       0.57      0.55      0.56       210\n",
      "           5       0.48      0.58      0.53       210\n",
      "           6       0.42      0.26      0.32       210\n",
      "           7       0.49      0.85      0.62       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.60      1470\n",
      "weighted avg       0.63      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   1   0  12  50  19  19]\n",
      " [  0 145   5  10  34  11   5]\n",
      " [  1  11 171  14   7   6   0]\n",
      " [  6   7   7 124  17  23  26]\n",
      " [ 17  11   1  13 128   6  34]\n",
      " [  8  11   5  22  10  69  85]\n",
      " [  0   2   0   9   6  18 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.52      0.62       210\n",
      "           2       0.77      0.69      0.73       210\n",
      "           3       0.90      0.81      0.86       210\n",
      "           4       0.61      0.59      0.60       210\n",
      "           5       0.51      0.61      0.55       210\n",
      "           6       0.45      0.33      0.38       210\n",
      "           7       0.51      0.83      0.63       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.62      1470\n",
      "weighted avg       0.65      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   0   0  13  45  27  15]\n",
      " [  1 149   2  12  32  10   4]\n",
      " [  1   4 178   8   8  11   0]\n",
      " [  6   7   7 131  15  25  19]\n",
      " [ 18  11   0  18 126   6  31]\n",
      " [  8  10   7  23   7  69  86]\n",
      " [  0   3   0   8   4  21 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.52      0.62       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.92      0.85      0.88       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.53      0.60      0.56       210\n",
      "           6       0.41      0.33      0.36       210\n",
      "           7       0.53      0.83      0.65       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113   1   1  14  41  20  20]\n",
      " [  0 148   5  11  32   9   5]\n",
      " [  3   5 176   5   6  15   0]\n",
      " [  8   7   7 125  15  33  15]\n",
      " [ 20  11   0  15 131   3  30]\n",
      " [  4  12   3  16  12  82  81]\n",
      " [  0   2   0   2   5  21 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.54      0.63       210\n",
      "           2       0.80      0.70      0.75       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.54      0.62      0.58       210\n",
      "           6       0.45      0.39      0.42       210\n",
      "           7       0.54      0.86      0.67       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   0   0  12  43  17  18]\n",
      " [  0 152   3   8  29  14   4]\n",
      " [  3   3 176  11   6  11   0]\n",
      " [  5   6   7 133  16  26  17]\n",
      " [ 17   9   0  17 130   8  29]\n",
      " [  4  14   5  22   5  81  79]\n",
      " [  0   2   0   7   5  17 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.57      0.67       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.63      0.63      0.63       210\n",
      "           5       0.56      0.62      0.59       210\n",
      "           6       0.47      0.39      0.42       210\n",
      "           7       0.55      0.85      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   0   0  11  43  28  13]\n",
      " [  0 159   2   9  26   9   5]\n",
      " [  2   3 178  15   5   7   0]\n",
      " [  4   7   6 135  20  20  18]\n",
      " [ 26  10   0  13 131   5  25]\n",
      " [  6  11   5  20   5  91  72]\n",
      " [  0   2   0   5   5  14 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.55      0.63       210\n",
      "           2       0.83      0.76      0.79       210\n",
      "           3       0.93      0.85      0.89       210\n",
      "           4       0.65      0.64      0.65       210\n",
      "           5       0.56      0.62      0.59       210\n",
      "           6       0.52      0.43      0.47       210\n",
      "           7       0.58      0.88      0.70       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   2   0   8  44  20  16]\n",
      " [  0 153   4  12  25  13   3]\n",
      " [  2   4 179  13   6   6   0]\n",
      " [  8   7   5 130  15  27  18]\n",
      " [ 23  11   1   7 138   8  22]\n",
      " [  7  10   5  15   7  87  79]\n",
      " [  0   1   0   5   7  26 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.57      0.65       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.92      0.85      0.89       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.47      0.41      0.44       210\n",
      "           7       0.55      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112   2   0  11  48  21  16]\n",
      " [  0 160   4   9  22  11   4]\n",
      " [  3   2 183  10   5   7   0]\n",
      " [  6   9   6 126  16  32  15]\n",
      " [ 18  11   0  14 133  10  24]\n",
      " [  8   9   7  19   8  86  73]\n",
      " [  0   3   0   1   5  29 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.53      0.63       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.92      0.87      0.89       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.56      0.63      0.60       210\n",
      "           6       0.44      0.41      0.42       210\n",
      "           7       0.57      0.82      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   1   0  13  41  20  15]\n",
      " [  0 163   3  10  21   9   4]\n",
      " [  1   6 179  10   5   9   0]\n",
      " [  7   6   7 130  17  24  19]\n",
      " [ 26  12   0  15 127   6  24]\n",
      " [ 11   9   6  17   9  87  71]\n",
      " [  0   3   0   7   7  18 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.57      0.64       210\n",
      "           2       0.81      0.78      0.80       210\n",
      "           3       0.92      0.85      0.88       210\n",
      "           4       0.64      0.62      0.63       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.50      0.41      0.45       210\n",
      "           7       0.57      0.83      0.68       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   1   0   9  42  22  16]\n",
      " [  0 157   4  10  22  14   3]\n",
      " [  1   4 179  10   7   8   1]\n",
      " [  8   9   4 133  16  25  15]\n",
      " [ 28  10   0  19 121   7  25]\n",
      " [  7  12   4  17   7  86  77]\n",
      " [  0   1   0   8   4  26 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.57      0.64       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.55      0.58      0.56       210\n",
      "           6       0.46      0.41      0.43       210\n",
      "           7       0.56      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   0   0   7  45  23  15]\n",
      " [  0 160   6  10  21  10   3]\n",
      " [  0   5 181   9   8   7   0]\n",
      " [  7   8   6 132  15  23  19]\n",
      " [ 23  12   0  13 127  13  22]\n",
      " [  8  16   8  15   7  90  66]\n",
      " [  0   1   0   5   4  24 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.57      0.65       210\n",
      "           2       0.79      0.76      0.78       210\n",
      "           3       0.90      0.86      0.88       210\n",
      "           4       0.69      0.63      0.66       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.47      0.43      0.45       210\n",
      "           7       0.58      0.84      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   1   0   8  48  23  15]\n",
      " [  1 163   3   8  22  10   3]\n",
      " [  4   8 180   6   4   8   0]\n",
      " [  8   6   7 132  17  30  10]\n",
      " [ 27  13   0  19 122  11  18]\n",
      " [  8  13   4  17   6  89  73]\n",
      " [  0   3   0   7   6  20 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.55      0.62       210\n",
      "           2       0.79      0.78      0.78       210\n",
      "           3       0.93      0.86      0.89       210\n",
      "           4       0.67      0.63      0.65       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.47      0.42      0.44       210\n",
      "           7       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   0   0   8  42  26  13]\n",
      " [  0 160   4   9  23  12   2]\n",
      " [  3   8 177   9   3   9   1]\n",
      " [  6   7   6 138  17  23  13]\n",
      " [ 24  14   0  16 128   6  22]\n",
      " [  8  12   4  19  11  89  67]\n",
      " [  0   2   0   5   6  28 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.58      0.65       210\n",
      "           2       0.79      0.76      0.77       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.68      0.66      0.67       210\n",
      "           5       0.56      0.61      0.58       210\n",
      "           6       0.46      0.42      0.44       210\n",
      "           7       0.59      0.80      0.68       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   0   0   9  43  27  11]\n",
      " [  0 162   3   8  21  13   3]\n",
      " [  1   5 179  10   6   9   0]\n",
      " [  6   9   7 135  18  24  11]\n",
      " [ 32  14   0  15 120   6  23]\n",
      " [  8   9   3  19  10 100  61]\n",
      " [  0   3   0   4   7  23 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.57      0.64       210\n",
      "           2       0.80      0.77      0.79       210\n",
      "           3       0.93      0.85      0.89       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.53      0.57      0.55       210\n",
      "           6       0.50      0.48      0.49       210\n",
      "           7       0.61      0.82      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 79   2  11  12  42  26  38]\n",
      " [  0 134   3  12  30  20  11]\n",
      " [  3  17 145  12   3  25   5]\n",
      " [  3  12  14  80  16  26  59]\n",
      " [ 24  16   1  23  89  11  46]\n",
      " [  6  11  10  33   7  48  95]\n",
      " [  0   2   0  17   9  27 155]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.38      0.49       210\n",
      "           2       0.69      0.64      0.66       210\n",
      "           3       0.79      0.69      0.74       210\n",
      "           4       0.42      0.38      0.40       210\n",
      "           5       0.45      0.42      0.44       210\n",
      "           6       0.26      0.23      0.24       210\n",
      "           7       0.38      0.74      0.50       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.50      1470\n",
      "weighted avg       0.53      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.2938775510204082\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 36   0  63   2  80  25   4]\n",
      " [  2  17 103   8  70   8   2]\n",
      " [  1   6 188   2  11   2   0]\n",
      " [  5   3  98  10  73  11  10]\n",
      " [ 21  10  37   4 101  23  14]\n",
      " [  0   6  93   5  58  35  13]\n",
      " [  1   2  52   5  64  41  45]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.17      0.26       210\n",
      "           2       0.39      0.08      0.13       210\n",
      "           3       0.30      0.90      0.45       210\n",
      "           4       0.28      0.05      0.08       210\n",
      "           5       0.22      0.48      0.30       210\n",
      "           6       0.24      0.17      0.20       210\n",
      "           7       0.51      0.21      0.30       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.35      0.29      0.25      1470\n",
      "weighted avg       0.35      0.29      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119   9   4  16  45   8   9]\n",
      " [ 11 139  17  16  20   2   5]\n",
      " [ 19   7 168  11   4   0   1]\n",
      " [ 29  24  13  98  25   9  12]\n",
      " [ 57  22   8  26  82   5  10]\n",
      " [ 44  31   6  42  16  30  41]\n",
      " [ 20   9   1  23  21  12 124]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.57      0.47       210\n",
      "           2       0.58      0.66      0.62       210\n",
      "           3       0.77      0.80      0.79       210\n",
      "           4       0.42      0.47      0.44       210\n",
      "           5       0.38      0.39      0.39       210\n",
      "           6       0.45      0.14      0.22       210\n",
      "           7       0.61      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.50      1470\n",
      "weighted avg       0.52      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114   8   3  15  48  10  12]\n",
      " [ 10 139  18  12  23   5   3]\n",
      " [ 14  16 165   9   5   1   0]\n",
      " [ 20  22   9 106  28  10  15]\n",
      " [ 53  23   7  19  88   7  13]\n",
      " [ 30  23   5  37  18  41  56]\n",
      " [  9   9   0  13  25  25 129]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.54      0.50       210\n",
      "           2       0.58      0.66      0.62       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.50      0.50      0.50       210\n",
      "           5       0.37      0.42      0.40       210\n",
      "           6       0.41      0.20      0.27       210\n",
      "           7       0.57      0.61      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[107   7   2  18  51  13  12]\n",
      " [  8 134  19  10  27   6   6]\n",
      " [ 10  16 166   9   8   1   0]\n",
      " [ 15  23   7 110  30  11  14]\n",
      " [ 42  18   7  23  98   7  15]\n",
      " [ 24  20   5  39  26  44  52]\n",
      " [  7   6   0  15  24  27 131]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.51       210\n",
      "           2       0.60      0.64      0.62       210\n",
      "           3       0.81      0.79      0.80       210\n",
      "           4       0.49      0.52      0.51       210\n",
      "           5       0.37      0.47      0.41       210\n",
      "           6       0.40      0.21      0.28       210\n",
      "           7       0.57      0.62      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.53      0.54      0.53      1470\n",
      "weighted avg       0.53      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[106   7   2  15  56   9  15]\n",
      " [  8 137  18  12  25   5   5]\n",
      " [  7  16 170  10   5   1   1]\n",
      " [ 15  15  17 106  30   9  18]\n",
      " [ 44  18   8  24  96   4  16]\n",
      " [ 23  26   6  39  24  36  56]\n",
      " [  8   7   1  12  24  19 139]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       210\n",
      "           2       0.61      0.65      0.63       210\n",
      "           3       0.77      0.81      0.79       210\n",
      "           4       0.49      0.50      0.50       210\n",
      "           5       0.37      0.46      0.41       210\n",
      "           6       0.43      0.17      0.25       210\n",
      "           7       0.56      0.66      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.53      0.54      0.52      1470\n",
      "weighted avg       0.53      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[102   6   4  20  54   9  15]\n",
      " [  9 132  22  10  26   3   8]\n",
      " [  8  13 168  10   6   3   2]\n",
      " [ 15  18  18 102  33   9  15]\n",
      " [ 32  19   8  23 100  10  18]\n",
      " [ 25  24   6  37  24  37  57]\n",
      " [  7   7   0  11  23  22 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.49      0.50       210\n",
      "           2       0.60      0.63      0.62       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.48      0.49      0.48       210\n",
      "           5       0.38      0.48      0.42       210\n",
      "           6       0.40      0.18      0.24       210\n",
      "           7       0.55      0.67      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.52      1470\n",
      "weighted avg       0.52      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[ 96   7   3  20  55  10  19]\n",
      " [  8 125  25  11  29   7   5]\n",
      " [  9   8 174   9   6   2   2]\n",
      " [ 10  16  18 108  36   9  13]\n",
      " [ 33  17   9  21 104   8  18]\n",
      " [ 23  19   8  39  28  34  59]\n",
      " [  4   7   0   7  22  14 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.46      0.49       210\n",
      "           2       0.63      0.60      0.61       210\n",
      "           3       0.73      0.83      0.78       210\n",
      "           4       0.50      0.51      0.51       210\n",
      "           5       0.37      0.50      0.42       210\n",
      "           6       0.40      0.16      0.23       210\n",
      "           7       0.57      0.74      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.53      0.54      0.53      1470\n",
      "weighted avg       0.53      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 81   0  11   6  53  18  41]\n",
      " [  1 119   6   9  44  21  10]\n",
      " [ 12   9 152   5   7  24   1]\n",
      " [  5  10  15  84  24  26  46]\n",
      " [ 15  13   1   8 123   8  42]\n",
      " [  6   7  10  31  18  39  99]\n",
      " [  0   1   0  11  13  19 166]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.39      0.49       210\n",
      "           2       0.75      0.57      0.64       210\n",
      "           3       0.78      0.72      0.75       210\n",
      "           4       0.55      0.40      0.46       210\n",
      "           5       0.44      0.59      0.50       210\n",
      "           6       0.25      0.19      0.21       210\n",
      "           7       0.41      0.79      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.51      1470\n",
      "weighted avg       0.55      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 82   0  11   5  54  25  33]\n",
      " [  1 117   8   9  43  24   8]\n",
      " [  9   4 152  11   6  26   2]\n",
      " [  6   9  15  76  31  26  47]\n",
      " [ 18  14   1   8 119   9  41]\n",
      " [  7   7  11  25  20  44  96]\n",
      " [  0   2   0  15  12  14 167]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.39      0.49       210\n",
      "           2       0.76      0.56      0.64       210\n",
      "           3       0.77      0.72      0.75       210\n",
      "           4       0.51      0.36      0.42       210\n",
      "           5       0.42      0.57      0.48       210\n",
      "           6       0.26      0.21      0.23       210\n",
      "           7       0.42      0.80      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.54      0.51      0.51      1470\n",
      "weighted avg       0.54      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.23605442176870747\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 23   6 116   2  62   1   0]\n",
      " [  0  31 135   0  42   2   0]\n",
      " [  1   5 199   0   5   0   0]\n",
      " [  4  15 127  10  53   1   0]\n",
      " [  9  17 105   0  76   3   0]\n",
      " [  2   8 149   5  40   6   0]\n",
      " [  0  11 137   1  50   9   2]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.11      0.18       210\n",
      "           2       0.33      0.15      0.20       210\n",
      "           3       0.21      0.95      0.34       210\n",
      "           4       0.56      0.05      0.09       210\n",
      "           5       0.23      0.36      0.28       210\n",
      "           6       0.27      0.03      0.05       210\n",
      "           7       1.00      0.01      0.02       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.46      0.24      0.17      1470\n",
      "weighted avg       0.46      0.24      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.2965986394557823\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 18  15  40   2  65  70   0]\n",
      " [  0  49  87   0  45  29   0]\n",
      " [  0  16 183   0   6   5   0]\n",
      " [  2  13  77  12  59  47   0]\n",
      " [  7  31  25   1  80  66   0]\n",
      " [  2  15  53   4  42  94   0]\n",
      " [  0   8  18   4  54 126   0]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.09      0.15       210\n",
      "           2       0.33      0.23      0.27       210\n",
      "           3       0.38      0.87      0.53       210\n",
      "           4       0.52      0.06      0.10       210\n",
      "           5       0.23      0.38      0.29       210\n",
      "           6       0.22      0.45      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.33      0.30      0.23      1470\n",
      "weighted avg       0.33      0.30      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.24693877551020407\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 21  10  86   0  66  27   0]\n",
      " [  0  36 124   0  44   6   0]\n",
      " [  0   7 196   0   6   1   0]\n",
      " [  1  10 119  10  61   9   0]\n",
      " [  7  25  70   0  80  28   0]\n",
      " [  2  13 130   3  42  20   0]\n",
      " [  0  11 101   2  54  42   0]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.10      0.17       210\n",
      "           2       0.32      0.17      0.22       210\n",
      "           3       0.24      0.93      0.38       210\n",
      "           4       0.67      0.05      0.09       210\n",
      "           5       0.23      0.38      0.28       210\n",
      "           6       0.15      0.10      0.12       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.33      0.25      0.18      1470\n",
      "weighted avg       0.33      0.25      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Normalize Scaling is: 0.21768707482993196\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 17   1 130   1  60   1   0]\n",
      " [  2  19 147   0  40   2   0]\n",
      " [  1   4 201   0   4   0   0]\n",
      " [  6   7 138   8  51   0   0]\n",
      " [ 12   7 120   0  71   0   0]\n",
      " [  3   3 159   4  38   3   0]\n",
      " [  0   6 150   4  48   1   1]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.08      0.14       210\n",
      "           2       0.40      0.09      0.15       210\n",
      "           3       0.19      0.96      0.32       210\n",
      "           4       0.47      0.04      0.07       210\n",
      "           5       0.23      0.34      0.27       210\n",
      "           6       0.43      0.01      0.03       210\n",
      "           7       1.00      0.00      0.01       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.45      0.22      0.14      1470\n",
      "weighted avg       0.45      0.22      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.22585034013605443\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  15   0   0   0 195]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  0   0  13   0   0   0 197]\n",
      " [  0   0   2   0   0   0 208]\n",
      " [  0   0   4   0   0   0 206]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.59      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.13      1470\n",
      "weighted avg       0.13      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.30612244897959184\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 13   0   2   0 147   0  48]\n",
      " [  4   0   4   0 166   0  36]\n",
      " [  2   0 121   0  63   0  24]\n",
      " [  5   0   8   0 115   0  82]\n",
      " [  1   0   1   0 163   0  45]\n",
      " [  2   0   2   0  72   0 134]\n",
      " [  0   0   1   0  56   0 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.06      0.11       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.87      0.58      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.21      0.78      0.33       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.29      0.73      0.42       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.26      0.31      0.22      1470\n",
      "weighted avg       0.26      0.31      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 12  14   0   3 133  45   3]\n",
      " [  0 108   2   6  58  34   2]\n",
      " [  1  46 119   3  17  23   1]\n",
      " [  1  46   2  10  69  79   3]\n",
      " [  1  36   1   0 127  42   3]\n",
      " [  0  20   2   2  52 111  23]\n",
      " [  0  12   0   1  44 110  43]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.06      0.11       210\n",
      "           2       0.38      0.51      0.44       210\n",
      "           3       0.94      0.57      0.71       210\n",
      "           4       0.40      0.05      0.09       210\n",
      "           5       0.25      0.60      0.36       210\n",
      "           6       0.25      0.53      0.34       210\n",
      "           7       0.55      0.20      0.30       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.51      0.36      0.33      1470\n",
      "weighted avg       0.51      0.36      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.41496598639455784\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54   5  11   1  91  35  13]\n",
      " [  2  93  20   2  56  31   6]\n",
      " [  2   1 163   2  16  21   5]\n",
      " [  2  16  34   8  67  58  25]\n",
      " [  6  20  17   0 122  38   7]\n",
      " [  2   9  11   2  50  64  72]\n",
      " [  6   5   8   0  38  47 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.26      0.38       210\n",
      "           2       0.62      0.44      0.52       210\n",
      "           3       0.62      0.78      0.69       210\n",
      "           4       0.53      0.04      0.07       210\n",
      "           5       0.28      0.58      0.38       210\n",
      "           6       0.22      0.30      0.25       210\n",
      "           7       0.45      0.50      0.48       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.49      0.41      0.39      1470\n",
      "weighted avg       0.49      0.41      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54   5   0  49  65  29   8]\n",
      " [  2  93   3  73  21  12   6]\n",
      " [  4   2 147  36   3  15   3]\n",
      " [  3  18  12  96  25  45  11]\n",
      " [  6  20   4  63  88  26   3]\n",
      " [  4  10   0  71   6  72  47]\n",
      " [  6   6   1  44   6  61  86]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.26      0.37       210\n",
      "           2       0.60      0.44      0.51       210\n",
      "           3       0.88      0.70      0.78       210\n",
      "           4       0.22      0.46      0.30       210\n",
      "           5       0.41      0.42      0.42       210\n",
      "           6       0.28      0.34      0.31       210\n",
      "           7       0.52      0.41      0.46       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.51      0.43      0.45      1470\n",
      "weighted avg       0.51      0.43      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.46802721088435373\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  15   1  51  52  14   9]\n",
      " [  4 116   2  49  25   7   7]\n",
      " [  4  18 146  31   3   6   2]\n",
      " [  8  27   5 100  24  31  15]\n",
      " [ 13  39   4  47  84  19   4]\n",
      " [  7  21   1  65   6  71  39]\n",
      " [  5  12   1  28   6  55 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.32      0.43       210\n",
      "           2       0.47      0.55      0.51       210\n",
      "           3       0.91      0.70      0.79       210\n",
      "           4       0.27      0.48      0.34       210\n",
      "           5       0.42      0.40      0.41       210\n",
      "           6       0.35      0.34      0.34       210\n",
      "           7       0.58      0.49      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.52      0.47      0.48      1470\n",
      "weighted avg       0.52      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.48775510204081635\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  10   1  13  53  50  10]\n",
      " [  8 116   2  17  22  38   7]\n",
      " [  6  16 145  11   3  26   3]\n",
      " [ 18  17   4  69  20  63  19]\n",
      " [ 20  31   4  11  89  44  11]\n",
      " [ 18  15   0  16   4 113  44]\n",
      " [  3  12   1   8   7  67 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.35      0.41       210\n",
      "           2       0.53      0.55      0.54       210\n",
      "           3       0.92      0.69      0.79       210\n",
      "           4       0.48      0.33      0.39       210\n",
      "           5       0.45      0.42      0.44       210\n",
      "           6       0.28      0.54      0.37       210\n",
      "           7       0.54      0.53      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.53      0.49      0.50      1470\n",
      "weighted avg       0.53      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 69   6   2  29  53  42   9]\n",
      " [  4 110   2  31  27  32   4]\n",
      " [  4   8 154  15   3  22   4]\n",
      " [ 12  10   7 106  19  43  13]\n",
      " [ 17  24   4  37  91  27  10]\n",
      " [ 11  11   0  51   4  91  42]\n",
      " [  5   9   1  19   7  68 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.33      0.42       210\n",
      "           2       0.62      0.52      0.57       210\n",
      "           3       0.91      0.73      0.81       210\n",
      "           4       0.37      0.50      0.43       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.28      0.43      0.34       210\n",
      "           7       0.55      0.48      0.51       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.53      0.49      0.50      1470\n",
      "weighted avg       0.53      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75   5   2  32  53  35   8]\n",
      " [  6 129   5  17  25  21   7]\n",
      " [  5  11 162  14   5   9   4]\n",
      " [ 13  15  12  97  30  25  18]\n",
      " [ 15  23   9  32 100  21  10]\n",
      " [ 19  23   6  31  10  69  52]\n",
      " [  8   6   2  15  11  60 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.36      0.43       210\n",
      "           2       0.61      0.61      0.61       210\n",
      "           3       0.82      0.77      0.79       210\n",
      "           4       0.41      0.46      0.43       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.29      0.33      0.31       210\n",
      "           7       0.52      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.51      1470\n",
      "weighted avg       0.51      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 89  10   3  14  59  25  10]\n",
      " [  4 127   2  18  33  19   7]\n",
      " [  4   5 161  13  11  10   6]\n",
      " [ 13  13  13  86  42  23  20]\n",
      " [ 27  27   5  23 100  19   9]\n",
      " [ 14  35   8  28  17  62  46]\n",
      " [  9   9   3  17  12  52 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.42      0.48       210\n",
      "           2       0.56      0.60      0.58       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.36      0.48      0.41       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.52      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92   9   5  20  56  21   7]\n",
      " [  4 122   8  18  25  25   8]\n",
      " [  9   7 162  14   6   9   3]\n",
      " [ 24  12  17  81  39  22  15]\n",
      " [ 34  21   3  22 101  17  12]\n",
      " [ 13  16   9  30  23  72  47]\n",
      " [ 10   7   3  13  19  49 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.44      0.46       210\n",
      "           2       0.63      0.58      0.60       210\n",
      "           3       0.78      0.77      0.78       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.38      0.48      0.42       210\n",
      "           6       0.33      0.34      0.34       210\n",
      "           7       0.54      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  10   5  28  41  17   8]\n",
      " [  7 127   4  18  25  22   7]\n",
      " [ 11  14 162   8   3   7   5]\n",
      " [ 18  19  13  98  24  23  15]\n",
      " [ 40  30   5  26  85  15   9]\n",
      " [ 19  30   7  28  17  62  47]\n",
      " [ 12   9   2  17  16  42 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.48      0.48       210\n",
      "           2       0.53      0.60      0.57       210\n",
      "           3       0.82      0.77      0.79       210\n",
      "           4       0.44      0.47      0.45       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.33      0.30      0.31       210\n",
      "           7       0.55      0.53      0.54       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  10   3  25  44  22   8]\n",
      " [  5 125   7  23  20  22   8]\n",
      " [ 10   8 166   8   6  10   2]\n",
      " [ 15  23  14  87  28  24  19]\n",
      " [ 36  27  10  31  78  19   9]\n",
      " [ 20  23   5  33  16  67  46]\n",
      " [ 13  11   3  16  14  48 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.47      0.48       210\n",
      "           2       0.55      0.60      0.57       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.38      0.37      0.37       210\n",
      "           6       0.32      0.32      0.32       210\n",
      "           7       0.53      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   8   8  23  40  20  13]\n",
      " [  7 121   7  22  24  21   8]\n",
      " [  6   7 168   5   4  14   6]\n",
      " [ 17  18  17  84  32  29  13]\n",
      " [ 43  24   6  27  80  14  16]\n",
      " [ 22  18   4  42  15  67  42]\n",
      " [ 11  11   1  18  13  45 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.47      0.47       210\n",
      "           2       0.58      0.58      0.58       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.38      0.38      0.38       210\n",
      "           6       0.32      0.32      0.32       210\n",
      "           7       0.53      0.53      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  12   7  22  40  19  12]\n",
      " [  6 124   8  19  23  23   7]\n",
      " [  6  11 166   6   6  12   3]\n",
      " [ 24  20  10  83  31  24  18]\n",
      " [ 45  29   8  22  78  14  14]\n",
      " [ 21  17   6  36  11  71  48]\n",
      " [ 16  13   2  13  10  41 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.47      0.46       210\n",
      "           2       0.55      0.59      0.57       210\n",
      "           3       0.80      0.79      0.80       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.39      0.37      0.38       210\n",
      "           6       0.35      0.34      0.34       210\n",
      "           7       0.53      0.55      0.54       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  11   3  20  41  25  10]\n",
      " [  9 128   6  20  21  19   7]\n",
      " [  6   7 167   8   5  11   6]\n",
      " [ 22  17  11  82  35  27  16]\n",
      " [ 44  23   6  19  82  19  17]\n",
      " [ 23  22   5  31  16  66  47]\n",
      " [ 12  10   1  16  10  50 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.59      0.61      0.60       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.39      0.39      0.39       210\n",
      "           6       0.30      0.31      0.31       210\n",
      "           7       0.52      0.53      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   7   9  22  34  23  14]\n",
      " [  6 132   6  20  20  18   8]\n",
      " [  6   9 170   6   6  11   2]\n",
      " [ 15  18  15  89  32  22  19]\n",
      " [ 47  25   6  20  79  20  13]\n",
      " [ 18  16  10  31  15  67  53]\n",
      " [ 16  11   3  17  11  43 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.48      0.48       210\n",
      "           2       0.61      0.63      0.62       210\n",
      "           3       0.78      0.81      0.79       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.40      0.38      0.39       210\n",
      "           6       0.33      0.32      0.32       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.50      0.51      0.51      1470\n",
      "weighted avg       0.50      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   7  10  20  39  24  11]\n",
      " [  5 127   7  17  19  23  12]\n",
      " [  4   9 169   5   4  13   6]\n",
      " [ 20  18  12  91  30  26  13]\n",
      " [ 44  24   4  30  76  19  13]\n",
      " [ 17  21   4  32  21  69  46]\n",
      " [ 11  13   2  12  16  45 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.47      0.48       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.81      0.80      0.81       210\n",
      "           4       0.44      0.43      0.44       210\n",
      "           5       0.37      0.36      0.37       210\n",
      "           6       0.32      0.33      0.32       210\n",
      "           7       0.52      0.53      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.49795918367346936\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   5  10  24  43  24  10]\n",
      " [  8 130   8  12  22  22   8]\n",
      " [  9   8 168   8   3   9   5]\n",
      " [ 21  19  14  81  26  32  17]\n",
      " [ 45  26   5  25  75  24  10]\n",
      " [ 14  16  11  33  18  71  47]\n",
      " [ 13  14   3  15  11  41 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.45      0.45       210\n",
      "           2       0.60      0.62      0.61       210\n",
      "           3       0.77      0.80      0.78       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.38      0.36      0.37       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.54      0.54      0.54       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   8   8  26  38  21  12]\n",
      " [  9 126   9  15  21  23   7]\n",
      " [  6  10 167   8   3  12   4]\n",
      " [ 16  16  14  85  30  29  20]\n",
      " [ 37  23   6  24  83  24  13]\n",
      " [ 22  21   7  29  18  66  47]\n",
      " [ 14  10   5  16  10  49 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.46      0.47       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.77      0.80      0.78       210\n",
      "           4       0.42      0.40      0.41       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.29      0.31      0.30       210\n",
      "           7       0.51      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.3952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 24   0  31   3  87   1  64]\n",
      " [  1  50  68   8  37   0  46]\n",
      " [  0   1 180   4   7   0  18]\n",
      " [  3   3  36   9  49   1 109]\n",
      " [  4   5  11   4 119   0  67]\n",
      " [  2   8  21   3  30   0 146]\n",
      " [  0   0   3   0   8   0 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.11      0.20       210\n",
      "           2       0.75      0.24      0.36       210\n",
      "           3       0.51      0.86      0.64       210\n",
      "           4       0.29      0.04      0.07       210\n",
      "           5       0.35      0.57      0.44       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.31      0.95      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.31      1470\n",
      "weighted avg       0.42      0.40      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.48299319727891155\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 86   2   1   2  67   0  52]\n",
      " [  2  96  25   5  47   1  34]\n",
      " [  1   9 175   2   9   0  14]\n",
      " [  9  13  24  15  69   1  79]\n",
      " [ 10  15   3   2 135   0  45]\n",
      " [  6  16  16   5  26   1 140]\n",
      " [  0   1   0   1   6   0 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.41      0.53       210\n",
      "           2       0.63      0.46      0.53       210\n",
      "           3       0.72      0.83      0.77       210\n",
      "           4       0.47      0.07      0.12       210\n",
      "           5       0.38      0.64      0.47       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.36      0.96      0.52       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.52      0.48      0.42      1470\n",
      "weighted avg       0.52      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89   0   1   4  66   7  43]\n",
      " [  0 142  10   3  35   2  18]\n",
      " [  1  19 170   2   6   5   7]\n",
      " [  3  28  14  44  50   6  65]\n",
      " [ 11  24   1   4 128   1  41]\n",
      " [  4  22  13  15  22   4 130]\n",
      " [  0   3   0   2   5   3 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.42      0.56       210\n",
      "           2       0.60      0.68      0.63       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.59      0.21      0.31       210\n",
      "           5       0.41      0.61      0.49       210\n",
      "           6       0.14      0.02      0.03       210\n",
      "           7       0.39      0.94      0.55       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.48      1470\n",
      "weighted avg       0.54      0.53      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89   2   1   8  61  10  39]\n",
      " [  0 148   5   7  33   7  10]\n",
      " [  1  16 164  12   5  10   2]\n",
      " [  2  20  13  82  32  11  50]\n",
      " [ 15  18   1  13 121   2  40]\n",
      " [  4  18   9  20  17  18 124]\n",
      " [  0   1   0   3   5   2 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.42      0.55       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.57      0.39      0.46       210\n",
      "           5       0.44      0.58      0.50       210\n",
      "           6       0.30      0.09      0.13       210\n",
      "           7       0.43      0.95      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.53      1470\n",
      "weighted avg       0.58      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   1   1  11  54  18  26]\n",
      " [  0 143   5  10  31  13   8]\n",
      " [  1  11 169  12   4  11   2]\n",
      " [  1  13  12  99  24  18  43]\n",
      " [ 13  17   1  11 126   6  36]\n",
      " [  2  16   8  33  11  25 115]\n",
      " [  0   1   0   2   5   4 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.47      0.61       210\n",
      "           2       0.71      0.68      0.69       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.56      0.47      0.51       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.26      0.12      0.16       210\n",
      "           7       0.46      0.94      0.62       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.57      1470\n",
      "weighted avg       0.60      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   0   0  10  55  26  22]\n",
      " [  0 148   4  13  25  16   4]\n",
      " [  2   8 170  13   4  12   1]\n",
      " [  3  12   8 112  16  27  32]\n",
      " [ 11  15   0  15 127  13  29]\n",
      " [  3   7   7  28  12  53 100]\n",
      " [  0   1   0   2   3   5 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.46      0.60       210\n",
      "           2       0.77      0.70      0.74       210\n",
      "           3       0.90      0.81      0.85       210\n",
      "           4       0.58      0.53      0.56       210\n",
      "           5       0.52      0.60      0.56       210\n",
      "           6       0.35      0.25      0.29       210\n",
      "           7       0.51      0.95      0.67       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.61      1470\n",
      "weighted avg       0.64      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   1   1   8  52  29  13]\n",
      " [  0 142   4  12  29  18   5]\n",
      " [  1   6 171  13   3  15   1]\n",
      " [  1   8   8 126  15  29  23]\n",
      " [ 14  19   1  12 125  13  26]\n",
      " [  3   6   4  21   9  77  90]\n",
      " [  0   0   0   2   4   7 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.50      0.63       210\n",
      "           2       0.78      0.68      0.72       210\n",
      "           3       0.90      0.81      0.86       210\n",
      "           4       0.65      0.60      0.62       210\n",
      "           5       0.53      0.60      0.56       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.55      0.94      0.70       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6503401360544218\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   0   0   9  45  25  15]\n",
      " [  1 147   3  11  28  18   2]\n",
      " [  2   6 169  10   7  15   1]\n",
      " [  1   6   7 126  15  36  19]\n",
      " [ 12  14   1  13 128  16  26]\n",
      " [  3   5   5  20  10  78  89]\n",
      " [  0   1   0   0   5  12 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.55      0.67       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.91      0.80      0.86       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.54      0.61      0.57       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.56      0.91      0.69       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114   0   0  12  44  25  15]\n",
      " [  0 152   4  11  23  17   3]\n",
      " [  4   4 172  16   3  10   1]\n",
      " [  1  10   5 132  16  26  20]\n",
      " [ 10  16   1  12 134  12  25]\n",
      " [  2   8   5  18   9  89  79]\n",
      " [  0   1   0   0   4  14 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.54      0.67       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.66      0.63      0.64       210\n",
      "           5       0.58      0.64      0.60       210\n",
      "           6       0.46      0.42      0.44       210\n",
      "           7       0.57      0.91      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113   1   0   5  50  29  12]\n",
      " [  0 161   2   9  23  10   5]\n",
      " [  2   4 175   8   8  12   1]\n",
      " [  3   8   5 133  19  27  15]\n",
      " [ 16  14   2  10 135  12  21]\n",
      " [  2   7   7  17  10  98  69]\n",
      " [  0   2   0   1   2  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.54      0.65       210\n",
      "           2       0.82      0.77      0.79       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.73      0.63      0.68       210\n",
      "           5       0.55      0.64      0.59       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.60      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   1   0   9  45  22  14]\n",
      " [  0 151   3  11  25  18   2]\n",
      " [  3   6 171  13   4  13   0]\n",
      " [  0   5   4 135  19  29  18]\n",
      " [ 16   9   0  16 137  13  19]\n",
      " [  2   8   7  16  11  93  73]\n",
      " [  0   1   0   0   4  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.57      0.68       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.92      0.81      0.87       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.56      0.65      0.60       210\n",
      "           6       0.45      0.44      0.45       210\n",
      "           7       0.60      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0   0   9  42  20  17]\n",
      " [  0 148   4  11  30  15   2]\n",
      " [  3  11 169   6   7  13   1]\n",
      " [  4   6   2 140  18  25  15]\n",
      " [ 19  14   1  16 128  11  21]\n",
      " [  3   6   5  13  10  98  75]\n",
      " [  0   1   0   1   2  15 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.58      0.68       210\n",
      "           2       0.80      0.70      0.75       210\n",
      "           3       0.93      0.80      0.86       210\n",
      "           4       0.71      0.67      0.69       210\n",
      "           5       0.54      0.61      0.57       210\n",
      "           6       0.50      0.47      0.48       210\n",
      "           7       0.59      0.91      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   3   0   6  47  24   9]\n",
      " [  2 155   2  10  21  17   3]\n",
      " [  3   5 171  11   7  12   1]\n",
      " [  2   9   5 137  19  25  13]\n",
      " [  7  12   3  21 140   8  19]\n",
      " [  3   7   4  17   9  91  79]\n",
      " [  0   2   0   0   2  15 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.58      0.70       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.92      0.81      0.87       210\n",
      "           4       0.68      0.65      0.67       210\n",
      "           5       0.57      0.67      0.62       210\n",
      "           6       0.47      0.43      0.45       210\n",
      "           7       0.61      0.91      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   2   1  13  41  25  10]\n",
      " [  1 159   5   5  26  10   4]\n",
      " [  3   7 173  12   4   9   2]\n",
      " [  2  10   4 140  17  25  12]\n",
      " [ 20  11   1  20 130   9  19]\n",
      " [  2  10   4  19   8 104  63]\n",
      " [  0   2   0   0   5  14 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.56      0.66       210\n",
      "           2       0.79      0.76      0.77       210\n",
      "           3       0.92      0.82      0.87       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.56      0.62      0.59       210\n",
      "           6       0.53      0.50      0.51       210\n",
      "           7       0.63      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0   1  12  41  25   9]\n",
      " [  0 157   4   9  23  13   4]\n",
      " [  5   3 171  12   2  17   0]\n",
      " [  2   6   8 146  13  21  14]\n",
      " [ 14  15   3  19 127  12  20]\n",
      " [  0   8   3  16  10 106  67]\n",
      " [  0   2   0   2   3  14 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.58      0.69       210\n",
      "           2       0.82      0.75      0.78       210\n",
      "           3       0.90      0.81      0.85       210\n",
      "           4       0.68      0.70      0.69       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.51      0.50      0.51       210\n",
      "           7       0.62      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   2   0   8  43  24  12]\n",
      " [  1 153   4  12  22  15   3]\n",
      " [  3   5 171  13   6  11   1]\n",
      " [  4   8   4 141  16  23  14]\n",
      " [ 14  14   1  17 135   8  21]\n",
      " [  2   8   4  24   8  91  73]\n",
      " [  0   2   0   1   3  15 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.58      0.68       210\n",
      "           2       0.80      0.73      0.76       210\n",
      "           3       0.93      0.81      0.87       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.49      0.43      0.46       210\n",
      "           7       0.60      0.90      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   0   0   9  44  24  12]\n",
      " [  0 162   3  10  21  10   4]\n",
      " [  5   5 173   9   2  15   1]\n",
      " [  3  10   4 144  14  27   8]\n",
      " [ 17  15   1  16 133   9  19]\n",
      " [  2   7   4  17  10 106  64]\n",
      " [  1   1   0   1   3  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.58      0.67       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.94      0.82      0.88       210\n",
      "           4       0.70      0.69      0.69       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.63      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   0   1   9  44  22  11]\n",
      " [  0 161   3  12  20  10   4]\n",
      " [  2   7 173   9   3  15   1]\n",
      " [  2   7   7 142  14  29   9]\n",
      " [ 17  12   1  19 133   8  20]\n",
      " [  2   9   6  17   9 105  62]\n",
      " [  1   1   0   2   3  21 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.59      0.69       210\n",
      "           2       0.82      0.77      0.79       210\n",
      "           3       0.91      0.82      0.86       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.63      0.87      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   1   1  10  47  18   8]\n",
      " [  2 159   3  13  19  10   4]\n",
      " [  4   6 171  11   5  11   2]\n",
      " [  2   7   8 142  14  26  11]\n",
      " [ 15  16   2  15 134  15  13]\n",
      " [  2   8   4  15   9 101  71]\n",
      " [  0   2   0   1   3  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.69       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.90      0.81      0.86       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.51      0.48      0.49       210\n",
      "           7       0.63      0.88      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   0   1  13  42  22   9]\n",
      " [  2 159   3  13  20   9   4]\n",
      " [  3   5 173  12   4  13   0]\n",
      " [  4   7   7 149  13  19  11]\n",
      " [ 17  14   1  18 130  13  17]\n",
      " [  2   8   6  20   8 104  62]\n",
      " [  0   2   0   2   2  18 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.59      0.68       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.91      0.82      0.86       210\n",
      "           4       0.66      0.71      0.68       210\n",
      "           5       0.59      0.62      0.61       210\n",
      "           6       0.53      0.50      0.51       210\n",
      "           7       0.64      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 75   0  11   4  63  21  36]\n",
      " [  0 114   7   8  49  24   8]\n",
      " [  8   8 155   5   8  25   1]\n",
      " [  3  12  15  69  35  29  47]\n",
      " [ 13  11   1   7 128   9  41]\n",
      " [  4   7  12  23  24  36 104]\n",
      " [  0   1   0  12  11   4 182]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.36      0.48       210\n",
      "           2       0.75      0.54      0.63       210\n",
      "           3       0.77      0.74      0.75       210\n",
      "           4       0.54      0.33      0.41       210\n",
      "           5       0.40      0.61      0.48       210\n",
      "           6       0.24      0.17      0.20       210\n",
      "           7       0.43      0.87      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.50      1470\n",
      "weighted avg       0.55      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Normalize Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[102   4   1  14  47  13  29]\n",
      " [  8 120  17  20  29  10   6]\n",
      " [  4  14 171   7   3  10   1]\n",
      " [  7  15  12  83  33  38  22]\n",
      " [ 12  26   6  23 104  10  29]\n",
      " [ 15  14  11  24  23  59  64]\n",
      " [  8   6   0  14  25  32 125]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.49      0.56       210\n",
      "           2       0.60      0.57      0.59       210\n",
      "           3       0.78      0.81      0.80       210\n",
      "           4       0.45      0.40      0.42       210\n",
      "           5       0.39      0.50      0.44       210\n",
      "           6       0.34      0.28      0.31       210\n",
      "           7       0.45      0.60      0.51       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122  10   1  18  41   8  10]\n",
      " [ 24 117  17  12  26  10   4]\n",
      " [ 11  16 162   9   9   3   0]\n",
      " [ 53  18   7  80  31   7  14]\n",
      " [ 61  27   4  30  65   8  15]\n",
      " [ 50  26   2  33  30  30  39]\n",
      " [ 41  16   0  30  38  14  71]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.58      0.43       210\n",
      "           2       0.51      0.56      0.53       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.27      0.31      0.29       210\n",
      "           6       0.38      0.14      0.21       210\n",
      "           7       0.46      0.34      0.39       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.43      1470\n",
      "weighted avg       0.45      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[110   5   2  19  46  12  16]\n",
      " [ 24 112  14  13  31  10   6]\n",
      " [  9  18 163   9   7   3   1]\n",
      " [ 44  16   7  82  35  11  15]\n",
      " [ 42  27   1  21  77  20  22]\n",
      " [ 41  18   4  28  32  40  47]\n",
      " [ 33  10   0  23  42  22  80]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.52      0.43       210\n",
      "           2       0.54      0.53      0.54       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.29      0.37      0.32       210\n",
      "           6       0.34      0.19      0.24       210\n",
      "           7       0.43      0.38      0.40       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.463265306122449\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[110   7   1  14  48  13  17]\n",
      " [ 19 120   9  13  32   9   8]\n",
      " [ 10  14 165  11   6   3   1]\n",
      " [ 36  13   7  89  42  14   9]\n",
      " [ 36  24   4  27  76  22  21]\n",
      " [ 29  20   5  37  41  37  41]\n",
      " [ 27   5   0  26  41  27  84]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.52      0.46       210\n",
      "           2       0.59      0.57      0.58       210\n",
      "           3       0.86      0.79      0.82       210\n",
      "           4       0.41      0.42      0.42       210\n",
      "           5       0.27      0.36      0.31       210\n",
      "           6       0.30      0.18      0.22       210\n",
      "           7       0.46      0.40      0.43       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[105   6   1  18  49  13  18]\n",
      " [ 11 122   9  19  36  10   3]\n",
      " [  9  18 162  12   5   3   1]\n",
      " [ 35   9   9  87  48  13   9]\n",
      " [ 32  26   1  28  87  17  19]\n",
      " [ 26  26   5  40  42  28  43]\n",
      " [ 22   6   0  26  49  20  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.50      0.47       210\n",
      "           2       0.57      0.58      0.58       210\n",
      "           3       0.87      0.77      0.82       210\n",
      "           4       0.38      0.41      0.40       210\n",
      "           5       0.28      0.41      0.33       210\n",
      "           6       0.27      0.13      0.18       210\n",
      "           7       0.48      0.41      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[103   6   1  16  55  10  19]\n",
      " [ 12 116  11  23  36   8   4]\n",
      " [ 10  15 164  11   7   3   0]\n",
      " [ 34  10   8  89  47  10  12]\n",
      " [ 30  27   1  22  95  15  20]\n",
      " [ 25  28   4  34  40  30  49]\n",
      " [ 24   7   0  24  40  17  98]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.49      0.46       210\n",
      "           2       0.56      0.55      0.55       210\n",
      "           3       0.87      0.78      0.82       210\n",
      "           4       0.41      0.42      0.41       210\n",
      "           5       0.30      0.45      0.36       210\n",
      "           6       0.32      0.14      0.20       210\n",
      "           7       0.49      0.47      0.48       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Normalize Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[106   5   3  19  49   8  20]\n",
      " [ 12 114  10  20  41   9   4]\n",
      " [  9  19 160   9   8   5   0]\n",
      " [ 26  13   9  86  53  13  10]\n",
      " [ 32  27   1  19  91  15  25]\n",
      " [ 28  20   5  35  38  31  53]\n",
      " [ 25   7   0  22  40  21  95]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.50      0.47       210\n",
      "           2       0.56      0.54      0.55       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.28      0.43      0.34       210\n",
      "           6       0.30      0.15      0.20       210\n",
      "           7       0.46      0.45      0.46       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Normalize Scaling is: 0.4095238095238095\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 54  21   1  53  44   9  28]\n",
      " [ 15 112  10  33  20   4  16]\n",
      " [  3  32 148  21   2   2   2]\n",
      " [  7  21   5  76  43  19  39]\n",
      " [  7  33   2  52  74   5  37]\n",
      " [ 12  23   4  53  26  31  61]\n",
      " [  3   5   0  47  28  20 107]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.26      0.35       210\n",
      "           2       0.45      0.53      0.49       210\n",
      "           3       0.87      0.70      0.78       210\n",
      "           4       0.23      0.36      0.28       210\n",
      "           5       0.31      0.35      0.33       210\n",
      "           6       0.34      0.15      0.21       210\n",
      "           7       0.37      0.51      0.43       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.41      1470\n",
      "weighted avg       0.44      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Normalize Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 52  26   1  53  41   7  30]\n",
      " [ 11 114   5  37  23   3  17]\n",
      " [  7  38 139  21   2   0   3]\n",
      " [  6  23   5  77  42  15  42]\n",
      " [  8  36   2  49  70   6  39]\n",
      " [ 11  32   2  49  23  30  63]\n",
      " [  4   9   0  45  32  17 103]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.25      0.34       210\n",
      "           2       0.41      0.54      0.47       210\n",
      "           3       0.90      0.66      0.76       210\n",
      "           4       0.23      0.37      0.28       210\n",
      "           5       0.30      0.33      0.32       210\n",
      "           6       0.38      0.14      0.21       210\n",
      "           7       0.35      0.49      0.41       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.44      0.40      0.40      1470\n",
      "weighted avg       0.44      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Normalize Scaling is: 0.5238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 88   3   0  16  53  17  33]\n",
      " [  6 122  10  22  29  14   7]\n",
      " [  3  12 175   7   2  11   0]\n",
      " [  7  13   8  86  31  45  20]\n",
      " [ 12  29   4  25 103  10  27]\n",
      " [ 12  10   8  28  19  64  69]\n",
      " [  8   4   0  16  21  29 132]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.42      0.51       210\n",
      "           2       0.63      0.58      0.61       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.40      0.49      0.44       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.46      0.63      0.53       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.52      1470\n",
      "weighted avg       0.54      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Normalize Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of SVM is:\n",
      " [[101   5   0  13  43  20  28]\n",
      " [  1 132   9  23  23  15   7]\n",
      " [  2  13 171   8   3  13   0]\n",
      " [  5  13   6  94  32  43  17]\n",
      " [  9  24   2  27 105  17  26]\n",
      " [  8  15   2  23  17  77  68]\n",
      " [  5   1   0  22  20  43 119]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.48      0.59       210\n",
      "           2       0.65      0.63      0.64       210\n",
      "           3       0.90      0.81      0.85       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.43      0.50      0.46       210\n",
      "           6       0.34      0.37      0.35       210\n",
      "           7       0.45      0.57      0.50       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.55      1470\n",
      "weighted avg       0.57      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Normalize Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 94   1   0  15  49  20  31]\n",
      " [  5 121   9  23  27  18   7]\n",
      " [  3  12 173   7   3  12   0]\n",
      " [  6  12   6  88  33  45  20]\n",
      " [  9  25   2  25 105  16  28]\n",
      " [  9  13   4  23  19  70  72]\n",
      " [  5   3   0  21  20  33 128]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.45      0.55       210\n",
      "           2       0.65      0.58      0.61       210\n",
      "           3       0.89      0.82      0.86       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.33      0.33      0.33       210\n",
      "           7       0.45      0.61      0.52       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.53      1470\n",
      "weighted avg       0.55      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Normalize Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 87   4   0  18  51  16  34]\n",
      " [  5 122  13  21  28  14   7]\n",
      " [  2  15 172   7   3  11   0]\n",
      " [  5  12  12  82  33  43  23]\n",
      " [ 13  28   6  23 103   8  29]\n",
      " [ 13  13   8  28  21  59  68]\n",
      " [  5   6   0  17  23  27 132]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.41      0.51       210\n",
      "           2       0.61      0.58      0.60       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.39      0.49      0.44       210\n",
      "           6       0.33      0.28      0.30       210\n",
      "           7       0.45      0.63      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.51      1470\n",
      "weighted avg       0.53      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.22585034013605443\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  11   0   0   0 199]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0 122   0   0   0  88]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.79      0.58      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.14      0.23      0.14      1470\n",
      "weighted avg       0.14      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.24081632653061225\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   1   4   0 198   7   0]\n",
      " [  0  29   5   0 173   3   0]\n",
      " [  0   0 116   0  88   6   0]\n",
      " [  0   1   0   0 204   5   0]\n",
      " [  0   2   0   0 205   3   0]\n",
      " [  0   1   1   0 204   4   0]\n",
      " [  0   1   0   0 209   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.83      0.14      0.24       210\n",
      "           3       0.92      0.55      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      0.98      0.27       210\n",
      "           6       0.14      0.02      0.03       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.29      0.24      0.18      1470\n",
      "weighted avg       0.29      0.24      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.26326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 29   4   1   0   0   1 175]\n",
      " [  3  30   3   0   0   3 171]\n",
      " [  0   1 115   0   0   6  88]\n",
      " [  0   1   0   0   0   5 204]\n",
      " [  2   1   0   0   0   1 206]\n",
      " [  1   0   1   0   0   3 205]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.14      0.24       210\n",
      "           2       0.81      0.14      0.24       210\n",
      "           3       0.96      0.55      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.16      0.01      0.03       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.42      0.26      0.21      1470\n",
      "weighted avg       0.42      0.26      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.282312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 27   2  17   2   1   2 159]\n",
      " [  1  29  21   1   0   6 152]\n",
      " [  0   1 146   0   0   2  61]\n",
      " [  0   0  11   1   0   5 193]\n",
      " [  0   1   7   0   2   1 199]\n",
      " [  1   0  13   0   1   3 192]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.13      0.23       210\n",
      "           2       0.88      0.14      0.24       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.25      0.00      0.01       210\n",
      "           5       0.50      0.01      0.02       210\n",
      "           6       0.16      0.01      0.03       210\n",
      "           7       0.18      0.99      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.51      0.28      0.21      1470\n",
      "weighted avg       0.51      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3074829931972789\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 43   1   4 103   1   0  58]\n",
      " [ 14  32   8 111   2   1  42]\n",
      " [  6   2 140  48   0   1  13]\n",
      " [  6   0   5 105   0   5  89]\n",
      " [  5   2   2 110   2   0  89]\n",
      " [ 11   1   3 108   1   2  84]\n",
      " [  1   0   2  79   0   0 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.20      0.29       210\n",
      "           2       0.84      0.15      0.26       210\n",
      "           3       0.85      0.67      0.75       210\n",
      "           4       0.16      0.50      0.24       210\n",
      "           5       0.33      0.01      0.02       210\n",
      "           6       0.22      0.01      0.02       210\n",
      "           7       0.25      0.61      0.36       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.45      0.31      0.28      1470\n",
      "weighted avg       0.45      0.31      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3258503401360544\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 29  13   2 102   1   5  58]\n",
      " [  3  69   4  87   0   5  42]\n",
      " [  0  16 139  40   0   2  13]\n",
      " [  2   6   3 106   0   4  89]\n",
      " [  0   8   0 108   3   2  89]\n",
      " [  0  10   1 108   2   5  84]\n",
      " [  0   3   2  77   0   0 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.14      0.24       210\n",
      "           2       0.55      0.33      0.41       210\n",
      "           3       0.92      0.66      0.77       210\n",
      "           4       0.17      0.50      0.25       210\n",
      "           5       0.50      0.01      0.03       210\n",
      "           6       0.22      0.02      0.04       210\n",
      "           7       0.25      0.61      0.36       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.50      0.33      0.30      1470\n",
      "weighted avg       0.50      0.33      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   6   2  53  10  43  14]\n",
      " [ 29  62   4  68   2  38   7]\n",
      " [  8   5 139  38   6  13   1]\n",
      " [ 45   1   1  70   5  65  23]\n",
      " [ 55   3   0  60   7  65  20]\n",
      " [ 32   4   1  82   8  56  27]\n",
      " [ 30   1   1  56   1  66  55]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.39      0.33       210\n",
      "           2       0.76      0.30      0.42       210\n",
      "           3       0.94      0.66      0.78       210\n",
      "           4       0.16      0.33      0.22       210\n",
      "           5       0.18      0.03      0.06       210\n",
      "           6       0.16      0.27      0.20       210\n",
      "           7       0.37      0.26      0.31       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.41      0.32      0.33      1470\n",
      "weighted avg       0.41      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55  15   2  43  47  34  14]\n",
      " [ 14  87   3  41  33  25   7]\n",
      " [  7  10 145  27  13   7   1]\n",
      " [ 30  12   1  59  38  47  23]\n",
      " [ 17  20   0  43  70  40  20]\n",
      " [ 16  29   0  53  44  42  26]\n",
      " [ 13  10   1  41  42  48  55]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.26      0.30       210\n",
      "           2       0.48      0.41      0.44       210\n",
      "           3       0.95      0.69      0.80       210\n",
      "           4       0.19      0.28      0.23       210\n",
      "           5       0.24      0.33      0.28       210\n",
      "           6       0.17      0.20      0.19       210\n",
      "           7       0.38      0.26      0.31       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.40      0.35      0.36      1470\n",
      "weighted avg       0.40      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.34829931972789113\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57  13   2  54  40  27  17]\n",
      " [ 15  90   4  45  25  19  12]\n",
      " [  7   8 144  31   7   9   4]\n",
      " [ 35  12   1  67  35  39  21]\n",
      " [ 24  19   0  49  56  34  28]\n",
      " [ 27  29   0  55  29  36  34]\n",
      " [ 16  10   1  44  34  43  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.27      0.29       210\n",
      "           2       0.50      0.43      0.46       210\n",
      "           3       0.95      0.69      0.80       210\n",
      "           4       0.19      0.32      0.24       210\n",
      "           5       0.25      0.27      0.26       210\n",
      "           6       0.17      0.17      0.17       210\n",
      "           7       0.35      0.30      0.32       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.39      0.35      0.36      1470\n",
      "weighted avg       0.39      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 59   9   2  51  24  33  32]\n",
      " [ 17  77   6  42  26  25  17]\n",
      " [  6   9 149  26   8   9   3]\n",
      " [ 33   9   2  67  27  47  25]\n",
      " [ 22   9   2  48  57  38  34]\n",
      " [ 20  17   3  54  28  50  38]\n",
      " [ 13   6   2  42  30  49  68]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.28      0.31       210\n",
      "           2       0.57      0.37      0.45       210\n",
      "           3       0.90      0.71      0.79       210\n",
      "           4       0.20      0.32      0.25       210\n",
      "           5       0.28      0.27      0.28       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.31      0.32      0.32       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.40      0.36      0.37      1470\n",
      "weighted avg       0.40      0.36      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36802721088435375\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68   9   2  46  21  48  16]\n",
      " [ 18  85   4  39  21  34   9]\n",
      " [  3   8 150  26   8  13   2]\n",
      " [ 35  11   3  68  22  52  19]\n",
      " [ 26  14   2  44  53  52  19]\n",
      " [ 25  23   3  49  21  66  23]\n",
      " [ 16  10   2  36  27  68  51]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.32      0.34       210\n",
      "           2       0.53      0.40      0.46       210\n",
      "           3       0.90      0.71      0.80       210\n",
      "           4       0.22      0.32      0.26       210\n",
      "           5       0.31      0.25      0.28       210\n",
      "           6       0.20      0.31      0.24       210\n",
      "           7       0.37      0.24      0.29       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.38      1470\n",
      "weighted avg       0.41      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3687074829931973\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  15   3  46  19  39  13]\n",
      " [ 20  98   7  40  15  22   8]\n",
      " [  6  11 149  26   9   7   2]\n",
      " [ 39  13   4  73  19  42  20]\n",
      " [ 38  15   2  45  49  40  21]\n",
      " [ 29  29   3  53  27  49  20]\n",
      " [ 23  12   3  41  33  49  49]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.36      0.34       210\n",
      "           2       0.51      0.47      0.49       210\n",
      "           3       0.87      0.71      0.78       210\n",
      "           4       0.23      0.35      0.27       210\n",
      "           5       0.29      0.23      0.26       210\n",
      "           6       0.20      0.23      0.21       210\n",
      "           7       0.37      0.23      0.29       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.40      0.37      0.38      1470\n",
      "weighted avg       0.40      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66  14   4  31  33  39  23]\n",
      " [ 20  93   5  27  27  28  10]\n",
      " [  3  10 152  10  22   9   4]\n",
      " [ 33   9   5  56  41  44  22]\n",
      " [ 27  19   4  21  70  46  23]\n",
      " [ 25  34   3  30  43  49  26]\n",
      " [ 13  15   2  29  49  48  54]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.31      0.33       210\n",
      "           2       0.48      0.44      0.46       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.27      0.27      0.27       210\n",
      "           5       0.25      0.33      0.28       210\n",
      "           6       0.19      0.23      0.21       210\n",
      "           7       0.33      0.26      0.29       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.38      1470\n",
      "weighted avg       0.39      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36802721088435375\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  13   3  40  30  40  23]\n",
      " [ 19  90   9  22  24  34  12]\n",
      " [  3   7 153   9  22  11   5]\n",
      " [ 27  16   7  51  36  51  22]\n",
      " [ 27  16   4  24  67  50  22]\n",
      " [ 22  29   5  31  38  53  32]\n",
      " [ 19   9   2  24  37  53  66]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.29      0.31       210\n",
      "           2       0.50      0.43      0.46       210\n",
      "           3       0.84      0.73      0.78       210\n",
      "           4       0.25      0.24      0.25       210\n",
      "           5       0.26      0.32      0.29       210\n",
      "           6       0.18      0.25      0.21       210\n",
      "           7       0.36      0.31      0.34       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.38      1470\n",
      "weighted avg       0.39      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  17   5  31  28  36  21]\n",
      " [ 19  99   7  23  19  28  15]\n",
      " [  4  12 153  11  18   9   3]\n",
      " [ 30  14   5  55  34  45  27]\n",
      " [ 27  27   6  23  65  41  21]\n",
      " [ 29  41   4  26  31  52  27]\n",
      " [ 25  10   3  29  37  45  61]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.35       210\n",
      "           2       0.45      0.47      0.46       210\n",
      "           3       0.84      0.73      0.78       210\n",
      "           4       0.28      0.26      0.27       210\n",
      "           5       0.28      0.31      0.29       210\n",
      "           6       0.20      0.25      0.22       210\n",
      "           7       0.35      0.29      0.32       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.39      0.38      0.38      1470\n",
      "weighted avg       0.39      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  21   2  48  23  25  26]\n",
      " [ 16  97   9  22  22  27  17]\n",
      " [  6  12 153  11  19   6   3]\n",
      " [ 31  16   8  74  22  27  32]\n",
      " [ 30  35   4  48  46  25  22]\n",
      " [ 25  34   7  54  22  36  32]\n",
      " [ 18  14   5  51  33  30  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.31      0.32       210\n",
      "           2       0.42      0.46      0.44       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.24      0.35      0.29       210\n",
      "           5       0.25      0.22      0.23       210\n",
      "           6       0.20      0.17      0.19       210\n",
      "           7       0.31      0.28      0.29       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63  18   4  43  23  31  28]\n",
      " [ 13 100   8  25  22  25  17]\n",
      " [  6   7 155  12  15  10   5]\n",
      " [ 28  17  10  65  26  36  28]\n",
      " [ 23  30   8  47  49  31  22]\n",
      " [ 24  31   9  52  29  38  27]\n",
      " [ 17  10   5  44  35  39  60]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.30      0.33       210\n",
      "           2       0.47      0.48      0.47       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.23      0.31      0.26       210\n",
      "           5       0.25      0.23      0.24       210\n",
      "           6       0.18      0.18      0.18       210\n",
      "           7       0.32      0.29      0.30       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  19   7  37  20  31  22]\n",
      " [ 20  96   8  24  18  29  15]\n",
      " [  5   9 157   9  12  14   4]\n",
      " [ 34  10   8  61  28  38  31]\n",
      " [ 39  26   7  29  47  36  26]\n",
      " [ 30  30   8  37  27  47  31]\n",
      " [ 20   8   7  34  32  46  63]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.35      0.34       210\n",
      "           2       0.48      0.46      0.47       210\n",
      "           3       0.78      0.75      0.76       210\n",
      "           4       0.26      0.29      0.28       210\n",
      "           5       0.26      0.22      0.24       210\n",
      "           6       0.20      0.22      0.21       210\n",
      "           7       0.33      0.30      0.31       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Normalize Scaling is: 0.3619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  21   6  37  24  27  22]\n",
      " [ 14  95  10  27  22  25  17]\n",
      " [  3  12 155  11  12  13   4]\n",
      " [ 35  19   4  59  28  37  28]\n",
      " [ 38  27   7  27  47  36  28]\n",
      " [ 26  29   7  43  32  42  31]\n",
      " [ 26  14   5  35  35  34  61]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.34       210\n",
      "           2       0.44      0.45      0.44       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.25      0.28      0.26       210\n",
      "           5       0.23      0.22      0.23       210\n",
      "           6       0.20      0.20      0.20       210\n",
      "           7       0.32      0.29      0.30       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Normalize Scaling is: 0.37210884353741497\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  17   8  30  22  32  23]\n",
      " [ 23  97   6  25  17  28  14]\n",
      " [  9  10 156  10   9  10   6]\n",
      " [ 36  18   6  58  27  34  31]\n",
      " [ 36  29   6  28  51  34  26]\n",
      " [ 27  33   5  33  29  45  38]\n",
      " [ 27  13   8  33  30  37  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.37      0.35       210\n",
      "           2       0.45      0.46      0.45       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.27      0.28      0.27       210\n",
      "           5       0.28      0.24      0.26       210\n",
      "           6       0.20      0.21      0.21       210\n",
      "           7       0.31      0.30      0.30       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.28095238095238095\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20   9   8  21   6   4 142]\n",
      " [  7  26  24  26   4   5 118]\n",
      " [  6  15 152  11   1   0  25]\n",
      " [  7  16  13  24   3   6 141]\n",
      " [  2   8   9   9   5   1 176]\n",
      " [  6  11  13   6   4   5 165]\n",
      " [  5   4   4   9   5   2 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.10      0.15       210\n",
      "           2       0.29      0.12      0.17       210\n",
      "           3       0.68      0.72      0.70       210\n",
      "           4       0.23      0.11      0.15       210\n",
      "           5       0.18      0.02      0.04       210\n",
      "           6       0.22      0.02      0.04       210\n",
      "           7       0.19      0.86      0.31       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.31      0.28      0.23      1470\n",
      "weighted avg       0.31      0.28      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.3517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 45  28   3  20   7  10  97]\n",
      " [ 11 112   8  14   8   6  51]\n",
      " [  6  40 146   5   1   2  10]\n",
      " [ 15  34   7  23  12  11 108]\n",
      " [ 14  35   4  13  11   4 129]\n",
      " [  7  41   8  15  12   9 118]\n",
      " [  4  14   1   9   9   2 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.21      0.29       210\n",
      "           2       0.37      0.53      0.44       210\n",
      "           3       0.82      0.70      0.75       210\n",
      "           4       0.23      0.11      0.15       210\n",
      "           5       0.18      0.05      0.08       210\n",
      "           6       0.20      0.04      0.07       210\n",
      "           7       0.25      0.81      0.38       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.36      0.35      0.31      1470\n",
      "weighted avg       0.36      0.35      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 49  23   0  30  31   4  73]\n",
      " [ 10 122   4  17  19   3  35]\n",
      " [  6  33 148  10   2   3   8]\n",
      " [ 10  30   7  31  29   9  94]\n",
      " [  7  27   5  28  39   5  99]\n",
      " [ 12  31   3  25  22  17 100]\n",
      " [  1   9   0  17  20   1 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.23      0.32       210\n",
      "           2       0.44      0.58      0.50       210\n",
      "           3       0.89      0.70      0.79       210\n",
      "           4       0.20      0.15      0.17       210\n",
      "           5       0.24      0.19      0.21       210\n",
      "           6       0.40      0.08      0.13       210\n",
      "           7       0.28      0.77      0.41       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.42      0.39      0.36      1470\n",
      "weighted avg       0.42      0.39      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 46  17   1  46  38  13  49]\n",
      " [ 10 111   2  34  23  10  20]\n",
      " [  4  30 146  16   3   6   5]\n",
      " [  5  18   4  66  29  17  71]\n",
      " [  4  28   3  41  52   6  76]\n",
      " [  7  24   3  49  22  16  89]\n",
      " [  0   7   0  31  19  11 142]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.22      0.32       210\n",
      "           2       0.47      0.53      0.50       210\n",
      "           3       0.92      0.70      0.79       210\n",
      "           4       0.23      0.31      0.27       210\n",
      "           5       0.28      0.25      0.26       210\n",
      "           6       0.20      0.08      0.11       210\n",
      "           7       0.31      0.68      0.43       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.43      0.39      0.38      1470\n",
      "weighted avg       0.43      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 53  12   0  45  51   9  40]\n",
      " [  4 111   3  37  32   3  20]\n",
      " [  2  24 155  18   3   5   3]\n",
      " [  4  16   3  69  42  16  60]\n",
      " [  4  27   3  37  72   5  62]\n",
      " [  6  21   2  40  33  25  83]\n",
      " [  2   5   0  30  29   8 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.25      0.37       210\n",
      "           2       0.51      0.53      0.52       210\n",
      "           3       0.93      0.74      0.82       210\n",
      "           4       0.25      0.33      0.28       210\n",
      "           5       0.27      0.34      0.31       210\n",
      "           6       0.35      0.12      0.18       210\n",
      "           7       0.34      0.65      0.44       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.42      1470\n",
      "weighted avg       0.48      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.42653061224489797\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61   9   0  49  55   5  31]\n",
      " [  3 106   4  39  32   7  19]\n",
      " [  3  24 150  22   5   2   4]\n",
      " [  5  13   5  69  46  19  53]\n",
      " [  5  21   3  38  91   3  49]\n",
      " [  9  17   1  43  36  28  76]\n",
      " [  1   7   0  35  32  13 122]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.29      0.41       210\n",
      "           2       0.54      0.50      0.52       210\n",
      "           3       0.92      0.71      0.80       210\n",
      "           4       0.23      0.33      0.27       210\n",
      "           5       0.31      0.43      0.36       210\n",
      "           6       0.36      0.13      0.20       210\n",
      "           7       0.34      0.58      0.43       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.49      0.43      0.43      1470\n",
      "weighted avg       0.49      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 60   9   0  50  51   6  34]\n",
      " [  5 110   3  40  30   9  13]\n",
      " [  1  22 154  21   6   3   3]\n",
      " [  1  14   1  84  44  18  48]\n",
      " [  9  17   2  37  85  17  43]\n",
      " [ 10  15   1  52  27  30  75]\n",
      " [  3   5   0  41  28  15 118]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.29      0.40       210\n",
      "           2       0.57      0.52      0.55       210\n",
      "           3       0.96      0.73      0.83       210\n",
      "           4       0.26      0.40      0.31       210\n",
      "           5       0.31      0.40      0.35       210\n",
      "           6       0.31      0.14      0.19       210\n",
      "           7       0.35      0.56      0.43       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.49      0.44      0.44      1470\n",
      "weighted avg       0.49      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 64  11   0  41  55   7  32]\n",
      " [  4 109   2  36  30  14  15]\n",
      " [  2  21 154  21   5   5   2]\n",
      " [  7  13   5  76  43  20  46]\n",
      " [  2  17   2  42  95  12  40]\n",
      " [  6  15   3  40  35  38  73]\n",
      " [  4   4   0  38  30  22 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.30      0.43       210\n",
      "           2       0.57      0.52      0.55       210\n",
      "           3       0.93      0.73      0.82       210\n",
      "           4       0.26      0.36      0.30       210\n",
      "           5       0.32      0.45      0.38       210\n",
      "           6       0.32      0.18      0.23       210\n",
      "           7       0.35      0.53      0.42       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.45      1470\n",
      "weighted avg       0.50      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 66   6   1  35  60  12  30]\n",
      " [  6 104   2  42  30  14  12]\n",
      " [  1  14 157  22   5   9   2]\n",
      " [  5  10   5  71  49  27  43]\n",
      " [  8  15   2  42  90  13  40]\n",
      " [  7  16   0  42  31  48  66]\n",
      " [  1   2   0  38  35  22 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.31      0.43       210\n",
      "           2       0.62      0.50      0.55       210\n",
      "           3       0.94      0.75      0.83       210\n",
      "           4       0.24      0.34      0.28       210\n",
      "           5       0.30      0.43      0.35       210\n",
      "           6       0.33      0.23      0.27       210\n",
      "           7       0.37      0.53      0.43       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.45      1470\n",
      "weighted avg       0.50      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.454421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 68   7   0  38  56  14  27]\n",
      " [  6 110   8  29  31  14  12]\n",
      " [  2  21 157  18   5   6   1]\n",
      " [  9  10   5  71  47  26  42]\n",
      " [  6  20   3  32  97  11  41]\n",
      " [ 10   8   1  47  35  50  59]\n",
      " [  3   2   0  40  30  20 115]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.32      0.43       210\n",
      "           2       0.62      0.52      0.57       210\n",
      "           3       0.90      0.75      0.82       210\n",
      "           4       0.26      0.34      0.29       210\n",
      "           5       0.32      0.46      0.38       210\n",
      "           6       0.35      0.24      0.28       210\n",
      "           7       0.39      0.55      0.45       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.50      0.45      0.46      1470\n",
      "weighted avg       0.50      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.45782312925170066\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 68   8   0  43  54   7  30]\n",
      " [  6 106   3  32  34  16  13]\n",
      " [  5  23 154  15   5   5   3]\n",
      " [ 13   8   4  81  41  27  36]\n",
      " [  7  17   2  41  99   8  36]\n",
      " [ 15  15   0  41  31  44  64]\n",
      " [  4   2   0  35  28  20 121]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.32      0.41       210\n",
      "           2       0.59      0.50      0.54       210\n",
      "           3       0.94      0.73      0.83       210\n",
      "           4       0.28      0.39      0.33       210\n",
      "           5       0.34      0.47      0.39       210\n",
      "           6       0.35      0.21      0.26       210\n",
      "           7       0.40      0.58      0.47       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.50      0.46      0.46      1470\n",
      "weighted avg       0.50      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77   3   1  30  51  21  27]\n",
      " [  5 109   8  25  34  16  13]\n",
      " [  3  22 155  16   5   7   2]\n",
      " [  7  10   3  80  39  36  35]\n",
      " [  5  14   2  32 103  14  40]\n",
      " [  9  16   0  46  30  50  59]\n",
      " [  3   0   0  31  34  32 110]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.37      0.48       210\n",
      "           2       0.63      0.52      0.57       210\n",
      "           3       0.92      0.74      0.82       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.35      0.49      0.41       210\n",
      "           6       0.28      0.24      0.26       210\n",
      "           7       0.38      0.52      0.44       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.47      1470\n",
      "weighted avg       0.51      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89   4   0  17  54  19  27]\n",
      " [  4 106   4  33  31  19  13]\n",
      " [  8  17 158  14   3   9   1]\n",
      " [  5  10   5  78  45  30  37]\n",
      " [ 10  20   4  33  96  12  35]\n",
      " [ 11  17   1  41  30  43  67]\n",
      " [  3   4   0  34  36  31 102]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.42      0.52       210\n",
      "           2       0.60      0.50      0.55       210\n",
      "           3       0.92      0.75      0.83       210\n",
      "           4       0.31      0.37      0.34       210\n",
      "           5       0.33      0.46      0.38       210\n",
      "           6       0.26      0.20      0.23       210\n",
      "           7       0.36      0.49      0.41       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.44693877551020406\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78   5   0  27  54  20  26]\n",
      " [  5 103   3  39  30  16  14]\n",
      " [  5  20 157  18   5   3   2]\n",
      " [ 10  15   4  68  44  37  32]\n",
      " [  5  20   3  37  93  18  34]\n",
      " [ 10   9   1  44  30  54  62]\n",
      " [  5   2   0  34  36  29 104]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.37      0.48       210\n",
      "           2       0.59      0.49      0.54       210\n",
      "           3       0.93      0.75      0.83       210\n",
      "           4       0.25      0.32      0.29       210\n",
      "           5       0.32      0.44      0.37       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.38      0.50      0.43       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.44625850340136053\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 74   7   0  32  50  19  28]\n",
      " [  5 106   5  29  37  19   9]\n",
      " [  6  18 158  11   4  11   2]\n",
      " [ 12  10   2  75  48  25  38]\n",
      " [ 13  21   2  29  88  19  38]\n",
      " [ 10   9   1  41  36  54  59]\n",
      " [  3   7   0  34  33  32 101]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.35      0.44       210\n",
      "           2       0.60      0.50      0.55       210\n",
      "           3       0.94      0.75      0.84       210\n",
      "           4       0.30      0.36      0.33       210\n",
      "           5       0.30      0.42      0.35       210\n",
      "           6       0.30      0.26      0.28       210\n",
      "           7       0.37      0.48      0.42       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Normalize Scaling is: 0.4496598639455782\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 86  10   1  28  48  11  26]\n",
      " [  6 101   4  29  36  21  13]\n",
      " [  4  14 160  12   9  10   1]\n",
      " [ 13  11   3  72  43  39  29]\n",
      " [  9  23   2  32  90  18  36]\n",
      " [ 13  11   1  47  29  49  60]\n",
      " [  3   4   0  40  33  27 103]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.41      0.50       210\n",
      "           2       0.58      0.48      0.53       210\n",
      "           3       0.94      0.76      0.84       210\n",
      "           4       0.28      0.34      0.31       210\n",
      "           5       0.31      0.43      0.36       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.38      0.49      0.43       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 76   9   0  27  50  21  27]\n",
      " [  4 108   6  29  36  16  11]\n",
      " [  5  15 160  13   5   8   4]\n",
      " [ 12  10   4  67  43  34  40]\n",
      " [  7  24   1  24  97  18  39]\n",
      " [ 12  16   2  36  34  56  54]\n",
      " [  8   3   0  32  36  23 108]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.36      0.46       210\n",
      "           2       0.58      0.51      0.55       210\n",
      "           3       0.92      0.76      0.84       210\n",
      "           4       0.29      0.32      0.31       210\n",
      "           5       0.32      0.46      0.38       210\n",
      "           6       0.32      0.27      0.29       210\n",
      "           7       0.38      0.51      0.44       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.46      1470\n",
      "weighted avg       0.49      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 72   8   0  27  56  23  24]\n",
      " [  3 101   4  39  29  22  12]\n",
      " [  1  17 159  18   7   6   2]\n",
      " [ 15  12   3  73  35  33  39]\n",
      " [ 11  21   3  27  94  22  32]\n",
      " [ 12  11   2  40  32  52  61]\n",
      " [  8   3   0  29  29  30 111]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.34      0.43       210\n",
      "           2       0.58      0.48      0.53       210\n",
      "           3       0.93      0.76      0.83       210\n",
      "           4       0.29      0.35      0.32       210\n",
      "           5       0.33      0.45      0.38       210\n",
      "           6       0.28      0.25      0.26       210\n",
      "           7       0.40      0.53      0.45       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77   6   1  39  43  13  31]\n",
      " [  3 110   5  36  30  13  13]\n",
      " [  3  16 159  13   6  11   2]\n",
      " [ 13   9   4  79  39  32  34]\n",
      " [ 11  21   1  39  94  17  27]\n",
      " [ 12  11   1  38  33  52  63]\n",
      " [  3   3   0  27  30  35 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.37      0.46       210\n",
      "           2       0.62      0.52      0.57       210\n",
      "           3       0.93      0.76      0.83       210\n",
      "           4       0.29      0.38      0.33       210\n",
      "           5       0.34      0.45      0.39       210\n",
      "           6       0.30      0.25      0.27       210\n",
      "           7       0.40      0.53      0.46       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.50      0.46      0.47      1470\n",
      "weighted avg       0.50      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Normalize Scaling is: 0.46190476190476193\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77   8   0  28  50  17  30]\n",
      " [  4 112   9  27  25  21  12]\n",
      " [  5  15 161  12   5  10   2]\n",
      " [ 14  15   5  76  35  33  32]\n",
      " [  8  15   2  33  95  24  33]\n",
      " [ 16  15   1  37  27  56  58]\n",
      " [  8   3   0  27  38  32 102]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.37      0.45       210\n",
      "           2       0.61      0.53      0.57       210\n",
      "           3       0.90      0.77      0.83       210\n",
      "           4       0.32      0.36      0.34       210\n",
      "           5       0.35      0.45      0.39       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.38      0.49      0.43       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Normalize Scaling is: 0.3891156462585034\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 54  28   2  50  37   7  32]\n",
      " [ 15  97  32  27  20   3  16]\n",
      " [  6  39 149  11   2   0   3]\n",
      " [ 11  25  11  69  34  15  45]\n",
      " [  9  35   6  48  68   4  40]\n",
      " [ 14  32   6  44  22  27  65]\n",
      " [  4   8   0  44  25  21 108]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.26      0.33       210\n",
      "           2       0.37      0.46      0.41       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.24      0.33      0.27       210\n",
      "           5       0.33      0.32      0.33       210\n",
      "           6       0.35      0.13      0.19       210\n",
      "           7       0.35      0.51      0.42       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.38      1470\n",
      "weighted avg       0.40      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//xlm_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = normalize_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
