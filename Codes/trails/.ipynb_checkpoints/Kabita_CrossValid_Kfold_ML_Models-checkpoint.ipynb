{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afc217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting path of file\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//kabita_dataset_labels.csv\")\n",
    "#converting datframe to numpy array\n",
    "labels = labels_df.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_fold, y_fold, model_name):\n",
    "    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "    results = cross_val_score(ml_model, x_fold, y_fold, cv=kfold)\n",
    "    print(\"Accuracies for K-Fold for \"+model_name+\" :\", results)\n",
    "    print(\"Mean Accuracy of K-Fold for \"+model_name+\" :\", results.mean()*100.0)\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for K-Fold for Multinomial Naive Bayes : [0.718 0.78  0.733 0.686 0.716 0.712 0.71  0.704 0.729 0.69 ]\n",
      "Mean Accuracy of K-Fold for Multinomial Naive Bayes : 71.77551020408163\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7095238095238096\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[156   2   1   7  26  17   1]\n",
      " [  0 156  10  14   9  19   2]\n",
      " [  0   3 181  11   1  14   0]\n",
      " [  2  12  17 142  12  20   5]\n",
      " [ 26  17   9  15 133   3   7]\n",
      " [  6  11   6  18   4 120  45]\n",
      " [  2   3   0   5   3  42 155]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.74      0.78       210\n",
      "           2       0.76      0.74      0.75       210\n",
      "           3       0.81      0.86      0.83       210\n",
      "           4       0.67      0.68      0.67       210\n",
      "           5       0.71      0.63      0.67       210\n",
      "           6       0.51      0.57      0.54       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  17   6  18   5  20   4]\n",
      " [ 11 145  20   9   7  18   0]\n",
      " [  9   5 170   6   2  18   0]\n",
      " [ 29  14  17 123   1  23   3]\n",
      " [ 56  49  25  30  32  11   7]\n",
      " [ 28  20   4  19   2 111  26]\n",
      " [ 14  14   0  11   2  57 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.67      0.56       210\n",
      "           2       0.55      0.69      0.61       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.57      0.59      0.58       210\n",
      "           5       0.63      0.15      0.25       210\n",
      "           6       0.43      0.53      0.47       210\n",
      "           7       0.74      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.55      1470\n",
      "weighted avg       0.59      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141  14   4  18   5  23   5]\n",
      " [ 11 147  19   9   6  18   0]\n",
      " [  7   4 170  12   3  14   0]\n",
      " [ 30  15  19 122   2  20   2]\n",
      " [ 60  47  27  33  24  11   8]\n",
      " [ 20  24   6  20   3 110  27]\n",
      " [ 11  16   1   7   1  71 103]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.58       210\n",
      "           2       0.55      0.70      0.62       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.55      0.58      0.57       210\n",
      "           5       0.55      0.11      0.19       210\n",
      "           6       0.41      0.52      0.46       210\n",
      "           7       0.71      0.49      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.53      1470\n",
      "weighted avg       0.57      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134  14   4  17  14  23   4]\n",
      " [  9 143  21  10   7  20   0]\n",
      " [ 11   3 168  11   2  15   0]\n",
      " [ 22  12  19 130   5  20   2]\n",
      " [ 50  46  31  37  30   8   8]\n",
      " [ 16  27   7  22   5 111  22]\n",
      " [  9  14   0  10   2  61 114]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.64      0.58       210\n",
      "           2       0.55      0.68      0.61       210\n",
      "           3       0.67      0.80      0.73       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.46      0.14      0.22       210\n",
      "           6       0.43      0.53      0.47       210\n",
      "           7       0.76      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136  13   4  16  15  24   2]\n",
      " [  9 151  21   9   4  16   0]\n",
      " [  9   4 171  11   1  14   0]\n",
      " [ 20  21  18 123   4  23   1]\n",
      " [ 49  50  36  33  29   7   6]\n",
      " [ 18  32   7  20   3 111  19]\n",
      " [  9  15   0  12   2  65 107]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.65      0.59       210\n",
      "           2       0.53      0.72      0.61       210\n",
      "           3       0.67      0.81      0.73       210\n",
      "           4       0.55      0.59      0.57       210\n",
      "           5       0.50      0.14      0.22       210\n",
      "           6       0.43      0.53      0.47       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.54      1470\n",
      "weighted avg       0.57      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136  12   3  16  13  27   3]\n",
      " [  9 142  27   8   6  18   0]\n",
      " [  8   3 174   9   0  16   0]\n",
      " [ 18  19  19 131   2  20   1]\n",
      " [ 47  48  35  34  30  10   6]\n",
      " [ 15  31   9  18   3 113  21]\n",
      " [ 11  12   0  10   2  63 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.65      0.60       210\n",
      "           2       0.53      0.68      0.60       210\n",
      "           3       0.65      0.83      0.73       210\n",
      "           4       0.58      0.62      0.60       210\n",
      "           5       0.54      0.14      0.23       210\n",
      "           6       0.42      0.54      0.47       210\n",
      "           7       0.78      0.53      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.55      1470\n",
      "weighted avg       0.58      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144  17   4  10   8  23   4]\n",
      " [  6 147  28   7   6  16   0]\n",
      " [  9   3 173   9   0  16   0]\n",
      " [ 15  21  17 131   5  20   1]\n",
      " [ 46  51  33  38  25  10   7]\n",
      " [ 14  31  10  18   1 117  19]\n",
      " [  8  17   1   9   2  63 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.69      0.64       210\n",
      "           2       0.51      0.70      0.59       210\n",
      "           3       0.65      0.82      0.73       210\n",
      "           4       0.59      0.62      0.61       210\n",
      "           5       0.53      0.12      0.19       210\n",
      "           6       0.44      0.56      0.49       210\n",
      "           7       0.78      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.55      1470\n",
      "weighted avg       0.59      0.58      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.21428571428571427\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 10   0   0   0 191   3   6]\n",
      " [  0   0   0   2 206   2   0]\n",
      " [  1   0   0   2 202   4   1]\n",
      " [  4   0   0   8 181  12   5]\n",
      " [  5   0   1   6 184   9   5]\n",
      " [  5   0   0   1 141  45  18]\n",
      " [  3   1   0   1  68  69  68]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.05      0.08       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.40      0.04      0.07       210\n",
      "           5       0.16      0.88      0.27       210\n",
      "           6       0.31      0.21      0.25       210\n",
      "           7       0.66      0.32      0.43       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.27      0.21      0.16      1470\n",
      "weighted avg       0.27      0.21      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   4   1   5  23  14   2]\n",
      " [  3 164  11  10   6  16   0]\n",
      " [  1   4 183   8   1  13   0]\n",
      " [ 10  15  18 134  10  19   4]\n",
      " [ 33  19  11  13 131   2   1]\n",
      " [ 12  18   5  20   3 118  34]\n",
      " [  7   8   0   5   2  39 149]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.77      0.74       210\n",
      "           2       0.71      0.78      0.74       210\n",
      "           3       0.80      0.87      0.83       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.74      0.62      0.68       210\n",
      "           6       0.53      0.56      0.55       210\n",
      "           7       0.78      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.24421768707482994\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 10   2 181   3   6   5   3]\n",
      " [  3  15 189   0   2   1   0]\n",
      " [  1   1 206   2   0   0   0]\n",
      " [  4   2 168  30   0   5   1]\n",
      " [ 15   9 157   9  12   5   3]\n",
      " [  5   2 156   2   4  28  13]\n",
      " [  1   1 137   1   0  12  58]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.05      0.08       210\n",
      "           2       0.47      0.07      0.12       210\n",
      "           3       0.17      0.98      0.29       210\n",
      "           4       0.64      0.14      0.23       210\n",
      "           5       0.50      0.06      0.10       210\n",
      "           6       0.50      0.13      0.21       210\n",
      "           7       0.74      0.28      0.40       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.47      0.24      0.21      1470\n",
      "weighted avg       0.47      0.24      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of SVM is:\n",
      " [[133   0   1   8  33  19  16]\n",
      " [  0 151  12  12  13  18   4]\n",
      " [  1   1 176  11   4  16   1]\n",
      " [  2   2  13 134  10  31  18]\n",
      " [ 23  10   7  13 122   3  32]\n",
      " [  1   9   2  10   4 126  58]\n",
      " [  0   0   0   4   0  39 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.63      0.72       210\n",
      "           2       0.87      0.72      0.79       210\n",
      "           3       0.83      0.84      0.84       210\n",
      "           4       0.70      0.64      0.67       210\n",
      "           5       0.66      0.58      0.62       210\n",
      "           6       0.50      0.60      0.55       210\n",
      "           7       0.56      0.80      0.66       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7251700680272108\n",
      "Confusion Matrix of SVM is:\n",
      " [[169   2   1   6  20  12   0]\n",
      " [  0 157  22   5   6  20   0]\n",
      " [  0   1 181  10   0  18   0]\n",
      " [  1   6  19 146   5  31   2]\n",
      " [ 40  16  12  14 120   4   4]\n",
      " [  3   8   4  15   5 146  29]\n",
      " [  0   1   1   5   3  53 147]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.80      0.80       210\n",
      "           2       0.82      0.75      0.78       210\n",
      "           3       0.75      0.86      0.80       210\n",
      "           4       0.73      0.70      0.71       210\n",
      "           5       0.75      0.57      0.65       210\n",
      "           6       0.51      0.70      0.59       210\n",
      "           7       0.81      0.70      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85 125   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [ 55 155   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.16      1.00      0.27       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.11      0.20      0.11      1470\n",
      "weighted avg       0.11      0.20      0.11      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.254421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155  55   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [109  90   0   0  11   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.74      0.65       210\n",
      "           2       0.17      0.99      0.30       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       1.00      0.05      0.10       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.25      0.25      0.15      1470\n",
      "weighted avg       0.25      0.25      0.15      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.35034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0   0  52   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   0  17   0   0 192   0]\n",
      " [100   0  26   0  20  64   0]\n",
      " [  0   0   2   0   0 208   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.57      0.63      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.91      0.10      0.17       210\n",
      "           6       0.22      0.99      0.36       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.33      0.35      0.26      1470\n",
      "weighted avg       0.33      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0  30  22   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   1  16   0   0 192   0]\n",
      " [ 86   4  22   0  34  63   1]\n",
      " [  0   0   2   0   0 204   4]\n",
      " [  2   0   0   0   0 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.74      0.68       210\n",
      "           2       0.86      0.14      0.24       210\n",
      "           3       0.68      0.63      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.94      0.16      0.28       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.90      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.37      1470\n",
      "weighted avg       0.61      0.41      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[137   0   1   0  18  54   0]\n",
      " [  0  70  17   0   2 121   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   5  13   0   1 191   0]\n",
      " [ 67  13  22   0  54  54   0]\n",
      " [  0   1   1   0   0 204   4]\n",
      " [  2   1   0   0   0 162  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.65      0.66       210\n",
      "           2       0.78      0.33      0.47       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.72      0.26      0.38       210\n",
      "           6       0.24      0.97      0.38       210\n",
      "           7       0.92      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.58      0.44      0.41      1470\n",
      "weighted avg       0.58      0.44      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1   0   1  54   0]\n",
      " [  0 110  17   0   3  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   7  12   0   0 190   0]\n",
      " [ 69  19  22   0  55  45   0]\n",
      " [  0   3   1   0   0 202   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.73      0.71       210\n",
      "           2       0.79      0.52      0.63       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.93      0.26      0.41       210\n",
      "           6       0.25      0.96      0.40       210\n",
      "           7       0.92      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.61      0.47      0.45      1470\n",
      "weighted avg       0.61      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1   0   1  54   0]\n",
      " [  0 106  17   3   4  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   4   8   6   1 188   2]\n",
      " [ 63  18  22   0  62  45   0]\n",
      " [  0   2   1   1   0 188  18]\n",
      " [  2   1   0   0   0 136  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.72       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.73      0.63      0.68       210\n",
      "           4       0.60      0.03      0.05       210\n",
      "           5       0.91      0.30      0.45       210\n",
      "           6       0.24      0.90      0.38       210\n",
      "           7       0.78      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.68      0.49      0.48      1470\n",
      "weighted avg       0.68      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1  54   1   0   0]\n",
      " [  0 104  16  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   3   8 191   3   0   4]\n",
      " [ 56  16  21  44  72   0   1]\n",
      " [  0   2   1 185   0   0  22]\n",
      " [  2   1   0 110   0   1  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.83      0.50      0.62       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.26      0.91      0.40       210\n",
      "           5       0.87      0.34      0.49       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.78      0.46      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.60      0.51      0.50      1470\n",
      "weighted avg       0.60      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5265306122448979\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   1  54   3   0   0]\n",
      " [  1 104  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   5   8 191   1   0   4]\n",
      " [ 51  16  18  44  81   0   0]\n",
      " [  0   2   1 181   0   0  26]\n",
      " [  2   1   0  92   0   1 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.26      0.91      0.41       210\n",
      "           5       0.88      0.39      0.54       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.61      0.53      0.52      1470\n",
      "weighted avg       0.61      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1  44   4   0   0]\n",
      " [  0 105  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  0   5   8 191   2   0   4]\n",
      " [ 48  17  18  38  88   0   1]\n",
      " [  0   2   1 181   1   0  25]\n",
      " [  2   1   0  93   0   2 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.27      0.91      0.42       210\n",
      "           5       0.86      0.42      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1   0   4  44   0]\n",
      " [  0 106  24   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  21   5   2 173   4]\n",
      " [ 48  17  18   0  89  38   0]\n",
      " [  0   2   3   0   1 178  26]\n",
      " [  2   1   1   1   2  93 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.69      0.71      0.70       210\n",
      "           4       0.56      0.02      0.05       210\n",
      "           5       0.85      0.42      0.57       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.79      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.67      0.54      0.53      1470\n",
      "weighted avg       0.67      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  20  15   2 164   4]\n",
      " [ 44  17  18   0  93  38   0]\n",
      " [  0   3   3   0   2 178  24]\n",
      " [  2   1   1   1   0  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.79      0.07      0.13       210\n",
      "           5       0.85      0.44      0.58       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.72      0.56      0.56      1470\n",
      "weighted avg       0.72      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  1   5  20  14   2 164   4]\n",
      " [ 44  17  18   0  92  38   1]\n",
      " [  0   2   3   0   1 177  27]\n",
      " [  2   1   1   1   3  88 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.78      0.07      0.12       210\n",
      "           5       0.83      0.44      0.57       210\n",
      "           6       0.28      0.84      0.42       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.71      0.56      0.56      1470\n",
      "weighted avg       0.71      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.572108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   1   0   8  44   0]\n",
      " [  0 115  15   4   7  69   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  19  36   2 144   4]\n",
      " [ 43  19  18   3  92  35   0]\n",
      " [  0   2   3   1   1 176  27]\n",
      " [  2   2   1   2   1  87 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.76       210\n",
      "           2       0.80      0.55      0.65       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.78      0.17      0.28       210\n",
      "           5       0.83      0.44      0.57       210\n",
      "           6       0.29      0.84      0.43       210\n",
      "           7       0.79      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.71      0.57      0.58      1470\n",
      "weighted avg       0.71      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   1   0   8  44   0]\n",
      " [  0 115  18   4   7  66   0]\n",
      " [  0   0 155   0   0  55   0]\n",
      " [  0   5  22  37   2 140   4]\n",
      " [ 44  19  22   3  92  29   1]\n",
      " [  0   2   3   1   0 179  25]\n",
      " [  2   1   1   2   4  88 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.81      0.55      0.65       210\n",
      "           3       0.70      0.74      0.72       210\n",
      "           4       0.79      0.18      0.29       210\n",
      "           5       0.81      0.44      0.57       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.71      0.58      0.58      1470\n",
      "weighted avg       0.71      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[160   0   2   0   5  43   0]\n",
      " [  0 116  22   4   7  61   0]\n",
      " [  0   0 162   0   0  48   0]\n",
      " [  0   5  28  36   3 135   3]\n",
      " [ 43  21  21   3  93  29   0]\n",
      " [  0   2   3   1   2 177  25]\n",
      " [  2   1   1   2   1  88 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.80      0.55      0.65       210\n",
      "           3       0.68      0.77      0.72       210\n",
      "           4       0.78      0.17      0.28       210\n",
      "           5       0.84      0.44      0.58       210\n",
      "           6       0.30      0.84      0.45       210\n",
      "           7       0.80      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.71      0.58      0.59      1470\n",
      "weighted avg       0.71      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[158   0   2   0   7  43   0]\n",
      " [  0 127  20   4   8  51   0]\n",
      " [  0   0 162   0   0  48   0]\n",
      " [  0   6  27  36   2 135   4]\n",
      " [ 41  23  20   5  95  26   0]\n",
      " [  0   2   3   1   1 179  24]\n",
      " [  2   1   1   2   0  92 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.75      0.77       210\n",
      "           2       0.80      0.60      0.69       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.75      0.17      0.28       210\n",
      "           5       0.84      0.45      0.59       210\n",
      "           6       0.31      0.85      0.46       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   2   0  11  43   0]\n",
      " [  0 127  18   5  10  50   0]\n",
      " [  0   0 161   2   0  47   0]\n",
      " [  1   5  28  43   2 127   4]\n",
      " [ 43  22  20   5  95  25   0]\n",
      " [  0   2   3   1   1 179  24]\n",
      " [  2   1   1   2   1  92 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.74      0.20      0.32       210\n",
      "           5       0.79      0.45      0.58       210\n",
      "           6       0.32      0.85      0.46       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.60      1470\n",
      "weighted avg       0.70      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.6006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   2   0  10  43   0]\n",
      " [  0 126  17   5  12  50   0]\n",
      " [  0   0 171   0   0  39   0]\n",
      " [  1   4  26  47   2 127   3]\n",
      " [ 40  21  21   8  97  23   0]\n",
      " [  0   2   3   2   0 179  24]\n",
      " [  2   2   1   2   3  92 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.73      0.22      0.34       210\n",
      "           5       0.78      0.46      0.58       210\n",
      "           6       0.32      0.85      0.47       210\n",
      "           7       0.80      0.51      0.63       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.71      0.60      0.60      1470\n",
      "weighted avg       0.71      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   2   0   8  43   0]\n",
      " [  0 128  17   6  11  48   0]\n",
      " [  0   0 172   4   0  34   0]\n",
      " [  1   5  25  58   2 116   3]\n",
      " [ 37  21  20   6 102  23   1]\n",
      " [  0   2   3   2   1 178  24]\n",
      " [  2   1   1   2   3  90 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.75      0.77       210\n",
      "           2       0.82      0.61      0.70       210\n",
      "           3       0.72      0.82      0.76       210\n",
      "           4       0.74      0.28      0.40       210\n",
      "           5       0.80      0.49      0.61       210\n",
      "           6       0.33      0.85      0.48       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.72      0.62      0.62      1470\n",
      "weighted avg       0.72      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   3   1  19   5  21   5]\n",
      " [  1  97  49  14   5  43   1]\n",
      " [  0   0 158   7   0  45   0]\n",
      " [  1  10  24 114   1  56   4]\n",
      " [ 61  24  33  29  45   6  12]\n",
      " [  0   7   4  28   1 130  40]\n",
      " [  0   1   0  17   0  43 149]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.46      0.55       210\n",
      "           3       0.59      0.75      0.66       210\n",
      "           4       0.50      0.54      0.52       210\n",
      "           5       0.79      0.21      0.34       210\n",
      "           6       0.38      0.62      0.47       210\n",
      "           7       0.71      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.57      1470\n",
      "weighted avg       0.62      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   2  11  11  25   5]\n",
      " [  1  98  50  12  16  33   0]\n",
      " [  0   0 156   7   0  47   0]\n",
      " [  0  14  24 103   3  62   4]\n",
      " [ 56  23  28  18  58  13  14]\n",
      " [  0   8   5  16   2 138  41]\n",
      " [  0   2   0   4   0  50 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.66      0.47      0.55       210\n",
      "           3       0.59      0.74      0.66       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.64      0.28      0.39       210\n",
      "           6       0.38      0.66      0.48       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.58      1470\n",
      "weighted avg       0.61      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   4   1  10   8  27   5]\n",
      " [  1  98  48  12  16  35   0]\n",
      " [  0   0 135   6   0  69   0]\n",
      " [  0  11  15 109   4  67   4]\n",
      " [ 62  22  30  20  53  10  13]\n",
      " [  0   7   2  14   3 141  43]\n",
      " [  0   1   0   6   0  49 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.69      0.47      0.56       210\n",
      "           3       0.58      0.64      0.61       210\n",
      "           4       0.62      0.52      0.56       210\n",
      "           5       0.63      0.25      0.36       210\n",
      "           6       0.35      0.67      0.46       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.61      0.57      0.57      1470\n",
      "weighted avg       0.61      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   4   2   8  11  28   3]\n",
      " [  0 104  51   7  13  35   0]\n",
      " [  0   0 161   6   0  43   0]\n",
      " [  0  13  27 106   7  53   4]\n",
      " [ 55  20  28  16  70   9  12]\n",
      " [  0   9   5  17   2 137  40]\n",
      " [  0   1   0   5   0  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.59      0.77      0.67       210\n",
      "           4       0.64      0.50      0.57       210\n",
      "           5       0.68      0.33      0.45       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.60      1470\n",
      "weighted avg       0.64      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   4   1   8   8  29   2]\n",
      " [  1 136  20  10   9  34   0]\n",
      " [  0   0 149   6   0  55   0]\n",
      " [  0  16  21 109   4  56   4]\n",
      " [ 54  22  25  13  75  10  11]\n",
      " [  0  10   4  16   1 138  41]\n",
      " [  1   2   0   6   1  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.72      0.65      0.68       210\n",
      "           3       0.68      0.71      0.69       210\n",
      "           4       0.65      0.52      0.58       210\n",
      "           5       0.77      0.36      0.49       210\n",
      "           6       0.38      0.66      0.48       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   4   2   8  10  27   2]\n",
      " [  0 138  21   9   9  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  18  23 104   4  58   3]\n",
      " [ 56  21  21  15  75  11  11]\n",
      " [  0   9   5  13   1 139  43]\n",
      " [  1   2   0   6   1  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.65      0.50      0.56       210\n",
      "           5       0.75      0.36      0.48       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   5   2   9  12  26   2]\n",
      " [  0 138  21   8  10  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  16  19 111   6  55   3]\n",
      " [ 52  20  18  19  81  10  10]\n",
      " [  0   8   5  14   3 138  42]\n",
      " [  0   2   0   6   1  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.64      0.53      0.58       210\n",
      "           5       0.72      0.39      0.50       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   5   2   8   7  27   1]\n",
      " [  0 136  22   9  11  32   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  13  19 115   6  53   4]\n",
      " [ 53  20  25  14  79   9  10]\n",
      " [  0   8   5  12   2 140  43]\n",
      " [  0   2   0   5   1  42 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.76      0.76       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.69      0.79      0.74       210\n",
      "           4       0.68      0.55      0.61       210\n",
      "           5       0.75      0.38      0.50       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   1   8   8  29   0]\n",
      " [  0 139  21   9   6  35   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  12  19 120   7  49   3]\n",
      " [ 48  23  26  14  81   9   9]\n",
      " [  0   8   5  14   2 139  42]\n",
      " [  1   2   0   5   1  41 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.77      0.39      0.51       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   1   9   8  27   1]\n",
      " [  0 140  23   9   6  32   0]\n",
      " [  0   0 164   7   0  39   0]\n",
      " [  0  15  22 114   5  51   3]\n",
      " [ 45  22  21  14  93   5  10]\n",
      " [  0  10   3  12   1 141  43]\n",
      " [  1   2   0   5   0  41 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.73      0.67      0.69       210\n",
      "           3       0.70      0.78      0.74       210\n",
      "           4       0.67      0.54      0.60       210\n",
      "           5       0.82      0.44      0.58       210\n",
      "           6       0.42      0.67      0.52       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   4   2   8  11  28   0]\n",
      " [  0 138  21  10   8  33   0]\n",
      " [  0   0 170   6   0  34   0]\n",
      " [  0  13  21 118   5  50   3]\n",
      " [ 53  22  27  15  76   9   8]\n",
      " [  0   8   4  12   2 141  43]\n",
      " [  1   2   0   5   1  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.74      0.36      0.49       210\n",
      "           6       0.42      0.67      0.52       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   1   8   7  29   1]\n",
      " [  0 141  21   9   6  33   0]\n",
      " [  0   0 163   6   0  41   0]\n",
      " [  0  11  18 124   4  50   3]\n",
      " [ 49  26  24  14  80   7  10]\n",
      " [  0   8   4  12   2 141  43]\n",
      " [  1   2   0   5   2  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.71      0.78      0.74       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.79      0.38      0.51       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   5   2   9   7  27   0]\n",
      " [  0 140  22  10   7  31   0]\n",
      " [  0   0 169   7   0  34   0]\n",
      " [  0   9  25 120   5  48   3]\n",
      " [ 50  23  22  12  88   5  10]\n",
      " [  0   6   5  14   3 139  43]\n",
      " [  1   1   1   5   2  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.69      0.80      0.74       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.42      0.66      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   4   2   9   9  27   0]\n",
      " [  0 141  21   9   8  31   0]\n",
      " [  0   0 170   6   0  34   0]\n",
      " [  0  13  20 123   5  46   3]\n",
      " [ 48  19  23  15  90   6   9]\n",
      " [  0   9   4  16   1 138  42]\n",
      " [  1   1   0   4   3  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.68      0.59      0.63       210\n",
      "           5       0.78      0.43      0.55       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   5   2   9   6  27   0]\n",
      " [  0 140  24  11   6  29   0]\n",
      " [  0   0 170   7   0  33   0]\n",
      " [  0  10  21 125   6  45   3]\n",
      " [ 51  24  24  14  84   6   7]\n",
      " [  0   7   4  17   1 140  41]\n",
      " [  2   2   0   6   0  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.82      0.40      0.54       210\n",
      "           6       0.43      0.67      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   2   9   7  27   0]\n",
      " [  0 141  22   9   8  30   0]\n",
      " [  0   0 170   7   0  33   0]\n",
      " [  0  11  21 126   5  44   3]\n",
      " [ 50  21  24  15  85   7   8]\n",
      " [  0  10   4  18   1 140  37]\n",
      " [  2   2   0   6   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.80      0.40      0.54       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.76      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   4   2   8   9  28   0]\n",
      " [  0 141  22   8   8  31   0]\n",
      " [  0   0 170   7   1  32   0]\n",
      " [  0  10  22 131   4  40   3]\n",
      " [ 47  22  23  14  88   7   9]\n",
      " [  0   8   5  17   1 140  39]\n",
      " [  1   2   1   5   1  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   2   9   8  27   0]\n",
      " [  0 144  19   8   8  31   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  13  21 128   4  41   3]\n",
      " [ 46  22  22  18  88   7   7]\n",
      " [  0   9   4  15   2 142  38]\n",
      " [  2   2   0   6   0  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.77       210\n",
      "           2       0.74      0.69      0.71       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.80      0.42      0.55       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.77      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   2   9   7  27   0]\n",
      " [  0 150  16   5   6  33   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  12  21 129   4  41   3]\n",
      " [ 49  24  23  16  83   7   8]\n",
      " [  0   9   4  16   1 141  39]\n",
      " [  1   2   1   5   1  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       0.69      0.61      0.65       210\n",
      "           5       0.81      0.40      0.53       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   4   2   9  11  26   0]\n",
      " [  0 149  17   9   5  30   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  11  22 129   4  40   4]\n",
      " [ 46  29  24  15  85   5   6]\n",
      " [  0   9   4  16   1 142  38]\n",
      " [  1   2   1   5   1  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.73      0.71      0.72       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.68      0.61      0.64       210\n",
      "           5       0.79      0.40      0.54       210\n",
      "           6       0.44      0.68      0.54       210\n",
      "           7       0.76      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[159   2   1   3  40   3   2]\n",
      " [ 13 152  17   7  18   3   0]\n",
      " [ 15   3 181   8   0   2   1]\n",
      " [ 20   6  18 144   9  10   3]\n",
      " [ 28  15  15  18 127   5   2]\n",
      " [ 44  14   5  19   9  73  46]\n",
      " [  6   3   0   2   0  29 170]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.76      0.64       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.76      0.86      0.81       210\n",
      "           4       0.72      0.69      0.70       210\n",
      "           5       0.63      0.60      0.62       210\n",
      "           6       0.58      0.35      0.44       210\n",
      "           7       0.76      0.81      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7054421768707483\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[152   1   1   8  33  13   2]\n",
      " [  0 155   9  13  11  19   3]\n",
      " [  0   2 179  12   3  13   1]\n",
      " [  3  11  17 146  12  16   5]\n",
      " [ 25  15   8  19 134   2   7]\n",
      " [  6  14   5  26   3 119  37]\n",
      " [  2   3   0   4   3  46 152]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.72      0.76       210\n",
      "           2       0.77      0.74      0.75       210\n",
      "           3       0.82      0.85      0.83       210\n",
      "           4       0.64      0.70      0.67       210\n",
      "           5       0.67      0.64      0.66       210\n",
      "           6       0.52      0.57      0.54       210\n",
      "           7       0.73      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143  16   7  14  10  15   5]\n",
      " [ 11 152  15   7   7  17   1]\n",
      " [ 11   6 168   5   3  17   0]\n",
      " [ 34  28  19 106   9  12   2]\n",
      " [ 53  44  17  19  69   5   3]\n",
      " [ 36  29   9  19  12  78  27]\n",
      " [ 24  14   2   9   6  46 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.68      0.55       210\n",
      "           2       0.53      0.72      0.61       210\n",
      "           3       0.71      0.80      0.75       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.59      0.33      0.42       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.74      0.52      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137  22   6  16  13  11   5]\n",
      " [ 12 160  13   7   9   9   0]\n",
      " [ 14  16 168   8   2   2   0]\n",
      " [ 31  29  14 115  10   9   2]\n",
      " [ 56  44  17  21  59   9   4]\n",
      " [ 28  63   6  18   6  59  30]\n",
      " [ 18  19   3   9   4  46 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.65      0.54       210\n",
      "           2       0.45      0.76      0.57       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.59      0.55      0.57       210\n",
      "           5       0.57      0.28      0.38       210\n",
      "           6       0.41      0.28      0.33       210\n",
      "           7       0.73      0.53      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.54      1470\n",
      "weighted avg       0.57      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[131  21   5  14  22  12   5]\n",
      " [ 11 160  15   7   7   9   1]\n",
      " [ 13  15 169   8   2   3   0]\n",
      " [ 27  26  11 122  12  11   1]\n",
      " [ 48  42  22  29  55  10   4]\n",
      " [ 23  60   6  23   9  59  30]\n",
      " [ 12  22   2  10   6  44 114]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.62      0.55       210\n",
      "           2       0.46      0.76      0.58       210\n",
      "           3       0.73      0.80      0.77       210\n",
      "           4       0.57      0.58      0.58       210\n",
      "           5       0.49      0.26      0.34       210\n",
      "           6       0.40      0.28      0.33       210\n",
      "           7       0.74      0.54      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.54      1470\n",
      "weighted avg       0.56      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134  20   6  13  20  13   4]\n",
      " [ 10 162  14   5  10   8   1]\n",
      " [ 13  15 169  10   1   2   0]\n",
      " [ 21  25  15 120  13  16   0]\n",
      " [ 52  43  23  26  55   8   3]\n",
      " [ 19  62   7  22   8  69  23]\n",
      " [ 14  24   0   9   3  45 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.64      0.57       210\n",
      "           2       0.46      0.77      0.58       210\n",
      "           3       0.72      0.80      0.76       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.50      0.26      0.34       210\n",
      "           6       0.43      0.33      0.37       210\n",
      "           7       0.79      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  23   5  11  16  13   2]\n",
      " [ 10 158  17   5  12   8   0]\n",
      " [ 11  16 170   9   0   4   0]\n",
      " [ 21  26  14 123   9  17   0]\n",
      " [ 50  42  27  22  57  11   1]\n",
      " [ 16  62  10  23   7  70  22]\n",
      " [ 13  32   0   7   3  43 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.67      0.59       210\n",
      "           2       0.44      0.75      0.56       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.61      0.59      0.60       210\n",
      "           5       0.55      0.27      0.36       210\n",
      "           6       0.42      0.33      0.37       210\n",
      "           7       0.82      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  21   6   9  21  10   3]\n",
      " [  8 159  17   5  13   8   0]\n",
      " [ 12  14 169   9   0   6   0]\n",
      " [ 22  29  18 120   7  14   0]\n",
      " [ 57  36  29  23  54  10   1]\n",
      " [ 14  63   9  22   5  72  25]\n",
      " [ 16  32   0   6   1  47 108]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.67      0.58       210\n",
      "           2       0.45      0.76      0.56       210\n",
      "           3       0.68      0.80      0.74       210\n",
      "           4       0.62      0.57      0.59       210\n",
      "           5       0.53      0.26      0.35       210\n",
      "           6       0.43      0.34      0.38       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.21292517006802722\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 10   0   0   0 191   3   6]\n",
      " [  0   0   0   2 206   2   0]\n",
      " [  1   0   0   2 202   4   1]\n",
      " [  4   0   0   8 181  12   5]\n",
      " [  5   0   1   6 183  10   5]\n",
      " [  5   0   0   1 141  45  18]\n",
      " [  3   1   0   1  69  69  67]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.05      0.08       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.40      0.04      0.07       210\n",
      "           5       0.16      0.87      0.26       210\n",
      "           6       0.31      0.21      0.25       210\n",
      "           7       0.66      0.32      0.43       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.27      0.21      0.16      1470\n",
      "weighted avg       0.27      0.21      0.16      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   2   0   8  25  10   3]\n",
      " [  2 168   8   9   5  18   0]\n",
      " [  1   3 181  10   0  15   0]\n",
      " [  9  18  20 134  10  16   3]\n",
      " [ 31  20   9  13 129   3   5]\n",
      " [ 10  19   5  18   4 119  35]\n",
      " [  4   4   0  11   1  43 147]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.76       210\n",
      "           2       0.72      0.80      0.76       210\n",
      "           3       0.81      0.86      0.84       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.74      0.61      0.67       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.76      0.70      0.73       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.2639455782312925\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 17   2 169   5   7   7   3]\n",
      " [  2  22 176   2   2   6   0]\n",
      " [  3   2 203   0   2   0   0]\n",
      " [  6   4 159  35   1   3   2]\n",
      " [ 11   6 173   2  12   5   1]\n",
      " [ 11  10 120   5   9  36  19]\n",
      " [  1   3 128   2   1  12  63]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.08      0.13       210\n",
      "           2       0.45      0.10      0.17       210\n",
      "           3       0.18      0.97      0.30       210\n",
      "           4       0.69      0.17      0.27       210\n",
      "           5       0.35      0.06      0.10       210\n",
      "           6       0.52      0.17      0.26       210\n",
      "           7       0.72      0.30      0.42       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.46      0.26      0.24      1470\n",
      "weighted avg       0.46      0.26      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of SVM is:\n",
      " [[126   0   0  12  34  23  15]\n",
      " [  0 146   8  13  20  19   4]\n",
      " [  3   1 171  14   4  16   1]\n",
      " [  6   7  13 136  10  26  12]\n",
      " [ 28  10  11  23 107   9  22]\n",
      " [  5  11   1  14   7 108  64]\n",
      " [  0   3   0   3   0  23 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67       210\n",
      "           2       0.82      0.70      0.75       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.63      0.65      0.64       210\n",
      "           5       0.59      0.51      0.55       210\n",
      "           6       0.48      0.51      0.50       210\n",
      "           7       0.61      0.86      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7129251700680272\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   0   1   7  32  14   5]\n",
      " [  1 158  13   7  12  19   0]\n",
      " [  1   2 181  12   1  13   0]\n",
      " [  3   8  15 147   9  24   4]\n",
      " [ 40  17  12  19 111   4   7]\n",
      " [  5  11   3  17   7 127  40]\n",
      " [  0   3   0   5   0  29 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.79      0.75      0.77       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.69      0.70      0.69       210\n",
      "           5       0.65      0.53      0.58       210\n",
      "           6       0.55      0.60      0.58       210\n",
      "           7       0.76      0.82      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.20136054421768707\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [124   0  86   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.16      0.20      0.12      1470\n",
      "weighted avg       0.16      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   1   0   0 154   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.25      0.26      0.19      1470\n",
      "weighted avg       0.25      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   0   0   0  34  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 79   0   1   0  41  89   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.53      0.20      0.29       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.25      1470\n",
      "weighted avg       0.32      0.31      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   0   0  55  56   0   0]\n",
      " [  0   0   2 206   2   0   0]\n",
      " [  0   0  86 124   0   0   0]\n",
      " [  0   0   1 208   1   0   0]\n",
      " [ 27   0   1  86  93   0   3]\n",
      " [  0   0   0 206   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.47      0.59       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.20      0.99      0.33       210\n",
      "           5       0.60      0.44      0.51       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.49      0.36      0.34      1470\n",
      "weighted avg       0.49      0.36      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  58   2   0   2 148   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 51   5   1   0  70  81   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   0   0   0   2 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       210\n",
      "           2       0.75      0.28      0.40       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.33      0.46       210\n",
      "           6       0.21      0.97      0.34       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.61      0.40      0.40      1470\n",
      "weighted avg       0.61      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  92   2   0   2 114   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 46  17   1   0  75  69   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.63      0.68       210\n",
      "           2       0.74      0.44      0.55       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.36      0.48       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.61      0.43      0.43      1470\n",
      "weighted avg       0.61      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45510204081632655\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   5   0   0  32  50   0]\n",
      " [  0 130   2   0   2  76   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   6   1   0   1 202   0]\n",
      " [ 38  22   1   0  83  64   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.59      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.40      0.50       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.61      0.46      0.45      1470\n",
      "weighted avg       0.61      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48707482993197276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   5   1   0  32  49   0]\n",
      " [  0 129  21   1   2  57   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   6  17   0   1 186   0]\n",
      " [ 34  22  19   0  87  46   2]\n",
      " [  0   3   2   0   0 201   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.59      0.67       210\n",
      "           2       0.78      0.61      0.69       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.41      0.52       210\n",
      "           6       0.26      0.96      0.41       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.47      1470\n",
      "weighted avg       0.58      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48639455782312924\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   6   0   0  32  49   0]\n",
      " [  0 147   2   1   3  57   0]\n",
      " [  0  35  97   0   0  78   0]\n",
      " [  0  22   1   0   1 184   2]\n",
      " [ 35  37   1   0  89  45   3]\n",
      " [  0   5   0   0   0 188  17]\n",
      " [  0   1   0   0   2 136  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.59      0.67       210\n",
      "           2       0.58      0.70      0.63       210\n",
      "           3       0.96      0.46      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.42      0.53       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.76      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.47      1470\n",
      "weighted avg       0.58      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   5   0   0  12  49   0]\n",
      " [  0 143   3   1   7  56   0]\n",
      " [  0  34 109   0   1  66   0]\n",
      " [  0  17   4   0   6 181   2]\n",
      " [ 65  31   1   0  65  46   2]\n",
      " [  0   4   1   0   1 187  17]\n",
      " [  2   1   0   0   0 136  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.69      0.68       210\n",
      "           2       0.61      0.68      0.64       210\n",
      "           3       0.92      0.52      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.71      0.31      0.43       210\n",
      "           6       0.26      0.89      0.40       210\n",
      "           7       0.77      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.56      0.49      0.47      1470\n",
      "weighted avg       0.56      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.507482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   5   0  49  32   0   0]\n",
      " [  0 143   3  57   7   0   0]\n",
      " [  0  34 109  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 38  29   1  46  91   1   4]\n",
      " [  0   4   1 182   1   1  21]\n",
      " [  0   1   0 110   2   1  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.59      0.67       210\n",
      "           2       0.62      0.68      0.65       210\n",
      "           3       0.92      0.52      0.66       210\n",
      "           4       0.26      0.87      0.40       210\n",
      "           5       0.65      0.43      0.52       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.46      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.62      0.51      0.50      1470\n",
      "weighted avg       0.62      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   5   0  50  40   0   0]\n",
      " [  0 130  15  57   8   0   0]\n",
      " [  0   0 143  66   1   0   0]\n",
      " [  0   7  11 182   6   0   4]\n",
      " [ 32  16  13  45 100   1   3]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  95   4   1 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.55      0.64       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.27      0.87      0.41       210\n",
      "           5       0.62      0.48      0.54       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.52      1470\n",
      "weighted avg       0.62      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   5   0  40  30   0   0]\n",
      " [  0 142   3  57   8   0   0]\n",
      " [  0  25 118  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 41  27   2  42  96   1   1]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  95   2   3 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.64      0.70       210\n",
      "           2       0.65      0.68      0.66       210\n",
      "           3       0.92      0.56      0.70       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.67      0.46      0.54       210\n",
      "           6       0.20      0.00      0.01       210\n",
      "           7       0.78      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.61      0.53      0.52      1470\n",
      "weighted avg       0.61      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   5   0  40  12   0   0]\n",
      " [  0 141   4  57   8   0   0]\n",
      " [  0  20 132  57   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 60  26   3  42  75   1   3]\n",
      " [  0   4   1 178   2   1  24]\n",
      " [  2   1   0  95   2   4 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.92      0.63      0.75       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.71      0.36      0.47       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.77      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.52      1470\n",
      "weighted avg       0.60      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[138   5   0  40  27   0   0]\n",
      " [  0 141   6  55   8   0   0]\n",
      " [  0  16 143  50   1   0   0]\n",
      " [  0  13   8 179   6   0   4]\n",
      " [ 42  26   3  41  96   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  0   1   0  95   5   4 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.66      0.71       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.88      0.68      0.77       210\n",
      "           4       0.28      0.85      0.42       210\n",
      "           5       0.67      0.46      0.54       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   5   0  40  18   0   0]\n",
      " [  0 140   7  54   9   0   0]\n",
      " [  0  16 148  45   1   0   0]\n",
      " [  0  13  11 176   6   0   4]\n",
      " [ 50  26   5  42  85   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  1   1   0  95   3   3 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72       210\n",
      "           2       0.68      0.67      0.67       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.28      0.84      0.42       210\n",
      "           5       0.69      0.40      0.51       210\n",
      "           6       0.20      0.00      0.01       210\n",
      "           7       0.78      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   5   0  40  15   0   0]\n",
      " [  0 136   6  54  14   0   0]\n",
      " [  0   8 148  45   9   0   0]\n",
      " [  0  13   9 175   9   0   4]\n",
      " [ 49  19   5  39  93   1   4]\n",
      " [  0   5   1 173   2   1  28]\n",
      " [  1   1   0  88   5   3 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.71      0.73       210\n",
      "           2       0.73      0.65      0.69       210\n",
      "           3       0.88      0.70      0.78       210\n",
      "           4       0.29      0.83      0.42       210\n",
      "           5       0.63      0.44      0.52       210\n",
      "           6       0.20      0.00      0.01       210\n",
      "           7       0.76      0.53      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.54      1470\n",
      "weighted avg       0.60      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   5   0   1  19  39   0]\n",
      " [  0 137   7   1  12  53   0]\n",
      " [  0   8 150   0   7  45   0]\n",
      " [  0  13  10  13   8 162   4]\n",
      " [ 47  18   5   4  94  38   4]\n",
      " [  0   4   1   0   2 174  29]\n",
      " [  1   1   0   0   2  92 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.70      0.72       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.87      0.71      0.78       210\n",
      "           4       0.68      0.06      0.11       210\n",
      "           5       0.65      0.45      0.53       210\n",
      "           6       0.29      0.83      0.43       210\n",
      "           7       0.75      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.68      0.56      0.56      1470\n",
      "weighted avg       0.68      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5836734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   5   0   1  19  39   0]\n",
      " [  0 138   6   2  12  52   0]\n",
      " [  0   8 150   1   7  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 46  18   5   4  98  35   4]\n",
      " [  0   5   1   1   2 174  27]\n",
      " [  1   1   0   1   1  89 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.72       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.87      0.71      0.79       210\n",
      "           4       0.78      0.17      0.27       210\n",
      "           5       0.67      0.47      0.55       210\n",
      "           6       0.30      0.83      0.44       210\n",
      "           7       0.77      0.56      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.59      1470\n",
      "weighted avg       0.70      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5870748299319728\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   5   0   1  20  39   0]\n",
      " [  0 147   6   3  12  42   0]\n",
      " [  0   8 150   1   7  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 45  22   5   6  99  31   2]\n",
      " [  0   5   1   1   3 174  26]\n",
      " [  1   1   0   1   1  93 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.69      0.72       210\n",
      "           2       0.73      0.70      0.72       210\n",
      "           3       0.87      0.71      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.66      0.47      0.55       210\n",
      "           6       0.31      0.83      0.45       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.69      0.59      0.59      1470\n",
      "weighted avg       0.69      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5816326530612245\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   2  20  10  21   5]\n",
      " [  1 108  19  27   6  48   1]\n",
      " [  0   0 144  16   0  50   0]\n",
      " [  3   6   9 125   2  61   4]\n",
      " [ 62  24  10  34  50  17  13]\n",
      " [  0   3   3  35   0 131  38]\n",
      " [  0   1   0  17   0  45 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.75      0.51      0.61       210\n",
      "           3       0.77      0.69      0.73       210\n",
      "           4       0.46      0.60      0.52       210\n",
      "           5       0.74      0.24      0.36       210\n",
      "           6       0.35      0.62      0.45       210\n",
      "           7       0.71      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.64      0.58      0.58      1470\n",
      "weighted avg       0.64      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   4   3  19  11  21   5]\n",
      " [  1 126  15  12  17  38   1]\n",
      " [  0   0 153  14   0  43   0]\n",
      " [  2   6  11 125   4  58   4]\n",
      " [ 57  19   7  28  68  14  17]\n",
      " [  0   4   4  29   0 130  43]\n",
      " [  0   0   0  11   0  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.79      0.60      0.68       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.53      0.60      0.56       210\n",
      "           5       0.68      0.32      0.44       210\n",
      "           6       0.37      0.62      0.47       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   1  16  10  22   5]\n",
      " [  0 127  16  13  16  37   1]\n",
      " [  0   0 156  15   0  39   0]\n",
      " [  2  11  11 130   6  46   4]\n",
      " [ 61  19   9  32  61  12  16]\n",
      " [  0   5   4  21   3 134  43]\n",
      " [  0   1   0   9   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.72       210\n",
      "           2       0.76      0.60      0.67       210\n",
      "           3       0.79      0.74      0.77       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.64      0.29      0.40       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   4   0  10  12  28   3]\n",
      " [  0 131  15  13  13  37   1]\n",
      " [  0   0 158  13   0  39   0]\n",
      " [  2  11  11 121  10  51   4]\n",
      " [ 54  20   6  23  80  15  12]\n",
      " [  0   6   3  19   4 134  44]\n",
      " [  0   1   0   8   0  40 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.76      0.62      0.68       210\n",
      "           3       0.82      0.75      0.78       210\n",
      "           4       0.58      0.58      0.58       210\n",
      "           5       0.67      0.38      0.49       210\n",
      "           6       0.39      0.64      0.48       210\n",
      "           7       0.72      0.77      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0  11  13  27   4]\n",
      " [  0 127  17  15  17  33   1]\n",
      " [  0   0 157  15   0  38   0]\n",
      " [  2  11  10 121   9  53   4]\n",
      " [ 52  20   6  26  82  12  12]\n",
      " [  0   6   4  18   4 134  44]\n",
      " [  0   1   0   8   0  41 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.75      0.60      0.67       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.57      0.58      0.57       210\n",
      "           5       0.66      0.39      0.49       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   5   0  15  12  24   3]\n",
      " [  1 134  14  11  13  37   0]\n",
      " [  0   0 157  15   0  38   0]\n",
      " [  0  10  10 136  10  41   3]\n",
      " [ 60  19   6  26  74  14  11]\n",
      " [  0   5   3  21   3 134  44]\n",
      " [  0   1   0   9   1  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.72       210\n",
      "           2       0.77      0.64      0.70       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.65      0.35      0.46       210\n",
      "           6       0.40      0.64      0.50       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   4   0   9  19  30   2]\n",
      " [  0 137  14  11  14  34   0]\n",
      " [  0   2 161  12   0  35   0]\n",
      " [  0  10  10 127  10  50   3]\n",
      " [ 57  18   6  18  84  17  10]\n",
      " [  0   7   4  13   3 138  45]\n",
      " [  0   2   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.65      0.60      0.63       210\n",
      "           5       0.64      0.40      0.49       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   5   0   8  10  30   3]\n",
      " [  0 136  16   9  17  32   0]\n",
      " [  0   0 164  13   0  33   0]\n",
      " [  0  13  10 129   9  45   4]\n",
      " [ 52  18   8  19  88  15  10]\n",
      " [  0   8   3  14   4 139  42]\n",
      " [  0   2   0   4   1  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.75      0.65      0.69       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.66      0.61      0.64       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   5   0   9  13  30   2]\n",
      " [  0 140  15  10  15  30   0]\n",
      " [  0   0 164  13   0  33   0]\n",
      " [  0  13  10 127  12  45   3]\n",
      " [ 50  19   7  19  91  15   9]\n",
      " [  0   7   3  13   5 139  43]\n",
      " [  0   1   0   5   1  42 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.60      0.63       210\n",
      "           5       0.66      0.43      0.52       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   4   0   9  25  30   1]\n",
      " [  0 138  16   9  15  32   0]\n",
      " [  0   0 168  12   0  30   0]\n",
      " [  0  10  10 132  12  42   4]\n",
      " [ 40  18   7  18 103  14  10]\n",
      " [  0   6   4  13   5 138  44]\n",
      " [  0   1   0   6   2  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.78      0.66      0.71       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.64      0.49      0.55       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   0   9  20  30   0]\n",
      " [  0 139  18  11  14  28   0]\n",
      " [  0   0 164  15   0  31   0]\n",
      " [  0  11  10 131  11  43   4]\n",
      " [ 42  15   7  21 103  13   9]\n",
      " [  0   6   4  11   4 143  42]\n",
      " [  0   0   0   5   2  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.73       210\n",
      "           2       0.79      0.66      0.72       210\n",
      "           3       0.81      0.78      0.79       210\n",
      "           4       0.65      0.62      0.63       210\n",
      "           5       0.67      0.49      0.57       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 142  12  11  14  31   0]\n",
      " [  0   1 164  11   0  34   0]\n",
      " [  0   9   8 133  10  47   3]\n",
      " [ 43  16   6  19 105  12   9]\n",
      " [  0   4   1  14   5 144  42]\n",
      " [  1   0   0   5   2  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75       210\n",
      "           2       0.81      0.68      0.74       210\n",
      "           3       0.86      0.78      0.82       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   4   0   9  22  29   1]\n",
      " [  0 142  15  10  14  29   0]\n",
      " [  0   4 164  10   0  32   0]\n",
      " [  0   9  11 130  11  45   4]\n",
      " [ 36  15   7  19 111  13   9]\n",
      " [  0   5   2  13   4 144  42]\n",
      " [  0   1   0   5   2  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.68      0.53      0.59       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 140  15  10  16  29   0]\n",
      " [  0   1 163  12   0  34   0]\n",
      " [  0   7  11 129  15  44   4]\n",
      " [ 33  16   5  18 114  14  10]\n",
      " [  0   4   2  13   7 140  44]\n",
      " [  1   0   0   5   2  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.72      0.76       210\n",
      "           2       0.81      0.67      0.73       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.66      0.61      0.64       210\n",
      "           5       0.67      0.54      0.60       210\n",
      "           6       0.42      0.67      0.51       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   0   9  15  30   0]\n",
      " [  0 142  14  11  14  29   0]\n",
      " [  0   5 161  13   0  31   0]\n",
      " [  0   9   9 133  13  42   4]\n",
      " [ 37  19   6  21 109  10   8]\n",
      " [  0   5   2  14   5 143  41]\n",
      " [  0   0   0   5   2  43 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.69      0.52      0.59       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.75      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   4   0   9  22  29   0]\n",
      " [  0 140  16  11  14  29   0]\n",
      " [  0   1 166  11   0  32   0]\n",
      " [  0   8   9 131  13  44   5]\n",
      " [ 38  17   6  18 110  12   9]\n",
      " [  0   6   1  13   5 145  40]\n",
      " [  1   0   0   5   2  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.70      0.74       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.66      0.52      0.59       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   4   0   9  19  29   0]\n",
      " [  0 140  15  11  15  29   0]\n",
      " [  0   3 165   9   0  33   0]\n",
      " [  0   8   8 135  13  43   3]\n",
      " [ 32  17   6  18 117  11   9]\n",
      " [  0   4   1  12   7 146  40]\n",
      " [  1   0   0   5   3  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.71      0.76       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.85      0.79      0.81       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.67      0.56      0.61       210\n",
      "           6       0.44      0.70      0.54       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   4   0   9  20  29   0]\n",
      " [  0 146  14  10  11  29   0]\n",
      " [  0   6 164   9   0  31   0]\n",
      " [  0   8  10 131  13  45   3]\n",
      " [ 35  22   5  21 111   7   9]\n",
      " [  0   5   2  12   7 145  39]\n",
      " [  1   0   0   5   3  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.70      0.75       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.44      0.69      0.54       210\n",
      "           7       0.75      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   4   0   9  24  29   0]\n",
      " [  0 141  14  11  15  29   0]\n",
      " [  0   4 164  10   1  31   0]\n",
      " [  0   7   9 131  13  47   3]\n",
      " [ 31  20   6  17 117  11   8]\n",
      " [  0   5   1  12   7 145  40]\n",
      " [  1   1   0   5   3  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.69      0.75       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.67      0.62      0.65       210\n",
      "           5       0.65      0.56      0.60       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.76      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   4   0   9  18  29   0]\n",
      " [  0 146  13  11  11  29   0]\n",
      " [  0   2 167   9   0  32   0]\n",
      " [  0   8   9 131  14  45   3]\n",
      " [ 35  20   6  16 116   9   8]\n",
      " [  0   5   2  14   5 143  41]\n",
      " [  1   0   0   5   3  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.71      0.76       210\n",
      "           2       0.79      0.70      0.74       210\n",
      "           3       0.85      0.80      0.82       210\n",
      "           4       0.67      0.62      0.65       210\n",
      "           5       0.69      0.55      0.62       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[150   1   0   6  47   5   1]\n",
      " [ 12 150   9  10  25   4   0]\n",
      " [ 14   3 179  10   2   2   0]\n",
      " [ 18   6  12 149  11  10   4]\n",
      " [ 24  11  11  21 135   6   2]\n",
      " [ 36  12   1  22   6  93  40]\n",
      " [  4   2   0   2   1  22 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.71      0.64       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.68      0.71      0.69       210\n",
      "           5       0.59      0.64      0.62       210\n",
      "           6       0.65      0.44      0.53       210\n",
      "           7       0.79      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7639455782312925\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[160   2   2  10  25  10   1]\n",
      " [  4 172   8   7  10   6   3]\n",
      " [  0   4 197   2   3   4   0]\n",
      " [  3  13   2 158  15  11   8]\n",
      " [ 24  15   5  15 146   3   2]\n",
      " [  5  10   3  17   5 134  36]\n",
      " [  4   1   1   3   8  37 156]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.76      0.78       210\n",
      "           2       0.79      0.82      0.81       210\n",
      "           3       0.90      0.94      0.92       210\n",
      "           4       0.75      0.75      0.75       210\n",
      "           5       0.69      0.70      0.69       210\n",
      "           6       0.65      0.64      0.65       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   6   2   5  34  10   2]\n",
      " [  3 165   8  10  17   6   1]\n",
      " [  4   8 190   6   1   1   0]\n",
      " [ 17  25  15 121  18  13   1]\n",
      " [ 34  30   3  11 126   2   4]\n",
      " [ 26  17  13  24   8  75  47]\n",
      " [  9   2   1   9   5  30 154]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.72      0.67       210\n",
      "           2       0.65      0.79      0.71       210\n",
      "           3       0.82      0.90      0.86       210\n",
      "           4       0.65      0.58      0.61       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.55      0.36      0.43       210\n",
      "           7       0.74      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   4   0   9  30  16   2]\n",
      " [  3 170   8  10  13   3   3]\n",
      " [  4   6 193   4   1   2   0]\n",
      " [ 14  20  20 125  17  12   2]\n",
      " [ 33  31   7  16 118   2   3]\n",
      " [ 18  13   9  21  12  94  43]\n",
      " [  4   2   1   7   3  41 152]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.71      0.69       210\n",
      "           2       0.69      0.81      0.75       210\n",
      "           3       0.81      0.92      0.86       210\n",
      "           4       0.65      0.60      0.62       210\n",
      "           5       0.61      0.56      0.58       210\n",
      "           6       0.55      0.45      0.49       210\n",
      "           7       0.74      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.68      1470\n",
      "weighted avg       0.67      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   5   1   8  30  13   3]\n",
      " [  1 161  11  10  21   5   1]\n",
      " [  4   5 194   6   0   1   0]\n",
      " [ 18  21  16 123  17  13   2]\n",
      " [ 30  23   9  14 131   2   1]\n",
      " [ 16  12   7  23  10  91  51]\n",
      " [  6   2   0  10   4  32 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.71      0.69       210\n",
      "           2       0.70      0.77      0.73       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.63      0.59      0.61       210\n",
      "           5       0.62      0.62      0.62       210\n",
      "           6       0.58      0.43      0.50       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   6   0   8  30  12   4]\n",
      " [  2 168  13   5  16   4   2]\n",
      " [  4   9 189   6   0   2   0]\n",
      " [ 16  17  18 125  22  11   1]\n",
      " [ 30  34  10   9 124   1   2]\n",
      " [ 15  14   8  20  11  88  54]\n",
      " [  6   2   0   9   6  30 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.71      0.69       210\n",
      "           2       0.67      0.80      0.73       210\n",
      "           3       0.79      0.90      0.84       210\n",
      "           4       0.69      0.60      0.64       210\n",
      "           5       0.59      0.59      0.59       210\n",
      "           6       0.59      0.42      0.49       210\n",
      "           7       0.71      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   5   2   7  34  12   5]\n",
      " [  2 161  14   4  23   3   3]\n",
      " [  4   6 191   6   0   3   0]\n",
      " [ 14  13  20 123  25  12   3]\n",
      " [ 26  25  10   6 139   1   3]\n",
      " [ 16  11   9  21  10  84  59]\n",
      " [  4   1   0   8   4  30 163]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.69      0.69       210\n",
      "           2       0.73      0.77      0.75       210\n",
      "           3       0.78      0.91      0.84       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.59      0.66      0.62       210\n",
      "           6       0.58      0.40      0.47       210\n",
      "           7       0.69      0.78      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   5   1   8  31  12   3]\n",
      " [  2 165  13   5  19   3   3]\n",
      " [  4   6 193   3   0   4   0]\n",
      " [ 16  13  21 119  27  11   3]\n",
      " [ 27  24  11   8 138   0   2]\n",
      " [ 16  13   7  20  10  88  56]\n",
      " [  2   2   0   8   5  31 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.72      0.79      0.75       210\n",
      "           3       0.78      0.92      0.85       210\n",
      "           4       0.70      0.57      0.62       210\n",
      "           5       0.60      0.66      0.63       210\n",
      "           6       0.59      0.42      0.49       210\n",
      "           7       0.71      0.77      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   2  15   6  48  30   9]\n",
      " [  1 116  28   9  28  25   3]\n",
      " [  1  10 176   5   0  18   0]\n",
      " [  5  14  30  41  56  46  18]\n",
      " [ 13  31   9   5 131   9  12]\n",
      " [  5   7   6  11  11 115  55]\n",
      " [  0   0   0   2   2  54 152]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.48      0.60       210\n",
      "           2       0.64      0.55      0.59       210\n",
      "           3       0.67      0.84      0.74       210\n",
      "           4       0.52      0.20      0.28       210\n",
      "           5       0.47      0.62      0.54       210\n",
      "           6       0.39      0.55      0.45       210\n",
      "           7       0.61      0.72      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.55      1470\n",
      "weighted avg       0.59      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 95   2  12   7  49  34  11]\n",
      " [  0 110  28   9  33  28   2]\n",
      " [  0  15 168   6   0  21   0]\n",
      " [  6  14  29  29  65  47  20]\n",
      " [ 14  34   7   6 129   5  15]\n",
      " [  5   7   7  12  12 110  57]\n",
      " [  0   0   0   1   4  54 151]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.45      0.58       210\n",
      "           2       0.60      0.52      0.56       210\n",
      "           3       0.67      0.80      0.73       210\n",
      "           4       0.41      0.14      0.21       210\n",
      "           5       0.44      0.61      0.51       210\n",
      "           6       0.37      0.52      0.43       210\n",
      "           7       0.59      0.72      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.52      1470\n",
      "weighted avg       0.55      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7571428571428571\n",
      "Confusion Matrix of SVM is:\n",
      " [[168   3   1   7  24   7   0]\n",
      " [  4 167   8  12  10   8   1]\n",
      " [  1   3 196   4   2   4   0]\n",
      " [  5  14   4 161   9  15   2]\n",
      " [ 32  16   2  11 145   3   1]\n",
      " [  8  14   6  17   1 126  38]\n",
      " [  2   2   0   3   5  48 150]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.80      0.78       210\n",
      "           2       0.76      0.80      0.78       210\n",
      "           3       0.90      0.93      0.92       210\n",
      "           4       0.75      0.77      0.76       210\n",
      "           5       0.74      0.69      0.71       210\n",
      "           6       0.60      0.60      0.60       210\n",
      "           7       0.78      0.71      0.75       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7578231292517007\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   6   0   7  23  13   0]\n",
      " [  1 170   6  13  12   6   2]\n",
      " [  1   7 189   2   6   5   0]\n",
      " [  9   8   3 151  19  17   3]\n",
      " [ 18  22   2  13 150   3   2]\n",
      " [  6   6   2  21   6 123  46]\n",
      " [  0   1   0   7   3  29 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.77      0.79       210\n",
      "           2       0.77      0.81      0.79       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.71      0.72      0.71       210\n",
      "           5       0.68      0.71      0.70       210\n",
      "           6       0.63      0.59      0.61       210\n",
      "           7       0.76      0.81      0.79       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7680272108843538\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   1   0   6  28  20   1]\n",
      " [  1 166   7  12  12  11   1]\n",
      " [  2   2 196   3   2   5   0]\n",
      " [  4   4   7 157  13  20   5]\n",
      " [ 19  18   1  13 153   2   4]\n",
      " [  3   6   0  12   6 127  56]\n",
      " [  1   0   0   1   3  29 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.73      0.78       210\n",
      "           2       0.84      0.79      0.82       210\n",
      "           3       0.93      0.93      0.93       210\n",
      "           4       0.77      0.75      0.76       210\n",
      "           5       0.71      0.73      0.72       210\n",
      "           6       0.59      0.60      0.60       210\n",
      "           7       0.72      0.84      0.78       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7054421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   2   4   6  25  13   4]\n",
      " [  2 162  11   9  15  10   1]\n",
      " [  1   6 189   5   1   8   0]\n",
      " [  4  12  19 114  21  25  15]\n",
      " [ 25  18   5  13 141   1   7]\n",
      " [  4   8   9  13   9 110  57]\n",
      " [  2   1   0   2   8  32 165]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.74      0.77       210\n",
      "           2       0.78      0.77      0.77       210\n",
      "           3       0.80      0.90      0.85       210\n",
      "           4       0.70      0.54      0.61       210\n",
      "           5       0.64      0.67      0.66       210\n",
      "           6       0.55      0.52      0.54       210\n",
      "           7       0.66      0.79      0.72       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.70      1470\n",
      "weighted avg       0.71      0.71      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [198   0  12   0   0   0   0]\n",
      " [ 79   0 131   0   0   0   0]\n",
      " [196   0  14   0   0   0   0]\n",
      " [206   0   4   0   0   0   0]\n",
      " [203   0   7   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      1.00      0.28       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.78      0.62      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.14      1470\n",
      "weighted avg       0.13      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 170   0  40]\n",
      " [  0   0   1  11 171   0  27]\n",
      " [  0   0 129   2  58   0  21]\n",
      " [  0   0   5   9 137   0  59]\n",
      " [  0   0   1   3 191   0  15]\n",
      " [  0   0   4   3  51   0 152]\n",
      " [  0   0   0   0  12   0 198]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.92      0.61      0.74       210\n",
      "           4       0.32      0.04      0.08       210\n",
      "           5       0.24      0.91      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.94      0.55       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.27      0.36      0.25      1470\n",
      "weighted avg       0.27      0.36      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130  40   0   0   0  28  12]\n",
      " [  5 177   1   0   0  24   3]\n",
      " [  2  56 129   2   0  21   0]\n",
      " [ 17 125   4   5   0  32  27]\n",
      " [ 29 165   1   0   0   4  11]\n",
      " [ 14  39   2   3   0  71  81]\n",
      " [  5   7   0   0   0  27 171]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.62      0.63       210\n",
      "           2       0.29      0.84      0.43       210\n",
      "           3       0.94      0.61      0.74       210\n",
      "           4       0.50      0.02      0.05       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.56      0.81      0.66       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.41      1470\n",
      "weighted avg       0.47      0.46      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   6   2   0  34  34   4]\n",
      " [  5 137   3   0  38  24   3]\n",
      " [  2  51 132   3   5  17   0]\n",
      " [ 17  33   9   4  87  46  14]\n",
      " [ 29  26   3   0 137   8   7]\n",
      " [ 14  14   3   2  24  86  67]\n",
      " [  5   0   1   0   7  45 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.62      0.63       210\n",
      "           2       0.51      0.65      0.57       210\n",
      "           3       0.86      0.63      0.73       210\n",
      "           4       0.44      0.02      0.04       210\n",
      "           5       0.41      0.65      0.51       210\n",
      "           6       0.33      0.41      0.37       210\n",
      "           7       0.62      0.72      0.67       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.50      1470\n",
      "weighted avg       0.55      0.53      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  15   4  12  26  27   4]\n",
      " [  5 140  13  11  27  11   3]\n",
      " [  2  25 171   4   3   5   0]\n",
      " [  9  24  25  76  28  36  12]\n",
      " [ 28  21   9  26 114   5   7]\n",
      " [  4  20   7  14  16  89  60]\n",
      " [  3   7   1   3   6  43 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64       210\n",
      "           2       0.56      0.67      0.61       210\n",
      "           3       0.74      0.81      0.78       210\n",
      "           4       0.52      0.36      0.43       210\n",
      "           5       0.52      0.54      0.53       210\n",
      "           6       0.41      0.42      0.42       210\n",
      "           7       0.63      0.70      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5829931972789115\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   3   2  24  33  20   4]\n",
      " [  8 131  11  24  22  11   3]\n",
      " [ 14   9 170   9   3   5   0]\n",
      " [ 17  23  13  90  20  37  10]\n",
      " [ 16  33   5  37 108   4   7]\n",
      " [ 12  20   5  25   5  85  58]\n",
      " [  9   6   1   5   1  39 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.59      0.60       210\n",
      "           2       0.58      0.62      0.60       210\n",
      "           3       0.82      0.81      0.82       210\n",
      "           4       0.42      0.43      0.42       210\n",
      "           5       0.56      0.51      0.54       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.65      0.71      0.68       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   2   8  20  36  18  10]\n",
      " [  5 132  12  20  25  12   4]\n",
      " [  4  17 171   8   4   6   0]\n",
      " [  7  22  14  85  33  33  16]\n",
      " [ 14  33   3  31 117   6   6]\n",
      " [  3  20  12  23   6  79  67]\n",
      " [  3   6   7   6   1  39 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.55      0.64       210\n",
      "           2       0.57      0.63      0.60       210\n",
      "           3       0.75      0.81      0.78       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.53      0.56      0.54       210\n",
      "           6       0.41      0.38      0.39       210\n",
      "           7       0.59      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   4   2  16  33  23  10]\n",
      " [  8 129  10  20  27  12   4]\n",
      " [  2  16 165  12   4  11   0]\n",
      " [ 13  17   8  94  20  46  12]\n",
      " [ 25  35   2  22 116   4   6]\n",
      " [ 10  18   3  15   5  92  67]\n",
      " [  0   6   5   6   4  42 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.58      0.63       210\n",
      "           2       0.57      0.61      0.59       210\n",
      "           3       0.85      0.79      0.81       210\n",
      "           4       0.51      0.45      0.48       210\n",
      "           5       0.56      0.55      0.55       210\n",
      "           6       0.40      0.44      0.42       210\n",
      "           7       0.60      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   7   3  24  31  15  10]\n",
      " [  3 134  12  21  27   9   4]\n",
      " [  1  18 172   9   4   6   0]\n",
      " [  9  24  10 102  22  30  13]\n",
      " [ 20  24   2  35 120   6   3]\n",
      " [ 12  18   5  23  11  79  62]\n",
      " [  7   4   5   5   7  43 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.57      0.63       210\n",
      "           2       0.59      0.64      0.61       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.47      0.49      0.48       210\n",
      "           5       0.54      0.57      0.56       210\n",
      "           6       0.42      0.38      0.40       210\n",
      "           7       0.60      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.59      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   5   3  22  29  15  11]\n",
      " [  6 127  14  21  23  15   4]\n",
      " [  0  12 175  11   4   7   1]\n",
      " [ 12  19  12 101  21  30  15]\n",
      " [ 19  24   3  26 125   8   5]\n",
      " [ 16  10   6  28   8  79  63]\n",
      " [  6   3   4   4   8  41 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.60      0.63       210\n",
      "           2       0.64      0.60      0.62       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.47      0.48      0.48       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.41      0.38      0.39       210\n",
      "           7       0.59      0.69      0.64       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   6   3  17  28  17  11]\n",
      " [ 11 126  12  21  27   8   5]\n",
      " [  6   5 175  12   6   5   1]\n",
      " [ 14  14   9  89  34  35  15]\n",
      " [ 23  23   4  27 117  10   6]\n",
      " [ 15  16   4  27   9  79  60]\n",
      " [  8   3   3  10   9  41 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.61      0.62       210\n",
      "           2       0.65      0.60      0.63       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.51      0.56      0.53       210\n",
      "           6       0.41      0.38      0.39       210\n",
      "           7       0.58      0.65      0.61       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125  11   3  18  26  15  12]\n",
      " [ 10 131  11  21  24   9   4]\n",
      " [  7   3 181   8   6   5   0]\n",
      " [ 15  17  15  89  32  30  12]\n",
      " [ 21  23   5  36 108  12   5]\n",
      " [ 18  12   6  26  11  76  61]\n",
      " [  7   1   5   7  12  39 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.60      0.61       210\n",
      "           2       0.66      0.62      0.64       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.60      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.57      0.58      0.57      1470\n",
      "weighted avg       0.57      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   4   6  16  35  14  11]\n",
      " [  9 124  15  22  25  11   4]\n",
      " [  3   8 183   8   4   4   0]\n",
      " [ 13  22  17  89  22  34  13]\n",
      " [ 27  24   5  25 108  12   9]\n",
      " [ 18  12   4  26  12  74  64]\n",
      " [  7   5   5  10  11  36 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.59      0.60       210\n",
      "           2       0.62      0.59      0.61       210\n",
      "           3       0.78      0.87      0.82       210\n",
      "           4       0.45      0.42      0.44       210\n",
      "           5       0.50      0.51      0.51       210\n",
      "           6       0.40      0.35      0.37       210\n",
      "           7       0.57      0.65      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.57      1470\n",
      "weighted avg       0.56      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   9   5  16  26  19   5]\n",
      " [  8 131  15  19  23  10   4]\n",
      " [  4   6 179  11   4   6   0]\n",
      " [ 13  19  11  87  30  36  14]\n",
      " [ 23  30   7  27 106  11   6]\n",
      " [ 14  18   4  24  10  73  67]\n",
      " [  4   3   5  10  11  38 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.62      0.64       210\n",
      "           2       0.61      0.62      0.62       210\n",
      "           3       0.79      0.85      0.82       210\n",
      "           4       0.45      0.41      0.43       210\n",
      "           5       0.50      0.50      0.50       210\n",
      "           6       0.38      0.35      0.36       210\n",
      "           7       0.59      0.66      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   7   8  23  29  14  10]\n",
      " [  9 126  13  22  24   8   8]\n",
      " [  5   6 175  14   3   7   0]\n",
      " [  8  17  11  92  32  30  20]\n",
      " [ 26  29   5  26 106   8  10]\n",
      " [ 16  19   5  25   9  76  60]\n",
      " [  2   1   7  12  14  45 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.57      0.60       210\n",
      "           2       0.61      0.60      0.61       210\n",
      "           3       0.78      0.83      0.81       210\n",
      "           4       0.43      0.44      0.43       210\n",
      "           5       0.49      0.50      0.50       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.54      0.61      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130  10   6  19  25  12   8]\n",
      " [  7 131  13  18  21  15   5]\n",
      " [  3   9 177  14   2   5   0]\n",
      " [ 10  18  12  84  32  36  18]\n",
      " [ 22  31   6  24 104  10  13]\n",
      " [ 17  19   6  24   8  77  59]\n",
      " [  3   1   7  12  13  44 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.62      0.65       210\n",
      "           2       0.60      0.62      0.61       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.43      0.40      0.41       210\n",
      "           5       0.51      0.50      0.50       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.56      0.62      0.59       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   7   6  21  26  13   9]\n",
      " [  9 126  12  18  27  14   4]\n",
      " [  5   5 180  12   3   5   0]\n",
      " [ 13  14  13  87  33  33  17]\n",
      " [ 24  25   9  27 104  10  11]\n",
      " [ 19  16   7  17  10  83  58]\n",
      " [  5   1   7  11  13  45 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.61      0.62       210\n",
      "           2       0.65      0.60      0.62       210\n",
      "           3       0.77      0.86      0.81       210\n",
      "           4       0.45      0.41      0.43       210\n",
      "           5       0.48      0.50      0.49       210\n",
      "           6       0.41      0.40      0.40       210\n",
      "           7       0.56      0.61      0.59       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.57      1470\n",
      "weighted avg       0.56      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   8   6  20  27  13   8]\n",
      " [  9 124  15  17  26  15   4]\n",
      " [  5   7 179   8   3   8   0]\n",
      " [ 13  17  11  86  30  35  18]\n",
      " [ 26  31   5  25 107   8   8]\n",
      " [ 16  17   7  25  10  83  52]\n",
      " [  4   0   7   9  14  45 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.62       210\n",
      "           2       0.61      0.59      0.60       210\n",
      "           3       0.78      0.85      0.81       210\n",
      "           4       0.45      0.41      0.43       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.59      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   9   4  19  27  18   9]\n",
      " [  8 132  14  19  24  10   3]\n",
      " [  6   8 176  10   5   5   0]\n",
      " [ 15  19  11  83  28  37  17]\n",
      " [ 29  32   4  25  98  16   6]\n",
      " [ 18  14   7  27  11  79  54]\n",
      " [  5   2   7  11  12  44 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.59      0.60       210\n",
      "           2       0.61      0.63      0.62       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.43      0.40      0.41       210\n",
      "           5       0.48      0.47      0.47       210\n",
      "           6       0.38      0.38      0.38       210\n",
      "           7       0.59      0.61      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.56      1470\n",
      "weighted avg       0.55      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5578231292517006\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   8   7  22  24  12   9]\n",
      " [  8 123  12  23  28  13   3]\n",
      " [  5   6 179  11   3   6   0]\n",
      " [  9  17  12  85  34  34  19]\n",
      " [ 28  30   4  26  98  15   9]\n",
      " [ 15  12   7  30  12  78  56]\n",
      " [  4   3   7   8  15  44 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.61      0.63       210\n",
      "           2       0.62      0.59      0.60       210\n",
      "           3       0.79      0.85      0.82       210\n",
      "           4       0.41      0.40      0.41       210\n",
      "           5       0.46      0.47      0.46       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.57      0.61      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.56      1470\n",
      "weighted avg       0.55      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79   1  18   0  45   4  63]\n",
      " [  1  87  63   0  35   1  23]\n",
      " [  1  14 175   0   2   2  16]\n",
      " [  8  21  40   0  67   2  72]\n",
      " [  8  28  20   0 126   0  28]\n",
      " [  3   6  20   0  18   2 161]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.38      0.51       210\n",
      "           2       0.55      0.41      0.47       210\n",
      "           3       0.52      0.83      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.18      0.01      0.02       210\n",
      "           7       0.36      0.99      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.41      0.46      0.38      1470\n",
      "weighted avg       0.41      0.46      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   3   0   0  52   9  39]\n",
      " [  2 130  18   0  36   7  17]\n",
      " [  3  17 170   0   4  11   5]\n",
      " [  9  31  28   2  71   8  61]\n",
      " [ 11  39   7   0 131   0  22]\n",
      " [  4   8  14   0  19  17 148]\n",
      " [  0   0   0   0   3   0 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.51      0.62       210\n",
      "           2       0.57      0.62      0.59       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       1.00      0.01      0.02       210\n",
      "           5       0.41      0.62      0.50       210\n",
      "           6       0.33      0.08      0.13       210\n",
      "           7       0.41      0.99      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.60      0.52      0.46      1470\n",
      "weighted avg       0.60      0.52      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   3   0   0  43  13  23]\n",
      " [  2 150   8   0  27  16   7]\n",
      " [  3  19 167   0   5  16   0]\n",
      " [ 12  32  24   4  75  25  38]\n",
      " [ 16  36   4   0 135   2  17]\n",
      " [  8  14   9   2  12  40 125]\n",
      " [  0   0   0   0   3   5 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.61      0.68       210\n",
      "           2       0.59      0.71      0.65       210\n",
      "           3       0.79      0.80      0.79       210\n",
      "           4       0.67      0.02      0.04       210\n",
      "           5       0.45      0.64      0.53       210\n",
      "           6       0.34      0.19      0.24       210\n",
      "           7       0.49      0.96      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.51      1470\n",
      "weighted avg       0.58      0.56      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   2   0   3  38  21  13]\n",
      " [  1 147   6   1  31  19   5]\n",
      " [  2  19 171   1   4  13   0]\n",
      " [ 11  20  15  35  67  35  27]\n",
      " [ 19  28   3   3 139   3  15]\n",
      " [  6  11   2   6  14  72  99]\n",
      " [  0   0   0   0   4  15 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.63      0.70       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.71      0.17      0.27       210\n",
      "           5       0.47      0.66      0.55       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.55      0.91      0.68       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.63      0.60      0.58      1470\n",
      "weighted avg       0.63      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   1   0   5  41  26   8]\n",
      " [  1 144   8   5  29  21   2]\n",
      " [  3  14 171   1   6  15   0]\n",
      " [ 10  18  11  62  51  36  22]\n",
      " [ 17  21   3   3 152   5   9]\n",
      " [  5   8   0   9  16  82  90]\n",
      " [  0   0   0   0   3  20 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.61      0.69       210\n",
      "           2       0.70      0.69      0.69       210\n",
      "           3       0.89      0.81      0.85       210\n",
      "           4       0.73      0.30      0.42       210\n",
      "           5       0.51      0.72      0.60       210\n",
      "           6       0.40      0.39      0.40       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.62      1470\n",
      "weighted avg       0.66      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   1   0   8  36  24   8]\n",
      " [  1 139   8  10  29  18   5]\n",
      " [  1  11 174   6   4  14   0]\n",
      " [  5   8   7  92  34  46  18]\n",
      " [ 15  20   2   9 150   5   9]\n",
      " [  3   5   1  12  12 105  72]\n",
      " [  0   0   0   0   3  28 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.63      0.72       210\n",
      "           2       0.76      0.66      0.71       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.67      0.44      0.53       210\n",
      "           5       0.56      0.71      0.63       210\n",
      "           6       0.44      0.50      0.47       210\n",
      "           7       0.62      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   1   0   6  34  24   7]\n",
      " [  2 149   7  11  23  15   3]\n",
      " [  1   9 176   6   5  13   0]\n",
      " [  5   9   7 104  30  38  17]\n",
      " [ 17  20   1  10 149   4   9]\n",
      " [  2   3   1  13  10 105  76]\n",
      " [  0   0   0   0   4  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.78      0.71      0.74       210\n",
      "           3       0.92      0.84      0.88       210\n",
      "           4       0.69      0.50      0.58       210\n",
      "           5       0.58      0.71      0.64       210\n",
      "           6       0.48      0.50      0.49       210\n",
      "           7       0.62      0.88      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   1   0   5  39  24   7]\n",
      " [  2 146   7  14  25  12   4]\n",
      " [  2   4 178   9   3  14   0]\n",
      " [  4   5   2 118  30  38  13]\n",
      " [ 16  19   0   9 155   3   8]\n",
      " [  3   3   0  14  10 109  71]\n",
      " [  0   0   0   1   4  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.72       210\n",
      "           2       0.82      0.70      0.75       210\n",
      "           3       0.95      0.85      0.90       210\n",
      "           4       0.69      0.56      0.62       210\n",
      "           5       0.58      0.74      0.65       210\n",
      "           6       0.48      0.52      0.50       210\n",
      "           7       0.63      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   0   7  32  24   5]\n",
      " [  3 151   7   9  24  13   3]\n",
      " [  3   6 181   4   4  12   0]\n",
      " [  6   4   4 120  27  32  17]\n",
      " [ 16  18   0  14 151   4   7]\n",
      " [  3   4   0  17   9 112  65]\n",
      " [  1   0   0   0   3  28 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.94      0.86      0.90       210\n",
      "           4       0.70      0.57      0.63       210\n",
      "           5       0.60      0.72      0.66       210\n",
      "           6       0.50      0.53      0.51       210\n",
      "           7       0.65      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7068027210884353\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   1   0   9  32  23   8]\n",
      " [  2 146   7   9  29  13   4]\n",
      " [  1   2 188   6   4   9   0]\n",
      " [  3   3   4 125  27  35  13]\n",
      " [ 17  18   0  10 152   6   7]\n",
      " [  4   2   1  12  10 113  68]\n",
      " [  2   0   0   2   3  25 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.65      0.73       210\n",
      "           2       0.85      0.70      0.76       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.72      0.60      0.65       210\n",
      "           5       0.59      0.72      0.65       210\n",
      "           6       0.50      0.54      0.52       210\n",
      "           7       0.64      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7068027210884353\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   1   0   6  33  26   5]\n",
      " [  3 152   6  13  22  11   3]\n",
      " [  2   6 184   3   5  10   0]\n",
      " [  7   6   4 123  27  31  12]\n",
      " [ 19  17   0  13 151   3   7]\n",
      " [  3   4   0  15  10 111  67]\n",
      " [  1   0   0   0   3  27 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.72       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.71      0.59      0.64       210\n",
      "           5       0.60      0.72      0.66       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   0   7  31  25   5]\n",
      " [  3 144   7  15  26  13   2]\n",
      " [  2   5 186   7   2   8   0]\n",
      " [  4   4   5 128  25  30  14]\n",
      " [ 16  17   0  16 148   5   8]\n",
      " [  4   1   1  14   8 113  69]\n",
      " [  0   0   0   0   3  31 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.67      0.74       210\n",
      "           2       0.84      0.69      0.75       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.68      0.61      0.64       210\n",
      "           5       0.61      0.70      0.65       210\n",
      "           6       0.50      0.54      0.52       210\n",
      "           7       0.64      0.84      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   0   0   7  30  24   7]\n",
      " [  2 152   7  14  20  12   3]\n",
      " [  1   5 184   6   3  11   0]\n",
      " [  7   4   5 128  25  29  12]\n",
      " [ 20  17   0  11 151   4   7]\n",
      " [  3   1   1  20   7 113  65]\n",
      " [  0   0   0   0   2  25 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.68      0.74       210\n",
      "           2       0.85      0.72      0.78       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.69      0.61      0.65       210\n",
      "           5       0.63      0.72      0.67       210\n",
      "           6       0.52      0.54      0.53       210\n",
      "           7       0.66      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   0   6  34  22   6]\n",
      " [  3 148   8  10  24  13   4]\n",
      " [  1   7 185   4   5   8   0]\n",
      " [  8   4   4 126  24  30  14]\n",
      " [ 16  16   1  14 150   4   9]\n",
      " [  1   2   0  19   8 113  67]\n",
      " [  1   0   0   1   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.83      0.70      0.76       210\n",
      "           3       0.93      0.88      0.91       210\n",
      "           4       0.70      0.60      0.65       210\n",
      "           5       0.61      0.71      0.66       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   2   0   8  31  23   6]\n",
      " [  1 151   7  16  19  14   2]\n",
      " [  1   6 185   4   6   8   0]\n",
      " [  6   6   4 122  24  33  15]\n",
      " [ 20  17   0  12 151   4   6]\n",
      " [  4   3   0  15   6 116  66]\n",
      " [  0   0   0   0   5  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.82      0.72      0.76       210\n",
      "           3       0.94      0.88      0.91       210\n",
      "           4       0.69      0.58      0.63       210\n",
      "           5       0.62      0.72      0.67       210\n",
      "           6       0.52      0.55      0.53       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7224489795918367\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   2   0   5  32  25   6]\n",
      " [  3 153   7  11  23  12   1]\n",
      " [  3   9 185   4   3   6   0]\n",
      " [  4   5   3 131  25  28  14]\n",
      " [ 17  15   0  12 157   4   5]\n",
      " [  4   5   0  13   5 119  64]\n",
      " [  0   0   0   2   4  27 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.73       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.74      0.62      0.68       210\n",
      "           5       0.63      0.75      0.68       210\n",
      "           6       0.54      0.57      0.55       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   0   9  27  24   5]\n",
      " [  3 152   7  13  21  12   2]\n",
      " [  2   5 186   1   7   9   0]\n",
      " [  6   6   4 125  26  28  15]\n",
      " [ 18  16   0  17 149   4   6]\n",
      " [  5   3   0  14   7 117  64]\n",
      " [  1   0   0   1   4  22 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.74       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.69      0.60      0.64       210\n",
      "           5       0.62      0.71      0.66       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.66      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   0   6  29  23   7]\n",
      " [  3 151   7  13  23  11   2]\n",
      " [  1   8 185   3   5   8   0]\n",
      " [  5   4   4 133  23  32   9]\n",
      " [ 22  18   1  15 144   4   6]\n",
      " [  5   4   1  16   7 111  66]\n",
      " [  1   0   0   1   3  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.81      0.72      0.76       210\n",
      "           3       0.93      0.88      0.91       210\n",
      "           4       0.71      0.63      0.67       210\n",
      "           5       0.62      0.69      0.65       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   1   0   7  30  24   6]\n",
      " [  5 152   7  13  20  12   1]\n",
      " [  3   6 187   3   4   7   0]\n",
      " [  9   6   4 135  19  25  12]\n",
      " [ 19  18   0  16 145   5   7]\n",
      " [  5   3   1  15   6 115  65]\n",
      " [  0   0   0   0   4  31 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.72       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.71      0.64      0.68       210\n",
      "           5       0.64      0.69      0.66       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.66      0.83      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.72      1470\n",
      "weighted avg       0.72      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7136054421768707\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   1   0   7  31  22   7]\n",
      " [  3 152   6  14  20  13   2]\n",
      " [  1   6 186   4   4   9   0]\n",
      " [  7   7   4 134  20  27  11]\n",
      " [ 22  18   0  14 145   4   7]\n",
      " [  6   4   1  15   6 113  65]\n",
      " [  0   0   0   2   4  27 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.81      0.72      0.76       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.71      0.64      0.67       210\n",
      "           5       0.63      0.69      0.66       210\n",
      "           6       0.53      0.54      0.53       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 83   1  27   6  49  35   9]\n",
      " [  1 107  41   6  28  26   1]\n",
      " [  0   9 181   4   0  16   0]\n",
      " [  7  15  34  30  62  42  20]\n",
      " [ 15  32  13   3 126   7  14]\n",
      " [  6   8  12  10  10 108  56]\n",
      " [  0   0   0   1   2  62 145]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.40      0.52       210\n",
      "           2       0.62      0.51      0.56       210\n",
      "           3       0.59      0.86      0.70       210\n",
      "           4       0.50      0.14      0.22       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.36      0.51      0.43       210\n",
      "           7       0.59      0.69      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.51      1470\n",
      "weighted avg       0.55      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ab723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5870748299319728\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[118  11   2  13  46  10  10]\n",
      " [  9 124  10  17  29  13   8]\n",
      " [  0  14 170   6   5   3  12]\n",
      " [  9  18  15  96  40  12  20]\n",
      " [ 12  15   4  18 135   6  20]\n",
      " [ 13  16   5  12  20  61  83]\n",
      " [  5   4   1   6   8  27 159]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.56      0.63       210\n",
      "           2       0.61      0.59      0.60       210\n",
      "           3       0.82      0.81      0.82       210\n",
      "           4       0.57      0.46      0.51       210\n",
      "           5       0.48      0.64      0.55       210\n",
      "           6       0.46      0.29      0.36       210\n",
      "           7       0.51      0.76      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  14   1  13  41   9   7]\n",
      " [ 28 121  10  16  25   6   4]\n",
      " [ 10  22 165   8   4   1   0]\n",
      " [ 60  42  14  44  36   4  10]\n",
      " [ 50  41   7  14  83   4  11]\n",
      " [ 48  34   5  22  16  46  39]\n",
      " [ 30  22   6  20  14  38  80]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.60      0.45       210\n",
      "           2       0.41      0.58      0.48       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.32      0.21      0.25       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.43      0.22      0.29       210\n",
      "           7       0.53      0.38      0.44       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.44      1470\n",
      "weighted avg       0.46      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122  13   1  19  39  10   6]\n",
      " [ 32 118   9  16  24   8   3]\n",
      " [  9  22 162   9   4   4   0]\n",
      " [ 51  31  11  48  43   7  19]\n",
      " [ 37  37   4  18  93   7  14]\n",
      " [ 48  27   4  16  16  57  42]\n",
      " [ 23  16   4  11  14  55  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.58      0.46       210\n",
      "           2       0.45      0.56      0.50       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.35      0.23      0.28       210\n",
      "           5       0.40      0.44      0.42       210\n",
      "           6       0.39      0.27      0.32       210\n",
      "           7       0.51      0.41      0.46       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.47959183673469385\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114  15   1  21  43  10   6]\n",
      " [ 29 112  12  15  27   8   7]\n",
      " [  7  21 165  12   2   3   0]\n",
      " [ 38  31  13  59  40   9  20]\n",
      " [ 33  33   3  18 104   6  13]\n",
      " [ 44  24   3  16  19  63  41]\n",
      " [ 23  10   4  12  17  56  88]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.54      0.46       210\n",
      "           2       0.46      0.53      0.49       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.39      0.28      0.33       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.41      0.30      0.35       210\n",
      "           7       0.50      0.42      0.46       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.48027210884353744\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114  15   1  23  42   6   9]\n",
      " [ 29 114  15  14  26   7   5]\n",
      " [  7  23 163   8   5   4   0]\n",
      " [ 39  36  13  57  41   7  17]\n",
      " [ 28  30   5  23 105   5  14]\n",
      " [ 44  26   6  17  13  56  48]\n",
      " [ 20  13   4  12  23  41  97]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.54      0.46       210\n",
      "           2       0.44      0.54      0.49       210\n",
      "           3       0.79      0.78      0.78       210\n",
      "           4       0.37      0.27      0.31       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.44      0.27      0.33       210\n",
      "           7       0.51      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.47      1470\n",
      "weighted avg       0.48      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  14   2  25  39   4   9]\n",
      " [ 26 115  18  12  25   8   6]\n",
      " [  7  23 167   7   2   4   0]\n",
      " [ 44  34  13  48  45   8  18]\n",
      " [ 31  33   5  29  93   2  17]\n",
      " [ 47  26   4  17  16  56  44]\n",
      " [ 21  16   4  10  20  46  93]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.56      0.47       210\n",
      "           2       0.44      0.55      0.49       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.32      0.23      0.27       210\n",
      "           5       0.39      0.44      0.41       210\n",
      "           6       0.44      0.27      0.33       210\n",
      "           7       0.50      0.44      0.47       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.48027210884353744\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  14   3  19  38   4   9]\n",
      " [ 24 112  16  15  27   9   7]\n",
      " [  9  22 163   9   1   6   0]\n",
      " [ 45  33  13  48  45  10  16]\n",
      " [ 33  31   7  17 102   3  17]\n",
      " [ 44  21   5  20  16  58  46]\n",
      " [ 20  16   4  10  16  44 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.59      0.48       210\n",
      "           2       0.45      0.53      0.49       210\n",
      "           3       0.77      0.78      0.77       210\n",
      "           4       0.35      0.23      0.28       210\n",
      "           5       0.42      0.49      0.45       210\n",
      "           6       0.43      0.28      0.34       210\n",
      "           7       0.51      0.48      0.49       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.47      1470\n",
      "weighted avg       0.48      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.2789115646258503\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 27   0  91   9  13  18  52]\n",
      " [  7   0 132   8   7   2  54]\n",
      " [  1   0 178   3   1  23   4]\n",
      " [  5   0 148   8   7  10  32]\n",
      " [  8   0 154   6   9   4  29]\n",
      " [ 17   0  45   6   3  41  98]\n",
      " [ 11   0  11  10   1  30 147]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.13      0.19       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.23      0.85      0.37       210\n",
      "           4       0.16      0.04      0.06       210\n",
      "           5       0.22      0.04      0.07       210\n",
      "           6       0.32      0.20      0.24       210\n",
      "           7       0.35      0.70      0.47       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.23      0.28      0.20      1470\n",
      "weighted avg       0.23      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2816326530612245\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 28   0  81  12  11  21  57]\n",
      " [ 14   0 124   6  10   2  54]\n",
      " [  4   0 174   1   4  14  13]\n",
      " [  8   0 139   8  11  11  33]\n",
      " [  9   0 148  10   7   6  30]\n",
      " [ 13   0  41   5   3  48 100]\n",
      " [ 10   0   9   8   2  32 149]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.13      0.19       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.24      0.83      0.38       210\n",
      "           4       0.16      0.04      0.06       210\n",
      "           5       0.15      0.03      0.05       210\n",
      "           6       0.36      0.23      0.28       210\n",
      "           7       0.34      0.71      0.46       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.22      0.28      0.20      1470\n",
      "weighted avg       0.22      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.5972789115646259\n",
      "Confusion Matrix of SVM is:\n",
      " [[117   6   0  15  47  17   8]\n",
      " [  9 131  11  17  25  11   6]\n",
      " [  0  23 164   6   3  14   0]\n",
      " [  7  21  11 104  39  14  14]\n",
      " [ 14  16   3  16 138   9  14]\n",
      " [ 13  21   2  25  14  90  45]\n",
      " [  4   4   2  15  12  39 134]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.56      0.63       210\n",
      "           2       0.59      0.62      0.61       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.53      0.50      0.51       210\n",
      "           5       0.50      0.66      0.57       210\n",
      "           6       0.46      0.43      0.45       210\n",
      "           7       0.61      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.36122448979591837\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 89   0  76   7   6  20  12]\n",
      " [ 20  32 122   6   9  10  11]\n",
      " [  8   0 182   3   2  15   0]\n",
      " [ 19   2 131  16  10  13  19]\n",
      " [ 15   2 145   8  10  10  20]\n",
      " [ 25   3  36   8   8  73  57]\n",
      " [ 16   1   9   5   3  47 129]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.42      0.44       210\n",
      "           2       0.80      0.15      0.26       210\n",
      "           3       0.26      0.87      0.40       210\n",
      "           4       0.30      0.08      0.12       210\n",
      "           5       0.21      0.05      0.08       210\n",
      "           6       0.39      0.35      0.37       210\n",
      "           7       0.52      0.61      0.56       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.42      0.36      0.32      1470\n",
      "weighted avg       0.42      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.3952380952380952\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 89   2  31  15  36  23  14]\n",
      " [ 23   1 106  17  12  33  18]\n",
      " [ 11   0 177   4   2  16   0]\n",
      " [ 22   3  69  30  51   8  27]\n",
      " [ 18   1  60  17  81   9  24]\n",
      " [ 30   0  19  13  15  71  62]\n",
      " [ 20   1   3   7   6  41 132]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.42      0.42       210\n",
      "           2       0.12      0.00      0.01       210\n",
      "           3       0.38      0.84      0.52       210\n",
      "           4       0.29      0.14      0.19       210\n",
      "           5       0.40      0.39      0.39       210\n",
      "           6       0.35      0.34      0.35       210\n",
      "           7       0.48      0.63      0.54       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.35      0.40      0.35      1470\n",
      "weighted avg       0.35      0.40      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.2578231292517007\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 61  23  72   1  19  27   7]\n",
      " [ 30   8 120   1  14  30   7]\n",
      " [ 16   2 172   0   5  15   0]\n",
      " [ 32   3 126   2  21  12  14]\n",
      " [ 20   6 143   1  16  11  13]\n",
      " [ 47  23  32   5   9  60  34]\n",
      " [ 61  11   8   7   5  58  60]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.29      0.26       210\n",
      "           2       0.11      0.04      0.06       210\n",
      "           3       0.26      0.82      0.39       210\n",
      "           4       0.12      0.01      0.02       210\n",
      "           5       0.18      0.08      0.11       210\n",
      "           6       0.28      0.29      0.28       210\n",
      "           7       0.44      0.29      0.35       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.23      0.26      0.21      1470\n",
      "weighted avg       0.23      0.26      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23129251700680273\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  12   0   0   0 198]\n",
      " [  0   0  55   0   0   0 155]\n",
      " [  0   0 131   0   0   0  79]\n",
      " [  0   0  15   0   0   0 195]\n",
      " [  0   0  17   0   0   0 193]\n",
      " [  0   0   9   0   0   0 201]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.55      0.62      0.58       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.10      0.23      0.12      1470\n",
      "weighted avg       0.10      0.23      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0  12   0   0 159   0  39]\n",
      " [  0  37  18   0 102   0  53]\n",
      " [  0  13 118   0  63   0  16]\n",
      " [  0  11   4   0 164   0  31]\n",
      " [  0  16   1   0 162   0  31]\n",
      " [  0   8   1   0  77   0 124]\n",
      " [  0   1   0   0  49   0 160]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.38      0.18      0.24       210\n",
      "           3       0.83      0.56      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.21      0.77      0.33       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.76      0.48       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.25      0.32      0.25      1470\n",
      "weighted avg       0.25      0.32      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   4   8   0  42  27  12]\n",
      " [ 45  15  40   0  57  41  12]\n",
      " [ 31   7 124   0  32   4  12]\n",
      " [ 83   3  12   0  81   9  22]\n",
      " [ 51  10   7   0 111  13  18]\n",
      " [ 60   3   6   0  17  50  74]\n",
      " [ 47   0   1   0   2  31 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.56      0.36       210\n",
      "           2       0.36      0.07      0.12       210\n",
      "           3       0.63      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.32      0.53      0.40       210\n",
      "           6       0.29      0.24      0.26       210\n",
      "           7       0.46      0.61      0.53       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.33      0.37      0.33      1470\n",
      "weighted avg       0.33      0.37      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117  16   0   0  40  25  12]\n",
      " [ 45  56  32   0  47  18  12]\n",
      " [ 31  25 121   0  18   3  12]\n",
      " [ 83  19   9   0  70   7  22]\n",
      " [ 51  25   2   0 106   8  18]\n",
      " [ 60  20   1   0  16  39  74]\n",
      " [ 47   9   1   0   2  22 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.56      0.36       210\n",
      "           2       0.33      0.27      0.29       210\n",
      "           3       0.73      0.58      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.35      0.50      0.42       210\n",
      "           6       0.32      0.19      0.23       210\n",
      "           7       0.46      0.61      0.53       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.35      0.39      0.35      1470\n",
      "weighted avg       0.35      0.39      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  13   2  22  20  25  12]\n",
      " [ 43  49  34  16  36  20  12]\n",
      " [ 20  14 132  21   8   3  12]\n",
      " [ 77  10  15  46  32   8  22]\n",
      " [ 51  21   2  23  87   8  18]\n",
      " [ 54  15   7  12   5  43  74]\n",
      " [ 37   5  11   1   1  26 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.55      0.38       210\n",
      "           2       0.39      0.23      0.29       210\n",
      "           3       0.65      0.63      0.64       210\n",
      "           4       0.33      0.22      0.26       210\n",
      "           5       0.46      0.41      0.44       210\n",
      "           6       0.32      0.20      0.25       210\n",
      "           7       0.46      0.61      0.53       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.40      1470\n",
      "weighted avg       0.41      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42517006802721086\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  13   6  44  22  32   7]\n",
      " [ 21  50  36  31  41  16  15]\n",
      " [  8  11 142  17  18  14   0]\n",
      " [ 28   8  15  84  39  15  21]\n",
      " [ 19  21   7  46  91  14  12]\n",
      " [ 28  15   8  30   7  76  46]\n",
      " [ 14   5   5  24   1  65  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.41      0.42       210\n",
      "           2       0.41      0.24      0.30       210\n",
      "           3       0.65      0.68      0.66       210\n",
      "           4       0.30      0.40      0.35       210\n",
      "           5       0.42      0.43      0.42       210\n",
      "           6       0.33      0.36      0.34       210\n",
      "           7       0.49      0.46      0.47       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.42      1470\n",
      "weighted avg       0.43      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   6   1  33  17  32   9]\n",
      " [ 31  44  35  44  24  15  17]\n",
      " [ 11  10 140  21  14  14   0]\n",
      " [ 65   6  10  62  30  17  20]\n",
      " [ 59  16   2  34  69  17  13]\n",
      " [ 46   9   4  26   2  82  41]\n",
      " [ 29   3   3  18   1  65  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.53      0.40       210\n",
      "           2       0.47      0.21      0.29       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.26      0.30      0.28       210\n",
      "           5       0.44      0.33      0.38       210\n",
      "           6       0.34      0.39      0.36       210\n",
      "           7       0.48      0.43      0.45       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.43      0.41      0.41      1470\n",
      "weighted avg       0.43      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   7   3  35  22  33  11]\n",
      " [ 28  47  34  46  24  15  16]\n",
      " [  3  12 140  25  16  14   0]\n",
      " [ 44  15  11  67  36  20  17]\n",
      " [ 48  25   2  34  72  17  12]\n",
      " [ 41   7   2  30  10  85  35]\n",
      " [ 22   5   3  18  11  62  89]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.47      0.40       210\n",
      "           2       0.40      0.22      0.29       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.26      0.32      0.29       210\n",
      "           5       0.38      0.34      0.36       210\n",
      "           6       0.35      0.40      0.37       210\n",
      "           7       0.49      0.42      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   6   3  28  27  25  16]\n",
      " [ 31  47  52  28  22  13  17]\n",
      " [  4  20 146  14   6  13   7]\n",
      " [ 41  18  15  59  35  15  27]\n",
      " [ 50  17   4  38  74  12  15]\n",
      " [ 41  13   4  18  14  68  52]\n",
      " [ 20   9   3   7  12  56 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.50      0.42       210\n",
      "           2       0.36      0.22      0.28       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.31      0.28      0.29       210\n",
      "           5       0.39      0.35      0.37       210\n",
      "           6       0.34      0.32      0.33       210\n",
      "           7       0.43      0.49      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.40      0.41      0.40      1470\n",
      "weighted avg       0.40      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  13   1  30  19  41  15]\n",
      " [ 24  52  44  28  25  23  14]\n",
      " [  4  19 146  13   8  15   5]\n",
      " [ 38  19  12  64  22  27  28]\n",
      " [ 47  23   3  39  62  20  16]\n",
      " [ 30  14   2  15  13  81  55]\n",
      " [ 23  10   4   6   7  57 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.43      0.39       210\n",
      "           2       0.35      0.25      0.29       210\n",
      "           3       0.69      0.70      0.69       210\n",
      "           4       0.33      0.30      0.32       210\n",
      "           5       0.40      0.30      0.34       210\n",
      "           6       0.31      0.39      0.34       210\n",
      "           7       0.44      0.49      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.40      1470\n",
      "weighted avg       0.41      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  14   2  32  40  33  10]\n",
      " [ 17  59  56  20  24  23  11]\n",
      " [  2  20 147  14  20   5   2]\n",
      " [ 38  23  13  58  37  24  17]\n",
      " [ 31  27  10  35  73  21  13]\n",
      " [ 27  18   4  22  40  61  38]\n",
      " [ 27  11   3  14  37  49  69]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.38      0.37       210\n",
      "           2       0.34      0.28      0.31       210\n",
      "           3       0.63      0.70      0.66       210\n",
      "           4       0.30      0.28      0.29       210\n",
      "           5       0.27      0.35      0.30       210\n",
      "           6       0.28      0.29      0.29       210\n",
      "           7       0.43      0.33      0.37       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.37      0.37      0.37      1470\n",
      "weighted avg       0.37      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3761904761904762\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  16   2  34  34  33  15]\n",
      " [ 15  58  40  34  24  25  14]\n",
      " [  3  22 148  27   5   2   3]\n",
      " [ 23  21  13  52  43  34  24]\n",
      " [ 37  27   4  27  72  27  16]\n",
      " [ 20  38   7  22  16  63  44]\n",
      " [ 13  22   3  24  13  51  84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.36      0.38       210\n",
      "           2       0.28      0.28      0.28       210\n",
      "           3       0.68      0.70      0.69       210\n",
      "           4       0.24      0.25      0.24       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.27      0.30      0.28       210\n",
      "           7       0.42      0.40      0.41       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.38      0.38      0.38      1470\n",
      "weighted avg       0.38      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37482993197278913\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  10   2  31  33  39  15]\n",
      " [ 18  58  39  32  33  19  11]\n",
      " [  1  20 145  16  21   5   2]\n",
      " [ 28  16  12  62  34  35  23]\n",
      " [ 43  24   2  42  69  20  10]\n",
      " [ 27  12   6  21  46  58  40]\n",
      " [ 22   7   6  17  30  49  79]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.38      0.37       210\n",
      "           2       0.39      0.28      0.32       210\n",
      "           3       0.68      0.69      0.69       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.26      0.33      0.29       210\n",
      "           6       0.26      0.28      0.27       210\n",
      "           7       0.44      0.38      0.41       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.38      1470\n",
      "weighted avg       0.38      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  19   3  24  38  30  15]\n",
      " [ 20  63  41  39  19  15  13]\n",
      " [  3  20 149  11  21   1   5]\n",
      " [ 23  26  14  63  28  29  27]\n",
      " [ 40  33   3  41  59  20  14]\n",
      " [ 26  19   7  18  45  49  46]\n",
      " [ 17  10   5  17  36  41  84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.39      0.39       210\n",
      "           2       0.33      0.30      0.32       210\n",
      "           3       0.67      0.71      0.69       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.24      0.28      0.26       210\n",
      "           6       0.26      0.23      0.25       210\n",
      "           7       0.41      0.40      0.41       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.37      0.37      0.37      1470\n",
      "weighted avg       0.37      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36394557823129253\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  16   1  26  32  31  21]\n",
      " [ 20  57  42  38  23  16  14]\n",
      " [  6  20 148  14  12   0  10]\n",
      " [ 24  24  14  60  34  32  22]\n",
      " [ 39  35   3  41  58  22  12]\n",
      " [ 21  40   4  18  19  53  55]\n",
      " [ 21  20   5  18  27  43  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.39       210\n",
      "           2       0.27      0.27      0.27       210\n",
      "           3       0.68      0.70      0.69       210\n",
      "           4       0.28      0.29      0.28       210\n",
      "           5       0.28      0.28      0.28       210\n",
      "           6       0.27      0.25      0.26       210\n",
      "           7       0.36      0.36      0.36       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37482993197278913\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  19   2  21  36  30  16]\n",
      " [ 17  61  42  43  18  14  15]\n",
      " [  4  22 148  11  20   2   3]\n",
      " [ 29  18  15  63  30  32  23]\n",
      " [ 43  33   3  33  60  21  17]\n",
      " [ 22  16   5  25  46  57  39]\n",
      " [ 20  10   6  17  38  43  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.41      0.40       210\n",
      "           2       0.34      0.29      0.31       210\n",
      "           3       0.67      0.70      0.69       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.24      0.29      0.26       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.40      0.36      0.38       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  21   4  28  30  30  19]\n",
      " [ 21  58  43  35  18  21  14]\n",
      " [  5  21 149  13  19   0   3]\n",
      " [ 25  23  15  60  31  31  25]\n",
      " [ 43  40   7  42  45  19  14]\n",
      " [ 21  18   4  27  30  53  57]\n",
      " [ 20  14   4  16  28  47  81]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.37      0.37       210\n",
      "           2       0.30      0.28      0.29       210\n",
      "           3       0.66      0.71      0.68       210\n",
      "           4       0.27      0.29      0.28       210\n",
      "           5       0.22      0.21      0.22       210\n",
      "           6       0.26      0.25      0.26       210\n",
      "           7       0.38      0.39      0.38       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.35      0.36      0.35      1470\n",
      "weighted avg       0.35      0.36      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35578231292517004\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  19   3  27  27  29  19]\n",
      " [ 20  58  47  34  19  19  13]\n",
      " [  1  20 146  17  13   2  11]\n",
      " [ 27  19  13  61  30  37  23]\n",
      " [ 49  37   3  42  46  19  14]\n",
      " [ 24  36  11  17  23  49  50]\n",
      " [ 26  22   6  18  21  40  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.41      0.39       210\n",
      "           2       0.27      0.28      0.28       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.28      0.29      0.29       210\n",
      "           5       0.26      0.22      0.24       210\n",
      "           6       0.25      0.23      0.24       210\n",
      "           7       0.37      0.37      0.37       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.35      0.36      0.35      1470\n",
      "weighted avg       0.35      0.36      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3687074829931973\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91  17   4  20  31  27  20]\n",
      " [ 17  57  44  33  23  19  17]\n",
      " [  3  21 151  11  22   1   1]\n",
      " [ 23  22  14  58  27  37  29]\n",
      " [ 46  31   4  40  49  23  17]\n",
      " [ 22  21   7  22  42  56  40]\n",
      " [ 19   6   9  18  32  46  80]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.43      0.42       210\n",
      "           2       0.33      0.27      0.30       210\n",
      "           3       0.65      0.72      0.68       210\n",
      "           4       0.29      0.28      0.28       210\n",
      "           5       0.22      0.23      0.22       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.39      0.38      0.39       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.36      0.37      0.37      1470\n",
      "weighted avg       0.36      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  20   2  26  32  32  20]\n",
      " [ 19  56  40  39  22  21  13]\n",
      " [  4  19 145  18  19   2   3]\n",
      " [ 27  20  15  63  28  33  24]\n",
      " [ 41  34   4  47  44  24  16]\n",
      " [ 21  23   5  21  43  57  40]\n",
      " [ 21  15   3  15  30  47  79]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.37      0.37       210\n",
      "           2       0.30      0.27      0.28       210\n",
      "           3       0.68      0.69      0.68       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.20      0.21      0.21       210\n",
      "           6       0.26      0.27      0.27       210\n",
      "           7       0.41      0.38      0.39       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  4   3  41   0  83   0  79]\n",
      " [  1   1 110   1  41   0  56]\n",
      " [  1   0 169   2  11   0  27]\n",
      " [  2   1  80   1  81   0  45]\n",
      " [  3   1  86   0  84   0  36]\n",
      " [  3   0  24   0  35   0 148]\n",
      " [  7   0   5   0  17   0 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.02      0.03       210\n",
      "           2       0.17      0.00      0.01       210\n",
      "           3       0.33      0.80      0.47       210\n",
      "           4       0.25      0.00      0.01       210\n",
      "           5       0.24      0.40      0.30       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.86      0.46       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.21      0.30      0.18      1470\n",
      "weighted avg       0.21      0.30      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.34829931972789113\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 45   7  16   3  98   0  41]\n",
      " [  4   5  79   4  63   0  55]\n",
      " [  4  12 152   1  14   0  27]\n",
      " [  8  14  32   8 108   0  40]\n",
      " [  8  12  26   4 128   0  32]\n",
      " [ 18   5  11   1  41   0 134]\n",
      " [ 14   2   2   0  18   0 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.21      0.29       210\n",
      "           2       0.09      0.02      0.04       210\n",
      "           3       0.48      0.72      0.58       210\n",
      "           4       0.38      0.04      0.07       210\n",
      "           5       0.27      0.61      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.83      0.49       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.29      0.35      0.26      1470\n",
      "weighted avg       0.29      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.3952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  16   2  11  42  13  23]\n",
      " [ 39  59  39   5  16  24  28]\n",
      " [ 23  27 137   4   3   3  13]\n",
      " [ 46  40  11  16  60   2  35]\n",
      " [ 34  49   6   4  85   6  26]\n",
      " [ 51  11   3   3  15  17 110]\n",
      " [ 31   4   0   0   4   7 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.49      0.38       210\n",
      "           2       0.29      0.28      0.28       210\n",
      "           3       0.69      0.65      0.67       210\n",
      "           4       0.37      0.08      0.13       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.24      0.08      0.12       210\n",
      "           7       0.41      0.78      0.54       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.38      0.40      0.36      1470\n",
      "weighted avg       0.38      0.40      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.42993197278911566\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102  13   0  10  47  22  16]\n",
      " [ 34  67  26  10  21  34  18]\n",
      " [ 13  29 143   4   5   4  12]\n",
      " [ 41  27   9  35  61   7  30]\n",
      " [ 33  31   3   9 102   8  24]\n",
      " [ 50   9   2  10  14  30  95]\n",
      " [ 31   3   0   1   4  18 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.49      0.40       210\n",
      "           2       0.37      0.32      0.34       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.44      0.17      0.24       210\n",
      "           5       0.40      0.49      0.44       210\n",
      "           6       0.24      0.14      0.18       210\n",
      "           7       0.44      0.73      0.55       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.41      1470\n",
      "weighted avg       0.43      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102  14   2  18  38  22  14]\n",
      " [ 36  76  21  14  19  29  15]\n",
      " [ 13  18 155   8   1   3  12]\n",
      " [ 37  25  13  45  53  11  26]\n",
      " [ 28  32   2  16 100  11  21]\n",
      " [ 43   5   2  18  12  41  89]\n",
      " [ 29   3   0   2   4  28 144]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.49      0.41       210\n",
      "           2       0.44      0.36      0.40       210\n",
      "           3       0.79      0.74      0.77       210\n",
      "           4       0.37      0.21      0.27       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.28      0.20      0.23       210\n",
      "           7       0.45      0.69      0.54       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   8   1  24  37  25  14]\n",
      " [ 32  69  29  22  21  22  15]\n",
      " [ 10   8 164   8   4   5  11]\n",
      " [ 36  18  11  60  47  16  22]\n",
      " [ 29  21   9  21  97   9  24]\n",
      " [ 44   2   2  20  12  52  78]\n",
      " [ 25   2   0   7   2  35 139]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.48      0.41       210\n",
      "           2       0.54      0.33      0.41       210\n",
      "           3       0.76      0.78      0.77       210\n",
      "           4       0.37      0.29      0.32       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.32      0.25      0.28       210\n",
      "           7       0.46      0.66      0.54       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.48775510204081635\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   9   0  21  38  22  15]\n",
      " [ 34  90  20  14  20  17  15]\n",
      " [  9  13 162   7   3   4  12]\n",
      " [ 31  19  10  68  43  16  23]\n",
      " [ 29  21   3  24 102   6  25]\n",
      " [ 40   4   1  22  11  51  81]\n",
      " [ 22   2   0   7   3  37 139]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.50      0.44       210\n",
      "           2       0.57      0.43      0.49       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.42      0.32      0.36       210\n",
      "           5       0.46      0.49      0.47       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.45      0.66      0.53       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.48      1470\n",
      "weighted avg       0.49      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   8   0  29  34  22  14]\n",
      " [ 33  82  25  24  17  14  15]\n",
      " [  9  10 166  13   5   6   1]\n",
      " [ 29  20  10  71  43  12  25]\n",
      " [ 28  22   3  30  96   8  23]\n",
      " [ 35   1   3  27   9  72  63]\n",
      " [ 20   1   0  10   3  46 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.49      0.44       210\n",
      "           2       0.57      0.39      0.46       210\n",
      "           3       0.80      0.79      0.80       210\n",
      "           4       0.35      0.34      0.34       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.48      0.62      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   5   1  29  35  17  16]\n",
      " [ 28  90  21  23  20  16  12]\n",
      " [  7   8 164  13   2   5  11]\n",
      " [ 28  14   8  83  38  10  29]\n",
      " [ 26  27   3  28  94   6  26]\n",
      " [ 33   1   2  28   8  68  70]\n",
      " [ 18   1   0  10   3  42 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.51      0.47       210\n",
      "           2       0.62      0.43      0.51       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.39      0.40      0.39       210\n",
      "           5       0.47      0.45      0.46       210\n",
      "           6       0.41      0.32      0.36       210\n",
      "           7       0.45      0.65      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   8   2  24  30  21  15]\n",
      " [ 27  94  26  18  22  13  10]\n",
      " [  3   9 167   9   3   6  13]\n",
      " [ 27  18  10  78  40  10  27]\n",
      " [ 29  27   4  19 100   6  25]\n",
      " [ 34   4   1  27   8  64  72]\n",
      " [ 20   1   0  12   3  42 132]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.52      0.48       210\n",
      "           2       0.58      0.45      0.51       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.42      0.37      0.39       210\n",
      "           5       0.49      0.48      0.48       210\n",
      "           6       0.40      0.30      0.34       210\n",
      "           7       0.45      0.63      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.508843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   7   1  23  36  22  12]\n",
      " [ 21  88  27  29  18  16  11]\n",
      " [  3   9 176  12   3   6   1]\n",
      " [ 24  15  11  79  40  18  23]\n",
      " [ 24  26   4  30  94   8  24]\n",
      " [ 30   4   1  25  12  81  57]\n",
      " [ 16   2   0  10   4  57 121]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.52      0.50       210\n",
      "           2       0.58      0.42      0.49       210\n",
      "           3       0.80      0.84      0.82       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.45      0.45      0.45       210\n",
      "           6       0.39      0.39      0.39       210\n",
      "           7       0.49      0.58      0.53       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113   4   3  25  36  15  14]\n",
      " [ 22  78  32  27  22  20   9]\n",
      " [  3  10 180   8   2   7   0]\n",
      " [ 20  12   9  92  40  11  26]\n",
      " [ 22  20   5  28 104   7  24]\n",
      " [ 27   7   1  21  12  87  55]\n",
      " [ 19   0   1   7   6  46 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52       210\n",
      "           2       0.60      0.37      0.46       210\n",
      "           3       0.78      0.86      0.82       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.47      0.50      0.48       210\n",
      "           6       0.45      0.41      0.43       210\n",
      "           7       0.51      0.62      0.56       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112   7   0  27  34  19  11]\n",
      " [ 24  85  29  19  24  18  11]\n",
      " [  4   8 180   8   3   6   1]\n",
      " [ 16   8  12  87  46  15  26]\n",
      " [ 24  21   4  27 102   8  24]\n",
      " [ 26   5   2  30  12  67  68]\n",
      " [ 14   0   0  13   3  54 126]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.53      0.52       210\n",
      "           2       0.63      0.40      0.49       210\n",
      "           3       0.79      0.86      0.82       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.46      0.49      0.47       210\n",
      "           6       0.36      0.32      0.34       210\n",
      "           7       0.47      0.60      0.53       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.51      1470\n",
      "weighted avg       0.52      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108   5   1  26  40  18  12]\n",
      " [ 22  87  28  26  21  15  11]\n",
      " [  3   5 174   8   3   7  10]\n",
      " [ 20  15  11  76  48  17  23]\n",
      " [ 26  19   4  25 107   6  23]\n",
      " [ 27   1   3  27  12  76  64]\n",
      " [ 10   1   0   9   4  53 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.51       210\n",
      "           2       0.65      0.41      0.51       210\n",
      "           3       0.79      0.83      0.81       210\n",
      "           4       0.39      0.36      0.37       210\n",
      "           5       0.46      0.51      0.48       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.48      0.63      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.51      1470\n",
      "weighted avg       0.52      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   6   1  32  35  18  12]\n",
      " [ 17  90  27  24  23  17  12]\n",
      " [  3  13 175   7   5   6   1]\n",
      " [ 21  14  12  86  37  11  29]\n",
      " [ 21  15   3  39 101   5  26]\n",
      " [ 22   0   2  30  12  67  77]\n",
      " [ 11   1   0  10   5  42 141]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.50      0.52       210\n",
      "           2       0.65      0.43      0.52       210\n",
      "           3       0.80      0.83      0.81       210\n",
      "           4       0.38      0.41      0.39       210\n",
      "           5       0.46      0.48      0.47       210\n",
      "           6       0.40      0.32      0.36       210\n",
      "           7       0.47      0.67      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   8   2  21  46  20  13]\n",
      " [ 12  90  27  30  22  18  11]\n",
      " [  2  10 180   8   2   5   3]\n",
      " [ 17  13  10  90  40  14  26]\n",
      " [ 20  23   2  34 103   3  25]\n",
      " [ 21   3   3  23  14  70  76]\n",
      " [ 16   0   2   7   5  36 144]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.48      0.50       210\n",
      "           2       0.61      0.43      0.50       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.42      0.43      0.43       210\n",
      "           5       0.44      0.49      0.47       210\n",
      "           6       0.42      0.33      0.37       210\n",
      "           7       0.48      0.69      0.57       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   7   0  34  30  19  13]\n",
      " [ 14  88  28  27  26  17  10]\n",
      " [  3  10 169  10   2   6  10]\n",
      " [ 15  22   9  88  38  14  24]\n",
      " [ 22  33   5  27  92  10  21]\n",
      " [ 22   4   4  31  12  70  67]\n",
      " [ 17   2   0   8   4  46 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.52       210\n",
      "           2       0.53      0.42      0.47       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.39      0.42      0.40       210\n",
      "           5       0.45      0.44      0.44       210\n",
      "           6       0.38      0.33      0.36       210\n",
      "           7       0.48      0.63      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.507482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   6   1  25  43  19  13]\n",
      " [ 20  88  29  20  25  17  11]\n",
      " [  4  10 177  10   4   5   0]\n",
      " [ 16  16  12  86  41  15  24]\n",
      " [ 30  27   4  31  89   9  20]\n",
      " [ 21   3   2  29  12  74  69]\n",
      " [ 15   1   1   7   7  50 129]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.49      0.49       210\n",
      "           2       0.58      0.42      0.49       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.39      0.35      0.37       210\n",
      "           7       0.48      0.61      0.54       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   3   2  31  38  21  10]\n",
      " [ 16 100  23  29  14  18  10]\n",
      " [  3  11 177  10   2   5   2]\n",
      " [ 18  16  11  92  34  14  25]\n",
      " [ 22  35   4  25  95   6  23]\n",
      " [ 21   3   2  30  14  73  67]\n",
      " [ 13   4   0   6   5  54 128]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.50      0.51       210\n",
      "           2       0.58      0.48      0.52       210\n",
      "           3       0.81      0.84      0.83       210\n",
      "           4       0.41      0.44      0.42       210\n",
      "           5       0.47      0.45      0.46       210\n",
      "           6       0.38      0.35      0.36       210\n",
      "           7       0.48      0.61      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5231292517006803\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   3   2  34  37  20  15]\n",
      " [ 17  92  27  21  27  14  12]\n",
      " [  2  11 176   8   6   6   1]\n",
      " [ 18  13   9  94  37  14  25]\n",
      " [ 24  22   5  30  98   7  24]\n",
      " [ 24   4   4  27  11  74  66]\n",
      " [ 13   1   0   9   2  49 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.47      0.49       210\n",
      "           2       0.63      0.44      0.52       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.42      0.45      0.43       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.40      0.35      0.38       210\n",
      "           7       0.49      0.65      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 31   0  88   3  15  21  52]\n",
      " [ 11   0 131   4   8   2  54]\n",
      " [  4   0 177   0   2  23   4]\n",
      " [  6   0 147   6   7  12  32]\n",
      " [  6   0 154   7   8   6  29]\n",
      " [ 16   0  45   5   2  44  98]\n",
      " [  9   0  10   9   2  38 142]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.15      0.21       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.24      0.84      0.37       210\n",
      "           4       0.18      0.03      0.05       210\n",
      "           5       0.18      0.04      0.06       210\n",
      "           6       0.30      0.21      0.25       210\n",
      "           7       0.35      0.68      0.46       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.23      0.28      0.20      1470\n",
      "weighted avg       0.23      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_gkb.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7510204081632653\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[173   6   1   4  20   5   1]\n",
      " [  3 159  10  11  15  12   0]\n",
      " [  0   4 190   9   2   5   0]\n",
      " [ 11   8   6 156  11  16   2]\n",
      " [ 29   9   5  11 148   5   3]\n",
      " [ 10  13   6  14   4 119  44]\n",
      " [  3   0   1   2   4  41 159]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.82      0.79       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.87      0.90      0.89       210\n",
      "           4       0.75      0.74      0.75       210\n",
      "           5       0.73      0.70      0.71       210\n",
      "           6       0.59      0.57      0.58       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   3   2   7  50   5   3]\n",
      " [ 11 152  12  10  19   4   2]\n",
      " [  6   5 185   9   5   0   0]\n",
      " [ 31  10  16 100  41   6   6]\n",
      " [ 42  18   6  10 125   1   8]\n",
      " [ 38  12   4  12  10  71  63]\n",
      " [  7   4   0   3   6  12 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.67      0.58       210\n",
      "           2       0.75      0.72      0.73       210\n",
      "           3       0.82      0.88      0.85       210\n",
      "           4       0.66      0.48      0.55       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.72      0.34      0.46       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   2   3   6  51   5   4]\n",
      " [  8 156  13   7  19   6   1]\n",
      " [  9   4 184   7   6   0   0]\n",
      " [ 24  12  19 106  35   8   6]\n",
      " [ 36  13   9  11 131   2   8]\n",
      " [ 35   6   3  17  10  76  63]\n",
      " [  4   2   0   1   4  23 176]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.66      0.60       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.80      0.88      0.83       210\n",
      "           4       0.68      0.50      0.58       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.63      0.36      0.46       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138   2   6  10  45   4   5]\n",
      " [  7 149  12   9  24   4   5]\n",
      " [  9   4 185   6   6   0   0]\n",
      " [ 24  12  17 105  38   7   7]\n",
      " [ 29  11   9   9 142   2   8]\n",
      " [ 31   6   3  15  12  72  71]\n",
      " [  3   2   0   1   8  14 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.66      0.61       210\n",
      "           2       0.80      0.71      0.75       210\n",
      "           3       0.80      0.88      0.84       210\n",
      "           4       0.68      0.50      0.58       210\n",
      "           5       0.52      0.68      0.59       210\n",
      "           6       0.70      0.34      0.46       210\n",
      "           7       0.65      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   0   3   8  49   5   5]\n",
      " [  5 153  12   7  24   3   6]\n",
      " [  9   4 185   6   5   1   0]\n",
      " [ 24  11  19 103  39   8   6]\n",
      " [ 24  13   5   8 148   2  10]\n",
      " [ 28   5   2  13  14  76  72]\n",
      " [  3   1   0   1   5  17 183]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.67      0.63       210\n",
      "           2       0.82      0.73      0.77       210\n",
      "           3       0.82      0.88      0.85       210\n",
      "           4       0.71      0.49      0.58       210\n",
      "           5       0.52      0.70      0.60       210\n",
      "           6       0.68      0.36      0.47       210\n",
      "           7       0.65      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.66      1470\n",
      "weighted avg       0.68      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   0   2  10  50   6   5]\n",
      " [  4 151  13   9  22   4   7]\n",
      " [ 10   3 183   7   6   1   0]\n",
      " [ 23  10  20  96  48   7   6]\n",
      " [ 26  11   6   4 150   2  11]\n",
      " [ 26   7   1  14  16  68  78]\n",
      " [  3   0   0   1   5  11 190]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.65      0.62       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.81      0.87      0.84       210\n",
      "           4       0.68      0.46      0.55       210\n",
      "           5       0.51      0.71      0.59       210\n",
      "           6       0.69      0.32      0.44       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.65      1470\n",
      "weighted avg       0.68      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   0   3   9  48   6   5]\n",
      " [  6 151  11   8  21   5   8]\n",
      " [  7   4 183   9   6   0   1]\n",
      " [ 23  11  20  98  45   6   7]\n",
      " [ 28  11   8   5 145   4   9]\n",
      " [ 28   7   1  14  13  68  79]\n",
      " [  3   0   0   1   5  13 188]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.66      0.63       210\n",
      "           2       0.82      0.72      0.77       210\n",
      "           3       0.81      0.87      0.84       210\n",
      "           4       0.68      0.47      0.55       210\n",
      "           5       0.51      0.69      0.59       210\n",
      "           6       0.67      0.32      0.44       210\n",
      "           7       0.63      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[103   6  12   8  47  28   6]\n",
      " [  3 103  23  10  37  24  10]\n",
      " [ 16  13 156   5   6  14   0]\n",
      " [ 15   7  32  62  53  34   7]\n",
      " [ 19  12  19  15 113  26   6]\n",
      " [ 12   9   1  15   3  84  86]\n",
      " [  0   0   0   0   1  30 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.49      0.54       210\n",
      "           2       0.69      0.49      0.57       210\n",
      "           3       0.64      0.74      0.69       210\n",
      "           4       0.54      0.30      0.38       210\n",
      "           5       0.43      0.54      0.48       210\n",
      "           6       0.35      0.40      0.37       210\n",
      "           7       0.61      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 93   8  22   4  41  35   7]\n",
      " [  5  91  29   8  28  38  11]\n",
      " [  9  19 159   6   4  13   0]\n",
      " [ 19  10  38  56  41  37   9]\n",
      " [ 13  16  35  15  93  29   9]\n",
      " [ 12  11   1  15   2  75  94]\n",
      " [  0   1   0   0   0  23 186]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.44      0.52       210\n",
      "           2       0.58      0.43      0.50       210\n",
      "           3       0.56      0.76      0.64       210\n",
      "           4       0.54      0.27      0.36       210\n",
      "           5       0.44      0.44      0.44       210\n",
      "           6       0.30      0.36      0.33       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7408163265306122\n",
      "Confusion Matrix of SVM is:\n",
      " [[172   4   1   4  22   5   2]\n",
      " [  3 172   7   7  16   4   1]\n",
      " [  0   7 188   8   2   5   0]\n",
      " [ 16  16   5 146   8  15   4]\n",
      " [ 41  12   6  14 131   5   1]\n",
      " [ 14  20   3  12   2 119  40]\n",
      " [  4   2   0   2   5  36 161]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.82      0.75       210\n",
      "           2       0.74      0.82      0.78       210\n",
      "           3       0.90      0.90      0.90       210\n",
      "           4       0.76      0.70      0.72       210\n",
      "           5       0.70      0.62      0.66       210\n",
      "           6       0.63      0.57      0.60       210\n",
      "           7       0.77      0.77      0.77       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[144   1   1   8  45  10   1]\n",
      " [  0 138   6  18  40   7   1]\n",
      " [  3   4 179   8  13   3   0]\n",
      " [  4   3   4 148  36  11   4]\n",
      " [ 11   4   4  10 174   4   3]\n",
      " [ 15   7   0  22  15 115  36]\n",
      " [  3   0   0   0   6  26 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.88      0.66      0.75       210\n",
      "           3       0.92      0.85      0.89       210\n",
      "           4       0.69      0.70      0.70       210\n",
      "           5       0.53      0.83      0.65       210\n",
      "           6       0.65      0.55      0.60       210\n",
      "           7       0.80      0.83      0.81       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.75      0.73      0.73      1470\n",
      "weighted avg       0.75      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7727891156462585\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   3   1   5  26  13   0]\n",
      " [  0 157   9  16  11  15   2]\n",
      " [  1   3 188   7   3   8   0]\n",
      " [  4   3   8 154  22  15   4]\n",
      " [ 19   8   3  11 153  11   5]\n",
      " [  8   1   2  15   3 133  48]\n",
      " [  2   0   0   0   3  16 189]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.77      0.80       210\n",
      "           2       0.90      0.75      0.82       210\n",
      "           3       0.89      0.90      0.89       210\n",
      "           4       0.74      0.73      0.74       210\n",
      "           5       0.69      0.73      0.71       210\n",
      "           6       0.63      0.63      0.63       210\n",
      "           7       0.76      0.90      0.83       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.78      0.77      0.77      1470\n",
      "weighted avg       0.78      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of SVM is:\n",
      " [[145   1   3   8  32  16   5]\n",
      " [  3 153  13   7  12  15   7]\n",
      " [  3   3 177  14   4   9   0]\n",
      " [  9   8  15 128  26  20   4]\n",
      " [ 31   9   9  11 127  13  10]\n",
      " [ 23  11  11  17   5  74  69]\n",
      " [  6   3   1   1   6  30 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.67       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.77      0.84      0.81       210\n",
      "           4       0.69      0.61      0.65       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.63      0.78      0.70       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 189   0  21]\n",
      " [  0   0   0   0 177   0  33]\n",
      " [  0   0   0   0 203   0   7]\n",
      " [  0   0   0   0 190   0  20]\n",
      " [  0   0   0   0 201   0   9]\n",
      " [  0   0   0   0  63   0 147]\n",
      " [  0   0   0   0  23   0 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.19      0.96      0.32       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.44      0.89      0.59       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.09      0.26      0.13      1470\n",
      "weighted avg       0.09      0.26      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.373469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0 176  15   6]\n",
      " [  0   0   7   0 170  20  13]\n",
      " [  0   0 130   0  73   7   0]\n",
      " [  0   0   7   0 183  11   9]\n",
      " [  0   0  12   0 189   6   3]\n",
      " [  0   0   4   0  59  69  78]\n",
      " [  0   0   0   0  23  26 161]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.75      0.62      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.90      0.35       210\n",
      "           6       0.45      0.33      0.38       210\n",
      "           7       0.60      0.77      0.67       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.29      0.37      0.30      1470\n",
      "weighted avg       0.29      0.37      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0  13   0  52  15   6]\n",
      " [ 20   9   7   0 150  11  13]\n",
      " [  9   0 130   0  64   7   0]\n",
      " [ 21   1   7   0 162  10   9]\n",
      " [ 38   0  12   0 151   6   3]\n",
      " [ 22   2   4   0  37  67  78]\n",
      " [ 20   2   0   0   3  24 161]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.53       210\n",
      "           2       0.64      0.04      0.08       210\n",
      "           3       0.75      0.62      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.24      0.72      0.36       210\n",
      "           6       0.48      0.32      0.38       210\n",
      "           7       0.60      0.77      0.67       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.39      1470\n",
      "weighted avg       0.46      0.44      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   1  12   0  52  16   5]\n",
      " [ 20  94   5   1  66  11  13]\n",
      " [  9  14 126   0  54   7   0]\n",
      " [ 21  14   4   1 151  10   9]\n",
      " [ 38  11   8   1 143   6   3]\n",
      " [ 22  10   3   1  29  72  73]\n",
      " [ 20   3   1   0   1  31 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.53       210\n",
      "           2       0.64      0.45      0.53       210\n",
      "           3       0.79      0.60      0.68       210\n",
      "           4       0.25      0.00      0.01       210\n",
      "           5       0.29      0.68      0.41       210\n",
      "           6       0.47      0.34      0.40       210\n",
      "           7       0.60      0.73      0.66       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.46      1470\n",
      "weighted avg       0.50      0.49      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120  10   8   0  52  16   4]\n",
      " [  7 109   6   1  65  15   7]\n",
      " [  8  19 148   0  28   7   0]\n",
      " [ 15  20   9   1 146  14   5]\n",
      " [ 34  17   6   1 142   8   2]\n",
      " [ 11  20   2   1  29  93  54]\n",
      " [  0  24   0   0   1  44 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.57      0.59       210\n",
      "           2       0.50      0.52      0.51       210\n",
      "           3       0.83      0.70      0.76       210\n",
      "           4       0.25      0.00      0.01       210\n",
      "           5       0.31      0.68      0.42       210\n",
      "           6       0.47      0.44      0.46       210\n",
      "           7       0.66      0.67      0.67       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.49      1470\n",
      "weighted avg       0.52      0.51      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   5   8  28  44  13  13]\n",
      " [  2 101   6  19  60  15   7]\n",
      " [  7   8 154  10  22   7   2]\n",
      " [ 12  14   3  73  82  14  12]\n",
      " [ 30  12   5  29 120   9   5]\n",
      " [  5  16   2  22  14  78  73]\n",
      " [  0   6   0   1   0  55 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.47      0.54       210\n",
      "           2       0.62      0.48      0.54       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.40      0.35      0.37       210\n",
      "           5       0.35      0.57      0.43       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.57      0.70      0.63       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.53      1470\n",
      "weighted avg       0.55      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   5   2  28  39  19   8]\n",
      " [  3  91   3  29  63  15   6]\n",
      " [  7   8 155  12  21   7   0]\n",
      " [ 11   6   4  86  79  16   8]\n",
      " [ 24  10   3  38 121  12   2]\n",
      " [ 10  12   2  24  13  82  67]\n",
      " [  1   5   0   3   0  51 150]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.52      0.58       210\n",
      "           2       0.66      0.43      0.52       210\n",
      "           3       0.92      0.74      0.82       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.36      0.58      0.44       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.62      0.71      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.55      1470\n",
      "weighted avg       0.57      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   5   0  33  46  14   7]\n",
      " [  4  96   4  14  49  38   5]\n",
      " [  5   6 156  11  25   7   0]\n",
      " [  8  14   4  81  74  24   5]\n",
      " [ 20   8   3  33 135  10   1]\n",
      " [  7  13   4  29  12  90  55]\n",
      " [  3   4   1   3   0  68 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.50      0.58       210\n",
      "           2       0.66      0.46      0.54       210\n",
      "           3       0.91      0.74      0.82       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.40      0.64      0.49       210\n",
      "           6       0.36      0.43      0.39       210\n",
      "           7       0.64      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.58      0.54      0.55      1470\n",
      "weighted avg       0.58      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   6   4  25  47  13   7]\n",
      " [  3 100   4  15  55  27   6]\n",
      " [  3   6 160  15  21   5   0]\n",
      " [  7  15   7  83  76  17   5]\n",
      " [ 26  12   5  28 128  10   1]\n",
      " [ 12  14   3  28  13  87  53]\n",
      " [  2   5   1   6   2  64 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.51      0.58       210\n",
      "           2       0.63      0.48      0.54       210\n",
      "           3       0.87      0.76      0.81       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.37      0.61      0.46       210\n",
      "           6       0.39      0.41      0.40       210\n",
      "           7       0.64      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.55      1470\n",
      "weighted avg       0.57      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   7   6  31  41  11   6]\n",
      " [  4 111   6  19  45  17   8]\n",
      " [  7   5 165  12  14   6   1]\n",
      " [ 16  14   6 108  44  18   4]\n",
      " [ 29  10   5  60  97   8   1]\n",
      " [ 11  14   5  31  14  86  49]\n",
      " [  5   6   1   6  19  43 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.51      0.55       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.85      0.79      0.82       210\n",
      "           4       0.40      0.51      0.45       210\n",
      "           5       0.35      0.46      0.40       210\n",
      "           6       0.46      0.41      0.43       210\n",
      "           7       0.65      0.62      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.55      1470\n",
      "weighted avg       0.57      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   5   2  25  37  12   9]\n",
      " [  9 112   5  13  47  17   7]\n",
      " [ 10   4 164  10  16   6   0]\n",
      " [ 27  14   6  81  57  16   9]\n",
      " [ 32  10   2  36 120   5   5]\n",
      " [ 14  18   3  21  18  83  53]\n",
      " [  6  12   1   1   9  47 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.57      0.56       210\n",
      "           2       0.64      0.53      0.58       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.43      0.39      0.41       210\n",
      "           5       0.39      0.57      0.47       210\n",
      "           6       0.45      0.40      0.42       210\n",
      "           7       0.62      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.56      1470\n",
      "weighted avg       0.57      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   9   4  28  36  14  10]\n",
      " [  9 108   5  20  49  14   5]\n",
      " [  4   6 167  11  17   5   0]\n",
      " [ 26  16   9  88  50  14   7]\n",
      " [ 29  11   6  43 110   6   5]\n",
      " [ 13  19   7  19  16  81  55]\n",
      " [  3  10   3   8  11  47 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54       210\n",
      "           2       0.60      0.51      0.56       210\n",
      "           3       0.83      0.80      0.81       210\n",
      "           4       0.41      0.42      0.41       210\n",
      "           5       0.38      0.52      0.44       210\n",
      "           6       0.45      0.39      0.41       210\n",
      "           7       0.61      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  14   6  22  29  13   5]\n",
      " [  5 117   6  18  39  19   6]\n",
      " [  6  12 165  12   9   6   0]\n",
      " [ 23  25   8  96  38  13   7]\n",
      " [ 36  29   6  36  95   5   3]\n",
      " [ 15  22   5  21  10  87  50]\n",
      " [  4  11   1  10   5  44 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58       210\n",
      "           2       0.51      0.56      0.53       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.45      0.46      0.45       210\n",
      "           5       0.42      0.45      0.44       210\n",
      "           6       0.47      0.41      0.44       210\n",
      "           7       0.66      0.64      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   9   5  27  36   9   9]\n",
      " [  7 107   7  23  40  20   6]\n",
      " [  5   6 164  15  12   7   1]\n",
      " [ 23  15   8 109  33  15   7]\n",
      " [ 36  19   6  50  87   7   5]\n",
      " [ 10  16   6  29  11  85  53]\n",
      " [  4  10   2   9   6  49 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.55      0.56       210\n",
      "           2       0.59      0.51      0.55       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.42      0.52      0.46       210\n",
      "           5       0.39      0.41      0.40       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.62      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   7  22  33  15   8]\n",
      " [ 10 105   6  19  40  25   5]\n",
      " [  9   8 168  12   8   4   1]\n",
      " [ 27  22  10  90  32  21   8]\n",
      " [ 38  16   5  43  97   8   3]\n",
      " [ 10  17   8  25  14  87  49]\n",
      " [  3  12   0   9   8  56 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.57      0.56       210\n",
      "           2       0.56      0.50      0.53       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.40      0.41      0.41       210\n",
      "           7       0.62      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  11   8  17  33  11   9]\n",
      " [ 10 112  10  16  34  21   7]\n",
      " [  6   5 170  11  10   8   0]\n",
      " [ 27  18  11  94  27  22  11]\n",
      " [ 31  21   8  42  86  13   9]\n",
      " [ 17  19   3  18  18  85  50]\n",
      " [  7   9   4  12   7  45 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.58      0.56       210\n",
      "           2       0.57      0.53      0.55       210\n",
      "           3       0.79      0.81      0.80       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.40      0.41      0.40       210\n",
      "           6       0.41      0.40      0.41       210\n",
      "           7       0.59      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   5   8  23  33  15   9]\n",
      " [  8 117   4  20  37  19   5]\n",
      " [  7  10 168  11   7   6   1]\n",
      " [ 21  26  11  93  28  23   8]\n",
      " [ 33  28   8  41  81  10   9]\n",
      " [ 14  20   5  24  13  81  53]\n",
      " [  4   9   0   5   8  47 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.56      0.57       210\n",
      "           2       0.54      0.56      0.55       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.43      0.44      0.44       210\n",
      "           5       0.39      0.39      0.39       210\n",
      "           6       0.40      0.39      0.39       210\n",
      "           7       0.62      0.65      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.545578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   8   9  20  32  16   8]\n",
      " [ 11 116   5  19  30  17  12]\n",
      " [  6   7 167  13   9   7   1]\n",
      " [ 25  23  13  92  29  20   8]\n",
      " [ 32  19  11  41  93   7   7]\n",
      " [ 10  22   5  20  15  88  50]\n",
      " [  4   9   3   8   6  51 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.56      0.56       210\n",
      "           2       0.57      0.55      0.56       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.43      0.44      0.43       210\n",
      "           5       0.43      0.44      0.44       210\n",
      "           6       0.43      0.42      0.42       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  15   6  20  35   9  10]\n",
      " [  9 117   8  16  35  19   6]\n",
      " [  7   8 167   7  12   9   0]\n",
      " [ 20  23  13  89  29  29   7]\n",
      " [ 33  20   5  41  95   9   7]\n",
      " [ 13  16   5  20  16  92  48]\n",
      " [  2  11   3   9   7  47 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.55      0.56       210\n",
      "           2       0.56      0.56      0.56       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.43      0.44      0.43       210\n",
      "           7       0.63      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  14   4  24  32  14   7]\n",
      " [ 10 116  10  20  32  18   4]\n",
      " [  6   9 165  11  12   6   1]\n",
      " [ 26  25   7  93  32  22   5]\n",
      " [ 31  29   8  41  90   6   5]\n",
      " [ 14  19   8  19  13  90  47]\n",
      " [  8   8   4  10   9  50 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55       210\n",
      "           2       0.53      0.55      0.54       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.43      0.44      0.43       210\n",
      "           5       0.41      0.43      0.42       210\n",
      "           6       0.44      0.43      0.43       210\n",
      "           7       0.64      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  8   0 168   1   2   4  27]\n",
      " [  2   7 132   0  13   2  54]\n",
      " [  2   0 198   0   0   0  10]\n",
      " [  3   2 164   0   6   3  32]\n",
      " [  6   5 169   0   3   0  27]\n",
      " [  7   0  36   0   2   4 161]\n",
      " [  1   0   0   0   1   1 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.04      0.07       210\n",
      "           2       0.50      0.03      0.06       210\n",
      "           3       0.23      0.94      0.37       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.11      0.01      0.03       210\n",
      "           6       0.29      0.02      0.04       210\n",
      "           7       0.40      0.99      0.57       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.26      0.29      0.16      1470\n",
      "weighted avg       0.26      0.29      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47619047619047616\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 55   5  32   1  90  17  10]\n",
      " [  8  88  28   1  54  16  15]\n",
      " [ 10  10 164   1  17   7   1]\n",
      " [  3  14  42   9 113  16  13]\n",
      " [  9  11  23   0 144  10  13]\n",
      " [  7   8  11   1  22  43 118]\n",
      " [  0   1   0   0   2  10 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.26      0.36       210\n",
      "           2       0.64      0.42      0.51       210\n",
      "           3       0.55      0.78      0.64       210\n",
      "           4       0.69      0.04      0.08       210\n",
      "           5       0.33      0.69      0.44       210\n",
      "           6       0.36      0.20      0.26       210\n",
      "           7       0.54      0.94      0.68       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.53      0.48      0.43      1470\n",
      "weighted avg       0.53      0.48      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   6   2   5  32  24   5]\n",
      " [ 11 133   5   9  28  14  10]\n",
      " [ 22  19 150   5   7   7   0]\n",
      " [ 35  15  23  54  51  22  10]\n",
      " [ 49  25  10  14  91  13   8]\n",
      " [ 16  14   4  10   6  65  95]\n",
      " [  0   2   0   0   0  14 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.65      0.57       210\n",
      "           2       0.62      0.63      0.63       210\n",
      "           3       0.77      0.71      0.74       210\n",
      "           4       0.56      0.26      0.35       210\n",
      "           5       0.42      0.43      0.43       210\n",
      "           6       0.41      0.31      0.35       210\n",
      "           7       0.60      0.92      0.73       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.54      1470\n",
      "weighted avg       0.56      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   1  10  31  25   5]\n",
      " [  5 137   4   9  33  14   8]\n",
      " [ 26   9 155   9   5   6   0]\n",
      " [ 28  14  15  79  41  25   8]\n",
      " [ 36  24   7  20  98  17   8]\n",
      " [ 23   8   0  12   5  71  91]\n",
      " [  1   2   0   0   0  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.64      0.58       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.57      0.38      0.45       210\n",
      "           5       0.46      0.47      0.46       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.61      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   6   1   8  36  26   4]\n",
      " [  2 135   4  13  32  18   6]\n",
      " [ 19   6 151  19   9   6   0]\n",
      " [ 10  11   9 110  38  26   6]\n",
      " [ 28  16   4  25 113  16   8]\n",
      " [ 13   6   1  16   7  88  79]\n",
      " [  1   1   0   0   1  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.63       210\n",
      "           2       0.75      0.64      0.69       210\n",
      "           3       0.89      0.72      0.79       210\n",
      "           4       0.58      0.52      0.55       210\n",
      "           5       0.48      0.54      0.51       210\n",
      "           6       0.44      0.42      0.43       210\n",
      "           7       0.65      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6448979591836734\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   3   1  13  36  26   3]\n",
      " [  3 134   3  15  33  17   5]\n",
      " [ 14   7 161  14   8   6   0]\n",
      " [  4  11   6 118  38  27   6]\n",
      " [ 20  15   4  22 125  16   8]\n",
      " [ 12   6   1  15   8  97  71]\n",
      " [  1   0   0   0   2  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.76      0.64      0.69       210\n",
      "           3       0.91      0.77      0.83       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.50      0.60      0.54       210\n",
      "           6       0.46      0.46      0.46       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.65      1470\n",
      "weighted avg       0.66      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   3   0  15  36  25   3]\n",
      " [  1 134   4  18  31  17   5]\n",
      " [ 11   6 162  17   8   6   0]\n",
      " [  3   9   5 131  28  27   7]\n",
      " [ 25  14   2  25 123  15   6]\n",
      " [ 13   6   0  19   6  95  71]\n",
      " [  0   0   0   0   2  21 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.61      0.65       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.94      0.77      0.85       210\n",
      "           4       0.58      0.62      0.60       210\n",
      "           5       0.53      0.59      0.55       210\n",
      "           6       0.46      0.45      0.46       210\n",
      "           7       0.67      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   3   1  16  35  21   3]\n",
      " [  2 136   5  16  27  18   6]\n",
      " [  8   6 172  11   7   6   0]\n",
      " [  5   9   5 128  32  27   4]\n",
      " [ 21  11   2  23 129  18   6]\n",
      " [ 10   4   0  24   4  99  69]\n",
      " [  1   0   0   0   1  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.68       210\n",
      "           2       0.80      0.65      0.72       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.59      0.61      0.60       210\n",
      "           5       0.55      0.61      0.58       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   0  14  36  19   5]\n",
      " [  1 142   3  16  26  17   5]\n",
      " [ 11   8 172  11   3   5   0]\n",
      " [  4   6   4 135  31  27   3]\n",
      " [ 16  11   2  23 136  17   5]\n",
      " [ 15   2   1  19   5  98  70]\n",
      " [  1   0   0   0   2  18 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.83      0.68      0.74       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.62      0.64      0.63       210\n",
      "           5       0.57      0.65      0.61       210\n",
      "           6       0.49      0.47      0.48       210\n",
      "           7       0.68      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   2   1  11  37  25   2]\n",
      " [  2 142   4  16  27  17   2]\n",
      " [  7   4 171  13  10   5   0]\n",
      " [  6   6   3 136  31  22   6]\n",
      " [ 20   8   2  21 139  13   7]\n",
      " [ 10   6   1  15   8 105  65]\n",
      " [  1   2   0   0   1  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.63      0.68       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.94      0.81      0.87       210\n",
      "           4       0.64      0.65      0.64       210\n",
      "           5       0.55      0.66      0.60       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.69      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   0   9  34  20   4]\n",
      " [  2 142   3  16  24  18   5]\n",
      " [  8   8 173  12   4   5   0]\n",
      " [  4   6   2 141  25  29   3]\n",
      " [ 22  11   3  25 130  11   8]\n",
      " [ 11   8   0  20   5 102  64]\n",
      " [  1   0   0   0   2  25 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.67      0.71       210\n",
      "           2       0.80      0.68      0.73       210\n",
      "           3       0.96      0.82      0.88       210\n",
      "           4       0.63      0.67      0.65       210\n",
      "           5       0.58      0.62      0.60       210\n",
      "           6       0.49      0.49      0.49       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   0  14  37  21   2]\n",
      " [  2 142   3  18  23  18   4]\n",
      " [  6   5 175  12   7   5   0]\n",
      " [  7   4   4 139  28  24   4]\n",
      " [ 22  10   2  21 132  16   7]\n",
      " [ 15   6   0  21   4  95  69]\n",
      " [  1   0   0   0   2  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.95      0.83      0.89       210\n",
      "           4       0.62      0.66      0.64       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   4   1   9  29  27   3]\n",
      " [  1 141   3  21  24  16   4]\n",
      " [  6   5 177  12   5   5   0]\n",
      " [  6   5   6 136  29  24   4]\n",
      " [ 19   8   2  19 139  16   7]\n",
      " [ 14   4   0  20   4 102  66]\n",
      " [  1   0   0   0   2  25 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.65      0.70       210\n",
      "           2       0.84      0.67      0.75       210\n",
      "           3       0.94      0.84      0.89       210\n",
      "           4       0.63      0.65      0.64       210\n",
      "           5       0.60      0.66      0.63       210\n",
      "           6       0.47      0.49      0.48       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   3   0  13  32  20   3]\n",
      " [  1 144   5  17  23  15   5]\n",
      " [ 10   6 175  13   1   5   0]\n",
      " [  4   8   5 128  34  25   6]\n",
      " [ 19   9   4  23 135  14   6]\n",
      " [ 14   6   0  18   5 101  66]\n",
      " [  0   0   0   0   3  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.66      0.70       210\n",
      "           2       0.82      0.69      0.75       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.60      0.61      0.61       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.49      0.48      0.48       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   3   1  13  30  20   2]\n",
      " [  1 138   5  18  24  20   4]\n",
      " [ 12   8 173   9   4   3   1]\n",
      " [  6   9   4 134  30  24   3]\n",
      " [ 22  10   2  25 131  13   7]\n",
      " [ 12   3   1  24   1 104  65]\n",
      " [  1   1   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.67      0.70       210\n",
      "           2       0.80      0.66      0.72       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.60      0.64      0.62       210\n",
      "           5       0.59      0.62      0.61       210\n",
      "           6       0.49      0.50      0.49       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   3   1   9  30  22   3]\n",
      " [  2 146   5  17  20  16   4]\n",
      " [  7   6 176  11   5   5   0]\n",
      " [  6   8   5 140  25  23   3]\n",
      " [ 22  12   3  21 132  14   6]\n",
      " [ 18   7   0  15   3 105  62]\n",
      " [  2   1   0   0   2  22 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.68      0.69       210\n",
      "           2       0.80      0.70      0.74       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.66      0.67      0.66       210\n",
      "           5       0.61      0.63      0.62       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.70      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   0  10  35  25   2]\n",
      " [  1 151   7  15  17  15   4]\n",
      " [  6   8 176  12   3   5   0]\n",
      " [ 11   7   7 129  25  27   4]\n",
      " [ 26   8   3  25 128  14   6]\n",
      " [ 15   4   0  20   3 113  55]\n",
      " [  1   0   0   0   1  24 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.64      0.66       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.91      0.84      0.87       210\n",
      "           4       0.61      0.61      0.61       210\n",
      "           5       0.60      0.61      0.61       210\n",
      "           6       0.51      0.54      0.52       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   3   0  13  32  25   2]\n",
      " [  0 150   6  12  21  16   5]\n",
      " [  9   7 177   8   4   5   0]\n",
      " [  6  10   4 138  25  22   5]\n",
      " [ 20  12   3  21 134  12   8]\n",
      " [ 17   4   0  19   3 105  62]\n",
      " [  1   0   0   1   2  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.65      0.66      0.65       210\n",
      "           5       0.61      0.64      0.62       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.69      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   3   0  12  36  20   3]\n",
      " [  3 149   7  14  21  12   4]\n",
      " [  7   8 176  12   2   5   0]\n",
      " [  8   9   7 134  25  23   4]\n",
      " [ 24  11   3  21 130  15   6]\n",
      " [ 14   4   1  20   4 109  58]\n",
      " [  1   0   0   0   3  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.65      0.67       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.91      0.84      0.87       210\n",
      "           4       0.63      0.64      0.63       210\n",
      "           5       0.59      0.62      0.60       210\n",
      "           6       0.53      0.52      0.52       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   0  12  29  25   1]\n",
      " [  2 150   6  12  21  15   4]\n",
      " [  5   7 175  12   6   5   0]\n",
      " [  7   8   5 143  20  23   4]\n",
      " [ 24  11   3  25 129  12   6]\n",
      " [ 13   7   0  20   3 106  61]\n",
      " [  1   0   0   1   2  25 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.67      0.70       210\n",
      "           2       0.81      0.71      0.76       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.64      0.68      0.66       210\n",
      "           5       0.61      0.61      0.61       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.70      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 87   9  30   8  37  33   6]\n",
      " [  5  93  41   4  26  32   9]\n",
      " [ 12  16 165   5   1  11   0]\n",
      " [ 23  13  52  49  29  34  10]\n",
      " [ 20  18  44  12  79  31   6]\n",
      " [ 16  11   6   8   2  74  93]\n",
      " [  0   1   0   0   0  32 177]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.41      0.47       210\n",
      "           2       0.58      0.44      0.50       210\n",
      "           3       0.49      0.79      0.60       210\n",
      "           4       0.57      0.23      0.33       210\n",
      "           5       0.45      0.38      0.41       210\n",
      "           6       0.30      0.35      0.32       210\n",
      "           7       0.59      0.84      0.69       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.48      1470\n",
      "weighted avg       0.50      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_ndisbert.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80480feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7714285714285715\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[162   2   0   3  36   5   2]\n",
      " [  2 170  10   8  11   8   1]\n",
      " [  0   1 197   6   1   5   0]\n",
      " [  6  11   4 157  17  13   2]\n",
      " [ 35   9   1  10 143   8   4]\n",
      " [ 10  15   4  15   7 136  23]\n",
      " [  5   0   1   1   3  31 169]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.82      0.81      0.81       210\n",
      "           3       0.91      0.94      0.92       210\n",
      "           4       0.79      0.75      0.77       210\n",
      "           5       0.66      0.68      0.67       210\n",
      "           6       0.66      0.65      0.65       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156   4   1   3  39   3   4]\n",
      " [  4 158  10   7  24   7   0]\n",
      " [  5  14 186   1   0   3   1]\n",
      " [ 17   9  21 121  30   8   4]\n",
      " [ 38  18  10  11 128   1   4]\n",
      " [ 24  30   7  27  17  55  50]\n",
      " [  8   5   0   5  15   9 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.74      0.68       210\n",
      "           2       0.66      0.75      0.71       210\n",
      "           3       0.79      0.89      0.84       210\n",
      "           4       0.69      0.58      0.63       210\n",
      "           5       0.51      0.61      0.55       210\n",
      "           6       0.64      0.26      0.37       210\n",
      "           7       0.73      0.80      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   2   2   3  41   4   6]\n",
      " [  2 172  11   5  14   6   0]\n",
      " [  3  11 189   0   2   4   1]\n",
      " [ 14  11  23 128  26   6   2]\n",
      " [ 34  23  11  13 123   0   6]\n",
      " [ 22  23   9  24  17  62  53]\n",
      " [  4   2   0   2  18  15 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.72      0.69       210\n",
      "           2       0.70      0.82      0.76       210\n",
      "           3       0.77      0.90      0.83       210\n",
      "           4       0.73      0.61      0.66       210\n",
      "           5       0.51      0.59      0.55       210\n",
      "           6       0.64      0.30      0.40       210\n",
      "           7       0.71      0.80      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.66      1470\n",
      "weighted avg       0.68      0.68      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   1   1   0  48   5   7]\n",
      " [  2 169  13   5  18   2   1]\n",
      " [  4  12 188   0   2   3   1]\n",
      " [  8  10  20 129  36   4   3]\n",
      " [ 28  19  11  16 128   1   7]\n",
      " [ 21  22   8  26  16  61  56]\n",
      " [  3   2   0   0  22   9 174]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.70      0.70       210\n",
      "           2       0.72      0.80      0.76       210\n",
      "           3       0.78      0.90      0.83       210\n",
      "           4       0.73      0.61      0.67       210\n",
      "           5       0.47      0.61      0.53       210\n",
      "           6       0.72      0.29      0.41       210\n",
      "           7       0.70      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   1   2   1  46   1   7]\n",
      " [  2 167  13   7  18   2   1]\n",
      " [  3  11 187   0   5   3   1]\n",
      " [ 10  13  25 121  34   3   4]\n",
      " [ 29  19  13  11 131   2   5]\n",
      " [ 18  18  11  24  19  62  58]\n",
      " [  2   0   1   0  17   8 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.73      0.80      0.76       210\n",
      "           3       0.74      0.89      0.81       210\n",
      "           4       0.74      0.58      0.65       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.77      0.30      0.43       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.67      1470\n",
      "weighted avg       0.70      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   2   2   1  49   1   7]\n",
      " [  2 165  12   8  18   4   1]\n",
      " [  2   9 189   1   4   4   1]\n",
      " [ 11  12  24 121  36   3   3]\n",
      " [ 20  20  14  11 135   2   8]\n",
      " [ 21  18  12  19  20  61  59]\n",
      " [  3   0   1   0  17   6 183]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.73      0.79      0.76       210\n",
      "           3       0.74      0.90      0.81       210\n",
      "           4       0.75      0.58      0.65       210\n",
      "           5       0.48      0.64      0.55       210\n",
      "           6       0.75      0.29      0.42       210\n",
      "           7       0.70      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.67      1470\n",
      "weighted avg       0.70      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   4   2   0  50   0   7]\n",
      " [  0 167  11   7  18   6   1]\n",
      " [  1  10 191   2   2   3   1]\n",
      " [ 12  11  24 121  34   4   4]\n",
      " [ 24  20  13   7 136   1   9]\n",
      " [ 16  21  16  21  21  55  60]\n",
      " [  1   1   1   1  14   5 187]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.70      0.72       210\n",
      "           2       0.71      0.80      0.75       210\n",
      "           3       0.74      0.91      0.82       210\n",
      "           4       0.76      0.58      0.66       210\n",
      "           5       0.49      0.65      0.56       210\n",
      "           6       0.74      0.26      0.39       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.67      1470\n",
      "weighted avg       0.70      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 93  10   6   6  53  17  25]\n",
      " [  0 135  19   6  34  10   6]\n",
      " [  4   9 175   6   8   7   1]\n",
      " [  3  11  25  70  47  25  29]\n",
      " [  9  26   1  15 118   3  38]\n",
      " [  4   9  22  15  15  63  82]\n",
      " [  0   2   0   6   9  26 167]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.44      0.58       210\n",
      "           2       0.67      0.64      0.66       210\n",
      "           3       0.71      0.83      0.76       210\n",
      "           4       0.56      0.33      0.42       210\n",
      "           5       0.42      0.56      0.48       210\n",
      "           6       0.42      0.30      0.35       210\n",
      "           7       0.48      0.80      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5238095238095238\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 90  10  12   2  53  24  19]\n",
      " [  2 120  28   9  36   9   6]\n",
      " [  7   8 178   5   7   4   1]\n",
      " [  6  10  28  58  54  28  26]\n",
      " [ 16  23   3   9 116   8  35]\n",
      " [  3  12  23  22  19  62  69]\n",
      " [  0   8   1   6  16  33 146]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.43      0.54       210\n",
      "           2       0.63      0.57      0.60       210\n",
      "           3       0.65      0.85      0.74       210\n",
      "           4       0.52      0.28      0.36       210\n",
      "           5       0.39      0.55      0.45       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.48      0.70      0.57       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.51      1470\n",
      "weighted avg       0.54      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7795918367346939\n",
      "Confusion Matrix of SVM is:\n",
      " [[171   1   0   1  30   6   1]\n",
      " [  4 178  10   3  12   2   1]\n",
      " [  0   3 199   6   0   2   0]\n",
      " [ 10  11   5 158  13  11   2]\n",
      " [ 39   8   2  13 139   6   3]\n",
      " [  6  16   8  12   6 135  27]\n",
      " [  2   1   0   1   4  36 166]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.81      0.77       210\n",
      "           2       0.82      0.85      0.83       210\n",
      "           3       0.89      0.95      0.92       210\n",
      "           4       0.81      0.75      0.78       210\n",
      "           5       0.68      0.66      0.67       210\n",
      "           6       0.68      0.64      0.66       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.78      0.78      0.78      1470\n",
      "weighted avg       0.78      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.754421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[122   1   0   0  69  16   2]\n",
      " [  0 156   3  11  28  11   1]\n",
      " [  1   2 180  13  11   3   0]\n",
      " [  2   2   2 159  29  13   3]\n",
      " [  7   6   1   6 181   4   5]\n",
      " [  4   6   6  20  13 135  26]\n",
      " [  0   0   0   2   6  26 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.58      0.71       210\n",
      "           2       0.90      0.74      0.81       210\n",
      "           3       0.94      0.86      0.90       210\n",
      "           4       0.75      0.76      0.76       210\n",
      "           5       0.54      0.86      0.66       210\n",
      "           6       0.65      0.64      0.65       210\n",
      "           7       0.83      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.79      0.75      0.76      1470\n",
      "weighted avg       0.79      0.75      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7965986394557824\n",
      "Confusion Matrix of SVM is:\n",
      " [[160   2   0   4  30  13   1]\n",
      " [  0 168   8   5  11  17   1]\n",
      " [  0   3 193   3   4   6   1]\n",
      " [  4   3   6 159  13  20   5]\n",
      " [ 18   9   3  10 153  10   7]\n",
      " [  8   7   6   9   3 145  32]\n",
      " [  0   0   0   0   1  16 193]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.76      0.80       210\n",
      "           2       0.88      0.80      0.84       210\n",
      "           3       0.89      0.92      0.91       210\n",
      "           4       0.84      0.76      0.79       210\n",
      "           5       0.71      0.73      0.72       210\n",
      "           6       0.64      0.69      0.66       210\n",
      "           7       0.80      0.92      0.86       210\n",
      "\n",
      "    accuracy                           0.80      1470\n",
      "   macro avg       0.80      0.80      0.80      1470\n",
      "weighted avg       0.80      0.80      0.80      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.754421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   2   0   3  43  10   1]\n",
      " [  2 165  13   4  14  11   1]\n",
      " [  1   2 191   9   1   5   1]\n",
      " [  4   7  25 137  14  16   7]\n",
      " [ 21  11   1  17 147   6   7]\n",
      " [  8   5  14  12   3 131  37]\n",
      " [  1   1   0   0   0  21 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.85      0.79      0.82       210\n",
      "           3       0.78      0.91      0.84       210\n",
      "           4       0.75      0.65      0.70       210\n",
      "           5       0.66      0.70      0.68       210\n",
      "           6       0.66      0.62      0.64       210\n",
      "           7       0.78      0.89      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23333333333333334\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3   0   0   0 207]\n",
      " [  0   0  18   0   0   0 192]\n",
      " [  0   0 135   0   0   0  75]\n",
      " [  0   0  33   0   0   0 177]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0  11   0   0   0 199]\n",
      " [  0   0   2   0   0   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.65      0.64      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.99      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.12      0.23      0.13      1470\n",
      "weighted avg       0.12      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3360544217687075\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[182   0   2   1   0   0  25]\n",
      " [151   0   9   9   0   0  41]\n",
      " [ 61   0 125  10   0   0  14]\n",
      " [144   0  13  20   0   0  33]\n",
      " [190   0   3   2   0   0  15]\n",
      " [ 78   0   7   4   0   0 121]\n",
      " [ 41   0   0   2   0   0 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.87      0.34       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.79      0.60      0.68       210\n",
      "           4       0.42      0.10      0.16       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.80      0.53       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.26      0.34      0.24      1470\n",
      "weighted avg       0.26      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   2   1  97  18   7]\n",
      " [ 11  13   4   1 140  39   2]\n",
      " [ 21   5 122   8  40  13   1]\n",
      " [ 22   8   6  19 122  23  10]\n",
      " [ 30   2   3   0 160   8   7]\n",
      " [ 22   4   3   4  56  76  45]\n",
      " [  4   1   0   1  37  47 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.40      0.42       210\n",
      "           2       0.39      0.06      0.11       210\n",
      "           3       0.87      0.58      0.70       210\n",
      "           4       0.56      0.09      0.16       210\n",
      "           5       0.25      0.76      0.37       210\n",
      "           6       0.34      0.36      0.35       210\n",
      "           7       0.62      0.57      0.60       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.50      0.40      0.39      1470\n",
      "weighted avg       0.50      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  25  10   1  79  12   6]\n",
      " [  3 150  11   2  35   8   1]\n",
      " [  3  43 138  10  13   2   1]\n",
      " [  8  54  19  20  90  12   7]\n",
      " [ 13  33  19   1 134   3   7]\n",
      " [ 17  50   7   5  36  58  37]\n",
      " [  4  16   0   1  30  43 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.37      0.46       210\n",
      "           2       0.40      0.71      0.52       210\n",
      "           3       0.68      0.66      0.67       210\n",
      "           4       0.50      0.10      0.16       210\n",
      "           5       0.32      0.64      0.43       210\n",
      "           6       0.42      0.28      0.33       210\n",
      "           7       0.66      0.55      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.45      1470\n",
      "weighted avg       0.51      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71   6   1  46  55  19  12]\n",
      " [  2 109   3  57  15  19   5]\n",
      " [  3  15 132  39   6  14   1]\n",
      " [  6  19   5 114  29  23  14]\n",
      " [ 10  21   7  67  90   6   9]\n",
      " [ 11  14   4  45  11  50  75]\n",
      " [  0  10   0  27   7  19 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.34      0.45       210\n",
      "           2       0.56      0.52      0.54       210\n",
      "           3       0.87      0.63      0.73       210\n",
      "           4       0.29      0.54      0.38       210\n",
      "           5       0.42      0.43      0.43       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.56      0.70      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.53      0.49      0.49      1470\n",
      "weighted avg       0.53      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   5   4  37  39  17   6]\n",
      " [  3 113   5  47  21  19   2]\n",
      " [  1  13 155  20   8  12   1]\n",
      " [ 20  19   7 100  31  25   8]\n",
      " [ 37  19   4  39  98   6   7]\n",
      " [ 14  14   6  33  26  75  42]\n",
      " [  6  10   1  12  22  37 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.49      0.52       210\n",
      "           2       0.59      0.54      0.56       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.35      0.48      0.40       210\n",
      "           5       0.40      0.47      0.43       210\n",
      "           6       0.39      0.36      0.37       210\n",
      "           7       0.65      0.58      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.53      1470\n",
      "weighted avg       0.54      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 90   6   0  36  54  16   8]\n",
      " [  3 114   4  35  37  11   6]\n",
      " [  2  10 158  14  14  11   1]\n",
      " [  6  15   9  93  59  19   9]\n",
      " [ 22  16   8  25 123   7   9]\n",
      " [ 11  12   4  39  25  74  45]\n",
      " [  2   6   1  16  16  37 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.43      0.52       210\n",
      "           2       0.64      0.54      0.59       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.36      0.44      0.40       210\n",
      "           5       0.38      0.59      0.46       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.63      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.56      0.53      0.54      1470\n",
      "weighted avg       0.56      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   5   1  39  58  14  11]\n",
      " [  5 117   7  26  26  23   6]\n",
      " [  2   9 158  11  16  14   0]\n",
      " [  4  14  15  95  42  27  13]\n",
      " [ 17  14   4  26 124  17   8]\n",
      " [ 11  12   4  26  27  77  53]\n",
      " [  5   8   2  17  13  35 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.39      0.49       210\n",
      "           2       0.65      0.56      0.60       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.40      0.45      0.42       210\n",
      "           5       0.41      0.59      0.48       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.59      0.62      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.56      0.53      0.54      1470\n",
      "weighted avg       0.56      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   8   1  29  51  17  10]\n",
      " [  6 124   6  23  33  14   4]\n",
      " [  1   9 159  10  14  16   1]\n",
      " [ 10  12   9  84  49  35  11]\n",
      " [ 22  18   4  14 126  20   6]\n",
      " [ 15  17   2  27  30  68  51]\n",
      " [  7   7   2  10  17  34 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.45      0.52       210\n",
      "           2       0.64      0.59      0.61       210\n",
      "           3       0.87      0.76      0.81       210\n",
      "           4       0.43      0.40      0.41       210\n",
      "           5       0.39      0.60      0.48       210\n",
      "           6       0.33      0.32      0.33       210\n",
      "           7       0.62      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103   8   4  23  50  14   8]\n",
      " [  9 118  12  20  27  18   6]\n",
      " [  1  10 160  12  13  13   1]\n",
      " [ 11  18  15  79  44  36   7]\n",
      " [ 39  17   6  20 112   8   8]\n",
      " [ 20  25  10  27  25  60  43]\n",
      " [ 10  10   3  12  20  35 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.49      0.51       210\n",
      "           2       0.57      0.56      0.57       210\n",
      "           3       0.76      0.76      0.76       210\n",
      "           4       0.41      0.38      0.39       210\n",
      "           5       0.38      0.53      0.45       210\n",
      "           6       0.33      0.29      0.30       210\n",
      "           7       0.62      0.57      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   8   1  33  44  16  10]\n",
      " [ 11 133   9  22  22   9   4]\n",
      " [  1   8 160  15  13  10   3]\n",
      " [ 13  21  11  90  45  20  10]\n",
      " [ 30  20   5  20 109  17   9]\n",
      " [ 19  29   5  27  28  58  44]\n",
      " [  7   5   5  15  17  27 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.47      0.50       210\n",
      "           2       0.59      0.63      0.61       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.39      0.52      0.45       210\n",
      "           6       0.37      0.28      0.32       210\n",
      "           7       0.63      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5244897959183673\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  13   5  25  43  16   7]\n",
      " [ 11 131  14  14  27   6   7]\n",
      " [  2  13 161  14  11   9   0]\n",
      " [ 20  14  11  85  47  24   9]\n",
      " [ 40  22   3  18 104  13  10]\n",
      " [ 22  25   9  26  19  64  45]\n",
      " [ 13  11   2  13  15  31 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.48      0.48       210\n",
      "           2       0.57      0.62      0.60       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.39      0.50      0.44       210\n",
      "           6       0.39      0.30      0.34       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   8   1  28  42  14  16]\n",
      " [ 13 126   9  12  23  22   5]\n",
      " [  1   8 162  11  14  12   2]\n",
      " [ 11  11  17  85  42  29  15]\n",
      " [ 31  19   5  26  99  18  12]\n",
      " [ 23  32   8  21  18  63  45]\n",
      " [ 11   9   3  14  14  34 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.48      0.50       210\n",
      "           2       0.59      0.60      0.60       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.43      0.40      0.42       210\n",
      "           5       0.39      0.47      0.43       210\n",
      "           6       0.33      0.30      0.31       210\n",
      "           7       0.57      0.60      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  12   0  28  35  18  13]\n",
      " [ 10 127  16  13  26  11   7]\n",
      " [  2  10 166  10  11  11   0]\n",
      " [ 15  20  13  87  38  26  11]\n",
      " [ 34  21   5  19 100  18  13]\n",
      " [ 20  30  11  25  18  58  48]\n",
      " [  6  15   0  14  19  31 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.50      0.52       210\n",
      "           2       0.54      0.60      0.57       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.44      0.41      0.43       210\n",
      "           5       0.40      0.48      0.44       210\n",
      "           6       0.34      0.28      0.30       210\n",
      "           7       0.58      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   9   5  25  39  19  13]\n",
      " [ 11 128  10  18  25  13   5]\n",
      " [  1  12 161  14  14   7   1]\n",
      " [ 17  18  15  79  42  31   8]\n",
      " [ 33  22   8  23  92  18  14]\n",
      " [ 22  28  11  26  18  59  46]\n",
      " [  8   9   2  13  21  36 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.48      0.50       210\n",
      "           2       0.57      0.61      0.59       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.40      0.38      0.39       210\n",
      "           5       0.37      0.44      0.40       210\n",
      "           6       0.32      0.28      0.30       210\n",
      "           7       0.58      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   8   3  24  37  17  13]\n",
      " [ 17 123  10  15  24  17   4]\n",
      " [  1   8 163  11  12  13   2]\n",
      " [ 14  20  18  79  40  28  11]\n",
      " [ 34  29  10  21  86  18  12]\n",
      " [ 16  33   8  18  20  70  45]\n",
      " [ 11   7   3  15  14  36 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.53       210\n",
      "           2       0.54      0.59      0.56       210\n",
      "           3       0.76      0.78      0.77       210\n",
      "           4       0.43      0.38      0.40       210\n",
      "           5       0.37      0.41      0.39       210\n",
      "           6       0.35      0.33      0.34       210\n",
      "           7       0.59      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   9   3  28  33  16  13]\n",
      " [ 10 133  11  13  21  19   3]\n",
      " [  1  13 164   8  12  10   2]\n",
      " [ 19  20  15  85  32  26  13]\n",
      " [ 34  34   9  17  90  18   8]\n",
      " [ 23  28  10  23  20  61  45]\n",
      " [  9   8   1  18  12  37 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.51      0.52       210\n",
      "           2       0.54      0.63      0.58       210\n",
      "           3       0.77      0.78      0.78       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.41      0.43      0.42       210\n",
      "           6       0.33      0.29      0.31       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  10   4  27  37  15  10]\n",
      " [  8 131  12  14  19  19   7]\n",
      " [  1  12 161   8  15  12   1]\n",
      " [ 16  17  13  83  38  31  12]\n",
      " [ 33  27   9  26  83  22  10]\n",
      " [ 17  32   6  25  17  69  44]\n",
      " [ 10   8   0  22   9  33 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.51      0.53       210\n",
      "           2       0.55      0.62      0.59       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.40      0.40      0.40       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.34      0.33      0.34       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  12   4  28  31  18  12]\n",
      " [  8 136  10  16  20  16   4]\n",
      " [  1  11 162   8  16  11   1]\n",
      " [ 22  20  11  85  34  26  12]\n",
      " [ 30  29   7  21  89  25   9]\n",
      " [ 16  26   7  26  20  71  44]\n",
      " [  8  13   2  13  12  33 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.50      0.53       210\n",
      "           2       0.55      0.65      0.60       210\n",
      "           3       0.80      0.77      0.78       210\n",
      "           4       0.43      0.40      0.42       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.35      0.34      0.35       210\n",
      "           7       0.61      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   9   5  29  31  19  12]\n",
      " [ 11 135  10  16  21  13   4]\n",
      " [  2  11 163  10  14   9   1]\n",
      " [ 23  23  13  82  35  23  11]\n",
      " [ 32  30   6  22  88  24   8]\n",
      " [ 19  23   7  26  17  72  46]\n",
      " [ 10  12   2  15  13  37 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.50      0.51       210\n",
      "           2       0.56      0.64      0.60       210\n",
      "           3       0.79      0.78      0.78       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.40      0.42      0.41       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.60      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3843537414965986\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 21   1  35   0 109   0  44]\n",
      " [  2  23  57   2  97   0  29]\n",
      " [  0   7 179   1  19   0   4]\n",
      " [  4   6  35   1  88   0  76]\n",
      " [  1  11   4   0 143   0  51]\n",
      " [  1   3  26   1  36   1 142]\n",
      " [  0   0   3   0  10   0 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.10      0.18       210\n",
      "           2       0.45      0.11      0.18       210\n",
      "           3       0.53      0.85      0.65       210\n",
      "           4       0.20      0.00      0.01       210\n",
      "           5       0.28      0.68      0.40       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.36      0.94      0.52       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.51      0.38      0.28      1470\n",
      "weighted avg       0.51      0.38      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49183673469387756\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 81  10   3   0  73   1  42]\n",
      " [  3 114  23   0  46   0  24]\n",
      " [  1  18 172   2  14   1   2]\n",
      " [  8  35  27  11  71   2  56]\n",
      " [  6  23   0   0 136   0  45]\n",
      " [  5   5  25   1  17   3 154]\n",
      " [  0   3   1   0   0   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.39      0.52       210\n",
      "           2       0.55      0.54      0.55       210\n",
      "           3       0.69      0.82      0.75       210\n",
      "           4       0.79      0.05      0.10       210\n",
      "           5       0.38      0.65      0.48       210\n",
      "           6       0.43      0.01      0.03       210\n",
      "           7       0.39      0.98      0.56       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.42      1470\n",
      "weighted avg       0.57      0.49      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   8   2   0  64   2  29]\n",
      " [  0 146  14   4  30   2  14]\n",
      " [  3  27 164   1  13   1   1]\n",
      " [  6  27  25  41  68   3  40]\n",
      " [ 12  27   0   1 136   0  34]\n",
      " [  7  11  24   4  16  14 134]\n",
      " [  0   5   1   1   5   1 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.50      0.61       210\n",
      "           2       0.58      0.70      0.63       210\n",
      "           3       0.71      0.78      0.75       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.41      0.65      0.50       210\n",
      "           6       0.61      0.07      0.12       210\n",
      "           7       0.44      0.94      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.62      0.55      0.50      1470\n",
      "weighted avg       0.62      0.55      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.582312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  10   2   1  59   6  26]\n",
      " [  1 156   8   1  27   9   8]\n",
      " [  3  18 172   6   9   1   1]\n",
      " [  5  21  23  62  61  11  27]\n",
      " [ 18  21   0   3 135   3  30]\n",
      " [  4  13  18   9  17  31 118]\n",
      " [  0   3   0   0   7   6 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.50      0.61       210\n",
      "           2       0.64      0.74      0.69       210\n",
      "           3       0.77      0.82      0.79       210\n",
      "           4       0.76      0.30      0.42       210\n",
      "           5       0.43      0.64      0.51       210\n",
      "           6       0.46      0.15      0.22       210\n",
      "           7       0.48      0.92      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.56      1470\n",
      "weighted avg       0.62      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   7   1   7  55   9  21]\n",
      " [  0 148  10  10  27   9   6]\n",
      " [  2  11 173  11  10   2   1]\n",
      " [  5  11  13  99  49  14  19]\n",
      " [ 14  18   0   9 141   7  21]\n",
      " [  3   5  14  18  12  51 107]\n",
      " [  0   1   0   3   5   9 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.52      0.64       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.63      0.47      0.54       210\n",
      "           5       0.47      0.67      0.55       210\n",
      "           6       0.50      0.24      0.33       210\n",
      "           7       0.52      0.91      0.67       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.61      1470\n",
      "weighted avg       0.64      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   3   0   4  58  22  13]\n",
      " [  0 148   6  15  27  10   4]\n",
      " [  1   5 179  11   8   5   1]\n",
      " [  5   8  11 116  44  11  15]\n",
      " [ 15  20   0  12 136   7  20]\n",
      " [  3   8  10  14  10  77  88]\n",
      " [  0   1   0   2   5   8 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.52      0.64       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.67      0.55      0.60       210\n",
      "           5       0.47      0.65      0.55       210\n",
      "           6       0.55      0.37      0.44       210\n",
      "           7       0.58      0.92      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   3   0   9  52  16  12]\n",
      " [  0 152   7  10  26  10   5]\n",
      " [  1   7 176  12   9   4   1]\n",
      " [  6   5  11 122  39  14  13]\n",
      " [ 12  18   0  16 142   8  14]\n",
      " [  5   5  10  15   8  92  75]\n",
      " [  0   1   0   1   3  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.56      0.67       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.86      0.84      0.85       210\n",
      "           4       0.66      0.58      0.62       210\n",
      "           5       0.51      0.68      0.58       210\n",
      "           6       0.59      0.44      0.50       210\n",
      "           7       0.62      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   3   1   9  50  18   9]\n",
      " [  0 154   8  12  21  11   4]\n",
      " [  1   7 179   9   9   4   1]\n",
      " [  4   7  10 124  37  15  13]\n",
      " [ 11  17   0  13 148   6  15]\n",
      " [  5  10   9  17   5  96  68]\n",
      " [  1   0   0   2   2  18 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.57      0.68       210\n",
      "           2       0.78      0.73      0.75       210\n",
      "           3       0.86      0.85      0.86       210\n",
      "           4       0.67      0.59      0.63       210\n",
      "           5       0.54      0.70      0.61       210\n",
      "           6       0.57      0.46      0.51       210\n",
      "           7       0.63      0.89      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   5   1   5  47  15  10]\n",
      " [  0 152  10  12  20  14   2]\n",
      " [  2   4 178   8   9   8   1]\n",
      " [  6   4   9 140  29  11  11]\n",
      " [ 13  18   0  15 143  11  10]\n",
      " [  2   9   8  17   9  98  67]\n",
      " [  0   0   0   4   2  15 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.60      0.71       210\n",
      "           2       0.79      0.72      0.76       210\n",
      "           3       0.86      0.85      0.86       210\n",
      "           4       0.70      0.67      0.68       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.57      0.47      0.51       210\n",
      "           7       0.65      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   3   0   8  46  21   5]\n",
      " [  0 153   8  14  18  12   5]\n",
      " [  3   5 181   8   7   6   0]\n",
      " [  5   4   7 136  32  18   8]\n",
      " [ 12  16   1  18 146   4  13]\n",
      " [  5   7  12  16   6 101  63]\n",
      " [  0   0   0   2   3  16 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.87      0.86      0.86       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.57      0.70      0.62       210\n",
      "           6       0.57      0.48      0.52       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   3   0   9  48  20   5]\n",
      " [  0 149   8  12  26  12   3]\n",
      " [  1   4 180  12   8   4   1]\n",
      " [  6   4   7 135  33  18   7]\n",
      " [ 11  15   3  11 151   6  13]\n",
      " [  4   8   6  17   7 104  64]\n",
      " [  1   2   0   2   5  20 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.81      0.71      0.75       210\n",
      "           3       0.88      0.86      0.87       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.54      0.72      0.62       210\n",
      "           6       0.57      0.50      0.53       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   2   0   3  47  21   5]\n",
      " [  1 148   8  16  21  13   3]\n",
      " [  1   5 179  13   8   4   0]\n",
      " [  6   6   6 145  25  13   9]\n",
      " [ 13  18   0  12 144  10  13]\n",
      " [  5  10   7  14   8 103  63]\n",
      " [  0   0   0   3   4  13 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.63      0.72       210\n",
      "           2       0.78      0.70      0.74       210\n",
      "           3       0.90      0.85      0.87       210\n",
      "           4       0.70      0.69      0.70       210\n",
      "           5       0.56      0.69      0.62       210\n",
      "           6       0.58      0.49      0.53       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7006802721088435\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   3   0   3  50  19   4]\n",
      " [  0 158   5  15  16  13   3]\n",
      " [  1   9 178   9   6   6   1]\n",
      " [  3   6   5 140  30  19   7]\n",
      " [ 16  12   1  19 143   6  13]\n",
      " [  5   7   6  22   6 100  64]\n",
      " [  0   0   0   1   5  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.62      0.72       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.91      0.85      0.88       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.56      0.68      0.61       210\n",
      "           6       0.53      0.48      0.50       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   4   0   5  42  16   6]\n",
      " [  0 158   7  12  16  14   3]\n",
      " [  2   5 183   9   5   6   0]\n",
      " [  6   5   8 137  33  14   7]\n",
      " [ 16  16   1  22 137   5  13]\n",
      " [  4   3   6  18   6 113  60]\n",
      " [  0   1   0   1   2  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.65      0.73       210\n",
      "           2       0.82      0.75      0.79       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.57      0.65      0.61       210\n",
      "           6       0.60      0.54      0.57       210\n",
      "           7       0.68      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7136054421768707\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   0   2  46  17   7]\n",
      " [  0 154   7  12  21  14   2]\n",
      " [  1   6 183  10   5   5   0]\n",
      " [  5   7   7 135  29  19   8]\n",
      " [ 14  14   2  16 148   3  13]\n",
      " [  3   5   9  22   7 107  57]\n",
      " [  1   0   0   2   4  15 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.64      0.73       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.88      0.87      0.88       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.57      0.70      0.63       210\n",
      "           6       0.59      0.51      0.55       210\n",
      "           7       0.68      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.717687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   2   0   7  46  22   4]\n",
      " [  1 157   6  11  19  14   2]\n",
      " [  4   6 185   7   3   4   1]\n",
      " [  4   4   4 150  27  14   7]\n",
      " [ 15  16   1  16 143   7  12]\n",
      " [  3   3   7  18   8 110  61]\n",
      " [  0   0   0   2   5  22 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.70       210\n",
      "           2       0.84      0.75      0.79       210\n",
      "           3       0.91      0.88      0.90       210\n",
      "           4       0.71      0.71      0.71       210\n",
      "           5       0.57      0.68      0.62       210\n",
      "           6       0.57      0.52      0.55       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   4   0   5  43  21   8]\n",
      " [  1 152   7  14  20  14   2]\n",
      " [  3   4 185  10   5   3   0]\n",
      " [  5   6   6 141  29  17   6]\n",
      " [ 20  16   1  14 141   7  11]\n",
      " [  6   6   7  15   7 118  51]\n",
      " [  0   0   0   5   2  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.61      0.69       210\n",
      "           2       0.81      0.72      0.76       210\n",
      "           3       0.90      0.88      0.89       210\n",
      "           4       0.69      0.67      0.68       210\n",
      "           5       0.57      0.67      0.62       210\n",
      "           6       0.58      0.56      0.57       210\n",
      "           7       0.70      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   4   0   1  47  19   8]\n",
      " [  0 156   8  13  16  15   2]\n",
      " [  3   9 182   8   4   3   1]\n",
      " [  7   5   7 140  28  17   6]\n",
      " [ 16  18   1  19 138   8  10]\n",
      " [  3   8   6  18   5 121  49]\n",
      " [  0   0   0   3   3  27 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.71       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.69      0.67      0.68       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.58      0.58      0.58       210\n",
      "           7       0.70      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   5   0   3  45  15  10]\n",
      " [  2 157  10  10  14  15   2]\n",
      " [  2   8 182  11   2   4   1]\n",
      " [  5   6   7 142  29  13   8]\n",
      " [ 15  16   1  16 143   9  10]\n",
      " [  6   6   5  20   8 112  53]\n",
      " [  0   0   0   3   5  25 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       210\n",
      "           2       0.79      0.75      0.77       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.58      0.68      0.63       210\n",
      "           6       0.58      0.53      0.56       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7224489795918367\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   4   0   2  45  13   9]\n",
      " [  1 156   9   8  19  14   3]\n",
      " [  1   6 185   9   5   4   0]\n",
      " [  4   5   7 147  26  13   8]\n",
      " [ 15  15   1  16 145   9   9]\n",
      " [  3   6   7  17   7 115  55]\n",
      " [  0   0   0   2   5  26 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.65      0.74       210\n",
      "           2       0.81      0.74      0.78       210\n",
      "           3       0.89      0.88      0.88       210\n",
      "           4       0.73      0.70      0.72       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.59      0.55      0.57       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5231292517006803\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 92  10  11   0  56  24  17]\n",
      " [  0 125  26   5  40   9   5]\n",
      " [ 15  13 166   3   9   3   1]\n",
      " [  9  14  26  48  53  29  31]\n",
      " [ 18  26   0   4 118   9  35]\n",
      " [  3  11  23   9  17  75  72]\n",
      " [  0   6   1   3  10  45 145]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.44      0.53       210\n",
      "           2       0.61      0.60      0.60       210\n",
      "           3       0.66      0.79      0.72       210\n",
      "           4       0.67      0.23      0.34       210\n",
      "           5       0.39      0.56      0.46       210\n",
      "           6       0.39      0.36      0.37       210\n",
      "           7       0.47      0.69      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.51      1470\n",
      "weighted avg       0.55      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_vbert.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7578231292517007\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[162   1   1   5  33   7   1]\n",
      " [  1 169   6   6  16   8   4]\n",
      " [  0   2 192   7   4   5   0]\n",
      " [  4   5   3 165   9  18   6]\n",
      " [ 32   9   3  14 141   5   6]\n",
      " [  7   9   5  21   5 123  40]\n",
      " [  3   2   0   1   8  34 162]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.77       210\n",
      "           2       0.86      0.80      0.83       210\n",
      "           3       0.91      0.91      0.91       210\n",
      "           4       0.75      0.79      0.77       210\n",
      "           5       0.65      0.67      0.66       210\n",
      "           6       0.61      0.59      0.60       210\n",
      "           7       0.74      0.77      0.76       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6387755102040816\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   5   2   6  24   6   6]\n",
      " [  6 172  13   6  11   1   1]\n",
      " [ 11   3 190   5   0   1   0]\n",
      " [ 30  17  16 123  12   4   8]\n",
      " [ 48  32  14  21  87   0   8]\n",
      " [ 47  28  20  14   8  56  37]\n",
      " [ 16   6   7   5  10  16 150]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.77      0.61       210\n",
      "           2       0.65      0.82      0.73       210\n",
      "           3       0.73      0.90      0.81       210\n",
      "           4       0.68      0.59      0.63       210\n",
      "           5       0.57      0.41      0.48       210\n",
      "           6       0.67      0.27      0.38       210\n",
      "           7       0.71      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.62      1470\n",
      "weighted avg       0.65      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   5   3   5  25   6   5]\n",
      " [  5 175  12   5  11   0   2]\n",
      " [  9   2 193   5   0   1   0]\n",
      " [ 24  11  18 128  15   3  11]\n",
      " [ 49  34  11  22  81   1  12]\n",
      " [ 41  23  23  16   6  62  39]\n",
      " [ 12   4   5   2  10  24 153]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.77      0.63       210\n",
      "           2       0.69      0.83      0.75       210\n",
      "           3       0.73      0.92      0.81       210\n",
      "           4       0.70      0.61      0.65       210\n",
      "           5       0.55      0.39      0.45       210\n",
      "           6       0.64      0.30      0.40       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.63      1470\n",
      "weighted avg       0.65      0.65      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   4   4   4  32   5   4]\n",
      " [  4 171  16   8   8   1   2]\n",
      " [ 10   2 192   5   0   1   0]\n",
      " [ 16  14  17 131  16   5  11]\n",
      " [ 46  30  13  20  89   2  10]\n",
      " [ 36  24  20  18   7  64  41]\n",
      " [ 10   6   5   3   9  23 154]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.75      0.64       210\n",
      "           2       0.68      0.81      0.74       210\n",
      "           3       0.72      0.91      0.81       210\n",
      "           4       0.69      0.62      0.66       210\n",
      "           5       0.55      0.42      0.48       210\n",
      "           6       0.63      0.30      0.41       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   4   3   4  31   5   6]\n",
      " [  5 175  14   5   8   1   2]\n",
      " [ 10   2 192   5   0   1   0]\n",
      " [ 20  14  20 127  15   4  10]\n",
      " [ 46  32  14  20  86   2  10]\n",
      " [ 29  25  25  18  10  61  42]\n",
      " [  9   6   6   3   9  16 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.75      0.65       210\n",
      "           2       0.68      0.83      0.75       210\n",
      "           3       0.70      0.91      0.79       210\n",
      "           4       0.70      0.60      0.65       210\n",
      "           5       0.54      0.41      0.47       210\n",
      "           6       0.68      0.29      0.41       210\n",
      "           7       0.70      0.77      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.63      1470\n",
      "weighted avg       0.65      0.65      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158   4   4   4  27   8   5]\n",
      " [  4 176  12   6   9   1   2]\n",
      " [ 11   1 191   6   0   1   0]\n",
      " [ 17  12  21 127  17   7   9]\n",
      " [ 46  30  15  21  87   3   8]\n",
      " [ 31  22  24  17   7  60  49]\n",
      " [  8   7   5   3   7  15 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.75      0.65       210\n",
      "           2       0.70      0.84      0.76       210\n",
      "           3       0.70      0.91      0.79       210\n",
      "           4       0.69      0.60      0.64       210\n",
      "           5       0.56      0.41      0.48       210\n",
      "           6       0.63      0.29      0.39       210\n",
      "           7       0.69      0.79      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.64      1470\n",
      "weighted avg       0.65      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   4   4   4  29   6   6]\n",
      " [  3 175  13   6  10   1   2]\n",
      " [ 11   2 191   5   0   1   0]\n",
      " [ 19  13  24 124  15   5  10]\n",
      " [ 46  31  15  16  90   1  11]\n",
      " [ 29  21  24  17   8  61  50]\n",
      " [ 11   6   4   1   4  18 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.75      0.65       210\n",
      "           2       0.69      0.83      0.76       210\n",
      "           3       0.69      0.91      0.79       210\n",
      "           4       0.72      0.59      0.65       210\n",
      "           5       0.58      0.43      0.49       210\n",
      "           6       0.66      0.29      0.40       210\n",
      "           7       0.68      0.79      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.64      1470\n",
      "weighted avg       0.65      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5476190476190477\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 88   3  12   8  43  15  41]\n",
      " [  1 120  21  16  24  20   8]\n",
      " [  9   7 161  10   4  13   6]\n",
      " [  6   6  15  94  16  25  48]\n",
      " [ 18  18   0  21 106   9  38]\n",
      " [  3   9  11  21   5  71  90]\n",
      " [  0   2   0   3   2  38 165]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.42      0.53       210\n",
      "           2       0.73      0.57      0.64       210\n",
      "           3       0.73      0.77      0.75       210\n",
      "           4       0.54      0.45      0.49       210\n",
      "           5       0.53      0.50      0.52       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.42      0.79      0.54       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.55      1470\n",
      "weighted avg       0.57      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 88   2  12  11  40  29  28]\n",
      " [  1 121  14  11  33  24   6]\n",
      " [ 10   3 163  14   3  14   3]\n",
      " [  6   9  18  80  27  28  42]\n",
      " [ 17  19   0  20 107  17  30]\n",
      " [  8  15  13  20   7  66  81]\n",
      " [  0   7   0   3   3  36 161]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.42      0.52       210\n",
      "           2       0.69      0.58      0.63       210\n",
      "           3       0.74      0.78      0.76       210\n",
      "           4       0.50      0.38      0.43       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.31      0.31      0.31       210\n",
      "           7       0.46      0.77      0.57       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.53      1470\n",
      "weighted avg       0.55      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7360544217687075\n",
      "Confusion Matrix of SVM is:\n",
      " [[164   2   0   8  26   9   1]\n",
      " [  1 168   7  11  16   4   3]\n",
      " [  2   7 192   2   2   5   0]\n",
      " [  9   9   6 161  10  14   1]\n",
      " [ 38  12   3  10 139   8   0]\n",
      " [ 15  22   6  21   3 112  31]\n",
      " [  9   3   0   6   5  41 146]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.75      0.80      0.78       210\n",
      "           3       0.90      0.91      0.91       210\n",
      "           4       0.74      0.77      0.75       210\n",
      "           5       0.69      0.66      0.68       210\n",
      "           6       0.58      0.53      0.56       210\n",
      "           7       0.80      0.70      0.74       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.73      1470\n",
      "weighted avg       0.74      0.74      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7285714285714285\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   2   0   1  36  29   4]\n",
      " [  0 167   4   8  17  13   1]\n",
      " [  5   1 181   7   5  11   0]\n",
      " [  4   5   6 148  19  19   9]\n",
      " [ 13  13   2  15 138  18  11]\n",
      " [  5   6   3  11   8 124  53]\n",
      " [  0   2   0   1   4  28 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.85      0.80      0.82       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.77      0.70      0.74       210\n",
      "           5       0.61      0.66      0.63       210\n",
      "           6       0.51      0.59      0.55       210\n",
      "           7       0.69      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7673469387755102\n",
      "Confusion Matrix of SVM is:\n",
      " [[155   2   0   3  32  15   3]\n",
      " [  0 173   6  12  11   6   2]\n",
      " [  2   0 194   5   4   5   0]\n",
      " [  2   5   7 162  10  16   8]\n",
      " [ 22  14   1  19 139   7   8]\n",
      " [  5  10   2  13   2 132  46]\n",
      " [  0   1   0   0   4  32 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.78       210\n",
      "           2       0.84      0.82      0.83       210\n",
      "           3       0.92      0.92      0.92       210\n",
      "           4       0.76      0.77      0.76       210\n",
      "           5       0.69      0.66      0.67       210\n",
      "           6       0.62      0.63      0.62       210\n",
      "           7       0.72      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[155   1   1   7  24  21   1]\n",
      " [  0 163  13   9  12  12   1]\n",
      " [  1   2 196   4   1   6   0]\n",
      " [  4   5   9 143  12  30   7]\n",
      " [ 32  18   4  26 112  10   8]\n",
      " [ 13  11   9  18   2 114  43]\n",
      " [  4   0   0   0   5  28 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.81      0.78      0.80       210\n",
      "           3       0.84      0.93      0.89       210\n",
      "           4       0.69      0.68      0.69       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.52      0.54      0.53       210\n",
      "           7       0.74      0.82      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23605442176870747\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  19   0   0   0 191]\n",
      " [  0   0  18   0   0   0 192]\n",
      " [  0   0 144   0   0   0  66]\n",
      " [  0   0  26   0   0   0 184]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0   7   0   0   0 203]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.60      0.69      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.97      0.28       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.11      0.24      0.13      1470\n",
      "weighted avg       0.11      0.24      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 18   0   1   0  92   0  99]\n",
      " [  7   0  11   0 140   0  52]\n",
      " [  5   0 139   0  32   0  34]\n",
      " [  7   0  19   0 102   0  82]\n",
      " [  2   0   4   0 158   0  46]\n",
      " [ 12   0   8   0  45   0 145]\n",
      " [  6   0   1   0  32   0 171]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.09      0.13       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.76      0.66      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.26      0.75      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.27      0.81      0.41       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.23      0.33      0.23      1470\n",
      "weighted avg       0.23      0.33      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83   9   1   0  83   2  32]\n",
      " [ 15  96   9   0  44   8  38]\n",
      " [ 19  19 136   0  13   8  15]\n",
      " [ 48  35  13   0  67  11  36]\n",
      " [ 25  27   1   0 131   4  22]\n",
      " [ 62  12   5   0  33   5  93]\n",
      " [ 26   7   0   0  25   4 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.40      0.34       210\n",
      "           2       0.47      0.46      0.46       210\n",
      "           3       0.82      0.65      0.73       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.33      0.62      0.43       210\n",
      "           6       0.12      0.02      0.04       210\n",
      "           7       0.39      0.70      0.50       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.35      0.41      0.36      1470\n",
      "weighted avg       0.35      0.41      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  13   1  25  49   4  23]\n",
      " [  6 102   7  36  41   7  11]\n",
      " [  4  12 135  37  12   7   3]\n",
      " [ 22  11   8  73  62   5  29]\n",
      " [ 36  20   0  21 111   2  20]\n",
      " [ 22  29   5  45  27  12  70]\n",
      " [ 15  15   0  14  23   4 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.45      0.46       210\n",
      "           2       0.50      0.49      0.50       210\n",
      "           3       0.87      0.64      0.74       210\n",
      "           4       0.29      0.35      0.32       210\n",
      "           5       0.34      0.53      0.41       210\n",
      "           6       0.29      0.06      0.10       210\n",
      "           7       0.47      0.66      0.55       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.44      1470\n",
      "weighted avg       0.46      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88   5   1  44  41  14  17]\n",
      " [  2 121   7  38  23  12   7]\n",
      " [  4  29 136  30   2   7   2]\n",
      " [ 13  21   7 109  24  23  13]\n",
      " [ 19  21   0  64  83  10  13]\n",
      " [ 19  25   5  60  11  37  53]\n",
      " [ 14   9   1  35   4  25 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.42      0.48       210\n",
      "           2       0.52      0.58      0.55       210\n",
      "           3       0.87      0.65      0.74       210\n",
      "           4       0.29      0.52      0.37       210\n",
      "           5       0.44      0.40      0.42       210\n",
      "           6       0.29      0.18      0.22       210\n",
      "           7       0.54      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.50      0.47      0.48      1470\n",
      "weighted avg       0.50      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94   5   2  21  42  27  19]\n",
      " [  6 117  14  18  37  16   2]\n",
      " [  4  14 152  18   7  11   4]\n",
      " [ 10  12  15  97  32  34  10]\n",
      " [ 24  17   4  32 104  15  14]\n",
      " [ 20  19  11  23  22  81  34]\n",
      " [  8   8   1  14  11  56 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.45      0.50       210\n",
      "           2       0.61      0.56      0.58       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.43      0.46      0.45       210\n",
      "           5       0.41      0.50      0.45       210\n",
      "           6       0.34      0.39      0.36       210\n",
      "           7       0.57      0.53      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.52      1470\n",
      "weighted avg       0.53      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 87  14   2  14  45  29  19]\n",
      " [  4 138  11  15  18  17   7]\n",
      " [  2   7 151  19  13  14   4]\n",
      " [ 11  26   8  92  26  36  11]\n",
      " [ 22  46   1  25  88  12  16]\n",
      " [ 15  27   9  27  15  70  47]\n",
      " [  5  20   0  16   5  39 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.41      0.49       210\n",
      "           2       0.50      0.66      0.57       210\n",
      "           3       0.83      0.72      0.77       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.42      0.42      0.42       210\n",
      "           6       0.32      0.33      0.33       210\n",
      "           7       0.55      0.60      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91   8   3  26  40  27  15]\n",
      " [  6 123  11  21  22  12  15]\n",
      " [  9   4 153  26   3  12   3]\n",
      " [  8  18   5  92  30  33  24]\n",
      " [ 22  27   2  29  94  12  24]\n",
      " [ 17  17  11  29  25  64  47]\n",
      " [  7  10   2   9  16  36 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.43      0.49       210\n",
      "           2       0.59      0.59      0.59       210\n",
      "           3       0.82      0.73      0.77       210\n",
      "           4       0.40      0.44      0.42       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.33      0.30      0.32       210\n",
      "           7       0.50      0.62      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88   9   5  25  46  22  15]\n",
      " [  7 120  10  26  22  13  12]\n",
      " [  5   4 159  25   2  13   2]\n",
      " [ 18  13   8  97  22  35  17]\n",
      " [ 25  23   3  42  83  14  20]\n",
      " [ 21  21   9  31  14  66  48]\n",
      " [  7  11   2  12  13  35 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.42      0.46       210\n",
      "           2       0.60      0.57      0.58       210\n",
      "           3       0.81      0.76      0.78       210\n",
      "           4       0.38      0.46      0.41       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.33      0.31      0.32       210\n",
      "           7       0.53      0.62      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  10   4  17  45  28  11]\n",
      " [  8 122   9  16  28  14  13]\n",
      " [  4   6 164  10  11  13   2]\n",
      " [ 16  19  10  76  41  33  15]\n",
      " [ 28  31   3  29  87  11  21]\n",
      " [ 24  19   8  23  23  60  53]\n",
      " [ 12  14   4  14  11  37 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.45      0.48       210\n",
      "           2       0.55      0.58      0.57       210\n",
      "           3       0.81      0.78      0.80       210\n",
      "           4       0.41      0.36      0.38       210\n",
      "           5       0.35      0.41      0.38       210\n",
      "           6       0.31      0.29      0.30       210\n",
      "           7       0.51      0.56      0.53       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   9   4  19  47  19  11]\n",
      " [  4 127  10  18  21  16  14]\n",
      " [  7   7 159  11   8  16   2]\n",
      " [ 26  19  11  88  29  23  14]\n",
      " [ 30  27   4  28  84  18  19]\n",
      " [ 20  24  11  24  20  63  48]\n",
      " [ 12  10   1  12  14  40 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.48      0.49       210\n",
      "           2       0.57      0.60      0.59       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.53      0.58      0.55       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107   9   2  23  39  20  10]\n",
      " [  6 121  12  17  23  17  14]\n",
      " [ 13   4 159  12   4  16   2]\n",
      " [ 28  18  10  83  28  30  13]\n",
      " [ 40  28   3  30  74  14  21]\n",
      " [ 21  17  10  26  20  63  53]\n",
      " [ 15  16   3  13  10  36 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.51      0.49       210\n",
      "           2       0.57      0.58      0.57       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.51      0.56      0.53       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49047619047619045\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  11   6  16  38  17  12]\n",
      " [  9 120  12  22  23  10  14]\n",
      " [  7   5 164  16   5  11   2]\n",
      " [ 21  21  12  84  29  28  15]\n",
      " [ 32  33   2  31  74  17  21]\n",
      " [ 26  19   8  31  14  68  44]\n",
      " [ 12  13   2  16  13  53 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.52      0.52       210\n",
      "           2       0.54      0.57      0.56       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.39      0.40      0.39       210\n",
      "           5       0.38      0.35      0.36       210\n",
      "           6       0.33      0.32      0.33       210\n",
      "           7       0.48      0.48      0.48       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99   8   4  21  46  21  11]\n",
      " [  7 127   7  18  24  15  12]\n",
      " [  6   6 156  14  12  13   3]\n",
      " [ 29  23  10  80  25  30  13]\n",
      " [ 33  30   5  32  79  13  18]\n",
      " [ 16  24  11  28  19  63  49]\n",
      " [  8  10   2  18  11  45 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.47      0.49       210\n",
      "           2       0.56      0.60      0.58       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.37      0.38      0.37       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.52      0.55      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8   7  23  39  17  16]\n",
      " [  7 127  11  19  25   6  15]\n",
      " [  8   5 164  12   6  13   2]\n",
      " [ 27  22  12  83  27  26  13]\n",
      " [ 34  27   3  35  74  14  23]\n",
      " [ 21  21  10  27  18  65  48]\n",
      " [ 14  13   3  17   9  43 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.48      0.48       210\n",
      "           2       0.57      0.60      0.59       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.35      0.31      0.33       210\n",
      "           7       0.49      0.53      0.51       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48299319727891155\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103  12   5  24  34  19  13]\n",
      " [ 10 122  12  13  25  15  13]\n",
      " [  9   5 162  13   5  14   2]\n",
      " [ 20  22  14  82  25  31  16]\n",
      " [ 37  31   3  34  72  16  17]\n",
      " [ 18  24  14  26  20  59  49]\n",
      " [ 11  14   1  17  13  44 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.49      0.49       210\n",
      "           2       0.53      0.58      0.55       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.37      0.34      0.36       210\n",
      "           6       0.30      0.28      0.29       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  10   4  19  43  20  12]\n",
      " [  7 119  10  16  26  13  19]\n",
      " [  8   8 164  12   6  10   2]\n",
      " [ 24  17   9  83  30  28  19]\n",
      " [ 39  30   3  32  72  14  20]\n",
      " [ 25  24  13  25  11  66  46]\n",
      " [ 19   8   1  16  15  39 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.49      0.47       210\n",
      "           2       0.55      0.57      0.56       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.35      0.31      0.33       210\n",
      "           7       0.49      0.53      0.51       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  10   4  21  38  23  13]\n",
      " [  7 120   9  18  26  14  16]\n",
      " [  8   6 164  11   5  14   2]\n",
      " [ 24  18   8  81  32  33  14]\n",
      " [ 37  31   3  34  73  13  19]\n",
      " [ 25  20  11  26  20  61  47]\n",
      " [ 16   8   3  17  12  41 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.56      0.57      0.57       210\n",
      "           3       0.81      0.78      0.80       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.35      0.35      0.35       210\n",
      "           6       0.31      0.29      0.30       210\n",
      "           7       0.50      0.54      0.52       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.48      1470\n",
      "weighted avg       0.48      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4850340136054422\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  11   3  19  43  19  13]\n",
      " [  6 122  10  16  25  15  16]\n",
      " [  7   8 162  13   4  13   3]\n",
      " [ 21  17  10  81  29  35  17]\n",
      " [ 37  33   2  33  70  15  20]\n",
      " [ 22  24  11  24  13  68  48]\n",
      " [ 18   8   1  19  15  41 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.49      0.48       210\n",
      "           2       0.55      0.58      0.56       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.35      0.33      0.34       210\n",
      "           6       0.33      0.32      0.33       210\n",
      "           7       0.48      0.51      0.50       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.48      1470\n",
      "weighted avg       0.49      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  11   4  20  44  19  12]\n",
      " [  5 121   7  16  29  15  17]\n",
      " [  7   8 160  12  10  10   3]\n",
      " [ 26  16   7  81  31  34  15]\n",
      " [ 34  32   3  35  74  14  18]\n",
      " [ 24  25  10  28  19  59  45]\n",
      " [ 17   9   2  15  17  41 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.48      0.47       210\n",
      "           2       0.55      0.58      0.56       210\n",
      "           3       0.83      0.76      0.79       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.33      0.35      0.34       210\n",
      "           6       0.31      0.28      0.29       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 29   0  21   0  71   0  89]\n",
      " [  4  66  43   0  67   3  27]\n",
      " [  1   3 179   2   9   0  16]\n",
      " [  0   6  39   4  52   1 108]\n",
      " [  1   8  10   0 126   0  65]\n",
      " [  4   4  26   0  27   1 148]\n",
      " [  0   1   3   0   5   0 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.14      0.23       210\n",
      "           2       0.75      0.31      0.44       210\n",
      "           3       0.56      0.85      0.67       210\n",
      "           4       0.67      0.02      0.04       210\n",
      "           5       0.35      0.60      0.44       210\n",
      "           6       0.20      0.00      0.01       210\n",
      "           7       0.31      0.96      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.51      0.41      0.33      1470\n",
      "weighted avg       0.51      0.41      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92   2   1   0  57   1  57]\n",
      " [  3 129  18   0  26   7  27]\n",
      " [  6   5 169   0  11   2  17]\n",
      " [ 19  19  23   8  57   3  81]\n",
      " [ 17  23   0   0 124   0  46]\n",
      " [ 16  11  19   3  19   1 141]\n",
      " [  0   1   0   0   4   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.44      0.51       210\n",
      "           2       0.68      0.61      0.65       210\n",
      "           3       0.73      0.80      0.77       210\n",
      "           4       0.73      0.04      0.07       210\n",
      "           5       0.42      0.59      0.49       210\n",
      "           6       0.07      0.00      0.01       210\n",
      "           7       0.36      0.98      0.52       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.43      1470\n",
      "weighted avg       0.51      0.50      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   3   0   2  38   6  42]\n",
      " [  4 147   7   7  22   9  14]\n",
      " [  8   4 165  13   3   8   9]\n",
      " [ 25  12  17  30  54   5  67]\n",
      " [ 27  23   0   9 107   1  43]\n",
      " [ 15  14  11   7  14  23 126]\n",
      " [  1   1   0   0   4   1 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.57      0.58       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.44      0.14      0.22       210\n",
      "           5       0.44      0.51      0.47       210\n",
      "           6       0.43      0.11      0.17       210\n",
      "           7       0.40      0.97      0.57       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.50      1470\n",
      "weighted avg       0.55      0.54      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   1   0   1  40  14  35]\n",
      " [  0 139   8   9  27  19   8]\n",
      " [  6   3 168  15   4  12   2]\n",
      " [ 17  10  10  70  34  16  53]\n",
      " [ 31  21   0  13 104   5  36]\n",
      " [ 10  11   8  14  13  33 121]\n",
      " [  0   0   0   1   3   3 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.57      0.61       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.57      0.33      0.42       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.32      0.16      0.21       210\n",
      "           7       0.44      0.97      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.55      1470\n",
      "weighted avg       0.58      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   2   0   4  37  14  30]\n",
      " [  1 142  10  11  28  12   6]\n",
      " [  2   1 174  15   6  10   2]\n",
      " [ 13   6   9 102  21  19  40]\n",
      " [ 26  17   0  20 106  10  31]\n",
      " [ 12   8   5  13  12  54 106]\n",
      " [  0   1   0   0   1   5 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.59      0.64       210\n",
      "           2       0.80      0.68      0.73       210\n",
      "           3       0.88      0.83      0.85       210\n",
      "           4       0.62      0.49      0.54       210\n",
      "           5       0.50      0.50      0.50       210\n",
      "           6       0.44      0.26      0.32       210\n",
      "           7       0.49      0.97      0.65       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   1   0   5  36  24  25]\n",
      " [  0 143  10   9  27  17   4]\n",
      " [  4   2 174  11   6  12   1]\n",
      " [  5   4   7 119  15  30  30]\n",
      " [ 22  15   0  21 113   9  30]\n",
      " [  5   5   6  14  12  67 101]\n",
      " [  0   0   0   0   2  13 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.57      0.65       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.88      0.83      0.86       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.54      0.54      0.54       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.51      0.93      0.65       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   1   0   5  40  23  20]\n",
      " [  0 148   8   9  26  14   5]\n",
      " [  3   3 179  12   1  11   1]\n",
      " [  3   5   8 123  19  27  25]\n",
      " [ 19  18   0  16 112  17  28]\n",
      " [  5   8   4  19   9  79  86]\n",
      " [  0   0   0   1   3  13 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.58      0.67       210\n",
      "           2       0.81      0.70      0.75       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.53      0.53      0.53       210\n",
      "           6       0.43      0.38      0.40       210\n",
      "           7       0.54      0.92      0.68       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   2   0   8  40  23  16]\n",
      " [  0 147   7  12  28  13   3]\n",
      " [  3   4 179  13   1  10   0]\n",
      " [  4   6   8 136  14  21  21]\n",
      " [ 21  18   0  20 115  10  26]\n",
      " [  4  10   5  17   7  85  82]\n",
      " [  0   1   0   2   3  18 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.58      0.67       210\n",
      "           2       0.78      0.70      0.74       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.65      0.65      0.65       210\n",
      "           5       0.55      0.55      0.55       210\n",
      "           6       0.47      0.40      0.44       210\n",
      "           7       0.56      0.89      0.68       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   1   0   7  42  24  15]\n",
      " [  0 151   7   8  29  13   2]\n",
      " [  2   4 177  15   3   8   1]\n",
      " [  4   6   8 133  15  24  20]\n",
      " [ 19  15   0  24 117  12  23]\n",
      " [  5   6   2  18  13  83  83]\n",
      " [  0   0   0   1   3  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.58      0.67       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.91      0.84      0.88       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.53      0.56      0.54       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.56      0.87      0.68       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   1   0   7  44  23  15]\n",
      " [  0 152   7  10  28  12   1]\n",
      " [  4   1 183   9   4   7   2]\n",
      " [  4   3   6 141  13  22  21]\n",
      " [ 18  13   0  27 123   8  21]\n",
      " [  6   9   2  18   6  98  71]\n",
      " [  0   0   0   2   3  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.85      0.72      0.78       210\n",
      "           3       0.92      0.87      0.90       210\n",
      "           4       0.66      0.67      0.67       210\n",
      "           5       0.56      0.59      0.57       210\n",
      "           6       0.52      0.47      0.49       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   3   0   4  43  21  17]\n",
      " [  0 149   7  12  28  12   2]\n",
      " [  4   0 184  11   3   7   1]\n",
      " [  3   3   7 134  19  26  18]\n",
      " [ 16  14   1  24 128   8  19]\n",
      " [  5   7   4  14   9  98  73]\n",
      " [  0   1   0   2   3  27 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.58      0.68       210\n",
      "           2       0.84      0.71      0.77       210\n",
      "           3       0.91      0.88      0.89       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.55      0.61      0.58       210\n",
      "           6       0.49      0.47      0.48       210\n",
      "           7       0.58      0.84      0.68       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   2   0   8  45  18  16]\n",
      " [  2 150   7  10  25  14   2]\n",
      " [  3   0 183  11   3   8   2]\n",
      " [  3   5   5 140  19  23  15]\n",
      " [ 22  16   0  26 114  13  19]\n",
      " [  6   9   4  18   8  98  67]\n",
      " [  0   1   0   3   2  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.58      0.66       210\n",
      "           2       0.82      0.71      0.76       210\n",
      "           3       0.92      0.87      0.89       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.53      0.54      0.54       210\n",
      "           6       0.51      0.47      0.49       210\n",
      "           7       0.60      0.88      0.71       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   1   0   8  42  21  14]\n",
      " [  0 152   6  10  26  14   2]\n",
      " [  5   1 185   8   3   6   2]\n",
      " [  2   5   6 142  17  23  15]\n",
      " [ 16  15   1  21 120  14  23]\n",
      " [  4   9   4  17   9 110  57]\n",
      " [  0   0   0   3   3  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.55      0.57      0.56       210\n",
      "           6       0.53      0.52      0.53       210\n",
      "           7       0.62      0.87      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   8  37  24  14]\n",
      " [  0 154   7  12  26   9   2]\n",
      " [  3   2 185   9   3   8   0]\n",
      " [  4   5   6 143  18  19  15]\n",
      " [ 16  15   0  18 129  15  17]\n",
      " [  6   6   4  18   9  96  71]\n",
      " [  1   0   0   1   3  28 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.84      0.73      0.78       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.60      0.84      0.70       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   1   0   7  45  29  10]\n",
      " [  1 155  10   8  22  13   1]\n",
      " [  3   2 183  13   0   8   1]\n",
      " [  2   5   9 136  16  24  18]\n",
      " [ 20  15   0  25 117  12  21]\n",
      " [  6   7   5  14  12  98  68]\n",
      " [  0   1   0   2   5  24 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.56      0.66       210\n",
      "           2       0.83      0.74      0.78       210\n",
      "           3       0.88      0.87      0.88       210\n",
      "           4       0.66      0.65      0.66       210\n",
      "           5       0.54      0.56      0.55       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.60      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   1   0   8  41  22  14]\n",
      " [  0 160   7  10  21  10   2]\n",
      " [  4   3 183  10   2   7   1]\n",
      " [  3   6   6 151  10  14  20]\n",
      " [ 19  19   1  28 114  10  19]\n",
      " [  8   8   6  19   7 100  62]\n",
      " [  0   2   0   0   2  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.59      0.67       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.90      0.87      0.89       210\n",
      "           4       0.67      0.72      0.69       210\n",
      "           5       0.58      0.54      0.56       210\n",
      "           6       0.56      0.48      0.51       210\n",
      "           7       0.62      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   1   0   4  43  24  14]\n",
      " [  0 158   6   7  26  11   2]\n",
      " [  4   2 185   8   1   8   2]\n",
      " [  4   7   4 142  16  17  20]\n",
      " [ 19  18   0  26 118   7  22]\n",
      " [  3   7   4  16   9 104  67]\n",
      " [  0   0   0   3   4  25 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.59      0.68       210\n",
      "           2       0.82      0.75      0.78       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.54      0.56      0.55       210\n",
      "           6       0.53      0.50      0.51       210\n",
      "           7       0.58      0.85      0.69       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   1   0   7  44  18  16]\n",
      " [  1 158   7  10  24   7   3]\n",
      " [  4   2 186   9   1   8   0]\n",
      " [  6   6   5 143  17  14  19]\n",
      " [ 20  14   0  25 119  11  21]\n",
      " [  7   7   4  15  10 103  64]\n",
      " [  0   2   0   0   2  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.59      0.67       210\n",
      "           2       0.83      0.75      0.79       210\n",
      "           3       0.92      0.89      0.90       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.55      0.57      0.56       210\n",
      "           6       0.56      0.49      0.52       210\n",
      "           7       0.60      0.87      0.71       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   8  41  20  14]\n",
      " [  0 158   7  10  25   7   3]\n",
      " [  3   2 184   9   4   8   0]\n",
      " [  4   7   6 144  17  17  15]\n",
      " [ 18  15   0  28 118   9  22]\n",
      " [  6   6   5  16  10  99  68]\n",
      " [  0   2   0   1   2  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.60      0.69       210\n",
      "           2       0.83      0.75      0.79       210\n",
      "           3       0.91      0.88      0.89       210\n",
      "           4       0.67      0.69      0.68       210\n",
      "           5       0.54      0.56      0.55       210\n",
      "           6       0.54      0.47      0.50       210\n",
      "           7       0.60      0.86      0.70       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   8  42  19  14]\n",
      " [  0 155   7   8  29   9   2]\n",
      " [  4   3 183  10   3   6   1]\n",
      " [  4   5   6 148  16  15  16]\n",
      " [ 21  15   0  30 117   8  19]\n",
      " [  8  10   5  14  13  97  63]\n",
      " [  0   2   0   0   3  27 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.60      0.68       210\n",
      "           2       0.81      0.74      0.77       210\n",
      "           3       0.91      0.87      0.89       210\n",
      "           4       0.68      0.70      0.69       210\n",
      "           5       0.52      0.56      0.54       210\n",
      "           6       0.54      0.46      0.50       210\n",
      "           7       0.61      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 83   3  13  10  41  48  12]\n",
      " [  3 126  22   7  21  28   3]\n",
      " [  7   8 169   8   1  17   0]\n",
      " [  4  12  22  74  21  52  25]\n",
      " [ 15  24   0  15 101  34  21]\n",
      " [  7  16  16  14   7  88  62]\n",
      " [  0   9   0   3   2  47 149]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.40      0.50       210\n",
      "           2       0.64      0.60      0.62       210\n",
      "           3       0.70      0.80      0.75       210\n",
      "           4       0.56      0.35      0.43       210\n",
      "           5       0.52      0.48      0.50       210\n",
      "           6       0.28      0.42      0.34       210\n",
      "           7       0.55      0.71      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//gpt_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7578231292517007\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[170   0   0   4  25  10   1]\n",
      " [  1 173   8  10  13   5   0]\n",
      " [  1   7 192   6   0   4   0]\n",
      " [  6  10   4 157  15  15   3]\n",
      " [ 20  15   4  18 146   2   5]\n",
      " [  7  17   5  13   3 113  52]\n",
      " [  2   2   0   4   3  36 163]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.81      0.82       210\n",
      "           2       0.77      0.82      0.80       210\n",
      "           3       0.90      0.91      0.91       210\n",
      "           4       0.74      0.75      0.74       210\n",
      "           5       0.71      0.70      0.70       210\n",
      "           6       0.61      0.54      0.57       210\n",
      "           7       0.73      0.78      0.75       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   5   2   5  34   6   5]\n",
      " [  4 170   7  10  15   3   1]\n",
      " [  2   9 189   5   0   4   1]\n",
      " [ 15  25  13 123  16  10   8]\n",
      " [ 32  36   5  15 117   0   5]\n",
      " [ 16  23   9  30   5  70  57]\n",
      " [  9   9   0  19   6  15 152]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.73      0.69       210\n",
      "           2       0.61      0.81      0.70       210\n",
      "           3       0.84      0.90      0.87       210\n",
      "           4       0.59      0.59      0.59       210\n",
      "           5       0.61      0.56      0.58       210\n",
      "           6       0.65      0.33      0.44       210\n",
      "           7       0.66      0.72      0.69       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   4   2   6  29  13   6]\n",
      " [  1 167   8  12  15   6   1]\n",
      " [  2   7 192   3   1   5   0]\n",
      " [ 11  19  12 130  13  16   9]\n",
      " [ 36  32   5  14 114   3   6]\n",
      " [ 13   9   8  27   6  87  60]\n",
      " [  5   0   0  16   3  31 155]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.70      0.80      0.75       210\n",
      "           3       0.85      0.91      0.88       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.63      0.54      0.58       210\n",
      "           6       0.54      0.41      0.47       210\n",
      "           7       0.65      0.74      0.69       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   2   1   9  33  12   5]\n",
      " [  1 166   7  13  15   6   2]\n",
      " [  2   8 190   3   3   3   1]\n",
      " [  9  18  13 128  17  19   6]\n",
      " [ 30  32   5  14 124   0   5]\n",
      " [  8  12  11  33   7  82  57]\n",
      " [  2   2   0  19   6  21 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72       210\n",
      "           2       0.69      0.79      0.74       210\n",
      "           3       0.84      0.90      0.87       210\n",
      "           4       0.58      0.61      0.60       210\n",
      "           5       0.60      0.59      0.60       210\n",
      "           6       0.57      0.39      0.46       210\n",
      "           7       0.68      0.76      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   1   1   7  28  16   7]\n",
      " [  1 170   8  10  14   5   2]\n",
      " [  1   7 193   2   2   4   1]\n",
      " [ 10  15  15 128  16  16  10]\n",
      " [ 37  34   6  11 117   0   5]\n",
      " [  8  10  11  28   6  85  62]\n",
      " [  1   1   0  14   6  27 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.72       210\n",
      "           2       0.71      0.81      0.76       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.64      0.61      0.62       210\n",
      "           5       0.62      0.56      0.59       210\n",
      "           6       0.56      0.40      0.47       210\n",
      "           7       0.65      0.77      0.70       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.68      1470\n",
      "weighted avg       0.67      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   1   1   8  30  16   6]\n",
      " [  1 163   9  14  14   7   2]\n",
      " [  1   8 192   2   2   4   1]\n",
      " [ 13  15  15 124  17  15  11]\n",
      " [ 34  31   7   9 122   0   7]\n",
      " [  9  10  11  28   6  76  70]\n",
      " [  1   1   0  13   5  25 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.71      0.78      0.74       210\n",
      "           3       0.82      0.91      0.86       210\n",
      "           4       0.63      0.59      0.61       210\n",
      "           5       0.62      0.58      0.60       210\n",
      "           6       0.53      0.36      0.43       210\n",
      "           7       0.63      0.79      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   2   1   7  31  16   5]\n",
      " [  1 168   9  14  10   7   1]\n",
      " [  1   8 192   3   1   4   1]\n",
      " [ 11  15  19 115  20  14  16]\n",
      " [ 39  31   7   8 119   0   6]\n",
      " [  6   7  10  23   7  84  73]\n",
      " [  1   1   0  12   4  24 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.72      0.80      0.76       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.62      0.57      0.59       210\n",
      "           6       0.56      0.40      0.47       210\n",
      "           7       0.62      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[115   0   1   5  51  26  12]\n",
      " [  1 138  11  15  19  22   4]\n",
      " [ 11   5 161  11   1  20   1]\n",
      " [  6  12  23  75  30  37  27]\n",
      " [ 24  28   4   9 124   7  14]\n",
      " [  3   5   2  14   5  92  89]\n",
      " [  0   0   0   1   0  29 180]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.55      0.62       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.80      0.77      0.78       210\n",
      "           4       0.58      0.36      0.44       210\n",
      "           5       0.54      0.59      0.56       210\n",
      "           6       0.39      0.44      0.42       210\n",
      "           7       0.55      0.86      0.67       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5836734693877551\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[117   0   1   5  51  27   9]\n",
      " [  1 130  13  16  22  26   2]\n",
      " [ 11   5 158  16   0  19   1]\n",
      " [  5  16  23  63  37  45  21]\n",
      " [ 29  26   6  10 118   6  15]\n",
      " [  3   5   4  19   6  94  79]\n",
      " [  0   0   0   2   1  29 178]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.56      0.62       210\n",
      "           2       0.71      0.62      0.66       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.48      0.30      0.37       210\n",
      "           5       0.50      0.56      0.53       210\n",
      "           6       0.38      0.45      0.41       210\n",
      "           7       0.58      0.85      0.69       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of SVM is:\n",
      " [[166   1   0   5  26  10   2]\n",
      " [  1 170   6  11  17   5   0]\n",
      " [  0   6 193   5   3   3   0]\n",
      " [ 15  11  10 150  10  13   1]\n",
      " [ 30  19   4  17 138   1   1]\n",
      " [ 17  21   7  19   5  91  50]\n",
      " [  1   4   0   6   8  39 152]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.79      0.75       210\n",
      "           2       0.73      0.81      0.77       210\n",
      "           3       0.88      0.92      0.90       210\n",
      "           4       0.70      0.71      0.71       210\n",
      "           5       0.67      0.66      0.66       210\n",
      "           6       0.56      0.43      0.49       210\n",
      "           7       0.74      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.71      0.72      0.72      1470\n",
      "weighted avg       0.71      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7605442176870748\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   0   0   6  24  23   1]\n",
      " [  1 173   4  16   9   7   0]\n",
      " [  0   7 182  11   3   7   0]\n",
      " [  0   6   4 154  13  30   3]\n",
      " [ 19  20   0  14 151   4   2]\n",
      " [  3   4   0  21   4 142  36]\n",
      " [  0   0   0   0   3  47 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.74      0.80       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.69      0.73      0.71       210\n",
      "           5       0.73      0.72      0.72       210\n",
      "           6       0.55      0.68      0.60       210\n",
      "           7       0.79      0.76      0.78       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7877551020408163\n",
      "Confusion Matrix of SVM is:\n",
      " [[160   0   0   6  23  20   1]\n",
      " [  1 172   8  12   9   8   0]\n",
      " [  0   1 198   2   3   6   0]\n",
      " [  0   6   6 164   8  24   2]\n",
      " [ 23  23   3   8 147   3   3]\n",
      " [  2   5   1  16   1 136  49]\n",
      " [  0   0   0   0   2  27 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.76      0.81       210\n",
      "           2       0.83      0.82      0.82       210\n",
      "           3       0.92      0.94      0.93       210\n",
      "           4       0.79      0.78      0.78       210\n",
      "           5       0.76      0.70      0.73       210\n",
      "           6       0.61      0.65      0.63       210\n",
      "           7       0.77      0.86      0.81       210\n",
      "\n",
      "    accuracy                           0.79      1470\n",
      "   macro avg       0.79      0.79      0.79      1470\n",
      "weighted avg       0.79      0.79      0.79      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7197278911564626\n",
      "Confusion Matrix of SVM is:\n",
      " [[160   0   0   6  27  15   2]\n",
      " [  0 158   9  17  14  12   0]\n",
      " [  0  15 164  16   3  12   0]\n",
      " [  2  10  20 135   8  27   8]\n",
      " [ 29  21   5   4 146   3   2]\n",
      " [  6   9   7  12   3 120  53]\n",
      " [  1   0   0   1   2  31 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.76      0.78       210\n",
      "           2       0.74      0.75      0.75       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.71      0.64      0.67       210\n",
      "           5       0.72      0.70      0.71       210\n",
      "           6       0.55      0.57      0.56       210\n",
      "           7       0.73      0.83      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23265306122448978\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [ 78   0 132   0   0   0   0]\n",
      " [198   0  12   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      1.00      0.28       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.86      0.63      0.73       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.15      0.23      0.14      1470\n",
      "weighted avg       0.15      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 175   0  35]\n",
      " [  0   0   3   0 177   0  30]\n",
      " [  0   0 128   4  56   0  22]\n",
      " [  0   0   5   7 144   0  54]\n",
      " [  0   0   3   0 190   0  17]\n",
      " [  0   0   2   0  42   0 166]\n",
      " [  0   0   1   0  10   0 199]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.90      0.61      0.73       210\n",
      "           4       0.64      0.03      0.06       210\n",
      "           5       0.24      0.90      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.95      0.54       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.31      0.36      0.24      1470\n",
      "weighted avg       0.31      0.36      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.48299319727891155\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157  18   0   0   0  26   9]\n",
      " [ 15 162   3   0   0  24   6]\n",
      " [ 15  41 130   2   0  21   1]\n",
      " [ 56  88   4   6   0  45  11]\n",
      " [125  65   3   0   0   4  13]\n",
      " [ 18  24   1   0   0  96  71]\n",
      " [  8   2   0   0   0  41 159]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.75      0.52       210\n",
      "           2       0.41      0.77      0.53       210\n",
      "           3       0.92      0.62      0.74       210\n",
      "           4       0.75      0.03      0.06       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.37      0.46      0.41       210\n",
      "           7       0.59      0.76      0.66       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.42      1470\n",
      "weighted avg       0.49      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   1   0  17  62  26   6]\n",
      " [  5 120   2  42  15  24   2]\n",
      " [ 11  24 130  19   4  21   1]\n",
      " [  5  14   4  82  52  43  10]\n",
      " [ 33  32   0  33 103   4   5]\n",
      " [  3   6   1  18  21  96  65]\n",
      " [  0   1   0   1  14  41 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.47      0.54       210\n",
      "           2       0.61      0.57      0.59       210\n",
      "           3       0.95      0.62      0.75       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.38      0.49      0.43       210\n",
      "           6       0.38      0.46      0.41       210\n",
      "           7       0.63      0.73      0.68       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.57      0.53      0.54      1470\n",
      "weighted avg       0.57      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   8   0  41  32  25   6]\n",
      " [  5 155   3  14  10  21   2]\n",
      " [ 11  24 146   8   0  20   1]\n",
      " [  5  41   8  97  14  38   7]\n",
      " [ 33  54   1  52  61   4   5]\n",
      " [  3  12   3  25   0 111  56]\n",
      " [  0   2   0  11   0  53 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.47      0.54       210\n",
      "           2       0.52      0.74      0.61       210\n",
      "           3       0.91      0.70      0.79       210\n",
      "           4       0.39      0.46      0.42       210\n",
      "           5       0.52      0.29      0.37       210\n",
      "           6       0.41      0.53      0.46       210\n",
      "           7       0.65      0.69      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.58      0.55      0.55      1470\n",
      "weighted avg       0.58      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   8   2  17  41  12  17]\n",
      " [  3 158   9  10  13  12   5]\n",
      " [  0  25 152   6  13  10   4]\n",
      " [  5  33   8  99  27  19  19]\n",
      " [ 40  50   1  29  81   2   7]\n",
      " [  1  13   8  12  15  75  86]\n",
      " [  0   2   0   6   7  41 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.54      0.61       210\n",
      "           2       0.55      0.75      0.63       210\n",
      "           3       0.84      0.72      0.78       210\n",
      "           4       0.55      0.47      0.51       210\n",
      "           5       0.41      0.39      0.40       210\n",
      "           6       0.44      0.36      0.39       210\n",
      "           7       0.53      0.73      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.582312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   7   2  16  45  24   7]\n",
      " [  9 143   8   7  31  10   2]\n",
      " [  5  11 162   4  15  12   1]\n",
      " [  4  19  12  90  40  37   8]\n",
      " [ 26  36   0  23 107  11   7]\n",
      " [ 17   8   6  15  14  91  59]\n",
      " [  4   1   0   5   1  45 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.52      0.57       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.85      0.77      0.81       210\n",
      "           4       0.56      0.43      0.49       210\n",
      "           5       0.42      0.51      0.46       210\n",
      "           6       0.40      0.43      0.41       210\n",
      "           7       0.65      0.73      0.69       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1  17  34  25  10]\n",
      " [  5 136   7  15  24  20   3]\n",
      " [  4  13 162  10   8   8   5]\n",
      " [  8  16   9  92  37  30  18]\n",
      " [ 34  20   0  43  99   7   7]\n",
      " [ 10   9   5  17   8  91  70]\n",
      " [  3   1   0   8   1  47 150]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.59      0.62       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.46      0.44      0.45       210\n",
      "           5       0.47      0.47      0.47       210\n",
      "           6       0.40      0.43      0.42       210\n",
      "           7       0.57      0.71      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   2   1  23  36  18   6]\n",
      " [  9 147   7  13  20  10   4]\n",
      " [  1   9 161  18  11   7   3]\n",
      " [ 15  12  10 102  37  23  11]\n",
      " [ 41  25   2  41  90   4   7]\n",
      " [ 15   8  12  28  10  74  63]\n",
      " [  6   0   1  16   7  33 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.59      0.59       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.42      0.49      0.45       210\n",
      "           5       0.43      0.43      0.43       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.61      0.70      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[127   3   1  17  35  21   6]\n",
      " [ 12 141  10  15  19   9   4]\n",
      " [  8  10 162  11   8   7   4]\n",
      " [ 13  21  10  94  37  26   9]\n",
      " [ 38  26   2  36  96   6   6]\n",
      " [ 16   7  10  28  10  81  58]\n",
      " [  5   3   1  15   9  39 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.60      0.59       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.44      0.45      0.44       210\n",
      "           5       0.45      0.46      0.45       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.61      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   4   1  18  40  21   4]\n",
      " [ 12 139   9  14  24  10   2]\n",
      " [  4  11 169  12   4   7   3]\n",
      " [ 17  19   8 102  33  25   6]\n",
      " [ 34  29   3  43  90   9   2]\n",
      " [ 19   9   9  32   6  76  59]\n",
      " [  3   4   3  18   3  44 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58       210\n",
      "           2       0.65      0.66      0.65       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.43      0.49      0.45       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.64      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   7   3  14  38  20   6]\n",
      " [  8 139   9  17  22  11   4]\n",
      " [  4   8 174   8   7   6   3]\n",
      " [ 17  18  10  93  40  26   6]\n",
      " [ 32  28   4  35  92  15   4]\n",
      " [ 18  16   8  26  10  73  59]\n",
      " [  8   7   2  18   5  44 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58       210\n",
      "           2       0.62      0.66      0.64       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.43      0.44      0.43       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.61      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   2   1  16  42  22   6]\n",
      " [  6 142   9  15  23  11   4]\n",
      " [  5   6 173   9   7   7   3]\n",
      " [ 12  17  10  97  35  30   9]\n",
      " [ 41  28   6  34  88   9   4]\n",
      " [ 19   6  11  26   5  78  65]\n",
      " [  5   4   0  16   6  44 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.58      0.58       210\n",
      "           2       0.69      0.68      0.68       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.43      0.42      0.42       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.60      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   3   2  18  33  24   5]\n",
      " [  8 138   9  13  21  17   4]\n",
      " [  3   6 176   9   6   4   6]\n",
      " [ 13  19  15  90  40  25   8]\n",
      " [ 36  28   4  37  91  11   3]\n",
      " [ 17  11   8  27  11  73  63]\n",
      " [  7   7   4  13   8  41 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60       210\n",
      "           2       0.65      0.66      0.65       210\n",
      "           3       0.81      0.84      0.82       210\n",
      "           4       0.43      0.43      0.43       210\n",
      "           5       0.43      0.43      0.43       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.59      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   8   2  15  39  20   4]\n",
      " [ 11 134  11  15  22  13   4]\n",
      " [  1   5 177  10   5   8   4]\n",
      " [ 11  25   9  97  30  32   6]\n",
      " [ 33  30   7  34  91   9   6]\n",
      " [ 18   8   8  31   9  77  59]\n",
      " [  6   4   3  15   8  45 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59       210\n",
      "           2       0.63      0.64      0.63       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.45      0.46      0.45       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.38      0.37      0.37       210\n",
      "           7       0.61      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  17   3   8  33  20   7]\n",
      " [  8 135   9  18  23  12   5]\n",
      " [  2   8 171  12   9   5   3]\n",
      " [  8  16   8 101  42  26   9]\n",
      " [ 33  28   2  40  93  10   4]\n",
      " [ 13  11  11  34  11  73  57]\n",
      " [  7   7   0  13   7  43 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.61       210\n",
      "           2       0.61      0.64      0.62       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.45      0.48      0.46       210\n",
      "           5       0.43      0.44      0.43       210\n",
      "           6       0.39      0.35      0.37       210\n",
      "           7       0.61      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   6   1  17  33  22   7]\n",
      " [  8 137  12  15  18  13   7]\n",
      " [  7   8 168  12   4   7   4]\n",
      " [  6  14  13  95  42  31   9]\n",
      " [ 40  21   6  42  85  11   5]\n",
      " [ 15   9  11  30  10  81  54]\n",
      " [  5   7   1  20   9  43 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.59      0.60       210\n",
      "           2       0.68      0.65      0.67       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.41      0.45      0.43       210\n",
      "           5       0.42      0.40      0.41       210\n",
      "           6       0.39      0.39      0.39       210\n",
      "           7       0.59      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  11   3  10  33  25   6]\n",
      " [  4 138  10  17  24  12   5]\n",
      " [  0   8 175  10   6   5   6]\n",
      " [  8  16  13 103  33  27  10]\n",
      " [ 36  25   5  37  92  12   3]\n",
      " [ 19   8   6  31  11  75  60]\n",
      " [  5   4   0  21   7  45 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.60       210\n",
      "           2       0.66      0.66      0.66       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.45      0.49      0.47       210\n",
      "           5       0.45      0.44      0.44       210\n",
      "           6       0.37      0.36      0.36       210\n",
      "           7       0.59      0.61      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  11   3  10  32  26   6]\n",
      " [  7 137   8  17  24  12   5]\n",
      " [  1   8 175  10   6   7   3]\n",
      " [  7  17  14 102  33  28   9]\n",
      " [ 37  25   5  36  93  11   3]\n",
      " [ 17   9   9  30  11  75  59]\n",
      " [  4   5   1  22   7  46 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.60       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.45      0.49      0.47       210\n",
      "           5       0.45      0.44      0.45       210\n",
      "           6       0.37      0.36      0.36       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   6   3  18  31  22   6]\n",
      " [  7 137  12  14  23  11   6]\n",
      " [  0   7 175  12   6   7   3]\n",
      " [  9  19  13  92  38  28  11]\n",
      " [ 35  28   7  33  91  10   6]\n",
      " [ 16  13  10  33   8  74  56]\n",
      " [  7   5   5  16   9  39 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.59      0.61       210\n",
      "           2       0.64      0.65      0.64       210\n",
      "           3       0.78      0.83      0.80       210\n",
      "           4       0.42      0.44      0.43       210\n",
      "           5       0.44      0.43      0.44       210\n",
      "           6       0.39      0.35      0.37       210\n",
      "           7       0.59      0.61      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47619047619047616\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 75   1  10   1  68   1  54]\n",
      " [  4 113  32   0  32   1  28]\n",
      " [  0  14 171   0  12   1  12]\n",
      " [  3  25  38   1  63   2  78]\n",
      " [ 10  27  11   1 128   0  33]\n",
      " [  1   8  20   0  13   2 166]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.36      0.50       210\n",
      "           2       0.60      0.54      0.57       210\n",
      "           3       0.61      0.81      0.70       210\n",
      "           4       0.33      0.00      0.01       210\n",
      "           5       0.41      0.61      0.49       210\n",
      "           6       0.29      0.01      0.02       210\n",
      "           7       0.36      1.00      0.53       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.40      1470\n",
      "weighted avg       0.49      0.48      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   1   1   0  46   9  32]\n",
      " [  1 144  10   0  28  14  13]\n",
      " [  2  24 158   0   5  16   5]\n",
      " [  7  38  25   1  60  14  65]\n",
      " [ 30  34   3   1 122   2  18]\n",
      " [  5  15   7   0   7  29 147]\n",
      " [  0   0   0   0   1   0 209]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.64       210\n",
      "           2       0.56      0.69      0.62       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.50      0.00      0.01       210\n",
      "           5       0.45      0.58      0.51       210\n",
      "           6       0.35      0.14      0.20       210\n",
      "           7       0.43      1.00      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.48      1470\n",
      "weighted avg       0.54      0.53      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   1   0   1  38  19  20]\n",
      " [  1 164   5   4  12  18   6]\n",
      " [ 11  23 155   3   0  16   2]\n",
      " [  9  52  21  13  44  33  38]\n",
      " [ 36  42   1   1 114   1  15]\n",
      " [  3  17   3   2  12  51 122]\n",
      " [  0   0   0   0   1   6 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.62      0.65       210\n",
      "           2       0.55      0.78      0.64       210\n",
      "           3       0.84      0.74      0.78       210\n",
      "           4       0.54      0.06      0.11       210\n",
      "           5       0.52      0.54      0.53       210\n",
      "           6       0.35      0.24      0.29       210\n",
      "           7       0.50      0.97      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.52      1470\n",
      "weighted avg       0.57      0.57      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0   0   2  50  20  16]\n",
      " [  1 153   4   8  19  22   3]\n",
      " [  4  11 158   3  15  19   0]\n",
      " [  4  21  10  61  47  41  26]\n",
      " [ 22  35   1   4 134   3  11]\n",
      " [  4  11   0   9  11  78  97]\n",
      " [  0   0   0   0   1  17 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.58      0.66       210\n",
      "           2       0.66      0.73      0.69       210\n",
      "           3       0.91      0.75      0.83       210\n",
      "           4       0.70      0.29      0.41       210\n",
      "           5       0.48      0.64      0.55       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.56      0.91      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.60      1470\n",
      "weighted avg       0.64      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0   0   3  47  27  11]\n",
      " [  0 149   5   8  23  22   3]\n",
      " [  1  10 172   8   6  13   0]\n",
      " [  2  12   6  93  31  45  21]\n",
      " [ 22  31   1   7 138   2   9]\n",
      " [  2   5   0  17   8  91  87]\n",
      " [  0   0   0   0   4  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.58      0.68       210\n",
      "           2       0.72      0.71      0.71       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.68      0.44      0.54       210\n",
      "           5       0.54      0.66      0.59       210\n",
      "           6       0.41      0.43      0.42       210\n",
      "           7       0.59      0.88      0.70       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   0   0   3  43  25   9]\n",
      " [  1 151   4  13  19  21   1]\n",
      " [  1   9 175   8   5  12   0]\n",
      " [  0   9   4 109  31  37  20]\n",
      " [ 21  28   0  10 140   3   8]\n",
      " [  1   4   0  17   6  95  87]\n",
      " [  0   0   0   0   0  22 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.62      0.71       210\n",
      "           2       0.75      0.72      0.73       210\n",
      "           3       0.96      0.83      0.89       210\n",
      "           4       0.68      0.52      0.59       210\n",
      "           5       0.57      0.67      0.62       210\n",
      "           6       0.44      0.45      0.45       210\n",
      "           7       0.60      0.90      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   0   0   4  43  26   9]\n",
      " [  1 152   4  17  18  17   1]\n",
      " [  0   9 173  13   2  13   0]\n",
      " [  2   6   1 117  24  42  18]\n",
      " [ 20  25   0  13 140   3   9]\n",
      " [  0   3   0  18   7 100  82]\n",
      " [  0   1   0   0   4  26 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.61      0.71       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.97      0.82      0.89       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.59      0.67      0.62       210\n",
      "           6       0.44      0.48      0.46       210\n",
      "           7       0.60      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   0   0   4  40  25   9]\n",
      " [  2 154   4  16  18  15   1]\n",
      " [  0   9 174   9   5  12   1]\n",
      " [  3   4   3 126  26  31  17]\n",
      " [ 21  23   0  15 140   3   8]\n",
      " [  2   4   0  14   7 110  73]\n",
      " [  0   0   0   0   2  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.63      0.71       210\n",
      "           2       0.79      0.73      0.76       210\n",
      "           3       0.96      0.83      0.89       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.59      0.67      0.62       210\n",
      "           6       0.50      0.52      0.51       210\n",
      "           7       0.63      0.89      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   0   0   4  45  23   9]\n",
      " [  0 156   4  14  22  12   2]\n",
      " [  1   6 181  11   3   8   0]\n",
      " [  1   5   1 127  23  37  16]\n",
      " [ 16  21   1  13 148   3   8]\n",
      " [  0   5   0  16   6 111  72]\n",
      " [  0   1   0   2   3  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.61      0.72       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.97      0.86      0.91       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.59      0.70      0.64       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.63      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.71      1470\n",
      "weighted avg       0.72      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   0   0   4  37  21  11]\n",
      " [  1 158   5  14  21  10   1]\n",
      " [  0   5 185   7   4   9   0]\n",
      " [  1   5   2 132  25  32  13]\n",
      " [ 17  22   0  11 150   3   7]\n",
      " [  1   5   0  14   4 121  65]\n",
      " [  0   1   0   1   2  25 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.65      0.75       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.72      0.63      0.67       210\n",
      "           5       0.62      0.71      0.66       210\n",
      "           6       0.55      0.58      0.56       210\n",
      "           7       0.65      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.73      1470\n",
      "weighted avg       0.74      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   0   0   6  36  22   9]\n",
      " [  1 156   6  16  19  12   0]\n",
      " [  0   5 189   5   2   8   1]\n",
      " [  0   5   4 138  23  27  13]\n",
      " [ 18  22   0  16 146   1   7]\n",
      " [  3   4   0  14   6 113  70]\n",
      " [  0   0   0   0   2  28 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.65      0.74       210\n",
      "           2       0.81      0.74      0.78       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.71      0.66      0.68       210\n",
      "           5       0.62      0.70      0.66       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.64      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   0   0   7  40  20   8]\n",
      " [  0 156   5  17  21  11   0]\n",
      " [  1   3 185   9   3   9   0]\n",
      " [  4   5   1 137  18  31  14]\n",
      " [ 19  24   1   9 145   4   8]\n",
      " [  3   3   1  20   6 117  60]\n",
      " [  0   0   0   1   1  30 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.73       210\n",
      "           2       0.82      0.74      0.78       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.69      0.65      0.67       210\n",
      "           5       0.62      0.69      0.65       210\n",
      "           6       0.53      0.56      0.54       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.717687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   1   0   7  37  20   8]\n",
      " [  2 158   7  16  16  10   1]\n",
      " [  0   4 186   7   3   9   1]\n",
      " [  1   5   1 135  24  30  14]\n",
      " [ 19  20   0  16 145   3   7]\n",
      " [  2   3   1  17   4 114  69]\n",
      " [  0   1   0   1   2  26 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.65      0.74       210\n",
      "           2       0.82      0.75      0.79       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.63      0.69      0.66       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.64      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   0   0   7  35  19   9]\n",
      " [  1 159   6  14  17  13   0]\n",
      " [  0   4 188   5   4   9   0]\n",
      " [  3   5   4 137  22  26  13]\n",
      " [ 20  21   0  14 144   5   6]\n",
      " [  2   4   0  18   5 116  65]\n",
      " [  0   1   0   2   2  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.63      0.69      0.66       210\n",
      "           6       0.54      0.55      0.55       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.73      1470\n",
      "weighted avg       0.73      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7306122448979592\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   0   0   5  34  22   8]\n",
      " [  1 162   5  14  17  10   1]\n",
      " [  1   3 188   4   5   9   0]\n",
      " [  4   4   2 138  20  33   9]\n",
      " [ 21  19   0  20 141   1   8]\n",
      " [  1   4   0  15   8 122  60]\n",
      " [  0   0   0   2   2  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.67      0.74       210\n",
      "           2       0.84      0.77      0.81       210\n",
      "           3       0.96      0.90      0.93       210\n",
      "           4       0.70      0.66      0.68       210\n",
      "           5       0.62      0.67      0.65       210\n",
      "           6       0.55      0.58      0.57       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7292517006802721\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   1   0   5  33  20   9]\n",
      " [  1 160   6  15  17  11   0]\n",
      " [  0   2 188   9   3   8   0]\n",
      " [  2   5   2 137  20  34  10]\n",
      " [ 19  21   0  15 145   3   7]\n",
      " [  2   4   0  18   5 123  58]\n",
      " [  1   0   0   2   0  30 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.68      0.75       210\n",
      "           2       0.83      0.76      0.79       210\n",
      "           3       0.96      0.90      0.93       210\n",
      "           4       0.68      0.65      0.67       210\n",
      "           5       0.65      0.69      0.67       210\n",
      "           6       0.54      0.59      0.56       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   0   0   5  30  21   8]\n",
      " [  1 159   7  14  18  11   0]\n",
      " [  0   0 186   9   5  10   0]\n",
      " [  2   5   2 143  18  30  10]\n",
      " [ 22  20   0  13 144   4   7]\n",
      " [  2   4   1  15   4 125  59]\n",
      " [  0   1   0   1   2  30 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.70      0.76       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.71      0.68      0.70       210\n",
      "           5       0.65      0.69      0.67       210\n",
      "           6       0.54      0.60      0.57       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.75      0.73      0.74      1470\n",
      "weighted avg       0.75      0.73      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   0   0   6  35  20   7]\n",
      " [  2 159   7  15  17  10   0]\n",
      " [  0   1 188  10   4   7   0]\n",
      " [  3   7   3 136  15  36  10]\n",
      " [ 22  16   0  17 145   4   6]\n",
      " [  1   2   0  16   7 110  74]\n",
      " [  0   0   0   2   2  27 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.68      0.75       210\n",
      "           2       0.86      0.76      0.81       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.64      0.69      0.67       210\n",
      "           6       0.51      0.52      0.52       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   0   0   5  32  24   5]\n",
      " [  2 159   7  13  19  10   0]\n",
      " [  0   4 186   8   3   9   0]\n",
      " [  3   7   3 131  24  32  10]\n",
      " [ 20  20   0  12 148   5   5]\n",
      " [  2   3   0  17   5 112  71]\n",
      " [  0   0   0   1   4  26 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.69      0.76       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.70      0.62      0.66       210\n",
      "           5       0.63      0.70      0.67       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.66      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   1   0   5  33  20   8]\n",
      " [  1 159   7  15  20   8   0]\n",
      " [  0   1 186  12   3   8   0]\n",
      " [  4   7   5 140  21  25   8]\n",
      " [ 23  19   0  14 144   6   4]\n",
      " [  2   3   1  19   3 116  66]\n",
      " [  0   0   0   2   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.68      0.75       210\n",
      "           2       0.84      0.76      0.79       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.68      0.67      0.67       210\n",
      "           5       0.64      0.69      0.66       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.67      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.73      1470\n",
      "weighted avg       0.73      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[116   0   2   5  48  32   7]\n",
      " [  2 117  32  14  19  24   2]\n",
      " [ 12   1 169   5   0  23   0]\n",
      " [  4  12  29  64  31  51  19]\n",
      " [ 32  29   7  10 105   5  22]\n",
      " [  5   4   8  10   5 112  66]\n",
      " [  0   0   0   1   0  47 162]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.55      0.61       210\n",
      "           2       0.72      0.56      0.63       210\n",
      "           3       0.68      0.80      0.74       210\n",
      "           4       0.59      0.30      0.40       210\n",
      "           5       0.50      0.50      0.50       210\n",
      "           6       0.38      0.53      0.44       210\n",
      "           7       0.58      0.77      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//xlm_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[155   1   1   6  29  13   5]\n",
      " [  3 158   9  10  18   9   3]\n",
      " [  1   7 181   6   6   8   1]\n",
      " [ 11  15  10 132  14  21   7]\n",
      " [ 28  21   5  16 131   4   5]\n",
      " [ 10  16   8  24   6 102  44]\n",
      " [  6   2   2   4   6  43 147]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.72      0.75      0.73       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.67      0.63      0.65       210\n",
      "           5       0.62      0.62      0.62       210\n",
      "           6       0.51      0.49      0.50       210\n",
      "           7       0.69      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132   7   0  11  42  10   8]\n",
      " [ 15 139   9   7  33   3   4]\n",
      " [ 11  19 165   5   6   2   2]\n",
      " [ 34  10  11  90  37  14  14]\n",
      " [ 48  22   3  14 108   4  11]\n",
      " [ 55  23   6  36  20  36  34]\n",
      " [ 24   5   1  26  20  15 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.63      0.50       210\n",
      "           2       0.62      0.66      0.64       210\n",
      "           3       0.85      0.79      0.81       210\n",
      "           4       0.48      0.43      0.45       210\n",
      "           5       0.41      0.51      0.45       210\n",
      "           6       0.43      0.17      0.24       210\n",
      "           7       0.62      0.57      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.53      1470\n",
      "weighted avg       0.54      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129   3   0  13  44  13   8]\n",
      " [ 14 135  10   6  37   4   4]\n",
      " [  9  15 165   6   9   4   2]\n",
      " [ 34  12   4  89  31  22  18]\n",
      " [ 44  19   4  15 108   6  14]\n",
      " [ 46  14   4  30  20  50  46]\n",
      " [ 15   4   0  15  13  32 131]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.61      0.51       210\n",
      "           2       0.67      0.64      0.66       210\n",
      "           3       0.88      0.79      0.83       210\n",
      "           4       0.51      0.42      0.46       210\n",
      "           5       0.41      0.51      0.46       210\n",
      "           6       0.38      0.24      0.29       210\n",
      "           7       0.59      0.62      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122   3   1  15  47  15   7]\n",
      " [  8 134  11  10  40   4   3]\n",
      " [ 10  18 162   5   9   4   2]\n",
      " [ 28   9   3  91  43  19  17]\n",
      " [ 34  22   4  11 117   6  16]\n",
      " [ 36   9   4  28  24  62  47]\n",
      " [ 11   1   0  14  17  32 135]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.58      0.53       210\n",
      "           2       0.68      0.64      0.66       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.52      0.43      0.47       210\n",
      "           5       0.39      0.56      0.46       210\n",
      "           6       0.44      0.30      0.35       210\n",
      "           7       0.59      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126   4   2  13  46  13   6]\n",
      " [  5 138  10  12  38   5   2]\n",
      " [  7  21 160   6   6   6   4]\n",
      " [ 26  11   4  88  43  18  20]\n",
      " [ 35  20   5  12 121   5  12]\n",
      " [ 34  10   2  30  28  59  47]\n",
      " [ 11   1   0  18  14  28 138]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.60      0.56       210\n",
      "           2       0.67      0.66      0.67       210\n",
      "           3       0.87      0.76      0.81       210\n",
      "           4       0.49      0.42      0.45       210\n",
      "           5       0.41      0.58      0.48       210\n",
      "           6       0.44      0.28      0.34       210\n",
      "           7       0.60      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.573469387755102\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125   4   2  14  47  11   7]\n",
      " [  7 139   9  12  38   3   2]\n",
      " [  8  22 158   7   7   5   3]\n",
      " [ 20  12   6  86  48  19  19]\n",
      " [ 31  18   5   9 123   6  18]\n",
      " [ 30  11   2  25  28  59  55]\n",
      " [  9   1   0  11  14  22 153]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.60      0.57       210\n",
      "           2       0.67      0.66      0.67       210\n",
      "           3       0.87      0.75      0.81       210\n",
      "           4       0.52      0.41      0.46       210\n",
      "           5       0.40      0.59      0.48       210\n",
      "           6       0.47      0.28      0.35       210\n",
      "           7       0.60      0.73      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[124   5   2  14  48   7  10]\n",
      " [  9 137   9  11  41   1   2]\n",
      " [  8  22 160   5   6   5   4]\n",
      " [ 20  17   3  82  45  22  21]\n",
      " [ 29  19   3  11 126   3  19]\n",
      " [ 35  12   5  28  24  51  55]\n",
      " [  8   1   0   9  14  26 152]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.59      0.56       210\n",
      "           2       0.64      0.65      0.65       210\n",
      "           3       0.88      0.76      0.82       210\n",
      "           4       0.51      0.39      0.44       210\n",
      "           5       0.41      0.60      0.49       210\n",
      "           6       0.44      0.24      0.31       210\n",
      "           7       0.58      0.72      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 49   7   9  22  63  12  48]\n",
      " [  0 130  12  13  45   2   8]\n",
      " [  2  53 130   4   7  11   3]\n",
      " [  6  25  12  49  47  13  58]\n",
      " [  6  23   2   5 131   3  40]\n",
      " [  7  23  11  21  25  37  86]\n",
      " [  1   8   2  20  24  14 141]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.23      0.35       210\n",
      "           2       0.48      0.62      0.54       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.37      0.23      0.28       210\n",
      "           5       0.38      0.62      0.47       210\n",
      "           6       0.40      0.18      0.25       210\n",
      "           7       0.37      0.67      0.47       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.43      1470\n",
      "weighted avg       0.49      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.4605442176870748\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 71   7  20   8  57  14  33]\n",
      " [  3 136  16  11  34   4   6]\n",
      " [  4  47 136   7   4  11   1]\n",
      " [  6  30  13  52  43  21  45]\n",
      " [ 12  27   2  10 119   3  37]\n",
      " [ 11  28  10  23  27  47  64]\n",
      " [  7   9   2  25  26  25 116]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.34      0.44       210\n",
      "           2       0.48      0.65      0.55       210\n",
      "           3       0.68      0.65      0.67       210\n",
      "           4       0.38      0.25      0.30       210\n",
      "           5       0.38      0.57      0.46       210\n",
      "           6       0.38      0.22      0.28       210\n",
      "           7       0.38      0.55      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.45      1470\n",
      "weighted avg       0.47      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of SVM is:\n",
      " [[157   5   2   9  22  11   4]\n",
      " [  6 162  11   7  14   8   2]\n",
      " [  2   7 192   2   1   4   2]\n",
      " [ 10  16  12 134  15  18   5]\n",
      " [ 41  26   5  14 116   4   4]\n",
      " [ 18  21   7  25   9  97  33]\n",
      " [  5   3   0  10   4  50 138]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.75      0.70       210\n",
      "           2       0.68      0.77      0.72       210\n",
      "           3       0.84      0.91      0.87       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.64      0.55      0.59       210\n",
      "           6       0.51      0.46      0.48       210\n",
      "           7       0.73      0.66      0.69       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.67      1470\n",
      "weighted avg       0.67      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 73   0   0   6  93   6  32]\n",
      " [  0 109   3  16  73   3   6]\n",
      " [  1   7 158   7  23  10   4]\n",
      " [  3   2   4  92  55  16  38]\n",
      " [  2   5   1   3 172   0  27]\n",
      " [  3   1   0  19  39  54  94]\n",
      " [  0   0   0   7  19  14 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.35      0.50       210\n",
      "           2       0.88      0.52      0.65       210\n",
      "           3       0.95      0.75      0.84       210\n",
      "           4       0.61      0.44      0.51       210\n",
      "           5       0.36      0.82      0.50       210\n",
      "           6       0.52      0.26      0.35       210\n",
      "           7       0.46      0.81      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.67      0.56      0.56      1470\n",
      "weighted avg       0.67      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of SVM is:\n",
      " [[139   3   0   4  35  21   8]\n",
      " [  0 165   7   8  17  11   2]\n",
      " [  1  15 174   5   1  13   1]\n",
      " [  5   6   8 136  17  29   9]\n",
      " [ 23  21   4  12 138   3   9]\n",
      " [  7   8   5  18   6 104  62]\n",
      " [  1   0   0   3   6  33 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.76      0.79      0.77       210\n",
      "           3       0.88      0.83      0.85       210\n",
      "           4       0.73      0.65      0.69       210\n",
      "           5       0.63      0.66      0.64       210\n",
      "           6       0.49      0.50      0.49       210\n",
      "           7       0.65      0.80      0.71       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of SVM is:\n",
      " [[130   5  13   7  30  18   7]\n",
      " [ 35 117  26   9  17   5   1]\n",
      " [ 33  12 145  10   1   9   0]\n",
      " [ 30   9  19  95  17  25  15]\n",
      " [ 42  20   4  11 118   3  12]\n",
      " [ 40   9  15  17   6  60  63]\n",
      " [  6   2   1   2   2  30 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.62      0.49       210\n",
      "           2       0.67      0.56      0.61       210\n",
      "           3       0.65      0.69      0.67       210\n",
      "           4       0.63      0.45      0.53       210\n",
      "           5       0.62      0.56      0.59       210\n",
      "           6       0.40      0.29      0.33       210\n",
      "           7       0.63      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.21972789115646257\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  14   0   0   0 196]\n",
      " [  0   0  12   0   0   0 198]\n",
      " [  0   0 114   0   0   0  96]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   2   0   0   0 208]\n",
      " [  0   0  12   0   0   0 198]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.54      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 13  22   1   0   0   0 174]\n",
      " [  2 105  10   0   0   0  93]\n",
      " [  0  23 114   0   0   0  73]\n",
      " [  0  36   3   0   0   0 171]\n",
      " [  1  32   1   0   0   0 176]\n",
      " [  6  30   6   0   0   0 168]\n",
      " [  0  12   1   0   0   0 197]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.06      0.11       210\n",
      "           2       0.40      0.50      0.45       210\n",
      "           3       0.84      0.54      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.19      0.94      0.31       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.29      0.29      0.22      1470\n",
      "weighted avg       0.29      0.29      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134  24   1   0   0   0  51]\n",
      " [ 70 113   4   0   0   0  23]\n",
      " [ 61  24 113   0   0   0  12]\n",
      " [ 92  36   3   0   0   0  79]\n",
      " [113  34   0   0   0   0  63]\n",
      " [ 70  38   4   0   0   0  98]\n",
      " [ 50  13   0   0   0   0 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.64      0.34       210\n",
      "           2       0.40      0.54      0.46       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.31      0.70      0.43       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.26      0.34      0.27      1470\n",
      "weighted avg       0.26      0.34      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   9   3  29  15   0  22]\n",
      " [ 70  80   2  17  33   2   6]\n",
      " [ 46   8 126  10  15   3   2]\n",
      " [ 92  15   3  52  21   0  27]\n",
      " [113  16   1  36  17   0  27]\n",
      " [ 70  24   5  49  10   3  49]\n",
      " [ 50   3   1  57   9   0  90]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.63      0.34       210\n",
      "           2       0.52      0.38      0.44       210\n",
      "           3       0.89      0.60      0.72       210\n",
      "           4       0.21      0.25      0.23       210\n",
      "           5       0.14      0.08      0.10       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.40      0.43      0.42       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.40      0.34      0.32      1470\n",
      "weighted avg       0.40      0.34      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3693877551020408\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   3   3   6  65   9  22]\n",
      " [ 45  73   2   9  68   7   6]\n",
      " [ 44   3 129   0  24   8   2]\n",
      " [ 73   5   4   7  68  26  27]\n",
      " [ 55   9   0   8 103   8  27]\n",
      " [ 61  13   4  11  33  39  49]\n",
      " [ 44   2   1   1  45  27  90]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.49      0.32       210\n",
      "           2       0.68      0.35      0.46       210\n",
      "           3       0.90      0.61      0.73       210\n",
      "           4       0.17      0.03      0.06       210\n",
      "           5       0.25      0.49      0.33       210\n",
      "           6       0.31      0.19      0.23       210\n",
      "           7       0.40      0.43      0.42       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.42      0.37      0.36      1470\n",
      "weighted avg       0.42      0.37      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.38503401360544215\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57   3   3  12  57  60  18]\n",
      " [ 10  75   1  18  54  43   9]\n",
      " [  4   1 128   5  21  48   3]\n",
      " [ 18   5   4  25  48  70  40]\n",
      " [ 20   9   0   5  98  52  26]\n",
      " [ 15  10   4  25  23  78  55]\n",
      " [ 15   2   1  13  21  53 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.27      0.33       210\n",
      "           2       0.71      0.36      0.48       210\n",
      "           3       0.91      0.61      0.73       210\n",
      "           4       0.24      0.12      0.16       210\n",
      "           5       0.30      0.47      0.37       210\n",
      "           6       0.19      0.37      0.25       210\n",
      "           7       0.41      0.50      0.45       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.45      0.39      0.40      1470\n",
      "weighted avg       0.45      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3870748299319728\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 62   4   5  18  44  62  15]\n",
      " [ 19  71  13  26  37  33  11]\n",
      " [  2   1 145   9  14  35   4]\n",
      " [ 18   7   7  26  42  80  30]\n",
      " [ 24   6   6  11  91  47  25]\n",
      " [ 14  14  10  25  16  76  55]\n",
      " [ 14   1   2  14  16  65  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.30      0.34       210\n",
      "           2       0.68      0.34      0.45       210\n",
      "           3       0.77      0.69      0.73       210\n",
      "           4       0.20      0.12      0.15       210\n",
      "           5       0.35      0.43      0.39       210\n",
      "           6       0.19      0.36      0.25       210\n",
      "           7       0.41      0.47      0.44       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.43      0.39      0.39      1470\n",
      "weighted avg       0.43      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   5   5  28  37  41  14]\n",
      " [ 28  81  15  22  23  33   8]\n",
      " [  9  10 148   7   7  26   3]\n",
      " [ 30  14   9  32  27  78  20]\n",
      " [ 47  16   3  19  70  33  22]\n",
      " [ 23  12  11  28  10  84  42]\n",
      " [ 17   6   1  16  13  74  83]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.38      0.36       210\n",
      "           2       0.56      0.39      0.46       210\n",
      "           3       0.77      0.70      0.74       210\n",
      "           4       0.21      0.15      0.18       210\n",
      "           5       0.37      0.33      0.35       210\n",
      "           6       0.23      0.40      0.29       210\n",
      "           7       0.43      0.40      0.41       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.42      0.39      0.40      1470\n",
      "weighted avg       0.42      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40272108843537413\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  10   6  23  31  45  14]\n",
      " [ 31  87  10  27  23  24   8]\n",
      " [  9   7 146   7  10  28   3]\n",
      " [ 30  14   6  39  29  74  18]\n",
      " [ 42  16   1  25  72  30  24]\n",
      " [ 26  14   9  28   8  84  41]\n",
      " [ 17   2   2  23  12  71  83]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.39      0.36       210\n",
      "           2       0.58      0.41      0.48       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.23      0.19      0.20       210\n",
      "           5       0.39      0.34      0.36       210\n",
      "           6       0.24      0.40      0.30       210\n",
      "           7       0.43      0.40      0.41       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.43      0.40      0.41      1470\n",
      "weighted avg       0.43      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4013605442176871\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  13   5  24  54  31  16]\n",
      " [ 18  92  11  32  29  15  13]\n",
      " [  9   5 147  19   9  17   4]\n",
      " [ 24  18   8  55  36  51  18]\n",
      " [ 32  19   3  31  89  15  21]\n",
      " [ 26  17   8  41  16  56  46]\n",
      " [ 19   4   2  22  28  51  84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.32      0.33       210\n",
      "           2       0.55      0.44      0.49       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.25      0.26      0.25       210\n",
      "           5       0.34      0.42      0.38       210\n",
      "           6       0.24      0.27      0.25       210\n",
      "           7       0.42      0.40      0.41       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.41      1470\n",
      "weighted avg       0.42      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3945578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  13   8  18  48  34  14]\n",
      " [ 20  94   9  25  31  21  10]\n",
      " [ 12   4 147  21   9  14   3]\n",
      " [ 22  17   9  56  37  53  16]\n",
      " [ 43  29   1  25  71  23  18]\n",
      " [ 19  14  10  47  16  64  40]\n",
      " [ 20   6   7  16  31  57  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.36      0.36       210\n",
      "           2       0.53      0.45      0.49       210\n",
      "           3       0.77      0.70      0.73       210\n",
      "           4       0.27      0.27      0.27       210\n",
      "           5       0.29      0.34      0.31       210\n",
      "           6       0.24      0.30      0.27       210\n",
      "           7       0.42      0.35      0.38       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.40      1470\n",
      "weighted avg       0.41      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  21   7  24  41  39  11]\n",
      " [ 18 108  11  15  23  23  12]\n",
      " [  6   8 148  11  10  24   3]\n",
      " [ 27  19   9  46  34  56  19]\n",
      " [ 35  33   5  18  73  29  17]\n",
      " [ 21  14  11  35  14  69  46]\n",
      " [ 16  12   2  18  15  69  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.32      0.33       210\n",
      "           2       0.50      0.51      0.51       210\n",
      "           3       0.77      0.70      0.73       210\n",
      "           4       0.28      0.22      0.24       210\n",
      "           5       0.35      0.35      0.35       210\n",
      "           6       0.22      0.33      0.27       210\n",
      "           7       0.42      0.37      0.39       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  13  16  14  34  43  18]\n",
      " [ 18  98  13  14  28  24  15]\n",
      " [  7   6 156  12   9  18   2]\n",
      " [ 22  15   9  52  33  57  22]\n",
      " [ 36  29   4  18  72  31  20]\n",
      " [ 18  19   6  37  15  71  44]\n",
      " [ 20   4   6  17  16  57  90]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.34      0.36       210\n",
      "           2       0.53      0.47      0.50       210\n",
      "           3       0.74      0.74      0.74       210\n",
      "           4       0.32      0.25      0.28       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.24      0.34      0.28       210\n",
      "           7       0.43      0.43      0.43       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  18   6  27  34  42  16]\n",
      " [ 18 109   8  14  27  22  12]\n",
      " [  7   8 157   7   9  18   4]\n",
      " [ 31  16  11  50  29  48  25]\n",
      " [ 38  25   7  19  71  28  22]\n",
      " [ 18  17  15  40  16  63  41]\n",
      " [ 23   7   6  19  19  54  82]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.32      0.33       210\n",
      "           2       0.55      0.52      0.53       210\n",
      "           3       0.75      0.75      0.75       210\n",
      "           4       0.28      0.24      0.26       210\n",
      "           5       0.35      0.34      0.34       210\n",
      "           6       0.23      0.30      0.26       210\n",
      "           7       0.41      0.39      0.40       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40680272108843535\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  16   6  24  31  41  19]\n",
      " [ 22 108   9  14  26  16  15]\n",
      " [ 12   7 157  10   8  12   4]\n",
      " [ 33  21  12  44  33  44  23]\n",
      " [ 43  26   4  19  70  22  26]\n",
      " [ 21  19  12  38  14  63  43]\n",
      " [ 25   8   4  19  16  55  83]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.35      0.33       210\n",
      "           2       0.53      0.51      0.52       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.26      0.21      0.23       210\n",
      "           5       0.35      0.33      0.34       210\n",
      "           6       0.25      0.30      0.27       210\n",
      "           7       0.39      0.40      0.39       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  16   7  22  34  43  18]\n",
      " [ 19 103  12  19  29  12  16]\n",
      " [  9   7 158  16   8  11   1]\n",
      " [ 26  21  12  59  31  43  18]\n",
      " [ 36  31   6  20  71  22  24]\n",
      " [ 19  21   9  45  10  70  36]\n",
      " [ 29   8   6  17  18  57  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.33      0.33       210\n",
      "           2       0.50      0.49      0.49       210\n",
      "           3       0.75      0.75      0.75       210\n",
      "           4       0.30      0.28      0.29       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.27      0.33      0.30       210\n",
      "           7       0.40      0.36      0.38       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  12   6  22  44  28  19]\n",
      " [ 16 105  12  18  30  14  15]\n",
      " [ 10   7 158  12   7   9   7]\n",
      " [ 32  22  10  57  31  40  18]\n",
      " [ 37  24   6  24  70  24  25]\n",
      " [ 18  21  12  40  15  61  43]\n",
      " [ 25   9   5  14  20  55  82]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.38      0.37       210\n",
      "           2       0.53      0.50      0.51       210\n",
      "           3       0.76      0.75      0.75       210\n",
      "           4       0.30      0.27      0.29       210\n",
      "           5       0.32      0.33      0.33       210\n",
      "           6       0.26      0.29      0.28       210\n",
      "           7       0.39      0.39      0.39       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  14   8  15  37  42  19]\n",
      " [ 17 106  13  18  27  14  15]\n",
      " [  8  11 163   9   6   8   5]\n",
      " [ 26  27   9  50  38  40  20]\n",
      " [ 39  25   5  17  73  21  30]\n",
      " [ 18  19  12  40  16  62  43]\n",
      " [ 20  11   9  15  24  53  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.36      0.36       210\n",
      "           2       0.50      0.50      0.50       210\n",
      "           3       0.74      0.78      0.76       210\n",
      "           4       0.30      0.24      0.27       210\n",
      "           5       0.33      0.35      0.34       210\n",
      "           6       0.26      0.30      0.28       210\n",
      "           7       0.37      0.37      0.37       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  17   6  25  40  38  16]\n",
      " [ 20 103  12  17  29  13  16]\n",
      " [  9  10 163  11   7   9   1]\n",
      " [ 23  25  10  56  33  42  21]\n",
      " [ 37  26   7  22  75  22  21]\n",
      " [ 20  22  12  37  17  63  39]\n",
      " [ 25   9   2  15  28  53  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.32      0.33       210\n",
      "           2       0.49      0.49      0.49       210\n",
      "           3       0.77      0.78      0.77       210\n",
      "           4       0.31      0.27      0.28       210\n",
      "           5       0.33      0.36      0.34       210\n",
      "           6       0.26      0.30      0.28       210\n",
      "           7       0.41      0.37      0.39       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  17   7  23  46  26  17]\n",
      " [ 21 104  11  16  28  14  16]\n",
      " [  9   7 165  11   6   8   4]\n",
      " [ 28  19   8  59  37  38  21]\n",
      " [ 36  26   3  25  74  21  25]\n",
      " [ 21  23   9  40  20  57  40]\n",
      " [ 30   7   3  16  27  51  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.34       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.31      0.28      0.30       210\n",
      "           5       0.31      0.35      0.33       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.38      0.36      0.37       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.42      1470\n",
      "weighted avg       0.42      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  6   4  26   5  27   1 141]\n",
      " [  5  12  56  16  22   2  97]\n",
      " [  3  12 152   2   8   0  33]\n",
      " [  3   4  26   5  15   1 156]\n",
      " [  3   7  11   8  10   0 171]\n",
      " [  3   1  25   2   3   3 173]\n",
      " [  1   0   5   4   4   1 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.03      0.05       210\n",
      "           2       0.30      0.06      0.10       210\n",
      "           3       0.50      0.72      0.59       210\n",
      "           4       0.12      0.02      0.04       210\n",
      "           5       0.11      0.05      0.07       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.20      0.93      0.33       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.27      0.26      0.17      1470\n",
      "weighted avg       0.27      0.26      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41156462585034015\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 46  31   5   6  47   0  75]\n",
      " [  0 130  22   0  36   1  21]\n",
      " [  2  51 142   0   6   0   9]\n",
      " [  5  50  13   3  28   3 108]\n",
      " [  3  32   4   1  97   0  73]\n",
      " [  5  37  15   2  25   1 125]\n",
      " [  5   9   2   3   5   0 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.22      0.33       210\n",
      "           2       0.38      0.62      0.47       210\n",
      "           3       0.70      0.68      0.69       210\n",
      "           4       0.20      0.01      0.03       210\n",
      "           5       0.40      0.46      0.43       210\n",
      "           6       0.20      0.00      0.01       210\n",
      "           7       0.31      0.89      0.46       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.35      1470\n",
      "weighted avg       0.41      0.41      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 57  19   1   2  71   2  58]\n",
      " [  1 148   7   1  39   1  13]\n",
      " [  4  49 145   1   2   0   9]\n",
      " [  8  46   7   6  51   9  83]\n",
      " [  1  35   2   0 126   0  46]\n",
      " [  7  42   4   3  31   5 118]\n",
      " [  5   9   2   1  13   0 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.27      0.39       210\n",
      "           2       0.43      0.70      0.53       210\n",
      "           3       0.86      0.69      0.77       210\n",
      "           4       0.43      0.03      0.05       210\n",
      "           5       0.38      0.60      0.46       210\n",
      "           6       0.29      0.02      0.04       210\n",
      "           7       0.36      0.86      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.39      1470\n",
      "weighted avg       0.49      0.45      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 64  14   1   4  74   1  52]\n",
      " [  1 141   6   5  45   3   9]\n",
      " [  4  38 150   2   6   4   6]\n",
      " [  6  37   6  23  60   5  73]\n",
      " [  2  34   2   3 126   0  43]\n",
      " [  6  30   6   8  39  16 105]\n",
      " [  3   9   0   6  17   5 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.30      0.43       210\n",
      "           2       0.47      0.67      0.55       210\n",
      "           3       0.88      0.71      0.79       210\n",
      "           4       0.45      0.11      0.18       210\n",
      "           5       0.34      0.60      0.44       210\n",
      "           6       0.47      0.08      0.13       210\n",
      "           7       0.37      0.81      0.51       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.53      0.47      0.43      1470\n",
      "weighted avg       0.53      0.47      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78  10   1   9  66   2  44]\n",
      " [  5 136   5  10  44   1   9]\n",
      " [  3  40 145   4   4   6   8]\n",
      " [  9  26   7  40  50  15  63]\n",
      " [  9  23   1   3 137   1  36]\n",
      " [  6  33   3  17  25  27  99]\n",
      " [  5   6   1   7  16  12 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.37      0.48       210\n",
      "           2       0.50      0.65      0.56       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.44      0.19      0.27       210\n",
      "           5       0.40      0.65      0.50       210\n",
      "           6       0.42      0.13      0.20       210\n",
      "           7       0.39      0.78      0.52       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.53      0.49      0.47      1470\n",
      "weighted avg       0.53      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83   7   1  10  64   8  37]\n",
      " [  1 133   4  11  48   4   9]\n",
      " [  2  35 148   9   4   8   4]\n",
      " [  7  22   3  50  50  18  60]\n",
      " [  9  26   0   6 130   1  38]\n",
      " [  5  20   5  22  31  42  85]\n",
      " [  4   7   0  15  15  10 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.40      0.52       210\n",
      "           2       0.53      0.63      0.58       210\n",
      "           3       0.92      0.70      0.80       210\n",
      "           4       0.41      0.24      0.30       210\n",
      "           5       0.38      0.62      0.47       210\n",
      "           6       0.46      0.20      0.28       210\n",
      "           7       0.41      0.76      0.53       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.50      1470\n",
      "weighted avg       0.55      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87   3   0  10  65  10  35]\n",
      " [  3 139   3  12  39   8   6]\n",
      " [  5  24 159  11   4   5   2]\n",
      " [  9  15   8  62  43  26  47]\n",
      " [ 10  22   2   9 131   1  35]\n",
      " [  4  16   6  18  28  46  92]\n",
      " [  0   6   0  13  16  14 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.41      0.53       210\n",
      "           2       0.62      0.66      0.64       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.46      0.30      0.36       210\n",
      "           5       0.40      0.62      0.49       210\n",
      "           6       0.42      0.22      0.29       210\n",
      "           7       0.43      0.77      0.55       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.56      0.53      0.52      1470\n",
      "weighted avg       0.56      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 91   3   0  11  58  18  29]\n",
      " [  2 135   5  20  37   4   7]\n",
      " [  4  21 161   6   7   8   3]\n",
      " [ 10  17   5  61  41  29  47]\n",
      " [ 11  22   1  11 129   2  34]\n",
      " [  6  16   5  15  21  63  84]\n",
      " [  0   4   1  13   9  19 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.43      0.54       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.90      0.77      0.83       210\n",
      "           4       0.45      0.29      0.35       210\n",
      "           5       0.43      0.61      0.50       210\n",
      "           6       0.44      0.30      0.36       210\n",
      "           7       0.45      0.78      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.54      1470\n",
      "weighted avg       0.57      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89   4   1   7  60  18  31]\n",
      " [  2 139   5  16  33   9   6]\n",
      " [  4  20 160   6   6  11   3]\n",
      " [  5  13   6  75  44  27  40]\n",
      " [ 10  20   1   7 136   3  33]\n",
      " [  9  14   4  24  19  64  76]\n",
      " [  1   3   0   9  15  22 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.42      0.54       210\n",
      "           2       0.65      0.66      0.66       210\n",
      "           3       0.90      0.76      0.83       210\n",
      "           4       0.52      0.36      0.42       210\n",
      "           5       0.43      0.65      0.52       210\n",
      "           6       0.42      0.30      0.35       210\n",
      "           7       0.46      0.76      0.57       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.56      1470\n",
      "weighted avg       0.59      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93   5   0   9  59  21  23]\n",
      " [  1 133   5  21  34  11   5]\n",
      " [  3  17 162   6   7  12   3]\n",
      " [  2  15   7  83  36  28  39]\n",
      " [ 15  19   0   9 133   2  32]\n",
      " [  7  19   3  19  17  69  76]\n",
      " [  4   3   1  11   7  24 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.44      0.56       210\n",
      "           2       0.63      0.63      0.63       210\n",
      "           3       0.91      0.77      0.84       210\n",
      "           4       0.53      0.40      0.45       210\n",
      "           5       0.45      0.63      0.53       210\n",
      "           6       0.41      0.33      0.37       210\n",
      "           7       0.47      0.76      0.58       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.56      1470\n",
      "weighted avg       0.59      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96   3   1  10  57  19  24]\n",
      " [  0 137   6  19  33   8   7]\n",
      " [  4  16 160   9   7  13   1]\n",
      " [  8   9   6  82  38  28  39]\n",
      " [ 14  15   1   7 138   4  31]\n",
      " [ 12  12   4  30  11  72  69]\n",
      " [  2   5   0   6  10  30 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.46      0.55       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.90      0.76      0.82       210\n",
      "           4       0.50      0.39      0.44       210\n",
      "           5       0.47      0.66      0.55       210\n",
      "           6       0.41      0.34      0.38       210\n",
      "           7       0.48      0.75      0.58       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96   2   0  13  56  22  21]\n",
      " [  3 137   5  13  33  13   6]\n",
      " [  3  18 163   6   4  13   3]\n",
      " [  5  12   5  87  37  35  29]\n",
      " [ 14  22   3  12 128   6  25]\n",
      " [  7  18   6  22  17  73  67]\n",
      " [  2   2   0  10   9  31 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.46      0.56       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.53      0.41      0.47       210\n",
      "           5       0.45      0.61      0.52       210\n",
      "           6       0.38      0.35      0.36       210\n",
      "           7       0.51      0.74      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   1   0  14  54  18  21]\n",
      " [  1 142   5  15  28  12   7]\n",
      " [  2  15 168   7   5  12   1]\n",
      " [  2  11   3  90  35  36  33]\n",
      " [ 17  21   1  12 129   4  26]\n",
      " [  4  15   5  25  20  69  72]\n",
      " [  1   5   0   6   9  25 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.49      0.60       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.92      0.80      0.86       210\n",
      "           4       0.53      0.43      0.47       210\n",
      "           5       0.46      0.61      0.53       210\n",
      "           6       0.39      0.33      0.36       210\n",
      "           7       0.51      0.78      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.572108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98   2   1  13  55  18  23]\n",
      " [  3 136   6  18  35   7   5]\n",
      " [  3  13 165   8   6  11   4]\n",
      " [  6   8   5  84  41  33  33]\n",
      " [ 16  20   1  13 127   3  30]\n",
      " [  6  12   4  32  17  77  62]\n",
      " [  1   4   0   9  11  31 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.47      0.57       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.91      0.79      0.84       210\n",
      "           4       0.47      0.40      0.43       210\n",
      "           5       0.43      0.60      0.51       210\n",
      "           6       0.43      0.37      0.39       210\n",
      "           7       0.50      0.73      0.59       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   7   0  10  59  18  19]\n",
      " [  1 137   6  13  37  11   5]\n",
      " [  6  18 163   5   6   8   4]\n",
      " [  7  11   5  93  34  31  29]\n",
      " [ 17  17   1  13 131   4  27]\n",
      " [  5  17   5  22  22  68  71]\n",
      " [  1   3   0   6  10  35 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.46      0.56       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.91      0.78      0.84       210\n",
      "           4       0.57      0.44      0.50       210\n",
      "           5       0.44      0.62      0.51       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.50      0.74      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.57      1470\n",
      "weighted avg       0.60      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   4   1  10  53  19  21]\n",
      " [  0 144   4  11  35  12   4]\n",
      " [  2  20 162   9   2  11   4]\n",
      " [  9  12   2  88  39  31  29]\n",
      " [ 16  19   2  17 128   2  26]\n",
      " [ 11  11   6  26  15  69  72]\n",
      " [  3   3   0   7   8  30 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.49      0.58       210\n",
      "           2       0.68      0.69      0.68       210\n",
      "           3       0.92      0.77      0.84       210\n",
      "           4       0.52      0.42      0.47       210\n",
      "           5       0.46      0.61      0.52       210\n",
      "           6       0.40      0.33      0.36       210\n",
      "           7       0.50      0.76      0.61       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   7   0  10  54  18  20]\n",
      " [  2 140   2  18  29  12   7]\n",
      " [  5  15 165   6   7   9   3]\n",
      " [  7   8   8  90  34  34  29]\n",
      " [ 16  21   1  15 127   5  25]\n",
      " [  8  12   7  26  14  75  68]\n",
      " [  1   7   0   7   8  24 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.48      0.58       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.90      0.79      0.84       210\n",
      "           4       0.52      0.43      0.47       210\n",
      "           5       0.47      0.60      0.53       210\n",
      "           6       0.42      0.36      0.39       210\n",
      "           7       0.52      0.78      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   7   0  13  50  18  23]\n",
      " [  3 136   4  15  32  18   2]\n",
      " [  3  17 164   7   4  14   1]\n",
      " [  7  12   6  92  35  37  21]\n",
      " [ 13  19   2  12 132   9  23]\n",
      " [  8  17   6  21  15  69  74]\n",
      " [  2   5   1   7   9  36 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57       210\n",
      "           2       0.64      0.65      0.64       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.55      0.44      0.49       210\n",
      "           5       0.48      0.63      0.54       210\n",
      "           6       0.34      0.33      0.34       210\n",
      "           7       0.51      0.71      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5850340136054422\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   5   1  10  47  21  25]\n",
      " [  2 141   4  22  27  10   4]\n",
      " [  4  14 164   9   6  13   0]\n",
      " [  8  12   8  92  31  33  26]\n",
      " [ 19  20   0  14 124   8  25]\n",
      " [  7  13   6  26  18  76  64]\n",
      " [  3   5   0   9   5  26 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.48      0.57       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.90      0.78      0.83       210\n",
      "           4       0.51      0.44      0.47       210\n",
      "           5       0.48      0.59      0.53       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.53      0.77      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5829931972789115\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   4   0  11  51  18  20]\n",
      " [  3 143   4  21  25   7   7]\n",
      " [  3  18 163   7   4  15   0]\n",
      " [  7  12   5  89  33  39  25]\n",
      " [ 18  21   1  12 127   7  24]\n",
      " [  9  19   6  25  17  75  59]\n",
      " [  3   5   0  11   8  29 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.50      0.59       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.91      0.78      0.84       210\n",
      "           4       0.51      0.42      0.46       210\n",
      "           5       0.48      0.60      0.53       210\n",
      "           6       0.39      0.36      0.38       210\n",
      "           7       0.53      0.73      0.62       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 73   1   5  15  61  14  41]\n",
      " [  5 126   5  10  51   7   6]\n",
      " [  9  75  91  10  16   6   3]\n",
      " [  6  23   8  53  50  16  54]\n",
      " [  9  21   0  11 127   2  40]\n",
      " [ 16  20   3  24  30  38  79]\n",
      " [  4   5   1  20  25  20 135]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.35      0.44       210\n",
      "           2       0.46      0.60      0.52       210\n",
      "           3       0.81      0.43      0.56       210\n",
      "           4       0.37      0.25      0.30       210\n",
      "           5       0.35      0.60      0.45       210\n",
      "           6       0.37      0.18      0.24       210\n",
      "           7       0.38      0.64      0.48       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.43      1470\n",
      "weighted avg       0.48      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//bert_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[131   6   6  13  31  17   6]\n",
      " [  3 153  10  11  17  13   3]\n",
      " [  4   4 178   6   5  12   1]\n",
      " [ 17   8  16 134  18  12   5]\n",
      " [ 40  16  10  22 108  11   3]\n",
      " [ 22  13  10  14   6 111  34]\n",
      " [  2   3   0   6  10  46 143]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       210\n",
      "           2       0.75      0.73      0.74       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.65      0.64      0.64       210\n",
      "           5       0.55      0.51      0.53       210\n",
      "           6       0.50      0.53      0.51       210\n",
      "           7       0.73      0.68      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.65      1470\n",
      "weighted avg       0.65      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123   5   7  13  51   5   6]\n",
      " [  8 154   9   5  29   4   1]\n",
      " [ 20   6 160  18   3   3   0]\n",
      " [ 37  14   9  86  53   5   6]\n",
      " [ 41  19   7  15 117   1  10]\n",
      " [ 44  15   9  19  15  45  63]\n",
      " [ 17   7   1   5   8  11 161]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.59      0.49       210\n",
      "           2       0.70      0.73      0.72       210\n",
      "           3       0.79      0.76      0.78       210\n",
      "           4       0.53      0.41      0.46       210\n",
      "           5       0.42      0.56      0.48       210\n",
      "           6       0.61      0.21      0.32       210\n",
      "           7       0.65      0.77      0.70       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.56      1470\n",
      "weighted avg       0.59      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121   4   6  18  50   5   6]\n",
      " [  8 154   8   6  28   3   3]\n",
      " [ 17   3 165  18   5   2   0]\n",
      " [ 29   6   9 106  45   7   8]\n",
      " [ 32  17   6  18 123   2  12]\n",
      " [ 38  14   5  14  15  61  63]\n",
      " [ 14   4   1   1   6  17 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.58      0.52       210\n",
      "           2       0.76      0.73      0.75       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.45      0.59      0.51       210\n",
      "           6       0.63      0.29      0.40       210\n",
      "           7       0.64      0.80      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6074829931972789\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114   6   7  17  53   4   9]\n",
      " [  7 153   9   8  28   3   2]\n",
      " [ 16   2 165  19   4   4   0]\n",
      " [ 26   9   9 105  47   6   8]\n",
      " [ 23  14   7  15 136   1  14]\n",
      " [ 32  22   6  15  16  56  63]\n",
      " [ 14   4   0   2   7  19 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.54      0.52       210\n",
      "           2       0.73      0.73      0.73       210\n",
      "           3       0.81      0.79      0.80       210\n",
      "           4       0.58      0.50      0.54       210\n",
      "           5       0.47      0.65      0.54       210\n",
      "           6       0.60      0.27      0.37       210\n",
      "           7       0.63      0.78      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[114   8   7  18  51   7   5]\n",
      " [  8 150  10   6  30   3   3]\n",
      " [ 14   2 179   9   4   2   0]\n",
      " [ 24   9  15  90  60   5   7]\n",
      " [ 26  15   5  15 133   1  15]\n",
      " [ 32  20   8  10  19  52  69]\n",
      " [ 13   5   0   0   7  14 171]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.54      0.52       210\n",
      "           2       0.72      0.71      0.72       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.61      0.43      0.50       210\n",
      "           5       0.44      0.63      0.52       210\n",
      "           6       0.62      0.25      0.35       210\n",
      "           7       0.63      0.81      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.59      1470\n",
      "weighted avg       0.62      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6074829931972789\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[107   7   8  18  57   6   7]\n",
      " [  6 147  10   6  32   4   5]\n",
      " [ 14   1 179  10   5   1   0]\n",
      " [ 24   8  15  94  54   6   9]\n",
      " [ 22  15   4  10 143   2  14]\n",
      " [ 36  19   7   7  18  50  73]\n",
      " [ 12   5   0   0   8  12 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.51      0.50       210\n",
      "           2       0.73      0.70      0.71       210\n",
      "           3       0.80      0.85      0.83       210\n",
      "           4       0.65      0.45      0.53       210\n",
      "           5       0.45      0.68      0.54       210\n",
      "           6       0.62      0.24      0.34       210\n",
      "           7       0.62      0.82      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.59      1470\n",
      "weighted avg       0.62      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6006802721088436\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[ 99   9  10  18  58   7   9]\n",
      " [  8 153   8   7  26   3   5]\n",
      " [ 13   5 173  10   6   2   1]\n",
      " [ 24   9  15  92  56   5   9]\n",
      " [ 18  16   5   9 144   1  17]\n",
      " [ 30  19   8   8  19  50  76]\n",
      " [ 10   5   0   0   9  14 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.47      0.48       210\n",
      "           2       0.71      0.73      0.72       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.64      0.44      0.52       210\n",
      "           5       0.45      0.69      0.55       210\n",
      "           6       0.61      0.24      0.34       210\n",
      "           7       0.60      0.82      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.4816326530612245\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 50  24   3  11  79  33  10]\n",
      " [  4 117   0   5  50  20  14]\n",
      " [ 11   5 108  10  56  20   0]\n",
      " [ 13   7   5  36 100  40   9]\n",
      " [  6  15   0   3 151  15  20]\n",
      " [  7  18   7  13  10  67  88]\n",
      " [  0   6   0   1   2  22 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.24      0.33       210\n",
      "           2       0.61      0.56      0.58       210\n",
      "           3       0.88      0.51      0.65       210\n",
      "           4       0.46      0.17      0.25       210\n",
      "           5       0.34      0.72      0.46       210\n",
      "           6       0.31      0.32      0.31       210\n",
      "           7       0.56      0.85      0.68       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.53      0.48      0.47      1470\n",
      "weighted avg       0.53      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 38  22   3  14  77  44  12]\n",
      " [  4 107   1   7  46  26  19]\n",
      " [ 10   6 107  36  32  19   0]\n",
      " [ 14  10   5  44  89  36  12]\n",
      " [  5  16   0   5 146  18  20]\n",
      " [  9  19   6  11  11  60  94]\n",
      " [  0   8   0   1   1  20 180]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.18      0.26       210\n",
      "           2       0.57      0.51      0.54       210\n",
      "           3       0.88      0.51      0.64       210\n",
      "           4       0.37      0.21      0.27       210\n",
      "           5       0.36      0.70      0.48       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.53      0.86      0.66       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.45      1470\n",
      "weighted avg       0.49      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of SVM is:\n",
      " [[140   6   7  14  23  15   5]\n",
      " [  9 161   8   9  13   8   2]\n",
      " [  7   6 179   8   3   7   0]\n",
      " [ 22  11  10 134  16  15   2]\n",
      " [ 55  24   4  13 105   5   4]\n",
      " [ 26  15  11  10   6 106  36]\n",
      " [  7   2   2   4   8  42 145]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.67      0.59       210\n",
      "           2       0.72      0.77      0.74       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.70      0.64      0.67       210\n",
      "           5       0.60      0.50      0.55       210\n",
      "           6       0.54      0.50      0.52       210\n",
      "           7       0.75      0.69      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.682312925170068\n",
      "Confusion Matrix of SVM is:\n",
      " [[101   2   3  18  60  23   3]\n",
      " [  2 153   4   8  26  16   1]\n",
      " [  8   1 176   9   6  10   0]\n",
      " [ 11   1  11 130  36  18   3]\n",
      " [  7   8   5  11 161  11   7]\n",
      " [ 10   9   7  13  15 116  40]\n",
      " [  0   1   0   1   5  37 166]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.48      0.58       210\n",
      "           2       0.87      0.73      0.79       210\n",
      "           3       0.85      0.84      0.85       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.52      0.77      0.62       210\n",
      "           6       0.50      0.55      0.53       210\n",
      "           7       0.75      0.79      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7027210884353742\n",
      "Confusion Matrix of SVM is:\n",
      " [[119   5   3  13  48  18   4]\n",
      " [  1 165   4   7  19  11   3]\n",
      " [  4   1 181  10   7   7   0]\n",
      " [ 11   1  12 136  28  19   3]\n",
      " [ 16   8   6  12 148   7  13]\n",
      " [ 12  13   9   9   9 106  52]\n",
      " [  1   2   0   1   3  25 178]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.57      0.64       210\n",
      "           2       0.85      0.79      0.81       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.72      0.65      0.68       210\n",
      "           5       0.56      0.70      0.63       210\n",
      "           6       0.55      0.50      0.53       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of SVM is:\n",
      " [[108   7   7  16  52  16   4]\n",
      " [  8 151   6   9  22  11   3]\n",
      " [ 16   5 172   9   4   4   0]\n",
      " [ 22   3  14 120  27  18   6]\n",
      " [ 26  13   8  14 130   4  15]\n",
      " [ 19  19  11  12   8  86  55]\n",
      " [  1   5   1   2   1  36 164]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.53       210\n",
      "           2       0.74      0.72      0.73       210\n",
      "           3       0.79      0.82      0.80       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.53      0.62      0.57       210\n",
      "           6       0.49      0.41      0.45       210\n",
      "           7       0.66      0.78      0.72       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.63      1470\n",
      "weighted avg       0.63      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23061224489795917\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0   0   0 200]\n",
      " [  0   0  17   0   0   0 193]\n",
      " [  0   0 130   0   0   0  80]\n",
      " [  0   0   9   0   0   0 201]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.62      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.14      1470\n",
      "weighted avg       0.13      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  5   0   5   0 188   0  12]\n",
      " [ 10   0   7   0 164   0  29]\n",
      " [  7   0 123   0  78   0   2]\n",
      " [  0   0   9   0 187   0  14]\n",
      " [  0   0   0   0 192   0  18]\n",
      " [  2   0   6   0  98   0 104]\n",
      " [  0   0   1   0  46   0 163]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.02      0.04       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.81      0.59      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.20      0.91      0.33       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.48      0.78      0.59       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.24      0.33      0.23      1470\n",
      "weighted avg       0.24      0.33      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  4  70   3   0 118  10   5]\n",
      " [  0 117  10   0  47  29   7]\n",
      " [  2  24  81   0  54  49   0]\n",
      " [  0  50   3   0 137  18   2]\n",
      " [  0  23   0   0 169   4  14]\n",
      " [  2  60   2   0  38  60  48]\n",
      " [  0  30   1   0  16  46 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.02      0.04       210\n",
      "           2       0.31      0.56      0.40       210\n",
      "           3       0.81      0.39      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.29      0.80      0.43       210\n",
      "           6       0.28      0.29      0.28       210\n",
      "           7       0.61      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.40      0.37      0.32      1470\n",
      "weighted avg       0.40      0.37      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  14   2  72  49   7   5]\n",
      " [ 42  90   1  16  38  18   5]\n",
      " [ 12  13  80  74  29   2   0]\n",
      " [ 41  11   3  95  48  10   2]\n",
      " [ 14   9   0  55 114   7  11]\n",
      " [ 48  30   2  30  12  44  44]\n",
      " [ 20  19   1  10   6  43 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.29      0.27       210\n",
      "           2       0.48      0.43      0.45       210\n",
      "           3       0.90      0.38      0.54       210\n",
      "           4       0.27      0.45      0.34       210\n",
      "           5       0.39      0.54      0.45       210\n",
      "           6       0.34      0.21      0.26       210\n",
      "           7       0.62      0.53      0.57       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.46      0.40      0.41      1470\n",
      "weighted avg       0.46      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 48  17   2  75  49  11   8]\n",
      " [ 12  99  11  39  35   7   7]\n",
      " [  8  12  95  76  15   3   1]\n",
      " [ 16  11   5 107  47  13  11]\n",
      " [  5  12   0  54 114  13  12]\n",
      " [ 24  28   2  39  13  29  75]\n",
      " [ 12  15   1   9   6  24 143]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.23      0.29       210\n",
      "           2       0.51      0.47      0.49       210\n",
      "           3       0.82      0.45      0.58       210\n",
      "           4       0.27      0.51      0.35       210\n",
      "           5       0.41      0.54      0.47       210\n",
      "           6       0.29      0.14      0.19       210\n",
      "           7       0.56      0.68      0.61       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.43      1470\n",
      "weighted avg       0.46      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  11   2  62  50  26  10]\n",
      " [ 22 124   3   9  24  23   5]\n",
      " [  7   8  99  71  11  14   0]\n",
      " [ 16  15   4  82  45  38  10]\n",
      " [  5  17   0  45 110  17  16]\n",
      " [ 26  23   3  16  15  64  63]\n",
      " [ 12   9   1   1   7  44 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.23      0.28       210\n",
      "           2       0.60      0.59      0.59       210\n",
      "           3       0.88      0.47      0.61       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.42      0.52      0.47       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.57      0.65      0.60       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4387755102040816\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79   6   5  67  30  13  10]\n",
      " [ 25 104  13  35  15  16   2]\n",
      " [ 20   7 111  61   5   6   0]\n",
      " [ 42   5   5  89  33  26  10]\n",
      " [ 40   9   2  51  82   9  17]\n",
      " [ 34  13   4  41   7  54  57]\n",
      " [ 19   5   1  10   2  47 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.38      0.34       210\n",
      "           2       0.70      0.50      0.58       210\n",
      "           3       0.79      0.53      0.63       210\n",
      "           4       0.25      0.42      0.32       210\n",
      "           5       0.47      0.39      0.43       210\n",
      "           6       0.32      0.26      0.28       210\n",
      "           7       0.57      0.60      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.49      0.44      0.45      1470\n",
      "weighted avg       0.49      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46190476190476193\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   6   4  45  46  20   8]\n",
      " [ 17 105  10  26  34  13   5]\n",
      " [ 20   4 112  59   8   7   0]\n",
      " [ 29   6   5  89  44  30   7]\n",
      " [ 30  11   3  41 102   8  15]\n",
      " [ 25  16   9  29  15  63  53]\n",
      " [ 10   7   3   8   9  46 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.39      0.38       210\n",
      "           2       0.68      0.50      0.58       210\n",
      "           3       0.77      0.53      0.63       210\n",
      "           4       0.30      0.42      0.35       210\n",
      "           5       0.40      0.49      0.44       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.59      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 64   8   7  43  56  20  12]\n",
      " [  4 117   7  19  31  14  18]\n",
      " [  5   4 121  58  15   6   1]\n",
      " [ 16  11   9  75  61  23  15]\n",
      " [ 11  10   5  35 123   8  18]\n",
      " [ 15  21   6  26  16  55  71]\n",
      " [ 11   8   1   8   6  41 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.30      0.38       210\n",
      "           2       0.65      0.56      0.60       210\n",
      "           3       0.78      0.58      0.66       210\n",
      "           4       0.28      0.36      0.32       210\n",
      "           5       0.40      0.59      0.47       210\n",
      "           6       0.33      0.26      0.29       210\n",
      "           7       0.50      0.64      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.47      1470\n",
      "weighted avg       0.49      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 87  12   9  28  51  19   4]\n",
      " [ 27 116   8  12  29  12   6]\n",
      " [ 14   5 121  52  11   6   1]\n",
      " [ 40  15  11  63  49  19  13]\n",
      " [ 38  13   4  18 114   8  15]\n",
      " [ 31  21   7  22  11  51  67]\n",
      " [ 15   9   3   8   5  38 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.41      0.38       210\n",
      "           2       0.61      0.55      0.58       210\n",
      "           3       0.74      0.58      0.65       210\n",
      "           4       0.31      0.30      0.31       210\n",
      "           5       0.42      0.54      0.48       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.55      0.63      0.59       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  11   6  30  54  20   7]\n",
      " [ 22 109  10  19  31  13   6]\n",
      " [ 12   5 114  52  12   9   6]\n",
      " [ 35   9   7  73  54  20  12]\n",
      " [ 43  10   5  29  99  11  13]\n",
      " [ 18  18  10  32  12  66  54]\n",
      " [ 14  12   3  14   7  37 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.39      0.38       210\n",
      "           2       0.63      0.52      0.57       210\n",
      "           3       0.74      0.54      0.62       210\n",
      "           4       0.29      0.35      0.32       210\n",
      "           5       0.37      0.47      0.41       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.56      0.59      0.57       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.46      1470\n",
      "weighted avg       0.47      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   8   8  41  47  19   7]\n",
      " [ 23 108   8  25  22  11  13]\n",
      " [  5   2 127  55  11   8   2]\n",
      " [ 37  14  12  73  49  14  11]\n",
      " [ 32  10   5  45  91  10  17]\n",
      " [ 18  26   8  33  10  57  58]\n",
      " [ 13  10   1  10   7  41 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38       210\n",
      "           2       0.61      0.51      0.56       210\n",
      "           3       0.75      0.60      0.67       210\n",
      "           4       0.26      0.35      0.30       210\n",
      "           5       0.38      0.43      0.41       210\n",
      "           6       0.36      0.27      0.31       210\n",
      "           7       0.54      0.61      0.57       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.46      1470\n",
      "weighted avg       0.47      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86   9   9  36  42  22   6]\n",
      " [ 19 104  11  28  26  13   9]\n",
      " [  6   5 124  56  10   9   0]\n",
      " [ 29  16   9  72  56  16  12]\n",
      " [ 30  16   6  38  97   8  15]\n",
      " [ 22  24  12  28  16  55  53]\n",
      " [  9   8   2  12   6  45 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.41      0.42       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.72      0.59      0.65       210\n",
      "           4       0.27      0.34      0.30       210\n",
      "           5       0.38      0.46      0.42       210\n",
      "           6       0.33      0.26      0.29       210\n",
      "           7       0.57      0.61      0.59       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.46      1470\n",
      "weighted avg       0.47      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4387755102040816\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  12   9  35  42  25  10]\n",
      " [ 21 106   9  17  27  18  12]\n",
      " [  9   7 121  54  10   7   2]\n",
      " [ 32  15  12  70  47  22  12]\n",
      " [ 30  15   8  30  93  17  17]\n",
      " [ 22  27  10  27  11  55  58]\n",
      " [ 11   9   4  13   8  42 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.37      0.37       210\n",
      "           2       0.55      0.50      0.53       210\n",
      "           3       0.70      0.58      0.63       210\n",
      "           4       0.28      0.33      0.31       210\n",
      "           5       0.39      0.44      0.42       210\n",
      "           6       0.30      0.26      0.28       210\n",
      "           7       0.53      0.59      0.55       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   6  11  41  43  24   5]\n",
      " [ 20 104  10  18  31  17  10]\n",
      " [ 11   3 128  51   9   7   1]\n",
      " [ 29  15  15  66  54  19  12]\n",
      " [ 32  12  15  31  92  14  14]\n",
      " [ 21  26  11  28  16  55  53]\n",
      " [ 15   6   4  11   6  43 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38       210\n",
      "           2       0.60      0.50      0.54       210\n",
      "           3       0.66      0.61      0.63       210\n",
      "           4       0.27      0.31      0.29       210\n",
      "           5       0.37      0.44      0.40       210\n",
      "           6       0.31      0.26      0.28       210\n",
      "           7       0.57      0.60      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  10   8  38  41  23  11]\n",
      " [ 21 105  13  18  30  16   7]\n",
      " [ 10   3 127  50  12   8   0]\n",
      " [ 25  17  14  70  52  20  12]\n",
      " [ 32  13  12  37  85  17  14]\n",
      " [ 21  26  10  29  16  59  49]\n",
      " [ 10  10   2  11   9  45 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.38      0.39       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.68      0.60      0.64       210\n",
      "           4       0.28      0.33      0.30       210\n",
      "           5       0.35      0.40      0.37       210\n",
      "           6       0.31      0.28      0.30       210\n",
      "           7       0.57      0.59      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   9   8  36  37  30  10]\n",
      " [ 18 105  12  22  27  17   9]\n",
      " [ 10   4 122  54   7  11   2]\n",
      " [ 36  14  12  73  45  17  13]\n",
      " [ 31  17  10  36  85  15  16]\n",
      " [ 13  21  13  31  14  61  57]\n",
      " [ 12   9   2  12   6  43 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.38      0.39       210\n",
      "           2       0.59      0.50      0.54       210\n",
      "           3       0.68      0.58      0.63       210\n",
      "           4       0.28      0.35      0.31       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.31      0.29      0.30       210\n",
      "           7       0.54      0.60      0.57       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.45      1470\n",
      "weighted avg       0.45      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   7   7  37  42  25   7]\n",
      " [ 18 111   6  22  27  16  10]\n",
      " [ 10   6 124  51  10   8   1]\n",
      " [ 28  19  11  79  46  15  12]\n",
      " [ 38   9  11  33  89  17  13]\n",
      " [ 18  24  10  29  17  55  57]\n",
      " [ 12   9   0  15   7  45 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.40      0.41       210\n",
      "           2       0.60      0.53      0.56       210\n",
      "           3       0.73      0.59      0.65       210\n",
      "           4       0.30      0.38      0.33       210\n",
      "           5       0.37      0.42      0.40       210\n",
      "           6       0.30      0.26      0.28       210\n",
      "           7       0.55      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.46      1470\n",
      "weighted avg       0.47      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  10  10  38  44  24   9]\n",
      " [ 17 108  10  15  29  20  11]\n",
      " [  7   6 122  55   8  10   2]\n",
      " [ 31  12  10  71  49  23  14]\n",
      " [ 32  15  11  36  85  15  16]\n",
      " [ 16  31   7  32  13  56  55]\n",
      " [ 10  10   2  14   6  44 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.36      0.38       210\n",
      "           2       0.56      0.51      0.54       210\n",
      "           3       0.71      0.58      0.64       210\n",
      "           4       0.27      0.34      0.30       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.54      0.59      0.56       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43945578231292515\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  10  13  33  42  27   9]\n",
      " [ 21 108   7  16  26  18  14]\n",
      " [  9   6 126  53   7   9   0]\n",
      " [ 27  11  15  70  52  22  13]\n",
      " [ 32  10   9  37  86  18  18]\n",
      " [ 19  24  13  28  18  57  51]\n",
      " [  8  12   2  13  10  42 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.36      0.38       210\n",
      "           2       0.60      0.51      0.55       210\n",
      "           3       0.68      0.60      0.64       210\n",
      "           4       0.28      0.33      0.30       210\n",
      "           5       0.36      0.41      0.38       210\n",
      "           6       0.30      0.27      0.28       210\n",
      "           7       0.54      0.59      0.56       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  5  19  16   1 114   2  53]\n",
      " [  0  33  24   1  72   0  80]\n",
      " [  1   2 169   1  25   1  11]\n",
      " [  4   2  21   3 138   2  40]\n",
      " [  0   5   5   0 166   0  34]\n",
      " [  0   9  19   0  31   1 150]\n",
      " [  0   2   2   0   3   0 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.02      0.05       210\n",
      "           2       0.46      0.16      0.23       210\n",
      "           3       0.66      0.80      0.73       210\n",
      "           4       0.50      0.01      0.03       210\n",
      "           5       0.30      0.79      0.44       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.36      0.97      0.52       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.42      0.39      0.29      1470\n",
      "weighted avg       0.42      0.39      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20  31  14   0 107   2  36]\n",
      " [  0  88  12   0  71   0  39]\n",
      " [  1  13 157   3  33   0   3]\n",
      " [  2  20  14   8 132   2  32]\n",
      " [  0  13   3   0 166   0  28]\n",
      " [  1  26  17   2  26   5 133]\n",
      " [  0   8   1   0   2   0 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.10      0.17       210\n",
      "           2       0.44      0.42      0.43       210\n",
      "           3       0.72      0.75      0.73       210\n",
      "           4       0.62      0.04      0.07       210\n",
      "           5       0.31      0.79      0.44       210\n",
      "           6       0.56      0.02      0.05       210\n",
      "           7       0.42      0.95      0.59       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.56      0.44      0.35      1470\n",
      "weighted avg       0.56      0.44      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 30  45   5  13  86  17  14]\n",
      " [  1 131   6   2  46   0  24]\n",
      " [  1  19 155   6  29   0   0]\n",
      " [  4  31   8  23 108  20  16]\n",
      " [  2  23   2   3 151   6  23]\n",
      " [  6  46  12   4  16  17 109]\n",
      " [  1  10   1   0   1   5 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.14      0.24       210\n",
      "           2       0.43      0.62      0.51       210\n",
      "           3       0.82      0.74      0.78       210\n",
      "           4       0.45      0.11      0.18       210\n",
      "           5       0.35      0.72      0.47       210\n",
      "           6       0.26      0.08      0.12       210\n",
      "           7       0.51      0.91      0.65       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.42      1470\n",
      "weighted avg       0.50      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 59  25   5  16  72  24   9]\n",
      " [  2 140   2  11  34   6  15]\n",
      " [ 15   8 160  16   9   2   0]\n",
      " [ 16  16   9  60  70  26  13]\n",
      " [  5  21   2  10 142  10  20]\n",
      " [ 16  30   8  11   8  37 100]\n",
      " [  1   8   1   1   1  12 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.28      0.36       210\n",
      "           2       0.56      0.67      0.61       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.48      0.29      0.36       210\n",
      "           5       0.42      0.68      0.52       210\n",
      "           6       0.32      0.18      0.23       210\n",
      "           7       0.54      0.89      0.67       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.51      1470\n",
      "weighted avg       0.53      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77  17   1  22  57  28   8]\n",
      " [  3 141   4  14  25  11  12]\n",
      " [ 60   6 117  12   9   5   1]\n",
      " [ 18  15   3  84  51  29  10]\n",
      " [ 14  20   2  10 135  11  18]\n",
      " [ 19  24   3  14   6  51  93]\n",
      " [  0   7   1   0   2  18 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.37      0.38       210\n",
      "           2       0.61      0.67      0.64       210\n",
      "           3       0.89      0.56      0.69       210\n",
      "           4       0.54      0.40      0.46       210\n",
      "           5       0.47      0.64      0.55       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.56      0.87      0.68       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 81  11   1  22  58  29   8]\n",
      " [  0 135   3  15  28  15  14]\n",
      " [ 43   5 132  17   5   7   1]\n",
      " [ 15   9   7  81  53  33  12]\n",
      " [  9  15   2  14 137  16  17]\n",
      " [  9  21   6  14   6  66  88]\n",
      " [  3   6   1   0   1  18 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.39      0.44       210\n",
      "           2       0.67      0.64      0.66       210\n",
      "           3       0.87      0.63      0.73       210\n",
      "           4       0.50      0.39      0.43       210\n",
      "           5       0.48      0.65      0.55       210\n",
      "           6       0.36      0.31      0.34       210\n",
      "           7       0.56      0.86      0.68       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  14   2  22  54  28   7]\n",
      " [  2 143   1  15  24  15  10]\n",
      " [ 53   6 121  16   6   8   0]\n",
      " [ 17   6   2  99  43  32  11]\n",
      " [  8  16   2  17 133  17  17]\n",
      " [ 16  15   3  18   4  72  82]\n",
      " [  0   6   0   0   2  25 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.40      0.43       210\n",
      "           2       0.69      0.68      0.69       210\n",
      "           3       0.92      0.58      0.71       210\n",
      "           4       0.53      0.47      0.50       210\n",
      "           5       0.50      0.63      0.56       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.58      0.84      0.69       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.56      1470\n",
      "weighted avg       0.58      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  10   0  18  55  25   9]\n",
      " [  2 143   3  14  22  16  10]\n",
      " [ 54   4 124  12   8   8   0]\n",
      " [ 17   7   2 102  40  32  10]\n",
      " [  8  16   2  16 137  14  17]\n",
      " [ 17  18   3  11   7  70  84]\n",
      " [  1   7   0   0   3  21 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.44      0.46       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.93      0.59      0.72       210\n",
      "           4       0.59      0.49      0.53       210\n",
      "           5       0.50      0.65      0.57       210\n",
      "           6       0.38      0.33      0.35       210\n",
      "           7       0.58      0.85      0.69       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.57      1470\n",
      "weighted avg       0.59      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 91  10   1  16  55  28   9]\n",
      " [  2 143   3  14  23  14  11]\n",
      " [ 56   1 118  16   6  13   0]\n",
      " [ 19   6   3 104  39  30   9]\n",
      " [ 11  15   2  17 137  12  16]\n",
      " [ 17  14   3  16   6  73  81]\n",
      " [  2   6   0   0   1  25 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.43      0.45       210\n",
      "           2       0.73      0.68      0.71       210\n",
      "           3       0.91      0.56      0.69       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.58      0.84      0.69       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.57      1470\n",
      "weighted avg       0.59      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  11   0  20  52  28   6]\n",
      " [  2 147   3  12  22  15   9]\n",
      " [ 56   3 125  12   4  10   0]\n",
      " [ 24   6   3 105  36  26  10]\n",
      " [ 12  13   2  16 134  14  19]\n",
      " [ 15  11   2  13  10  81  78]\n",
      " [  3   4   0   0   2  20 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.44      0.45       210\n",
      "           2       0.75      0.70      0.73       210\n",
      "           3       0.93      0.60      0.72       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.42      0.39      0.40       210\n",
      "           7       0.60      0.86      0.71       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99  11   0  25  42  24   9]\n",
      " [  1 154   2   9  20  14  10]\n",
      " [ 52   4 125  11   9   9   0]\n",
      " [ 22   4   1 108  35  29  11]\n",
      " [ 13  14   3  11 137  15  17]\n",
      " [ 12  13   3  10  10  85  77]\n",
      " [  2   3   0   0   3  24 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.47      0.48       210\n",
      "           2       0.76      0.73      0.75       210\n",
      "           3       0.93      0.60      0.73       210\n",
      "           4       0.62      0.51      0.56       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.59      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92   9   1  15  58  25  10]\n",
      " [  2 150   5   9  23  15   6]\n",
      " [ 53   2 126  11   5  13   0]\n",
      " [ 23   5   2 109  34  27  10]\n",
      " [ 13  14   3  17 134  14  15]\n",
      " [ 15  17   3  11   7  86  71]\n",
      " [  4   2   0   0   1  27 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.44      0.45       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.63      0.52      0.57       210\n",
      "           5       0.51      0.64      0.57       210\n",
      "           6       0.42      0.41      0.41       210\n",
      "           7       0.61      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   7   0  18  52  25   5]\n",
      " [  3 152   2  10  20  17   6]\n",
      " [ 49   2 131  12   6  10   0]\n",
      " [ 20   8   2 115  32  26   7]\n",
      " [ 16  12   4  17 133  11  17]\n",
      " [ 14  14   4  16   6  91  65]\n",
      " [  2   3   0   0   2  31 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.49      0.49       210\n",
      "           2       0.77      0.72      0.75       210\n",
      "           3       0.92      0.62      0.74       210\n",
      "           4       0.61      0.55      0.58       210\n",
      "           5       0.53      0.63      0.58       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.63      0.82      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  11   0  18  52  31   5]\n",
      " [  4 153   3   9  20  11  10]\n",
      " [ 54   3 127   9   6  10   1]\n",
      " [ 19   5   2 114  36  23  11]\n",
      " [ 14  13   5  16 138   8  16]\n",
      " [ 14  18   4  14   6  79  75]\n",
      " [  2   4   1   0   2  26 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.44      0.45       210\n",
      "           2       0.74      0.73      0.73       210\n",
      "           3       0.89      0.60      0.72       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.53      0.66      0.59       210\n",
      "           6       0.42      0.38      0.40       210\n",
      "           7       0.60      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100  11   0  22  49  21   7]\n",
      " [  3 153   4   9  18  15   8]\n",
      " [ 54   2 124  12   8  10   0]\n",
      " [ 19   4   3 108  40  31   5]\n",
      " [ 17  12   3  22 130  12  14]\n",
      " [ 15  17   2  13   6  80  77]\n",
      " [  1   3   0   0   2  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.48      0.48       210\n",
      "           2       0.76      0.73      0.74       210\n",
      "           3       0.91      0.59      0.72       210\n",
      "           4       0.58      0.51      0.55       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.41      0.38      0.40       210\n",
      "           7       0.62      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   9   1  18  51  25   6]\n",
      " [  5 146   4  12  23  14   6]\n",
      " [ 54   3 128  12   4   9   0]\n",
      " [ 25   4   3 111  35  24   8]\n",
      " [ 15  11   4  16 136  12  16]\n",
      " [ 16  16   3   7  10  90  68]\n",
      " [  1   3   0   2   1  33 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.90      0.61      0.73       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.52      0.65      0.58       210\n",
      "           6       0.43      0.43      0.43       210\n",
      "           7       0.62      0.81      0.70       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105  10   1  17  46  25   6]\n",
      " [  3 154   3  13  14  13  10]\n",
      " [ 53   5 125  13   4  10   0]\n",
      " [ 26   4   3 115  29  27   6]\n",
      " [ 14  12   2  22 134   9  17]\n",
      " [ 18  15   3  11   7  80  76]\n",
      " [  3   3   0   1   1  29 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.50      0.49       210\n",
      "           2       0.76      0.73      0.75       210\n",
      "           3       0.91      0.60      0.72       210\n",
      "           4       0.60      0.55      0.57       210\n",
      "           5       0.57      0.64      0.60       210\n",
      "           6       0.41      0.38      0.40       210\n",
      "           7       0.60      0.82      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  11   0  18  49  22   9]\n",
      " [  5 149   3  13  19  13   8]\n",
      " [ 58   3 125  10   6   8   0]\n",
      " [ 22   4   5 105  37  29   8]\n",
      " [ 20  10   3  18 134  10  15]\n",
      " [ 16  16   2  14   9  83  70]\n",
      " [  1   3   0   1   2  29 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.48      0.47       210\n",
      "           2       0.76      0.71      0.73       210\n",
      "           3       0.91      0.60      0.72       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.52      0.64      0.58       210\n",
      "           6       0.43      0.40      0.41       210\n",
      "           7       0.61      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   6   1  17  48  27   7]\n",
      " [  3 146   4  13  20  17   7]\n",
      " [ 55   5 129  12   3   5   1]\n",
      " [ 21   4   4 110  37  27   7]\n",
      " [ 16  14   2  21 129  11  17]\n",
      " [ 13  17   2   9  12  88  69]\n",
      " [  2   3   0   1   2  28 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.75      0.70      0.72       210\n",
      "           3       0.91      0.61      0.73       210\n",
      "           4       0.60      0.52      0.56       210\n",
      "           5       0.51      0.61      0.56       210\n",
      "           6       0.43      0.42      0.43       210\n",
      "           7       0.62      0.83      0.71       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97  10   0  19  52  25   7]\n",
      " [  3 148   3  14  16  18   8]\n",
      " [ 53   4 124  14   4  10   1]\n",
      " [ 19   3   4 115  32  27  10]\n",
      " [ 17  13   2  17 134  12  15]\n",
      " [ 15  15   3  12   9  87  69]\n",
      " [  4   4   0   1   2  25 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.46      0.46       210\n",
      "           2       0.75      0.70      0.73       210\n",
      "           3       0.91      0.59      0.72       210\n",
      "           4       0.60      0.55      0.57       210\n",
      "           5       0.54      0.64      0.58       210\n",
      "           6       0.43      0.41      0.42       210\n",
      "           7       0.61      0.83      0.70       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 47  25   4  15  76  36   7]\n",
      " [  5 114   8   5  48  12  18]\n",
      " [ 10   6  99  35  44  16   0]\n",
      " [ 15  11   7  42  93  31  11]\n",
      " [  6  18   0   4 147  19  16]\n",
      " [ 10  21   8  13  12  57  89]\n",
      " [  0   7   0   1   2  22 178]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.22      0.31       210\n",
      "           2       0.56      0.54      0.55       210\n",
      "           3       0.79      0.47      0.59       210\n",
      "           4       0.37      0.20      0.26       210\n",
      "           5       0.35      0.70      0.47       210\n",
      "           6       0.30      0.27      0.28       210\n",
      "           7       0.56      0.85      0.67       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.45      1470\n",
      "weighted avg       0.49      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7428571428571429\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[152   4   0   2  37   9   6]\n",
      " [  2 167   6   7  12  10   6]\n",
      " [  0   7 191   5   2   5   0]\n",
      " [  4  11   4 162   9  15   5]\n",
      " [ 27  12   7  14 136   7   7]\n",
      " [  8  10   4  12   3 132  41]\n",
      " [  3   5   1   1   5  43 152]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.72      0.75       210\n",
      "           2       0.77      0.80      0.78       210\n",
      "           3       0.90      0.91      0.90       210\n",
      "           4       0.80      0.77      0.78       210\n",
      "           5       0.67      0.65      0.66       210\n",
      "           6       0.60      0.63      0.61       210\n",
      "           7       0.70      0.72      0.71       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6448979591836734\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   4   1  10  52   4   5]\n",
      " [  7 155  13  10  22   0   3]\n",
      " [  8  10 183   4   4   1   0]\n",
      " [ 18  12   9 134  28   7   2]\n",
      " [ 34  23   6  13 129   2   3]\n",
      " [ 21  24   8  33  11  61  52]\n",
      " [ 10   6   1  11  15  15 152]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.64      0.61       210\n",
      "           2       0.66      0.74      0.70       210\n",
      "           3       0.83      0.87      0.85       210\n",
      "           4       0.62      0.64      0.63       210\n",
      "           5       0.49      0.61      0.55       210\n",
      "           6       0.68      0.29      0.41       210\n",
      "           7       0.70      0.72      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   3   3   6  43   9   6]\n",
      " [  4 155  13   9  23   1   5]\n",
      " [ 10   8 178   6   5   3   0]\n",
      " [ 16   9   9 147  21   6   2]\n",
      " [ 39  23   9  16 118   1   4]\n",
      " [ 23  18   8  30  10  67  54]\n",
      " [  6   3   0   9  12  30 150]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.67      0.62       210\n",
      "           2       0.71      0.74      0.72       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.66      0.70      0.68       210\n",
      "           5       0.51      0.56      0.53       210\n",
      "           6       0.57      0.32      0.41       210\n",
      "           7       0.68      0.71      0.70       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[127   2   3  10  55   7   6]\n",
      " [  3 158  10   7  25   2   5]\n",
      " [ 10   6 182   5   4   3   0]\n",
      " [ 13   8   9 146  21  10   3]\n",
      " [ 25  18   7  16 136   5   3]\n",
      " [ 18  15   8  29  15  63  62]\n",
      " [  6   3   1   9  11  22 158]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.60      0.62       210\n",
      "           2       0.75      0.75      0.75       210\n",
      "           3       0.83      0.87      0.85       210\n",
      "           4       0.66      0.70      0.68       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.56      0.30      0.39       210\n",
      "           7       0.67      0.75      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   4   3   7  49   6   6]\n",
      " [  2 157  10   7  29   0   5]\n",
      " [  5   6 186   5   5   3   0]\n",
      " [ 10   5  16 145  20   8   6]\n",
      " [ 34  19   8  15 123   4   7]\n",
      " [ 19  14   8  33  15  60  61]\n",
      " [  5   2   1   9  13  18 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.64      0.64       210\n",
      "           2       0.76      0.75      0.75       210\n",
      "           3       0.80      0.89      0.84       210\n",
      "           4       0.66      0.69      0.67       210\n",
      "           5       0.48      0.59      0.53       210\n",
      "           6       0.61      0.29      0.39       210\n",
      "           7       0.66      0.77      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125   4   3   8  56   7   7]\n",
      " [  3 151  13   9  29   1   4]\n",
      " [  4   6 188   4   5   3   0]\n",
      " [  9   7  14 145  20   9   6]\n",
      " [ 26  19   8  13 131   3  10]\n",
      " [ 17  15   7  30  14  66  61]\n",
      " [  6   3   1   8  12  16 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.60      0.62       210\n",
      "           2       0.74      0.72      0.73       210\n",
      "           3       0.80      0.90      0.85       210\n",
      "           4       0.67      0.69      0.68       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.63      0.31      0.42       210\n",
      "           7       0.65      0.78      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[130   3   3   8  51   6   9]\n",
      " [  3 151  14   8  26   3   5]\n",
      " [  5   6 186   6   4   3   0]\n",
      " [  9  10  16 144  18   5   8]\n",
      " [ 32  17   8  14 130   4   5]\n",
      " [ 21  16   9  24  17  63  60]\n",
      " [  4   2   1   9  10  16 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.62      0.63       210\n",
      "           2       0.74      0.72      0.73       210\n",
      "           3       0.78      0.89      0.83       210\n",
      "           4       0.68      0.69      0.68       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.63      0.30      0.41       210\n",
      "           7       0.66      0.80      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.507482993197279\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 85   5  12  11  46  12  39]\n",
      " [  0 146  16   1  29   7  11]\n",
      " [  4  31 147  15   2   8   3]\n",
      " [  6  20  12  77  27  12  56]\n",
      " [ 21  19   1  11 113   2  43]\n",
      " [  9  24  12  26  15  34  90]\n",
      " [  0  11   0  15  14  26 144]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.40      0.51       210\n",
      "           2       0.57      0.70      0.63       210\n",
      "           3       0.73      0.70      0.72       210\n",
      "           4       0.49      0.37      0.42       210\n",
      "           5       0.46      0.54      0.50       210\n",
      "           6       0.34      0.16      0.22       210\n",
      "           7       0.37      0.69      0.48       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.4850340136054422\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 84   5  12  12  44  16  37]\n",
      " [  0 144  10   4  34   6  12]\n",
      " [  1  27 153  12   3  11   3]\n",
      " [  6  21  18  69  28  13  55]\n",
      " [ 28  18   0  10 109   2  43]\n",
      " [ 12  25  11  27  18  31  86]\n",
      " [  0  13   0  33  19  22 123]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.40      0.49       210\n",
      "           2       0.57      0.69      0.62       210\n",
      "           3       0.75      0.73      0.74       210\n",
      "           4       0.41      0.33      0.37       210\n",
      "           5       0.43      0.52      0.47       210\n",
      "           6       0.31      0.15      0.20       210\n",
      "           7       0.34      0.59      0.43       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.47      1470\n",
      "weighted avg       0.49      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7421768707482993\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   0   0   3  31  13   1]\n",
      " [  2 170   9  10  12   7   0]\n",
      " [  1   5 194   5   2   3   0]\n",
      " [  8  12  10 156   7  15   2]\n",
      " [ 36  15   1  15 130   7   6]\n",
      " [ 13  12   6  14   2 129  34]\n",
      " [  5   1   0   3   6  45 150]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.77      0.74       210\n",
      "           2       0.79      0.81      0.80       210\n",
      "           3       0.88      0.92      0.90       210\n",
      "           4       0.76      0.74      0.75       210\n",
      "           5       0.68      0.62      0.65       210\n",
      "           6       0.59      0.61      0.60       210\n",
      "           7       0.78      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of SVM is:\n",
      " [[117   0   0  11  53  25   4]\n",
      " [  0 154   3  18  22  12   1]\n",
      " [  0   2 177  20   6   5   0]\n",
      " [  2   2   4 165  20  16   1]\n",
      " [  7   3   1  24 166   6   3]\n",
      " [  3   2   4  23  12 133  33]\n",
      " [  1   1   0  10   6  35 157]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.56      0.69       210\n",
      "           2       0.94      0.73      0.82       210\n",
      "           3       0.94      0.84      0.89       210\n",
      "           4       0.61      0.79      0.69       210\n",
      "           5       0.58      0.79      0.67       210\n",
      "           6       0.57      0.63      0.60       210\n",
      "           7       0.79      0.75      0.77       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.76      0.73      0.73      1470\n",
      "weighted avg       0.76      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7639455782312925\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   0   0   7  38  21   6]\n",
      " [  0 173   6   8   9  12   2]\n",
      " [  2   1 192   6   1   8   0]\n",
      " [  3   5   4 160  12  21   5]\n",
      " [ 22  14   2  16 144   6   6]\n",
      " [  4   7   2  14   5 137  41]\n",
      " [  0   1   0   1   5  24 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.66      0.73       210\n",
      "           2       0.86      0.82      0.84       210\n",
      "           3       0.93      0.91      0.92       210\n",
      "           4       0.75      0.76      0.76       210\n",
      "           5       0.67      0.69      0.68       210\n",
      "           6       0.60      0.65      0.62       210\n",
      "           7       0.75      0.85      0.80       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[142   0   0   4  36  22   6]\n",
      " [  1 172   8   8  10   9   2]\n",
      " [  1   3 196   6   0   4   0]\n",
      " [  4   8   9 143  13  27   6]\n",
      " [ 27  14   4  22 127   5  11]\n",
      " [  9  11   4  17   4 103  62]\n",
      " [  0   1   0   3   6  27 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.89      0.93      0.91       210\n",
      "           4       0.70      0.68      0.69       210\n",
      "           5       0.65      0.60      0.63       210\n",
      "           6       0.52      0.49      0.51       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[208   0   2   0   0   0   0]\n",
      " [190   0  20   0   0   0   0]\n",
      " [ 93   0 117   0   0   0   0]\n",
      " [200   0  10   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [205   0   5   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.99      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.75      0.56      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.28435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[175   1   1   0   0   0  33]\n",
      " [172   9  11   0   0   0  18]\n",
      " [ 87  37  80   0   0   0   6]\n",
      " [134   5   5   0   0   0  66]\n",
      " [157   1   0   0   0   0  52]\n",
      " [110   1   1   0   0   0  98]\n",
      " [ 51   4   1   0   0   0 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.83      0.32       210\n",
      "           2       0.16      0.04      0.07       210\n",
      "           3       0.81      0.38      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      0.73      0.48       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.22      0.28      0.20      1470\n",
      "weighted avg       0.22      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3442176870748299\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[169   6   1  12   0   0  22]\n",
      " [ 89  86   9  17   0   0   9]\n",
      " [ 71  19  80  37   0   0   3]\n",
      " [122  13   2  53   0   0  20]\n",
      " [149   9   0  20   0   0  32]\n",
      " [ 97  14   1  29   0   0  69]\n",
      " [ 48   4   1  39   0   0 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.80      0.35       210\n",
      "           2       0.57      0.41      0.48       210\n",
      "           3       0.85      0.38      0.53       210\n",
      "           4       0.26      0.25      0.25       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.56      0.49       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.33      0.34      0.30      1470\n",
      "weighted avg       0.33      0.34      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60   4   2 121   0  12  11]\n",
      " [  2  77  20  97   0   1  13]\n",
      " [  4   3  96  70   0   2  35]\n",
      " [  1   6   9 169   0   9  16]\n",
      " [  7   8   1 162   0  11  21]\n",
      " [ 12   8   7 114   0  24  45]\n",
      " [  0   2   3  74   0   9 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.29      0.41       210\n",
      "           2       0.71      0.37      0.48       210\n",
      "           3       0.70      0.46      0.55       210\n",
      "           4       0.21      0.80      0.33       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.35      0.11      0.17       210\n",
      "           7       0.46      0.58      0.52       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.45      0.37      0.35      1470\n",
      "weighted avg       0.45      0.37      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60   5   0  61  64  11   9]\n",
      " [  1  87  10  57  47   2   6]\n",
      " [  2   6 126  58  13   4   1]\n",
      " [  7  12   1 123  52   3  12]\n",
      " [ 14   3   1  42 135   4  11]\n",
      " [ 16  12   3  94  24  20  41]\n",
      " [  5   3   1  61  27   4 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.29      0.38       210\n",
      "           2       0.68      0.41      0.51       210\n",
      "           3       0.89      0.60      0.72       210\n",
      "           4       0.25      0.59      0.35       210\n",
      "           5       0.37      0.64      0.47       210\n",
      "           6       0.42      0.10      0.16       210\n",
      "           7       0.58      0.52      0.55       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.54      0.45      0.45      1470\n",
      "weighted avg       0.54      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 53  19  13  47  51  19   8]\n",
      " [  0 100  32  38  26  11   3]\n",
      " [  0  15 166  20   3   4   2]\n",
      " [  1  30  18  88  31  32  10]\n",
      " [ 10  25   5  38 102  16  14]\n",
      " [ 10  18  18  67  10  47  40]\n",
      " [  4   7   2  48   9  49  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.25      0.37       210\n",
      "           2       0.47      0.48      0.47       210\n",
      "           3       0.65      0.79      0.72       210\n",
      "           4       0.25      0.42      0.32       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.26      0.22      0.24       210\n",
      "           7       0.54      0.43      0.48       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.44      1470\n",
      "weighted avg       0.47      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44693877551020406\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  14   1  24  37  24   8]\n",
      " [ 23 108  19  18  25  12   5]\n",
      " [ 14  23 118  14  34   5   2]\n",
      " [ 33  20   7  82  28  28  12]\n",
      " [ 43  14   2  26  93  16  16]\n",
      " [ 46  17   9  37   9  49  43]\n",
      " [ 36   7   1  18   7  36 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.49      0.40       210\n",
      "           2       0.53      0.51      0.52       210\n",
      "           3       0.75      0.56      0.64       210\n",
      "           4       0.37      0.39      0.38       210\n",
      "           5       0.40      0.44      0.42       210\n",
      "           6       0.29      0.23      0.26       210\n",
      "           7       0.55      0.50      0.52       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46462585034013604\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  16   3  23  28  33   7]\n",
      " [ 26 106  21  11  27  15   4]\n",
      " [  9   9 132  13  35   9   3]\n",
      " [ 34  16   9  81  21  35  14]\n",
      " [ 43  10   3  22  94  22  16]\n",
      " [ 23  19   9  35   5  70  49]\n",
      " [ 18   6   1  15  13  57 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.48      0.43       210\n",
      "           2       0.58      0.50      0.54       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.42      0.45      0.43       210\n",
      "           6       0.29      0.33      0.31       210\n",
      "           7       0.52      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.47      1470\n",
      "weighted avg       0.48      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93   9   4  42  24  31   7]\n",
      " [ 14 102  20  24  26  15   9]\n",
      " [  8   9 129  14  35  13   2]\n",
      " [ 23  13   7  90  25  40  12]\n",
      " [ 30  10   3  31  97  22  17]\n",
      " [ 16  17   8  40   9  76  44]\n",
      " [  7   5   1  28  13  53 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.44      0.46       210\n",
      "           2       0.62      0.49      0.54       210\n",
      "           3       0.75      0.61      0.68       210\n",
      "           4       0.33      0.43      0.38       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.30      0.36      0.33       210\n",
      "           7       0.53      0.49      0.51       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.48      1470\n",
      "weighted avg       0.49      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  22   3  21  26  35   4]\n",
      " [ 11 116  22  12  23  17   9]\n",
      " [  6  10 132  14  33  14   1]\n",
      " [ 16  24   7  78  32  44   9]\n",
      " [ 32  18   4  24  93  26  13]\n",
      " [ 18  19   9  26  15  89  34]\n",
      " [ 10  14   3  12  16  63  92]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.47      0.49       210\n",
      "           2       0.52      0.55      0.54       210\n",
      "           3       0.73      0.63      0.68       210\n",
      "           4       0.42      0.37      0.39       210\n",
      "           5       0.39      0.44      0.42       210\n",
      "           6       0.31      0.42      0.36       210\n",
      "           7       0.57      0.44      0.49       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.48      1470\n",
      "weighted avg       0.49      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  18   3  20  23  32   8]\n",
      " [ 18 111  25  12  23  12   9]\n",
      " [  5  10 129  10  33  22   1]\n",
      " [ 30  21   7  68  30  40  14]\n",
      " [ 32  17   3  20 103  22  13]\n",
      " [ 29  18  11  25  14  73  40]\n",
      " [ 23  10   3  12  14  52  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.50      0.47       210\n",
      "           2       0.54      0.53      0.53       210\n",
      "           3       0.71      0.61      0.66       210\n",
      "           4       0.41      0.32      0.36       210\n",
      "           5       0.43      0.49      0.46       210\n",
      "           6       0.29      0.35      0.32       210\n",
      "           7       0.53      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  13   5  24  30  25  11]\n",
      " [ 13 110  20  22  28  11   6]\n",
      " [  4   8 131  14  33  15   5]\n",
      " [ 19  21   9  80  38  28  15]\n",
      " [ 29  20   4  24  98  15  20]\n",
      " [ 22  21   5  28  23  55  56]\n",
      " [ 13  15   2  14  22  34 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.49      0.50       210\n",
      "           2       0.53      0.52      0.53       210\n",
      "           3       0.74      0.62      0.68       210\n",
      "           4       0.39      0.38      0.38       210\n",
      "           5       0.36      0.47      0.41       210\n",
      "           6       0.30      0.26      0.28       210\n",
      "           7       0.49      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  12   7  20  30  31  11]\n",
      " [ 12 109  25  18  19  13  14]\n",
      " [  4  11 132  10  34  17   2]\n",
      " [ 18  21  13  71  29  37  21]\n",
      " [ 27  20   7  24  94  19  19]\n",
      " [ 21  23   9  26  14  62  55]\n",
      " [ 12   8   4  13  19  41 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.47      0.49       210\n",
      "           2       0.53      0.52      0.53       210\n",
      "           3       0.67      0.63      0.65       210\n",
      "           4       0.39      0.34      0.36       210\n",
      "           5       0.39      0.45      0.42       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.48      0.54      0.51       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  11   6  18  35  33   6]\n",
      " [ 15 107  21  17  24  18   8]\n",
      " [  5  10 132  15  32  15   1]\n",
      " [ 18  16  14  77  38  35  12]\n",
      " [ 32  16   5  25  98  20  14]\n",
      " [ 17  21   7  30  25  69  41]\n",
      " [ 14   9   2  14  23  45 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.48      0.49       210\n",
      "           2       0.56      0.51      0.53       210\n",
      "           3       0.71      0.63      0.66       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.36      0.47      0.40       210\n",
      "           6       0.29      0.33      0.31       210\n",
      "           7       0.56      0.49      0.52       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  15   7  21  28  33   5]\n",
      " [ 15 116  23  19  15  15   7]\n",
      " [  5   9 132  11  36  17   0]\n",
      " [ 24  16  13  82  27  32  16]\n",
      " [ 32  15   5  24  99  20  15]\n",
      " [ 25  23   8  30  18  68  38]\n",
      " [ 14  10   3  21  20  44  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.48      0.47       210\n",
      "           2       0.57      0.55      0.56       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.41      0.47      0.44       210\n",
      "           6       0.30      0.32      0.31       210\n",
      "           7       0.55      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.48      1470\n",
      "weighted avg       0.48      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  11   6  24  26  34   5]\n",
      " [ 14 116  28  10  17  14  11]\n",
      " [  5  11 130  10  37  14   3]\n",
      " [ 25  20   9  86  29  28  13]\n",
      " [ 38  19   4  19  91  21  18]\n",
      " [ 24  25   7  33  17  60  44]\n",
      " [ 19  13   1  12  23  42 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.50      0.47       210\n",
      "           2       0.54      0.55      0.55       210\n",
      "           3       0.70      0.62      0.66       210\n",
      "           4       0.44      0.41      0.43       210\n",
      "           5       0.38      0.43      0.40       210\n",
      "           6       0.28      0.29      0.28       210\n",
      "           7       0.52      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  13   5  22  29  31   8]\n",
      " [ 16 109  23  16  20  16  10]\n",
      " [  3  10 130  14  35  15   3]\n",
      " [ 23  16  13  83  31  31  13]\n",
      " [ 33  24   3  21  96  17  16]\n",
      " [ 25  21   5  32  21  61  45]\n",
      " [ 12  10   4  16  21  39 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.49      0.48       210\n",
      "           2       0.54      0.52      0.53       210\n",
      "           3       0.71      0.62      0.66       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.38      0.46      0.41       210\n",
      "           6       0.29      0.29      0.29       210\n",
      "           7       0.53      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  14   5  21  28  32   9]\n",
      " [ 12 109  22  17  25  14  11]\n",
      " [  5  13 132   9  35  13   3]\n",
      " [ 23  21  10  81  33  27  15]\n",
      " [ 32  21   3  21  98  16  19]\n",
      " [ 27  25   5  33  22  56  42]\n",
      " [ 18   9   2  12  25  34 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.37      0.47      0.41       210\n",
      "           6       0.29      0.27      0.28       210\n",
      "           7       0.53      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47959183673469385\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  10   5  22  26  36   7]\n",
      " [ 14 117  22  16  19  12  10]\n",
      " [  4  13 130  12  34  13   4]\n",
      " [ 21  26   8  81  24  28  22]\n",
      " [ 30  22   6  20  99  15  18]\n",
      " [ 17  20   9  37  15  68  44]\n",
      " [ 15  14   4  14  18  39 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.50      0.50       210\n",
      "           2       0.53      0.56      0.54       210\n",
      "           3       0.71      0.62      0.66       210\n",
      "           4       0.40      0.39      0.39       210\n",
      "           5       0.42      0.47      0.44       210\n",
      "           6       0.32      0.32      0.32       210\n",
      "           7       0.50      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  15   4  24  25  33   5]\n",
      " [ 12 112  24  23  15  15   9]\n",
      " [  4  10 133   9  36  13   5]\n",
      " [ 21  21   4  86  36  25  17]\n",
      " [ 38  21   6  21  86  16  22]\n",
      " [ 21  22  12  23  19  68  45]\n",
      " [ 14  11   4  14  22  37 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.53      0.53      0.53       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.36      0.41      0.38       210\n",
      "           6       0.33      0.32      0.33       210\n",
      "           7       0.51      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.48      1470\n",
      "weighted avg       0.48      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.3795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 16   2  39   3  86   0  64]\n",
      " [  0  27  98   2  56   0  27]\n",
      " [  0   4 178   4  14   0  10]\n",
      " [  0   4  34  13  48   0 111]\n",
      " [  1   6   9   0 129   0  65]\n",
      " [  0   5  26   6  37   0 136]\n",
      " [  0   2   2   2   9   0 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.08      0.14       210\n",
      "           2       0.54      0.13      0.21       210\n",
      "           3       0.46      0.85      0.60       210\n",
      "           4       0.43      0.06      0.11       210\n",
      "           5       0.34      0.61      0.44       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.93      0.48       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.43      0.38      0.28      1470\n",
      "weighted avg       0.43      0.38      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 56   4  13   4  90   0  43]\n",
      " [  0  99  33   3  60   0  15]\n",
      " [  1  11 173   1  15   1   8]\n",
      " [  3  18  22  29  67   0  71]\n",
      " [  3   9   3   1 149   0  45]\n",
      " [  6   8  21  15  46   4 110]\n",
      " [  0   4   0   9  14   0 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.27      0.40       210\n",
      "           2       0.65      0.47      0.55       210\n",
      "           3       0.65      0.82      0.73       210\n",
      "           4       0.47      0.14      0.21       210\n",
      "           5       0.34      0.71      0.46       210\n",
      "           6       0.80      0.02      0.04       210\n",
      "           7       0.39      0.87      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.42      1470\n",
      "weighted avg       0.59      0.47      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95   5   2  10  54   2  42]\n",
      " [  1 131  15   4  46   0  13]\n",
      " [  9  11 171   6   5   1   7]\n",
      " [  6  21  20  54  44   2  63]\n",
      " [ 21  13   1   3 128   0  44]\n",
      " [ 11  26  15  19  23   7 109]\n",
      " [  0   9   0  10  10   6 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.45      0.54       210\n",
      "           2       0.61      0.62      0.62       210\n",
      "           3       0.76      0.81      0.79       210\n",
      "           4       0.51      0.26      0.34       210\n",
      "           5       0.41      0.61      0.49       210\n",
      "           6       0.39      0.03      0.06       210\n",
      "           7       0.39      0.83      0.53       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.48      1470\n",
      "weighted avg       0.53      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100   8   1  12  49   6  34]\n",
      " [  1 139   9   6  41   3  11]\n",
      " [  1  13 173   8   8   5   2]\n",
      " [  6  15  18  77  32  18  44]\n",
      " [ 18  14   1   9 127   1  40]\n",
      " [ 10  16  16  29  20  20  99]\n",
      " [  0   6   0  11  10   8 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.48      0.58       210\n",
      "           2       0.66      0.66      0.66       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.51      0.37      0.43       210\n",
      "           5       0.44      0.60      0.51       210\n",
      "           6       0.33      0.10      0.15       210\n",
      "           7       0.43      0.83      0.57       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.53      1470\n",
      "weighted avg       0.56      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105   2   1  14  45  15  28]\n",
      " [  0 140  10   6  39   9   6]\n",
      " [  2   8 172  14   4   9   1]\n",
      " [  4  10  17  92  25  22  40]\n",
      " [ 17  14   0  12 124   7  36]\n",
      " [ 10  14  16  24  18  31  97]\n",
      " [  0   6   0  11   8  15 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.50      0.60       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.53      0.44      0.48       210\n",
      "           5       0.47      0.59      0.52       210\n",
      "           6       0.29      0.15      0.19       210\n",
      "           7       0.45      0.81      0.58       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.55      1470\n",
      "weighted avg       0.57      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   1   1  15  48  23  20]\n",
      " [  0 142  11   8  36   8   5]\n",
      " [  1   7 176  19   2   5   0]\n",
      " [  3  10  11 100  30  26  30]\n",
      " [ 18  12   0  12 128   2  38]\n",
      " [  8  12  11  25  12  55  87]\n",
      " [  0   5   0   8   5  15 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.49      0.60       210\n",
      "           2       0.75      0.68      0.71       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.53      0.48      0.50       210\n",
      "           5       0.49      0.61      0.54       210\n",
      "           6       0.41      0.26      0.32       210\n",
      "           7       0.50      0.84      0.62       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   2   1  12  44  22  23]\n",
      " [  0 147   8   8  35   9   3]\n",
      " [  0  10 170  16   6   8   0]\n",
      " [  6   5  10 122  21  18  28]\n",
      " [ 23  13   0  12 122  10  30]\n",
      " [  9  12   9  22  10  73  75]\n",
      " [  0   4   0   8   8  17 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.50      0.60       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.61      0.58      0.60       210\n",
      "           5       0.50      0.58      0.54       210\n",
      "           6       0.46      0.35      0.40       210\n",
      "           7       0.52      0.82      0.64       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   2   0  11  43  29  18]\n",
      " [  1 149   9  11  26   9   5]\n",
      " [  1   3 177  12   6  11   0]\n",
      " [  5   9   4 125  16  30  21]\n",
      " [ 19  10   1  14 128   8  30]\n",
      " [  8  13   9  23   6  69  82]\n",
      " [  0   3   0   9   4  18 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.51      0.61       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.89      0.84      0.86       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.56      0.61      0.58       210\n",
      "           6       0.40      0.33      0.36       210\n",
      "           7       0.53      0.84      0.65       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   1   0  13  46  19  14]\n",
      " [  0 153   7  16  21   7   6]\n",
      " [  0   3 178  14   5  10   0]\n",
      " [  5   6   7 131  19  23  19]\n",
      " [ 17  11   1  14 132  10  25]\n",
      " [  8  13   5  16   8  91  69]\n",
      " [  0   3   0   7   6  22 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.56      0.66       210\n",
      "           2       0.81      0.73      0.76       210\n",
      "           3       0.90      0.85      0.87       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.56      0.63      0.59       210\n",
      "           6       0.50      0.43      0.46       210\n",
      "           7       0.56      0.82      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   1   0   7  44  28  14]\n",
      " [  0 148   8   8  32  10   4]\n",
      " [  2   5 175  13   5  10   0]\n",
      " [  6   5   8 129  15  29  18]\n",
      " [ 16  10   1  12 138   5  28]\n",
      " [  9   8   7  21   8  80  77]\n",
      " [  0   4   0   7   5  17 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.55      0.65       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.88      0.83      0.86       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.56      0.66      0.60       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.56      0.84      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   1   0  10  48  26  15]\n",
      " [  0 151   7  10  27  11   4]\n",
      " [  3   6 175  12   4  10   0]\n",
      " [  6   5   5 134  14  31  15]\n",
      " [ 19  10   1  12 135  12  21]\n",
      " [  6  15   7  13   9  87  73]\n",
      " [  0   3   0   5   4  26 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.52      0.62       210\n",
      "           2       0.79      0.72      0.75       210\n",
      "           3       0.90      0.83      0.86       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.56      0.64      0.60       210\n",
      "           6       0.43      0.41      0.42       210\n",
      "           7       0.57      0.82      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114   3   0  11  45  23  14]\n",
      " [  0 157   6  14  21  10   2]\n",
      " [  4   4 177  13   4   8   0]\n",
      " [  4   9   2 131  22  24  18]\n",
      " [ 21  11   0  18 126   6  28]\n",
      " [  7  11   5  19  14  80  74]\n",
      " [  0   2   0   5   8  28 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.54      0.63       210\n",
      "           2       0.80      0.75      0.77       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.53      0.60      0.56       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.55      0.80      0.65       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   1   0   5  45  26  16]\n",
      " [  0 157   7  11  18  14   3]\n",
      " [  1   4 179  10   6   9   1]\n",
      " [  8   6   9 131  15  29  12]\n",
      " [ 23  12   1  17 126   9  22]\n",
      " [  7  12   4  20  10  94  63]\n",
      " [  0   2   0   3   7  24 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.56      0.64       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.90      0.85      0.87       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.46      0.45      0.45       210\n",
      "           7       0.60      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   1   0   6  46  27  11]\n",
      " [  1 152   7   9  24  13   4]\n",
      " [  2   4 180   9   5  10   0]\n",
      " [  5   9   7 128  16  30  15]\n",
      " [ 25  11   0  16 127  11  20]\n",
      " [  7  14   6  17  10  91  65]\n",
      " [  0   3   0   2   6  20 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.57      0.64       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.90      0.86      0.88       210\n",
      "           4       0.68      0.61      0.64       210\n",
      "           5       0.54      0.60      0.57       210\n",
      "           6       0.45      0.43      0.44       210\n",
      "           7       0.61      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   0   0   9  47  23  14]\n",
      " [  0 151   7  10  26  15   1]\n",
      " [  1   8 177   8   5  11   0]\n",
      " [  7   7   7 130  18  24  17]\n",
      " [ 18  10   0  15 137  11  19]\n",
      " [  5   9   5  16   9  95  71]\n",
      " [  0   3   0   3   8  23 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.56      0.65       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.90      0.84      0.87       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.55      0.65      0.60       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.59      0.82      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   2   0   9  45  18  13]\n",
      " [  0 156   8   8  24  12   2]\n",
      " [  1   6 175  10   3  14   1]\n",
      " [  7   9   7 126  17  27  17]\n",
      " [ 21  13   0  22 126   9  19]\n",
      " [  7  14   7  14   9  89  70]\n",
      " [  0   2   0   4   5  24 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.59      0.67       210\n",
      "           2       0.77      0.74      0.76       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.65      0.60      0.63       210\n",
      "           5       0.55      0.60      0.57       210\n",
      "           6       0.46      0.42      0.44       210\n",
      "           7       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   3   0   8  44  26  13]\n",
      " [  0 161   7  11  21   8   2]\n",
      " [  2   2 180   8   7  11   0]\n",
      " [  5   9   4 129  19  28  16]\n",
      " [ 25  10   0  18 126   8  23]\n",
      " [  6  16   7  19   9  85  68]\n",
      " [  0   3   0   3   6  23 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.55      0.64       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.91      0.86      0.88       210\n",
      "           4       0.66      0.61      0.64       210\n",
      "           5       0.54      0.60      0.57       210\n",
      "           6       0.45      0.40      0.43       210\n",
      "           7       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   0   0  10  41  28  10]\n",
      " [  0 159   8   6  24  10   3]\n",
      " [  1   5 180  11   5   8   0]\n",
      " [  5   7   6 135  16  25  16]\n",
      " [ 22  13   0  15 131   6  23]\n",
      " [  6  13   6  24   6  89  66]\n",
      " [  1   4   0   3   7  23 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.58      0.66       210\n",
      "           2       0.79      0.76      0.77       210\n",
      "           3       0.90      0.86      0.88       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.57      0.62      0.60       210\n",
      "           6       0.47      0.42      0.45       210\n",
      "           7       0.59      0.82      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   1   0  14  42  23  12]\n",
      " [  0 159   7   8  23  10   3]\n",
      " [  3   5 182   9   2   9   0]\n",
      " [  4   8   5 136  13  27  17]\n",
      " [ 25  12   0  18 128   5  22]\n",
      " [  9  10   6  20   9  87  69]\n",
      " [  0   5   0   8   7  24 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.56      0.64       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.91      0.87      0.89       210\n",
      "           4       0.64      0.65      0.64       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.47      0.41      0.44       210\n",
      "           7       0.57      0.79      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   2   0   9  46  24  10]\n",
      " [  1 163   7   9  21   7   2]\n",
      " [  1   4 179  10   4  11   1]\n",
      " [  5   7   6 135  15  28  14]\n",
      " [ 26  12   0  18 126   9  19]\n",
      " [  7  10   6  22   8  85  72]\n",
      " [  0   5   0   4   7  29 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.57      0.64       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.65      0.64      0.65       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.58      0.79      0.67       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 85   6  13  11  41  18  36]\n",
      " [  0 129  32   4  26  10   9]\n",
      " [  2   8 175  11   1  10   3]\n",
      " [  5  16  23  80  17  17  52]\n",
      " [ 30  22   1  14  97   2  44]\n",
      " [ 12  20  19  29  10  35  85]\n",
      " [  0  16   0  29  14  22 129]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.40      0.49       210\n",
      "           2       0.59      0.61      0.60       210\n",
      "           3       0.67      0.83      0.74       210\n",
      "           4       0.45      0.38      0.41       210\n",
      "           5       0.47      0.46      0.47       210\n",
      "           6       0.31      0.17      0.22       210\n",
      "           7       0.36      0.61      0.45       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.48      1470\n",
      "weighted avg       0.50      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7816326530612245\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[162   1   0   1  36   7   3]\n",
      " [  2 168   6   9  20   4   1]\n",
      " [  0   2 195   5   2   6   0]\n",
      " [  2   7   2 164  12  21   2]\n",
      " [ 22   7   3  15 151   5   7]\n",
      " [  4   9   5  16   6 138  32]\n",
      " [  0   2   0   0   6  31 171]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.77      0.81       210\n",
      "           2       0.86      0.80      0.83       210\n",
      "           3       0.92      0.93      0.93       210\n",
      "           4       0.78      0.78      0.78       210\n",
      "           5       0.65      0.72      0.68       210\n",
      "           6       0.65      0.66      0.65       210\n",
      "           7       0.79      0.81      0.80       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.79      0.78      0.78      1470\n",
      "weighted avg       0.79      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   1   3   9  47   3   5]\n",
      " [  6 161  16   9  18   0   0]\n",
      " [ 14  10 176   7   1   1   1]\n",
      " [ 28  13   6 124  29   4   6]\n",
      " [ 42  15   5  14 127   1   6]\n",
      " [ 25  25   6  27  23  48  56]\n",
      " [  6   5   0   5  14  14 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.68      0.60       210\n",
      "           2       0.70      0.77      0.73       210\n",
      "           3       0.83      0.84      0.83       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.68      0.23      0.34       210\n",
      "           7       0.69      0.79      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   2   3  10  48   3   8]\n",
      " [  5 153  20  10  16   4   2]\n",
      " [ 13   9 175   8   3   1   1]\n",
      " [ 18  11   4 138  32   1   6]\n",
      " [ 39  15   9  14 122   2   9]\n",
      " [ 22  20   4  25  22  57  60]\n",
      " [  5   3   0   3  14  20 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.65      0.61       210\n",
      "           2       0.72      0.73      0.72       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.47      0.58      0.52       210\n",
      "           6       0.65      0.27      0.38       210\n",
      "           7       0.66      0.79      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6571428571428571\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[130   2   2  10  56   3   7]\n",
      " [  8 153  15  10  18   4   2]\n",
      " [ 12   9 173   5   5   4   2]\n",
      " [ 13  10   5 145  29   2   6]\n",
      " [ 30  11   6  18 136   1   8]\n",
      " [ 20  16   6  24  25  57  62]\n",
      " [  2   1   0   3  16  16 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       210\n",
      "           2       0.76      0.73      0.74       210\n",
      "           3       0.84      0.82      0.83       210\n",
      "           4       0.67      0.69      0.68       210\n",
      "           5       0.48      0.65      0.55       210\n",
      "           6       0.66      0.27      0.38       210\n",
      "           7       0.66      0.82      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[131   2   0   8  58   5   6]\n",
      " [  6 150  14   8  25   4   3]\n",
      " [ 10  10 174   7   4   4   1]\n",
      " [ 12  10  10 138  32   1   7]\n",
      " [ 32  12   6  15 135   1   9]\n",
      " [ 16  23   6  23  29  52  61]\n",
      " [  2   3   0   2  16  10 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.62      0.63       210\n",
      "           2       0.71      0.71      0.71       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.69      0.66      0.67       210\n",
      "           5       0.45      0.64      0.53       210\n",
      "           6       0.68      0.25      0.36       210\n",
      "           7       0.67      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   1   1   9  55   6   4]\n",
      " [  6 150  13   9  24   5   3]\n",
      " [  8  10 173   7   7   5   0]\n",
      " [ 11  10   7 139  34   2   7]\n",
      " [ 33  13   6  13 135   1   9]\n",
      " [ 12  21   6  22  33  48  68]\n",
      " [  3   3   0   3  14   9 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.64      0.64       210\n",
      "           2       0.72      0.71      0.72       210\n",
      "           3       0.84      0.82      0.83       210\n",
      "           4       0.69      0.66      0.67       210\n",
      "           5       0.45      0.64      0.53       210\n",
      "           6       0.63      0.23      0.34       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6489795918367347\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128   1   1   9  61   4   6]\n",
      " [  6 147  11   9  31   3   3]\n",
      " [  9  12 171   8   5   3   2]\n",
      " [ 12   8  11 140  29   3   7]\n",
      " [ 29  14   6  13 140   1   7]\n",
      " [ 12  19   6  24  27  46  76]\n",
      " [  4   2   0   2  12   8 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.62       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.83      0.81      0.82       210\n",
      "           4       0.68      0.67      0.67       210\n",
      "           5       0.46      0.67      0.54       210\n",
      "           6       0.68      0.22      0.33       210\n",
      "           7       0.64      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.64      1470\n",
      "weighted avg       0.67      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 78   0  11   4  60  19  38]\n",
      " [  0 128   6  10  36  20  10]\n",
      " [  9  14 156   6   5  19   1]\n",
      " [  4   9  15  76  32  24  50]\n",
      " [ 17  11   0   8 126   5  43]\n",
      " [  4   6  12  30  23  38  97]\n",
      " [  0   2   0  13  11  25 159]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.37      0.48       210\n",
      "           2       0.75      0.61      0.67       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.52      0.36      0.43       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.25      0.18      0.21       210\n",
      "           7       0.40      0.76      0.52       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.51      1470\n",
      "weighted avg       0.55      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 80   0  11   3  62  25  29]\n",
      " [  0 113  10   9  47  25   6]\n",
      " [  8  11 156   5   7  22   1]\n",
      " [  4  10  15  68  46  27  40]\n",
      " [ 18  10   1   8 126   8  39]\n",
      " [  5   9  13  25  32  44  82]\n",
      " [  0   4   0  20  23  17 146]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.38      0.49       210\n",
      "           2       0.72      0.54      0.62       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.49      0.32      0.39       210\n",
      "           5       0.37      0.60      0.46       210\n",
      "           6       0.26      0.21      0.23       210\n",
      "           7       0.43      0.70      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.50      1470\n",
      "weighted avg       0.53      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7687074829931972\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   1   0   1  37   9   1]\n",
      " [  1 172   8   8  18   3   0]\n",
      " [  0   2 199   3   4   2   0]\n",
      " [  3   9   5 166  12  15   0]\n",
      " [ 24   8   4  18 147   4   5]\n",
      " [  6  14   3  25   8 119  35]\n",
      " [  1   0   1   0   6  36 166]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.77      0.79       210\n",
      "           2       0.83      0.82      0.83       210\n",
      "           3       0.90      0.95      0.93       210\n",
      "           4       0.75      0.79      0.77       210\n",
      "           5       0.63      0.70      0.67       210\n",
      "           6       0.63      0.57      0.60       210\n",
      "           7       0.80      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.77      0.77      0.77      1470\n",
      "weighted avg       0.77      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of SVM is:\n",
      " [[105   0   0   6  60  29  10]\n",
      " [  0 154   2   9  26  17   2]\n",
      " [  3   4 167  13   8  15   0]\n",
      " [  1   4   1 153  20  25   6]\n",
      " [  2   2   2  14 165  10  15]\n",
      " [  2   1   1   9  10 126  61]\n",
      " [  0   1   0   0   4  15 190]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.50      0.65       210\n",
      "           2       0.93      0.73      0.82       210\n",
      "           3       0.97      0.80      0.87       210\n",
      "           4       0.75      0.73      0.74       210\n",
      "           5       0.56      0.79      0.66       210\n",
      "           6       0.53      0.60      0.56       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.76      0.72      0.72      1470\n",
      "weighted avg       0.76      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7979591836734694\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   0   0   5  35  17   2]\n",
      " [  0 180   5   8   8   8   1]\n",
      " [  1   2 193   7   3   4   0]\n",
      " [  0   5   4 173  10  16   2]\n",
      " [ 21  11   1  15 150   4   8]\n",
      " [  2   4   3  14   2 139  46]\n",
      " [  0   1   0   0   4  18 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.72      0.78       210\n",
      "           2       0.89      0.86      0.87       210\n",
      "           3       0.94      0.92      0.93       210\n",
      "           4       0.78      0.82      0.80       210\n",
      "           5       0.71      0.71      0.71       210\n",
      "           6       0.67      0.66      0.67       210\n",
      "           7       0.76      0.89      0.82       210\n",
      "\n",
      "    accuracy                           0.80      1470\n",
      "   macro avg       0.80      0.80      0.80      1470\n",
      "weighted avg       0.80      0.80      0.80      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7462585034013606\n",
      "Confusion Matrix of SVM is:\n",
      " [[149   1   1   3  40  10   6]\n",
      " [  0 172   9   7  13   7   2]\n",
      " [  1   3 185   7   5   9   0]\n",
      " [  4   5   7 159  11  21   3]\n",
      " [ 38  11   7  16 123   5  10]\n",
      " [  3   5   7  14   5 123  53]\n",
      " [  0   2   0   1   3  18 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.71      0.74       210\n",
      "           2       0.86      0.82      0.84       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.77      0.76      0.76       210\n",
      "           5       0.61      0.59      0.60       210\n",
      "           6       0.64      0.59      0.61       210\n",
      "           7       0.72      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.74      1470\n",
      "weighted avg       0.75      0.75      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.24761904761904763\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  21   0   0   0 189]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0 156   0   0   0  54]\n",
      " [  0   0  14   0   0   0 196]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0  16   0   0   0 194]\n",
      " [  0   0   2   0   0   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.66      0.74      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.99      0.29       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.12      0.25      0.14      1470\n",
      "weighted avg       0.12      0.25      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3272108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  21   0 144   0  45]\n",
      " [  0   0  20   0 159   0  31]\n",
      " [  0   0 156   0  33   0  21]\n",
      " [  0   0  14   0 125   0  71]\n",
      " [  0   0   8   0 162   0  40]\n",
      " [  0   0  16   0  71   0 123]\n",
      " [  0   0   2   0  45   0 163]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.66      0.74      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.77      0.34       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.33      0.78      0.46       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.17      0.33      0.21      1470\n",
      "weighted avg       0.17      0.33      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38299319727891157\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 14   6   5  26 140   0  19]\n",
      " [  0  70  16  13  93   0  18]\n",
      " [  2  15 152  18  20   0   3]\n",
      " [  1   9  13  38 116   0  33]\n",
      " [  1   8   7  24 154   0  16]\n",
      " [  1   4  15  33  67   0  90]\n",
      " [  1   2   1  28  43   0 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.07      0.12       210\n",
      "           2       0.61      0.33      0.43       210\n",
      "           3       0.73      0.72      0.73       210\n",
      "           4       0.21      0.18      0.19       210\n",
      "           5       0.24      0.73      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.64      0.52       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.42      0.38      0.34      1470\n",
      "weighted avg       0.42      0.38      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83   1   7   4  72  40   3]\n",
      " [ 11  62  14   3  84  32   4]\n",
      " [  3   4 158  10  18  16   1]\n",
      " [  9   4  12  18 107  44  16]\n",
      " [ 51   8   4   8 104  29   6]\n",
      " [  3   1   9   7  64  82  44]\n",
      " [  6   0   2   4  38  72  88]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.40      0.44       210\n",
      "           2       0.78      0.30      0.43       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.33      0.09      0.14       210\n",
      "           5       0.21      0.50      0.30       210\n",
      "           6       0.26      0.39      0.31       210\n",
      "           7       0.54      0.42      0.47       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.48      0.40      0.41      1470\n",
      "weighted avg       0.48      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 64   1   3  18  81  40   3]\n",
      " [  3  69  12  52  51  19   4]\n",
      " [  2   3 158  28   7  11   1]\n",
      " [  1   8   2  64  76  43  16]\n",
      " [  8  11   5  17 134  29   6]\n",
      " [  0   4   5  29  46  82  44]\n",
      " [  2   1   0  17  27  75  88]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.30      0.44       210\n",
      "           2       0.71      0.33      0.45       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.32      0.64      0.42       210\n",
      "           6       0.27      0.39      0.32       210\n",
      "           7       0.54      0.42      0.47       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.54      0.45      0.46      1470\n",
      "weighted avg       0.54      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  11   4  15  74  17   7]\n",
      " [  9 105   6  26  43  16   5]\n",
      " [  2  10 161  22   7   7   1]\n",
      " [ 15  18   4  61  72  26  14]\n",
      " [ 20  17   5  19 131   5  13]\n",
      " [ 18  11   5  25  43  58  50]\n",
      " [ 13   6   1  16  23  37 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.39      0.44       210\n",
      "           2       0.59      0.50      0.54       210\n",
      "           3       0.87      0.77      0.81       210\n",
      "           4       0.33      0.29      0.31       210\n",
      "           5       0.33      0.62      0.43       210\n",
      "           6       0.35      0.28      0.31       210\n",
      "           7       0.56      0.54      0.55       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.51      0.48      0.49      1470\n",
      "weighted avg       0.51      0.48      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   9   3  13  65  34   6]\n",
      " [  3 104   4  16  40  40   3]\n",
      " [  3   8 162  14   6  15   2]\n",
      " [  7  13   1  71  48  53  17]\n",
      " [ 13  16   5  16 118  32  10]\n",
      " [ 13   7   6  31  31  78  44]\n",
      " [  7   3   1   6  22  62 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.38      0.48       210\n",
      "           2       0.65      0.50      0.56       210\n",
      "           3       0.89      0.77      0.83       210\n",
      "           4       0.43      0.34      0.38       210\n",
      "           5       0.36      0.56      0.44       210\n",
      "           6       0.25      0.37      0.30       210\n",
      "           7       0.57      0.52      0.54       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.54      0.49      0.50      1470\n",
      "weighted avg       0.54      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92   5   5  25  48  31   4]\n",
      " [  5 100  14  33  38  19   1]\n",
      " [  6   3 164  26   4   5   2]\n",
      " [  8  10  10  85  41  39  17]\n",
      " [ 16   9   7  29 125  14  10]\n",
      " [  8   8  13  44  25  73  39]\n",
      " [  5   3   7   9  21  49 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.44      0.53       210\n",
      "           2       0.72      0.48      0.57       210\n",
      "           3       0.75      0.78      0.76       210\n",
      "           4       0.34      0.40      0.37       210\n",
      "           5       0.41      0.60      0.49       210\n",
      "           6       0.32      0.35      0.33       210\n",
      "           7       0.61      0.55      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.54      0.51      0.52      1470\n",
      "weighted avg       0.54      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  19   5  15  37  23   7]\n",
      " [  9 121   5  19  32  24   0]\n",
      " [  3  14 163  16   3  10   1]\n",
      " [ 14  17   3  83  38  41  14]\n",
      " [ 20  28   6  17 116  14   9]\n",
      " [ 13  22  10  35  21  68  41]\n",
      " [  7  15   1  16  17  36 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.50      0.55       210\n",
      "           2       0.51      0.58      0.54       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.44      0.55      0.49       210\n",
      "           6       0.31      0.32      0.32       210\n",
      "           7       0.62      0.56      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  13   5  18  44  20  11]\n",
      " [  9 124   6  21  30  16   4]\n",
      " [  8  11 159  19   6   7   0]\n",
      " [ 14  18   3  80  39  40  16]\n",
      " [ 16  28   4  19 116  13  14]\n",
      " [ 15  24   5  34  25  58  49]\n",
      " [  8  13   1  11  17  35 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.47      0.52       210\n",
      "           2       0.54      0.59      0.56       210\n",
      "           3       0.87      0.76      0.81       210\n",
      "           4       0.40      0.38      0.39       210\n",
      "           5       0.42      0.55      0.48       210\n",
      "           6       0.31      0.28      0.29       210\n",
      "           7       0.57      0.60      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   8   8  18  39  26  10]\n",
      " [  7 122  12  17  31  17   4]\n",
      " [  4  13 163  18   4   6   2]\n",
      " [ 11  19   4  84  39  36  17]\n",
      " [ 18  24   9  21 114  13  11]\n",
      " [ 12  19  13  36  19  69  42]\n",
      " [  9  11   2  13  10  46 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.56      0.58      0.57       210\n",
      "           3       0.77      0.78      0.77       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.45      0.54      0.49       210\n",
      "           6       0.32      0.33      0.33       210\n",
      "           7       0.58      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  14   5  17  38  21   9]\n",
      " [ 11 118   9  19  28  20   5]\n",
      " [  7   6 169  13   3  11   1]\n",
      " [ 14  24   6  83  38  34  11]\n",
      " [ 20  24   7  24 110  17   8]\n",
      " [ 19  23  12  32  19  62  43]\n",
      " [ 11  12   5  12  10  33 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53       210\n",
      "           2       0.53      0.56      0.55       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.45      0.52      0.48       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  14   3  21  40  25   6]\n",
      " [ 10 122   9  23  26  18   2]\n",
      " [  6   9 166  15   6   6   2]\n",
      " [ 14  23   8  89  31  29  16]\n",
      " [ 22  28   6  31 100  15   8]\n",
      " [ 20  23   9  38  11  66  43]\n",
      " [ 13  11   2  12   6  32 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.48      0.51       210\n",
      "           2       0.53      0.58      0.55       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.39      0.42      0.41       210\n",
      "           5       0.45      0.48      0.47       210\n",
      "           6       0.35      0.31      0.33       210\n",
      "           7       0.64      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  12   4  22  40  25   7]\n",
      " [ 14 121  10  23  23  16   3]\n",
      " [  5   6 165  17   8   8   1]\n",
      " [ 12  25   4  87  36  29  17]\n",
      " [ 19  26   8  34 100  15   8]\n",
      " [ 15  22   8  34  16  68  47]\n",
      " [  6  10   6  16  14  34 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.52       210\n",
      "           2       0.55      0.58      0.56       210\n",
      "           3       0.80      0.79      0.80       210\n",
      "           4       0.37      0.41      0.39       210\n",
      "           5       0.42      0.48      0.45       210\n",
      "           6       0.35      0.32      0.34       210\n",
      "           7       0.60      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  12   6  18  33  27   7]\n",
      " [ 10 118   7  22  25  21   7]\n",
      " [  9   6 163  20   4   7   1]\n",
      " [  8  24   5  83  30  42  18]\n",
      " [ 24  27   6  26  97  16  14]\n",
      " [ 15  18   6  35  19  71  46]\n",
      " [ 11  11   4  15  12  39 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.51      0.54       210\n",
      "           2       0.55      0.56      0.55       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.44      0.46      0.45       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.56      0.56      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.52      1470\n",
      "weighted avg       0.52      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  14   5  23  33  27   7]\n",
      " [ 11 122   8  14  26  24   5]\n",
      " [  6   9 166  16   4   8   1]\n",
      " [ 14  24   5  88  27  34  18]\n",
      " [ 28  28  10  23  91  19  11]\n",
      " [ 17  22  12  28  14  72  45]\n",
      " [ 12  11   5  14   9  35 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.48      0.51       210\n",
      "           2       0.53      0.58      0.55       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.43      0.42      0.42       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.33      0.34      0.34       210\n",
      "           7       0.59      0.59      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  16   6  17  31  27   8]\n",
      " [ 16 119   8  22  22  18   5]\n",
      " [  9   6 165  15   4  10   1]\n",
      " [ 11  21   7  87  26  42  16]\n",
      " [ 32  26   5  33  87  12  15]\n",
      " [ 14  17  13  37   9  72  48]\n",
      " [  7  12   2  12  10  45 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.50      0.52       210\n",
      "           2       0.55      0.57      0.56       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.39      0.41      0.40       210\n",
      "           5       0.46      0.41      0.44       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.57      0.58      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.52      1470\n",
      "weighted avg       0.52      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  18   6  19  37  18   7]\n",
      " [ 11 126   8  23  18  18   6]\n",
      " [  3   9 164  21   3  10   0]\n",
      " [ 19  25   7  85  26  35  13]\n",
      " [ 26  27   9  23  93  17  15]\n",
      " [ 14  18  11  40  12  67  48]\n",
      " [ 10  14   2  11  10  38 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53       210\n",
      "           2       0.53      0.60      0.56       210\n",
      "           3       0.79      0.78      0.79       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.47      0.44      0.45       210\n",
      "           6       0.33      0.32      0.32       210\n",
      "           7       0.58      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  13   7  25  34  23   6]\n",
      " [ 10 122   8  21  25  22   2]\n",
      " [  6   8 170  13   5   6   2]\n",
      " [ 13  25   7  83  27  38  17]\n",
      " [ 30  30   6  29  91  14  10]\n",
      " [ 14  23  11  31  19  68  44]\n",
      " [ 11  13   3  13  12  40 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.49      0.52       210\n",
      "           2       0.52      0.58      0.55       210\n",
      "           3       0.80      0.81      0.81       210\n",
      "           4       0.39      0.40      0.39       210\n",
      "           5       0.43      0.43      0.43       210\n",
      "           6       0.32      0.32      0.32       210\n",
      "           7       0.59      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  12   4  20  33  25  11]\n",
      " [ 11 123   6  22  25  17   6]\n",
      " [  6   7 167  15   7   6   2]\n",
      " [ 11  24   5  82  30  38  20]\n",
      " [ 34  34   6  25  84  14  13]\n",
      " [ 15  24  10  34  19  62  46]\n",
      " [  7   7   3  13  11  38 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53       210\n",
      "           2       0.53      0.59      0.56       210\n",
      "           3       0.83      0.80      0.81       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.57      0.62      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  7   3  21   0  75   2 102]\n",
      " [  0  47  64   1  58   0  40]\n",
      " [  2   4 183   0   7   2  12]\n",
      " [  2   5  31   3  76   3  90]\n",
      " [  0   4   7   0  98   1 100]\n",
      " [  2   4  20   1  55   2 126]\n",
      " [  1   0   2   0  23   0 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.03      0.06       210\n",
      "           2       0.70      0.22      0.34       210\n",
      "           3       0.56      0.87      0.68       210\n",
      "           4       0.60      0.01      0.03       210\n",
      "           5       0.25      0.47      0.33       210\n",
      "           6       0.20      0.01      0.02       210\n",
      "           7       0.28      0.88      0.43       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.44      0.36      0.27      1470\n",
      "weighted avg       0.44      0.36      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61   3   2   0  94   3  47]\n",
      " [  1 115  19   2  50   0  23]\n",
      " [  1  15 171   0   7   2  14]\n",
      " [  8  20  19  10  77   1  75]\n",
      " [  5  11   5   2 140   1  46]\n",
      " [  5  12  13   5  32   1 142]\n",
      " [  0   2   0   0   8   0 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.29      0.42       210\n",
      "           2       0.65      0.55      0.59       210\n",
      "           3       0.75      0.81      0.78       210\n",
      "           4       0.53      0.05      0.09       210\n",
      "           5       0.34      0.67      0.45       210\n",
      "           6       0.12      0.00      0.01       210\n",
      "           7       0.37      0.95      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.50      0.47      0.41      1470\n",
      "weighted avg       0.50      0.47      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5244897959183673\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96   1   0   1  61   5  46]\n",
      " [  1 137   6   6  39   0  21]\n",
      " [  2  20 165   4   7   4   8]\n",
      " [  3  19  17  38  65   6  62]\n",
      " [ 12  14   2   7 131   1  43]\n",
      " [  5  15  12  13  28   5 132]\n",
      " [  0   2   0   0   8   1 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.46      0.58       210\n",
      "           2       0.66      0.65      0.66       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.55      0.18      0.27       210\n",
      "           5       0.39      0.62      0.48       210\n",
      "           6       0.23      0.02      0.04       210\n",
      "           7       0.39      0.95      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.48      1470\n",
      "weighted avg       0.55      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98   3   1   4  56  12  36]\n",
      " [  0 144   6   8  36   3  13]\n",
      " [  5  17 165   7   3   9   4]\n",
      " [  2  11  14  77  42  18  46]\n",
      " [ 15  15   2  12 121   2  43]\n",
      " [  3  12   8  21  22  21 123]\n",
      " [  0   1   0   1   6   3 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.47      0.59       210\n",
      "           2       0.71      0.69      0.70       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.59      0.37      0.45       210\n",
      "           5       0.42      0.58      0.49       210\n",
      "           6       0.31      0.10      0.15       210\n",
      "           7       0.43      0.95      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.54      1470\n",
      "weighted avg       0.59      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104   0   0   5  53  16  32]\n",
      " [  0 145   7   6  37   7   8]\n",
      " [  2  12 169   9   5  10   3]\n",
      " [  2   9  12  96  32  18  41]\n",
      " [ 14  15   1  11 126   8  35]\n",
      " [  3  10   7  25  20  29 116]\n",
      " [  0   1   0   0   6   3 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.50      0.62       210\n",
      "           2       0.76      0.69      0.72       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.63      0.46      0.53       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.32      0.14      0.19       210\n",
      "           7       0.46      0.95      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.58      1470\n",
      "weighted avg       0.62      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103   2   0   4  55  24  22]\n",
      " [  0 140   6  13  33  13   5]\n",
      " [  1   8 173   9   5  13   1]\n",
      " [  2   7  10 112  22  28  29]\n",
      " [ 14  14   2  15 126   7  32]\n",
      " [  4   6   7  28  12  52 101]\n",
      " [  0   1   0   0   5   5 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.49      0.62       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.87      0.82      0.85       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.37      0.25      0.30       210\n",
      "           7       0.51      0.95      0.66       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.61      1470\n",
      "weighted avg       0.64      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108   0   0  11  50  22  19]\n",
      " [  0 148   5  11  27  14   5]\n",
      " [  2  10 171  10   4  13   0]\n",
      " [  2   7   7 122  19  28  25]\n",
      " [ 13  16   1  12 128  12  28]\n",
      " [  3  11   4  25  14  56  97]\n",
      " [  0   0   0   1   5  10 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.51      0.64       210\n",
      "           2       0.77      0.70      0.74       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.64      0.58      0.61       210\n",
      "           5       0.52      0.61      0.56       210\n",
      "           6       0.36      0.27      0.31       210\n",
      "           7       0.53      0.92      0.67       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109   0   0   6  51  30  14]\n",
      " [  0 152   5  11  28  10   4]\n",
      " [  4  10 174   5   5  11   1]\n",
      " [  1   7   4 125  18  36  19]\n",
      " [ 12  12   1  11 136  12  26]\n",
      " [  3   7   5  18  15  73  89]\n",
      " [  0   2   0   1   5  12 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.52      0.64       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.71      0.60      0.65       210\n",
      "           5       0.53      0.65      0.58       210\n",
      "           6       0.40      0.35      0.37       210\n",
      "           7       0.55      0.90      0.69       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[110   0   0   6  51  32  11]\n",
      " [  0 151   4  10  23  18   4]\n",
      " [  2   5 172   9   3  16   3]\n",
      " [  2   9   3 134  19  33  10]\n",
      " [ 18  12   1   9 135  11  24]\n",
      " [  4   7   5  21  11  88  74]\n",
      " [  0   2   0   1   5  13 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.52      0.64       210\n",
      "           2       0.81      0.72      0.76       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.71      0.64      0.67       210\n",
      "           5       0.55      0.64      0.59       210\n",
      "           6       0.42      0.42      0.42       210\n",
      "           7       0.60      0.90      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   0   0   8  46  24  12]\n",
      " [  1 156   4   9  23  13   4]\n",
      " [  2   4 175  10   3  16   0]\n",
      " [  2   6   8 139  16  27  12]\n",
      " [ 11  12   2  18 134  12  21]\n",
      " [  2   9   7  19  12  81  80]\n",
      " [  0   0   0   1   4  14 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.57      0.69       210\n",
      "           2       0.83      0.74      0.79       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.68      0.66      0.67       210\n",
      "           5       0.56      0.64      0.60       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.60      0.91      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   1   0  10  49  23  11]\n",
      " [  1 160   5   9  23   9   3]\n",
      " [  2   6 173  15   4  10   0]\n",
      " [  2   7   4 138  18  27  14]\n",
      " [ 15  14   1  14 133  10  23]\n",
      " [  2   7   8  22  10  87  74]\n",
      " [  0   0   0   1   5  13 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.55      0.67       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.91      0.82      0.86       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.55      0.63      0.59       210\n",
      "           6       0.49      0.41      0.45       210\n",
      "           7       0.60      0.91      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   0   0   9  43  22  13]\n",
      " [  0 157   4  10  23  12   4]\n",
      " [  3   4 173  12   6  12   0]\n",
      " [  2   8   4 142  18  24  12]\n",
      " [ 16  13   0  14 138   7  22]\n",
      " [  5   6   5  19  11  86  78]\n",
      " [  0   3   0   1   3  15 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.59      0.69       210\n",
      "           2       0.82      0.75      0.78       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.69      0.68      0.68       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.48      0.41      0.44       210\n",
      "           7       0.59      0.90      0.71       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   0   0   6  53  18  13]\n",
      " [  0 156   6  10  21  15   2]\n",
      " [  2   9 175   2   4  17   1]\n",
      " [  1  10   6 128  22  30  13]\n",
      " [ 16  11   1  15 134  11  22]\n",
      " [  7   7   6  21   9  89  71]\n",
      " [  0   1   0   1   4  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.57      0.67       210\n",
      "           2       0.80      0.74      0.77       210\n",
      "           3       0.90      0.83      0.87       210\n",
      "           4       0.70      0.61      0.65       210\n",
      "           5       0.54      0.64      0.59       210\n",
      "           6       0.45      0.42      0.44       210\n",
      "           7       0.61      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   0   0  12  50  18  12]\n",
      " [  1 161   4  11  19  11   3]\n",
      " [  1   6 175  13   4  10   1]\n",
      " [  2   8   3 136  17  28  16]\n",
      " [ 16  15   1  15 135   9  19]\n",
      " [  2   8   5  15  15  90  75]\n",
      " [  0   1   0   1   4  10 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.56      0.67       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.55      0.64      0.59       210\n",
      "           6       0.51      0.43      0.47       210\n",
      "           7       0.61      0.92      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   0   0   8  42  20  13]\n",
      " [  0 161   5   9  21  11   3]\n",
      " [  2   6 175   7   5  14   1]\n",
      " [  2   5   5 140  20  25  13]\n",
      " [ 18  13   1  15 133  11  19]\n",
      " [  4   5   6  17   9  95  74]\n",
      " [  0   0   0   4   3  15 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.70       210\n",
      "           2       0.85      0.77      0.80       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.70      0.67      0.68       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.50      0.45      0.47       210\n",
      "           7       0.60      0.90      0.72       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0   0  11  45  22  10]\n",
      " [  0 163   5  10  18   7   7]\n",
      " [  2   7 174  12   2  12   1]\n",
      " [  2   8   6 131  18  33  12]\n",
      " [ 14  11   2  18 139   9  17]\n",
      " [  4   7   4  19  10  90  76]\n",
      " [  0   1   0   0   3  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.58      0.69       210\n",
      "           2       0.83      0.78      0.80       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.59      0.66      0.62       210\n",
      "           6       0.48      0.43      0.45       210\n",
      "           7       0.61      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   0   0   7  43  26  10]\n",
      " [  0 160   4   9  23   8   6]\n",
      " [  2   4 175  12   5  11   1]\n",
      " [  2   6   7 137  15  32  11]\n",
      " [ 16  12   2  19 132  10  19]\n",
      " [  5  10   5  12  12  91  75]\n",
      " [  0   1   0   1   3  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.59      0.69       210\n",
      "           2       0.83      0.76      0.79       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.48      0.43      0.45       210\n",
      "           7       0.61      0.91      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   8  44  19  12]\n",
      " [  0 158   7  10  22  10   3]\n",
      " [  1   6 175   7   4  16   1]\n",
      " [  3   4   4 142  15  26  16]\n",
      " [ 16  12   1  18 137  14  12]\n",
      " [  3   9   6  19   8  94  71]\n",
      " [  0   2   0   0   2  17 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.60      0.70       210\n",
      "           2       0.82      0.75      0.79       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.70      0.68      0.69       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.48      0.45      0.46       210\n",
      "           7       0.62      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   0   0  11  43  21  11]\n",
      " [  0 158   6  12  20  11   3]\n",
      " [  3   6 174  11   4  11   1]\n",
      " [  4   6   8 136  14  24  18]\n",
      " [ 20  15   2  16 132  10  15]\n",
      " [  3   6   5  20   6  89  81]\n",
      " [  0   1   0   1   4  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.59      0.68       210\n",
      "           2       0.82      0.75      0.79       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.66      0.65      0.65       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.49      0.42      0.45       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   1   0  11  44  19  12]\n",
      " [  0 162   3  12  18  12   3]\n",
      " [  3   7 175   7   5  12   1]\n",
      " [  4   8   7 130  20  29  12]\n",
      " [ 22  12   1  16 133   9  17]\n",
      " [  5   8   5  19  10  89  74]\n",
      " [  0   1   0   1   3  30 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.59      0.67       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.45      0.42      0.43       210\n",
      "           7       0.60      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 76   0  11   2  64  27  30]\n",
      " [  0 115   4   9  49  27   6]\n",
      " [  8  19 144   4   8  26   1]\n",
      " [  4  10  15  67  43  30  41]\n",
      " [ 13  11   1   8 127  10  40]\n",
      " [  3   6  12  19  31  44  95]\n",
      " [  0   1   0   9  15   4 181]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.36      0.48       210\n",
      "           2       0.71      0.55      0.62       210\n",
      "           3       0.77      0.69      0.73       210\n",
      "           4       0.57      0.32      0.41       210\n",
      "           5       0.38      0.60      0.46       210\n",
      "           6       0.26      0.21      0.23       210\n",
      "           7       0.46      0.86      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.50      1470\n",
      "weighted avg       0.55      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[105   9   2  14  43  17  20]\n",
      " [  5 123  14  13  33  14   8]\n",
      " [  6  11 168  10  10   5   0]\n",
      " [ 18  12   9  92  26  33  20]\n",
      " [ 31  25   6  35  80  20  13]\n",
      " [ 17  17   7  23  16  71  59]\n",
      " [ 19   3   3  21  12  37 115]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.50      0.51       210\n",
      "           2       0.61      0.59      0.60       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.36      0.38      0.37       210\n",
      "           6       0.36      0.34      0.35       210\n",
      "           7       0.49      0.55      0.52       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4414965986394558\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[118   8   2  24  42   5  11]\n",
      " [ 22 116  13  25  27   4   3]\n",
      " [ 21  14 160   8   4   2   1]\n",
      " [ 50  18   3  87  30  10  12]\n",
      " [ 54  28   1  34  68  10  15]\n",
      " [ 46  20   7  47  26  25  39]\n",
      " [ 36  14   0  35  40  10  75]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.56      0.42       210\n",
      "           2       0.53      0.55      0.54       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.33      0.41      0.37       210\n",
      "           5       0.29      0.32      0.30       210\n",
      "           6       0.38      0.12      0.18       210\n",
      "           7       0.48      0.36      0.41       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.43      1470\n",
      "weighted avg       0.46      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[112   2   1  19  47  12  17]\n",
      " [ 19 114  10  27  28   7   5]\n",
      " [ 12  14 164  12   5   2   1]\n",
      " [ 38  15   2  89  34  15  17]\n",
      " [ 42  22   2  24  82  17  21]\n",
      " [ 46  16   6  39  32  25  46]\n",
      " [ 29  11   0  34  40  11  85]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.53      0.44       210\n",
      "           2       0.59      0.54      0.56       210\n",
      "           3       0.89      0.78      0.83       210\n",
      "           4       0.36      0.42      0.39       210\n",
      "           5       0.31      0.39      0.34       210\n",
      "           6       0.28      0.12      0.17       210\n",
      "           7       0.44      0.40      0.42       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45510204081632655\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[ 99   2   1  25  50  12  21]\n",
      " [ 17 122   5  26  28   7   5]\n",
      " [ 10  15 160  15   6   3   1]\n",
      " [ 27  11   5 100  40  13  14]\n",
      " [ 40  21   4  30  82  15  18]\n",
      " [ 35  15   5  47  35  27  46]\n",
      " [ 22   7   0  37  47  18  79]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.47      0.43       210\n",
      "           2       0.63      0.58      0.61       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.36      0.48      0.41       210\n",
      "           5       0.28      0.39      0.33       210\n",
      "           6       0.28      0.13      0.18       210\n",
      "           7       0.43      0.38      0.40       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.45      1470\n",
      "weighted avg       0.47      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[100   4   2  22  53  14  15]\n",
      " [ 16 121   5  28  28   7   5]\n",
      " [  8  20 153  19   5   4   1]\n",
      " [ 31  13   4 101  37  12  12]\n",
      " [ 39  25   2  30  81  12  21]\n",
      " [ 30  13   5  55  34  24  49]\n",
      " [ 19   7   0  40  46  15  83]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.48      0.44       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.34      0.48      0.40       210\n",
      "           5       0.29      0.39      0.33       210\n",
      "           6       0.27      0.11      0.16       210\n",
      "           7       0.45      0.40      0.42       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45510204081632655\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[101   4   1  23  49  15  17]\n",
      " [ 15 121   4  28  29   6   7]\n",
      " [  6  23 152  17   7   4   1]\n",
      " [ 35  11   7  93  42  11  11]\n",
      " [ 35  25   3  33  83  13  18]\n",
      " [ 32  13   5  53  32  29  46]\n",
      " [ 23   6   0  34  40  17  90]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.48      0.44       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.88      0.72      0.80       210\n",
      "           4       0.33      0.44      0.38       210\n",
      "           5       0.29      0.40      0.34       210\n",
      "           6       0.31      0.14      0.19       210\n",
      "           7       0.47      0.43      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.45      1470\n",
      "weighted avg       0.47      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.454421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[105   3   1  22  49  12  18]\n",
      " [ 17 117   3  25  36   6   6]\n",
      " [  8  22 150  15   8   5   2]\n",
      " [ 30  12   4  97  41  12  14]\n",
      " [ 30  24   2  33  87  10  24]\n",
      " [ 34  19   5  46  33  22  51]\n",
      " [ 17   7   0  35  42  19  90]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.50      0.47       210\n",
      "           2       0.57      0.56      0.57       210\n",
      "           3       0.91      0.71      0.80       210\n",
      "           4       0.36      0.46      0.40       210\n",
      "           5       0.29      0.41      0.34       210\n",
      "           6       0.26      0.10      0.15       210\n",
      "           7       0.44      0.43      0.43       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.45      1470\n",
      "weighted avg       0.47      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 58  24   1  47  44   8  28]\n",
      " [ 18 114   5  35  21   3  14]\n",
      " [  2  34 145  23   2   1   3]\n",
      " [  7  26   5  68  45  20  39]\n",
      " [  9  34   1  47  78   5  36]\n",
      " [  9  28   6  47  26  32  62]\n",
      " [  4  10   0  40  30  22 104]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.28      0.37       210\n",
      "           2       0.42      0.54      0.48       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.22      0.32      0.26       210\n",
      "           5       0.32      0.37      0.34       210\n",
      "           6       0.35      0.15      0.21       210\n",
      "           7       0.36      0.50      0.42       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.41      1470\n",
      "weighted avg       0.44      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 52  32   1  50  41   7  27]\n",
      " [ 16 119  10  27  20   3  15]\n",
      " [  7  40 140  18   2   1   2]\n",
      " [ 11  27   5  75  40  12  40]\n",
      " [ 12  40   3  44  72   3  36]\n",
      " [ 14  32   4  50  23  24  63]\n",
      " [  5   5   0  48  29  20 103]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.25      0.32       210\n",
      "           2       0.40      0.57      0.47       210\n",
      "           3       0.86      0.67      0.75       210\n",
      "           4       0.24      0.36      0.29       210\n",
      "           5       0.32      0.34      0.33       210\n",
      "           6       0.34      0.11      0.17       210\n",
      "           7       0.36      0.49      0.42       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.39      1470\n",
      "weighted avg       0.42      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of SVM is:\n",
      " [[115   7   3  19  36  13  17]\n",
      " [  7 133  18  12  24  12   4]\n",
      " [  6  13 174   6   6   4   1]\n",
      " [ 26  18   7  89  23  26  21]\n",
      " [ 32  36   6  38  74  16   8]\n",
      " [ 24  24   7  24  19  65  47]\n",
      " [ 21   6   1  22  13  33 114]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.55      0.52       210\n",
      "           2       0.56      0.63      0.60       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.42      0.42      0.42       210\n",
      "           5       0.38      0.35      0.37       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.54      0.54      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.51      0.52      0.52      1470\n",
      "weighted avg       0.51      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 67   0   0  21  87   9  26]\n",
      " [  1  90   2  34  68   8   7]\n",
      " [  1   6 155  20  25   2   1]\n",
      " [  3   2   0  85  74  22  24]\n",
      " [  3   9   0  25 140   5  28]\n",
      " [  2   2   0  32  73  44  57]\n",
      " [  2   1   0  25  51  25 106]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.32      0.46       210\n",
      "           2       0.82      0.43      0.56       210\n",
      "           3       0.99      0.74      0.84       210\n",
      "           4       0.35      0.40      0.38       210\n",
      "           5       0.27      0.67      0.38       210\n",
      "           6       0.38      0.21      0.27       210\n",
      "           7       0.43      0.50      0.46       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.58      0.47      0.48      1470\n",
      "weighted avg       0.58      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 93   5   0  18  46  19  29]\n",
      " [  4 130  10  20  23  16   7]\n",
      " [  3  13 171   8   3  12   0]\n",
      " [  7  14   6  94  27  44  18]\n",
      " [ 11  26   2  27  97  17  30]\n",
      " [  8  14   3  27  17  71  70]\n",
      " [  7   4   0  22  17  37 123]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.44      0.54       210\n",
      "           2       0.63      0.62      0.62       210\n",
      "           3       0.89      0.81      0.85       210\n",
      "           4       0.44      0.45      0.44       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.33      0.34      0.33       210\n",
      "           7       0.44      0.59      0.51       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.53      1470\n",
      "weighted avg       0.55      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 92   3   1  18  50  14  32]\n",
      " [  7 125  17  19  22  15   5]\n",
      " [  4  15 174   7   2   8   0]\n",
      " [  9  14   9  89  28  44  17]\n",
      " [ 20  28   5  28  96   8  25]\n",
      " [ 12  17   8  30  18  60  65]\n",
      " [  9   6   0  13  18  32 132]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.44      0.51       210\n",
      "           2       0.60      0.60      0.60       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.41      0.46      0.43       210\n",
      "           6       0.33      0.29      0.31       210\n",
      "           7       0.48      0.63      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22585034013605443\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0   0   0 201]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0 122   0   0   0  88]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.80      0.58      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.14      0.23      0.14      1470\n",
      "weighted avg       0.14      0.23      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.24693877551020407\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  7   1   2   0 200   0   0]\n",
      " [  5  30   3   0 172   0   0]\n",
      " [  0   0 122   0  88   0   0]\n",
      " [  1   1   4   0 204   0   0]\n",
      " [  2   3   1   0 204   0   0]\n",
      " [  2   4   3   0 201   0   0]\n",
      " [  0   4   0   0 206   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.03      0.06       210\n",
      "           2       0.70      0.14      0.24       210\n",
      "           3       0.90      0.58      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      0.97      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.31      0.25      0.18      1470\n",
      "weighted avg       0.31      0.25      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.27006802721088435\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 31   2   0   0   0   2 175]\n",
      " [  4  34   1   0   0   2 169]\n",
      " [  3   0 120   0   0   2  85]\n",
      " [  0   1   3   0   0   1 205]\n",
      " [  1   4   0   0   0   1 204]\n",
      " [  2   3   1   0   0   2 202]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.15      0.25       210\n",
      "           2       0.77      0.16      0.27       210\n",
      "           3       0.96      0.57      0.72       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.20      0.01      0.02       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.41      0.27      0.22      1470\n",
      "weighted avg       0.41      0.27      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2816326530612245\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 30   1  12   0   0   3 164]\n",
      " [  3  33  20   0   0   2 152]\n",
      " [  0   0 138   0   0   4  68]\n",
      " [  0   0  11   3   0   1 195]\n",
      " [  2   1   6   0   0   3 198]\n",
      " [  4   2  13   0   0   3 188]\n",
      " [  1   0   2   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.14      0.24       210\n",
      "           2       0.89      0.16      0.27       210\n",
      "           3       0.68      0.66      0.67       210\n",
      "           4       1.00      0.01      0.03       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.19      0.01      0.03       210\n",
      "           7       0.18      0.99      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.53      0.28      0.22      1470\n",
      "weighted avg       0.53      0.28      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3040816326530612\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 31  11   2 111   0   1  54]\n",
      " [  1  47   8 113   0   1  40]\n",
      " [  0  11 131  56   0   0  12]\n",
      " [  0   7   4 115   0   0  84]\n",
      " [  1   8   1 121   0   0  79]\n",
      " [  2  12   4 110   0   4  78]\n",
      " [  1   1   1  88   0   0 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.15      0.25       210\n",
      "           2       0.48      0.22      0.31       210\n",
      "           3       0.87      0.62      0.73       210\n",
      "           4       0.16      0.55      0.25       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.67      0.02      0.04       210\n",
      "           7       0.26      0.57      0.35       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.47      0.30      0.27      1470\n",
      "weighted avg       0.47      0.30      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 22  10   3 117   1   3  54]\n",
      " [  3  77   3  83   2   2  40]\n",
      " [  0  14 135  47   2   0  12]\n",
      " [  0  10   2 111   1   3  83]\n",
      " [  0  10   1 116   3   1  79]\n",
      " [  2  10   4 111   0   5  78]\n",
      " [  0   4   1  86   0   0 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.10      0.19       210\n",
      "           2       0.57      0.37      0.45       210\n",
      "           3       0.91      0.64      0.75       210\n",
      "           4       0.17      0.53      0.25       210\n",
      "           5       0.33      0.01      0.03       210\n",
      "           6       0.36      0.02      0.04       210\n",
      "           7       0.26      0.57      0.35       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.49      0.32      0.29      1470\n",
      "weighted avg       0.49      0.32      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79   5   3  64   7  33  19]\n",
      " [ 33  72   4  60   5  27   9]\n",
      " [ 11   9 135  39   6   8   2]\n",
      " [ 45   8   2  70  12  59  14]\n",
      " [ 57   5   1  64  20  39  24]\n",
      " [ 41   5   2  77   8  41  36]\n",
      " [ 32   5   2  55  10  52  54]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.38      0.31       210\n",
      "           2       0.66      0.34      0.45       210\n",
      "           3       0.91      0.64      0.75       210\n",
      "           4       0.16      0.33      0.22       210\n",
      "           5       0.29      0.10      0.14       210\n",
      "           6       0.16      0.20      0.17       210\n",
      "           7       0.34      0.26      0.29       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.40      0.32      0.34      1470\n",
      "weighted avg       0.40      0.32      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 47   7   4  56  46  34  16]\n",
      " [ 11  63  12  53  36  29   6]\n",
      " [  3   3 143  34  14   8   5]\n",
      " [ 14   9   4  69  40  61  13]\n",
      " [ 10   5   2  64  64  42  23]\n",
      " [ 13   8   7  72  32  44  34]\n",
      " [  7   1   2  55  34  58  53]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.22      0.30       210\n",
      "           2       0.66      0.30      0.41       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.17      0.33      0.23       210\n",
      "           5       0.24      0.30      0.27       210\n",
      "           6       0.16      0.21      0.18       210\n",
      "           7       0.35      0.25      0.29       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.41      0.33      0.35      1470\n",
      "weighted avg       0.41      0.33      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 46   5   1  61  45  12  40]\n",
      " [  7  67   7  69  28   8  24]\n",
      " [  3   4 141  41   8   6   7]\n",
      " [ 12   5   5  72  41  16  59]\n",
      " [ 10   3   1  65  64  10  57]\n",
      " [ 10  12   2  75  33  20  58]\n",
      " [  3   1   2  58  35  16  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.22      0.31       210\n",
      "           2       0.69      0.32      0.44       210\n",
      "           3       0.89      0.67      0.76       210\n",
      "           4       0.16      0.34      0.22       210\n",
      "           5       0.25      0.30      0.28       210\n",
      "           6       0.23      0.10      0.13       210\n",
      "           7       0.28      0.45      0.35       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.43      0.34      0.35      1470\n",
      "weighted avg       0.43      0.34      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  16   2  42  28  13  36]\n",
      " [ 21  82   8  41  28   8  22]\n",
      " [  1  20 145  19  13   6   6]\n",
      " [ 23  12   5  66  33  16  55]\n",
      " [ 31  22   1  42  50  13  51]\n",
      " [ 30  21   1  58  24  23  53]\n",
      " [ 25   7   1  38  30  18  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.35      0.35       210\n",
      "           2       0.46      0.39      0.42       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.22      0.31      0.26       210\n",
      "           5       0.24      0.24      0.24       210\n",
      "           6       0.24      0.11      0.15       210\n",
      "           7       0.29      0.43      0.35       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.36      1470\n",
      "weighted avg       0.38      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  20   2  30  20  32  34]\n",
      " [ 15  85  10  24  23  28  25]\n",
      " [  3  19 146  10  11  15   6]\n",
      " [ 26  17   6  48  18  37  58]\n",
      " [ 28  25   2  32  48  19  56]\n",
      " [ 30  23   6  42  19  36  54]\n",
      " [ 29  11   2  20  18  38  92]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.35       210\n",
      "           2       0.42      0.40      0.41       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.23      0.23      0.23       210\n",
      "           5       0.31      0.23      0.26       210\n",
      "           6       0.18      0.17      0.17       210\n",
      "           7       0.28      0.44      0.34       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3625850340136054\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  13   3  33  20  28  41]\n",
      " [ 13  80   8  19  28  35  27]\n",
      " [  5   8 147   8  13  23   6]\n",
      " [ 30  11   7  50  17  35  60]\n",
      " [ 27  13   2  32  44  36  56]\n",
      " [ 33  10   5  42  26  46  48]\n",
      " [ 28  10   2  21  21  34  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.34       210\n",
      "           2       0.55      0.38      0.45       210\n",
      "           3       0.84      0.70      0.77       210\n",
      "           4       0.24      0.24      0.24       210\n",
      "           5       0.26      0.21      0.23       210\n",
      "           6       0.19      0.22      0.21       210\n",
      "           7       0.28      0.45      0.35       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.39      0.36      0.37      1470\n",
      "weighted avg       0.39      0.36      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34965986394557824\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57  12   4  29  36  34  38]\n",
      " [ 12  82   8  24  27  38  19]\n",
      " [  6   9 148   9   9  25   4]\n",
      " [ 23  18   4  44  31  31  59]\n",
      " [ 19  14   0  28  53  38  58]\n",
      " [ 27  15   6  37  26  44  55]\n",
      " [ 11   9   2  28  34  40  86]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.27      0.31       210\n",
      "           2       0.52      0.39      0.44       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.22      0.21      0.22       210\n",
      "           5       0.25      0.25      0.25       210\n",
      "           6       0.18      0.21      0.19       210\n",
      "           7       0.27      0.41      0.33       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.38      0.35      0.36      1470\n",
      "weighted avg       0.38      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55  16   8  22  37  30  42]\n",
      " [ 11  85  10  17  28  33  26]\n",
      " [  7   7 149   9  14  20   4]\n",
      " [ 28  13   5  42  31  27  64]\n",
      " [ 19  21   0  27  57  28  58]\n",
      " [ 29  20   5  33  31  37  55]\n",
      " [ 20   8   5  28  26  39  84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.26      0.29       210\n",
      "           2       0.50      0.40      0.45       210\n",
      "           3       0.82      0.71      0.76       210\n",
      "           4       0.24      0.20      0.22       210\n",
      "           5       0.25      0.27      0.26       210\n",
      "           6       0.17      0.18      0.17       210\n",
      "           7       0.25      0.40      0.31       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.37      0.35      0.35      1470\n",
      "weighted avg       0.37      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.354421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  18  11  29  21  23  37]\n",
      " [ 11  91   9  29  30  18  22]\n",
      " [  5  10 150  16   9  16   4]\n",
      " [ 34  16   7  47  31  24  51]\n",
      " [ 33  18   0  32  49  23  55]\n",
      " [ 29  24   8  36  29  38  46]\n",
      " [ 24  12   3  32  35  29  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.34      0.34       210\n",
      "           2       0.48      0.43      0.46       210\n",
      "           3       0.80      0.71      0.75       210\n",
      "           4       0.21      0.22      0.22       210\n",
      "           5       0.24      0.23      0.24       210\n",
      "           6       0.22      0.18      0.20       210\n",
      "           7       0.26      0.36      0.30       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.37      0.35      0.36      1470\n",
      "weighted avg       0.37      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  20  13  35  22  21  31]\n",
      " [ 21  86  12  25  31  12  23]\n",
      " [ 11   8 144  12   7  24   4]\n",
      " [ 33  17   6  51  27  26  50]\n",
      " [ 26  19   7  30  51  27  50]\n",
      " [ 43  19  12  30  32  33  41]\n",
      " [ 23  11   8  30  31  33  74]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.32      0.31       210\n",
      "           2       0.48      0.41      0.44       210\n",
      "           3       0.71      0.69      0.70       210\n",
      "           4       0.24      0.24      0.24       210\n",
      "           5       0.25      0.24      0.25       210\n",
      "           6       0.19      0.16      0.17       210\n",
      "           7       0.27      0.35      0.31       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.35      0.34      0.35      1470\n",
      "weighted avg       0.35      0.34      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  17   6  29  30  25  33]\n",
      " [ 17  94  12  18  31  20  18]\n",
      " [ 11  13 153   7   9  13   4]\n",
      " [ 24  23   5  46  36  26  50]\n",
      " [ 27  20   6  25  53  24  55]\n",
      " [ 28  28   6  29  42  34  43]\n",
      " [ 21  13   8  25  37  32  74]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.33      0.34       210\n",
      "           2       0.45      0.45      0.45       210\n",
      "           3       0.78      0.73      0.75       210\n",
      "           4       0.26      0.22      0.24       210\n",
      "           5       0.22      0.25      0.24       210\n",
      "           6       0.20      0.16      0.18       210\n",
      "           7       0.27      0.35      0.30       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36462585034013606\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  19   7  30  34  18  29]\n",
      " [ 11  98  12  21  34  19  15]\n",
      " [  8  13 151   9  13  14   2]\n",
      " [ 25  25   5  58  39  23  35]\n",
      " [ 29  21   3  35  51  29  42]\n",
      " [ 34  28   5  35  37  35  36]\n",
      " [ 20  14   4  30  41  31  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.35      0.36       210\n",
      "           2       0.45      0.47      0.46       210\n",
      "           3       0.81      0.72      0.76       210\n",
      "           4       0.27      0.28      0.27       210\n",
      "           5       0.20      0.24      0.22       210\n",
      "           6       0.21      0.17      0.18       210\n",
      "           7       0.31      0.33      0.32       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.37      1470\n",
      "weighted avg       0.37      0.36      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  18  12  30  28  19  30]\n",
      " [ 14  95   9  20  36  19  17]\n",
      " [  9  14 152  10  10  14   1]\n",
      " [ 31  23   7  49  41  24  35]\n",
      " [ 28  22   7  29  57  28  39]\n",
      " [ 37  19  10  43  27  38  36]\n",
      " [ 18   7   5  50  44  28  58]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.35      0.35       210\n",
      "           2       0.48      0.45      0.47       210\n",
      "           3       0.75      0.72      0.74       210\n",
      "           4       0.21      0.23      0.22       210\n",
      "           5       0.23      0.27      0.25       210\n",
      "           6       0.22      0.18      0.20       210\n",
      "           7       0.27      0.28      0.27       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  19  11  31  25  24  29]\n",
      " [ 15  98  11  21  35  14  16]\n",
      " [  7  14 152  11   9  13   4]\n",
      " [ 28  27   6  44  48  22  35]\n",
      " [ 29  20   4  32  63  20  42]\n",
      " [ 34  31   7  33  31  38  36]\n",
      " [ 23  10   6  40  42  27  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.34      0.34       210\n",
      "           2       0.45      0.47      0.46       210\n",
      "           3       0.77      0.72      0.75       210\n",
      "           4       0.21      0.21      0.21       210\n",
      "           5       0.25      0.30      0.27       210\n",
      "           6       0.24      0.18      0.21       210\n",
      "           7       0.28      0.30      0.29       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.36      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  6   6  13  18   4   2 161]\n",
      " [  8  31  29  11  10   3 118]\n",
      " [  4  11 153  10   3   0  29]\n",
      " [  7  18  14  14   4   8 145]\n",
      " [  4   8  11  11   2   1 173]\n",
      " [  5   6  17  14   7   5 156]\n",
      " [  4   4   2   7   2   1 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.03      0.05       210\n",
      "           2       0.37      0.15      0.21       210\n",
      "           3       0.64      0.73      0.68       210\n",
      "           4       0.16      0.07      0.09       210\n",
      "           5       0.06      0.01      0.02       210\n",
      "           6       0.25      0.02      0.04       210\n",
      "           7       0.20      0.90      0.32       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.26      0.27      0.20      1470\n",
      "weighted avg       0.26      0.27      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.336734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61  23   4  10   7   2 103]\n",
      " [ 30 102   6  10   4   6  52]\n",
      " [  9  34 147   5   0   3  12]\n",
      " [ 29  32   7  14   3   7 118]\n",
      " [ 23  35   4   8   4   4 132]\n",
      " [ 20  39   8   9   6   6 122]\n",
      " [ 20  14   1   5   3   6 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.29      0.30       210\n",
      "           2       0.37      0.49      0.42       210\n",
      "           3       0.83      0.70      0.76       210\n",
      "           4       0.23      0.07      0.10       210\n",
      "           5       0.15      0.02      0.03       210\n",
      "           6       0.18      0.03      0.05       210\n",
      "           7       0.23      0.77      0.35       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.33      0.34      0.29      1470\n",
      "weighted avg       0.33      0.34      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 52  28   2  16  35   4  73]\n",
      " [ 14 103   9  22  27   5  30]\n",
      " [  4  25 146  17   6   3   9]\n",
      " [ 12  35   3  24  34   9  93]\n",
      " [  6  27   5  18  52   6  96]\n",
      " [ 11  33   5  22  25  15  99]\n",
      " [  9  11   0  11  22   4 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.25      0.33       210\n",
      "           2       0.39      0.49      0.44       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.18      0.11      0.14       210\n",
      "           5       0.26      0.25      0.25       210\n",
      "           6       0.33      0.07      0.12       210\n",
      "           7       0.28      0.73      0.40       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.40      0.37      0.35      1470\n",
      "weighted avg       0.40      0.37      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.38979591836734695\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 55  22   1  27  47   4  54]\n",
      " [ 12 110   3  28  28   5  24]\n",
      " [  2  35 144  17   6   2   4]\n",
      " [  6  25   7  43  46  10  73]\n",
      " [  7  29   3  25  68   3  75]\n",
      " [  5  31   3  37  33  15  86]\n",
      " [  5  11   0  24  27   5 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.26      0.36       210\n",
      "           2       0.42      0.52      0.47       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.21      0.20      0.21       210\n",
      "           5       0.27      0.32      0.29       210\n",
      "           6       0.34      0.07      0.12       210\n",
      "           7       0.30      0.66      0.42       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.43      0.39      0.38      1470\n",
      "weighted avg       0.43      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41360544217687073\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 59   9   2  44  50   8  38]\n",
      " [  8 110   3  35  23   9  22]\n",
      " [  1  21 153  24   5   2   4]\n",
      " [  7  11   5  72  37  13  65]\n",
      " [ 10  20   6  40  65   6  63]\n",
      " [  5  26   3  46  25  19  86]\n",
      " [  1   2   0  42  28   7 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.28      0.39       210\n",
      "           2       0.55      0.52      0.54       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.24      0.34      0.28       210\n",
      "           5       0.28      0.31      0.29       210\n",
      "           6       0.30      0.09      0.14       210\n",
      "           7       0.32      0.62      0.42       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.46      0.41      0.41      1470\n",
      "weighted avg       0.46      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 59   9   0  37  56  13  36]\n",
      " [  4 112   4  34  27   7  22]\n",
      " [  3  22 149  24   6   3   3]\n",
      " [  7  12   6  71  44  20  50]\n",
      " [  4  21   3  47  78   4  53]\n",
      " [  8  22   3  44  34  23  76]\n",
      " [  2   5   0  44  27  12 120]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.28      0.40       210\n",
      "           2       0.55      0.53      0.54       210\n",
      "           3       0.90      0.71      0.79       210\n",
      "           4       0.24      0.34      0.28       210\n",
      "           5       0.29      0.37      0.32       210\n",
      "           6       0.28      0.11      0.16       210\n",
      "           7       0.33      0.57      0.42       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.47      0.42      0.42      1470\n",
      "weighted avg       0.47      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.42857142857142855\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 65   7   0  41  50  13  34]\n",
      " [  6 102   9  33  34  14  12]\n",
      " [  3  28 153  16   4   4   2]\n",
      " [  5  18   1  77  43  21  45]\n",
      " [  5  21   1  44  80  11  48]\n",
      " [  8  16   3  47  33  39  64]\n",
      " [  0   4   0  36  34  22 114]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.31      0.43       210\n",
      "           2       0.52      0.49      0.50       210\n",
      "           3       0.92      0.73      0.81       210\n",
      "           4       0.26      0.37      0.31       210\n",
      "           5       0.29      0.38      0.33       210\n",
      "           6       0.31      0.19      0.23       210\n",
      "           7       0.36      0.54      0.43       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.48      0.43      0.43      1470\n",
      "weighted avg       0.48      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43537414965986393\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 63   6   0  44  51  13  33]\n",
      " [  4 112   9  34  31   8  12]\n",
      " [  1  24 154  19   3   6   3]\n",
      " [  6  11   1  79  51  17  45]\n",
      " [  8  28   2  37  85   6  44]\n",
      " [ 12  20   2  42  35  37  62]\n",
      " [  2   5   0  41  32  20 110]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.30      0.41       210\n",
      "           2       0.54      0.53      0.54       210\n",
      "           3       0.92      0.73      0.81       210\n",
      "           4       0.27      0.38      0.31       210\n",
      "           5       0.30      0.40      0.34       210\n",
      "           6       0.35      0.18      0.23       210\n",
      "           7       0.36      0.52      0.42       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.44      1470\n",
      "weighted avg       0.48      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44285714285714284\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 63   6   0  45  50  16  30]\n",
      " [  7 111   4  37  30   9  12]\n",
      " [  6  22 158  13   6   3   2]\n",
      " [  6  14   2  77  44  28  39]\n",
      " [ 11  20   1  35  93  11  39]\n",
      " [  8  14   2  45  40  41  60]\n",
      " [  5   2   0  38  35  22 108]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.30      0.40       210\n",
      "           2       0.59      0.53      0.56       210\n",
      "           3       0.95      0.75      0.84       210\n",
      "           4       0.27      0.37      0.31       210\n",
      "           5       0.31      0.44      0.37       210\n",
      "           6       0.32      0.20      0.24       210\n",
      "           7       0.37      0.51      0.43       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.45      1470\n",
      "weighted avg       0.48      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.43945578231292515\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 67   7   1  44  47  17  27]\n",
      " [  5 107   2  39  30  14  13]\n",
      " [  1  22 156  18   5   7   1]\n",
      " [  5  10   4  79  45  28  39]\n",
      " [  8  18   2  41  90  15  36]\n",
      " [  3  23   0  43  31  40  70]\n",
      " [  8   2   0  34  33  26 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.32      0.44       210\n",
      "           2       0.57      0.51      0.54       210\n",
      "           3       0.95      0.74      0.83       210\n",
      "           4       0.27      0.38      0.31       210\n",
      "           5       0.32      0.43      0.37       210\n",
      "           6       0.27      0.19      0.22       210\n",
      "           7       0.37      0.51      0.43       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.49      0.44      0.45      1470\n",
      "weighted avg       0.49      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 72   5   0  38  50  16  29]\n",
      " [  6 109   3  36  29  16  11]\n",
      " [  4  17 157  15   5  10   2]\n",
      " [ 10  14   5  74  45  29  33]\n",
      " [ 12  25   2  37  89  10  35]\n",
      " [  7  13   5  49  26  49  61]\n",
      " [  3   5   0  36  29  25 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.34      0.44       210\n",
      "           2       0.58      0.52      0.55       210\n",
      "           3       0.91      0.75      0.82       210\n",
      "           4       0.26      0.35      0.30       210\n",
      "           5       0.33      0.42      0.37       210\n",
      "           6       0.32      0.23      0.27       210\n",
      "           7       0.40      0.53      0.45       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.46      1470\n",
      "weighted avg       0.49      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.445578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 71   5   0  38  49  25  22]\n",
      " [  5 107   2  38  28  17  13]\n",
      " [  2  19 158  19   6   4   2]\n",
      " [ 12  11   5  72  46  26  38]\n",
      " [  8  22   1  36  91  17  35]\n",
      " [  8  12   2  44  33  49  62]\n",
      " [ 10   3   0  36  33  21 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.34      0.44       210\n",
      "           2       0.60      0.51      0.55       210\n",
      "           3       0.94      0.75      0.84       210\n",
      "           4       0.25      0.34      0.29       210\n",
      "           5       0.32      0.43      0.37       210\n",
      "           6       0.31      0.23      0.27       210\n",
      "           7       0.38      0.51      0.44       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.45      1470\n",
      "weighted avg       0.49      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 71   7   0  39  47  20  26]\n",
      " [  4 105   8  40  28  13  12]\n",
      " [  6  19 157  13   4   9   2]\n",
      " [ 12  12   5  79  39  30  33]\n",
      " [ 13  21   2  40  87  14  33]\n",
      " [  8  16   1  51  28  44  62]\n",
      " [  3   2   0  40  31  18 116]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.34      0.43       210\n",
      "           2       0.58      0.50      0.54       210\n",
      "           3       0.91      0.75      0.82       210\n",
      "           4       0.26      0.38      0.31       210\n",
      "           5       0.33      0.41      0.37       210\n",
      "           6       0.30      0.21      0.25       210\n",
      "           7       0.41      0.55      0.47       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.48      0.45      0.45      1470\n",
      "weighted avg       0.48      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 76   5   0  36  49  19  25]\n",
      " [ 12 106   3  31  34  13  11]\n",
      " [  6  17 158  15   7   6   1]\n",
      " [ 14  10   5  79  39  29  34]\n",
      " [ 10  18   2  39  89  20  32]\n",
      " [ 11  16   1  50  31  42  59]\n",
      " [ 10   5   0  34  32  29 100]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.36      0.44       210\n",
      "           2       0.60      0.50      0.55       210\n",
      "           3       0.93      0.75      0.83       210\n",
      "           4       0.28      0.38      0.32       210\n",
      "           5       0.32      0.42      0.36       210\n",
      "           6       0.27      0.20      0.23       210\n",
      "           7       0.38      0.48      0.42       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.45      1470\n",
      "weighted avg       0.47      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.445578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 76   8   0  32  46  22  26]\n",
      " [  9 104  11  33  24  18  11]\n",
      " [  2  20 155  16   4  11   2]\n",
      " [ 15  15   4  67  41  34  34]\n",
      " [ 11  19   2  34  91  17  36]\n",
      " [  6  13   1  46  30  53  61]\n",
      " [  5   2   0  33  38  23 109]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.36      0.46       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.90      0.74      0.81       210\n",
      "           4       0.26      0.32      0.28       210\n",
      "           5       0.33      0.43      0.38       210\n",
      "           6       0.30      0.25      0.27       210\n",
      "           7       0.39      0.52      0.45       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.48      0.45      0.45      1470\n",
      "weighted avg       0.48      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83   4   0  21  53  24  25]\n",
      " [  6 111  10  33  26  12  12]\n",
      " [  4  20 159  14   4   6   3]\n",
      " [  7  14   7  69  47  33  33]\n",
      " [ 14  19   1  37  92  13  34]\n",
      " [  8  21   0  39  31  49  62]\n",
      " [  5   3   0  33  25  35 109]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.40      0.49       210\n",
      "           2       0.58      0.53      0.55       210\n",
      "           3       0.90      0.76      0.82       210\n",
      "           4       0.28      0.33      0.30       210\n",
      "           5       0.33      0.44      0.38       210\n",
      "           6       0.28      0.23      0.26       210\n",
      "           7       0.39      0.52      0.45       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.46      1470\n",
      "weighted avg       0.49      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 81   4   0  29  50  17  29]\n",
      " [  5 116   7  24  30  19   9]\n",
      " [  7  16 161  12   3  10   1]\n",
      " [  8  13   5  79  39  31  35]\n",
      " [ 14  18   1  28  97  17  35]\n",
      " [ 14  13   1  45  28  49  60]\n",
      " [  8   6   0  30  27  27 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.39      0.47       210\n",
      "           2       0.62      0.55      0.59       210\n",
      "           3       0.92      0.77      0.84       210\n",
      "           4       0.32      0.38      0.35       210\n",
      "           5       0.35      0.46      0.40       210\n",
      "           6       0.29      0.23      0.26       210\n",
      "           7       0.40      0.53      0.46       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.50      0.47      0.48      1470\n",
      "weighted avg       0.50      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79   8   0  31  48  15  29]\n",
      " [  7 114   3  21  37  20   8]\n",
      " [  5  20 158  12   4   8   3]\n",
      " [ 15  13   5  71  35  38  33]\n",
      " [ 17  17   4  31  91  15  35]\n",
      " [ 10  23   1  34  28  55  59]\n",
      " [  4   3   0  31  37  37  98]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.38      0.46       210\n",
      "           2       0.58      0.54      0.56       210\n",
      "           3       0.92      0.75      0.83       210\n",
      "           4       0.31      0.34      0.32       210\n",
      "           5       0.33      0.43      0.37       210\n",
      "           6       0.29      0.26      0.28       210\n",
      "           7       0.37      0.47      0.41       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.48      0.45      0.46      1470\n",
      "weighted avg       0.48      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45850340136054424\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 76   9   0  30  47  25  23]\n",
      " [  8 110   3  29  29  18  13]\n",
      " [  5  17 159  15   5   5   4]\n",
      " [ 11  11   7  76  37  37  31]\n",
      " [ 18  18   1  36  90  12  35]\n",
      " [ 10  19   0  37  23  60  61]\n",
      " [  7   2   0  27  30  41 103]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.36      0.44       210\n",
      "           2       0.59      0.52      0.56       210\n",
      "           3       0.94      0.76      0.84       210\n",
      "           4       0.30      0.36      0.33       210\n",
      "           5       0.34      0.43      0.38       210\n",
      "           6       0.30      0.29      0.29       210\n",
      "           7       0.38      0.49      0.43       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.47      1470\n",
      "weighted avg       0.49      0.46      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78   8   1  30  44  20  29]\n",
      " [  8 114   5  29  24  19  11]\n",
      " [  3  23 157  10   6   9   2]\n",
      " [ 16  12   5  72  43  29  33]\n",
      " [ 17  22   2  40  82  11  36]\n",
      " [ 13  17   0  32  34  52  62]\n",
      " [  6   4   0  24  24  35 117]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.37      0.44       210\n",
      "           2       0.57      0.54      0.56       210\n",
      "           3       0.92      0.75      0.83       210\n",
      "           4       0.30      0.34      0.32       210\n",
      "           5       0.32      0.39      0.35       210\n",
      "           6       0.30      0.25      0.27       210\n",
      "           7       0.40      0.56      0.47       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.46      1470\n",
      "weighted avg       0.48      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 56  27   2  49  37   7  32]\n",
      " [ 16 102  21  32  19   4  16]\n",
      " [  6  39 143  17   2   0   3]\n",
      " [ 12  23   7  74  34  15  45]\n",
      " [ 10  35   5  49  66   4  41]\n",
      " [ 14  27   6  48  21  25  69]\n",
      " [  5   7   0  43  24  19 112]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.27      0.34       210\n",
      "           2       0.39      0.49      0.43       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.24      0.35      0.28       210\n",
      "           5       0.33      0.31      0.32       210\n",
      "           6       0.34      0.12      0.18       210\n",
      "           7       0.35      0.53      0.42       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.39      1470\n",
      "weighted avg       0.41      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//xlm_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model, x_df, labels, \"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_df, labels,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_df, labels,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_df, labels,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_df, labels,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_df, labels,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_df, labels,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_df=mms_scale.fit_transform(x_df)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_df, labels,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
