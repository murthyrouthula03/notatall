{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a97c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc7a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels\n",
       "0          2\n",
       "1          3\n",
       "2          3\n",
       "3          3\n",
       "4          1\n",
       "...      ...\n",
       "4895       7\n",
       "4896       7\n",
       "4897       5\n",
       "4898       7\n",
       "4899       7\n",
       "\n",
       "[4900 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading labels\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Nisha//Input//Nisha_dataset_labels.csv\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60cfe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b881f",
   "metadata": {},
   "source": [
    "### Data split for TFIDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5044766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.7326530612244898\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[170   3   0   5  17  15   0]\n",
      " [  1 151  11  18   7  22   0]\n",
      " [  0   9 176  17   1   7   0]\n",
      " [  2  14  15 143  10  25   1]\n",
      " [ 23  18   5  26 124   8   6]\n",
      " [  1  15   2  30   0 134  28]\n",
      " [  1   1   0   0   1  28 179]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.81      0.83       210\n",
      "           2       0.72      0.72      0.72       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.78      0.59      0.67       210\n",
      "           6       0.56      0.64      0.60       210\n",
      "           7       0.84      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.5027210884353741\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   9  31   3   6  19   1]\n",
      " [ 22 127  35  11   8   6   1]\n",
      " [  3   9 183  13   0   2   0]\n",
      " [ 29  29  55  82   3  12   0]\n",
      " [ 46  44  64  16  32   7   1]\n",
      " [ 28  24  78  11   3  52  14]\n",
      " [  8   3  56   0   1  20 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.67      0.58       210\n",
      "           2       0.52      0.60      0.56       210\n",
      "           3       0.36      0.87      0.51       210\n",
      "           4       0.60      0.39      0.47       210\n",
      "           5       0.60      0.15      0.24       210\n",
      "           6       0.44      0.25      0.32       210\n",
      "           7       0.88      0.58      0.70       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.48      1470\n",
      "weighted avg       0.56      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5197278911564626\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136  20  10   3   7  31   3]\n",
      " [ 14 141  25  12   5  12   1]\n",
      " [  2  21 177   6   1   3   0]\n",
      " [ 24  35  35  84   3  29   0]\n",
      " [ 45  47  29  22  27  37   3]\n",
      " [ 23  52  21  15   2  81  16]\n",
      " [  7  16  12   4   1  52 118]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.65      0.59       210\n",
      "           2       0.42      0.67      0.52       210\n",
      "           3       0.57      0.84      0.68       210\n",
      "           4       0.58      0.40      0.47       210\n",
      "           5       0.59      0.13      0.21       210\n",
      "           6       0.33      0.39      0.36       210\n",
      "           7       0.84      0.56      0.67       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.50      1470\n",
      "weighted avg       0.55      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5095238095238095\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132  22  10   4   6  33   3]\n",
      " [ 12 135  29  12  10  12   0]\n",
      " [  1  23 172  11   1   2   0]\n",
      " [ 13  35  36  92   2  32   0]\n",
      " [ 31  59  28  26  28  35   3]\n",
      " [ 24  56  19  18   4  75  14]\n",
      " [  5  12   6   5   0  67 115]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.63      0.62       210\n",
      "           2       0.39      0.64      0.49       210\n",
      "           3       0.57      0.82      0.67       210\n",
      "           4       0.55      0.44      0.49       210\n",
      "           5       0.55      0.13      0.21       210\n",
      "           6       0.29      0.36      0.32       210\n",
      "           7       0.85      0.55      0.67       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.50      1470\n",
      "weighted avg       0.55      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.5006802721088436\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[124  26  12   5   5  37   1]\n",
      " [  7 143  29  12   3  16   0]\n",
      " [  1  21 173   8   3   4   0]\n",
      " [ 12  33  39  89   2  35   0]\n",
      " [ 33  59  33  23  18  42   2]\n",
      " [ 17  58  18  17   4  83  13]\n",
      " [  4  13  10   6   0  71 106]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.59      0.61       210\n",
      "           2       0.41      0.68      0.51       210\n",
      "           3       0.55      0.82      0.66       210\n",
      "           4       0.56      0.42      0.48       210\n",
      "           5       0.51      0.09      0.15       210\n",
      "           6       0.29      0.40      0.33       210\n",
      "           7       0.87      0.50      0.64       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.48      1470\n",
      "weighted avg       0.54      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.4931972789115646\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  29  13   4   4  39   0]\n",
      " [  8 139  29  13   2  19   0]\n",
      " [  1  19 175  11   0   4   0]\n",
      " [  9  33  36  86   3  43   0]\n",
      " [ 33  55  30  24  16  48   4]\n",
      " [ 13  62  17  13   3  88  14]\n",
      " [  3  16   9   3   0  79 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.58      0.61       210\n",
      "           2       0.39      0.66      0.49       210\n",
      "           3       0.57      0.83      0.67       210\n",
      "           4       0.56      0.41      0.47       210\n",
      "           5       0.57      0.08      0.13       210\n",
      "           6       0.28      0.42      0.33       210\n",
      "           7       0.85      0.48      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.55      0.49      0.48      1470\n",
      "weighted avg       0.55      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.49047619047619045\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122  25  14   6   4  39   0]\n",
      " [  8 131  30  12   6  23   0]\n",
      " [  3  19 167  13   2   6   0]\n",
      " [  7  27  34  89   6  47   0]\n",
      " [ 32  56  30  19  14  57   2]\n",
      " [ 11  53  14  14   2 105  11]\n",
      " [  3  14  11   2   0  87  93]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.40      0.62      0.49       210\n",
      "           3       0.56      0.80      0.65       210\n",
      "           4       0.57      0.42      0.49       210\n",
      "           5       0.41      0.07      0.11       210\n",
      "           6       0.29      0.50      0.37       210\n",
      "           7       0.88      0.44      0.59       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.54      0.49      0.47      1470\n",
      "weighted avg       0.54      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.527891156462585\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[134   2  11  45   6  10   2]\n",
      " [ 15 129  53   7   4   1   1]\n",
      " [  1   8 196   3   1   0   1]\n",
      " [  9  37  58  80  16   8   2]\n",
      " [ 60  20   4  79  29  14   4]\n",
      " [ 14  36  61  19   6  26  48]\n",
      " [  3   4   3   3   5  10 182]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.55      0.61      0.58       210\n",
      "           3       0.51      0.93      0.66       210\n",
      "           4       0.34      0.38      0.36       210\n",
      "           5       0.43      0.14      0.21       210\n",
      "           6       0.38      0.12      0.19       210\n",
      "           7       0.76      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.50      0.53      0.49      1470\n",
      "weighted avg       0.50      0.53      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes is: 0.6952380952380952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[164   4  11   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 31  18   8  22 124   4   3]\n",
      " [  5  28  47  27   2  77  24]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.78      0.78       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.72      0.59      0.65       210\n",
      "           6       0.65      0.37      0.47       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM is: 0.7360544217687075\n",
      "Confusion Matrix of SVM is:\n",
      " [[164   1   0   1  25  19   0]\n",
      " [  1 153  12  16   4  24   0]\n",
      " [  0   8 178  17   1   6   0]\n",
      " [  2  17  15 134  11  30   1]\n",
      " [ 20  20   6  20 136   3   5]\n",
      " [  1  11   5  19   1 144  29]\n",
      " [  0   1   0   0   1  35 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.78      0.82       210\n",
      "           2       0.73      0.73      0.73       210\n",
      "           3       0.82      0.85      0.84       210\n",
      "           4       0.65      0.64      0.64       210\n",
      "           5       0.76      0.65      0.70       210\n",
      "           6       0.55      0.69      0.61       210\n",
      "           7       0.83      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.6517006802721088\n",
      "Confusion Matrix of SVM is:\n",
      " [[128   4   1   3  31  43   0]\n",
      " [  4 132  12  20  18  23   1]\n",
      " [  0  13 165  16   5  11   0]\n",
      " [  3  12  12 121  19  42   1]\n",
      " [ 16  14   5  33 110  29   3]\n",
      " [  7  13   5  16   3 144  22]\n",
      " [  0   2   0   1   1  48 158]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.61      0.70       210\n",
      "           2       0.69      0.63      0.66       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.58      0.58      0.58       210\n",
      "           5       0.59      0.52      0.55       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.85      0.75      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.7238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   4   0   4  29  17   0]\n",
      " [  1 154   9  18   8  20   0]\n",
      " [  0  13 167  18   3   9   0]\n",
      " [  2  16  12 140  11  28   1]\n",
      " [ 17  18   5  25 132   7   6]\n",
      " [  4  15   2  23   0 139  27]\n",
      " [  0   1   0   1   1  31 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.74      0.80       210\n",
      "           2       0.70      0.73      0.71       210\n",
      "           3       0.86      0.80      0.82       210\n",
      "           4       0.61      0.67      0.64       210\n",
      "           5       0.72      0.63      0.67       210\n",
      "           6       0.55      0.66      0.60       210\n",
      "           7       0.84      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.73      1470\n",
      "weighted avg       0.73      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.6727891156462585\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   4   1   2  24  16   1]\n",
      " [  1 129  29  25   5  21   0]\n",
      " [  0   5 181  17   1   6   0]\n",
      " [  1  15  20 135  10  23   6]\n",
      " [ 60  21  12  24  84   5   4]\n",
      " [  1  11   5  35   1 124  33]\n",
      " [  0   3   0   1   0  32 174]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.77      0.74       210\n",
      "           2       0.69      0.61      0.65       210\n",
      "           3       0.73      0.86      0.79       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.67      0.40      0.50       210\n",
      "           6       0.55      0.59      0.57       210\n",
      "           7       0.80      0.83      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.19931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [127   0  83   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.15      0.20      0.12      1470\n",
      "weighted avg       0.15      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.25510204081632654\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   0   0   0   0   0 128]\n",
      " [  1   0   3   0   0   0 206]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   0   0 205]\n",
      " [ 64   0   1   0   0   0 145]\n",
      " [  1   0   0   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.24      0.26      0.19      1470\n",
      "weighted avg       0.24      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   0   0   0  56   0  44]\n",
      " [  2   0   3   0   0   0 205]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   3   0 202]\n",
      " [ 69   0   1   0  61   0  79]\n",
      " [  2   0   0   0   1   0 207]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.50      0.29      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      1.00      0.33       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.26      1470\n",
      "weighted avg       0.32      0.32      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.3782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  44   0   0  44   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  3 201   2   0   3   0   1]\n",
      " [ 59  77   1   0  71   0   2]\n",
      " [  1 199   0   0   2   0   8]\n",
      " [  0 134   0   0   0   0  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.21      0.97      0.34       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.34      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.46      0.38      0.35      1470\n",
      "weighted avg       0.46      0.38      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  44   0   0  68   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  0 201   2   0   6   0   1]\n",
      " [ 17  76   1   0 113   0   3]\n",
      " [  0 197   0   0   3   0  10]\n",
      " [  0 110   0   0   0   1  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.47      0.60       210\n",
      "           2       0.21      0.97      0.35       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.54      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.49      0.41      0.38      1470\n",
      "weighted avg       0.49      0.41      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.4170068027210884\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   0   0   0  70  44   0]\n",
      " [  1  27   3   0   1 177   1]\n",
      " [  0   0  83   0   0 127   0]\n",
      " [  0   0   2   0   6 201   1]\n",
      " [ 13  13   1   0 117  63   3]\n",
      " [  0   0   0   0   3 197  10]\n",
      " [  0   0   0   0   6 111  93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.46      0.60       210\n",
      "           2       0.68      0.13      0.22       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.58      0.56      0.57       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.44      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.59      0.42      0.41      1470\n",
      "weighted avg       0.59      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.44625850340136053\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   1   0   1  41  43   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  35  83   0   0  92   0]\n",
      " [  3  14   2   0   3 187   1]\n",
      " [ 46  25   1   1  83  51   3]\n",
      " [  1   2   0   0   2 195  10]\n",
      " [  0   1   0   0   3 110  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.49      0.36      0.41       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.62      0.40      0.48       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.44      1470\n",
      "weighted avg       0.55      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.4673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   0  43  43   0]\n",
      " [  1  74  29   1   1 104   0]\n",
      " [  0   0 118   0   0  92   0]\n",
      " [  3   1  15   0   3 187   1]\n",
      " [ 45  19   9   3  82  49   3]\n",
      " [  1   0   2   0   2 195  10]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.77      0.35      0.48       210\n",
      "           3       0.68      0.56      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.39      0.48       210\n",
      "           6       0.25      0.93      0.39       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.56      0.47      0.46      1470\n",
      "weighted avg       0.56      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.482312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  44  43   0]\n",
      " [  1  80  25   0   1 102   1]\n",
      " [  0   0 134   0   0  76   0]\n",
      " [  3   1  16   0   3 186   1]\n",
      " [ 44  19   9   3  83  49   3]\n",
      " [  1   0   3   0   2 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64       210\n",
      "           2       0.78      0.38      0.51       210\n",
      "           3       0.72      0.64      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.40      0.48       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.47      1470\n",
      "weighted avg       0.56      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   0   0  43  44   0]\n",
      " [  1  94  12   0   2 100   1]\n",
      " [  0  14 126   0   0  70   0]\n",
      " [  3  10   7   0   3 186   1]\n",
      " [ 47  21   3   1  86  49   3]\n",
      " [  1   2   1   0   2 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64       210\n",
      "           2       0.66      0.45      0.53       210\n",
      "           3       0.85      0.60      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.41      0.49       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.56      0.49      0.48      1470\n",
      "weighted avg       0.56      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5142857142857142\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   0  18  44   0]\n",
      " [  1  93  10   2   5  98   1]\n",
      " [  0  11 129   0   0  70   0]\n",
      " [  4  10   7  16   2 170   1]\n",
      " [ 53  16   5   5  81  47   3]\n",
      " [  2   2   1   0   1 194  10]\n",
      " [  0   1   0   0   4 110  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.61      0.71       210\n",
      "           4       0.70      0.08      0.14       210\n",
      "           5       0.73      0.39      0.50       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.69      0.51      0.52      1470\n",
      "weighted avg       0.69      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5292517006802722\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   1  16  45   0]\n",
      " [  1  92  11   4   5  96   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  4  10   7  38   2 148   1]\n",
      " [ 55  19   4   4  79  46   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.81      0.18      0.30       210\n",
      "           5       0.74      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   3  15  43   0]\n",
      " [  2  90  12   3   4  98   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11   9  43   2 139   1]\n",
      " [ 54  19   4  11  76  43   3]\n",
      " [  2   1   2   1   1 193  10]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.43      0.53       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.70      0.20      0.32       210\n",
      "           5       0.75      0.36      0.49       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  18  37   0]\n",
      " [  2  92  11   4   4  97   0]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11  10  42   3 139   0]\n",
      " [ 51  19   4   7  88  39   2]\n",
      " [  2   1   2   1   1 194   9]\n",
      " [  0   1   0   0   3 111  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.78      0.20      0.32       210\n",
      "           5       0.75      0.42      0.54       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.90      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.71      0.54      0.55      1470\n",
      "weighted avg       0.71      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  20  35   0]\n",
      " [  2 106  11   1   6  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  17   9  43   3 133   0]\n",
      " [ 49  20   4   7  89  39   2]\n",
      " [  2   5   2   1   1 189  10]\n",
      " [  0   1   0   0   3 110  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.83      0.20      0.33       210\n",
      "           5       0.73      0.42      0.54       210\n",
      "           6       0.29      0.90      0.43       210\n",
      "           7       0.88      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.71      0.55      0.56      1470\n",
      "weighted avg       0.71      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   2  17  34   0]\n",
      " [  2 106  11   2   5  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  16  10  42   4 133   0]\n",
      " [ 54  21   4   6  90  32   3]\n",
      " [  2   5   2   1   1 190   9]\n",
      " [  0   1   0   0   4 111  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.74      0.43      0.54       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.5564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   0   0   0  22  32   0]\n",
      " [  2 104  13   2   6  82   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  11  44   3 131   0]\n",
      " [ 54  22   5   7  89  30   3]\n",
      " [  2   5   2   1   1 189  10]\n",
      " [  0   1   0   0   4 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.82      0.67      0.73       210\n",
      "           4       0.81      0.21      0.33       210\n",
      "           5       0.71      0.42      0.53       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.87      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.56      1470\n",
      "weighted avg       0.70      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree is: 0.5551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   2  27  32   0]\n",
      " [  2 105  13   2   4  83   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  12  42   3 131   1]\n",
      " [ 50  21   5   6  92  30   6]\n",
      " [  2   4   2   1   1 188  12]\n",
      " [  0   1   0   0   4 105 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.71       210\n",
      "           2       0.67      0.50      0.57       210\n",
      "           3       0.81      0.67      0.73       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.83      0.48      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.69      0.56      0.56      1470\n",
      "weighted avg       0.69      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   0   1  23  34   0]\n",
      " [  2 104  11   2   7  83   1]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  15  13  41   4 130   2]\n",
      " [ 49  19   5   5  96  30   6]\n",
      " [  2   4   2   1   1 183  17]\n",
      " [  0   1   0   0   3  95 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.70      0.50      0.58       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.81      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   0  23  30   0]\n",
      " [  2 105  12   3   6  82   0]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  12  13  42   6 130   2]\n",
      " [ 47  18   5   5  97  32   6]\n",
      " [  3   5   2   1   1 183  15]\n",
      " [  0   1   0   0   4 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.71      0.50      0.59       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.82      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.57      1470\n",
      "weighted avg       0.70      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.5680272108843537\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   4   1   2  23  35   2]\n",
      " [  1  91   6  21  17  73   1]\n",
      " [  2   0 124   3   0  81   0]\n",
      " [  4  10   3  92  15  83   3]\n",
      " [ 59  20   1  21  86  17   6]\n",
      " [  4   6   1  30   3 142  24]\n",
      " [  0   2   0   1   3  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.68      0.68       210\n",
      "           2       0.68      0.43      0.53       210\n",
      "           3       0.91      0.59      0.72       210\n",
      "           4       0.54      0.44      0.48       210\n",
      "           5       0.59      0.41      0.48       210\n",
      "           6       0.30      0.68      0.41       210\n",
      "           7       0.81      0.75      0.78       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.64      0.57      0.58      1470\n",
      "weighted avg       0.64      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   3  10  18  25   1]\n",
      " [  1 119   7  23   4  55   1]\n",
      " [  1   0 134   5   0  70   0]\n",
      " [  5  15   9 114  10  55   2]\n",
      " [ 65  22   2  22  81  13   5]\n",
      " [  3  12   4  41   3 119  28]\n",
      " [  0   5   1   9   1  32 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.69       210\n",
      "           2       0.68      0.57      0.62       210\n",
      "           3       0.84      0.64      0.72       210\n",
      "           4       0.51      0.54      0.53       210\n",
      "           5       0.69      0.39      0.50       210\n",
      "           6       0.32      0.57      0.41       210\n",
      "           7       0.81      0.77      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.65      0.60      0.61      1470\n",
      "weighted avg       0.65      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6142857142857143\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   2   4  22  32   1]\n",
      " [  1 117   7  20   7  57   1]\n",
      " [  0   0 134   3   1  72   0]\n",
      " [  3  15   6 110  13  61   2]\n",
      " [ 52  23   2  20  95  13   5]\n",
      " [  2  15   1  30   2 135  25]\n",
      " [  0   5   0   1   1  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.66      0.56      0.60       210\n",
      "           3       0.88      0.64      0.74       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.67      0.45      0.54       210\n",
      "           6       0.33      0.64      0.44       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.67      0.61      0.63      1470\n",
      "weighted avg       0.67      0.61      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   2   1   4  19  34   2]\n",
      " [  1 116  19  20  10  43   1]\n",
      " [  0   0 148   3   0  59   0]\n",
      " [  4  12  10 117  15  50   2]\n",
      " [ 61  26   4  20  81  13   5]\n",
      " [  3  11   2  29   3 135  27]\n",
      " [  0   5   0   1   1  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69       210\n",
      "           2       0.67      0.55      0.61       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.36      0.64      0.46       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   1   1  11  18  28   2]\n",
      " [  1 117  21  24   8  38   1]\n",
      " [  0   0 153   7   0  50   0]\n",
      " [  3  12  11 129  13  41   1]\n",
      " [ 56  27   5  21  89   7   5]\n",
      " [  3  11   2  40   3 126  25]\n",
      " [  0   4   0   8   2  35 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.54      0.61      0.57       210\n",
      "           5       0.67      0.42      0.52       210\n",
      "           6       0.39      0.60      0.47       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest is: 0.6326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  17  35   1]\n",
      " [  1 123  17  20   7  41   1]\n",
      " [  0   1 147   6   0  56   0]\n",
      " [  3  13  10 122  13  48   1]\n",
      " [ 58  23   4  19  89  12   5]\n",
      " [  3  11   2  27   4 138  25]\n",
      " [  0   5   0   0   1  43 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.59      0.63       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.37      0.66      0.47       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   3   2   4  17  33   1]\n",
      " [  1 126  21  19   3  39   1]\n",
      " [  0   1 152   3   0  54   0]\n",
      " [  3  12  11 119  13  50   2]\n",
      " [ 48  25   6  18  97  11   5]\n",
      " [  3  13   3  28   1 136  26]\n",
      " [  0   4   0   0   2  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.71      0.72       210\n",
      "           2       0.68      0.60      0.64       210\n",
      "           3       0.78      0.72      0.75       210\n",
      "           4       0.62      0.57      0.59       210\n",
      "           5       0.73      0.46      0.57       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   3   2   3  17  33   1]\n",
      " [  1 134  11  19   5  39   1]\n",
      " [  0   9 144   2   0  55   0]\n",
      " [  4  14  10 119  11  50   2]\n",
      " [ 47  29   3  18  98  10   5]\n",
      " [  3  13   1  22   3 145  23]\n",
      " [  0   5   0   1   1  37 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.65      0.64      0.64       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.73      0.47      0.57       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.66      1470\n",
      "weighted avg       0.69      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   2   3  21  29   0]\n",
      " [  1 134  12  17   5  40   1]\n",
      " [  0   9 144   5   0  52   0]\n",
      " [  4  12  11 118  11  52   2]\n",
      " [ 58  26   2  17  92  10   5]\n",
      " [  4  13   1  25   2 142  23]\n",
      " [  0   5   0   0   1  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.71       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.84      0.69      0.75       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.39      0.68      0.49       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   4  23  25   0]\n",
      " [  1 133  11  19   3  42   1]\n",
      " [  0   9 144   4   0  53   0]\n",
      " [  3  15   9 119  11  51   2]\n",
      " [ 46  26   2  19 103   9   5]\n",
      " [  4  10   1  22   2 149  22]\n",
      " [  0   5   0   0   1  36 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       210\n",
      "           2       0.67      0.63      0.65       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.64      0.57      0.60       210\n",
      "           5       0.72      0.49      0.58       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.85      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   2  22  26   0]\n",
      " [  1 136  10  18   2  42   1]\n",
      " [  0   9 144   3   0  54   0]\n",
      " [  3  16   9 121  12  47   2]\n",
      " [ 41  23   1  17 113  10   5]\n",
      " [  3  10   1  18   3 153  22]\n",
      " [  0   1   0   0   3  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.86      0.69      0.76       210\n",
      "           4       0.68      0.58      0.62       210\n",
      "           5       0.73      0.54      0.62       210\n",
      "           6       0.42      0.73      0.53       210\n",
      "           7       0.85      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   2   4  19  25   1]\n",
      " [  1 140  11  18   3  36   1]\n",
      " [  0   8 145   2   0  55   0]\n",
      " [  3  16  10 121  10  47   3]\n",
      " [ 51  26   1  17 100  10   5]\n",
      " [  3  10   2  17   3 150  25]\n",
      " [  0   5   0   1   2  29 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.68      0.67      0.67       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.73      0.48      0.58       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   3  22  27   0]\n",
      " [  1 137  13  17   4  37   1]\n",
      " [  0  10 146   5   0  49   0]\n",
      " [  4  14  10 123   9  48   2]\n",
      " [ 53  25   1  19  98   9   5]\n",
      " [  3  10   1  17   2 154  23]\n",
      " [  0   1   0   1   2  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.85      0.70      0.76       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.72      0.47      0.56       210\n",
      "           6       0.43      0.73      0.54       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   1   3  21  26   0]\n",
      " [  1 138  11  17   4  38   1]\n",
      " [  0  12 145   2   0  51   0]\n",
      " [  2  16  10 120  13  47   2]\n",
      " [ 47  24   1  20 102  11   5]\n",
      " [  3  13   2  14   3 150  25]\n",
      " [  0   2   0   0   2  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.67      0.66      0.66       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.70      0.49      0.57       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.84      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   1   2   1  19  24   0]\n",
      " [  1 140  10  17   5  36   1]\n",
      " [  0   9 148   1   0  52   0]\n",
      " [  3  13  11 117  14  50   2]\n",
      " [ 48  23   1  18 107   8   5]\n",
      " [  3  11   1  18   2 153  22]\n",
      " [  0   3   0   1   1  39 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.78      0.76       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.72      0.51      0.60       210\n",
      "           6       0.42      0.73      0.53       210\n",
      "           7       0.85      0.79      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   3  24  24   0]\n",
      " [  1 141  12  16   3  36   1]\n",
      " [  0  12 145   3   0  50   0]\n",
      " [  2  14   9 117  14  52   2]\n",
      " [ 41  22   2  20 111   9   5]\n",
      " [  2  12   1  18   3 149  25]\n",
      " [  0   4   0   2   1  35 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.76       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   5  23  24   0]\n",
      " [  1 140  11  17   5  35   1]\n",
      " [  0  12 146   5   0  47   0]\n",
      " [  3  13  11 120  12  49   2]\n",
      " [ 42  24   1  19 112   7   5]\n",
      " [  3  11   1  24   3 143  25]\n",
      " [  0   4   0   1   2  34 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.68      0.67      0.67       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   2   3  25  22   1]\n",
      " [  1 138  12  15   7  36   1]\n",
      " [  0  11 146   5   0  48   0]\n",
      " [  3  13  11 119  13  49   2]\n",
      " [ 47  22   1  20 105   9   6]\n",
      " [  3  11   2  20   3 149  22]\n",
      " [  0   1   0   0   3  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.67      0.50      0.57       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   2   4  24  26   0]\n",
      " [  1 144  10  16   3  35   1]\n",
      " [  0  13 145   4   0  48   0]\n",
      " [  2  14   9 124  13  46   2]\n",
      " [ 44  21   1  21 112   6   5]\n",
      " [  3  12   1  19   2 148  25]\n",
      " [  0   1   0   4   2  33 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.70      0.69      0.69       210\n",
      "           3       0.86      0.69      0.77       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.43      0.70      0.54       210\n",
      "           7       0.84      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   5  23  23   0]\n",
      " [  1 143  10  17   3  35   1]\n",
      " [  0  12 148   4   0  46   0]\n",
      " [  3  13  10 125  12  44   3]\n",
      " [ 36  22   1  20 117   9   5]\n",
      " [  3  10   2  22   2 147  24]\n",
      " [  0   0   0   1   2  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.71      0.68      0.70       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.74      0.56      0.63       210\n",
      "           6       0.43      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.6850340136054421\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[176   3   0   5  21   5   0]\n",
      " [  9 151  14  15  17   4   0]\n",
      " [  5  13 171  18   3   0   0]\n",
      " [ 16   9  16 137  23   8   1]\n",
      " [ 21  22   6  30 117   9   5]\n",
      " [ 35  23   7  32   2  78  33]\n",
      " [  4   1   1   0   1  26 177]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.84      0.74       210\n",
      "           2       0.68      0.72      0.70       210\n",
      "           3       0.80      0.81      0.80       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.64      0.56      0.59       210\n",
      "           6       0.60      0.37      0.46       210\n",
      "           7       0.82      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "tfidf_500_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tfidf_500_vectors.csv\",encoding_errors='ignore')\n",
    "# Splitting the data\n",
    "x_train,x_test,y_train,y_test = train_test_split(tfidf_500_df,labels_df['Labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['Labels'])\n",
    "\n",
    "#Modelling\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression()\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af5083",
   "metadata": {},
   "source": [
    "### Data split for Count vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3271f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.726530612244898\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[165   1   0   4  22  18   0]\n",
      " [  1 144  17  18   8  22   0]\n",
      " [  0   5 185  14   0   6   0]\n",
      " [  2  11  23 135  15  23   1]\n",
      " [ 28  19   6  18 130   5   4]\n",
      " [  2  12   7  25   3 134  27]\n",
      " [  0   1   1   1   1  31 175]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.79      0.81       210\n",
      "           2       0.75      0.69      0.71       210\n",
      "           3       0.77      0.88      0.82       210\n",
      "           4       0.63      0.64      0.64       210\n",
      "           5       0.73      0.62      0.67       210\n",
      "           6       0.56      0.64      0.60       210\n",
      "           7       0.85      0.83      0.84       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.5054421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[165  13  16   2   3  11   0]\n",
      " [ 13 129  42   8   2  16   0]\n",
      " [  0   8 186  11   0   5   0]\n",
      " [ 19  35  65  54   1  36   0]\n",
      " [103  47  18  14  20   6   2]\n",
      " [ 17  30  68   8   1  76  10]\n",
      " [  8  11  23   2   2  51 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.79      0.62       210\n",
      "           2       0.47      0.61      0.53       210\n",
      "           3       0.44      0.89      0.59       210\n",
      "           4       0.55      0.26      0.35       210\n",
      "           5       0.69      0.10      0.17       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.90      0.54      0.67       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.56      0.51      0.47      1470\n",
      "weighted avg       0.56      0.51      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5176870748299319\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161  14  10   1   6  18   0]\n",
      " [ 11 129  38   9   2  21   0]\n",
      " [  0   9 192   6   0   3   0]\n",
      " [ 17  39  50  63   1  40   0]\n",
      " [ 93  44  33  16  15   8   1]\n",
      " [ 21  23  49   9   0  99   9]\n",
      " [ 14  10  14   1   0  69 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.77      0.61       210\n",
      "           2       0.48      0.61      0.54       210\n",
      "           3       0.50      0.91      0.64       210\n",
      "           4       0.60      0.30      0.40       210\n",
      "           5       0.62      0.07      0.13       210\n",
      "           6       0.38      0.47      0.42       210\n",
      "           7       0.91      0.49      0.63       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.57      0.52      0.48      1470\n",
      "weighted avg       0.57      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5231292517006803\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[160  14  13   1   5  17   0]\n",
      " [  7 132  43   8   2  18   0]\n",
      " [  0   9 194   4   0   3   0]\n",
      " [ 11  34  58  57   1  49   0]\n",
      " [ 86  49  31  18  19   5   2]\n",
      " [ 16  17  47  11   0 110   9]\n",
      " [ 10   8  19   2   0  74  97]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.76      0.64       210\n",
      "           2       0.50      0.63      0.56       210\n",
      "           3       0.48      0.92      0.63       210\n",
      "           4       0.56      0.27      0.37       210\n",
      "           5       0.70      0.09      0.16       210\n",
      "           6       0.40      0.52      0.45       210\n",
      "           7       0.90      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.59      0.52      0.49      1470\n",
      "weighted avg       0.59      0.52      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.5190476190476191\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158  13  13   1   6  19   0]\n",
      " [  7 128  44   7   1  23   0]\n",
      " [  1   9 192   3   0   5   0]\n",
      " [  7  34  54  66   1  48   0]\n",
      " [ 89  47  35  16  15   6   2]\n",
      " [ 11  22  49   8   0 110  10]\n",
      " [ 10   6  17   2   0  81  94]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.75      0.64       210\n",
      "           2       0.49      0.61      0.55       210\n",
      "           3       0.48      0.91      0.63       210\n",
      "           4       0.64      0.31      0.42       210\n",
      "           5       0.65      0.07      0.13       210\n",
      "           6       0.38      0.52      0.44       210\n",
      "           7       0.89      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.58      0.52      0.49      1470\n",
      "weighted avg       0.58      0.52      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.5142857142857142\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156  11  14   2   5  22   0]\n",
      " [  4 126  45   9   1  25   0]\n",
      " [  1   9 191   1   0   8   0]\n",
      " [  6  31  59  59   2  53   0]\n",
      " [ 91  46  32  12  16  10   3]\n",
      " [ 11  21  47   5   0 117   9]\n",
      " [  9   6  16   2   0  86  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.74      0.64       210\n",
      "           2       0.50      0.60      0.55       210\n",
      "           3       0.47      0.91      0.62       210\n",
      "           4       0.66      0.28      0.39       210\n",
      "           5       0.67      0.08      0.14       210\n",
      "           6       0.36      0.56      0.44       210\n",
      "           7       0.88      0.43      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.59      0.51      0.48      1470\n",
      "weighted avg       0.59      0.51      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.5061224489795918\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156  10  14   2   5  23   0]\n",
      " [  2 114  54   7   1  32   0]\n",
      " [  0   9 191   2   0   8   0]\n",
      " [  5  33  57  60   2  53   0]\n",
      " [ 90  41  37  12  15  13   2]\n",
      " [  8  24  41   7   0 121   9]\n",
      " [  8   5  19   1   0  90  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.74      0.65       210\n",
      "           2       0.48      0.54      0.51       210\n",
      "           3       0.46      0.91      0.61       210\n",
      "           4       0.66      0.29      0.40       210\n",
      "           5       0.65      0.07      0.13       210\n",
      "           6       0.36      0.58      0.44       210\n",
      "           7       0.89      0.41      0.56       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.58      0.51      0.47      1470\n",
      "weighted avg       0.58      0.51      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.47006802721088436\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 60   4  13 119   8   6   0]\n",
      " [ 14 130  52  11   2   0   1]\n",
      " [  2   8 196   3   1   0   0]\n",
      " [  9  40  59  81  16   4   1]\n",
      " [ 55  22   4  90  27   8   4]\n",
      " [ 22  32  66  23   4  18  45]\n",
      " [  6   3   7   4   3   8 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.29      0.32       210\n",
      "           2       0.54      0.62      0.58       210\n",
      "           3       0.49      0.93      0.65       210\n",
      "           4       0.24      0.39      0.30       210\n",
      "           5       0.44      0.13      0.20       210\n",
      "           6       0.41      0.09      0.14       210\n",
      "           7       0.78      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.43      1470\n",
      "weighted avg       0.47      0.47      0.43      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes is: 0.691156462585034\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM is: 0.7374149659863946\n",
      "Confusion Matrix of SVM is:\n",
      " [[165   2   0   2  22  19   0]\n",
      " [  1 152  12  17   4  24   0]\n",
      " [  0   3 186  16   0   5   0]\n",
      " [  2  12  19 131  14  30   2]\n",
      " [ 29  19   5  16 134   3   4]\n",
      " [  3  12   7  16   3 143  26]\n",
      " [  0   4   1   1   1  30 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.79      0.80       210\n",
      "           2       0.75      0.72      0.73       210\n",
      "           3       0.81      0.89      0.85       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.75      0.64      0.69       210\n",
      "           6       0.56      0.68      0.62       210\n",
      "           7       0.84      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.4020408163265306\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 74   3  83   2  12  35   1]\n",
      " [  0  65 109   4   2  30   0]\n",
      " [  0   5 203   1   0   1   0]\n",
      " [  3  12  99  37   7  52   0]\n",
      " [ 47  16  60  11  58  17   1]\n",
      " [  2   3 114   2   3  80   6]\n",
      " [  0   2  58   1   0  75  74]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.35      0.44       210\n",
      "           2       0.61      0.31      0.41       210\n",
      "           3       0.28      0.97      0.43       210\n",
      "           4       0.64      0.18      0.28       210\n",
      "           5       0.71      0.28      0.40       210\n",
      "           6       0.28      0.38      0.32       210\n",
      "           7       0.90      0.35      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.57      0.40      0.40      1470\n",
      "weighted avg       0.57      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.7108843537414966\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   2   0   2  33  21   0]\n",
      " [  1 135  19  15  12  28   0]\n",
      " [  0   9 171  15   4  11   0]\n",
      " [  1  11  19 124  21  33   1]\n",
      " [ 21  15   4  18 143   5   4]\n",
      " [  1   6   5  18   9 148  23]\n",
      " [  0   3   0   2   6  27 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.72      0.79       210\n",
      "           2       0.75      0.64      0.69       210\n",
      "           3       0.78      0.81      0.80       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.63      0.68      0.65       210\n",
      "           6       0.54      0.70      0.61       210\n",
      "           7       0.86      0.82      0.84       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.6482993197278911\n",
      "Confusion Matrix of SVM is:\n",
      " [[160   8   0   3  22  17   0]\n",
      " [ 12 120  26  17   5  30   0]\n",
      " [  2  10 163  13   0  22   0]\n",
      " [ 13  30  20 103   9  34   1]\n",
      " [ 42  37   6  18 100   5   2]\n",
      " [  8   9   6  20   1 145  21]\n",
      " [  2   0   3   0   1  42 162]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.76      0.71       210\n",
      "           2       0.56      0.57      0.57       210\n",
      "           3       0.73      0.78      0.75       210\n",
      "           4       0.59      0.49      0.54       210\n",
      "           5       0.72      0.48      0.57       210\n",
      "           6       0.49      0.69      0.57       210\n",
      "           7       0.87      0.77      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.22380952380952382\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0   0   0 201]\n",
      " [  0   0  58   0   0   0 152]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  0   0  21   0   0   0 189]\n",
      " [  0   0  47   0   0   0 163]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   4   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.46      0.59      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.98      0.29       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.09      0.22      0.12      1470\n",
      "weighted avg       0.09      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.2938775510204082\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   2   7   0   0   0 123]\n",
      " [  1  25  33   0   0   0 151]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  3   3  18   0   0   0 186]\n",
      " [ 53  15  32   0   0   0 110]\n",
      " [  1   1   2   0   0   0 206]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.37      0.45       210\n",
      "           2       0.53      0.12      0.19       210\n",
      "           3       0.56      0.59      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.19      0.98      0.32       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.27      0.29      0.22      1470\n",
      "weighted avg       0.27      0.29      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   4   0   8   0  43]\n",
      " [  2  25  33   0   0   0 150]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  5   3  18   0   0   0 184]\n",
      " [ 95  13  23   0  20   0  59]\n",
      " [  3   1   2   0   0   0 204]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.73      0.66       210\n",
      "           2       0.57      0.12      0.20       210\n",
      "           3       0.60      0.59      0.59       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.71      0.10      0.17       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.22      0.98      0.36       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.28      1470\n",
      "weighted avg       0.38      0.36      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree is: 0.4217687074829932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   0  12  43   0]\n",
      " [  1  25  33   0   1 149   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 83   7  14   0  47  57   2]\n",
      " [  3   1   2   0   0 196   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.73      0.68       210\n",
      "           2       0.66      0.12      0.20       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.77      0.22      0.35       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.54      0.42      0.39      1470\n",
      "weighted avg       0.54      0.42      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.44829931972789117\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   1   0   0  18  43   0]\n",
      " [  1  57  26   0   1 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 68  18  14   1  61  46   2]\n",
      " [  2   2   2   0   1 195   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.70      0.68       210\n",
      "           2       0.70      0.27      0.39       210\n",
      "           3       0.66      0.59      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.29      0.42       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.43      1470\n",
      "weighted avg       0.55      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.463265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   1   0   0  13  43   0]\n",
      " [  1  56  25   0   3 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 74  16  14   1  56  47   2]\n",
      " [  3   2   2   0   0 192  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.73      0.69       210\n",
      "           2       0.71      0.27      0.39       210\n",
      "           3       0.67      0.59      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.77      0.27      0.40       210\n",
      "           6       0.25      0.91      0.39       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.56      0.46      0.44      1470\n",
      "weighted avg       0.56      0.46      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree is: 0.49455782312925173\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  25  43   0]\n",
      " [  1  89  22   0   3  94   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17   0   2 180   1]\n",
      " [ 53  16  14   0  82  43   2]\n",
      " [  2   3   2   0   1 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69       210\n",
      "           2       0.77      0.42      0.55       210\n",
      "           3       0.68      0.59      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.39      0.51       210\n",
      "           6       0.26      0.91      0.40       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  21  43   0]\n",
      " [  1  90  20   2   4  92   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17  22   3 158   0]\n",
      " [ 58  14  12   3  81  41   1]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.69      0.69       210\n",
      "           2       0.78      0.43      0.55       210\n",
      "           3       0.69      0.59      0.64       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.74      0.39      0.51       210\n",
      "           6       0.27      0.91      0.41       210\n",
      "           7       0.89      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.70      0.51      0.52      1470\n",
      "weighted avg       0.70      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  21  46   0]\n",
      " [  1  91  19   5   4  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   6  16  38   2 142   1]\n",
      " [ 56  16  11   2  78  44   3]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.68      0.68       210\n",
      "           2       0.77      0.43      0.55       210\n",
      "           3       0.71      0.59      0.64       210\n",
      "           4       0.84      0.18      0.30       210\n",
      "           5       0.74      0.37      0.50       210\n",
      "           6       0.27      0.91      0.42       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.53      1470\n",
      "weighted avg       0.70      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5251700680272109\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  23  45   0]\n",
      " [  4  89  19   3   5  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  6   3  16  47   4 133   1]\n",
      " [ 53  14  11   4  83  42   3]\n",
      " [  4   2   2   2   0 189  11]\n",
      " [  0   1   3   0   1 105 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.67       210\n",
      "           2       0.81      0.42      0.56       210\n",
      "           3       0.71      0.59      0.64       210\n",
      "           4       0.84      0.22      0.35       210\n",
      "           5       0.72      0.40      0.51       210\n",
      "           6       0.27      0.90      0.42       210\n",
      "           7       0.86      0.48      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  22  45   0]\n",
      " [  3  88  30   4   6  78   1]\n",
      " [  0   0 141   0   0  69   0]\n",
      " [  7   3  25  47   3 124   1]\n",
      " [ 54  16  12   5  80  40   3]\n",
      " [  4   2   6   2   0 185  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.68      0.68       210\n",
      "           2       0.79      0.42      0.55       210\n",
      "           3       0.64      0.67      0.66       210\n",
      "           4       0.81      0.22      0.35       210\n",
      "           5       0.72      0.38      0.50       210\n",
      "           6       0.29      0.88      0.43       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.68      0.53      0.54      1470\n",
      "weighted avg       0.68      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5428571428571428\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  25  43   0]\n",
      " [  3  95  26   2   6  78   0]\n",
      " [  0   0 148   0   0  62   0]\n",
      " [  7   3  25  45   6 124   0]\n",
      " [ 53  17  12   5  86  35   2]\n",
      " [  3   2   9   3   0 182  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.68       210\n",
      "           2       0.80      0.45      0.58       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.82      0.21      0.34       210\n",
      "           5       0.70      0.41      0.52       210\n",
      "           6       0.29      0.87      0.43       210\n",
      "           7       0.89      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5482993197278911\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0   0  23  37   0]\n",
      " [  3  96  26   2   4  79   0]\n",
      " [  0   0 147   0   1  62   0]\n",
      " [  6   3  24  46   6 124   1]\n",
      " [ 53  17  11   6  85  36   2]\n",
      " [  3   2   9   3   0 183  10]\n",
      " [  0   1   4   1   0 104 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.70       210\n",
      "           2       0.80      0.46      0.58       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.79      0.22      0.34       210\n",
      "           5       0.71      0.40      0.52       210\n",
      "           6       0.29      0.87      0.44       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.55      1470\n",
      "weighted avg       0.69      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  27  37   0]\n",
      " [  2  95  26   2   5  80   0]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  6   3  23  46   6 125   1]\n",
      " [ 47  17  11   7  90  35   3]\n",
      " [  3   2   9   3   0 180  13]\n",
      " [  0   1   4   1   1  98 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70       210\n",
      "           2       0.80      0.45      0.58       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.78      0.22      0.34       210\n",
      "           5       0.69      0.43      0.53       210\n",
      "           6       0.29      0.86      0.44       210\n",
      "           7       0.86      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree is: 0.5523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   1   0   0  20  34   0]\n",
      " [  3  98  24   1   4  79   1]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  5   4  23  45   8 124   1]\n",
      " [ 60  16  11   7  82  30   4]\n",
      " [  2   2   9   2   2 181  12]\n",
      " [  0   1   5   0   0  99 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.71       210\n",
      "           2       0.80      0.47      0.59       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.82      0.21      0.34       210\n",
      "           5       0.69      0.39      0.50       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  23  35   0]\n",
      " [  3 103  24   1   5  73   1]\n",
      " [  0   0 145   1   2  62   0]\n",
      " [  7   3  22  47   6 124   1]\n",
      " [ 60  20  10   5  83  27   5]\n",
      " [  2   2   9   2   2 180  13]\n",
      " [  0   1   4   1   0 100 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.79      0.49      0.61       210\n",
      "           3       0.68      0.69      0.68       210\n",
      "           4       0.82      0.22      0.35       210\n",
      "           5       0.69      0.40      0.50       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.84      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.5680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  24  34   0]\n",
      " [  6 103  25   1   6  68   1]\n",
      " [  0   0 155   1   2  52   0]\n",
      " [  5   3  25  47   7 122   1]\n",
      " [ 52  19  11   6  92  27   3]\n",
      " [  3   0   8   3   1 182  13]\n",
      " [  0   1   4   1   0  99 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.81      0.49      0.61       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.80      0.22      0.35       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.31      0.87      0.46       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.69      0.57      0.57      1470\n",
      "weighted avg       0.69      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0   1  25  33   0]\n",
      " [  3 103  25  14   7  58   0]\n",
      " [  0   0 155   3   2  50   0]\n",
      " [  6   3  25  58   7 110   1]\n",
      " [ 57  19  11  11  88  21   3]\n",
      " [  2   2   8  11   2 173  12]\n",
      " [  0   2   4   2   1  97 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.79      0.49      0.61       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.58      0.28      0.37       210\n",
      "           5       0.67      0.42      0.51       210\n",
      "           6       0.32      0.82      0.46       210\n",
      "           7       0.87      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.66      0.57      0.57      1470\n",
      "weighted avg       0.66      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   1  22  32   0]\n",
      " [  3 105  25  11   5  60   1]\n",
      " [  0   0 154   3   2  51   0]\n",
      " [  4   4  23  56  10 112   1]\n",
      " [ 52  21  11  10  91  20   5]\n",
      " [  2   3   7  11   1 173  13]\n",
      " [  0   2   4   2   0  97 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.72       210\n",
      "           2       0.77      0.50      0.61       210\n",
      "           3       0.69      0.73      0.71       210\n",
      "           4       0.60      0.27      0.37       210\n",
      "           5       0.69      0.43      0.53       210\n",
      "           6       0.32      0.82      0.46       210\n",
      "           7       0.84      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.66      0.57      0.58      1470\n",
      "weighted avg       0.66      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   1   0   1  23  33   0]\n",
      " [  3 105  24  11   6  60   1]\n",
      " [  0   2 152   3   2  51   0]\n",
      " [  7   6  23  57   5 111   1]\n",
      " [ 56  20  11  10  87  23   3]\n",
      " [  2   1   5  13   3 168  18]\n",
      " [  0   2   3   3   0  91 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.71       210\n",
      "           2       0.77      0.50      0.61       210\n",
      "           3       0.70      0.72      0.71       210\n",
      "           4       0.58      0.27      0.37       210\n",
      "           5       0.69      0.41      0.52       210\n",
      "           6       0.31      0.80      0.45       210\n",
      "           7       0.83      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.65      0.57      0.57      1470\n",
      "weighted avg       0.65      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.5571428571428572\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   6   4  17  20   4]\n",
      " [  1  71  57  28  10  38   5]\n",
      " [  0   0 123  22   0  61   4]\n",
      " [  3   6  21 109  11  41  19]\n",
      " [ 67  14  34  16  64   7   8]\n",
      " [  3   8   3  35   2 114  45]\n",
      " [  0   2   3   1   1  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.70      0.34      0.46       210\n",
      "           3       0.50      0.59      0.54       210\n",
      "           4       0.51      0.52      0.51       210\n",
      "           5       0.61      0.30      0.41       210\n",
      "           6       0.38      0.54      0.44       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   3   4  22  22   4]\n",
      " [  1 109  36  19   4  37   4]\n",
      " [  0   0 145   5   0  54   6]\n",
      " [  4   9  20 113  11  38  15]\n",
      " [ 60  22  20  14  78   7   9]\n",
      " [  3   9   5  31   3 116  43]\n",
      " [  0   4   3   0   1  25 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71       210\n",
      "           2       0.70      0.52      0.60       210\n",
      "           3       0.62      0.69      0.66       210\n",
      "           4       0.61      0.54      0.57       210\n",
      "           5       0.66      0.37      0.47       210\n",
      "           6       0.39      0.55      0.46       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest is: 0.6122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   3   6  24  19   1]\n",
      " [  1 103  36  25   4  40   1]\n",
      " [  0   0 146   8   0  56   0]\n",
      " [  4  10  19 127  11  35   4]\n",
      " [ 58  22  19  16  83   5   7]\n",
      " [  3  10   6  44   2 119  26]\n",
      " [  0   5   3   9   0  27 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.68      0.49      0.57       210\n",
      "           3       0.63      0.70      0.66       210\n",
      "           4       0.54      0.60      0.57       210\n",
      "           5       0.67      0.40      0.50       210\n",
      "           6       0.40      0.57      0.47       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest is: 0.617687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   1   6  21  21   1]\n",
      " [  1 105  35  25   3  40   1]\n",
      " [  0   0 146   5   0  59   0]\n",
      " [  4  12  17 124  10  41   2]\n",
      " [ 58  23  13  17  87   5   7]\n",
      " [  3  10   6  43   2 120  26]\n",
      " [  0   5   2   6   0  29 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.50      0.57       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.55      0.59      0.57       210\n",
      "           5       0.71      0.41      0.52       210\n",
      "           6       0.38      0.57      0.46       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   2   4  20  24   1]\n",
      " [  1 108  38  22   4  36   1]\n",
      " [  0   0 156   5   0  49   0]\n",
      " [  4  10  20 112  13  48   3]\n",
      " [ 69  23  19  16  69   8   6]\n",
      " [  3   9   6  31   1 133  27]\n",
      " [  0   3   3   0   1  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.75      0.71       210\n",
      "           2       0.70      0.51      0.59       210\n",
      "           3       0.64      0.74      0.69       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.64      0.33      0.43       210\n",
      "           6       0.39      0.63      0.49       210\n",
      "           7       0.81      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   4  23  23   1]\n",
      " [  1 110  37  23   3  35   1]\n",
      " [  0   0 156   4   0  50   0]\n",
      " [  3  17  21 114   6  47   2]\n",
      " [ 47  27  11  19  93   8   5]\n",
      " [  3  11   6  31   0 134  25]\n",
      " [  0   4   2   1   1  40 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.64      0.52      0.58       210\n",
      "           3       0.67      0.74      0.70       210\n",
      "           4       0.58      0.54      0.56       210\n",
      "           5       0.74      0.44      0.55       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.6197278911564625\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   4   3  19  26   1]\n",
      " [  1 111  36  23   2  36   1]\n",
      " [  0   0 156   4   0  50   0]\n",
      " [  3  15  20 112   9  49   2]\n",
      " [ 56  27  18  16  78   9   6]\n",
      " [  3  11   4  31   0 136  25]\n",
      " [  0   4   2   1   1  40 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.65      0.74      0.69       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.72      0.37      0.49       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.82      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   0   3  20  27   1]\n",
      " [  1 111  36  24   1  36   1]\n",
      " [  0   0 156  14   0  40   0]\n",
      " [  4  17  18 119   3  46   3]\n",
      " [ 58  25  10  21  85   6   5]\n",
      " [  3   9   6  30   0 138  24]\n",
      " [  0   4   2   1   0  40 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.56      0.57      0.56       210\n",
      "           5       0.78      0.40      0.53       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0   4  21  24   1]\n",
      " [  1 111  36  21   2  38   1]\n",
      " [  0   0 157  15   0  38   0]\n",
      " [  3  15  20 117   7  46   2]\n",
      " [ 55  27  11  18  88   7   4]\n",
      " [  3   9   6  30   0 135  27]\n",
      " [  0   4   2   0   1  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.68      0.75      0.71       210\n",
      "           4       0.57      0.56      0.56       210\n",
      "           5       0.74      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.82      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6387755102040816\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0   4  19  24   1]\n",
      " [  1 110  38  23   3  34   1]\n",
      " [  0   0 161  15   0  34   0]\n",
      " [  3  14  21 118   7  45   2]\n",
      " [ 52  26  11  18  93   6   4]\n",
      " [  3   8   7  31   0 134  27]\n",
      " [  0   4   2   0   0  41 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       210\n",
      "           2       0.67      0.52      0.59       210\n",
      "           3       0.67      0.77      0.72       210\n",
      "           4       0.56      0.56      0.56       210\n",
      "           5       0.76      0.44      0.56       210\n",
      "           6       0.42      0.64      0.51       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest is: 0.6360544217687075\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   0   4  22  25   1]\n",
      " [  1 117  30  17   5  39   1]\n",
      " [  0   0 158  13   0  39   0]\n",
      " [  3  14  21 117   8  45   2]\n",
      " [ 56  25   9  21  89   6   4]\n",
      " [  3  12   7  28   0 133  27]\n",
      " [  0   3   2   0   1  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.70      0.75      0.72       210\n",
      "           4       0.58      0.56      0.57       210\n",
      "           5       0.71      0.42      0.53       210\n",
      "           6       0.41      0.63      0.50       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0   4  22  23   1]\n",
      " [  1 112  36  23   3  34   1]\n",
      " [  0   0 162  13   0  35   0]\n",
      " [  3  13  20 116  11  45   2]\n",
      " [ 55  26   9  19  90   6   5]\n",
      " [  3   9   7  29   1 136  25]\n",
      " [  0   4   2   0   0  41 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.67      0.53      0.60       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.57      0.55      0.56       210\n",
      "           5       0.71      0.43      0.53       210\n",
      "           6       0.42      0.65      0.51       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   3  22  25   1]\n",
      " [  1 117  31  23   3  34   1]\n",
      " [  0   1 162  12   0  35   0]\n",
      " [  3  14  20 119   6  46   2]\n",
      " [ 47  28  10  16  97   8   4]\n",
      " [  3   8   7  31   0 135  26]\n",
      " [  0   3   2   0   0  40 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.70      0.77      0.73       210\n",
      "           4       0.58      0.57      0.57       210\n",
      "           5       0.76      0.46      0.57       210\n",
      "           6       0.42      0.64      0.51       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   0   4  22  24   1]\n",
      " [  1 117  34  19   2  36   1]\n",
      " [  0   0 162  15   0  33   0]\n",
      " [  4  14  21 120   5  44   2]\n",
      " [ 52  28  10  17  92   7   4]\n",
      " [  3   9   7  28   0 138  25]\n",
      " [  0   4   2   1   0  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.74       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.76      0.44      0.56       210\n",
      "           6       0.43      0.66      0.52       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   4  22  25   1]\n",
      " [  1 114  35  20   2  37   1]\n",
      " [  0   1 165  12   0  32   0]\n",
      " [  3  15  21 121   5  43   2]\n",
      " [ 44  28  10  17 100   7   4]\n",
      " [  3  10   8  28   0 136  25]\n",
      " [  0   4   2   1   0  41 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.66      0.54      0.59       210\n",
      "           3       0.68      0.79      0.73       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.78      0.48      0.59       210\n",
      "           6       0.42      0.65      0.51       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   4  23  24   1]\n",
      " [  1 117  32  22   2  35   1]\n",
      " [  0   2 166  10   0  32   0]\n",
      " [  3  14  23 118   8  42   2]\n",
      " [ 51  25  10  18  95   7   4]\n",
      " [  3  11   8  27   0 134  27]\n",
      " [  0   4   2   1   0  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.67      0.56      0.61       210\n",
      "           3       0.69      0.79      0.73       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.74      0.45      0.56       210\n",
      "           6       0.43      0.64      0.51       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   1   3  20  26   1]\n",
      " [  1 121  27  20   3  37   1]\n",
      " [  0   0 167  12   0  31   0]\n",
      " [  4  16  19 121   7  41   2]\n",
      " [ 48  26   9  18  98   8   3]\n",
      " [  3   9   9  27   0 137  25]\n",
      " [  0   5   2   1   0  39 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.68      0.58      0.62       210\n",
      "           3       0.71      0.80      0.75       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.77      0.47      0.58       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.84      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.6517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  22  25   0]\n",
      " [  1 123  29  19   3  34   1]\n",
      " [  0   0 170   9   0  31   0]\n",
      " [  3  17  20 123   5  40   2]\n",
      " [ 56  28  10  16  87   9   4]\n",
      " [  3  10  10  27   0 134  26]\n",
      " [  0   5   2   0   0  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.59      0.62       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.74      0.41      0.53       210\n",
      "           6       0.43      0.64      0.51       210\n",
      "           7       0.83      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  22  25   0]\n",
      " [  1 121  28  21   3  35   1]\n",
      " [  0   1 164  14   0  31   0]\n",
      " [  3  17  19 125   5  39   2]\n",
      " [ 46  27   9  17  98   7   6]\n",
      " [  3   8   9  28   0 137  25]\n",
      " [  0   5   2   1   0  39 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.67      0.58      0.62       210\n",
      "           3       0.71      0.78      0.74       210\n",
      "           4       0.60      0.60      0.60       210\n",
      "           5       0.77      0.47      0.58       210\n",
      "           6       0.44      0.65      0.52       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  22  25   0]\n",
      " [  1 122  29  20   3  34   1]\n",
      " [  0   2 168  10   0  30   0]\n",
      " [  3  15  21 122   7  40   2]\n",
      " [ 54  27  10  16  91   8   4]\n",
      " [  3   9   9  28   0 137  24]\n",
      " [  0   4   2   0   0  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.68      0.58      0.63       210\n",
      "           3       0.70      0.80      0.75       210\n",
      "           4       0.61      0.58      0.60       210\n",
      "           5       0.74      0.43      0.55       210\n",
      "           6       0.44      0.65      0.52       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.6877551020408164\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[177   3   2   5  19   4   0]\n",
      " [  9 138  21  17  17   7   1]\n",
      " [  5  10 177  17   1   0   0]\n",
      " [ 16  11  21 130  23   8   1]\n",
      " [ 24  19   7  23 127   7   3]\n",
      " [ 37  18  11  33   2  75  34]\n",
      " [  3   1   3   0   1  15 187]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.84      0.74       210\n",
      "           2       0.69      0.66      0.67       210\n",
      "           3       0.73      0.84      0.78       210\n",
      "           4       0.58      0.62      0.60       210\n",
      "           5       0.67      0.60      0.64       210\n",
      "           6       0.65      0.36      0.46       210\n",
      "           7       0.83      0.89      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "cv_500_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//cv_500_vectors.csv\",encoding_errors='ignore')\n",
    "cv_500_df\n",
    "\n",
    "# Train Test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(cv_500_df,labels_df['Labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['Labels'])\n",
    "\n",
    "# Modelling\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2687f07",
   "metadata": {},
   "source": [
    "### Data split for Term frequency vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4afe912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.7163265306122449\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[169   1   0   5  16  17   2]\n",
      " [  1 141  22  19   4  22   1]\n",
      " [  0   7 178  17   0   8   0]\n",
      " [  2  14  20 140   9  19   6]\n",
      " [ 29  21   6  23 122   4   5]\n",
      " [  2  12   6  33   1 123  33]\n",
      " [  0   1   2   0   1  26 180]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.80      0.82       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.76      0.85      0.80       210\n",
      "           4       0.59      0.67      0.63       210\n",
      "           5       0.80      0.58      0.67       210\n",
      "           6       0.56      0.59      0.57       210\n",
      "           7       0.79      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.5142857142857142\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158  10  16   2  12  12   0]\n",
      " [ 17 135  40   8   6   4   0]\n",
      " [  4  13 176  13   1   3   0]\n",
      " [ 31  30  62  65   3  19   0]\n",
      " [ 71  38  45   9  41   5   1]\n",
      " [ 23  27  75  13   2  59  11]\n",
      " [ 10   6  45   4   2  21 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60       210\n",
      "           2       0.52      0.64      0.58       210\n",
      "           3       0.38      0.84      0.53       210\n",
      "           4       0.57      0.31      0.40       210\n",
      "           5       0.61      0.20      0.30       210\n",
      "           6       0.48      0.28      0.35       210\n",
      "           7       0.91      0.58      0.71       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.57      0.51      0.50      1470\n",
      "weighted avg       0.57      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152  12   6   2   7  30   1]\n",
      " [ 13 134  32  12   5  14   0]\n",
      " [  2  11 176  16   0   5   0]\n",
      " [ 23  30  40  75   5  36   1]\n",
      " [ 74  44  28  11  30  23   0]\n",
      " [ 19  31  16  15   3 114  12]\n",
      " [  8  16   5   7   1  60 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.72      0.61       210\n",
      "           2       0.48      0.64      0.55       210\n",
      "           3       0.58      0.84      0.69       210\n",
      "           4       0.54      0.36      0.43       210\n",
      "           5       0.59      0.14      0.23       210\n",
      "           6       0.40      0.54      0.46       210\n",
      "           7       0.89      0.54      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.52      1470\n",
      "weighted avg       0.57      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150  11  10   3   8  27   1]\n",
      " [  9 132  34  11   4  20   0]\n",
      " [  1  13 179  11   0   6   0]\n",
      " [ 15  24  43  83   6  39   0]\n",
      " [ 62  48  29  12  38  20   1]\n",
      " [ 18  25  19  19   3 118   8]\n",
      " [  5  13  10   7   0  65 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.71      0.64       210\n",
      "           2       0.50      0.63      0.55       210\n",
      "           3       0.55      0.85      0.67       210\n",
      "           4       0.57      0.40      0.47       210\n",
      "           5       0.64      0.18      0.28       210\n",
      "           6       0.40      0.56      0.47       210\n",
      "           7       0.92      0.52      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.54      1470\n",
      "weighted avg       0.59      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.5435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148  11   9   3   8  30   1]\n",
      " [  8 132  33  11   3  23   0]\n",
      " [  1  14 182   8   0   5   0]\n",
      " [  8  32  46  76   6  41   1]\n",
      " [ 64  48  28  11  35  23   1]\n",
      " [ 14  23  17  23   2 119  12]\n",
      " [  6  12  13   6   1  65 107]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.70      0.64       210\n",
      "           2       0.49      0.63      0.55       210\n",
      "           3       0.55      0.87      0.68       210\n",
      "           4       0.55      0.36      0.44       210\n",
      "           5       0.64      0.17      0.26       210\n",
      "           6       0.39      0.57      0.46       210\n",
      "           7       0.88      0.51      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.58      0.54      0.53      1470\n",
      "weighted avg       0.58      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.5469387755102041\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   9   8   3   8  33   0]\n",
      " [  8 131  35  12   2  22   0]\n",
      " [  1  15 180   6   0   8   0]\n",
      " [  8  30  43  79   3  47   0]\n",
      " [ 62  43  26  12  34  32   1]\n",
      " [  6  27  17  22   2 125  11]\n",
      " [  5  13  10   5   0  71 106]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.71      0.66       210\n",
      "           2       0.49      0.62      0.55       210\n",
      "           3       0.56      0.86      0.68       210\n",
      "           4       0.57      0.38      0.45       210\n",
      "           5       0.69      0.16      0.26       210\n",
      "           6       0.37      0.60      0.46       210\n",
      "           7       0.90      0.50      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.5346938775510204\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148  14   6   5   7  30   0]\n",
      " [ 10 130  36  10   1  23   0]\n",
      " [  1  16 174  14   0   5   0]\n",
      " [  7  33  35  85   2  48   0]\n",
      " [ 60  43  28   8  33  37   1]\n",
      " [  4  47  15  20   1 114   9]\n",
      " [  4  14  11   5   0  74 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.70      0.67       210\n",
      "           2       0.44      0.62      0.51       210\n",
      "           3       0.57      0.83      0.68       210\n",
      "           4       0.58      0.40      0.48       210\n",
      "           5       0.75      0.16      0.26       210\n",
      "           6       0.34      0.54      0.42       210\n",
      "           7       0.91      0.49      0.63       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.60      0.53      0.52      1470\n",
      "weighted avg       0.60      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.49863945578231295\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   3  13  80   8   6   0]\n",
      " [ 15 129  53   8   3   1   1]\n",
      " [  1   9 195   3   1   0   1]\n",
      " [  9  37  58  82  17   6   1]\n",
      " [ 61  21   4  84  24  12   4]\n",
      " [ 15  35  62  21   4  24  49]\n",
      " [  4   4   3   4   3  13 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.48      0.48       210\n",
      "           2       0.54      0.61      0.58       210\n",
      "           3       0.50      0.93      0.65       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.40      0.11      0.18       210\n",
      "           6       0.39      0.11      0.18       210\n",
      "           7       0.76      0.85      0.80       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.48      0.50      0.46      1470\n",
      "weighted avg       0.48      0.50      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes is: 0.691156462585034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM is: 0.7217687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   0   0   4  23  22   0]\n",
      " [  1 143  17  22   2  24   1]\n",
      " [  0   8 178  17   0   7   0]\n",
      " [  1  16  20 137   7  28   1]\n",
      " [ 21  20   9  20 130   5   5]\n",
      " [  2  10   6  25   1 137  29]\n",
      " [  0   1   1   0   1  32 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.77      0.81       210\n",
      "           2       0.72      0.68      0.70       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.79      0.62      0.70       210\n",
      "           6       0.54      0.65      0.59       210\n",
      "           7       0.83      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.680952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[141   4   0   4  29  31   1]\n",
      " [  1 142  10  17   7  33   0]\n",
      " [  0   9 162  20   2  17   0]\n",
      " [  1  15  10 126  11  47   0]\n",
      " [ 17  16   3  23 115  32   4]\n",
      " [  3   9   1  23   1 156  17]\n",
      " [  1   0   0   0   2  48 159]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.73      0.68      0.70       210\n",
      "           3       0.87      0.77      0.82       210\n",
      "           4       0.59      0.60      0.60       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.43      0.74      0.54       210\n",
      "           7       0.88      0.76      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.7183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   3   0   4  26  23   1]\n",
      " [  1 157  10  20   1  21   0]\n",
      " [  0  10 170  21   1   8   0]\n",
      " [  1  18  14 138   8  30   1]\n",
      " [ 21  25   3  23 124   8   6]\n",
      " [  2  11   1  31   1 135  29]\n",
      " [  0   0   0   2   1  28 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.73      0.79       210\n",
      "           2       0.70      0.75      0.72       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.58      0.66      0.61       210\n",
      "           5       0.77      0.59      0.67       210\n",
      "           6       0.53      0.64      0.58       210\n",
      "           7       0.83      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.6258503401360545\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   0   0   8  50  16   2]\n",
      " [  0 109  33  28  20  20   0]\n",
      " [  0   7 160  35   1   7   0]\n",
      " [  2  20  24 131   6  21   6]\n",
      " [ 54  24  16  17  89   6   4]\n",
      " [  3  11   6  33   0 125  32]\n",
      " [  0   1   3   1   1  32 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.64      0.67       210\n",
      "           2       0.63      0.52      0.57       210\n",
      "           3       0.66      0.76      0.71       210\n",
      "           4       0.52      0.62      0.57       210\n",
      "           5       0.53      0.42      0.47       210\n",
      "           6       0.55      0.60      0.57       210\n",
      "           7       0.80      0.82      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.2163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   0   0   0 209]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.27755102040816326\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   0   1   0   0   0 128]\n",
      " [  1   9  18   0   0   0 182]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   0   0 199]\n",
      " [ 63   0   5   0   0   0 142]\n",
      " [  1   0   1   0   0   0 208]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.36      0.28      0.21      1470\n",
      "weighted avg       0.36      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   1   0  41   0  44]\n",
      " [  2   9  18   0   0   0 181]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   3   0 196]\n",
      " [ 71   0   5   0  58   0  76]\n",
      " [  2   0   1   0   1   0 206]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.56      0.28      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      1.00      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.45      0.35      0.29      1470\n",
      "weighted avg       0.45      0.35      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree is: 0.40068027210884355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1   0  42  44   0]\n",
      " [  1   9  18   0   1 180   1]\n",
      " [  0   0 108   0   0 102   0]\n",
      " [  3   0   8   0   3 195   1]\n",
      " [ 54   0   5   0  75  74   2]\n",
      " [  1   0   1   0   2 198   8]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.59      0.63       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.36      0.45       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.38      1470\n",
      "weighted avg       0.59      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   1   0   0  37  44   0]\n",
      " [  1  24   3   0   1 180   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 50   4   1   0  79  73   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.47      0.11      0.18       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.38      0.48       210\n",
      "           6       0.22      0.93      0.35       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.55      0.42      0.41      1470\n",
      "weighted avg       0.55      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.4414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  43  44   0]\n",
      " [  1  50   3   0   1 154   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 40  16   1   1  88  61   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.65       210\n",
      "           2       0.56      0.24      0.33       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.64      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.57      0.44      0.44      1470\n",
      "weighted avg       0.57      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.45918367346938777\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 38  17   1   2  89  60   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   1 110  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.59      0.65       210\n",
      "           2       0.65      0.36      0.46       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.58      0.46      0.46      1470\n",
      "weighted avg       0.58      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   5   0   1 127   1]\n",
      " [  0  12 110   0   0  88   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 35  17   1   2  92  61   2]\n",
      " [  2   1   0   0   1 197   9]\n",
      " [  0   0   0   0   0 111  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.67      0.36      0.47       210\n",
      "           3       0.93      0.52      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.67      0.44      0.53       210\n",
      "           6       0.24      0.94      0.38       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.47      1470\n",
      "weighted avg       0.59      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   0   1  41  44   0]\n",
      " [  1 104   5   1   1  98   0]\n",
      " [  0  26 111   0   0  73   0]\n",
      " [  3  18   2   0   3 183   1]\n",
      " [ 42  28   1   2  89  45   3]\n",
      " [  2   3   0   0   1 194  10]\n",
      " [  0   3   0   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.58      0.64       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.66      0.42      0.52       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  1  88  21   0   2  97   1]\n",
      " [  0  11 131   0   0  68   0]\n",
      " [  5   7  13   0   1 183   1]\n",
      " [ 63  18  11   1  69  45   3]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.69      0.42      0.52       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.33      0.46       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   2   0   0  19  44   0]\n",
      " [  1  93  15   2   3  95   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  4   8  12  22   2 161   1]\n",
      " [ 55  16  11   3  79  44   2]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.71      0.44      0.55       210\n",
      "           3       0.76      0.63      0.69       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.77      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.52      1470\n",
      "weighted avg       0.70      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   0   1  35  43   0]\n",
      " [  1  94  15   4   2  93   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  2   7  16  34   4 146   1]\n",
      " [ 28  17  11   4 105  42   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   2   0   2 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.71      0.45      0.55       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.79      0.16      0.27       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  2  91   8   4   9  96   0]\n",
      " [  0  10 120   0  12  68   0]\n",
      " [  5   7   7  42  11 137   1]\n",
      " [ 52  18   1   5  91  40   3]\n",
      " [  3   1   1   2   1 193   9]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.70      0.43      0.54       210\n",
      "           3       0.88      0.57      0.69       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.62      0.43      0.51       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   2   0   0  22  35   0]\n",
      " [  2  94  11   7   2  94   0]\n",
      " [  0  10 126   6   0  68   0]\n",
      " [  5   7   8  50   2 137   1]\n",
      " [ 56  19   6   9  81  37   2]\n",
      " [  3   1   1   3   0 192  10]\n",
      " [  0   1   0   2   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.70      0.45      0.55       210\n",
      "           3       0.83      0.60      0.70       210\n",
      "           4       0.65      0.24      0.35       210\n",
      "           5       0.76      0.39      0.51       210\n",
      "           6       0.29      0.91      0.44       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   2   0   0  19  37   0]\n",
      " [  2  96  10   1   5  95   1]\n",
      " [  0  12 128   0   2  68   0]\n",
      " [  5   9   9  41   8 137   1]\n",
      " [ 48  22   4   5  91  37   3]\n",
      " [  1   1   1   2   3 193   9]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.67      0.46      0.54       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.29      0.92      0.44       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0   0  25  34   0]\n",
      " [  2 108  10   2   7  81   0]\n",
      " [  0  10 130   0   2  68   0]\n",
      " [  4  17   8  41   9 130   1]\n",
      " [ 50  22   4   5  97  29   3]\n",
      " [  2   6   1   2   2 188   9]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.71      0.72       210\n",
      "           2       0.65      0.51      0.58       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.67      0.46      0.55       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   1  30  33   0]\n",
      " [  2 109  11   1   8  78   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  4  17  10  42   9 127   1]\n",
      " [ 44  21   5   4 102  30   4]\n",
      " [  1   6   1   2   3 189   8]\n",
      " [  0   1   0   0   3 108  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.69      0.71       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  26  32   0]\n",
      " [  2 107  11   2   7  80   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  3  16  10  41  11 128   1]\n",
      " [ 46  21   5   6 102  27   3]\n",
      " [  2   5   1   2   2 186  12]\n",
      " [  0   1   0   0   4 103 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.66      0.51      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.80      0.20      0.31       210\n",
      "           5       0.66      0.49      0.56       210\n",
      "           6       0.30      0.89      0.45       210\n",
      "           7       0.86      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  28  36   0]\n",
      " [  2 104  12   3  10  78   1]\n",
      " [  0   8 139   3   1  59   0]\n",
      " [  3  14  12  40  12 127   2]\n",
      " [ 40  18   6   8 103  30   5]\n",
      " [  2   5   1   3   1 181  17]\n",
      " [  0   1   0   0   4  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.69      0.72       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.82      0.66      0.73       210\n",
      "           4       0.70      0.19      0.30       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.82      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.68      0.56      0.57      1470\n",
      "weighted avg       0.68      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0   0  37  32   0]\n",
      " [  2 111  11   2  10  73   1]\n",
      " [  0  10 139   1   1  59   0]\n",
      " [  2  16  10  41  13 126   2]\n",
      " [ 28  23   4   5 122  23   5]\n",
      " [  1   5   1   3   2 184  14]\n",
      " [  0   1   0   0   3  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.65      0.58      0.61       210\n",
      "           6       0.31      0.88      0.46       210\n",
      "           7       0.83      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.58      1470\n",
      "weighted avg       0.70      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.5918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   3   2   6  15  19   2]\n",
      " [  1  84  40  27   6  49   3]\n",
      " [  0   0 139   9   0  62   0]\n",
      " [  3  11  11 122  12  47   4]\n",
      " [ 65  20  11  20  79  10   5]\n",
      " [  5   6   1  49   2 120  27]\n",
      " [  0   1   0  13   2  31 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.67      0.40      0.50       210\n",
      "           3       0.68      0.66      0.67       210\n",
      "           4       0.50      0.58      0.54       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.36      0.57      0.44       210\n",
      "           7       0.80      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.5993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   2   5  20  21   4]\n",
      " [  1  95  41  22   7  39   5]\n",
      " [  0   7 145   6   0  49   3]\n",
      " [  4  13  12 108  15  40  18]\n",
      " [ 67  20   9  16  81  10   7]\n",
      " [  3  11   1  32   3 118  42]\n",
      " [  0   2   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.64      0.45      0.53       210\n",
      "           3       0.69      0.69      0.69       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.39      0.56      0.46       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest is: 0.6231292517006802\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   2   7  21  18   1]\n",
      " [  1  96  31  26   5  49   2]\n",
      " [  0   0 140   9   0  61   0]\n",
      " [  3   8  11 135  12  39   2]\n",
      " [ 58  19  10  20  90   7   6]\n",
      " [  2  10   1  37   4 128  28]\n",
      " [  0   4   0   9   1  28 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.69      0.46      0.55       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.68      0.43      0.52       210\n",
      "           6       0.39      0.61      0.47       210\n",
      "           7       0.81      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   6  22  21   1]\n",
      " [  1 101  31  26   4  46   1]\n",
      " [  0   0 147   7   0  56   0]\n",
      " [  3  13  13 125  11  44   1]\n",
      " [ 58  21   5  20  91   9   6]\n",
      " [  2  10   1  29   4 138  26]\n",
      " [  0   1   0   2   4  35 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.48      0.56       210\n",
      "           3       0.74      0.70      0.72       210\n",
      "           4       0.58      0.60      0.59       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   2   3  24  24   1]\n",
      " [  1 112  30  23   2  41   1]\n",
      " [  0   2 149   6   0  53   0]\n",
      " [  3  12  13 119  12  49   2]\n",
      " [ 59  21   5  19  91   9   6]\n",
      " [  3   9   2  28   3 138  27]\n",
      " [  0   3   0   0   1  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.70      0.53      0.61       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.60      0.57      0.58       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  23  24   2]\n",
      " [  1 108  31  23   4  42   1]\n",
      " [  0   1 149   2   0  58   0]\n",
      " [  4  15  13 115   7  54   2]\n",
      " [ 56  21   5  20  92  11   5]\n",
      " [  3   8   1  21   4 146  27]\n",
      " [  0   4   0   1   0  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.74      0.71      0.73       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.71      0.44      0.54       210\n",
      "           6       0.39      0.70      0.50       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   3  22  24   1]\n",
      " [  1 112  27  23   4  42   1]\n",
      " [  0   0 150   1   0  59   0]\n",
      " [  4  10  13 117  12  52   2]\n",
      " [ 44  23   5  19 101  13   5]\n",
      " [  2   8   1  29   4 137  29]\n",
      " [  0   3   0   1   2  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.71      0.53      0.61       210\n",
      "           3       0.76      0.71      0.74       210\n",
      "           4       0.61      0.56      0.58       210\n",
      "           5       0.70      0.48      0.57       210\n",
      "           6       0.37      0.65      0.48       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  21  27   1]\n",
      " [  1 113  26  22   5  42   1]\n",
      " [  0   1 152   4   0  53   0]\n",
      " [  3  14  13 114  10  54   2]\n",
      " [ 52  25   5  18  93  12   5]\n",
      " [  2   8   1  21   4 148  26]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.40      0.70      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   1   3  23  23   1]\n",
      " [  1 113  31  20   4  40   1]\n",
      " [  0   3 151   3   0  53   0]\n",
      " [  3  12  13 114  13  53   2]\n",
      " [ 50  19   4  20 102  10   5]\n",
      " [  2   9   2  24   4 145  24]\n",
      " [  0   3   0   0   1  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.62      0.54      0.58       210\n",
      "           5       0.69      0.49      0.57       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6448979591836734\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   1   4  23  25   1]\n",
      " [  1 113  30  22   3  40   1]\n",
      " [  0   3 151  10   0  46   0]\n",
      " [  3  13  12 122  10  48   2]\n",
      " [ 51  23   4  20  97  10   5]\n",
      " [  3   8   3  28   3 140  25]\n",
      " [  0   2   0   0   1  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.75      0.72      0.73       210\n",
      "           4       0.59      0.58      0.59       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   4  24  24   1]\n",
      " [  1 118  25  22   4  39   1]\n",
      " [  0   1 155   6   0  48   0]\n",
      " [  3  14  12 118  11  50   2]\n",
      " [ 41  25   4  20 105  10   5]\n",
      " [  2   7   3  29   4 138  27]\n",
      " [  0   3   0   0   1  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.69      0.56      0.62       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   1   4  26  24   1]\n",
      " [  1 117  24  21   5  41   1]\n",
      " [  0   1 156   6   0  47   0]\n",
      " [  3  12  13 121  10  49   2]\n",
      " [ 39  20   4  24 110   8   5]\n",
      " [  3   7   1  20   3 147  29]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.73      0.56      0.63       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.71      0.52      0.60       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   1   1   4  27  24   1]\n",
      " [  1 119  25  23   3  38   1]\n",
      " [  0   2 159   5   0  44   0]\n",
      " [  3  14  13 116  11  51   2]\n",
      " [ 45  22   5  22 104   7   5]\n",
      " [  2   7   3  18   4 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.74       210\n",
      "           2       0.72      0.57      0.63       210\n",
      "           3       0.77      0.76      0.76       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   4  28  24   1]\n",
      " [  1 118  24  21   7  38   1]\n",
      " [  0   4 157   6   0  43   0]\n",
      " [  3  15  12 118  10  50   2]\n",
      " [ 39  23   4  18 112   9   5]\n",
      " [  1   7   3  18   5 150  26]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75       210\n",
      "           2       0.70      0.56      0.62       210\n",
      "           3       0.78      0.75      0.76       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  29  23   1]\n",
      " [  1 121  25  20   4  38   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  3  13  13 118  11  50   2]\n",
      " [ 36  22   5  17 116   9   5]\n",
      " [  1   8   2  21   4 148  26]\n",
      " [  0   2   0   0   1  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.71      0.75       210\n",
      "           2       0.70      0.58      0.63       210\n",
      "           3       0.78      0.77      0.78       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.55      0.62       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   4  24  23   1]\n",
      " [  1 120  25  21   5  37   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  2  14  13 120  12  47   2]\n",
      " [ 37  20   5  18 116   9   5]\n",
      " [  1   9   3  26   5 140  26]\n",
      " [  0   1   0   0   2  38 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.76       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.71      0.55      0.62       210\n",
      "           6       0.42      0.67      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   1   5  28  22   1]\n",
      " [  1 125  25  18   4  36   1]\n",
      " [  0   5 158  12   0  35   0]\n",
      " [  2  13  13 124  11  45   2]\n",
      " [ 38  22   4  18 114   9   5]\n",
      " [  2   8   3  24   3 144  26]\n",
      " [  0   1   0   0   1  40 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.72      0.75       210\n",
      "           2       0.71      0.60      0.65       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.44      0.69      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   3  27  23   1]\n",
      " [  1 123  24  18   7  36   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 125  11  45   2]\n",
      " [ 36  22   5  20 115   7   5]\n",
      " [  3   8   3  24   3 141  28]\n",
      " [  0   1   0   0   3  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.70      0.59      0.64       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.69      0.55      0.61       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.82      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  26  24   0]\n",
      " [  1 124  26  18   6  34   1]\n",
      " [  0   3 162  11   0  34   0]\n",
      " [  2  13  13 121  13  46   2]\n",
      " [ 37  20   4  18 117   9   5]\n",
      " [  2   7   3  20   3 147  28]\n",
      " [  0   0   0   0   3  36 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.73      0.59      0.65       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.70      0.56      0.62       210\n",
      "           6       0.45      0.70      0.54       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   1   4  24  22   1]\n",
      " [  1 124  24  20   5  35   1]\n",
      " [  0   6 159  11   0  34   0]\n",
      " [  2  13  12 122  12  47   2]\n",
      " [ 36  20   4  22 116   7   5]\n",
      " [  2   8   2  23   4 143  28]\n",
      " [  0   2   0   0   1  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.77       210\n",
      "           2       0.71      0.59      0.64       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.72      0.55      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.6986394557823129\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[177   3   0   8  21   1   0]\n",
      " [  9 149  18  15  15   4   0]\n",
      " [  5   8 178  18   1   0   0]\n",
      " [ 16  12  19 140  16   6   1]\n",
      " [ 25  21   7  23 122   8   4]\n",
      " [ 32  21   8  34   1  80  34]\n",
      " [  4   2   2   0   1  20 181]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.84      0.74       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.77      0.85      0.81       210\n",
      "           4       0.59      0.67      0.62       210\n",
      "           5       0.69      0.58      0.63       210\n",
      "           6       0.67      0.38      0.49       210\n",
      "           7       0.82      0.86      0.84       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "tf_500_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tf_500_vectors.csv\",encoding_errors='ignore')\n",
    "tf_500_df\n",
    "\n",
    "# Train Test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(tf_500_df,labels_df['Labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['Labels'])\n",
    "\n",
    "# Modelling\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression()\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158cf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
