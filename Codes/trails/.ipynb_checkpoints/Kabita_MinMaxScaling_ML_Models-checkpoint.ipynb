{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//kabita_dataset_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b63a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of Train-test split, MinMax Scaling\n",
    "def minmax_scaling(x_data, y_data):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.30,random_state=21,stratify=y_data)\n",
    "    # MinMax scaling of train data\n",
    "    minmax_model = MinMaxScaler(feature_range=(0,5))\n",
    "    np.set_printoptions(precision=3)\n",
    "    scaled_data_train = minmax_model.fit_transform(x_train)\n",
    "    # MinMax scaling of test data\n",
    "    scaled_data_test = minmax_model.fit_transform(x_test)\n",
    "    return scaled_data_train, scaled_data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" after MinMax Scaling is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after MinMax Scaling is: 0.7306122448979592\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[160   1   1   4  29  12   3]\n",
      " [  0 158  11  10  12  19   0]\n",
      " [  1   2 181  13   0  13   0]\n",
      " [  1  10  16 151  11  17   4]\n",
      " [ 25  13   9  17 139   2   5]\n",
      " [  5   9   5  30   4 119  38]\n",
      " [  1   1   0   4   0  38 166]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.76      0.79       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.81      0.86      0.84       210\n",
      "           4       0.66      0.72      0.69       210\n",
      "           5       0.71      0.66      0.69       210\n",
      "           6       0.54      0.57      0.55       210\n",
      "           7       0.77      0.79      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5945578231292517\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137  10   7  15   8  31   2]\n",
      " [  9 153  20   7   3  18   0]\n",
      " [  8   4 173   6   2  17   0]\n",
      " [ 30  13  15 130   0  21   1]\n",
      " [ 53  38  21  28  44  22   4]\n",
      " [ 23  15   6  17   6 115  28]\n",
      " [  4   6   0   5   4  69 122]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.65      0.58       210\n",
      "           2       0.64      0.73      0.68       210\n",
      "           3       0.71      0.82      0.77       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.66      0.21      0.32       210\n",
      "           6       0.39      0.55      0.46       210\n",
      "           7       0.78      0.58      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.58      1470\n",
      "weighted avg       0.62      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   6   4  16  11  28   2]\n",
      " [ 12 147  15  12   3  20   1]\n",
      " [ 10   2 172   8   2  16   0]\n",
      " [ 27  11  18 132   1  19   2]\n",
      " [ 56  38  24  30  36  21   5]\n",
      " [ 21  19   2  18   3 119  28]\n",
      " [  6  13   4   4   0  70 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.68      0.59       210\n",
      "           2       0.62      0.70      0.66       210\n",
      "           3       0.72      0.82      0.77       210\n",
      "           4       0.60      0.63      0.61       210\n",
      "           5       0.64      0.17      0.27       210\n",
      "           6       0.41      0.57      0.47       210\n",
      "           7       0.75      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.57      1470\n",
      "weighted avg       0.61      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   7   2  16  13  30   2]\n",
      " [  9 147  17   9   8  19   1]\n",
      " [  9   4 170  10   2  15   0]\n",
      " [ 19  14  17 133   2  23   2]\n",
      " [ 54  41  25  30  35  20   5]\n",
      " [ 16  15   4  22   2 123  28]\n",
      " [  2  10   5   7   0  70 116]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61       210\n",
      "           2       0.62      0.70      0.66       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.59      0.63      0.61       210\n",
      "           5       0.56      0.17      0.26       210\n",
      "           6       0.41      0.59      0.48       210\n",
      "           7       0.75      0.55      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.57      1470\n",
      "weighted avg       0.60      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   8   5  14  11  36   1]\n",
      " [ 10 146  17  10   5  22   0]\n",
      " [  7   5 172   9   1  16   0]\n",
      " [ 18   8  17 137   0  26   4]\n",
      " [ 50  47  25  28  31  25   4]\n",
      " [ 17  17   3  23   1 129  20]\n",
      " [  3  14   3   8   0  68 114]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.64      0.60       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.71      0.82      0.76       210\n",
      "           4       0.60      0.65      0.62       210\n",
      "           5       0.63      0.15      0.24       210\n",
      "           6       0.40      0.61      0.48       210\n",
      "           7       0.80      0.54      0.65       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.57      1470\n",
      "weighted avg       0.61      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133  12   3  16   8  37   1]\n",
      " [  8 146  19   8   5  24   0]\n",
      " [  7   2 173   8   1  19   0]\n",
      " [ 16  12  16 137   3  22   4]\n",
      " [ 55  47  23  28  24  31   2]\n",
      " [ 15  15   5  22   2 128  23]\n",
      " [  3  12   3   5   0  76 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.63      0.60       210\n",
      "           2       0.59      0.70      0.64       210\n",
      "           3       0.71      0.82      0.77       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.56      0.11      0.19       210\n",
      "           6       0.38      0.61      0.47       210\n",
      "           7       0.79      0.53      0.63       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.56      1470\n",
      "weighted avg       0.60      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  13   4   9   9  44   2]\n",
      " [  8 141  26  11   5  19   0]\n",
      " [  8   2 172   8   1  19   0]\n",
      " [ 14  12  15 137   2  26   4]\n",
      " [ 55  42  21  28  23  38   3]\n",
      " [ 16  16   5  19   2 133  19]\n",
      " [  3   8   2   6   0  86 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.61      0.58       210\n",
      "           2       0.60      0.67      0.64       210\n",
      "           3       0.70      0.82      0.76       210\n",
      "           4       0.63      0.65      0.64       210\n",
      "           5       0.55      0.11      0.18       210\n",
      "           6       0.36      0.63      0.46       210\n",
      "           7       0.79      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.60      0.57      0.55      1470\n",
      "weighted avg       0.60      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after MinMax Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[154   2   8  18  20   3   5]\n",
      " [  7 122  66   7   4   4   0]\n",
      " [  5   6 193   4   0   1   1]\n",
      " [ 19  20  40 116   9   4   2]\n",
      " [ 70  12  13  49  53   7   6]\n",
      " [ 25  30  43  28   6  42  36]\n",
      " [ 14  11   4   5   2  22 152]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.73      0.61       210\n",
      "           2       0.60      0.58      0.59       210\n",
      "           3       0.53      0.92      0.67       210\n",
      "           4       0.51      0.55      0.53       210\n",
      "           5       0.56      0.25      0.35       210\n",
      "           6       0.51      0.20      0.29       210\n",
      "           7       0.75      0.72      0.74       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.54      1470\n",
      "weighted avg       0.57      0.57      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after MinMax Scaling is: 0.7136054421768707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   1  10   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  11  32 143   6   8   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  12  44  18   5  97  28]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       210\n",
      "           2       0.78      0.77      0.77       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.74      0.68      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.64      0.46      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after MinMax Scaling is: 0.717687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[163   3   0   7  24  11   2]\n",
      " [  1 166   9  11   4  19   0]\n",
      " [  1   7 180   6   1  15   0]\n",
      " [  5  17  17 144   6  19   2]\n",
      " [ 30  16  14  15 125   4   6]\n",
      " [  7  15   5  24   3 121  35]\n",
      " [  2   2   0   6   3  41 156]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       210\n",
      "           2       0.73      0.79      0.76       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.68      0.69      0.68       210\n",
      "           5       0.75      0.60      0.66       210\n",
      "           6       0.53      0.58      0.55       210\n",
      "           7       0.78      0.74      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after MinMax Scaling is: 0.654421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[120   1   0  14  28  44   3]\n",
      " [  2 140   9  16  17  26   0]\n",
      " [  4   2 172  11   4  17   0]\n",
      " [  9   5   9 151   7  27   2]\n",
      " [ 23   9   6  32 104  30   6]\n",
      " [  7   9   1  20   5 135  33]\n",
      " [  0   4   0   5   1  60 140]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.57      0.64       210\n",
      "           2       0.82      0.67      0.74       210\n",
      "           3       0.87      0.82      0.85       210\n",
      "           4       0.61      0.72      0.66       210\n",
      "           5       0.63      0.50      0.55       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.76      0.67      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.66      1470\n",
      "weighted avg       0.69      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after MinMax Scaling is: 0.7149659863945578\n",
      "Confusion Matrix of SVM is:\n",
      " [[131   0   0   7  41  18  13]\n",
      " [  1 152   8  12  13  21   3]\n",
      " [  0   5 174  11   2  17   1]\n",
      " [  4   4  11 147   9  22  13]\n",
      " [ 11   8   5  18 143   5  20]\n",
      " [  7   5   1  16   7 117  57]\n",
      " [  0   0   0   3   0  20 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.62      0.72       210\n",
      "           2       0.87      0.72      0.79       210\n",
      "           3       0.87      0.83      0.85       210\n",
      "           4       0.69      0.70      0.69       210\n",
      "           5       0.67      0.68      0.67       210\n",
      "           6       0.53      0.56      0.54       210\n",
      "           7       0.64      0.89      0.74       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.72      1470\n",
      "weighted avg       0.73      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after MinMax Scaling is: 0.7340136054421769\n",
      "Confusion Matrix of SVM is:\n",
      " [[169   1   0   7  18  12   3]\n",
      " [  0 164  16   8   4  18   0]\n",
      " [  0   3 179  10   0  18   0]\n",
      " [  0   8  16 147   7  24   8]\n",
      " [ 24  18  17  21 120   3   7]\n",
      " [  4   5   2  19   3 129  48]\n",
      " [  0   1   0   5   1  32 171]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.80      0.83       210\n",
      "           2       0.82      0.78      0.80       210\n",
      "           3       0.78      0.85      0.81       210\n",
      "           4       0.68      0.70      0.69       210\n",
      "           5       0.78      0.57      0.66       210\n",
      "           6       0.55      0.61      0.58       210\n",
      "           7       0.72      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.20748299319727892\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [115   0  95   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.16      0.21      0.13      1470\n",
      "weighted avg       0.16      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.2653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   2   0   0 153   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.25      0.27      0.20      1470\n",
      "weighted avg       0.25      0.27      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.3122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   0   0   0  43  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 78   0   2   0  42  88   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.53      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.20      0.28       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.25      1470\n",
      "weighted avg       0.32      0.31      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66   2   0   0  89   0  53]\n",
      " [  0  54   2   0   2   0 152]\n",
      " [  0   0  95   0   0   0 115]\n",
      " [  0   6   1   0   1   0 202]\n",
      " [ 13   4   2   0 107   0  84]\n",
      " [  0   3   0   0   0   0 207]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.31      0.46       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.53      0.51      0.52       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.99      0.34       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.47      0.36      0.33      1470\n",
      "weighted avg       0.47      0.36      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   2   0  53  46   0   0]\n",
      " [  0  54   2 152   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 40   4   2  81  80   0   3]\n",
      " [  0   3   0 203   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.52      0.61       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.21      0.96      0.34       210\n",
      "           5       0.62      0.38      0.47       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.39      1470\n",
      "weighted avg       0.59      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  53   0   0   0]\n",
      " [  0  83   2 123   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 82   9   2  75  39   1   2]\n",
      " [  0   2   0 203   0   1   4]\n",
      " [  2   1   0 162   0   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.74      0.69       210\n",
      "           2       0.81      0.40      0.53       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.22      0.96      0.35       210\n",
      "           5       0.95      0.19      0.31       210\n",
      "           6       0.50      0.00      0.01       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.71      0.42      0.41      1470\n",
      "weighted avg       0.71      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0   0   0  53   0]\n",
      " [  0 122   2   0   3  83   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   6   1   1   0 201   0]\n",
      " [ 74  20   2   0  47  65   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.74      0.70       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.94      0.22      0.36       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.78      0.45      0.44      1470\n",
      "weighted avg       0.78      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.48095238095238096\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[136   2   0  53  19   0   0]\n",
      " [  0 122   2  83   3   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 200   0   0   2]\n",
      " [ 38  20   2  64  83   1   2]\n",
      " [  0   3   0 190   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.24      0.95      0.38       210\n",
      "           5       0.78      0.40      0.52       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.66      0.48      0.48      1470\n",
      "weighted avg       0.66      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   2   0  53  20   0   0]\n",
      " [  0 122   3  82   3   0   0]\n",
      " [  0   0 109 101   0   0   0]\n",
      " [  0   5   4 197   2   0   2]\n",
      " [ 35  18   3  63  88   1   2]\n",
      " [  0   3   1 189   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.81      0.58      0.68       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.24      0.94      0.38       210\n",
      "           5       0.77      0.42      0.54       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.66      0.49      0.49      1470\n",
      "weighted avg       0.66      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[126   3   0   0  29  52   0]\n",
      " [  0 141   3   0   3  63   0]\n",
      " [  0  37 109   0   0  64   0]\n",
      " [  0  21   4   1   2 180   2]\n",
      " [ 24  30   3   0 104  47   2]\n",
      " [  0   5   1   0   0 188  16]\n",
      " [  0   1   0   1   2 136  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.59      0.67      0.63       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.50      0.00      0.01       210\n",
      "           5       0.74      0.50      0.59       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.66      0.50      0.49      1470\n",
      "weighted avg       0.66      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   3   0  52  11   0   0]\n",
      " [  0 140   4  63   3   0   0]\n",
      " [  0  21 125  64   0   0   0]\n",
      " [  0  21   4 179   2   0   4]\n",
      " [ 51  28   6  45  76   1   3]\n",
      " [  0   5   1 183   0   1  20]\n",
      " [  2   1   0 111   0   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.69      0.71       210\n",
      "           2       0.64      0.67      0.65       210\n",
      "           3       0.89      0.60      0.71       210\n",
      "           4       0.26      0.85      0.39       210\n",
      "           5       0.83      0.36      0.50       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.64      0.52      0.51      1470\n",
      "weighted avg       0.64      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5428571428571428\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   2   0  52  21   0   0]\n",
      " [  0 133   4  63  10   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 179  13   0   4]\n",
      " [ 30  13   6  45 112   1   3]\n",
      " [  0   3   1 179   2   1  24]\n",
      " [  0   1   0  93   2   1 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.74      0.63      0.68       210\n",
      "           3       0.89      0.60      0.71       210\n",
      "           4       0.27      0.85      0.40       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.65      0.54      0.54      1470\n",
      "weighted avg       0.65      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   2   0  42  10   0   0]\n",
      " [  0 134   4  63   9   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 185   7   0   4]\n",
      " [ 53  12   6  43  95   1   0]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  2   1   0  93   0   1 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.74      0.64      0.69       210\n",
      "           3       0.89      0.60      0.71       210\n",
      "           4       0.28      0.88      0.42       210\n",
      "           5       0.75      0.45      0.56       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.81      0.54      0.65       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.65      0.55      0.54      1470\n",
      "weighted avg       0.65      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  42  11   0   0]\n",
      " [  0 136   5  63   6   0   0]\n",
      " [  0  13 138  55   4   0   0]\n",
      " [  0  10   4 184   8   0   4]\n",
      " [ 50  13   6  42  96   1   2]\n",
      " [  0   3   1 179   2   2  23]\n",
      " [  2   1   0  93   0   2 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.74       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.90      0.66      0.76       210\n",
      "           4       0.28      0.88      0.42       210\n",
      "           5       0.76      0.46      0.57       210\n",
      "           6       0.40      0.01      0.02       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.66      0.56      0.55      1470\n",
      "weighted avg       0.66      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0  42  27   0   0]\n",
      " [  0 136   6  62   6   0   0]\n",
      " [  0  13 144  49   4   0   0]\n",
      " [  1  10   5 184   6   0   4]\n",
      " [ 33  13   6  43 114   1   0]\n",
      " [  0   3   1 179   2   2  23]\n",
      " [  0   1   0  93   4   1 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       210\n",
      "           2       0.77      0.65      0.70       210\n",
      "           3       0.89      0.69      0.77       210\n",
      "           4       0.28      0.88      0.43       210\n",
      "           5       0.70      0.54      0.61       210\n",
      "           6       0.50      0.01      0.02       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.68      0.57      0.56      1470\n",
      "weighted avg       0.68      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0  43  16   0   0]\n",
      " [  0 134   7  61   8   0   0]\n",
      " [  0  10 152  44   4   0   0]\n",
      " [  0  10   6 182   8   0   4]\n",
      " [ 50  12   6  42  97   1   2]\n",
      " [  0   3   1 179   2   4  21]\n",
      " [  2   1   0  93   0   5 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.88      0.72      0.80       210\n",
      "           4       0.28      0.87      0.43       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.40      0.02      0.04       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.66      0.56      0.55      1470\n",
      "weighted avg       0.66      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0  43  16   0   0]\n",
      " [  0 135   6  62   7   0   0]\n",
      " [  0   9 153  44   4   0   0]\n",
      " [  0  10   6 183   7   0   4]\n",
      " [ 43  13   6  42 105   1   0]\n",
      " [  0   3   1 175   2   5  24]\n",
      " [  1   1   0  86   1  12 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.78      0.64      0.71       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.29      0.87      0.43       210\n",
      "           5       0.74      0.50      0.60       210\n",
      "           6       0.28      0.02      0.04       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.65      0.57      0.56      1470\n",
      "weighted avg       0.65      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   1   0   1  18  42   0]\n",
      " [  0 134   7   0   8  61   0]\n",
      " [  0   9 153   0   4  44   0]\n",
      " [  0  10   6  16   7 167   4]\n",
      " [ 45  13   6   0 103  43   0]\n",
      " [  0   3   1   0   2 181  23]\n",
      " [  1   1   0   1   1  93 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.89      0.08      0.14       210\n",
      "           5       0.72      0.49      0.58       210\n",
      "           6       0.29      0.86      0.43       210\n",
      "           7       0.81      0.54      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.73      0.58      0.58      1470\n",
      "weighted avg       0.73      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   1   0   1  23  42   0]\n",
      " [  0 133   7   0   9  61   0]\n",
      " [  0   8 154   1   4  43   0]\n",
      " [  0   9   8  35   7 147   4]\n",
      " [ 33  12   6   3 116  40   0]\n",
      " [  0   3   1   1   2 179  24]\n",
      " [  0   1   0   2   4  93 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.68      0.74       210\n",
      "           2       0.80      0.63      0.71       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.81      0.17      0.28       210\n",
      "           5       0.70      0.55      0.62       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.73      0.59      0.60      1470\n",
      "weighted avg       0.73      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   2  18  42   0]\n",
      " [  0 145   7   0   8  50   0]\n",
      " [  0   9 154   0   3  44   0]\n",
      " [  0   8   7  36   7 148   4]\n",
      " [ 41  18   6   3 106  36   0]\n",
      " [  0   3   1   1   2 179  24]\n",
      " [  1   1   0   2   1 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74       210\n",
      "           2       0.78      0.69      0.73       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.82      0.17      0.28       210\n",
      "           5       0.73      0.50      0.60       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.73      0.59      0.60      1470\n",
      "weighted avg       0.73      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   2  18  42   0]\n",
      " [  0 145   7   0   8  50   0]\n",
      " [  0   9 154   0   3  44   0]\n",
      " [  0   8   7  36   7 148   4]\n",
      " [ 41  18   6   3 106  36   0]\n",
      " [  0   3   1   1   2 179  24]\n",
      " [  1   1   0   2   1 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74       210\n",
      "           2       0.78      0.69      0.73       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.82      0.17      0.28       210\n",
      "           5       0.73      0.50      0.60       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.73      0.59      0.60      1470\n",
      "weighted avg       0.73      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   3   0  19   5  19   9]\n",
      " [  1 111   7  13  35  43   0]\n",
      " [  0   0 151  23   0  35   1]\n",
      " [  0  11   8 125  10  49   7]\n",
      " [ 62  15   6  29  72  12  14]\n",
      " [  0   7   5  24   4 129  41]\n",
      " [  0   0   1  18   0  43 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.76      0.53      0.62       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.50      0.60      0.54       210\n",
      "           5       0.57      0.34      0.43       210\n",
      "           6       0.39      0.61      0.48       210\n",
      "           7       0.67      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6353741496598639\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   5   2  18   6  21   3]\n",
      " [  1 126   6  11  23  43   0]\n",
      " [  0   0 152  27   0  30   1]\n",
      " [  1   7   9 141   7  40   5]\n",
      " [ 60  19   6  25  71  13  16]\n",
      " [  0   2   5  21   4 139  39]\n",
      " [  0   0   1  14   0  45 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.79      0.60      0.68       210\n",
      "           3       0.84      0.72      0.78       210\n",
      "           4       0.55      0.67      0.60       210\n",
      "           5       0.64      0.34      0.44       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.70      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   0  18   5  21   1]\n",
      " [  0 130   9  10  18  43   0]\n",
      " [  0   0 156  17   0  36   1]\n",
      " [  1   7   9 142   3  41   7]\n",
      " [ 67  17   7  23  69  15  12]\n",
      " [  0   3   4  24   1 136  42]\n",
      " [  1   0   1  11   0  44 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73       210\n",
      "           2       0.81      0.62      0.70       210\n",
      "           3       0.84      0.74      0.79       210\n",
      "           4       0.58      0.68      0.62       210\n",
      "           5       0.72      0.33      0.45       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.64      1470\n",
      "weighted avg       0.68      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   7   0  16   6  22   2]\n",
      " [  0 133   9  12  17  39   0]\n",
      " [  0   0 157  16   0  36   1]\n",
      " [  1  11   8 144   8  34   4]\n",
      " [ 68  22   7  24  65  12  12]\n",
      " [  0   6   4  31   2 126  41]\n",
      " [  0   0   1  13   0  41 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72       210\n",
      "           2       0.74      0.63      0.68       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.56      0.69      0.62       210\n",
      "           5       0.66      0.31      0.42       210\n",
      "           6       0.41      0.60      0.48       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   3   0  16   8  23   2]\n",
      " [  0 138  10  14  12  36   0]\n",
      " [  0   0 167  14   0  29   0]\n",
      " [  0   7   9 149   5  36   4]\n",
      " [ 57  16   7  27  78  12  13]\n",
      " [  0   3   5  29   2 131  40]\n",
      " [  0   0   1  14   0  38 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.83      0.66      0.73       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.57      0.71      0.63       210\n",
      "           5       0.74      0.37      0.50       210\n",
      "           6       0.43      0.62      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   3   0  18   9  22   1]\n",
      " [  0 136   9  13  15  37   0]\n",
      " [  0   0 158  15   0  37   0]\n",
      " [  0   9  10 151   2  34   4]\n",
      " [ 56  16   7  24  82  12  13]\n",
      " [  0   3   4  29   2 133  39]\n",
      " [  0   0   1  13   0  41 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.81      0.65      0.72       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.57      0.72      0.64       210\n",
      "           5       0.75      0.39      0.51       210\n",
      "           6       0.42      0.63      0.51       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  16   8  23   2]\n",
      " [  0 138  11  10  16  35   0]\n",
      " [  0   0 161  13   0  36   0]\n",
      " [  1   8  10 143   3  41   4]\n",
      " [ 53  16   7  24  83  15  12]\n",
      " [  0   4   4  22   3 137  40]\n",
      " [  0   0   1   9   0  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.76      0.75       210\n",
      "           2       0.82      0.66      0.73       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.73      0.40      0.51       210\n",
      "           6       0.42      0.65      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0  17   9  23   1]\n",
      " [  0 139   7  14  13  37   0]\n",
      " [  0   0 160  13   0  37   0]\n",
      " [  1   6  10 143   4  42   4]\n",
      " [ 45  17   7  22  94  14  11]\n",
      " [  0   3   4  19   2 143  39]\n",
      " [  0   0   1   9   0  45 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.83      0.66      0.74       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.77      0.45      0.57       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  16   8  24   1]\n",
      " [  1 140   7  14  12  36   0]\n",
      " [  0   0 162  13   0  35   0]\n",
      " [  0   6   9 145   3  43   4]\n",
      " [ 51  17   7  21  87  16  11]\n",
      " [  0   3   4  20   2 143  38]\n",
      " [  0   0   1   8   1  47 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.76      0.76       210\n",
      "           2       0.83      0.67      0.74       210\n",
      "           3       0.85      0.77      0.81       210\n",
      "           4       0.61      0.69      0.65       210\n",
      "           5       0.77      0.41      0.54       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.74      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   9  12  30   0]\n",
      " [  0 142  11  10  10  37   0]\n",
      " [  0   1 166  14   0  29   0]\n",
      " [  0   6  10 134   5  51   4]\n",
      " [ 48  15   7  19  97  15   9]\n",
      " [  0   3   4  15   2 149  37]\n",
      " [  0   0   1   5   0  51 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.65      0.64      0.64       210\n",
      "           5       0.77      0.46      0.58       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   2   0   9   8  30   0]\n",
      " [  0 143   8  10  12  37   0]\n",
      " [  0   0 160  11   0  39   0]\n",
      " [  0   6   9 139   4  48   4]\n",
      " [ 56  16   7  19  86  16  10]\n",
      " [  0   3   4  16   2 144  41]\n",
      " [  1   0   1   6   1  51 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.76      0.41      0.53       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.73      0.71      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0  12   9  27   0]\n",
      " [  0 141  11  10  14  34   0]\n",
      " [  0   0 168  11   0  31   0]\n",
      " [  0   6  10 141   4  45   4]\n",
      " [ 58  16   7  19  86  15   9]\n",
      " [  0   3   5  16   2 145  39]\n",
      " [  1   0   1   6   1  51 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       210\n",
      "           2       0.84      0.67      0.75       210\n",
      "           3       0.83      0.80      0.82       210\n",
      "           4       0.66      0.67      0.66       210\n",
      "           5       0.74      0.41      0.53       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.74      0.71      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0  12   9  28   1]\n",
      " [  0 143  10   9  11  37   0]\n",
      " [  0   0 168  12   0  30   0]\n",
      " [  0   6  10 139   4  47   4]\n",
      " [ 44  16   7  23  94  15  11]\n",
      " [  0   4   3  17   2 146  38]\n",
      " [  0   0   1   7   0  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.77       210\n",
      "           2       0.84      0.68      0.75       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.63      0.66      0.65       210\n",
      "           5       0.78      0.45      0.57       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0  12  10  28   0]\n",
      " [  0 147  10   9  10  34   0]\n",
      " [  0   0 169  10   0  31   0]\n",
      " [  0   6   9 141   5  45   4]\n",
      " [ 46  15   7  21  95  16  10]\n",
      " [  0   4   3  16   2 143  42]\n",
      " [  0   0   1   5   1  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.84      0.70      0.77       210\n",
      "           3       0.85      0.80      0.83       210\n",
      "           4       0.66      0.67      0.67       210\n",
      "           5       0.77      0.45      0.57       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.69      1470\n",
      "weighted avg       0.72      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6884353741496598\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  13   8  27   1]\n",
      " [  0 149   7  10  13  31   0]\n",
      " [  0   4 161   9   0  36   0]\n",
      " [  0   8   9 139   5  45   4]\n",
      " [ 40  14   7  19 106  14  10]\n",
      " [  0   3   1  19   2 146  39]\n",
      " [  0   0   0   7   1  50 152]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.76      0.78       210\n",
      "           2       0.83      0.71      0.76       210\n",
      "           3       0.87      0.77      0.82       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.79      0.50      0.61       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.74      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.73      0.69      0.70      1470\n",
      "weighted avg       0.73      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0  11  13  28   0]\n",
      " [  0 148   9  12  12  29   0]\n",
      " [  0   4 171   8   1  26   0]\n",
      " [  0   8  10 142   4  42   4]\n",
      " [ 33  14   7  21 111  12  12]\n",
      " [  0   3   4  19   2 142  40]\n",
      " [  0   0   1   7   1  48 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.78       210\n",
      "           2       0.83      0.70      0.76       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.65      0.68      0.66       210\n",
      "           5       0.77      0.53      0.63       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.73      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   0  10  16  28   1]\n",
      " [  0 148   7   9  14  32   0]\n",
      " [  0   5 161  10   0  34   0]\n",
      " [  0   9   9 142   5  41   4]\n",
      " [ 35  14   7  21 109  14  10]\n",
      " [  0   3   4  15   2 144  42]\n",
      " [  0   0   0   5   2  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.86      0.77      0.81       210\n",
      "           4       0.67      0.68      0.67       210\n",
      "           5       0.74      0.52      0.61       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   0   9  16  30   0]\n",
      " [  0 152   8  10  10  30   0]\n",
      " [  0   3 170  10   0  27   0]\n",
      " [  0   9  10 142   4  41   4]\n",
      " [ 40  14   7  20 104  15  10]\n",
      " [  0   3   3  20   3 144  37]\n",
      " [  1   0   0   5   1  48 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.73      0.76       210\n",
      "           2       0.83      0.72      0.77       210\n",
      "           3       0.86      0.81      0.83       210\n",
      "           4       0.66      0.68      0.67       210\n",
      "           5       0.75      0.50      0.60       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.75      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   0   9  14  30   1]\n",
      " [  0 155   8   8   8  31   0]\n",
      " [  0   4 170  11   0  25   0]\n",
      " [  0   9  10 142   5  40   4]\n",
      " [ 33  14   7  21 110  14  11]\n",
      " [  0   5   4  17   3 141  40]\n",
      " [  0   0   0   5   2  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.73      0.78       210\n",
      "           2       0.82      0.74      0.78       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.67      0.68      0.67       210\n",
      "           5       0.77      0.52      0.62       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.71      1470\n",
      "weighted avg       0.73      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6979591836734694\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   3   0  10  14  28   0]\n",
      " [  0 154   7   8  10  31   0]\n",
      " [  0   3 170   9   0  28   0]\n",
      " [  0  10   9 140   5  42   4]\n",
      " [ 36  16   7  18 107  16  10]\n",
      " [  0   3   3  19   2 145  38]\n",
      " [  1   0   0   5   1  48 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.74      0.77       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.77      0.51      0.61       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.75      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.7380952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   3   0   7  22  15   2]\n",
      " [  0 163  10  11  10  15   1]\n",
      " [  2   4 177   7   2  18   0]\n",
      " [  7   8  10 157   4  19   5]\n",
      " [ 27  14   7  20 126   7   9]\n",
      " [  7   5   3  20   1 130  44]\n",
      " [  3   1   0   5   1  29 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.77       210\n",
      "           2       0.82      0.78      0.80       210\n",
      "           3       0.86      0.84      0.85       210\n",
      "           4       0.69      0.75      0.72       210\n",
      "           5       0.76      0.60      0.67       210\n",
      "           6       0.56      0.62      0.59       210\n",
      "           7       0.74      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after MinMax Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[149   0   1   5  43  11   1]\n",
      " [ 13 150   9   9  22   7   0]\n",
      " [ 14   3 176  11   4   2   0]\n",
      " [ 18   4  13 147  12  12   4]\n",
      " [ 27  11  12  25 124   7   4]\n",
      " [ 36  10   3  22   6  93  40]\n",
      " [  4   3   0   3   0  20 180]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.71      0.63       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.66      0.70      0.68       210\n",
      "           5       0.59      0.59      0.59       210\n",
      "           6       0.61      0.44      0.51       210\n",
      "           7       0.79      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after MinMax Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[155   2   1   8  26  16   2]\n",
      " [  1 117  41  11  24  16   0]\n",
      " [  1   1 182   9   3  14   0]\n",
      " [  1   9  19 139  20  18   4]\n",
      " [ 23  11  10   7 150   6   3]\n",
      " [  4  12   5  22   3 119  45]\n",
      " [  1   3   0   5   2  42 157]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.78       210\n",
      "           2       0.75      0.56      0.64       210\n",
      "           3       0.71      0.87      0.78       210\n",
      "           4       0.69      0.66      0.68       210\n",
      "           5       0.66      0.71      0.68       210\n",
      "           6       0.52      0.57      0.54       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158  14   6   6   4  21   1]\n",
      " [  4 151  15   9   8  22   1]\n",
      " [  8   4 159   8   0  31   0]\n",
      " [ 25  21  16 121   0  25   2]\n",
      " [ 64  47  13  22  44  17   3]\n",
      " [ 16  22   5  16   3 122  26]\n",
      " [  5  12   3  14   0  66 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.75      0.64       210\n",
      "           2       0.56      0.72      0.63       210\n",
      "           3       0.73      0.76      0.74       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.75      0.21      0.33       210\n",
      "           6       0.40      0.58      0.47       210\n",
      "           7       0.77      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.63      0.59      0.58      1470\n",
      "weighted avg       0.63      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   9   6   8   4  19   3]\n",
      " [  3 162  14   6   3  21   1]\n",
      " [  4   9 168  14   2  13   0]\n",
      " [ 18  20  16 129   2  23   2]\n",
      " [ 57  53  16  24  36  20   4]\n",
      " [ 11  20   5  23   1 129  21]\n",
      " [  8  13   2   8   0  94  85]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.77      0.68       210\n",
      "           2       0.57      0.77      0.65       210\n",
      "           3       0.74      0.80      0.77       210\n",
      "           4       0.61      0.61      0.61       210\n",
      "           5       0.75      0.17      0.28       210\n",
      "           6       0.40      0.61      0.49       210\n",
      "           7       0.73      0.40      0.52       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.63      0.59      0.57      1470\n",
      "weighted avg       0.63      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[164   7   4   6   3  24   2]\n",
      " [  5 156  17   6   5  20   1]\n",
      " [  4  12 166  14   1  13   0]\n",
      " [ 12  21  17 133   1  24   2]\n",
      " [ 54  53  18  27  36  20   2]\n",
      " [  9  15   5  29   0 126  26]\n",
      " [  6  14   4  10   0  85  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.78      0.71       210\n",
      "           2       0.56      0.74      0.64       210\n",
      "           3       0.72      0.79      0.75       210\n",
      "           4       0.59      0.63      0.61       210\n",
      "           5       0.78      0.17      0.28       210\n",
      "           6       0.40      0.60      0.48       210\n",
      "           7       0.73      0.43      0.54       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.63      0.59      0.57      1470\n",
      "weighted avg       0.63      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[166  10   4   5   1  23   1]\n",
      " [  3 163  16   6   2  20   0]\n",
      " [  5  89  91  10   1  14   0]\n",
      " [  6  24  17 136   2  22   3]\n",
      " [ 54  54  25  26  31  18   2]\n",
      " [  8  22   5  27   0 127  21]\n",
      " [  3  16   3  13   0  90  85]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.79      0.73       210\n",
      "           2       0.43      0.78      0.55       210\n",
      "           3       0.57      0.43      0.49       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.84      0.15      0.25       210\n",
      "           6       0.40      0.60      0.48       210\n",
      "           7       0.76      0.40      0.53       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.52      1470\n",
      "weighted avg       0.61      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[162  10   4   7   1  23   3]\n",
      " [  2 158  20   8   1  21   0]\n",
      " [  4   2 175  12   1  16   0]\n",
      " [  8  18  17 142   1  21   3]\n",
      " [ 58  52  25  26  32  16   1]\n",
      " [  6  18   9  29   1 128  19]\n",
      " [  4  14   3   9   0  89  91]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.77      0.71       210\n",
      "           2       0.58      0.75      0.66       210\n",
      "           3       0.69      0.83      0.76       210\n",
      "           4       0.61      0.68      0.64       210\n",
      "           5       0.86      0.15      0.26       210\n",
      "           6       0.41      0.61      0.49       210\n",
      "           7       0.78      0.43      0.56       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.66      0.60      0.58      1470\n",
      "weighted avg       0.66      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[160  12   6   4   2  25   1]\n",
      " [  3 158  21   8   1  19   0]\n",
      " [  2   2 176  13   1  16   0]\n",
      " [  6  19  18 145   1  19   2]\n",
      " [ 53  57  30  24  29  16   1]\n",
      " [  5  20  10  25   0 130  20]\n",
      " [  5  16   2  11   0  89  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.76      0.72       210\n",
      "           2       0.56      0.75      0.64       210\n",
      "           3       0.67      0.84      0.74       210\n",
      "           4       0.63      0.69      0.66       210\n",
      "           5       0.85      0.14      0.24       210\n",
      "           6       0.41      0.62      0.50       210\n",
      "           7       0.78      0.41      0.54       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.66      0.60      0.58      1470\n",
      "weighted avg       0.66      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after MinMax Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[155   2   9  17  20   3   4]\n",
      " [ 10  97  89   7   4   3   0]\n",
      " [  4   6 193   5   0   1   1]\n",
      " [ 33  17  41 106   9   3   1]\n",
      " [ 69  12  13  49  59   6   2]\n",
      " [ 27  28  49  25   3  37  41]\n",
      " [ 13  10   7  10   2  28 140]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.74      0.60       210\n",
      "           2       0.56      0.46      0.51       210\n",
      "           3       0.48      0.92      0.63       210\n",
      "           4       0.48      0.50      0.49       210\n",
      "           5       0.61      0.28      0.38       210\n",
      "           6       0.46      0.18      0.25       210\n",
      "           7       0.74      0.67      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.51      1470\n",
      "weighted avg       0.55      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after MinMax Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after MinMax Scaling is: 0.7170068027210884\n",
      "Confusion Matrix of SVM is:\n",
      " [[157   2   2   7  22  18   2]\n",
      " [  2 155  18   8  11  16   0]\n",
      " [  2   1 185   6   1  15   0]\n",
      " [  5  13  22 131  15  20   4]\n",
      " [ 30  10  10   7 146   4   3]\n",
      " [  4  11   5  15   6 132  37]\n",
      " [  1   5   0  10   4  42 148]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.76       210\n",
      "           2       0.79      0.74      0.76       210\n",
      "           3       0.76      0.88      0.82       210\n",
      "           4       0.71      0.62      0.66       210\n",
      "           5       0.71      0.70      0.70       210\n",
      "           6       0.53      0.63      0.58       210\n",
      "           7       0.76      0.70      0.73       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after MinMax Scaling is: 0.4238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[103   1  92   0   9   4   1]\n",
      " [  0  44 155   1   7   3   0]\n",
      " [  0   0 207   1   1   1   0]\n",
      " [  0   4 106  89   5   5   1]\n",
      " [ 49  20  47  10  74   5   5]\n",
      " [  1   5 144   8   1  34  17]\n",
      " [  1   2 111   4   1  19  72]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.49      0.57       210\n",
      "           2       0.58      0.21      0.31       210\n",
      "           3       0.24      0.99      0.39       210\n",
      "           4       0.79      0.42      0.55       210\n",
      "           5       0.76      0.35      0.48       210\n",
      "           6       0.48      0.16      0.24       210\n",
      "           7       0.75      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.61      0.42      0.43      1470\n",
      "weighted avg       0.61      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after MinMax Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[129   1   1   6  53  18   2]\n",
      " [  1 141  11  11  29  17   0]\n",
      " [  0   0 171  13  11  15   0]\n",
      " [  0   5  12 118  43  27   5]\n",
      " [ 16   6   7   9 163   2   7]\n",
      " [  1   6   2  11  24 113  53]\n",
      " [  0   0   0   3  22  27 158]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.61      0.72       210\n",
      "           2       0.89      0.67      0.76       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.69      0.56      0.62       210\n",
      "           5       0.47      0.78      0.59       210\n",
      "           6       0.52      0.54      0.53       210\n",
      "           7       0.70      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after MinMax Scaling is: 0.7244897959183674\n",
      "Confusion Matrix of SVM is:\n",
      " [[164   1   0   8  16  20   1]\n",
      " [  0 138  42   6   7  17   0]\n",
      " [  0   0 182   9   1  18   0]\n",
      " [  0   6  21 144   5  31   3]\n",
      " [ 29  11  13   7 140   3   7]\n",
      " [  0   5   3  16   5 147  34]\n",
      " [  0   3   0   4   3  50 150]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.78      0.81       210\n",
      "           2       0.84      0.66      0.74       210\n",
      "           3       0.70      0.87      0.77       210\n",
      "           4       0.74      0.69      0.71       210\n",
      "           5       0.79      0.67      0.72       210\n",
      "           6       0.51      0.70      0.59       210\n",
      "           7       0.77      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.74      0.72      0.73      1470\n",
      "weighted avg       0.74      0.72      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.2\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85 125   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [ 55 155   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.16      1.00      0.27       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.11      0.20      0.11      1470\n",
      "weighted avg       0.11      0.20      0.11      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.254421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155  55   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [109  90   0   0  11   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.74      0.65       210\n",
      "           2       0.17      0.99      0.30       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       1.00      0.05      0.10       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.25      0.25      0.15      1470\n",
      "weighted avg       0.25      0.25      0.15      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.35034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0   0  52   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   0  17   0   0 192   0]\n",
      " [100   0  26   0  20  64   0]\n",
      " [  0   0   2   0   0 208   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.57      0.63      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.91      0.10      0.17       210\n",
      "           6       0.22      0.99      0.36       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.33      0.35      0.26      1470\n",
      "weighted avg       0.33      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0  30  22   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   1  16   0   0 192   0]\n",
      " [ 86   4  22   0  34  63   1]\n",
      " [  0   0   2   0   0 204   4]\n",
      " [  2   0   0   0   0 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.74      0.68       210\n",
      "           2       0.86      0.14      0.24       210\n",
      "           3       0.68      0.63      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.94      0.16      0.28       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.90      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.37      1470\n",
      "weighted avg       0.61      0.41      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[137   0   1   0  18  54   0]\n",
      " [  0  70  17   0   2 121   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   5  13   0   1 191   0]\n",
      " [ 75  13  22   0  46  54   0]\n",
      " [  0   1   1   0   0 204   4]\n",
      " [  2   1   0   0   0 162  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.65      0.65       210\n",
      "           2       0.78      0.33      0.47       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.22      0.33       210\n",
      "           6       0.24      0.97      0.38       210\n",
      "           7       0.92      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.57      0.43      0.41      1470\n",
      "weighted avg       0.57      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0 110  17   0   3  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   7  12   0   0 190   0]\n",
      " [ 81  19  22   0  43  45   0]\n",
      " [  0   3   1   0   0 202   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.74      0.69       210\n",
      "           2       0.79      0.52      0.63       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.93      0.20      0.34       210\n",
      "           6       0.25      0.96      0.40       210\n",
      "           7       0.92      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.61      0.47      0.44      1470\n",
      "weighted avg       0.61      0.47      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4816326530612245\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0 106  17   3   4  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   4   8   6   1 188   2]\n",
      " [ 75  18  22   0  50  45   0]\n",
      " [  0   2   1   1   0 188  18]\n",
      " [  2   1   0   0   0 136  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.74      0.70       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.73      0.63      0.68       210\n",
      "           4       0.60      0.03      0.05       210\n",
      "           5       0.91      0.24      0.38       210\n",
      "           6       0.24      0.90      0.38       210\n",
      "           7       0.78      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.68      0.48      0.47      1470\n",
      "weighted avg       0.68      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1  54   0   0   0]\n",
      " [  0 104  16  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   3   8 191   3   0   4]\n",
      " [ 68  16  21  44  60   0   1]\n",
      " [  0   2   1 185   0   0  22]\n",
      " [  2   1   0 110   0   1  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.71       210\n",
      "           2       0.83      0.50      0.62       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.26      0.91      0.40       210\n",
      "           5       0.86      0.29      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.78      0.46      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.59      0.50      0.49      1470\n",
      "weighted avg       0.59      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   0   1  54   2   0   0]\n",
      " [  1 104  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   5   8 191   1   0   4]\n",
      " [ 63  16  18  44  69   0   0]\n",
      " [  0   2   1 181   0   0  26]\n",
      " [  2   1   0  92   0   1 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.71       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.26      0.91      0.41       210\n",
      "           5       0.87      0.33      0.48       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.60      0.52      0.51      1470\n",
      "weighted avg       0.60      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1  44   4   0   0]\n",
      " [  0 105  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  0   5   8 191   2   0   4]\n",
      " [ 60  17  18  38  76   0   1]\n",
      " [  0   2   1 181   1   0  25]\n",
      " [  2   1   0  93   0   2 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.77      0.74       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.27      0.91      0.42       210\n",
      "           5       0.84      0.36      0.51       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.60      0.53      0.52      1470\n",
      "weighted avg       0.60      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1   0   4  44   0]\n",
      " [  0 106  24   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  21   5   2 173   4]\n",
      " [ 59  17  18   0  78  38   0]\n",
      " [  0   2   3   0   1 178  26]\n",
      " [  2   1   1   1   2  93 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.77      0.75       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.69      0.71      0.70       210\n",
      "           4       0.56      0.02      0.05       210\n",
      "           5       0.83      0.37      0.51       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.79      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.67      0.54      0.52      1470\n",
      "weighted avg       0.67      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  20  15   2 164   4]\n",
      " [ 55  17  18   0  82  38   0]\n",
      " [  0   3   3   0   2 178  24]\n",
      " [  2   1   1   1   0  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.79      0.07      0.13       210\n",
      "           5       0.83      0.39      0.53       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.71      0.55      0.55      1470\n",
      "weighted avg       0.71      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  1   5  20  12   4 164   4]\n",
      " [ 55  17  18   0  81  38   1]\n",
      " [  0   2   3   0   1 176  28]\n",
      " [  2   1   1   1   3  88 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.74       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.75      0.06      0.11       210\n",
      "           5       0.79      0.39      0.52       210\n",
      "           6       0.28      0.84      0.41       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.54      1470\n",
      "weighted avg       0.70      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   4   7  69   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  19  34   4 144   4]\n",
      " [ 53  20  18   3  81  35   0]\n",
      " [  0   2   3   1   1 175  28]\n",
      " [  2   1   1   2   1  87 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.80      0.55      0.65       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.77      0.16      0.27       210\n",
      "           5       0.81      0.39      0.52       210\n",
      "           6       0.29      0.83      0.42       210\n",
      "           7       0.78      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   4   7  69   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  18  37   2 144   4]\n",
      " [ 55  19  16   3  81  35   1]\n",
      " [  0   2   3   1   0 178  26]\n",
      " [  2   1   1   2   3  88 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.81      0.55      0.65       210\n",
      "           3       0.74      0.71      0.72       210\n",
      "           4       0.79      0.18      0.29       210\n",
      "           5       0.82      0.39      0.52       210\n",
      "           6       0.29      0.85      0.43       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.71      0.57      0.57      1470\n",
      "weighted avg       0.71      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.573469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[160   0   2   0   5  43   0]\n",
      " [  0 116  19   4   7  64   0]\n",
      " [  0   0 157   0   0  53   0]\n",
      " [  0   5  24  36   3 139   3]\n",
      " [ 53  22  16   3  81  35   0]\n",
      " [  0   2   3   1   2 177  25]\n",
      " [  2   1   1   2   0  88 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.79      0.55      0.65       210\n",
      "           3       0.71      0.75      0.73       210\n",
      "           4       0.78      0.17      0.28       210\n",
      "           5       0.83      0.39      0.53       210\n",
      "           6       0.30      0.84      0.44       210\n",
      "           7       0.81      0.55      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.71      0.57      0.58      1470\n",
      "weighted avg       0.71      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   2   0   6  43   0]\n",
      " [  0 127  17   4   8  54   0]\n",
      " [  0   0 157   0   0  53   0]\n",
      " [  0   6  23  36   2 139   4]\n",
      " [ 53  23  16   4  82  32   0]\n",
      " [  0   2   3   1   1 178  25]\n",
      " [  2   1   1   2   0  91 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.80      0.60      0.69       210\n",
      "           3       0.72      0.75      0.73       210\n",
      "           4       0.77      0.17      0.28       210\n",
      "           5       0.83      0.39      0.53       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.80      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.71      0.58      0.58      1470\n",
      "weighted avg       0.71      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   2   0  11  43   0]\n",
      " [  0 127  17   5   8  53   0]\n",
      " [  0   0 156   2   0  52   0]\n",
      " [  1   5  24  41   4 131   4]\n",
      " [ 53  22  16   4  84  31   0]\n",
      " [  0   2   3   1   1 178  25]\n",
      " [  2   1   1   2   0  91 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.71      0.74      0.73       210\n",
      "           4       0.75      0.20      0.31       210\n",
      "           5       0.78      0.40      0.53       210\n",
      "           6       0.31      0.85      0.45       210\n",
      "           7       0.80      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.58      1470\n",
      "weighted avg       0.70      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   2   0   8  43   0]\n",
      " [  0 125  17   5  10  53   0]\n",
      " [  0   0 166   0   0  44   0]\n",
      " [  1   4  22  45   4 131   3]\n",
      " [ 50  21  19   7  86  27   0]\n",
      " [  0   2   3   2   0 178  25]\n",
      " [  2   1   1   2   3  91 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.82      0.60      0.69       210\n",
      "           3       0.72      0.79      0.75       210\n",
      "           4       0.74      0.21      0.33       210\n",
      "           5       0.77      0.41      0.54       210\n",
      "           6       0.31      0.85      0.46       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[158   0   2   0   7  43   0]\n",
      " [  0 127  17   6   9  51   0]\n",
      " [  0   0 167   4   0  39   0]\n",
      " [  1   5  21  56   4 120   3]\n",
      " [ 50  21  18   5  88  27   1]\n",
      " [  0   2   3   2   1 178  24]\n",
      " [  2   1   1   2   3  90 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.73      0.80      0.76       210\n",
      "           4       0.75      0.27      0.39       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.32      0.85      0.47       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.71      0.60      0.61      1470\n",
      "weighted avg       0.71      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[158   0   2   0   7  43   0]\n",
      " [  0 127  17   6   9  51   0]\n",
      " [  0   0 167   4   0  39   0]\n",
      " [  1   5  21  56   4 120   3]\n",
      " [ 50  21  18   5  88  27   1]\n",
      " [  0   2   3   2   1 178  24]\n",
      " [  2   1   1   2   3  90 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.73      0.80      0.76       210\n",
      "           4       0.75      0.27      0.39       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.32      0.85      0.47       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.71      0.60      0.61      1470\n",
      "weighted avg       0.71      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   4   1  19   5  23   5]\n",
      " [  1  97  49  14   5  43   1]\n",
      " [  0   0 158   7   0  45   0]\n",
      " [  1  10  24 114   1  56   4]\n",
      " [ 59  24  33  30  46   6  12]\n",
      " [  0   7   4  28   1 132  38]\n",
      " [  0   1   0  17   0  46 146]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.46      0.55       210\n",
      "           3       0.59      0.75      0.66       210\n",
      "           4       0.50      0.54      0.52       210\n",
      "           5       0.79      0.22      0.34       210\n",
      "           6       0.38      0.63      0.47       210\n",
      "           7       0.71      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.57      1470\n",
      "weighted avg       0.62      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   5   2  11  12  27   6]\n",
      " [  1  97  50  12  17  33   0]\n",
      " [  0   0 156   7   0  47   0]\n",
      " [  0  14  24 103   3  62   4]\n",
      " [ 56  23  28  19  57  13  14]\n",
      " [  0   8   5  16   2 138  41]\n",
      " [  0   2   0   4   0  50 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.65      0.46      0.54       210\n",
      "           3       0.59      0.74      0.66       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.63      0.27      0.38       210\n",
      "           6       0.37      0.66      0.48       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.57      1470\n",
      "weighted avg       0.61      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   1  10   6  29   6]\n",
      " [  1  98  48  12  16  35   0]\n",
      " [  0   0 135   6   0  69   0]\n",
      " [  0  11  15 103   4  73   4]\n",
      " [ 62  22  30  19  52  12  13]\n",
      " [  0   7   2  11   3 145  42]\n",
      " [  0   1   0   6   0  49 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.47      0.55       210\n",
      "           3       0.58      0.64      0.61       210\n",
      "           4       0.62      0.49      0.55       210\n",
      "           5       0.64      0.25      0.36       210\n",
      "           6       0.35      0.69      0.47       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.61      0.57      0.57      1470\n",
      "weighted avg       0.61      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.5959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   2   8  11  30   4]\n",
      " [  0 105  50   7  12  36   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  13  25 100   7  61   4]\n",
      " [ 56  20  25  16  69  12  12]\n",
      " [  0   9   5  14   2 141  39]\n",
      " [  0   1   0   5   0  49 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.71      0.72       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.59      0.74      0.66       210\n",
      "           4       0.64      0.48      0.55       210\n",
      "           5       0.68      0.33      0.44       210\n",
      "           6       0.37      0.67      0.48       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.63      0.60      0.59      1470\n",
      "weighted avg       0.63      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   1   8   9  32   2]\n",
      " [  1 136  20  10   9  34   0]\n",
      " [  0   0 149   6   0  55   0]\n",
      " [  0  16  21 102   4  63   4]\n",
      " [ 53  22  23  14  74  12  12]\n",
      " [  0  10   4  13   1 141  41]\n",
      " [  1   2   0   6   1  45 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.73       210\n",
      "           2       0.71      0.65      0.68       210\n",
      "           3       0.68      0.71      0.70       210\n",
      "           4       0.64      0.49      0.55       210\n",
      "           5       0.76      0.35      0.48       210\n",
      "           6       0.37      0.67      0.48       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.66      0.62      0.62      1470\n",
      "weighted avg       0.66      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6265306122448979\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   5   2   8   8  29   2]\n",
      " [  0 138  21   9   9  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  17  23 101   5  61   3]\n",
      " [ 59  20  20  15  74  12  10]\n",
      " [  0   9   5  12   1 140  43]\n",
      " [  1   2   0   6   1  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.69      0.74      0.71       210\n",
      "           4       0.64      0.48      0.55       210\n",
      "           5       0.76      0.35      0.48       210\n",
      "           6       0.38      0.67      0.49       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   6   2   9  11  28   2]\n",
      " [  0 138  21   8  10  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  16  19 108   6  58   3]\n",
      " [ 52  21  18  19  78  11  11]\n",
      " [  0   8   5  13   3 139  42]\n",
      " [  0   2   0   6   1  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.72      0.37      0.49       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   6   2   8   6  29   1]\n",
      " [  0 136  22   9  11  32   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  13  19 109   5  60   4]\n",
      " [ 55  21  23  14  76  10  11]\n",
      " [  0   8   5  11   2 142  42]\n",
      " [  0   2   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.73      0.65      0.69       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.67      0.52      0.58       210\n",
      "           5       0.75      0.36      0.49       210\n",
      "           6       0.40      0.68      0.50       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6448979591836734\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   5   1   8   7  31   0]\n",
      " [  0 139  21   9   6  35   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  12  19 112   7  57   3]\n",
      " [ 52  23  25  15  76  10   9]\n",
      " [  0   8   5  13   2 140  42]\n",
      " [  1   2   0   5   1  43 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.77      0.36      0.49       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   5   1   9   7  29   1]\n",
      " [  0 141  22   9   5  33   0]\n",
      " [  0   0 158   7   0  45   0]\n",
      " [  0  15  20 107   5  60   3]\n",
      " [ 53  21  19  15  85   7  10]\n",
      " [  0  10   3  12   1 141  43]\n",
      " [  1   2   0   5   0  43 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.71      0.75      0.73       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       0.83      0.40      0.54       210\n",
      "           6       0.39      0.67      0.50       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   5   2   8  10  30   0]\n",
      " [  0 138  21  10   8  33   0]\n",
      " [  0   0 165   6   0  39   0]\n",
      " [  0  13  19 113   4  58   3]\n",
      " [ 56  23  25  14  73  10   9]\n",
      " [  0   8   4  12   2 140  44]\n",
      " [  1   2   0   5   1  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.67      0.54      0.60       210\n",
      "           5       0.74      0.35      0.47       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.74      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   5   1   8   8  31   1]\n",
      " [  0 141  21   9   6  33   0]\n",
      " [  0   0 158   6   0  46   0]\n",
      " [  0  11  16 118   4  58   3]\n",
      " [ 56  25  22  14  76   9   8]\n",
      " [  0   8   4  12   2 141  43]\n",
      " [  1   2   0   5   1  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.71      0.75      0.73       210\n",
      "           4       0.69      0.56      0.62       210\n",
      "           5       0.78      0.36      0.50       210\n",
      "           6       0.39      0.67      0.49       210\n",
      "           7       0.74      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   6   2   9   7  29   0]\n",
      " [  0 140  21  10   7  32   0]\n",
      " [  0   0 164   7   0  39   0]\n",
      " [  0   9  23 113   5  57   3]\n",
      " [ 55  22  21  12  83   7  10]\n",
      " [  0   6   5  13   3 140  43]\n",
      " [  1   1   1   5   2  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.69      0.78      0.73       210\n",
      "           4       0.67      0.54      0.60       210\n",
      "           5       0.78      0.40      0.52       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.73      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   5   2   9  10  29   0]\n",
      " [  0 141  20   9   8  32   0]\n",
      " [  0   0 165   6   0  39   0]\n",
      " [  0  12  19 114   6  56   3]\n",
      " [ 52  20  20  16  86   8   8]\n",
      " [  0  10   4  13   1 140  42]\n",
      " [  1   1   0   5   2  48 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.74       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.72      0.79      0.75       210\n",
      "           4       0.66      0.54      0.60       210\n",
      "           5       0.76      0.41      0.53       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.74      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   5   2   9   4  29   0]\n",
      " [  0 140  23  11   6  30   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  10  19 116   6  56   3]\n",
      " [ 57  25  22  15  77   7   7]\n",
      " [  0   7   4  14   1 142  42]\n",
      " [  2   2   0   6   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.77      0.75       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.65      0.55      0.60       210\n",
      "           5       0.82      0.37      0.51       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.65      1470\n",
      "weighted avg       0.69      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   5   2   9   7  29   0]\n",
      " [  0 141  21   9   8  31   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  11  19 120   5  52   3]\n",
      " [ 56  23  23  15  78   8   7]\n",
      " [  0  10   4  15   1 140  40]\n",
      " [  2   2   0   6   0  47 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.71      0.79      0.74       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.79      0.37      0.50       210\n",
      "           6       0.41      0.67      0.50       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   5   2   8   6  30   0]\n",
      " [  0 142  21   8   8  31   0]\n",
      " [  0   0 164   7   1  38   0]\n",
      " [  0  10  20 121   4  52   3]\n",
      " [ 53  23  21  17  78   9   9]\n",
      " [  0   8   5  14   1 144  38]\n",
      " [  1   2   1   6   1  47 152]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.76      0.75       210\n",
      "           2       0.75      0.68      0.71       210\n",
      "           3       0.70      0.78      0.74       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.79      0.37      0.50       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.75      0.72      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.65      1470\n",
      "weighted avg       0.69      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   5   2   9   7  29   0]\n",
      " [  0 144  18   8   8  32   0]\n",
      " [  0   0 165   8   0  37   0]\n",
      " [  0  13  19 118   4  53   3]\n",
      " [ 53  23  19  20  78   9   8]\n",
      " [  0   9   4  12   2 144  39]\n",
      " [  2   2   0   6   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.73      0.69      0.71       210\n",
      "           3       0.73      0.79      0.76       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.79      0.37      0.50       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.65      1470\n",
      "weighted avg       0.69      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   5   2   9   6  29   0]\n",
      " [  0 149  16   5   6  34   0]\n",
      " [  0   0 165   8   0  37   0]\n",
      " [  0  12  19 118   5  53   3]\n",
      " [ 54  24  21  18  78   8   7]\n",
      " [  0   9   4  13   1 144  39]\n",
      " [  1   2   1   5   1  45 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.74      0.71      0.73       210\n",
      "           3       0.72      0.79      0.75       210\n",
      "           4       0.67      0.56      0.61       210\n",
      "           5       0.80      0.37      0.51       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   5   2   9   8  28   0]\n",
      " [  0 149  16   9   5  31   0]\n",
      " [  0   0 165   8   0  37   0]\n",
      " [  0  11  20 120   3  52   4]\n",
      " [ 53  28  22  19  76   6   6]\n",
      " [  0   9   4  13   1 145  38]\n",
      " [  1   2   1   5   1  50 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.73      0.71      0.72       210\n",
      "           3       0.72      0.79      0.75       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.81      0.36      0.50       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.76      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.65      1470\n",
      "weighted avg       0.69      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   5   4   6   9  22   1]\n",
      " [  1 167  13   7   4  18   0]\n",
      " [  2   1 170   7   0  30   0]\n",
      " [  3  10  14 144   2  34   3]\n",
      " [ 54  32  17  15  81   6   5]\n",
      " [  2  13   4  12   2 139  38]\n",
      " [  2   3   0   7   1  46 151]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.78      0.75       210\n",
      "           2       0.72      0.80      0.76       210\n",
      "           3       0.77      0.81      0.79       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.82      0.39      0.52       210\n",
      "           6       0.47      0.66      0.55       210\n",
      "           7       0.76      0.72      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after MinMax Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[158   2   1   3  40   4   2]\n",
      " [ 13 152  18   7  18   2   0]\n",
      " [ 15   4 180   9   0   2   0]\n",
      " [ 19   6  20 144   8  10   3]\n",
      " [ 29  16  17  16 123   5   4]\n",
      " [ 43  14   4  20   8  75  46]\n",
      " [  6   3   0   2   1  27 171]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.75      0.64       210\n",
      "           2       0.77      0.72      0.75       210\n",
      "           3       0.75      0.86      0.80       210\n",
      "           4       0.72      0.69      0.70       210\n",
      "           5       0.62      0.59      0.60       210\n",
      "           6       0.60      0.36      0.45       210\n",
      "           7       0.76      0.81      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after MinMax Scaling is: 0.7421768707482993\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[159   1   1   4  35   9   1]\n",
      " [  0 161  10  11   9  18   1]\n",
      " [  1   1 183  12   0  13   0]\n",
      " [  1   9  17 151  12  16   4]\n",
      " [ 21  11   9  15 148   0   6]\n",
      " [  5  10   5  24   6 122  38]\n",
      " [  2   1   0   5   2  33 167]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.76      0.80       210\n",
      "           2       0.83      0.77      0.80       210\n",
      "           3       0.81      0.87      0.84       210\n",
      "           4       0.68      0.72      0.70       210\n",
      "           5       0.70      0.70      0.70       210\n",
      "           6       0.58      0.58      0.58       210\n",
      "           7       0.77      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   6   4   5  10  22   2]\n",
      " [  4 160  16   7   8  15   0]\n",
      " [  4   5 179   4   1  17   0]\n",
      " [ 23  17  17 125   1  26   1]\n",
      " [ 68  32  30  15  45  18   2]\n",
      " [ 19  19   4  15   2 125  26]\n",
      " [  8  12   0   8   0  63 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.77      0.65       210\n",
      "           2       0.64      0.76      0.69       210\n",
      "           3       0.72      0.85      0.78       210\n",
      "           4       0.70      0.60      0.64       210\n",
      "           5       0.67      0.21      0.32       210\n",
      "           6       0.44      0.60      0.50       210\n",
      "           7       0.79      0.57      0.66       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.61      1470\n",
      "weighted avg       0.64      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   7   2   4  11  32   0]\n",
      " [  4 160  15   7   7  17   0]\n",
      " [  5   1 183   5   1  15   0]\n",
      " [ 21  14  20 128   1  25   1]\n",
      " [ 71  31  30  21  39  17   1]\n",
      " [ 12  20   5  15   2 131  25]\n",
      " [  8   9   2   3   0  79 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.73      0.64       210\n",
      "           2       0.66      0.76      0.71       210\n",
      "           3       0.71      0.87      0.78       210\n",
      "           4       0.70      0.61      0.65       210\n",
      "           5       0.64      0.19      0.29       210\n",
      "           6       0.41      0.62      0.50       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.60      1470\n",
      "weighted avg       0.64      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6136054421768707\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   7   2   5  11  30   1]\n",
      " [  4 153  20   6   8  19   0]\n",
      " [  3   2 185   5   1  14   0]\n",
      " [ 17  16  23 130   3  19   2]\n",
      " [ 71  32  30  19  41  16   1]\n",
      " [ 10  20   4  17   1 130  28]\n",
      " [  6  12   3   7   0  73 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.73      0.65       210\n",
      "           2       0.63      0.73      0.68       210\n",
      "           3       0.69      0.88      0.78       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.63      0.20      0.30       210\n",
      "           6       0.43      0.62      0.51       210\n",
      "           7       0.77      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.60      1470\n",
      "weighted avg       0.63      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   9   1   4  10  33   0]\n",
      " [  5 153  21   6   7  18   0]\n",
      " [  2   3 185   6   0  14   0]\n",
      " [ 15  16  23 130   1  23   2]\n",
      " [ 71  34  32  17  36  18   2]\n",
      " [  4  21   5  15   1 140  24]\n",
      " [  4  14   1   5   0  77 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.73      0.66       210\n",
      "           2       0.61      0.73      0.67       210\n",
      "           3       0.69      0.88      0.77       210\n",
      "           4       0.71      0.62      0.66       210\n",
      "           5       0.65      0.17      0.27       210\n",
      "           6       0.43      0.67      0.53       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.60      1470\n",
      "weighted avg       0.64      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.617687074829932\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   6   1   4  12  33   1]\n",
      " [  4 152  23   5   6  20   0]\n",
      " [  2   2 184   5   0  17   0]\n",
      " [ 17  13  24 129   1  24   2]\n",
      " [ 69  33  34  19  36  17   2]\n",
      " [  9  16   5  12   1 141  26]\n",
      " [  7  12   2   5   0  71 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.73      0.65       210\n",
      "           2       0.65      0.72      0.68       210\n",
      "           3       0.67      0.88      0.76       210\n",
      "           4       0.72      0.61      0.66       210\n",
      "           5       0.64      0.17      0.27       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.60      1470\n",
      "weighted avg       0.64      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   5   2   5  10  30   1]\n",
      " [  3 149  23   4   6  25   0]\n",
      " [  1   0 185   5   0  19   0]\n",
      " [ 12  14  25 131   0  26   2]\n",
      " [ 69  32  34  22  29  21   3]\n",
      " [  2  13   7  19   0 149  20]\n",
      " [  4  15   1   5   0  81 104]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.75      0.69       210\n",
      "           2       0.65      0.71      0.68       210\n",
      "           3       0.67      0.88      0.76       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.64      0.14      0.23       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.80      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.59      1470\n",
      "weighted avg       0.64      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after MinMax Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[156   2   9  15  22   2   4]\n",
      " [  7  98  89   8   5   3   0]\n",
      " [  5   6 193   4   0   1   1]\n",
      " [ 17  18  41 119   8   4   3]\n",
      " [ 74  12  13  48  51   7   5]\n",
      " [ 17  31  47  30   5  45  35]\n",
      " [ 10  13   4   7   3  19 154]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.74      0.63       210\n",
      "           2       0.54      0.47      0.50       210\n",
      "           3       0.49      0.92      0.64       210\n",
      "           4       0.52      0.57      0.54       210\n",
      "           5       0.54      0.24      0.34       210\n",
      "           6       0.56      0.21      0.31       210\n",
      "           7       0.76      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.53      1470\n",
      "weighted avg       0.56      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after MinMax Scaling is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after MinMax Scaling is: 0.726530612244898\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   3   0   8  29   9   3]\n",
      " [  1 167  10   9   6  17   0]\n",
      " [  1   2 185   5   1  16   0]\n",
      " [  6  16  18 140  10  18   2]\n",
      " [ 27  13  12  16 135   3   4]\n",
      " [  6  12   4  20   6 124  38]\n",
      " [  4   3   0   7   2  35 159]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.77       210\n",
      "           2       0.77      0.80      0.78       210\n",
      "           3       0.81      0.88      0.84       210\n",
      "           4       0.68      0.67      0.67       210\n",
      "           5       0.71      0.64      0.68       210\n",
      "           6       0.56      0.59      0.57       210\n",
      "           7       0.77      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after MinMax Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of SVM is:\n",
      " [[128   2   0   9  34  36   1]\n",
      " [  0 157   9  13   7  24   0]\n",
      " [  0   4 178   7   2  19   0]\n",
      " [  7   6   9 157   3  25   3]\n",
      " [ 18  14  10  29 113  23   3]\n",
      " [  4   7   1  12   5 151  30]\n",
      " [  0   1   0   5   1  63 140]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.61      0.70       210\n",
      "           2       0.82      0.75      0.78       210\n",
      "           3       0.86      0.85      0.85       210\n",
      "           4       0.68      0.75      0.71       210\n",
      "           5       0.68      0.54      0.60       210\n",
      "           6       0.44      0.72      0.55       210\n",
      "           7       0.79      0.67      0.72       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after MinMax Scaling is: 0.7326530612244898\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   0   0   7  38  17  10]\n",
      " [  0 156   7  14   9  19   5]\n",
      " [  0   5 177   7   2  18   1]\n",
      " [  1   4   9 155   4  25  12]\n",
      " [ 15   7   8  17 143   4  16]\n",
      " [  1   5   1  15   8 120  60]\n",
      " [  0   0   0   3   1  18 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.66      0.76       210\n",
      "           2       0.88      0.74      0.81       210\n",
      "           3       0.88      0.84      0.86       210\n",
      "           4       0.71      0.74      0.72       210\n",
      "           5       0.70      0.68      0.69       210\n",
      "           6       0.54      0.57      0.56       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.75      0.73      0.73      1470\n",
      "weighted avg       0.75      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after MinMax Scaling is: 0.7442176870748299\n",
      "Confusion Matrix of SVM is:\n",
      " [[168   1   0   7  21  10   3]\n",
      " [  0 166  18   7   2  17   0]\n",
      " [  0   1 182   8   0  19   0]\n",
      " [  0  13  17 153   4  19   4]\n",
      " [ 28  14  22  17 120   4   5]\n",
      " [  1   6   3  25   2 132  41]\n",
      " [  2   2   0   8   0  25 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.80      0.82       210\n",
      "           2       0.82      0.79      0.80       210\n",
      "           3       0.75      0.87      0.81       210\n",
      "           4       0.68      0.73      0.70       210\n",
      "           5       0.81      0.57      0.67       210\n",
      "           6       0.58      0.63      0.61       210\n",
      "           7       0.77      0.82      0.79       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.75      0.74      0.74      1470\n",
      "weighted avg       0.75      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.20136054421768707\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [124   0  86   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.16      0.20      0.12      1470\n",
      "weighted avg       0.16      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   1   0   0 154   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.25      0.26      0.19      1470\n",
      "weighted avg       0.25      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   0   0   0  55  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 68   0   1   0  52  89   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.52       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.25      0.33       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.25      1470\n",
      "weighted avg       0.32      0.30      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.354421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   0   0  55  77   0   0]\n",
      " [  0   0   2 206   2   0   0]\n",
      " [  0   0  86 124   0   0   0]\n",
      " [  0   0   1 208   1   0   0]\n",
      " [ 16   0   1  86 104   0   3]\n",
      " [  0   0   0 206   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.37      0.51       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.20      0.99      0.33       210\n",
      "           5       0.56      0.50      0.53       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.49      0.35      0.33      1470\n",
      "weighted avg       0.49      0.35      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  58   2   0   2 148   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 49   5   1   0  72  81   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   0   0   0   2 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.75      0.28      0.40       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.34      0.47       210\n",
      "           6       0.21      0.97      0.34       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.40      1470\n",
      "weighted avg       0.61      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  92   2   0   2 114   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 44  17   1   0  77  69   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.63      0.69       210\n",
      "           2       0.74      0.44      0.55       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.37      0.49       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.61      0.43      0.43      1470\n",
      "weighted avg       0.61      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   0   0  36  50   0]\n",
      " [  0 131   2   0   2  75   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   6   1   0   1 202   0]\n",
      " [ 34  22   1   0  87  64   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.68      0.41      0.51       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.61      0.46      0.45      1470\n",
      "weighted avg       0.61      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   1   0  36  49   0]\n",
      " [  0 130  21   1   2  56   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   6  17   0   1 186   0]\n",
      " [ 29  22  19   0  92  46   2]\n",
      " [  0   3   2   0   0 201   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.26      0.96      0.41       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.59      0.49      0.47      1470\n",
      "weighted avg       0.59      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.49183673469387756\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   0   0  36  49   0]\n",
      " [  0 147   3   1   3  56   0]\n",
      " [  0  30 102   0   0  78   0]\n",
      " [  0  22   1   0   1 184   2]\n",
      " [ 27  34   4   0  97  45   3]\n",
      " [  0   4   1   0   0 188  17]\n",
      " [  0   1   0   0   2 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.57      0.67       210\n",
      "           2       0.60      0.70      0.65       210\n",
      "           3       0.92      0.49      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.46      0.56       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.76      0.33      0.46       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.48      1470\n",
      "weighted avg       0.58      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   0  16  49   0]\n",
      " [  0 143   4   1   7  55   0]\n",
      " [  0  29 114   0   1  66   0]\n",
      " [  0  17   4   0   6 181   2]\n",
      " [ 56  28   4   0  74  46   2]\n",
      " [  0   4   2   0   0 187  17]\n",
      " [  2   1   0   0   0 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.67      0.69       210\n",
      "           2       0.63      0.68      0.65       210\n",
      "           3       0.89      0.54      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.71      0.35      0.47       210\n",
      "           6       0.26      0.89      0.40       210\n",
      "           7       0.77      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.57      0.50      0.48      1470\n",
      "weighted avg       0.57      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   5   0  49  36   0   0]\n",
      " [  0 143   4  56   7   0   0]\n",
      " [  0  29 114  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 31  25   4  46  99   1   4]\n",
      " [  0   4   2 182   0   1  21]\n",
      " [  0   1   0 111   2   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.65      0.68      0.66       210\n",
      "           3       0.89      0.54      0.67       210\n",
      "           4       0.26      0.87      0.40       210\n",
      "           5       0.66      0.47      0.55       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.62      0.51      0.50      1470\n",
      "weighted avg       0.62      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   5   0  50  46   0   0]\n",
      " [  0 131  15  56   8   0   0]\n",
      " [  0   0 143  66   1   0   0]\n",
      " [  0   7  11 182   6   0   4]\n",
      " [ 22  15  13  45 111   1   3]\n",
      " [  0   4   2 178   0   1  25]\n",
      " [  0   1   0  94   4   2 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.52      0.64       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.27      0.87      0.41       210\n",
      "           5       0.63      0.53      0.58       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.77      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.53      1470\n",
      "weighted avg       0.62      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   0  40  33   0   0]\n",
      " [  0 142   4  56   8   0   0]\n",
      " [  0  20 123  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 29  23   5  41 110   1   1]\n",
      " [  0   4   2 178   0   1  25]\n",
      " [  0   1   0  94   2   7 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.63      0.71       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.89      0.59      0.71       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.69      0.52      0.59       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   5   0  40  16   0   0]\n",
      " [  0 141   5  56   8   0   0]\n",
      " [  0  16 136  57   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 46  22   6  41  91   1   3]\n",
      " [  0   4   2 178   1   1  24]\n",
      " [  2   1   0  94   2   8 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.71      0.73       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.89      0.65      0.75       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.73      0.43      0.54       210\n",
      "           6       0.10      0.00      0.01       210\n",
      "           7       0.77      0.49      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134   5   0  40  31   0   0]\n",
      " [  0 141   7  54   8   0   0]\n",
      " [  0  12 147  50   1   0   0]\n",
      " [  0  13   8 179   6   0   4]\n",
      " [ 33  22   6  40 107   1   1]\n",
      " [  0   4   3 177   0   1  25]\n",
      " [  0   1   0  94   5   8 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.64      0.71       210\n",
      "           2       0.71      0.67      0.69       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.28      0.85      0.42       210\n",
      "           5       0.68      0.51      0.58       210\n",
      "           6       0.10      0.00      0.01       210\n",
      "           7       0.77      0.49      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.54      1470\n",
      "weighted avg       0.60      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   5   0  40  21   0   0]\n",
      " [  0 140   8  53   9   0   0]\n",
      " [  0  12 152  45   1   0   0]\n",
      " [  0  13  11 176   6   0   4]\n",
      " [ 40  22   6  41  99   1   1]\n",
      " [  0   4   3 177   0   1  25]\n",
      " [  1   1   0  94   5   4 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.69      0.73       210\n",
      "           2       0.71      0.67      0.69       210\n",
      "           3       0.84      0.72      0.78       210\n",
      "           4       0.28      0.84      0.42       210\n",
      "           5       0.70      0.47      0.56       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.61      0.56      0.54      1470\n",
      "weighted avg       0.61      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   5   0  40  19   0   0]\n",
      " [  0 137   7  53  13   0   0]\n",
      " [  0   8 152  45   5   0   0]\n",
      " [  0  13   9 175   9   0   4]\n",
      " [ 40  17   6  40 102   1   4]\n",
      " [  0   5   2 173   1   1  28]\n",
      " [  1   1   0  86   7   4 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.86      0.72      0.79       210\n",
      "           4       0.29      0.83      0.43       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.76      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.61      0.56      0.55      1470\n",
      "weighted avg       0.61      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   5   0   1  23  39   0]\n",
      " [  0 138   8   1  11  52   0]\n",
      " [  0   8 153   0   4  45   0]\n",
      " [  0  13  10  13   8 162   4]\n",
      " [ 37  16   6   2 106  39   4]\n",
      " [  0   4   2   0   1 176  27]\n",
      " [  1   1   0   0   2 100 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.85      0.73      0.79       210\n",
      "           4       0.76      0.06      0.11       210\n",
      "           5       0.68      0.50      0.58       210\n",
      "           6       0.29      0.84      0.43       210\n",
      "           7       0.75      0.50      0.60       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.56      1470\n",
      "weighted avg       0.70      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   5   0   1  23  39   0]\n",
      " [  0 139   7   2  11  51   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 36  16   6   4 108  36   4]\n",
      " [  0   5   2   1   1 176  25]\n",
      " [  1   1   0   1   1  94 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.78      0.17      0.27       210\n",
      "           5       0.70      0.51      0.59       210\n",
      "           6       0.30      0.84      0.44       210\n",
      "           7       0.78      0.53      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   1  25  39   0]\n",
      " [  0 148   7   3  11  41   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 38  19   6   6 106  33   2]\n",
      " [  0   5   2   1   2 176  24]\n",
      " [  1   1   0   1   1  98 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.68      0.50      0.58       210\n",
      "           6       0.31      0.84      0.45       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after MinMax Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   1  25  39   0]\n",
      " [  0 148   7   3  11  41   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 38  19   6   6 106  33   2]\n",
      " [  0   5   2   1   2 176  24]\n",
      " [  1   1   0   1   1  98 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.68      0.50      0.58       210\n",
      "           6       0.31      0.84      0.45       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   4   3  18   9  21   5]\n",
      " [  1 120  20  16   5  47   1]\n",
      " [  0   0 149  14   0  47   0]\n",
      " [  2   6  10 129   2  57   4]\n",
      " [ 60  27  17  33  46  13  14]\n",
      " [  0   4   8  33   0 127  38]\n",
      " [  0   1   1  16   0  45 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.74      0.57      0.65       210\n",
      "           3       0.72      0.71      0.71       210\n",
      "           4       0.50      0.61      0.55       210\n",
      "           5       0.74      0.22      0.34       210\n",
      "           6       0.36      0.60      0.45       210\n",
      "           7       0.70      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.59      1470\n",
      "weighted avg       0.64      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.617687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   4  19  10  21   5]\n",
      " [  1 130  16  10  15  37   1]\n",
      " [  0   0 158  12   0  40   0]\n",
      " [  1  10  13 127   3  52   4]\n",
      " [ 57  20  12  28  66  10  17]\n",
      " [  0   8   9  26   0 125  42]\n",
      " [  0   0   1  12   0  41 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70       210\n",
      "           2       0.75      0.62      0.68       210\n",
      "           3       0.74      0.75      0.75       210\n",
      "           4       0.54      0.60      0.57       210\n",
      "           5       0.70      0.31      0.43       210\n",
      "           6       0.38      0.60      0.47       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6197278911564625\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   2  15  11  22   5]\n",
      " [  0 128  17  13  15  36   1]\n",
      " [  0   0 161  13   0  36   0]\n",
      " [  1  12  11 131   6  45   4]\n",
      " [ 66  19  13  33  56   8  15]\n",
      " [  0   7   8  20   3 130  42]\n",
      " [  0   0   1   9   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.71       210\n",
      "           2       0.75      0.61      0.67       210\n",
      "           3       0.76      0.77      0.76       210\n",
      "           4       0.56      0.62      0.59       210\n",
      "           5       0.62      0.27      0.37       210\n",
      "           6       0.40      0.62      0.49       210\n",
      "           7       0.70      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   5   1   9  13  28   3]\n",
      " [  0 133  16  12  12  36   1]\n",
      " [  0   0 160  11   0  39   0]\n",
      " [  1  10  11 121  10  53   4]\n",
      " [ 55  20  10  22  79  11  13]\n",
      " [  0   6   6  18   3 134  43]\n",
      " [  0   0   1   8   1  40 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.72       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.67      0.38      0.48       210\n",
      "           6       0.39      0.64      0.49       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.636734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   4   1  10  14  27   4]\n",
      " [  0 129  17  14  16  33   1]\n",
      " [  0   0 164  12   0  34   0]\n",
      " [  1  11  11 123   8  53   3]\n",
      " [ 53  21  10  26  79   9  12]\n",
      " [  0   7   7  19   2 132  43]\n",
      " [  0   0   1   8   1  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.72       210\n",
      "           2       0.75      0.61      0.68       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.58      0.59      0.58       210\n",
      "           5       0.66      0.38      0.48       210\n",
      "           6       0.40      0.63      0.49       210\n",
      "           7       0.72      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   5   1  14  12  24   3]\n",
      " [  1 135  15  12  12  35   0]\n",
      " [  0   0 161  13   0  36   0]\n",
      " [  0  10   9 138   8  42   3]\n",
      " [ 62  20  10  26  70  10  12]\n",
      " [  0   6   5  21   3 131  44]\n",
      " [  0   0   1   9   1  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.71       210\n",
      "           2       0.77      0.64      0.70       210\n",
      "           3       0.80      0.77      0.78       210\n",
      "           4       0.59      0.66      0.62       210\n",
      "           5       0.66      0.33      0.44       210\n",
      "           6       0.41      0.62      0.49       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   1   9  19  29   2]\n",
      " [  0 138  14  11  13  34   0]\n",
      " [  0   2 164  10   0  34   0]\n",
      " [  0  10  10 130   9  48   3]\n",
      " [ 55  18  10  18  83  14  12]\n",
      " [  0   5   7  15   3 136  44]\n",
      " [  0   1   1   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.69      0.71       210\n",
      "           2       0.77      0.66      0.71       210\n",
      "           3       0.79      0.78      0.79       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.65      0.40      0.49       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   1   8  12  29   3]\n",
      " [  0 138  15  11  14  32   0]\n",
      " [  0   0 165  11   0  34   0]\n",
      " [  0  12  10 132   8  45   3]\n",
      " [ 52  18  10  18  89  13  10]\n",
      " [  0   8   5  15   4 135  43]\n",
      " [  0   1   1   4   1  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.76      0.66      0.70       210\n",
      "           3       0.80      0.79      0.79       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.70      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   1   8  14  29   0]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   0 165  12   0  33   0]\n",
      " [  0  12   9 131  11  44   3]\n",
      " [ 50  19   9  18  91  13  10]\n",
      " [  0   8   4  17   3 136  42]\n",
      " [  0   1   0   6   1  42 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.81      0.79      0.80       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.42      0.65      0.51       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   5   1   9  22  29   1]\n",
      " [  0 138  15   9  15  33   0]\n",
      " [  0   0 168  11   0  31   0]\n",
      " [  0  12   9 134  10  42   3]\n",
      " [ 43  18  10  18  99  12  10]\n",
      " [  0   6   6  16   4 138  40]\n",
      " [  0   1   0   6   2  47 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.77      0.66      0.71       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.74      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   1   9  21  28   0]\n",
      " [  0 140  17   9  14  30   0]\n",
      " [  0   0 173  13   0  24   0]\n",
      " [  0  11  10 135   9  42   3]\n",
      " [ 42  15  11  21 100  11  10]\n",
      " [  0   6   6  15   4 139  40]\n",
      " [  0   0   0   5   2  48 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.73       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.65      0.64      0.65       210\n",
      "           5       0.67      0.48      0.56       210\n",
      "           6       0.43      0.66      0.52       210\n",
      "           7       0.75      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   5   1   9  16  28   0]\n",
      " [  0 143  11   9  15  32   0]\n",
      " [  0   1 172  10   0  27   0]\n",
      " [  0  10   8 135   8  46   3]\n",
      " [ 44  18   9  21  98  11   9]\n",
      " [  0   6   2  16   4 143  39]\n",
      " [  1   0   0   5   2  48 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.74       210\n",
      "           2       0.78      0.68      0.73       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.69      0.47      0.56       210\n",
      "           6       0.43      0.68      0.52       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   1   9  21  28   1]\n",
      " [  0 142  15   9  14  30   0]\n",
      " [  0   4 175   8   0  23   0]\n",
      " [  0   9  11 132  11  43   4]\n",
      " [ 36  17   9  19 107  13   9]\n",
      " [  0   5   5  15   4 141  40]\n",
      " [  0   1   0   6   2  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.78      0.68      0.72       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.67      0.63      0.65       210\n",
      "           5       0.67      0.51      0.58       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   1   9  14  28   1]\n",
      " [  0 141  14   9  16  30   0]\n",
      " [  0   1 176  10   0  23   0]\n",
      " [  0   9  11 133  10  43   4]\n",
      " [ 38  17   9  18 108  11   9]\n",
      " [  0   4   4  15   5 141  41]\n",
      " [  1   0   0   5   3  47 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.67      0.63      0.65       210\n",
      "           5       0.69      0.51      0.59       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.74      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 143  13   9  14  31   0]\n",
      " [  0   5 170  10   0  25   0]\n",
      " [  0  10  10 139   6  41   4]\n",
      " [ 37  19   8  24 104  10   8]\n",
      " [  0   5   5  14   4 141  41]\n",
      " [  1   0   1   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.82      0.81      0.82       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.71      0.50      0.58       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   5   1   9  25  28   0]\n",
      " [  0 141  15  12  13  29   0]\n",
      " [  0   1 175   9   0  25   0]\n",
      " [  0  10  10 134  10  42   4]\n",
      " [ 38  16   9  18 109  11   9]\n",
      " [  0   6   4  15   5 141  39]\n",
      " [  1   0   1   5   1  48 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.81      0.83      0.82       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.67      0.52      0.58       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   5   1   9  20  28   0]\n",
      " [  0 143  14   9  13  31   0]\n",
      " [  0   3 174   7   0  26   0]\n",
      " [  0   8   9 136  12  42   3]\n",
      " [ 31  17   8  19 115  11   9]\n",
      " [  0   4   2  12   7 147  38]\n",
      " [  1   0   0   5   3  47 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.76       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.84      0.83      0.83       210\n",
      "           4       0.69      0.65      0.67       210\n",
      "           5       0.68      0.55      0.61       210\n",
      "           6       0.44      0.70      0.54       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   1   9  17  28   0]\n",
      " [  0 146  14   8  11  31   0]\n",
      " [  0   4 176   6   0  24   0]\n",
      " [  0  10  10 136   9  42   3]\n",
      " [ 36  21   9  20 108   7   9]\n",
      " [  0   5   4  13   5 146  37]\n",
      " [  1   0   0   5   2  49 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.69      0.65      0.67       210\n",
      "           5       0.71      0.51      0.60       210\n",
      "           6       0.45      0.70      0.54       210\n",
      "           7       0.76      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   5   1   9  26  27   0]\n",
      " [  0 143  13   9  14  31   0]\n",
      " [  0   4 175   6   1  24   0]\n",
      " [  0   7  10 137  10  43   3]\n",
      " [ 31  21   8  17 114  11   8]\n",
      " [  0   4   4  11   6 144  41]\n",
      " [  1   1   0   5   3  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.71      0.65      0.68       210\n",
      "           5       0.66      0.54      0.59       210\n",
      "           6       0.44      0.69      0.54       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after MinMax Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   5   1   7  24  29   0]\n",
      " [  0 151  12   9   7  31   0]\n",
      " [  0   2 178   6   0  24   0]\n",
      " [  0   8  10 138   8  43   3]\n",
      " [ 35  19   8  16 113  11   8]\n",
      " [  0   5   4  16   5 142  38]\n",
      " [  1   0   0   5   2  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.79      0.72      0.76       210\n",
      "           3       0.84      0.85      0.84       210\n",
      "           4       0.70      0.66      0.68       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after MinMax Scaling is: 0.7428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[162   5   1   8  20  12   2]\n",
      " [  0 167   9  10   8  15   1]\n",
      " [  1   5 177   6   2  19   0]\n",
      " [  4   8  10 158   5  21   4]\n",
      " [ 24  18   7  22 125   3  11]\n",
      " [  2   6   3  19   4 131  45]\n",
      " [  3   1   0   4   2  28 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.77      0.80       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.86      0.84      0.85       210\n",
      "           4       0.70      0.75      0.72       210\n",
      "           5       0.75      0.60      0.66       210\n",
      "           6       0.57      0.62      0.60       210\n",
      "           7       0.73      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.75      0.74      0.74      1470\n",
      "weighted avg       0.75      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after MinMax Scaling is: 0.7013605442176871\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[149   1   0   5  49   5   1]\n",
      " [ 12 153  10  10  21   4   0]\n",
      " [ 14   4 179  10   1   2   0]\n",
      " [ 18   6  10 150  12  10   4]\n",
      " [ 27  12  11  23 129   6   2]\n",
      " [ 37  11   2  21   6  92  41]\n",
      " [  4   2   0   2   1  22 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.71      0.63       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.68      0.71      0.70       210\n",
      "           5       0.59      0.61      0.60       210\n",
      "           6       0.65      0.44      0.52       210\n",
      "           7       0.79      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after MinMax Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[183   2   2   8   2  13   0]\n",
      " [  3 186   7   7   0   7   0]\n",
      " [  2   6 195   2   0   5   0]\n",
      " [  4  15   1 168   0  18   4]\n",
      " [ 95  43   8  25  29   8   2]\n",
      " [  5  12   3  18   0 153  19]\n",
      " [ 10   1   2   7   1  83 106]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.87      0.71       210\n",
      "           2       0.70      0.89      0.78       210\n",
      "           3       0.89      0.93      0.91       210\n",
      "           4       0.71      0.80      0.76       210\n",
      "           5       0.91      0.14      0.24       210\n",
      "           6       0.53      0.73      0.62       210\n",
      "           7       0.81      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.74      0.69      0.66      1470\n",
      "weighted avg       0.74      0.69      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   5   3   5  33  10   1]\n",
      " [  2 167  10  11  14   5   1]\n",
      " [  5   7 189   6   1   2   0]\n",
      " [ 20  22  13 122  18  14   1]\n",
      " [ 38  30   4  11 121   2   4]\n",
      " [ 27  16  13  22   7  75  50]\n",
      " [  8   1   1  13   6  26 155]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.73      0.66       210\n",
      "           2       0.67      0.80      0.73       210\n",
      "           3       0.81      0.90      0.85       210\n",
      "           4       0.64      0.58      0.61       210\n",
      "           5       0.60      0.58      0.59       210\n",
      "           6       0.56      0.36      0.44       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   4   1   9  26  16   3]\n",
      " [  3 169  10   9  12   5   2]\n",
      " [  4   6 192   5   1   2   0]\n",
      " [ 12  18  18 124  19  18   1]\n",
      " [ 40  32   7  13 112   2   4]\n",
      " [ 20  12  10  21   9  92  46]\n",
      " [  7   2   0   7   3  45 146]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.72      0.68       210\n",
      "           2       0.70      0.80      0.75       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.62      0.53      0.57       210\n",
      "           6       0.51      0.44      0.47       210\n",
      "           7       0.72      0.70      0.71       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.680952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   3   2  10  29  14   2]\n",
      " [  1 162  11  10  20   4   2]\n",
      " [  4   3 193   7   0   3   0]\n",
      " [ 17  20  14 122  20  16   1]\n",
      " [ 28  27   8  12 130   3   2]\n",
      " [ 15  10   9  27   8  88  53]\n",
      " [  4   3   0   9   3  35 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.71      0.70       210\n",
      "           2       0.71      0.77      0.74       210\n",
      "           3       0.81      0.92      0.86       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.62      0.62      0.62       210\n",
      "           6       0.54      0.42      0.47       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.67      0.68      0.68      1470\n",
      "weighted avg       0.67      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   4   2   8  30  15   2]\n",
      " [  2 170  12   5  14   5   2]\n",
      " [  4   7 190   6   0   3   0]\n",
      " [ 18  15  17 125  24  10   1]\n",
      " [ 25  30   9  11 130   3   2]\n",
      " [ 12  11   9  24  10  92  52]\n",
      " [  6   3   0  10   4  30 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.71      0.81      0.76       210\n",
      "           3       0.79      0.90      0.85       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.61      0.62      0.62       210\n",
      "           6       0.58      0.44      0.50       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   3   3   6  34  15   3]\n",
      " [  2 164  14   4  21   3   2]\n",
      " [  3   7 192   5   0   3   0]\n",
      " [ 15  14  19 124  22  15   1]\n",
      " [ 26  28  10  11 132   1   2]\n",
      " [ 12  11   9  27  10  84  57]\n",
      " [  5   2   0   6   4  28 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.72      0.78      0.75       210\n",
      "           3       0.78      0.91      0.84       210\n",
      "           4       0.68      0.59      0.63       210\n",
      "           5       0.59      0.63      0.61       210\n",
      "           6       0.56      0.40      0.47       210\n",
      "           7       0.72      0.79      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after MinMax Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   4   1   6  31  16   2]\n",
      " [  2 170  12   5  15   4   2]\n",
      " [  4   6 193   3   0   4   0]\n",
      " [ 14  16  21 123  21  13   2]\n",
      " [ 28  29  10  11 130   0   2]\n",
      " [ 12  10  14  21  10  87  56]\n",
      " [  3   2   0   9   4  32 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.72      0.81      0.76       210\n",
      "           3       0.77      0.92      0.84       210\n",
      "           4       0.69      0.59      0.63       210\n",
      "           5       0.62      0.62      0.62       210\n",
      "           6       0.56      0.41      0.48       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.68      0.69      0.68      1470\n",
      "weighted avg       0.68      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after MinMax Scaling is: 0.5496598639455782\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 89   1  12  13  45  44   6]\n",
      " [  0 113  24  11  30  30   2]\n",
      " [  1   9 160   9   1  30   0]\n",
      " [  2  11  27  56  41  57  16]\n",
      " [ 12  27   6  14 127  10  14]\n",
      " [  3   5   4  14   9 122  53]\n",
      " [  0   0   0   0   2  67 141]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.42      0.56       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.69      0.76      0.72       210\n",
      "           4       0.48      0.27      0.34       210\n",
      "           5       0.50      0.60      0.55       210\n",
      "           6       0.34      0.58      0.43       210\n",
      "           7       0.61      0.67      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.55      1470\n",
      "weighted avg       0.59      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after MinMax Scaling is: 0.23333333333333334\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 17 158   1   6   9  13   6]\n",
      " [  5 184   2   5   2   7   5]\n",
      " [  0 176  17   5   2   6   4]\n",
      " [  4 155   0  28   6   9   8]\n",
      " [  7 168   2  12  10   8   3]\n",
      " [ 11 123   5   6   6  39  20]\n",
      " [  2 122   3  10   3  22  48]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.08      0.13       210\n",
      "           2       0.17      0.88      0.28       210\n",
      "           3       0.57      0.08      0.14       210\n",
      "           4       0.39      0.13      0.20       210\n",
      "           5       0.26      0.05      0.08       210\n",
      "           6       0.38      0.19      0.25       210\n",
      "           7       0.51      0.23      0.32       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.38      0.23      0.20      1470\n",
      "weighted avg       0.38      0.23      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17548/619479168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Working on SVM Kernal:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mtv_svm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mml_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtv_svm_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SVM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Decision Tree Classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17548/3936712632.py\u001b[0m in \u001b[0;36mml_training\u001b[1;34m(ml_model, x_train, x_test, y_train, y_test, model_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Function for Modelling and extracting Metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mml_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mml_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mml_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mml_pred_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" after MinMax Scaling is:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[0;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ab723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_gkb.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_ndisbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80480feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//bert_vectorized_kabita_dataset_vbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//gpt_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//SentenceTransformers//xlm_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//bert_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Kabita//FineTunedTransformers//xlm_base_finetuned_vectorized_kabita_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['kabita_labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
