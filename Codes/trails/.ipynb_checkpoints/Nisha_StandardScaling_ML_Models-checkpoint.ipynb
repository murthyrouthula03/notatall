{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Nisha//Input//Nisha_dataset_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b63a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of Train-test split, Standard Scaling\n",
    "def standard_scaling(x_data, y_data):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.30,random_state=21,stratify=y_data)\n",
    "    # Standard scaling of train data\n",
    "    scaler_model = StandardScaler()\n",
    "    scaled_data_train = scaler_model.fit_transform(x_train)\n",
    "    # Standard scaling of test data\n",
    "    scaled_data_test = scaler_model.fit_transform(x_test)\n",
    "    return scaled_data_train, scaled_data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" after Standard Scaling is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[158   1   1   3  26  17   4]\n",
      " [  6 146  13  11  19  15   0]\n",
      " [  0  12 170  19   3   6   0]\n",
      " [  6  11  17 124  28  21   3]\n",
      " [ 28  22   3  22 119  10   6]\n",
      " [  8  19   9  26   3 110  35]\n",
      " [  5   2   0   2   6  38 157]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.69      0.70      0.69       210\n",
      "           3       0.80      0.81      0.80       210\n",
      "           4       0.60      0.59      0.59       210\n",
      "           5       0.58      0.57      0.57       210\n",
      "           6       0.51      0.52      0.52       210\n",
      "           7       0.77      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135  21  13  10  17  10   4]\n",
      " [ 28 124  23   9  19   6   1]\n",
      " [  6  15 173  11   4   1   0]\n",
      " [ 44  25  24  91  18   8   0]\n",
      " [ 56  53  14  34  46   4   3]\n",
      " [ 40  41  38  12  14  47  18]\n",
      " [ 22  14  17   6   7  25 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.64      0.50       210\n",
      "           2       0.42      0.59      0.49       210\n",
      "           3       0.57      0.82      0.68       210\n",
      "           4       0.53      0.43      0.48       210\n",
      "           5       0.37      0.22      0.27       210\n",
      "           6       0.47      0.22      0.30       210\n",
      "           7       0.82      0.57      0.67       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.48      1470\n",
      "weighted avg       0.51      0.50      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[124  19   9  10  24  21   3]\n",
      " [ 21 132  18  13  14  11   1]\n",
      " [  7  16 168   7   6   6   0]\n",
      " [ 35  32  18  95  16  14   0]\n",
      " [ 46  53  13  36  44  11   7]\n",
      " [ 31  33  13  13  15  85  20]\n",
      " [ 19  13   3   8   7  49 111]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.59      0.50       210\n",
      "           2       0.44      0.63      0.52       210\n",
      "           3       0.69      0.80      0.74       210\n",
      "           4       0.52      0.45      0.48       210\n",
      "           5       0.35      0.21      0.26       210\n",
      "           6       0.43      0.40      0.42       210\n",
      "           7       0.78      0.53      0.63       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.51      1470\n",
      "weighted avg       0.52      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[122  21  13   9  21  21   3]\n",
      " [ 14 128  22  11  21  14   0]\n",
      " [  5  17 170   4   6   8   0]\n",
      " [ 31  26  19 101  20  13   0]\n",
      " [ 46  50  14  36  45  10   9]\n",
      " [ 31  36  12   9  14  89  19]\n",
      " [ 12  16   4   7   8  50 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.58      0.52       210\n",
      "           2       0.44      0.61      0.51       210\n",
      "           3       0.67      0.81      0.73       210\n",
      "           4       0.57      0.48      0.52       210\n",
      "           5       0.33      0.21      0.26       210\n",
      "           6       0.43      0.42      0.43       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  21  13   9  19  22   3]\n",
      " [ 19 127  22  13  18  11   0]\n",
      " [  6  16 163   9   8   8   0]\n",
      " [ 22  24  18 112  17  17   0]\n",
      " [ 49  55  14  33  42  11   6]\n",
      " [ 31  37  10  11  15  89  17]\n",
      " [  8  17   6   5   7  57 110]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.59      0.53       210\n",
      "           2       0.43      0.60      0.50       210\n",
      "           3       0.66      0.78      0.71       210\n",
      "           4       0.58      0.53      0.56       210\n",
      "           5       0.33      0.20      0.25       210\n",
      "           6       0.41      0.42      0.42       210\n",
      "           7       0.81      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.51      1470\n",
      "weighted avg       0.53      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  21  16   8  18  28   2]\n",
      " [ 18 125  19  13  19  16   0]\n",
      " [  6  16 169   3   6  10   0]\n",
      " [ 22  25  24 102  19  18   0]\n",
      " [ 48  63  11  34  38  11   5]\n",
      " [ 31  37  11  11  15  92  13]\n",
      " [  8  18  11   3   8  56 106]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.56      0.51       210\n",
      "           2       0.41      0.60      0.49       210\n",
      "           3       0.65      0.80      0.72       210\n",
      "           4       0.59      0.49      0.53       210\n",
      "           5       0.31      0.18      0.23       210\n",
      "           6       0.40      0.44      0.42       210\n",
      "           7       0.84      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  20  19  11  11  28   2]\n",
      " [ 17 124  22  11  17  19   0]\n",
      " [  8  16 162   9   6   9   0]\n",
      " [ 22  28  22 103  17  18   0]\n",
      " [ 45  63  11  33  36  16   6]\n",
      " [ 29  34  12  11  16  95  13]\n",
      " [  8  18   8   5   6  63 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.57      0.52       210\n",
      "           2       0.41      0.59      0.48       210\n",
      "           3       0.63      0.77      0.70       210\n",
      "           4       0.56      0.49      0.52       210\n",
      "           5       0.33      0.17      0.23       210\n",
      "           6       0.38      0.45      0.41       210\n",
      "           7       0.83      0.49      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.50      1470\n",
      "weighted avg       0.52      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.22244897959183674\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[  9   0   1   1 190   8   1]\n",
      " [  3   0   1   1 196   8   1]\n",
      " [  2   4   0   4 200   0   0]\n",
      " [  2   0   0   5 194   8   1]\n",
      " [  9   2   0   4 180  10   5]\n",
      " [  1   1   2   3 142  48  13]\n",
      " [  1   0   0   0  63  61  85]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.04      0.08       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.28      0.02      0.04       210\n",
      "           5       0.15      0.86      0.26       210\n",
      "           6       0.34      0.23      0.27       210\n",
      "           7       0.80      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.27      0.22      0.17      1470\n",
      "weighted avg       0.27      0.22      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[164   4  11   6  22   2   1]\n",
      " [  1 148  33  19   5   4   0]\n",
      " [  0   8 198   4   0   0   0]\n",
      " [  5   9  36 132  18  10   0]\n",
      " [ 31  18   8  21 125   4   3]\n",
      " [  5  28  48  26   2  77  24]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.78      0.79       210\n",
      "           2       0.69      0.70      0.69       210\n",
      "           3       0.58      0.94      0.72       210\n",
      "           4       0.63      0.63      0.63       210\n",
      "           5       0.72      0.60      0.65       210\n",
      "           6       0.65      0.37      0.47       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of SVM is:\n",
      " [[166   1   0   4  21  17   1]\n",
      " [  4 152  13  14  11  16   0]\n",
      " [  0  10 171  19   1   9   0]\n",
      " [  9  20  21 119  19  20   2]\n",
      " [ 38  22   8  24 112   2   4]\n",
      " [ 13  22  15  20   3 117  20]\n",
      " [  4   7   2   2   1  49 145]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.79      0.75       210\n",
      "           2       0.65      0.72      0.68       210\n",
      "           3       0.74      0.81      0.78       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.51      0.56      0.53       210\n",
      "           7       0.84      0.69      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.27414965986394557\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 13   5 174   4   6   4   4]\n",
      " [  3  20 173   7   4   3   0]\n",
      " [  0   3 205   0   1   1   0]\n",
      " [ 11   6 142  37  10   4   0]\n",
      " [  8  11 154  14  12   6   5]\n",
      " [ 11  11 137   5   8  28  10]\n",
      " [  0   2 104   0   1  15  88]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.06      0.10       210\n",
      "           2       0.34      0.10      0.15       210\n",
      "           3       0.19      0.98      0.32       210\n",
      "           4       0.55      0.18      0.27       210\n",
      "           5       0.29      0.06      0.10       210\n",
      "           6       0.46      0.13      0.21       210\n",
      "           7       0.82      0.42      0.56       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.42      0.27      0.24      1470\n",
      "weighted avg       0.42      0.27      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of SVM is:\n",
      " [[134   5   3   6  23  28  11]\n",
      " [  2 137  13  15  16  24   3]\n",
      " [  0  15 167  17   2   8   1]\n",
      " [  5  12  16 119  23  27   8]\n",
      " [ 30  27  10  33  77  11  22]\n",
      " [ 11  19   7  10   6 105  52]\n",
      " [  2   1   1   1   0  29 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.64      0.68       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.77      0.80      0.78       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.52      0.37      0.43       210\n",
      "           6       0.45      0.50      0.48       210\n",
      "           7       0.64      0.84      0.73       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of SVM is:\n",
      " [[149   3   2   4  26  24   2]\n",
      " [  5 147  10  14  14  20   0]\n",
      " [  0   9 174  19   1   7   0]\n",
      " [  4  16  18 127  25  19   1]\n",
      " [ 42  29   8  32  84  10   5]\n",
      " [  8  21  11  17   7 119  27]\n",
      " [  4   2   1   2   1  28 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.78      0.83      0.80       210\n",
      "           4       0.59      0.60      0.60       210\n",
      "           5       0.53      0.40      0.46       210\n",
      "           6       0.52      0.57      0.54       210\n",
      "           7       0.83      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.19931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [127   0  83   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.15      0.20      0.12      1470\n",
      "weighted avg       0.15      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25510204081632654\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   0   0   0   0   0 128]\n",
      " [  1   0   3   0   0   0 206]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   0   0 205]\n",
      " [ 64   0   1   0   0   0 145]\n",
      " [  1   0   0   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.24      0.26      0.19      1470\n",
      "weighted avg       0.24      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   0   0   0  56   0  44]\n",
      " [  2   0   3   0   0   0 205]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   3   0 202]\n",
      " [ 69   0   1   0  61   0  79]\n",
      " [  2   0   0   0   1   0 207]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.50      0.29      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      1.00      0.33       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.26      1470\n",
      "weighted avg       0.32      0.32      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37551020408163266\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  44   0   0  48   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  3 201   2   0   3   0   1]\n",
      " [ 59  77   1   0  71   0   2]\n",
      " [  1 199   0   0   2   0   8]\n",
      " [  0 134   0   0   0   0  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.56      0.60       210\n",
      "           2       0.21      0.97      0.34       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.57      0.34      0.42       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.46      0.38      0.35      1470\n",
      "weighted avg       0.46      0.38      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40408163265306124\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 94  44   0   0  72   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  0 201   2   0   6   0   1]\n",
      " [ 16  76   1   0 114   0   3]\n",
      " [  0 197   0   0   3   0  10]\n",
      " [  0 110   0   0   0   1  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.45      0.59       210\n",
      "           2       0.21      0.97      0.35       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.58      0.54      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.49      0.40      0.38      1470\n",
      "weighted avg       0.49      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92   0   0   0  74  44   0]\n",
      " [  1  27   3   0   1 177   1]\n",
      " [  0   0  83   0   0 127   0]\n",
      " [  0   0   2   0   6 201   1]\n",
      " [ 12  13   1   0 118  63   3]\n",
      " [  0   0   0   0   3 197  10]\n",
      " [  0   0   0   0   5 111  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.44      0.58       210\n",
      "           2       0.68      0.13      0.22       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.57      0.56      0.57       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.59      0.42      0.41      1470\n",
      "weighted avg       0.59      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   1   0   1  45  43   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  36  83   0   0  91   0]\n",
      " [  3  15   2   0   3 186   1]\n",
      " [ 47  25   1   1  82  51   3]\n",
      " [  1   2   0   0   2 195  10]\n",
      " [  0   1   0   0   4 110  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.57      0.63       210\n",
      "           2       0.48      0.36      0.41       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.60      0.39      0.47       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.55      0.44      0.44      1470\n",
      "weighted avg       0.55      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   1   0   0  47  43   0]\n",
      " [  1  74  29   1   1 104   0]\n",
      " [  0   0 119   0   0  91   0]\n",
      " [  3   2  16   0   3 185   1]\n",
      " [ 46  19   9   3  81  49   3]\n",
      " [  1   0   2   0   2 195  10]\n",
      " [  0   1   0   0   4 111  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.57      0.63       210\n",
      "           2       0.76      0.35      0.48       210\n",
      "           3       0.68      0.57      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.39      0.47       210\n",
      "           6       0.25      0.93      0.39       210\n",
      "           7       0.87      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.55      0.46      0.45      1470\n",
      "weighted avg       0.55      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   1   0   0  48  43   0]\n",
      " [  1  80  25   0   1 102   1]\n",
      " [  0   0 135   0   0  75   0]\n",
      " [  3   2  17   0   3 184   1]\n",
      " [ 46  19   9   3  81  49   3]\n",
      " [  1   0   3   0   2 194  10]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.56      0.62       210\n",
      "           2       0.78      0.38      0.51       210\n",
      "           3       0.71      0.64      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.58      0.39      0.46       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.47      1470\n",
      "weighted avg       0.56      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   0   0   0  47  44   0]\n",
      " [  1  93  12   0   3 100   1]\n",
      " [  0  12 129   0   0  69   0]\n",
      " [  3  12   7   0   3 184   1]\n",
      " [ 48  22   4   1  83  49   3]\n",
      " [  1   2   1   0   2 194  10]\n",
      " [  0   1   0   0   6 109  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.57      0.62       210\n",
      "           2       0.65      0.44      0.53       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.58      0.40      0.47       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.48      1470\n",
      "weighted avg       0.56      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   0   0   0  20  44   0]\n",
      " [  1  93  10   2   5  98   1]\n",
      " [  0   9 132   0   0  69   0]\n",
      " [  4  12   7  16   2 168   1]\n",
      " [ 50  16   6   5  83  47   3]\n",
      " [  2   2   1   0   1 194  10]\n",
      " [  0   1   0   0   5 110  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.63      0.72       210\n",
      "           4       0.70      0.08      0.14       210\n",
      "           5       0.72      0.40      0.51       210\n",
      "           6       0.27      0.92      0.41       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.69      0.52      0.52      1470\n",
      "weighted avg       0.69      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   0   0   1  19  44   0]\n",
      " [  1  93  11   4   4  96   1]\n",
      " [  0   7 134   0   0  69   0]\n",
      " [  4  12   7  38   2 146   1]\n",
      " [ 52  19   5   4  81  46   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.84      0.64      0.73       210\n",
      "           4       0.81      0.18      0.30       210\n",
      "           5       0.72      0.39      0.50       210\n",
      "           6       0.28      0.92      0.42       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   0   0   3  17  43   0]\n",
      " [  2  92  12   3   4  96   1]\n",
      " [  0   7 134   0   0  69   0]\n",
      " [  5  13  11  41   2 137   1]\n",
      " [ 48  19   5  12  80  43   3]\n",
      " [  2   1   2   2   1 192  10]\n",
      " [  0   1   0   0   4 111  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.82      0.64      0.72       210\n",
      "           4       0.67      0.20      0.30       210\n",
      "           5       0.74      0.38      0.50       210\n",
      "           6       0.28      0.91      0.43       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.68      0.53      0.54      1470\n",
      "weighted avg       0.68      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   0   0   0  21  36   0]\n",
      " [  2  93  11   4   4  96   0]\n",
      " [  0   7 134   0   0  69   0]\n",
      " [  5  13  12  40   3 137   0]\n",
      " [ 47  19   5   7  91  39   2]\n",
      " [  2   1   2   2   1 192  10]\n",
      " [  0   1   0   0   5 111  93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.82      0.64      0.72       210\n",
      "           4       0.75      0.19      0.30       210\n",
      "           5       0.73      0.43      0.54       210\n",
      "           6       0.28      0.91      0.43       210\n",
      "           7       0.89      0.44      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   0   0  23  35   0]\n",
      " [  2 108  11   1   5  82   1]\n",
      " [  0   7 134   0   0  69   0]\n",
      " [  5  21  11  41   3 129   0]\n",
      " [ 44  20   5   7  93  39   2]\n",
      " [  2   5   2   2   1 189   9]\n",
      " [  0   1   0   0   5 110  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.67      0.51      0.58       210\n",
      "           3       0.82      0.64      0.72       210\n",
      "           4       0.80      0.20      0.31       210\n",
      "           5       0.72      0.44      0.55       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.89      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   0   2  21  33   0]\n",
      " [  2 109  11   2   4  81   1]\n",
      " [  0   7 134   0   0  69   0]\n",
      " [  5  21  12  39   4 129   0]\n",
      " [ 48  21   5   6  95  32   3]\n",
      " [  2   5   2   2   1 189   9]\n",
      " [  0   1   0   0   6 111  92]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.82      0.64      0.72       210\n",
      "           4       0.76      0.19      0.30       210\n",
      "           5       0.73      0.45      0.56       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.88      0.44      0.58       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  23  32   0]\n",
      " [  2 107  12   2   6  80   1]\n",
      " [  0   7 143   0   0  60   0]\n",
      " [  5  21  12  41   3 128   0]\n",
      " [ 47  22   6   7  95  30   3]\n",
      " [  2   5   2   2   1 188  10]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.66      0.51      0.57       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.71      0.45      0.55       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.87      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   2  27  32   0]\n",
      " [  2 103  12   2   4  86   1]\n",
      " [  0   7 141   0   2  60   0]\n",
      " [  5  21  13  39   3 128   1]\n",
      " [ 44  21   6   7  96  30   6]\n",
      " [  2   4   2   2   1 186  13]\n",
      " [  0   1   0   0   5 105  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.72       210\n",
      "           2       0.66      0.49      0.56       210\n",
      "           3       0.81      0.67      0.73       210\n",
      "           4       0.75      0.19      0.30       210\n",
      "           5       0.70      0.46      0.55       210\n",
      "           6       0.30      0.89      0.44       210\n",
      "           7       0.82      0.47      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.68      0.55      0.56      1470\n",
      "weighted avg       0.68      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   0   1  24  33   0]\n",
      " [  2 103  10   2   6  86   1]\n",
      " [  0   6 144   0   0  60   0]\n",
      " [  5  20  14  38   4 127   2]\n",
      " [ 43  19   6   5 101  30   6]\n",
      " [  2   4   2   2   1 181  18]\n",
      " [  0   1   0   0   4  95 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.67      0.49      0.57       210\n",
      "           3       0.82      0.69      0.75       210\n",
      "           4       0.79      0.18      0.29       210\n",
      "           5       0.72      0.48      0.58       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.69      0.56      0.57      1470\n",
      "weighted avg       0.69      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  25  30   0]\n",
      " [  2 104  11   3   5  85   0]\n",
      " [  0   6 142   0   2  60   0]\n",
      " [  5  16  14  40   6 127   2]\n",
      " [ 41  18   6   5 102  32   6]\n",
      " [  3   5   2   2   1 182  15]\n",
      " [  0   1   0   0   6  98 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.81      0.68      0.74       210\n",
      "           4       0.80      0.19      0.31       210\n",
      "           5       0.69      0.49      0.57       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.82      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.6353741496598639\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   3  32  23   0]\n",
      " [  2 131  12  22  13  26   4]\n",
      " [  0  12 167   6   0  23   2]\n",
      " [  4  24  17 104  17  36   8]\n",
      " [ 36  28   7  20 109   3   7]\n",
      " [  4  13   3  30   5 125  30]\n",
      " [  1   4   0   6   8  44 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       210\n",
      "           2       0.62      0.62      0.62       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.54      0.50      0.52       210\n",
      "           5       0.59      0.52      0.55       210\n",
      "           6       0.45      0.60      0.51       210\n",
      "           7       0.74      0.70      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   4   1   2  24  35   2]\n",
      " [  1  90   7  20  17  74   1]\n",
      " [  2   0 123   3   0  82   0]\n",
      " [  5  10   3  91  15  83   3]\n",
      " [ 58  20   1  23  85  17   6]\n",
      " [  4   6   1  30   3 142  24]\n",
      " [  0   3   0   1   3  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.68      0.67       210\n",
      "           2       0.68      0.43      0.52       210\n",
      "           3       0.90      0.59      0.71       210\n",
      "           4       0.54      0.43      0.48       210\n",
      "           5       0.58      0.40      0.48       210\n",
      "           6       0.30      0.68      0.41       210\n",
      "           7       0.81      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.64      0.56      0.58      1470\n",
      "weighted avg       0.64      0.56      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   2  10  19  25   1]\n",
      " [  1 114   9  24   4  57   1]\n",
      " [  1   0 135   6   0  68   0]\n",
      " [  4  14   9 117   8  56   2]\n",
      " [ 64  24   4  23  77  13   5]\n",
      " [  3  12   4  41   3 119  28]\n",
      " [  0   4   1  10   1  32 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.70       210\n",
      "           2       0.67      0.54      0.60       210\n",
      "           3       0.82      0.64      0.72       210\n",
      "           4       0.51      0.56      0.53       210\n",
      "           5       0.69      0.37      0.48       210\n",
      "           6       0.32      0.57      0.41       210\n",
      "           7       0.81      0.77      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.60      1470\n",
      "weighted avg       0.64      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   1   4  22  33   1]\n",
      " [  1 114   8  20   7  59   1]\n",
      " [  0   0 135   3   1  71   0]\n",
      " [  4  15   5 110  10  64   2]\n",
      " [ 52  26   2  21  92  12   5]\n",
      " [  2  15   1  29   2 136  25]\n",
      " [  0   4   0   1   1  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.65      0.54      0.59       210\n",
      "           3       0.89      0.64      0.75       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.68      0.44      0.53       210\n",
      "           6       0.33      0.65      0.44       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.67      0.61      0.62      1470\n",
      "weighted avg       0.67      0.61      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   1   4  20  34   2]\n",
      " [  1 113  20  21   8  46   1]\n",
      " [  0   0 149   3   0  58   0]\n",
      " [  4  12   8 119  13  52   2]\n",
      " [ 59  28   5  19  82  12   5]\n",
      " [  3  10   3  29   3 135  27]\n",
      " [  0   4   0   1   1  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.70      0.69       210\n",
      "           2       0.67      0.54      0.60       210\n",
      "           3       0.80      0.71      0.75       210\n",
      "           4       0.61      0.57      0.59       210\n",
      "           5       0.65      0.39      0.49       210\n",
      "           6       0.36      0.64      0.46       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   1   1  12  19  27   2]\n",
      " [  1 114  22  25   7  40   1]\n",
      " [  0   0 153   7   0  50   0]\n",
      " [  4  12  11 127  12  43   1]\n",
      " [ 55  28   5  21  89   7   5]\n",
      " [  3  11   3  40   3 125  25]\n",
      " [  0   3   0   9   2  35 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.67      0.54      0.60       210\n",
      "           3       0.78      0.73      0.76       210\n",
      "           4       0.53      0.60      0.56       210\n",
      "           5       0.67      0.42      0.52       210\n",
      "           6       0.38      0.60      0.47       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   2   1   4  18  35   1]\n",
      " [  1 121  18  22   5  42   1]\n",
      " [  0   0 149   6   0  55   0]\n",
      " [  3  13  10 121  13  49   1]\n",
      " [ 56  25   5  19  89  11   5]\n",
      " [  3  11   3  27   4 137  25]\n",
      " [  0   4   0   0   1  45 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.58      0.63       210\n",
      "           3       0.80      0.71      0.75       210\n",
      "           4       0.61      0.58      0.59       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.83      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6360544217687075\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   3   1   5  20  33   0]\n",
      " [  1 122  22  21   3  40   1]\n",
      " [  0   0 153   3   0  54   0]\n",
      " [  3  12  10 118  13  52   2]\n",
      " [ 46  26   7  18  97  11   5]\n",
      " [  3  13   3  29   1 134  27]\n",
      " [  0   4   0   0   1  42 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72       210\n",
      "           2       0.68      0.58      0.63       210\n",
      "           3       0.78      0.73      0.75       210\n",
      "           4       0.61      0.56      0.58       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.37      0.64      0.47       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   3   1   4  18  33   0]\n",
      " [  1 130  12  22   5  39   1]\n",
      " [  0   6 147   1   0  56   0]\n",
      " [  4  14   9 118  11  52   2]\n",
      " [ 50  29   5  17  94  10   5]\n",
      " [  3  12   2  24   2 143  24]\n",
      " [  0   4   0   1   1  38 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.66      0.62      0.64       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.72      0.45      0.55       210\n",
      "           6       0.39      0.68      0.49       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  21  29   0]\n",
      " [  1 130  12  21   4  41   1]\n",
      " [  0   7 146   5   0  52   0]\n",
      " [  4  12  11 117  11  53   2]\n",
      " [ 58  27   3  16  92   9   5]\n",
      " [  4  14   1  26   1 141  23]\n",
      " [  0   4   0   0   1  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.71       210\n",
      "           2       0.66      0.62      0.64       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.62      0.56      0.59       210\n",
      "           5       0.71      0.44      0.54       210\n",
      "           6       0.39      0.67      0.49       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   4  26  27   0]\n",
      " [  1 129  12  21   3  43   1]\n",
      " [  0   7 146   4   0  53   0]\n",
      " [  4  14   8 120   9  53   2]\n",
      " [ 41  27   3  20 105   9   5]\n",
      " [  4  13   1  25   2 142  23]\n",
      " [  0   5   0   0   1  36 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.66      0.61      0.64       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.62      0.57      0.59       210\n",
      "           5       0.72      0.50      0.59       210\n",
      "           6       0.39      0.68      0.50       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.66      1470\n",
      "weighted avg       0.69      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   0   4  23  26   0]\n",
      " [  1 130  11  21   2  44   1]\n",
      " [  0   8 146   2   0  54   0]\n",
      " [  3  15   9 122  11  48   2]\n",
      " [ 45  23   3  18 106  10   5]\n",
      " [  2  13   1  23   4 143  24]\n",
      " [  0   3   0   0   1  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.67      0.62      0.65       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.64      0.58      0.61       210\n",
      "           5       0.72      0.50      0.59       210\n",
      "           6       0.40      0.68      0.50       210\n",
      "           7       0.84      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   0   4  20  27   1]\n",
      " [  1 132  13  21   3  39   1]\n",
      " [  0   6 147   3   0  54   0]\n",
      " [  3  15  10 119  11  49   3]\n",
      " [ 45  25   3  17 105  10   5]\n",
      " [  2  14   1  20   3 144  26]\n",
      " [  0   4   0   0   2  30 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.67      0.63      0.65       210\n",
      "           3       0.84      0.70      0.77       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.73      0.50      0.59       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.83      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   1   1   3  23  28   0]\n",
      " [  1 133  14  18   4  39   1]\n",
      " [  0   6 147   4   0  53   0]\n",
      " [  4  14   9 124   9  48   2]\n",
      " [ 51  26   4  17  98   9   5]\n",
      " [  2  12   1  21   2 147  25]\n",
      " [  0   2   0   0   1  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.69      0.63      0.66       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.66      0.59      0.62       210\n",
      "           5       0.72      0.47      0.56       210\n",
      "           6       0.40      0.70      0.51       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   1   3  21  25   0]\n",
      " [  1 134  11  19   5  39   1]\n",
      " [  0   9 146   1   0  54   0]\n",
      " [  2  16  10 121  11  48   2]\n",
      " [ 46  23   3  19 105   9   5]\n",
      " [  3  14   2  17   1 148  25]\n",
      " [  0   3   0   0   1  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.73      0.50      0.59       210\n",
      "           6       0.41      0.70      0.52       210\n",
      "           7       0.84      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   2   1   2  20  24   0]\n",
      " [  1 136  13  18   2  39   1]\n",
      " [  0   9 147   1   0  53   0]\n",
      " [  3  14  10 115  13  53   2]\n",
      " [ 49  22   3  17 106   8   5]\n",
      " [  3  15   1  19   2 145  25]\n",
      " [  0   3   0   1   1  39 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.68      0.65      0.66       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.66      0.55      0.60       210\n",
      "           5       0.74      0.50      0.60       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   5  25  23   0]\n",
      " [  1 137  13  18   2  38   1]\n",
      " [  0  10 146   2   0  52   0]\n",
      " [  3  15  11 114  12  53   2]\n",
      " [ 39  22   3  21 111   9   5]\n",
      " [  2  14   1  21   2 145  25]\n",
      " [  0   3   0   1   2  37 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.67      0.65      0.66       210\n",
      "           3       0.83      0.70      0.76       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   1   6  22  23   0]\n",
      " [  1 136  13  17   4  38   1]\n",
      " [  0  10 147   4   0  49   0]\n",
      " [  3  14  11 118  12  50   2]\n",
      " [ 40  25   4  16 112   8   5]\n",
      " [  2  13   1  24   4 142  24]\n",
      " [  0   4   0   0   1  35 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.76       210\n",
      "           2       0.67      0.65      0.66       210\n",
      "           3       0.83      0.70      0.76       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.84      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   4  25  23   1]\n",
      " [  1 133  13  18   6  38   1]\n",
      " [  0  10 147   4   0  49   0]\n",
      " [  3  16  11 116  12  50   2]\n",
      " [ 40  22   3  20 110   9   6]\n",
      " [  3  18   1  21   3 142  22]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.66      0.63      0.64       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.63      0.55      0.59       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   5  24  25   0]\n",
      " [  1 141   9  17   4  37   1]\n",
      " [  0  11 147   4   0  48   0]\n",
      " [  2  13  11 126  11  45   2]\n",
      " [ 45  24   2  21 107   6   5]\n",
      " [  4  14   1  21   0 144  26]\n",
      " [  0   1   0   2   3  36 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.86      0.70      0.77       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.72      0.51      0.60       210\n",
      "           6       0.42      0.69      0.52       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   6  25  22   0]\n",
      " [  1 140  11  17   4  36   1]\n",
      " [  0  10 147   3   0  50   0]\n",
      " [  3  13  11 123  12  45   3]\n",
      " [ 33  24   3  19 117   9   5]\n",
      " [  2  13   1  24   2 143  25]\n",
      " [  0   1   0   1   1  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.73      0.76       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.84      0.70      0.77       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.73      0.56      0.63       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  31  19   0]\n",
      " [  1 147  11  24   3  23   1]\n",
      " [  0  10 176  14   0  10   0]\n",
      " [  3  16  14 136   9  27   5]\n",
      " [ 33  23   6  19 121   3   5]\n",
      " [  4  14   6  24   3 126  33]\n",
      " [  0   2   0   1   4  28 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.73      0.76       210\n",
      "           2       0.69      0.70      0.69       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.53      0.60      0.57       210\n",
      "           7       0.80      0.83      0.82       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[166   3   0   5  23  12   1]\n",
      " [ 13 154  10  11  18   4   0]\n",
      " [  5  14 168  18   5   0   0]\n",
      " [ 16   8  13 133  29  11   0]\n",
      " [ 20  20   2  35 114  15   4]\n",
      " [ 36  21   5  32   4  79  33]\n",
      " [  2   1   1   0   0  30 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.79      0.71       210\n",
      "           2       0.70      0.73      0.71       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.59      0.54      0.57       210\n",
      "           6       0.52      0.38      0.44       210\n",
      "           7       0.82      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[153   2   0   6  28  19   2]\n",
      " [  4 149  10  14  15  18   0]\n",
      " [  0  11 178  15   1   5   0]\n",
      " [  5   9  16 125  30  22   3]\n",
      " [ 25  20   2  19 127  10   7]\n",
      " [  5  20   4  27   4 115  35]\n",
      " [  5   2   1   3   6  35 158]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.75       210\n",
      "           2       0.70      0.71      0.70       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.60      0.60      0.60       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.51      0.55      0.53       210\n",
      "           7       0.77      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5265306122448979\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  19  15  10   7  17   2]\n",
      " [ 20 131  34  10   5   9   1]\n",
      " [  5   9 182  11   1   2   0]\n",
      " [ 26  22  32  98   9  21   2]\n",
      " [ 55  50  15  42  27  12   9]\n",
      " [ 33  35  35  13  10  61  23]\n",
      " [ 20  10   2   5   6  32 135]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.67      0.55       210\n",
      "           2       0.47      0.62      0.54       210\n",
      "           3       0.58      0.87      0.69       210\n",
      "           4       0.52      0.47      0.49       210\n",
      "           5       0.42      0.13      0.20       210\n",
      "           6       0.40      0.29      0.34       210\n",
      "           7       0.78      0.64      0.71       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.50      1470\n",
      "weighted avg       0.52      0.53      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138  19  17  11   6  16   3]\n",
      " [ 18 125  31  17  10   8   1]\n",
      " [  2  13 187   3   4   1   0]\n",
      " [ 18  24  37 105   9  15   2]\n",
      " [ 47  47  19  42  34  13   8]\n",
      " [ 26  32  35  13   7  77  20]\n",
      " [ 19   6   5   2   5  42 131]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.66      0.58       210\n",
      "           2       0.47      0.60      0.53       210\n",
      "           3       0.56      0.89      0.69       210\n",
      "           4       0.54      0.50      0.52       210\n",
      "           5       0.45      0.16      0.24       210\n",
      "           6       0.45      0.37      0.40       210\n",
      "           7       0.79      0.62      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141  20  12  10   7  18   2]\n",
      " [ 10 130  35  14  12   7   2]\n",
      " [  2  16 186   2   3   1   0]\n",
      " [ 16  25  32 106  11  19   1]\n",
      " [ 46  56  19  36  34  12   7]\n",
      " [ 28  34  33  11   7  76  21]\n",
      " [ 12   7   5   2   5  51 128]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.67      0.61       210\n",
      "           2       0.45      0.62      0.52       210\n",
      "           3       0.58      0.89      0.70       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.43      0.16      0.24       210\n",
      "           6       0.41      0.36      0.39       210\n",
      "           7       0.80      0.61      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.53      1470\n",
      "weighted avg       0.54      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141  18  11  12   8  19   1]\n",
      " [  9 132  34  16   9  10   0]\n",
      " [  3  13 185   1   6   2   0]\n",
      " [ 17  26  35 106   8  17   1]\n",
      " [ 51  53  20  41  30  11   4]\n",
      " [ 27  30  36  12   6  77  22]\n",
      " [ 11  11   6   2   6  56 118]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.67      0.60       210\n",
      "           2       0.47      0.63      0.54       210\n",
      "           3       0.57      0.88      0.69       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.41      0.14      0.21       210\n",
      "           6       0.40      0.37      0.38       210\n",
      "           7       0.81      0.56      0.66       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141  18  14   8   7  20   2]\n",
      " [ 10 132  37  13   6  12   0]\n",
      " [  5  12 185   2   4   2   0]\n",
      " [ 13  25  36 111   6  19   0]\n",
      " [ 50  52  21  43  31   9   4]\n",
      " [ 26  36  35   9   6  80  18]\n",
      " [  8  15   6   4   4  47 126]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61       210\n",
      "           2       0.46      0.63      0.53       210\n",
      "           3       0.55      0.88      0.68       210\n",
      "           4       0.58      0.53      0.55       210\n",
      "           5       0.48      0.15      0.23       210\n",
      "           6       0.42      0.38      0.40       210\n",
      "           7       0.84      0.60      0.70       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.53      1470\n",
      "weighted avg       0.56      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143  19  13   9   6  19   1]\n",
      " [  6 136  38  13   4  13   0]\n",
      " [  5  11 185   5   1   3   0]\n",
      " [ 14  21  32 111   5  27   0]\n",
      " [ 55  52  22  40  27   9   5]\n",
      " [ 24  38  34   8   3  83  20]\n",
      " [ 11  14   5   3   4  54 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.68      0.61       210\n",
      "           2       0.47      0.65      0.54       210\n",
      "           3       0.56      0.88      0.69       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.54      0.13      0.21       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.82      0.57      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.52      1470\n",
      "weighted avg       0.56      0.55      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.21972789115646257\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[  6   0   1   1 193   8   1]\n",
      " [  3   0   1   1 196   8   1]\n",
      " [  2   4   0   4 200   0   0]\n",
      " [  2   0   0   5 193   9   1]\n",
      " [  7   2   0   3 183   9   6]\n",
      " [  2   1   2   2 146  44  13]\n",
      " [  1   0   0   0  62  62  85]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.03      0.05       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.31      0.02      0.04       210\n",
      "           5       0.16      0.87      0.26       210\n",
      "           6       0.31      0.21      0.25       210\n",
      "           7       0.79      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.26      0.22      0.16      1470\n",
      "weighted avg       0.26      0.22      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   1   1   2  24  19   1]\n",
      " [  6 154  11  15   6  18   0]\n",
      " [  0   8 191   5   0   6   0]\n",
      " [  7  15  27 116  17  23   5]\n",
      " [ 41  20   8  14 119   4   4]\n",
      " [  7  21  14  19   1 124  24]\n",
      " [  9   3   6   5   2  37 148]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73       210\n",
      "           2       0.69      0.73      0.71       210\n",
      "           3       0.74      0.91      0.82       210\n",
      "           4       0.66      0.55      0.60       210\n",
      "           5       0.70      0.57      0.63       210\n",
      "           6       0.54      0.59      0.56       210\n",
      "           7       0.81      0.70      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.24693877551020407\n",
      "Confusion Matrix of SVM is:\n",
      " [[  9   4 186   2   5   2   2]\n",
      " [  1   8 193   4   2   2   0]\n",
      " [  0   1 208   0   1   0   0]\n",
      " [  7   5 155  31   6   6   0]\n",
      " [ 11  11 156   9  10   7   6]\n",
      " [  5   3 163   4   1  24  10]\n",
      " [  2   1 125   0   1   8  73]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.04      0.07       210\n",
      "           2       0.24      0.04      0.07       210\n",
      "           3       0.18      0.99      0.30       210\n",
      "           4       0.62      0.15      0.24       210\n",
      "           5       0.38      0.05      0.08       210\n",
      "           6       0.49      0.11      0.19       210\n",
      "           7       0.80      0.35      0.49       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.42      0.25      0.20      1470\n",
      "weighted avg       0.42      0.25      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of SVM is:\n",
      " [[144   3   0   3  27  17  16]\n",
      " [  1 126  16  14  20  31   2]\n",
      " [  0   8 182   8   3   9   0]\n",
      " [  4  12  17 111  23  27  16]\n",
      " [ 23  13   5  18 111   3  37]\n",
      " [  1  10   3   9   4 129  54]\n",
      " [  0   1   0   0   1  29 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.69      0.75       210\n",
      "           2       0.73      0.60      0.66       210\n",
      "           3       0.82      0.87      0.84       210\n",
      "           4       0.68      0.53      0.60       210\n",
      "           5       0.59      0.53      0.56       210\n",
      "           6       0.53      0.61      0.57       210\n",
      "           7       0.59      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6829931972789116\n",
      "Confusion Matrix of SVM is:\n",
      " [[166   1   0   2  22  18   1]\n",
      " [  2 125  29  16   8  30   0]\n",
      " [  0   4 181  16   1   8   0]\n",
      " [  2  10  23 130  14  30   1]\n",
      " [ 56  18   9  23  93   6   5]\n",
      " [  4  11  10  14   3 143  25]\n",
      " [  0   1   1   0   2  40 166]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.79      0.75       210\n",
      "           2       0.74      0.60      0.66       210\n",
      "           3       0.72      0.86      0.78       210\n",
      "           4       0.65      0.62      0.63       210\n",
      "           5       0.65      0.44      0.53       210\n",
      "           6       0.52      0.68      0.59       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22380952380952382\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0   0   0 201]\n",
      " [  0   0  58   0   0   0 152]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  0   0  21   0   0   0 189]\n",
      " [  0   0  47   0   0   0 163]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   4   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.46      0.59      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.98      0.29       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.09      0.22      0.12      1470\n",
      "weighted avg       0.09      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2938775510204082\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   2   7   0   0   0 123]\n",
      " [  1  25  33   0   0   0 151]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  3   3  18   0   0   0 186]\n",
      " [ 53  15  32   0   0   0 110]\n",
      " [  1   1   2   0   0   0 206]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.37      0.45       210\n",
      "           2       0.53      0.12      0.19       210\n",
      "           3       0.56      0.59      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.19      0.98      0.32       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.27      0.29      0.22      1470\n",
      "weighted avg       0.27      0.29      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   4   0   8   0  43]\n",
      " [  2  25  33   0   0   0 150]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  5   3  18   0   0   0 184]\n",
      " [ 95  13  23   0  20   0  59]\n",
      " [  3   1   2   0   0   0 204]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.73      0.66       210\n",
      "           2       0.57      0.12      0.20       210\n",
      "           3       0.60      0.59      0.59       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.71      0.10      0.17       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.22      0.98      0.36       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.28      1470\n",
      "weighted avg       0.38      0.36      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   0  12  43   0]\n",
      " [  1  25  33   0   1 149   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 83   7  14   0  47  57   2]\n",
      " [  3   1   2   0   0 196   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.73      0.68       210\n",
      "           2       0.66      0.12      0.20       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.77      0.22      0.35       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.54      0.42      0.39      1470\n",
      "weighted avg       0.54      0.42      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44829931972789117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   1   0   0  18  43   0]\n",
      " [  1  57  26   0   1 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 68  18  14   1  61  46   2]\n",
      " [  2   2   2   0   1 195   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.70      0.68       210\n",
      "           2       0.70      0.27      0.39       210\n",
      "           3       0.66      0.59      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.29      0.42       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.43      1470\n",
      "weighted avg       0.55      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.463265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   1   0   0  13  43   0]\n",
      " [  1  56  25   0   3 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 74  16  14   1  56  47   2]\n",
      " [  3   2   2   0   0 192  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.73      0.69       210\n",
      "           2       0.71      0.27      0.39       210\n",
      "           3       0.67      0.59      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.77      0.27      0.40       210\n",
      "           6       0.25      0.91      0.39       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.56      0.46      0.44      1470\n",
      "weighted avg       0.56      0.46      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  25  43   0]\n",
      " [  1  89  22   0   3  94   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17   0   2 180   1]\n",
      " [ 53  16  14   0  82  43   2]\n",
      " [  2   3   2   0   1 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69       210\n",
      "           2       0.77      0.42      0.55       210\n",
      "           3       0.68      0.59      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.39      0.51       210\n",
      "           6       0.26      0.91      0.40       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  21  43   0]\n",
      " [  1  90  20   2   4  92   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17  22   3 158   0]\n",
      " [ 58  14  12   3  81  41   1]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.69      0.69       210\n",
      "           2       0.78      0.43      0.55       210\n",
      "           3       0.69      0.59      0.64       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.74      0.39      0.51       210\n",
      "           6       0.27      0.91      0.41       210\n",
      "           7       0.89      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.70      0.51      0.52      1470\n",
      "weighted avg       0.70      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  21  46   0]\n",
      " [  1  91  19   5   4  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   6  16  38   2 142   1]\n",
      " [ 56  16  11   2  78  44   3]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.68      0.68       210\n",
      "           2       0.77      0.43      0.55       210\n",
      "           3       0.71      0.59      0.64       210\n",
      "           4       0.84      0.18      0.30       210\n",
      "           5       0.74      0.37      0.50       210\n",
      "           6       0.27      0.91      0.42       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.53      1470\n",
      "weighted avg       0.70      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  23  45   0]\n",
      " [  4  89  19   3   5  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  6   3  16  47   4 133   1]\n",
      " [ 53  14  11   4  83  42   3]\n",
      " [  4   2   2   2   0 189  11]\n",
      " [  0   1   3   0   1 105 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.67       210\n",
      "           2       0.81      0.42      0.56       210\n",
      "           3       0.71      0.59      0.64       210\n",
      "           4       0.84      0.22      0.35       210\n",
      "           5       0.72      0.40      0.51       210\n",
      "           6       0.27      0.90      0.42       210\n",
      "           7       0.86      0.48      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  22  45   0]\n",
      " [  3  88  30   4   6  78   1]\n",
      " [  0   0 141   0   0  69   0]\n",
      " [  7   3  25  47   3 124   1]\n",
      " [ 54  16  12   5  80  40   3]\n",
      " [  4   2   6   2   0 185  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.68      0.68       210\n",
      "           2       0.79      0.42      0.55       210\n",
      "           3       0.64      0.67      0.66       210\n",
      "           4       0.81      0.22      0.35       210\n",
      "           5       0.72      0.38      0.50       210\n",
      "           6       0.29      0.88      0.43       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.68      0.53      0.54      1470\n",
      "weighted avg       0.68      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5428571428571428\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  25  43   0]\n",
      " [  3  95  26   2   6  78   0]\n",
      " [  0   0 148   0   0  62   0]\n",
      " [  7   3  25  45   6 124   0]\n",
      " [ 53  17  12   5  86  35   2]\n",
      " [  3   2   9   3   0 182  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.68       210\n",
      "           2       0.80      0.45      0.58       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.82      0.21      0.34       210\n",
      "           5       0.70      0.41      0.52       210\n",
      "           6       0.29      0.87      0.43       210\n",
      "           7       0.89      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0   0  23  37   0]\n",
      " [  3  97  26   2   3  79   0]\n",
      " [  0   0 147   0   1  62   0]\n",
      " [  6   3  24  46   6 124   1]\n",
      " [ 53  17  11   6  85  36   2]\n",
      " [  3   2   9   3   0 183  10]\n",
      " [  0   1   4   1   0 104 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.70       210\n",
      "           2       0.80      0.46      0.59       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.79      0.22      0.34       210\n",
      "           5       0.72      0.40      0.52       210\n",
      "           6       0.29      0.87      0.44       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   1   0   0  26  37   0]\n",
      " [  2  96  26   2   4  80   0]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  6   3  23  46   6 125   1]\n",
      " [ 47  17  11   7  90  35   3]\n",
      " [  3   2   9   3   0 180  13]\n",
      " [  0   1   4   1   1  98 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.80      0.46      0.58       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.78      0.22      0.34       210\n",
      "           5       0.70      0.43      0.53       210\n",
      "           6       0.29      0.86      0.44       210\n",
      "           7       0.86      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   1   0   0  19  34   0]\n",
      " [  3  99  24   1   3  79   1]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  5   4  23  45   8 124   1]\n",
      " [ 60  16  11   7  82  30   4]\n",
      " [  2   2   9   2   2 181  12]\n",
      " [  0   1   5   0   0  99 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.72       210\n",
      "           2       0.80      0.47      0.59       210\n",
      "           3       0.67      0.70      0.68       210\n",
      "           4       0.82      0.21      0.34       210\n",
      "           5       0.71      0.39      0.50       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.69      0.55      0.56      1470\n",
      "weighted avg       0.69      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  23  35   0]\n",
      " [  3 104  24   1   4  73   1]\n",
      " [  0   0 145   1   2  62   0]\n",
      " [  7   3  22  46   7 124   1]\n",
      " [ 60  20  10   5  83  27   5]\n",
      " [  2   2   9   2   2 180  13]\n",
      " [  0   1   4   1   0 100 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.79      0.50      0.61       210\n",
      "           3       0.68      0.69      0.68       210\n",
      "           4       0.82      0.22      0.35       210\n",
      "           5       0.69      0.40      0.50       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.84      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.68      0.55      0.56      1470\n",
      "weighted avg       0.68      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5687074829931973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   1   0   0  23  34   0]\n",
      " [  6 103  25   1   6  68   1]\n",
      " [  0   0 155   1   2  52   0]\n",
      " [  5   3  25  47   7 122   1]\n",
      " [ 52  19  11   6  92  27   3]\n",
      " [  3   0   8   3   1 182  13]\n",
      " [  0   1   4   1   0  99 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.81      0.49      0.61       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.80      0.22      0.35       210\n",
      "           5       0.70      0.44      0.54       210\n",
      "           6       0.31      0.87      0.46       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.69      0.57      0.57      1470\n",
      "weighted avg       0.69      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   1  24  33   0]\n",
      " [  3 104  25  14   6  58   0]\n",
      " [  0   0 155   3   2  50   0]\n",
      " [  6   3  25  58   7 110   1]\n",
      " [ 57  19  11  11  88  21   3]\n",
      " [  2   2   8  11   2 173  12]\n",
      " [  0   2   4   2   1  97 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.70       210\n",
      "           2       0.79      0.50      0.61       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.58      0.28      0.37       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.32      0.82      0.46       210\n",
      "           7       0.87      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.66      0.57      0.57      1470\n",
      "weighted avg       0.66      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   1   0   1  21  32   0]\n",
      " [  3 105  25  11   5  60   1]\n",
      " [  0   0 154   3   2  51   0]\n",
      " [  4   4  23  55  11 112   1]\n",
      " [ 52  21  11  10  91  20   5]\n",
      " [  2   3   7  11   1 173  13]\n",
      " [  0   2   4   2   0  97 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.77      0.50      0.61       210\n",
      "           3       0.69      0.73      0.71       210\n",
      "           4       0.59      0.26      0.36       210\n",
      "           5       0.69      0.43      0.53       210\n",
      "           6       0.32      0.82      0.46       210\n",
      "           7       0.84      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.66      0.57      0.58      1470\n",
      "weighted avg       0.66      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   1   0   1  23  33   0]\n",
      " [  3 106  24  11   5  60   1]\n",
      " [  0   2 152   3   2  51   0]\n",
      " [  7   6  23  57   5 111   1]\n",
      " [ 56  21  11  10  86  23   3]\n",
      " [  2   1   5  13   3 168  18]\n",
      " [  0   2   3   3   0  91 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.72      0.71       210\n",
      "           2       0.76      0.50      0.61       210\n",
      "           3       0.70      0.72      0.71       210\n",
      "           4       0.58      0.27      0.37       210\n",
      "           5       0.69      0.41      0.51       210\n",
      "           6       0.31      0.80      0.45       210\n",
      "           7       0.83      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.65      0.57      0.57      1470\n",
      "weighted avg       0.65      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   4   0   2  30  22   0]\n",
      " [  5 134  27  10  12  22   0]\n",
      " [  0   8 186   6   3   6   1]\n",
      " [  9  22  37  93  12  34   3]\n",
      " [ 50  27  12  12  94  13   2]\n",
      " [ 13  19   8  22   5 120  23]\n",
      " [  1   9   2   1   1  42 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.72      0.69       210\n",
      "           2       0.60      0.64      0.62       210\n",
      "           3       0.68      0.89      0.77       210\n",
      "           4       0.64      0.44      0.52       210\n",
      "           5       0.60      0.45      0.51       210\n",
      "           6       0.46      0.57      0.51       210\n",
      "           7       0.84      0.73      0.78       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   6   4  17  20   4]\n",
      " [  1  71  57  28  10  38   5]\n",
      " [  0   0 123  22   0  61   4]\n",
      " [  3   6  21 109  11  41  19]\n",
      " [ 67  14  34  16  64   7   8]\n",
      " [  3   8   3  35   2 114  45]\n",
      " [  0   2   3   1   1  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.70      0.34      0.46       210\n",
      "           3       0.50      0.59      0.54       210\n",
      "           4       0.51      0.52      0.51       210\n",
      "           5       0.61      0.30      0.41       210\n",
      "           6       0.38      0.54      0.44       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   3   4  22  22   4]\n",
      " [  1 109  36  19   4  37   4]\n",
      " [  0   0 145   5   0  54   6]\n",
      " [  4   9  20 113  11  38  15]\n",
      " [ 60  22  20  14  78   7   9]\n",
      " [  3   9   5  31   3 116  43]\n",
      " [  0   4   3   0   1  26 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71       210\n",
      "           2       0.70      0.52      0.60       210\n",
      "           3       0.62      0.69      0.66       210\n",
      "           4       0.61      0.54      0.57       210\n",
      "           5       0.66      0.37      0.47       210\n",
      "           6       0.39      0.55      0.45       210\n",
      "           7       0.68      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   3   6  24  19   1]\n",
      " [  1 103  36  25   4  40   1]\n",
      " [  0   0 146   8   0  56   0]\n",
      " [  4  10  19 127  11  35   4]\n",
      " [ 58  23  19  16  82   5   7]\n",
      " [  3  10   6  44   2 119  26]\n",
      " [  0   5   3   9   0  27 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.68      0.49      0.57       210\n",
      "           3       0.63      0.70      0.66       210\n",
      "           4       0.54      0.60      0.57       210\n",
      "           5       0.67      0.39      0.49       210\n",
      "           6       0.40      0.57      0.47       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   1   6  21  21   1]\n",
      " [  1 105  35  25   3  40   1]\n",
      " [  0   0 146   5   0  59   0]\n",
      " [  4  12  17 124  10  41   2]\n",
      " [ 58  24  13  17  86   5   7]\n",
      " [  3  10   6  43   2 120  26]\n",
      " [  0   5   2   6   0  29 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.55      0.59      0.57       210\n",
      "           5       0.70      0.41      0.52       210\n",
      "           6       0.38      0.57      0.46       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   2   4  20  24   1]\n",
      " [  1 108  38  22   4  36   1]\n",
      " [  0   0 156   5   0  49   0]\n",
      " [  4  10  20 112  13  48   3]\n",
      " [ 69  24  19  16  68   8   6]\n",
      " [  3   8   6  31   2 133  27]\n",
      " [  0   3   3   0   1  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.75      0.71       210\n",
      "           2       0.70      0.51      0.59       210\n",
      "           3       0.64      0.74      0.69       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.63      0.32      0.43       210\n",
      "           6       0.39      0.63      0.49       210\n",
      "           7       0.81      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.61      1470\n",
      "weighted avg       0.63      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   4  23  23   1]\n",
      " [  1 110  37  23   3  35   1]\n",
      " [  0   0 156   4   0  50   0]\n",
      " [  3  17  21 114   6  47   2]\n",
      " [ 47  27  11  19  93   8   5]\n",
      " [  3  11   6  31   0 134  25]\n",
      " [  0   4   2   1   1  40 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.64      0.52      0.58       210\n",
      "           3       0.67      0.74      0.70       210\n",
      "           4       0.58      0.54      0.56       210\n",
      "           5       0.74      0.44      0.55       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   4   3  19  26   1]\n",
      " [  1 111  36  23   2  36   1]\n",
      " [  0   0 156   4   0  50   0]\n",
      " [  3  15  20 112   9  49   2]\n",
      " [ 57  28  18  16  76   9   6]\n",
      " [  3  11   4  31   0 136  25]\n",
      " [  0   4   2   1   1  40 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.65      0.53      0.58       210\n",
      "           3       0.65      0.74      0.69       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.71      0.36      0.48       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.82      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   0   3  20  27   1]\n",
      " [  1 111  36  24   1  36   1]\n",
      " [  0   0 156  14   0  40   0]\n",
      " [  4  17  18 119   3  46   3]\n",
      " [ 58  27  10  21  83   6   5]\n",
      " [  3   9   6  30   0 138  24]\n",
      " [  0   4   2   1   0  40 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.56      0.57      0.56       210\n",
      "           5       0.78      0.40      0.52       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   2   0   4  21  24   1]\n",
      " [  1 111  36  21   2  38   1]\n",
      " [  0   0 157  15   0  38   0]\n",
      " [  3  15  20 117   7  46   2]\n",
      " [ 55  27  11  18  88   7   4]\n",
      " [  3   9   6  30   0 135  27]\n",
      " [  0   4   2   0   1  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.68      0.75      0.71       210\n",
      "           4       0.57      0.56      0.56       210\n",
      "           5       0.74      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.82      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6387755102040816\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0   4  19  24   1]\n",
      " [  1 110  38  23   3  34   1]\n",
      " [  0   0 161  15   0  34   0]\n",
      " [  3  14  21 118   7  45   2]\n",
      " [ 52  26  11  18  93   6   4]\n",
      " [  3   8   7  31   0 134  27]\n",
      " [  0   4   2   0   0  41 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       210\n",
      "           2       0.67      0.52      0.59       210\n",
      "           3       0.67      0.77      0.72       210\n",
      "           4       0.56      0.56      0.56       210\n",
      "           5       0.76      0.44      0.56       210\n",
      "           6       0.42      0.64      0.51       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   0   4  22  25   1]\n",
      " [  1 117  30  17   5  39   1]\n",
      " [  0   0 158  13   0  39   0]\n",
      " [  3  14  21 117   8  45   2]\n",
      " [ 56  26   9  21  88   6   4]\n",
      " [  3  12   7  28   0 133  27]\n",
      " [  0   3   2   0   1  41 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.70      0.75      0.72       210\n",
      "           4       0.58      0.56      0.57       210\n",
      "           5       0.71      0.42      0.53       210\n",
      "           6       0.41      0.63      0.49       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.636734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   4  22  24   1]\n",
      " [  1 112  36  23   3  34   1]\n",
      " [  0   0 162  13   0  35   0]\n",
      " [  3  13  20 116  11  45   2]\n",
      " [ 55  26   9  19  90   6   5]\n",
      " [  3   9   7  29   1 136  25]\n",
      " [  0   4   2   0   0  41 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.67      0.53      0.60       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.57      0.55      0.56       210\n",
      "           5       0.71      0.43      0.53       210\n",
      "           6       0.42      0.65      0.51       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   3  22  25   1]\n",
      " [  1 117  31  23   3  34   1]\n",
      " [  0   1 162  12   0  35   0]\n",
      " [  3  14  20 119   6  46   2]\n",
      " [ 47  28  10  16  97   8   4]\n",
      " [  3   8   7  31   0 135  26]\n",
      " [  0   3   2   0   0  40 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.70      0.77      0.73       210\n",
      "           4       0.58      0.57      0.57       210\n",
      "           5       0.76      0.46      0.57       210\n",
      "           6       0.42      0.64      0.51       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   0   4  22  24   1]\n",
      " [  1 117  34  19   2  36   1]\n",
      " [  0   0 162  15   0  33   0]\n",
      " [  4  14  21 120   5  44   2]\n",
      " [ 52  29  10  17  91   7   4]\n",
      " [  3  11   7  27   0 137  25]\n",
      " [  0   4   2   1   0  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.74       210\n",
      "           2       0.66      0.56      0.61       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.76      0.43      0.55       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   4  22  24   1]\n",
      " [  1 114  35  20   2  37   1]\n",
      " [  0   1 165  12   0  32   0]\n",
      " [  3  15  21 121   5  43   2]\n",
      " [ 44  29  10  16  99   8   4]\n",
      " [  3  10   8  28   0 137  24]\n",
      " [  0   4   2   1   0  41 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.65      0.54      0.59       210\n",
      "           3       0.68      0.79      0.73       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.77      0.47      0.59       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.84      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   4  23  24   1]\n",
      " [  1 117  32  22   2  35   1]\n",
      " [  0   1 166  10   0  33   0]\n",
      " [  3  14  23 118   8  42   2]\n",
      " [ 51  25  10  18  95   7   4]\n",
      " [  3  10   8  27   0 135  27]\n",
      " [  0   4   2   1   0  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.69      0.79      0.73       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.74      0.45      0.56       210\n",
      "           6       0.43      0.64      0.51       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   1   1   3  20  26   1]\n",
      " [  1 121  27  20   3  37   1]\n",
      " [  0   0 167  12   0  31   0]\n",
      " [  4  16  19 121   7  41   2]\n",
      " [ 49  28   9  18  95   8   3]\n",
      " [  3   9  10  27   0 136  25]\n",
      " [  0   5   2   1   0  39 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.67      0.58      0.62       210\n",
      "           3       0.71      0.80      0.75       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.76      0.45      0.57       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.84      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  22  25   0]\n",
      " [  1 123  29  19   3  34   1]\n",
      " [  0   0 170   9   0  31   0]\n",
      " [  3  16  20 124   5  40   2]\n",
      " [ 56  28  10  16  87   9   4]\n",
      " [  3  10  10  27   0 135  25]\n",
      " [  0   5   2   0   0  39 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.59      0.63       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.62      0.59      0.61       210\n",
      "           5       0.74      0.41      0.53       210\n",
      "           6       0.43      0.64      0.52       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   1   4  23  25   0]\n",
      " [  1 121  28  21   3  35   1]\n",
      " [  0   1 164  12   0  33   0]\n",
      " [  3  17  19 125   5  39   2]\n",
      " [ 46  27  10  16  98   7   6]\n",
      " [  3   8   9  28   0 138  24]\n",
      " [  0   5   2   1   0  39 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.74       210\n",
      "           2       0.67      0.58      0.62       210\n",
      "           3       0.70      0.78      0.74       210\n",
      "           4       0.60      0.60      0.60       210\n",
      "           5       0.76      0.47      0.58       210\n",
      "           6       0.44      0.66      0.52       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  22  25   0]\n",
      " [  1 122  29  20   3  34   1]\n",
      " [  0   3 167  10   0  30   0]\n",
      " [  3  15  21 122   7  40   2]\n",
      " [ 54  27   9  17  91   8   4]\n",
      " [  3   9   9  28   0 137  24]\n",
      " [  0   4   2   0   0  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.67      0.58      0.62       210\n",
      "           3       0.70      0.80      0.75       210\n",
      "           4       0.61      0.58      0.59       210\n",
      "           5       0.74      0.43      0.55       210\n",
      "           6       0.44      0.65      0.52       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[162   4   0   4  22  17   1]\n",
      " [  2 139  20  19   7  22   1]\n",
      " [  0   8 190   6   0   6   0]\n",
      " [  5  21  29 111  10  32   2]\n",
      " [ 53  32   9  13  93   8   2]\n",
      " [  6  19   9  15   3 141  17]\n",
      " [  1   7   2   1   0  35 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.77      0.74       210\n",
      "           2       0.60      0.66      0.63       210\n",
      "           3       0.73      0.90      0.81       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.54      0.67      0.60       210\n",
      "           7       0.88      0.78      0.83       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[172   2   2   6  23   5   0]\n",
      " [ 14 146  18  16  12   3   1]\n",
      " [  5  17 177   7   4   0   0]\n",
      " [ 21  13  16 124  27   8   1]\n",
      " [ 30  22   4  31 112   9   2]\n",
      " [ 47  20   8  35   5  64  31]\n",
      " [  4   1   1   0   1  24 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.82      0.68       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.57      0.59      0.58       210\n",
      "           5       0.61      0.53      0.57       210\n",
      "           6       0.57      0.30      0.40       210\n",
      "           7       0.84      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[153   2   2   5  24  20   4]\n",
      " [  6 150  11  13  16  14   0]\n",
      " [  0  11 174  16   3   6   0]\n",
      " [  7  10  17 124  28  22   2]\n",
      " [ 25  21   3  22 121  10   8]\n",
      " [  8  18   9  26   6 109  34]\n",
      " [  5   1   1   2   6  37 158]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.70      0.71      0.71       210\n",
      "           3       0.80      0.83      0.81       210\n",
      "           4       0.60      0.59      0.59       210\n",
      "           5       0.59      0.58      0.58       210\n",
      "           6       0.50      0.52      0.51       210\n",
      "           7       0.77      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  19   5   7  22  14   3]\n",
      " [ 25 130  17   7  21   9   1]\n",
      " [  5  17 166  11   5   6   0]\n",
      " [ 42  28  19  87  20  13   1]\n",
      " [ 63  47  15  27  53   2   3]\n",
      " [ 46  41  17  12  13  64  17]\n",
      " [ 28  20   6   6   7  20 123]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50       210\n",
      "           2       0.43      0.62      0.51       210\n",
      "           3       0.68      0.79      0.73       210\n",
      "           4       0.55      0.41      0.47       210\n",
      "           5       0.38      0.25      0.30       210\n",
      "           6       0.50      0.30      0.38       210\n",
      "           7       0.83      0.59      0.69       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.51      1470\n",
      "weighted avg       0.54      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[131  18   9  15  24  10   3]\n",
      " [ 15 138  19  17  15   5   1]\n",
      " [  6  17 163  16   8   0   0]\n",
      " [ 40  26  14  97  21  11   1]\n",
      " [ 53  43  15  31  60   4   4]\n",
      " [ 31  37  16  31  19  55  21]\n",
      " [ 21  13   4   5   7  36 124]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.62      0.52       210\n",
      "           2       0.47      0.66      0.55       210\n",
      "           3       0.68      0.78      0.72       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.39      0.29      0.33       210\n",
      "           6       0.45      0.26      0.33       210\n",
      "           7       0.81      0.59      0.68       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.51      1470\n",
      "weighted avg       0.53      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5197278911564626\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137  16   9  14  22   9   3]\n",
      " [ 14 125  24  16  23   8   0]\n",
      " [  5  17 168  10  10   0   0]\n",
      " [ 25  28  17  98  29  12   1]\n",
      " [ 55  49  12  28  56   3   7]\n",
      " [ 27  46  15  30  15  56  21]\n",
      " [ 18  12   6   3  10  37 124]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.65      0.56       210\n",
      "           2       0.43      0.60      0.50       210\n",
      "           3       0.67      0.80      0.73       210\n",
      "           4       0.49      0.47      0.48       210\n",
      "           5       0.34      0.27      0.30       210\n",
      "           6       0.45      0.27      0.33       210\n",
      "           7       0.79      0.59      0.68       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.51      1470\n",
      "weighted avg       0.52      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138  23   5   9  23  10   2]\n",
      " [ 17 132  25  16  14   6   0]\n",
      " [  7  19 161  14   7   2   0]\n",
      " [ 22  27  18 108  21  14   0]\n",
      " [ 55  53  13  27  55   2   5]\n",
      " [ 31  44  14  29  17  57  18]\n",
      " [ 12  13   7   3  14  37 124]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.66      0.56       210\n",
      "           2       0.42      0.63      0.51       210\n",
      "           3       0.66      0.77      0.71       210\n",
      "           4       0.52      0.51      0.52       210\n",
      "           5       0.36      0.26      0.30       210\n",
      "           6       0.45      0.27      0.34       210\n",
      "           7       0.83      0.59      0.69       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[131  25  15   3  16  17   3]\n",
      " [ 17 136  26   7  17   7   0]\n",
      " [  6  21 168   4   7   4   0]\n",
      " [ 21  33  26  97  18  15   0]\n",
      " [ 48  57  14  27  56   3   5]\n",
      " [ 30  63  13   7  16  64  17]\n",
      " [  9  17  10   2  14  31 127]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.62      0.56       210\n",
      "           2       0.39      0.65      0.48       210\n",
      "           3       0.62      0.80      0.70       210\n",
      "           4       0.66      0.46      0.54       210\n",
      "           5       0.39      0.27      0.32       210\n",
      "           6       0.45      0.30      0.36       210\n",
      "           7       0.84      0.60      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135  18  14   3  18  19   3]\n",
      " [ 17 130  26  10  12  15   0]\n",
      " [  8  15 167   4   6  10   0]\n",
      " [ 23  26  24  95  17  25   0]\n",
      " [ 49  57  15  27  54   5   3]\n",
      " [ 30  40  15   6  16  85  18]\n",
      " [ 12  16   7   3  13  34 125]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.64      0.56       210\n",
      "           2       0.43      0.62      0.51       210\n",
      "           3       0.62      0.80      0.70       210\n",
      "           4       0.64      0.45      0.53       210\n",
      "           5       0.40      0.26      0.31       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.84      0.60      0.70       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.22040816326530613\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[  6   0   1   1 193   8   1]\n",
      " [  3   0   1   1 196   8   1]\n",
      " [  2   4   0   4 200   0   0]\n",
      " [  2   0   0   5 194   8   1]\n",
      " [  7   2   0   3 182  10   6]\n",
      " [  1   1   2   3 144  47  12]\n",
      " [  1   0   0   0  63  62  84]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.03      0.05       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.29      0.02      0.04       210\n",
      "           5       0.16      0.87      0.26       210\n",
      "           6       0.33      0.22      0.27       210\n",
      "           7       0.80      0.40      0.53       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.26      0.22      0.17      1470\n",
      "weighted avg       0.26      0.22      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 198   4   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 33  18   8  22 123   3   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.63      0.62      0.63       210\n",
      "           5       0.72      0.59      0.64       210\n",
      "           6       0.65      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of SVM is:\n",
      " [[160   2   0   4  22  20   2]\n",
      " [  5 155  11  14   7  18   0]\n",
      " [  1   9 178  13   1   8   0]\n",
      " [  7  20  27 115  14  25   2]\n",
      " [ 38  21   7  23 114   3   4]\n",
      " [  9  22  12  22   1 123  21]\n",
      " [  7   5   6   4   2  34 152]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.76      0.73       210\n",
      "           2       0.66      0.74      0.70       210\n",
      "           3       0.74      0.85      0.79       210\n",
      "           4       0.59      0.55      0.57       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.53      0.59      0.56       210\n",
      "           7       0.84      0.72      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.27006802721088435\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 10   3 186   2   6   1   2]\n",
      " [  1  20 177   6   3   3   0]\n",
      " [  0   2 205   1   1   1   0]\n",
      " [  9   4 139  39  14   5   0]\n",
      " [  5   7 169  11  12   3   3]\n",
      " [ 13   9 136   6   6  27  13]\n",
      " [  1   2 108   0   0  15  84]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.05      0.08       210\n",
      "           2       0.43      0.10      0.16       210\n",
      "           3       0.18      0.98      0.31       210\n",
      "           4       0.60      0.19      0.28       210\n",
      "           5       0.29      0.06      0.10       210\n",
      "           6       0.49      0.13      0.20       210\n",
      "           7       0.82      0.40      0.54       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.44      0.27      0.24      1470\n",
      "weighted avg       0.44      0.27      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of SVM is:\n",
      " [[140   4   5   5  27  20   9]\n",
      " [  1 143  12  16  15  21   2]\n",
      " [  0  11 172  16   1   9   1]\n",
      " [  5  14  21 118  21  21  10]\n",
      " [ 31  22   8  30  89  10  20]\n",
      " [  4  19   8  13   5 109  52]\n",
      " [  1   1   2   1   0  26 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.71       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.75      0.82      0.79       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.56      0.42      0.48       210\n",
      "           6       0.50      0.52      0.51       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.64      0.65      0.64      1470\n",
      "weighted avg       0.64      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   3   0   3  21  20   2]\n",
      " [  1 149  11  15  12  22   0]\n",
      " [  0   7 179  17   1   6   0]\n",
      " [  3  14  18 134  17  23   1]\n",
      " [ 41  25   8  28  93   6   9]\n",
      " [  5  22   4  22   3 124  30]\n",
      " [  2   1   0   2   1  31 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.67      0.71      0.69       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.61      0.64      0.62       210\n",
      "           5       0.63      0.44      0.52       210\n",
      "           6       0.53      0.59      0.56       210\n",
      "           7       0.80      0.82      0.81       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   0   0   0 209]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   0   1   0   0   0 128]\n",
      " [  1   9  18   0   0   0 182]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   0   0 199]\n",
      " [ 63   0   5   0   0   0 142]\n",
      " [  1   0   1   0   0   0 208]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.36      0.28      0.21      1470\n",
      "weighted avg       0.36      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   1   0  41   0  44]\n",
      " [  2   9  18   0   0   0 181]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   3   0 196]\n",
      " [ 71   0   5   0  58   0  76]\n",
      " [  2   0   1   0   1   0 206]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.56      0.28      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      1.00      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.45      0.35      0.29      1470\n",
      "weighted avg       0.45      0.35      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1   0  42  44   0]\n",
      " [  1   9  18   0   1 180   1]\n",
      " [  0   0 108   0   0 102   0]\n",
      " [  3   0   8   0   3 195   1]\n",
      " [ 54   0   5   0  75  74   2]\n",
      " [  1   0   1   0   2 198   8]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.59      0.63       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.36      0.45       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.38      1470\n",
      "weighted avg       0.59      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   1   0   0  37  44   0]\n",
      " [  1  24   3   0   1 180   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 50   4   1   0  79  73   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.47      0.11      0.18       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.38      0.48       210\n",
      "           6       0.22      0.93      0.35       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.55      0.42      0.41      1470\n",
      "weighted avg       0.55      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  43  44   0]\n",
      " [  1  50   3   0   1 154   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 40  16   1   1  88  61   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.65       210\n",
      "           2       0.56      0.24      0.33       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.64      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.57      0.44      0.44      1470\n",
      "weighted avg       0.57      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45850340136054424\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   7   2   0   3 194   1]\n",
      " [ 38  18   1   2  89  59   3]\n",
      " [  1   2   0   0   2 195  10]\n",
      " [  0   0   0   0   1 110  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.59      0.65       210\n",
      "           2       0.64      0.36      0.46       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.58      0.46      0.46      1470\n",
      "weighted avg       0.58      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47346938775510206\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   5   0   1 127   1]\n",
      " [  0  12 110   0   0  88   0]\n",
      " [  3   7   2   0   3 194   1]\n",
      " [ 34  18   1   2  93  60   2]\n",
      " [  2   2   0   0   1 196   9]\n",
      " [  0   0   0   0   0 111  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.65      0.36      0.46       210\n",
      "           3       0.93      0.52      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.67      0.44      0.53       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.47      1470\n",
      "weighted avg       0.59      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   0   1  41  44   0]\n",
      " [  1 104   5   1   1  98   0]\n",
      " [  0  26 111   0   0  73   0]\n",
      " [  3  19   2   0   3 182   1]\n",
      " [ 43  29   1   2  88  44   3]\n",
      " [  2   4   0   0   1 193  10]\n",
      " [  0   3   0   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64       210\n",
      "           2       0.56      0.50      0.52       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.66      0.42      0.51       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  20  44   0]\n",
      " [  1  89  20   0   2  97   1]\n",
      " [  0  11 131   0   0  68   0]\n",
      " [  5   8  13   0   1 182   1]\n",
      " [ 62  19  11   1  70  44   3]\n",
      " [  3   2   2   0   0 193  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.67      0.42      0.52       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.33      0.46       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.87      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   2   0   0  19  44   0]\n",
      " [  1  94  14   2   3  95   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  4   9  12  22   2 160   1]\n",
      " [ 54  17  11   3  80  43   2]\n",
      " [  3   2   2   0   0 193  10]\n",
      " [  0   1   2   0   0 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.70       210\n",
      "           2       0.70      0.45      0.54       210\n",
      "           3       0.76      0.63      0.69       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.77      0.38      0.51       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.52      1470\n",
      "weighted avg       0.70      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   0   1  35  43   0]\n",
      " [  1  95  14   4   2  93   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  2   8  16  34   4 145   1]\n",
      " [ 27  18  11   4 106  41   3]\n",
      " [  2   2   2   0   1 193  10]\n",
      " [  0   1   2   0   2 109  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.70       210\n",
      "           2       0.70      0.45      0.55       210\n",
      "           3       0.75      0.63      0.68       210\n",
      "           4       0.79      0.16      0.27       210\n",
      "           5       0.71      0.50      0.59       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.86      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  20  44   0]\n",
      " [  2  93   8   4   8  95   0]\n",
      " [  0  10 120   0  12  68   0]\n",
      " [  5   8   7  42  11 136   1]\n",
      " [ 51  19   1   5  92  39   3]\n",
      " [  3   2   1   2   1 192   9]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.88      0.57      0.69       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.63      0.44      0.52       210\n",
      "           6       0.28      0.91      0.43       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   2   0   1  21  35   0]\n",
      " [  2  96  11   6   2  93   0]\n",
      " [  0  10 126   6   0  68   0]\n",
      " [  5   8   8  50   2 136   1]\n",
      " [ 56  20   6   9  80  37   2]\n",
      " [  3   2   1   3   0 191  10]\n",
      " [  0   1   0   2   1 108  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.69      0.46      0.55       210\n",
      "           3       0.83      0.60      0.70       210\n",
      "           4       0.65      0.24      0.35       210\n",
      "           5       0.75      0.38      0.51       210\n",
      "           6       0.29      0.91      0.44       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.68      0.54      0.55      1470\n",
      "weighted avg       0.68      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   2   0   0  19  36   0]\n",
      " [  2  98  10   1   4  94   1]\n",
      " [  0  12 128   0   2  68   0]\n",
      " [  5  10   9  41   8 136   1]\n",
      " [ 48  23   4   5  91  36   3]\n",
      " [  1   2   1   2   3 191  10]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.66      0.47      0.55       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.69      0.43      0.53       210\n",
      "           6       0.29      0.91      0.43       210\n",
      "           7       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  24  34   0]\n",
      " [  2 111  10   2   5  80   0]\n",
      " [  0  10 130   0   2  68   0]\n",
      " [  4  18   8  41   9 129   1]\n",
      " [ 51  23   4   4  96  28   4]\n",
      " [  2   7   1   2   2 186  10]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.65      0.53      0.58       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.68      0.46      0.55       210\n",
      "           6       0.29      0.89      0.44       210\n",
      "           7       0.87      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   1  29  32   0]\n",
      " [  2 111  11   1   7  77   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  4  18  10  42   9 126   1]\n",
      " [ 44  22   5   4 102  29   4]\n",
      " [  1   6   1   2   4 187   9]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72       210\n",
      "           2       0.66      0.53      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.89      0.45       210\n",
      "           7       0.87      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   1   0   0  24  33   0]\n",
      " [  2 110  11   2   5  79   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  3  17  10  41  11 127   1]\n",
      " [ 47  22   5   5 100  26   5]\n",
      " [  2   5   1   2   3 185  12]\n",
      " [  0   1   0   0   4 103 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.66      0.52      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.67      0.48      0.56       210\n",
      "           6       0.30      0.88      0.45       210\n",
      "           7       0.84      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   0  27  35   0]\n",
      " [  2 106  12   3   9  77   1]\n",
      " [  0   8 139   3   1  59   0]\n",
      " [  3  15  12  40  12 126   2]\n",
      " [ 41  19   6   8 102  28   6]\n",
      " [  2   5   1   3   2 180  17]\n",
      " [  0   1   0   0   4  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.70      0.73       210\n",
      "           2       0.68      0.50      0.58       210\n",
      "           3       0.82      0.66      0.73       210\n",
      "           4       0.70      0.19      0.30       210\n",
      "           5       0.65      0.49      0.56       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.81      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.67      0.56      0.57      1470\n",
      "weighted avg       0.67      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   1  35  32   0]\n",
      " [  2 113  11   2   9  72   1]\n",
      " [  0  10 139   1   1  59   0]\n",
      " [  2  17  10  41  13 125   2]\n",
      " [ 28  24   4   5 122  21   6]\n",
      " [  1   5   1   3   3 183  14]\n",
      " [  0   1   0   0   3  95 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.66      0.54      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.77      0.20      0.31       210\n",
      "           5       0.66      0.58      0.62       210\n",
      "           6       0.31      0.87      0.46       210\n",
      "           7       0.83      0.53      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.59      1470\n",
      "weighted avg       0.70      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.6503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   2   0   4  31  22   1]\n",
      " [  2 134  14  24  13  19   4]\n",
      " [  0  12 174  15   1   7   1]\n",
      " [  3  18  17 109  20  31  12]\n",
      " [ 36  24   5  16 115   6   8]\n",
      " [  4  10   7  33   8 109  39]\n",
      " [  0   3   0   5   6  31 165]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.66      0.64      0.65       210\n",
      "           3       0.80      0.83      0.81       210\n",
      "           4       0.53      0.52      0.52       210\n",
      "           5       0.59      0.55      0.57       210\n",
      "           6       0.48      0.52      0.50       210\n",
      "           7       0.72      0.79      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.65      1470\n",
      "weighted avg       0.65      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[163   3   2   6  15  19   2]\n",
      " [  1  84  41  27   6  48   3]\n",
      " [  0   0 139   9   0  62   0]\n",
      " [  3  12  11 122  11  47   4]\n",
      " [ 63  22  12  21  77  10   5]\n",
      " [  5   6   2  50   2 119  26]\n",
      " [  0   1   0  13   2  31 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.66      0.40      0.50       210\n",
      "           3       0.67      0.66      0.67       210\n",
      "           4       0.49      0.58      0.53       210\n",
      "           5       0.68      0.37      0.48       210\n",
      "           6       0.35      0.57      0.44       210\n",
      "           7       0.80      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   2   5  20  21   4]\n",
      " [  1  93  42  22   7  40   5]\n",
      " [  0   7 145   6   0  49   3]\n",
      " [  4  14  12 110  14  40  16]\n",
      " [ 68  21   9  17  78  10   7]\n",
      " [  3  11   2  31   3 120  40]\n",
      " [  0   2   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.75      0.71       210\n",
      "           2       0.62      0.44      0.52       210\n",
      "           3       0.68      0.69      0.69       210\n",
      "           4       0.58      0.52      0.55       210\n",
      "           5       0.63      0.37      0.47       210\n",
      "           6       0.39      0.57      0.46       210\n",
      "           7       0.70      0.84      0.77       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   2   8  21  17   1]\n",
      " [  1  97  31  26   5  48   2]\n",
      " [  0   0 140   9   0  61   0]\n",
      " [  3   9  11 135  12  38   2]\n",
      " [ 59  20  10  21  88   6   6]\n",
      " [  2  11   2  39   4 125  27]\n",
      " [  0   4   0   9   1  28 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.68      0.46      0.55       210\n",
      "           3       0.71      0.67      0.69       210\n",
      "           4       0.55      0.64      0.59       210\n",
      "           5       0.67      0.42      0.52       210\n",
      "           6       0.39      0.60      0.47       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6258503401360545\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   2   6  20  21   2]\n",
      " [  1 101  31  26   4  46   1]\n",
      " [  0   0 146   8   0  56   0]\n",
      " [  3  13  13 126  11  43   1]\n",
      " [ 58  23   6  20  88   9   6]\n",
      " [  2  10   2  31   4 135  26]\n",
      " [  0   1   0   2   4  36 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.48      0.56       210\n",
      "           3       0.73      0.70      0.71       210\n",
      "           4       0.58      0.60      0.59       210\n",
      "           5       0.67      0.42      0.52       210\n",
      "           6       0.39      0.64      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   3  23  24   1]\n",
      " [  1 112  30  22   2  42   1]\n",
      " [  0   2 149   5   0  54   0]\n",
      " [  3  12  13 119  12  49   2]\n",
      " [ 59  22   6  19  89   9   6]\n",
      " [  2  10   2  27   4 138  27]\n",
      " [  0   3   0   0   1  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.69      0.53      0.60       210\n",
      "           3       0.74      0.71      0.72       210\n",
      "           4       0.61      0.57      0.59       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6319727891156462\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  23  24   2]\n",
      " [  1 108  31  23   4  42   1]\n",
      " [  0   0 150   2   0  58   0]\n",
      " [  4  14  13 117   7  53   2]\n",
      " [ 51  22   6  19  96  11   5]\n",
      " [  3   9   2  24   4 141  27]\n",
      " [  0   4   0   1   0  42 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.74      0.71      0.72       210\n",
      "           4       0.62      0.56      0.59       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.38      0.67      0.49       210\n",
      "           7       0.81      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   2   3  23  24   1]\n",
      " [  1 112  27  24   4  41   1]\n",
      " [  0   0 150   1   0  59   0]\n",
      " [  4  11  13 116  12  52   2]\n",
      " [ 47  24   6  20  96  12   5]\n",
      " [  2   9   2  28   4 137  28]\n",
      " [  0   3   0   1   2  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.70      0.53      0.60       210\n",
      "           3       0.75      0.71      0.73       210\n",
      "           4       0.60      0.55      0.58       210\n",
      "           5       0.68      0.46      0.55       210\n",
      "           6       0.38      0.65      0.48       210\n",
      "           7       0.82      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   2   3  22  27   1]\n",
      " [  1 114  26  22   4  42   1]\n",
      " [  0   1 152   4   0  53   0]\n",
      " [  3  14  13 116   9  53   2]\n",
      " [ 51  27   5  21  89  12   5]\n",
      " [  2   9   2  23   4 145  25]\n",
      " [  0   2   0   0   2  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.67      0.54      0.60       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.61      0.55      0.58       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   3   1   3  22  23   1]\n",
      " [  1 113  31  20   4  40   1]\n",
      " [  0   3 151   2   0  54   0]\n",
      " [  3  12  13 115  12  53   2]\n",
      " [ 47  21   6  20 101  10   5]\n",
      " [  2  10   2  28   4 139  25]\n",
      " [  0   3   0   0   1  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.74      0.72      0.73       210\n",
      "           4       0.61      0.55      0.58       210\n",
      "           5       0.70      0.48      0.57       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   1   1   4  24  25   1]\n",
      " [  1 114  31  20   3  40   1]\n",
      " [  0   1 153  10   0  46   0]\n",
      " [  3  14  12 121  10  48   2]\n",
      " [ 52  23   4  21  95  10   5]\n",
      " [  3   9   3  27   3 138  27]\n",
      " [  0   3   0   0   2  36 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.75      0.73      0.74       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.69      0.45      0.55       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  25  24   1]\n",
      " [  1 113  29  20   5  41   1]\n",
      " [  0   1 155   6   0  48   0]\n",
      " [  3  14  12 120   9  50   2]\n",
      " [ 41  27   5  20 102  10   5]\n",
      " [  2   8   2  28   3 140  27]\n",
      " [  0   3   0   0   1  36 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.67      0.54      0.60       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.61      0.57      0.59       210\n",
      "           5       0.70      0.49      0.57       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   1   4  26  24   1]\n",
      " [  1 116  27  20   4  41   1]\n",
      " [  0   1 155   5   0  49   0]\n",
      " [  3  12  13 121  11  48   2]\n",
      " [ 39  22   4  22 110   8   5]\n",
      " [  4   9   2  22   1 143  29]\n",
      " [  0   2   0   0   2  37 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.71      0.55      0.62       210\n",
      "           3       0.77      0.74      0.75       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.71      0.52      0.60       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   5  28  23   1]\n",
      " [  1 117  25  23   3  40   1]\n",
      " [  0   2 156   4   0  48   0]\n",
      " [  3  14  13 118  11  49   2]\n",
      " [ 49  22   5  23  99   7   5]\n",
      " [  2   9   3  23   4 143  26]\n",
      " [  0   1   0   0   1  39 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.70      0.56      0.62       210\n",
      "           3       0.77      0.74      0.76       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.68      0.47      0.56       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.83      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   5  28  23   1]\n",
      " [  1 114  27  20   7  40   1]\n",
      " [  0   5 153   5   0  47   0]\n",
      " [  3  14  12 120   9  50   2]\n",
      " [ 39  23   4  18 112   9   5]\n",
      " [  2   8   3  23   4 144  26]\n",
      " [  0   1   0   0   2  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.74       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.77      0.73      0.75       210\n",
      "           4       0.63      0.57      0.60       210\n",
      "           5       0.69      0.53      0.60       210\n",
      "           6       0.41      0.69      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  29  23   1]\n",
      " [  1 119  25  20   5  39   1]\n",
      " [  0   1 162   3   0  44   0]\n",
      " [  3  14  13 118   9  51   2]\n",
      " [ 40  21   5  18 112   9   5]\n",
      " [  1   9   3  20   4 146  27]\n",
      " [  0   1   0   0   2  42 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.53      0.60       210\n",
      "           6       0.41      0.70      0.52       210\n",
      "           7       0.82      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  26  23   1]\n",
      " [  1 119  25  21   4  39   1]\n",
      " [  0   1 162   2   0  45   0]\n",
      " [  2  15  13 120  11  47   2]\n",
      " [ 38  20   6  19 113   9   5]\n",
      " [  1   9   4  26   4 142  24]\n",
      " [  0   1   0   0   2  38 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.76       210\n",
      "           2       0.71      0.57      0.63       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   5  29  22   1]\n",
      " [  1 125  24  17   5  37   1]\n",
      " [  0   4 158  12   0  36   0]\n",
      " [  2  12  13 125  11  45   2]\n",
      " [ 40  21   5  21 110   8   5]\n",
      " [  2   8   3  25   2 144  26]\n",
      " [  0   1   0   0   2  41 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.72      0.60      0.65       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.69      0.52      0.60       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   3  27  24   0]\n",
      " [  1 124  23  18   6  37   1]\n",
      " [  0   6 157  11   0  36   0]\n",
      " [  2  13  12 124  12  45   2]\n",
      " [ 38  22   5  20 112   8   5]\n",
      " [  2   8   3  25   4 141  27]\n",
      " [  0   1   0   0   3  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.75       210\n",
      "           2       0.70      0.59      0.64       210\n",
      "           3       0.78      0.75      0.76       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.43      0.67      0.53       210\n",
      "           7       0.83      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   5  26  23   0]\n",
      " [  1 121  25  22   4  36   1]\n",
      " [  0   3 160  12   0  35   0]\n",
      " [  2  15  13 121  11  46   2]\n",
      " [ 38  20   4  19 115   9   5]\n",
      " [  2   7   3  25   3 143  27]\n",
      " [  0   1   0   0   2  36 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.75       210\n",
      "           2       0.72      0.58      0.64       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.59      0.58      0.58       210\n",
      "           5       0.71      0.55      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   1   4  24  22   1]\n",
      " [  1 122  23  23   4  36   1]\n",
      " [  0   3 159  11   0  37   0]\n",
      " [  2  13  12 125  11  45   2]\n",
      " [ 36  21   4  21 116   7   5]\n",
      " [  2   8   3  23   3 145  26]\n",
      " [  0   2   0   0   0  41 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.77       210\n",
      "           2       0.71      0.58      0.64       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.60      0.60      0.60       210\n",
      "           5       0.73      0.55      0.63       210\n",
      "           6       0.44      0.69      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   4  29  19   0]\n",
      " [  1 137  18  27   5  21   1]\n",
      " [  0   6 183  10   1  10   0]\n",
      " [  3  10  20 138  11  26   2]\n",
      " [ 26  24   5  22 125   3   5]\n",
      " [  3  11   6  27   5 129  29]\n",
      " [  1   2   0   0   5  27 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.73      0.77       210\n",
      "           2       0.71      0.65      0.68       210\n",
      "           3       0.78      0.87      0.82       210\n",
      "           4       0.61      0.66      0.63       210\n",
      "           5       0.69      0.60      0.64       210\n",
      "           6       0.55      0.61      0.58       210\n",
      "           7       0.83      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   2   0   6  25   9   0]\n",
      " [ 13 153  11  14  14   5   0]\n",
      " [  5  11 172  18   4   0   0]\n",
      " [ 17  10  13 135  25  10   0]\n",
      " [ 22  19   1  32 122  10   4]\n",
      " [ 32  20   4  36   2  85  31]\n",
      " [  3   1   1   0   2  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.80      0.71       210\n",
      "           2       0.71      0.73      0.72       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.56      0.64      0.60       210\n",
      "           5       0.63      0.58      0.60       210\n",
      "           6       0.58      0.40      0.48       210\n",
      "           7       0.83      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7387755102040816\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[157   2   6   7  25  13   0]\n",
      " [  2 168   4  14  15   5   2]\n",
      " [  0   3 200   3   0   4   0]\n",
      " [  3  18   5 145  20  11   8]\n",
      " [ 36  13   3  20 127   7   4]\n",
      " [ 11  20   9  15   7 118  30]\n",
      " [  4   0   0   3   4  28 171]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.75      0.80      0.77       210\n",
      "           3       0.88      0.95      0.92       210\n",
      "           4       0.70      0.69      0.70       210\n",
      "           5       0.64      0.60      0.62       210\n",
      "           6       0.63      0.56      0.60       210\n",
      "           7       0.80      0.81      0.80       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.73      0.74      0.74      1470\n",
      "weighted avg       0.73      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   8   2   4  35   7   4]\n",
      " [ 10 163   6   6  23   1   1]\n",
      " [  1   7 194   3   1   4   0]\n",
      " [ 24  27  18  99  30   6   6]\n",
      " [ 42  30   7  21 101   2   7]\n",
      " [ 32  28  10  16  11  72  41]\n",
      " [ 12   6   1   5   7  17 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.71      0.62       210\n",
      "           2       0.61      0.78      0.68       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.64      0.47      0.54       210\n",
      "           5       0.49      0.48      0.48       210\n",
      "           6       0.66      0.34      0.45       210\n",
      "           7       0.73      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   7   5   3  34   9   6]\n",
      " [  6 167   6  10  17   2   2]\n",
      " [  0   7 193   3   3   4   0]\n",
      " [ 15  20  21 108  33  10   3]\n",
      " [ 39  31   6  23 102   1   8]\n",
      " [ 26  25   9  15   9  84  42]\n",
      " [  8   3   0   4   4  27 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.70      0.65       210\n",
      "           2       0.64      0.80      0.71       210\n",
      "           3       0.80      0.92      0.86       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       0.50      0.49      0.50       210\n",
      "           6       0.61      0.40      0.48       210\n",
      "           7       0.73      0.78      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   8   4   5  39   9   4]\n",
      " [  5 165   7   8  20   1   4]\n",
      " [  0   6 194   4   2   4   0]\n",
      " [ 12  23  20 111  32   7   5]\n",
      " [ 39  27   6  22 106   1   9]\n",
      " [ 22  25   5  20  10  81  47]\n",
      " [  7   3   0   2   9  22 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.67      0.65       210\n",
      "           2       0.64      0.79      0.71       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.65      0.53      0.58       210\n",
      "           5       0.49      0.50      0.50       210\n",
      "           6       0.65      0.39      0.48       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   5   3   6  36   9   4]\n",
      " [  8 167   7   5  18   2   3]\n",
      " [  0   5 196   4   2   3   0]\n",
      " [ 11  28  24  97  37   6   7]\n",
      " [ 32  35   7  17 108   2   9]\n",
      " [ 27  22   6  19  11  78  47]\n",
      " [  7   3   0   1   7  23 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.70      0.67       210\n",
      "           2       0.63      0.80      0.70       210\n",
      "           3       0.81      0.93      0.87       210\n",
      "           4       0.65      0.46      0.54       210\n",
      "           5       0.49      0.51      0.50       210\n",
      "           6       0.63      0.37      0.47       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   3   3   6  40  10   4]\n",
      " [  6 164   9   5  21   2   3]\n",
      " [  0   6 196   3   2   3   0]\n",
      " [ 12  22  24  99  37   8   8]\n",
      " [ 27  33   5  16 119   3   7]\n",
      " [ 24  23   9  22  10  76  46]\n",
      " [  5   3   0   3   5  21 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.67       210\n",
      "           2       0.65      0.78      0.71       210\n",
      "           3       0.80      0.93      0.86       210\n",
      "           4       0.64      0.47      0.54       210\n",
      "           5       0.51      0.57      0.54       210\n",
      "           6       0.62      0.36      0.46       210\n",
      "           7       0.72      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   5   3   3  39  10   6]\n",
      " [  5 165  10   3  22   2   3]\n",
      " [  1   6 196   4   1   2   0]\n",
      " [ 10  22  25 100  36   9   8]\n",
      " [ 24  32   8  16 119   2   9]\n",
      " [ 27  19   9  21  12  78  44]\n",
      " [  6   3   0   2   5  20 174]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.67       210\n",
      "           2       0.65      0.79      0.71       210\n",
      "           3       0.78      0.93      0.85       210\n",
      "           4       0.67      0.48      0.56       210\n",
      "           5       0.51      0.57      0.54       210\n",
      "           6       0.63      0.37      0.47       210\n",
      "           7       0.71      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[100   2  31   6  35  26  10]\n",
      " [  0 108  34   7  33  24   4]\n",
      " [  0   4 171   8   5  22   0]\n",
      " [  5  16  27  56  59  32  15]\n",
      " [ 21  17   4   5 135  11  17]\n",
      " [ 11  11  14   8   8 100  58]\n",
      " [  0   0   0   1   2  44 163]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.48      0.58       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.61      0.81      0.70       210\n",
      "           4       0.62      0.27      0.37       210\n",
      "           5       0.49      0.64      0.55       210\n",
      "           6       0.39      0.48      0.43       210\n",
      "           7       0.61      0.78      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.56      1470\n",
      "weighted avg       0.59      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[108   3  21   4  39  27   8]\n",
      " [  0 102  35   7  35  27   4]\n",
      " [  1   9 166   8   4  22   0]\n",
      " [  7  14  21  51  70  34  13]\n",
      " [ 14  17   4   8 134   9  24]\n",
      " [ 10   8  13   8  14  96  61]\n",
      " [  0   0   0   1   5  43 161]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.51      0.62       210\n",
      "           2       0.67      0.49      0.56       210\n",
      "           3       0.64      0.79      0.71       210\n",
      "           4       0.59      0.24      0.34       210\n",
      "           5       0.45      0.64      0.52       210\n",
      "           6       0.37      0.46      0.41       210\n",
      "           7       0.59      0.77      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[165   4   3   4  22  12   0]\n",
      " [  2 170   3  17   8   8   2]\n",
      " [  0   4 200   2   1   3   0]\n",
      " [  4  16   6 149  22   9   4]\n",
      " [ 48  14   2  23 115   1   7]\n",
      " [ 13  20   8  24   6 109  30]\n",
      " [  3   1   0   2   3  36 165]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.79      0.74       210\n",
      "           2       0.74      0.81      0.77       210\n",
      "           3       0.90      0.95      0.93       210\n",
      "           4       0.67      0.71      0.69       210\n",
      "           5       0.65      0.55      0.59       210\n",
      "           6       0.61      0.52      0.56       210\n",
      "           7       0.79      0.79      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.72      0.73      0.73      1470\n",
      "weighted avg       0.72      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   5   1   3  42  16   5]\n",
      " [  3 162   3   8  23   9   2]\n",
      " [  0   7 188   8   3   4   0]\n",
      " [  4  15   3 136  29  22   1]\n",
      " [ 16  18   0  19 146   5   6]\n",
      " [  7  10   4  19  10 122  38]\n",
      " [  0   0   0   0   7  22 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.66      0.73       210\n",
      "           2       0.75      0.77      0.76       210\n",
      "           3       0.94      0.90      0.92       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.56      0.70      0.62       210\n",
      "           6       0.61      0.58      0.60       210\n",
      "           7       0.78      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7551020408163265\n",
      "Confusion Matrix of SVM is:\n",
      " [[147   2   1   1  33  23   3]\n",
      " [  3 162   4  16  14   9   2]\n",
      " [  0   5 192   9   2   2   0]\n",
      " [  3  13   5 136  25  25   3]\n",
      " [ 18  12   0  20 146   7   7]\n",
      " [  9   6   2  13   5 141  34]\n",
      " [  0   0   0   0   2  22 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.75       210\n",
      "           2       0.81      0.77      0.79       210\n",
      "           3       0.94      0.91      0.93       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.64      0.70      0.67       210\n",
      "           6       0.62      0.67      0.64       210\n",
      "           7       0.79      0.89      0.84       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   3   4   3  30  17   5]\n",
      " [  2 157  11  13  15  11   1]\n",
      " [  0   6 189   6   5   4   0]\n",
      " [  6  18   8 123  23  21  11]\n",
      " [ 33  17   1  18 126   7   8]\n",
      " [  7  13  12  29   5 104  40]\n",
      " [  1   1   0   2   3  33 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.70      0.73       210\n",
      "           2       0.73      0.75      0.74       210\n",
      "           3       0.84      0.90      0.87       210\n",
      "           4       0.63      0.59      0.61       210\n",
      "           5       0.61      0.60      0.60       210\n",
      "           6       0.53      0.50      0.51       210\n",
      "           7       0.72      0.81      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2578231292517007\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   4   0   0   0 206]\n",
      " [  0   0  51   0   0   0 159]\n",
      " [  0   0 169   0   0   0  41]\n",
      " [  0   0  24   0   0   0 186]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0  19   0   0   0 191]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.62      0.80      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.11      0.26      0.14      1470\n",
      "weighted avg       0.11      0.26      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   1   3   0 179   0  27]\n",
      " [  0  46   5   0 140   0  19]\n",
      " [  0   4 165   0  27   0  14]\n",
      " [  0   2  22   0 144   0  42]\n",
      " [  0   3   3   0 181   0  23]\n",
      " [  0   3  16   0  58   0 133]\n",
      " [  0   0   0   0  14   0 196]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.78      0.22      0.34       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.24      0.86      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.93      0.59       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.32      0.40      0.30      1470\n",
      "weighted avg       0.32      0.40      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   0   4   0  34  11  16]\n",
      " [ 20  46   5   0 120  13   6]\n",
      " [  2   3 158   8  25   9   5]\n",
      " [ 19   1  14   9 125  15  27]\n",
      " [ 35   3   2   1 146   3  20]\n",
      " [ 32   1  14   4  26  60  73]\n",
      " [  9   0   0   0   5  32 164]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.69      0.61       210\n",
      "           2       0.85      0.22      0.35       210\n",
      "           3       0.80      0.75      0.78       210\n",
      "           4       0.41      0.04      0.08       210\n",
      "           5       0.30      0.70      0.42       210\n",
      "           6       0.42      0.29      0.34       210\n",
      "           7       0.53      0.78      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.46      1470\n",
      "weighted avg       0.55      0.50      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   7   1   0  27  11  19]\n",
      " [ 20 134   2   0  32  14   8]\n",
      " [  2  17 151   4  11  19   6]\n",
      " [ 19  52  11   6  74  17  31]\n",
      " [ 35  35   0   0 114   5  21]\n",
      " [ 32   8   6   2  19  52  91]\n",
      " [  9   2   0   0   3   9 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.69      0.61       210\n",
      "           2       0.53      0.64      0.58       210\n",
      "           3       0.88      0.72      0.79       210\n",
      "           4       0.50      0.03      0.05       210\n",
      "           5       0.41      0.54      0.47       210\n",
      "           6       0.41      0.25      0.31       210\n",
      "           7       0.52      0.89      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.49      1470\n",
      "weighted avg       0.54      0.54      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   2   9  31  35   2]\n",
      " [  9 105   5  44  18  27   2]\n",
      " [  1  10 158  22   4  15   0]\n",
      " [  9  10  10  89  43  40   9]\n",
      " [ 26   9   2  48  98  22   5]\n",
      " [ 11   6   8  14  18 124  29]\n",
      " [  1   0   0   5   4  77 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.61      0.65       210\n",
      "           2       0.74      0.50      0.60       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.39      0.42      0.40       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.36      0.59      0.45       210\n",
      "           7       0.72      0.59      0.65       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.60      0.56      0.57      1470\n",
      "weighted avg       0.60      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.580952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   4   2  17  42  25   5]\n",
      " [  2 108   4  40  38  14   4]\n",
      " [  0  11 159  23   4  12   1]\n",
      " [  1  14  11 102  45  24  13]\n",
      " [  9   6   3  46 123  15   8]\n",
      " [  6  13   6  34  13  99  39]\n",
      " [  5   1   0   9   2  45 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.55      0.66       210\n",
      "           2       0.69      0.51      0.59       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.38      0.49      0.42       210\n",
      "           5       0.46      0.59      0.52       210\n",
      "           6       0.42      0.47      0.45       210\n",
      "           7       0.68      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.59      1470\n",
      "weighted avg       0.62      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   8   1  18  38  19   7]\n",
      " [  4 123   4  28  34  13   4]\n",
      " [  1  10 161  21   6  10   1]\n",
      " [  4  28   9  94  37  25  13]\n",
      " [ 13  25   2  40 111  11   8]\n",
      " [  7  19   5  31   7 106  35]\n",
      " [  5   5   0   5   2  54 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.57      0.66       210\n",
      "           2       0.56      0.59      0.57       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.40      0.45      0.42       210\n",
      "           5       0.47      0.53      0.50       210\n",
      "           6       0.45      0.50      0.47       210\n",
      "           7       0.67      0.66      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.59      1470\n",
      "weighted avg       0.60      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134   9   1  15  30  15   6]\n",
      " [  8 123   2  28  30  15   4]\n",
      " [  0   9 165  18   6  11   1]\n",
      " [  7  25   4  95  41  28  10]\n",
      " [ 23  21   2  37 107  10  10]\n",
      " [ 14  11   6  31   8 100  40]\n",
      " [  4   6   0   7   5  51 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       210\n",
      "           2       0.60      0.59      0.59       210\n",
      "           3       0.92      0.79      0.85       210\n",
      "           4       0.41      0.45      0.43       210\n",
      "           5       0.47      0.51      0.49       210\n",
      "           6       0.43      0.48      0.45       210\n",
      "           7       0.66      0.65      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[131   6   3  14  33  15   8]\n",
      " [ 10 117  14  22  30  11   6]\n",
      " [  2   7 172  16   6   7   0]\n",
      " [ 16  22  12  76  39  30  15]\n",
      " [ 32  21   2  24 105  16  10]\n",
      " [ 12  15   8  33   9  94  39]\n",
      " [  9   2   0   7   3  50 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       210\n",
      "           2       0.62      0.56      0.58       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.40      0.36      0.38       210\n",
      "           5       0.47      0.50      0.48       210\n",
      "           6       0.42      0.45      0.43       210\n",
      "           7       0.64      0.66      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   2  10  39  18  10]\n",
      " [  9 127   5  24  32  11   2]\n",
      " [  4   8 163  20   7   8   0]\n",
      " [ 14  18   8  88  42  28  12]\n",
      " [ 24  21   1  21 118  15  10]\n",
      " [ 14  19  10  27  12  94  34]\n",
      " [ 10   2   1   7   4  52 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.61      0.62       210\n",
      "           2       0.64      0.60      0.62       210\n",
      "           3       0.86      0.78      0.81       210\n",
      "           4       0.45      0.42      0.43       210\n",
      "           5       0.46      0.56      0.51       210\n",
      "           6       0.42      0.45      0.43       210\n",
      "           7       0.66      0.64      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   4   2  19  34  14   7]\n",
      " [  6 133   5  24  27  12   3]\n",
      " [  4   9 162  20  10   3   2]\n",
      " [  8  19   9  90  47  25  12]\n",
      " [ 24  19   1  29 111  16  10]\n",
      " [ 18  17   9  31  11  92  32]\n",
      " [  5   6   1   8   6  58 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.62      0.64       210\n",
      "           2       0.64      0.63      0.64       210\n",
      "           3       0.86      0.77      0.81       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.42      0.44      0.43       210\n",
      "           7       0.66      0.60      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.58      1470\n",
      "weighted avg       0.59      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   4   2  14  34  13   8]\n",
      " [  9 134   4  18  27  13   5]\n",
      " [  0   9 164  20   8   8   1]\n",
      " [ 16  16  12  88  42  22  14]\n",
      " [ 39  20   1  24  99  15  12]\n",
      " [ 16  15   8  26  17  91  37]\n",
      " [  8   3   0  11   7  53 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.64      0.62       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.86      0.78      0.82       210\n",
      "           4       0.44      0.42      0.43       210\n",
      "           5       0.42      0.47      0.45       210\n",
      "           6       0.42      0.43      0.43       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   3  16  36   9   9]\n",
      " [  8 137   6  18  25  11   5]\n",
      " [  5  10 162  19   8   5   1]\n",
      " [ 16  25  13  85  39  22  10]\n",
      " [ 38  23   3  28  95  12  11]\n",
      " [ 25  14   7  31  19  82  32]\n",
      " [  8   5   1   7  10  50 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.42      0.40      0.41       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.65      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[137   6   3  14  34   7   9]\n",
      " [ 14 130   4  17  29  11   5]\n",
      " [  2  11 171  14   4   7   1]\n",
      " [ 15  17  10  86  43  24  15]\n",
      " [ 39  21   4  26  93  14  13]\n",
      " [ 20  22   5  32  15  85  31]\n",
      " [ 12   2   1   9   6  52 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.65      0.61       210\n",
      "           2       0.62      0.62      0.62       210\n",
      "           3       0.86      0.81      0.84       210\n",
      "           4       0.43      0.41      0.42       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.57      1470\n",
      "weighted avg       0.57      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   6   2  15  35  14   8]\n",
      " [ 10 135   6  20  26   9   4]\n",
      " [  4  11 168  17   3   6   1]\n",
      " [ 11  26  10  80  43  27  13]\n",
      " [ 32  23   4  30  93  17  11]\n",
      " [ 23  19   8  35  11  86  28]\n",
      " [ 10   6   2  12   5  45 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.62      0.60       210\n",
      "           2       0.60      0.64      0.62       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.43      0.44      0.44       210\n",
      "           6       0.42      0.41      0.42       210\n",
      "           7       0.67      0.62      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134   4   4  17  31   9  11]\n",
      " [ 15 129   5  18  30  10   3]\n",
      " [  0  11 171  16   8   4   0]\n",
      " [ 17  18  13  88  44  21   9]\n",
      " [ 37  24   4  28  88  17  12]\n",
      " [ 20  18   9  35  15  82  31]\n",
      " [  9   4   1  11   9  47 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.64      0.61       210\n",
      "           2       0.62      0.61      0.62       210\n",
      "           3       0.83      0.81      0.82       210\n",
      "           4       0.41      0.42      0.42       210\n",
      "           5       0.39      0.42      0.40       210\n",
      "           6       0.43      0.39      0.41       210\n",
      "           7       0.66      0.61      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   4   2  14  40   7   8]\n",
      " [ 13 126   4  19  27  16   5]\n",
      " [  2  11 162  22   6   6   1]\n",
      " [  9  24  12  84  42  25  14]\n",
      " [ 32  26   5  30  91  16  10]\n",
      " [ 22  21   9  32  22  78  26]\n",
      " [  3  10   1  10   6  53 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.64      0.63       210\n",
      "           2       0.57      0.60      0.58       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.40      0.40      0.40       210\n",
      "           5       0.39      0.43      0.41       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.66      0.60      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   4  12  35  13   9]\n",
      " [ 18 127   4  15  31   9   6]\n",
      " [  3  13 166  19   4   5   0]\n",
      " [ 17  24  14  87  37  21  10]\n",
      " [ 31  26   4  29  93  15  12]\n",
      " [ 19  19   8  33  18  84  29]\n",
      " [  5   5   1  10   8  53 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.41      0.44      0.43       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.66      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   4  12  35  13   9]\n",
      " [ 18 127   4  15  31   9   6]\n",
      " [  3  13 166  19   4   5   0]\n",
      " [ 17  24  14  87  37  21  10]\n",
      " [ 31  26   4  29  93  15  12]\n",
      " [ 19  19   8  33  18  84  29]\n",
      " [  5   5   1  10   8  53 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.41      0.44      0.43       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.66      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   4  12  35  13   9]\n",
      " [ 18 127   4  15  31   9   6]\n",
      " [  3  13 166  19   4   5   0]\n",
      " [ 17  24  14  87  37  21  10]\n",
      " [ 31  26   4  29  93  15  12]\n",
      " [ 19  19   8  33  18  84  29]\n",
      " [  5   5   1  10   8  53 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.41      0.44      0.43       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.66      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   4  12  35  13   9]\n",
      " [ 18 127   4  15  31   9   6]\n",
      " [  3  13 166  19   4   5   0]\n",
      " [ 17  24  14  87  37  21  10]\n",
      " [ 31  26   4  29  93  15  12]\n",
      " [ 19  19   8  33  18  84  29]\n",
      " [  5   5   1  10   8  53 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.41      0.44      0.43       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.66      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 81   2  24   0  53   0  50]\n",
      " [  0  60  77   0  52   0  21]\n",
      " [  1   1 188   0   8   0  12]\n",
      " [ 11  11  40   2  90   0  56]\n",
      " [  5  16  11   0 132   0  46]\n",
      " [  7   3  22   0  23   1 154]\n",
      " [  0   1   0   0   1   0 208]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.39      0.51       210\n",
      "           2       0.64      0.29      0.39       210\n",
      "           3       0.52      0.90      0.66       210\n",
      "           4       1.00      0.01      0.02       210\n",
      "           5       0.37      0.63      0.46       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.38      0.99      0.55       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.67      0.46      0.37      1470\n",
      "weighted avg       0.67      0.46      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5292517006802722\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   4   1   0  52   4  31]\n",
      " [  3 115  21   0  52   2  17]\n",
      " [  2   6 179   0   8   8   7]\n",
      " [ 17  18  29   3  95   2  46]\n",
      " [ 11  22   2   0 144   0  31]\n",
      " [ 10   8  15   2  20  12 143]\n",
      " [  0   1   0   0   2   0 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.56      0.64       210\n",
      "           2       0.66      0.55      0.60       210\n",
      "           3       0.72      0.85      0.78       210\n",
      "           4       0.60      0.01      0.03       210\n",
      "           5       0.39      0.69      0.49       210\n",
      "           6       0.43      0.06      0.10       210\n",
      "           7       0.43      0.99      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.57      0.53      0.46      1470\n",
      "weighted avg       0.57      0.53      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   1   0  43  11  19]\n",
      " [  3 145   6   0  36   9  11]\n",
      " [  2  12 171   1   8  15   1]\n",
      " [ 12  30  17  17  91  12  31]\n",
      " [ 22  30   2   0 133   2  21]\n",
      " [ 13  21   5   1  15  44 111]\n",
      " [  0   2   0   0   3   3 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       210\n",
      "           2       0.60      0.69      0.64       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.89      0.08      0.15       210\n",
      "           5       0.40      0.63      0.49       210\n",
      "           6       0.46      0.21      0.29       210\n",
      "           7       0.51      0.96      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.63      0.57      0.53      1470\n",
      "weighted avg       0.63      0.57      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.608843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   2   0   3  48  16  13]\n",
      " [  2 149   3   0  37  13   6]\n",
      " [  0  10 175   6   7  11   1]\n",
      " [  7  28  12  36  84  19  24]\n",
      " [ 15  24   1   2 146   5  17]\n",
      " [ 10  11   4  13  15  65  92]\n",
      " [  0   1   0   1   3   9 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.61      0.69       210\n",
      "           2       0.66      0.71      0.69       210\n",
      "           3       0.90      0.83      0.86       210\n",
      "           4       0.59      0.17      0.27       210\n",
      "           5       0.43      0.70      0.53       210\n",
      "           6       0.47      0.31      0.37       210\n",
      "           7       0.56      0.93      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.59      1470\n",
      "weighted avg       0.63      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   0   2  52  19   9]\n",
      " [  1 146   4   6  34  14   5]\n",
      " [  0   7 174  11   5  13   0]\n",
      " [  6  23   5  67  68  23  18]\n",
      " [ 14  23   1   4 145   7  16]\n",
      " [  7  12   3  19  12  87  70]\n",
      " [  0   1   0   1   3  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.69      0.70      0.69       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.61      0.32      0.42       210\n",
      "           5       0.45      0.69      0.55       210\n",
      "           6       0.48      0.41      0.44       210\n",
      "           7       0.61      0.88      0.72       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   1   0   4  47  20   7]\n",
      " [  2 147   1   8  32  17   3]\n",
      " [  0   7 174  12   4  13   0]\n",
      " [  5  20   4  78  62  23  18]\n",
      " [ 19  18   1   8 141   5  18]\n",
      " [  8  14   2  15  10  97  64]\n",
      " [  0   0   0   1   3  21 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.62      0.70       210\n",
      "           2       0.71      0.70      0.71       210\n",
      "           3       0.96      0.83      0.89       210\n",
      "           4       0.62      0.37      0.46       210\n",
      "           5       0.47      0.67      0.55       210\n",
      "           6       0.49      0.46      0.48       210\n",
      "           7       0.63      0.88      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   1   0   6  40  22   7]\n",
      " [  1 147   2  10  31  16   3]\n",
      " [  0   6 180   9   5  10   0]\n",
      " [  5  12   5  93  53  28  14]\n",
      " [ 15  17   1  12 144   7  14]\n",
      " [  7   9   1  24   5 105  59]\n",
      " [  0   1   0   0   4  22 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.72       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.60      0.44      0.51       210\n",
      "           5       0.51      0.69      0.59       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.65      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   1   0   5  41  20   5]\n",
      " [  2 147   2  13  27  15   4]\n",
      " [  0   7 181   9   5   8   0]\n",
      " [  3  11   5 112  38  26  15]\n",
      " [ 19  16   1  12 142   6  14]\n",
      " [ 12   8   1  21   5 102  61]\n",
      " [  0   1   0   1   2  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.65      0.53      0.58       210\n",
      "           5       0.55      0.68      0.60       210\n",
      "           6       0.51      0.49      0.50       210\n",
      "           7       0.65      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.68      1470\n",
      "weighted avg       0.70      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   0   3  41  19   6]\n",
      " [  1 151   2  14  24  16   2]\n",
      " [  0   8 182   7   5   8   0]\n",
      " [  5   8   2 108  44  34   9]\n",
      " [ 17  15   1  15 141   8  13]\n",
      " [ 11  11   1  18   5 112  52]\n",
      " [  0   0   0   0   3  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.73       210\n",
      "           2       0.77      0.72      0.75       210\n",
      "           3       0.97      0.87      0.91       210\n",
      "           4       0.65      0.51      0.58       210\n",
      "           5       0.54      0.67      0.60       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.69      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   0   7  36  22   5]\n",
      " [  3 151   3  12  27  11   3]\n",
      " [  0   7 184   7   4   8   0]\n",
      " [  4  11   4 113  39  26  13]\n",
      " [ 17  17   1  13 142   7  13]\n",
      " [ 12  11   2  15   7 108  55]\n",
      " [  0   0   0   1   3  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.76      0.72      0.74       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.67      0.54      0.60       210\n",
      "           5       0.55      0.68      0.61       210\n",
      "           6       0.52      0.51      0.52       210\n",
      "           7       0.67      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   0   3  44  22   3]\n",
      " [  3 147   3  17  25  13   2]\n",
      " [  0   6 187   7   4   6   0]\n",
      " [  4   9   5 111  42  25  14]\n",
      " [ 13  13   0  17 148   7  12]\n",
      " [ 10  11   1  19   4 114  51]\n",
      " [  0   1   0   0   4  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.65      0.72       210\n",
      "           2       0.78      0.70      0.74       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.64      0.53      0.58       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.69      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   1   6  35  20   5]\n",
      " [  3 152   4  15  23  11   2]\n",
      " [  0   5 186   8   4   7   0]\n",
      " [  8  10   5 118  32  25  12]\n",
      " [ 16  14   0  19 141  10  10]\n",
      " [ 11  10   2  20   4 112  51]\n",
      " [  0   0   0   1   2  15 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.67      0.72       210\n",
      "           2       0.79      0.72      0.75       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.59      0.67      0.63       210\n",
      "           6       0.56      0.53      0.55       210\n",
      "           7       0.71      0.91      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   2   1   7  38  18   7]\n",
      " [  4 148   3  20  21  12   2]\n",
      " [  0   7 183   7   5   8   0]\n",
      " [  1   9   3 120  40  22  15]\n",
      " [ 21  13   0  17 139   7  13]\n",
      " [ 10   9   3  22   4 108  54]\n",
      " [  1   0   0   0   3  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.65      0.71       210\n",
      "           2       0.79      0.70      0.74       210\n",
      "           3       0.95      0.87      0.91       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.56      0.66      0.60       210\n",
      "           6       0.55      0.51      0.53       210\n",
      "           7       0.67      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   1   0   7  40  18   4]\n",
      " [  3 150   4  18  22  11   2]\n",
      " [  0   6 186   7   3   7   1]\n",
      " [  3   7   4 121  37  25  13]\n",
      " [ 17  13   0  24 137  10   9]\n",
      " [  9  12   1  17   6 112  53]\n",
      " [  0   0   0   0   4  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.55      0.65      0.60       210\n",
      "           6       0.54      0.53      0.54       210\n",
      "           7       0.69      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   1   0   5  39  18   4]\n",
      " [  3 155   3  10  25  12   2]\n",
      " [  0   5 185   6   5   9   0]\n",
      " [  1  12   2 119  37  28  11]\n",
      " [ 20  16   0  17 139   9   9]\n",
      " [ 11   9   2  21   2 116  49]\n",
      " [  0   1   0   0   2  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.68      0.74       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.67      0.57      0.61       210\n",
      "           5       0.56      0.66      0.61       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   0  10  35  17   6]\n",
      " [  2 149   3  18  24  12   2]\n",
      " [  0   5 186   8   4   7   0]\n",
      " [  4   9   3 119  39  23  13]\n",
      " [ 18  17   0  19 136  10  10]\n",
      " [  7   9   1  20   6 123  44]\n",
      " [  0   0   0   1   3  25 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.78      0.71      0.74       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.61      0.57      0.59       210\n",
      "           5       0.55      0.65      0.60       210\n",
      "           6       0.57      0.59      0.58       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.71      1470\n",
      "weighted avg       0.71      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6945578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   1   5  40  21   5]\n",
      " [  3 151   3  15  23  13   2]\n",
      " [  0   7 185   8   3   7   0]\n",
      " [  3  10   3 122  36  25  11]\n",
      " [ 21  16   1  19 132  10  11]\n",
      " [ 10   9   1  21   5 114  50]\n",
      " [  0   0   0   0   3  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.65      0.71       210\n",
      "           2       0.77      0.72      0.75       210\n",
      "           3       0.95      0.88      0.92       210\n",
      "           4       0.64      0.58      0.61       210\n",
      "           5       0.55      0.63      0.58       210\n",
      "           6       0.53      0.54      0.54       210\n",
      "           7       0.70      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.70      1470\n",
      "weighted avg       0.70      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   3   1   6  33  16   7]\n",
      " [  3 156   4  12  22  10   3]\n",
      " [  0   7 186   7   3   7   0]\n",
      " [  4   8   3 124  37  26   8]\n",
      " [ 19  18   1  18 133  10  11]\n",
      " [ 10  11   1  24   3 109  52]\n",
      " [  0   1   0   0   4  28 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.76      0.74      0.75       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.65      0.59      0.62       210\n",
      "           5       0.57      0.63      0.60       210\n",
      "           6       0.53      0.52      0.52       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   0   0  10  34  23   5]\n",
      " [  3 152   4  17  20  11   3]\n",
      " [  0   6 185  10   2   7   0]\n",
      " [  3  12   4 118  37  27   9]\n",
      " [ 22  15   0  24 129   7  13]\n",
      " [ 11  10   3  17   6 111  52]\n",
      " [  0   0   0   0   3  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.71       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.94      0.88      0.91       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.56      0.61      0.59       210\n",
      "           6       0.52      0.53      0.52       210\n",
      "           7       0.69      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   1   0   9  38  18   7]\n",
      " [  1 156   6  15  18  11   3]\n",
      " [  0   5 185   9   4   7   0]\n",
      " [  3  16   4 116  36  26   9]\n",
      " [ 22  16   1  22 132   6  11]\n",
      " [  9  10   3  22   6 109  51]\n",
      " [  0   0   0   0   3  28 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.65      0.72       210\n",
      "           2       0.76      0.74      0.75       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.60      0.55      0.58       210\n",
      "           5       0.56      0.63      0.59       210\n",
      "           6       0.53      0.52      0.53       210\n",
      "           7       0.69      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   2   0  10  33  18   7]\n",
      " [  3 153   6  16  18  12   2]\n",
      " [  0   6 186   7   4   7   0]\n",
      " [  4  15   3 119  33  28   8]\n",
      " [ 21  16   1  18 134  10  10]\n",
      " [ 11   9   2  20   6 113  49]\n",
      " [  0   0   0   0   3  29 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.76      0.73      0.74       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.63      0.57      0.59       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.52      0.54      0.53       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 98   2  37   3  35  26   9]\n",
      " [  0  97  40  11  34  25   3]\n",
      " [  1   2 179   8   3  17   0]\n",
      " [  7  12  32  48  66  33  12]\n",
      " [ 21  15   7   9 131  12  15]\n",
      " [  8   7  17  12   9  93  64]\n",
      " [  0   0   0   1   3  55 151]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57       210\n",
      "           2       0.72      0.46      0.56       210\n",
      "           3       0.57      0.85      0.69       210\n",
      "           4       0.52      0.23      0.32       210\n",
      "           5       0.47      0.62      0.53       210\n",
      "           6       0.36      0.44      0.39       210\n",
      "           7       0.59      0.72      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.53      1470\n",
      "weighted avg       0.57      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ab723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[141   7   4   9  33   8   8]\n",
      " [  3 108  19  30  26  19   5]\n",
      " [  0  13 181   8   2   1   5]\n",
      " [  6  19  11 102  41  11  20]\n",
      " [ 24  12   2  23 136   8   5]\n",
      " [  6  22  18  28  11  72  53]\n",
      " [  3   2   2   4   7  27 165]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.72       210\n",
      "           2       0.59      0.51      0.55       210\n",
      "           3       0.76      0.86      0.81       210\n",
      "           4       0.50      0.49      0.49       210\n",
      "           5       0.53      0.65      0.58       210\n",
      "           6       0.49      0.34      0.40       210\n",
      "           7       0.63      0.79      0.70       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.61      0.62      0.61      1470\n",
      "weighted avg       0.61      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.44625850340136053\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[130  23   1  15  24   9   8]\n",
      " [ 36 109  10  16  18  11  10]\n",
      " [ 12  16 162  15   3   0   2]\n",
      " [ 52  45  13  52  28   8  12]\n",
      " [ 53  50   5  32  56   6   8]\n",
      " [ 39  37  13  18  21  45  37]\n",
      " [ 20  15   3  13  15  42 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.62      0.47       210\n",
      "           2       0.37      0.52      0.43       210\n",
      "           3       0.78      0.77      0.78       210\n",
      "           4       0.32      0.25      0.28       210\n",
      "           5       0.34      0.27      0.30       210\n",
      "           6       0.37      0.21      0.27       210\n",
      "           7       0.57      0.49      0.52       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128  17   1  24  22  11   7]\n",
      " [ 27 105  10  27  18  13  10]\n",
      " [ 12  10 169   9   3   1   6]\n",
      " [ 48  35  11  58  35  10  13]\n",
      " [ 54  37   6  34  60  11   8]\n",
      " [ 32  33  13  17  17  52  46]\n",
      " [ 15  11   2  10  10  58 104]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.61      0.49       210\n",
      "           2       0.42      0.50      0.46       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.32      0.28      0.30       210\n",
      "           5       0.36      0.29      0.32       210\n",
      "           6       0.33      0.25      0.28       210\n",
      "           7       0.54      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.45      1470\n",
      "weighted avg       0.45      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.45918367346938777\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[118  20   1  24  27  11   9]\n",
      " [ 30  98  10  26  21  13  12]\n",
      " [  6  12 174   9   2   1   6]\n",
      " [ 33  39  13  66  32  12  15]\n",
      " [ 41  44   3  45  54  12  11]\n",
      " [ 29  27  14  19  19  46  56]\n",
      " [ 10  11   2   4  12  52 119]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.56      0.49       210\n",
      "           2       0.39      0.47      0.43       210\n",
      "           3       0.80      0.83      0.81       210\n",
      "           4       0.34      0.31      0.33       210\n",
      "           5       0.32      0.26      0.29       210\n",
      "           6       0.31      0.22      0.26       210\n",
      "           7       0.52      0.57      0.54       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.45      1470\n",
      "weighted avg       0.45      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.463265306122449\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  19   1  20  28  11  10]\n",
      " [ 24 100   9  32  23  12  10]\n",
      " [  7  11 172  10   3   1   6]\n",
      " [ 32  39  13  70  30  12  14]\n",
      " [ 39  36  10  44  58  15   8]\n",
      " [ 28  26  15  21  19  47  54]\n",
      " [ 10  13   2   4  11  57 113]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.58      0.51       210\n",
      "           2       0.41      0.48      0.44       210\n",
      "           3       0.77      0.82      0.80       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.34      0.28      0.30       210\n",
      "           6       0.30      0.22      0.26       210\n",
      "           7       0.53      0.54      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.45      1470\n",
      "weighted avg       0.45      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4748299319727891\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  22   1  21  28   7  10]\n",
      " [ 29 108   9  23  20  11  10]\n",
      " [  7   9 173  11   2   2   6]\n",
      " [ 34  34  14  68  34   9  17]\n",
      " [ 40  36   7  44  65   9   9]\n",
      " [ 29  28  16  18  17  45  57]\n",
      " [ 11  14   2   4  11  50 118]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.58      0.50       210\n",
      "           2       0.43      0.51      0.47       210\n",
      "           3       0.78      0.82      0.80       210\n",
      "           4       0.36      0.32      0.34       210\n",
      "           5       0.37      0.31      0.34       210\n",
      "           6       0.34      0.21      0.26       210\n",
      "           7       0.52      0.56      0.54       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[124  23   3  19  24   8   9]\n",
      " [ 29 106  10  25  16  13  11]\n",
      " [  7  13 172   9   1   7   1]\n",
      " [ 28  40  12  66  38   9  17]\n",
      " [ 43  39   9  40  63   8   8]\n",
      " [ 25  29  15  22  17  48  54]\n",
      " [ 12  16   2   4   8  50 118]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.59      0.52       210\n",
      "           2       0.40      0.50      0.45       210\n",
      "           3       0.77      0.82      0.79       210\n",
      "           4       0.36      0.31      0.33       210\n",
      "           5       0.38      0.30      0.33       210\n",
      "           6       0.34      0.23      0.27       210\n",
      "           7       0.54      0.56      0.55       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.3074829931972789\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 44   0  28  68   0   8  62]\n",
      " [ 16   0  90  49   0   1  54]\n",
      " [  4   0 142  42   0   0  22]\n",
      " [  9   0  92  70   0   1  38]\n",
      " [ 14   0 108  66   0   1  21]\n",
      " [ 12   0  25  47   0   6 120]\n",
      " [  5   0   4  10   0   1 190]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.21      0.28       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.29      0.68      0.41       210\n",
      "           4       0.20      0.33      0.25       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.33      0.03      0.05       210\n",
      "           7       0.37      0.90      0.53       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.23      0.31      0.22      1470\n",
      "weighted avg       0.23      0.31      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.30272108843537415\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 43   0  50  43   0   9  65]\n",
      " [ 16   0 113  23   0   4  54]\n",
      " [  6   0 180   2   0   6  16]\n",
      " [ 11   0 133  27   0   7  32]\n",
      " [ 19   0 136  32   0   2  21]\n",
      " [ 14   0  49  18   0  22 107]\n",
      " [  6   0   6   6   0  19 173]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.20      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.27      0.86      0.41       210\n",
      "           4       0.18      0.13      0.15       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.32      0.10      0.16       210\n",
      "           7       0.37      0.82      0.51       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.22      0.30      0.21      1470\n",
      "weighted avg       0.22      0.30      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   7   2   9  38  12   4]\n",
      " [  8 109  16  30  24  18   5]\n",
      " [  0  14 182   7   1   1   5]\n",
      " [  5  20  10 103  41  15  16]\n",
      " [ 25   9   2  30 134   5   5]\n",
      " [ 10  22  17  32  13  64  52]\n",
      " [  6   8   2   4   7  28 155]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.66      0.69       210\n",
      "           2       0.58      0.52      0.55       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.48      0.49      0.48       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.45      0.30      0.36       210\n",
      "           7       0.64      0.74      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.3782312925170068\n",
      "Confusion Matrix of SVM is:\n",
      " [[110   1  48  28   0  10  13]\n",
      " [ 22  24 116  16   0  16  16]\n",
      " [  5   2 187   5   0   2   9]\n",
      " [ 17   2 139  17   0  10  25]\n",
      " [ 27   3 141  22   4   1  12]\n",
      " [ 21   7  47  18   3  34  80]\n",
      " [  8   3   6   5   1   7 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.52      0.52       210\n",
      "           2       0.57      0.11      0.19       210\n",
      "           3       0.27      0.89      0.42       210\n",
      "           4       0.15      0.08      0.11       210\n",
      "           5       0.50      0.02      0.04       210\n",
      "           6       0.42      0.16      0.23       210\n",
      "           7       0.54      0.86      0.66       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.43      0.38      0.31      1470\n",
      "weighted avg       0.43      0.38      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.40272108843537413\n",
      "Confusion Matrix of SVM is:\n",
      " [[114   0  26  35  11   8  16]\n",
      " [ 22   9  97  24  11  28  19]\n",
      " [  8   2 182   9   0   3   6]\n",
      " [ 17   0  91  37  28   8  29]\n",
      " [ 30   2  75  35  53   2  13]\n",
      " [ 27   2  34  24   8  25  90]\n",
      " [ 19   0   0   7   4   8 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.54      0.51       210\n",
      "           2       0.60      0.04      0.08       210\n",
      "           3       0.36      0.87      0.51       210\n",
      "           4       0.22      0.18      0.19       210\n",
      "           5       0.46      0.25      0.33       210\n",
      "           6       0.30      0.12      0.17       210\n",
      "           7       0.50      0.82      0.62       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.34      1470\n",
      "weighted avg       0.42      0.40      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.24353741496598638\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 68   0  51  27  21  21  22]\n",
      " [ 37   1 117  20   5   5  25]\n",
      " [ 17   0 180   1   0   3   9]\n",
      " [ 26   0 142  14   1   7  20]\n",
      " [ 27   0 145  24   6   2   6]\n",
      " [ 56   0  50  11  13  17  63]\n",
      " [ 81   0   6   6   8  37  72]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.32      0.26       210\n",
      "           2       1.00      0.00      0.01       210\n",
      "           3       0.26      0.86      0.40       210\n",
      "           4       0.14      0.07      0.09       210\n",
      "           5       0.11      0.03      0.05       210\n",
      "           6       0.18      0.08      0.11       210\n",
      "           7       0.33      0.34      0.34       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.32      0.24      0.18      1470\n",
      "weighted avg       0.32      0.24      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.14285714285714285\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.14      1.00      0.25       210\n",
      "\n",
      "    accuracy                           0.14      1470\n",
      "   macro avg       0.02      0.14      0.04      1470\n",
      "weighted avg       0.02      0.14      0.04      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.24353741496598638\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0 174   0   0  36]\n",
      " [  0   0   0 165   0   0  45]\n",
      " [  0   0   0 188   0   0  22]\n",
      " [  0   0   0 174   0   0  36]\n",
      " [  0   0   0 192   0   0  18]\n",
      " [  0   0   0 100   0   0 110]\n",
      " [  0   0   0  26   0   0 184]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.17      0.83      0.28       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.41      0.88      0.56       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.08      0.24      0.12      1470\n",
      "weighted avg       0.08      0.24      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   0   0  88   0   0  22]\n",
      " [ 24   0   0 142   0   0  44]\n",
      " [  8   0   0 183   0   0  19]\n",
      " [ 12   0   0 163   0   0  35]\n",
      " [ 19   0   0 175   0   0  16]\n",
      " [ 37   0   0  67   0   0 106]\n",
      " [ 18   0   0  15   0   0 177]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.20      0.78      0.31       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.42      0.84      0.56       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.15      0.30      0.19      1470\n",
      "weighted avg       0.15      0.30      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  24   2  64   0  16  20]\n",
      " [ 13  80   1  62   0  11  43]\n",
      " [  7 153   6  30   0   1  13]\n",
      " [ 11  40   8 123   0   1  27]\n",
      " [ 15  41   1 134   0   4  15]\n",
      " [ 23  23  19  44   0  14  87]\n",
      " [ 10   4  21  11   0   8 156]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.40      0.45       210\n",
      "           2       0.22      0.38      0.28       210\n",
      "           3       0.10      0.03      0.04       210\n",
      "           4       0.26      0.59      0.36       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.25      0.07      0.11       210\n",
      "           7       0.43      0.74      0.55       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.26      0.31      0.26      1470\n",
      "weighted avg       0.26      0.31      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 90  13   0  58  22  12  15]\n",
      " [ 13  46   0  58  55  12  26]\n",
      " [  7  71   5  29  96   2   0]\n",
      " [ 11  21   5 112  35   4  22]\n",
      " [ 17  14   1 120  46   2  10]\n",
      " [ 26  20   9  35  19  21  80]\n",
      " [ 10  13  11  11   3  18 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.43      0.47       210\n",
      "           2       0.23      0.22      0.23       210\n",
      "           3       0.16      0.02      0.04       210\n",
      "           4       0.26      0.53      0.35       210\n",
      "           5       0.17      0.22      0.19       210\n",
      "           6       0.30      0.10      0.15       210\n",
      "           7       0.48      0.69      0.57       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.30      0.32      0.29      1470\n",
      "weighted avg       0.30      0.32      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34217687074829933\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  13   5  58  19  18  11]\n",
      " [  9  46  11  51  52  25  16]\n",
      " [  6  71  43  18  69   3   0]\n",
      " [  6  21  11 108  31  19  14]\n",
      " [ 13  14   3 121  42   8   9]\n",
      " [ 19  21  16  35  14  48  57]\n",
      " [  8  13  11  11   3  34 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.41      0.48       210\n",
      "           2       0.23      0.22      0.22       210\n",
      "           3       0.43      0.20      0.28       210\n",
      "           4       0.27      0.51      0.35       210\n",
      "           5       0.18      0.20      0.19       210\n",
      "           6       0.31      0.23      0.26       210\n",
      "           7       0.55      0.62      0.58       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.37      0.34      0.34      1470\n",
      "weighted avg       0.37      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  20  12  59  10  24  13]\n",
      " [  9  86   6  57   7  31  14]\n",
      " [  5 125  35  23   2  20   0]\n",
      " [  5  39   8 114   8  21  15]\n",
      " [ 10  37   3 125  14  11  10]\n",
      " [ 21  24  13  40   4  55  53]\n",
      " [ 10   7  11  11   0  40 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.34      0.42       210\n",
      "           2       0.25      0.41      0.31       210\n",
      "           3       0.40      0.17      0.23       210\n",
      "           4       0.27      0.54      0.36       210\n",
      "           5       0.31      0.07      0.11       210\n",
      "           6       0.27      0.26      0.27       210\n",
      "           7       0.56      0.62      0.59       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.37      0.34      0.33      1470\n",
      "weighted avg       0.37      0.34      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  19   1  82   8  17  12]\n",
      " [ 10  63   5  93   6  18  15]\n",
      " [  7  83  34  83   0   3   0]\n",
      " [  5  24  10 139   4  12  16]\n",
      " [ 14  25   1 147   9   4  10]\n",
      " [ 21  21  14  52   6  49  47]\n",
      " [  9  13  12  17   2  33 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.34      0.41       210\n",
      "           2       0.25      0.30      0.28       210\n",
      "           3       0.44      0.16      0.24       210\n",
      "           4       0.23      0.66      0.34       210\n",
      "           5       0.26      0.04      0.07       210\n",
      "           6       0.36      0.23      0.28       210\n",
      "           7       0.55      0.59      0.57       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.37      0.33      0.31      1470\n",
      "weighted avg       0.37      0.33      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 89   7   2  66   9  25  12]\n",
      " [ 19  47  13  77  11  26  17]\n",
      " [ 22  18  91  75   0   4   0]\n",
      " [ 10  11  20 127   7  20  15]\n",
      " [ 25   6   6 139  10  14  10]\n",
      " [ 22  16  29  41   8  49  45]\n",
      " [ 10   5  21  11   2  45 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.42      0.44       210\n",
      "           2       0.43      0.22      0.29       210\n",
      "           3       0.50      0.43      0.46       210\n",
      "           4       0.24      0.60      0.34       210\n",
      "           5       0.21      0.05      0.08       210\n",
      "           6       0.27      0.23      0.25       210\n",
      "           7       0.54      0.55      0.55       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.34      1470\n",
      "weighted avg       0.38      0.36      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  26   7  50  21  23   8]\n",
      " [  8  62  19  40  36  28  17]\n",
      " [  6  19 105  23  53   4   0]\n",
      " [  6  28  19  97  23  23  14]\n",
      " [ 19  31  14  98  29  10   9]\n",
      " [ 23  17  29  35  16  50  40]\n",
      " [ 15   5  22  10   6  42 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.36      0.41       210\n",
      "           2       0.33      0.30      0.31       210\n",
      "           3       0.49      0.50      0.49       210\n",
      "           4       0.27      0.46      0.34       210\n",
      "           5       0.16      0.14      0.15       210\n",
      "           6       0.28      0.24      0.26       210\n",
      "           7       0.56      0.52      0.54       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  36   7  47  17  22   9]\n",
      " [  8  63  25  38  38  18  20]\n",
      " [ 15  18  93  23  53   6   2]\n",
      " [ 10  27  26  94  20  19  14]\n",
      " [ 18  28  17 100  29   5  13]\n",
      " [ 19  20  27  32  16  58  38]\n",
      " [ 10   7  15  10   9  58 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.34      0.40       210\n",
      "           2       0.32      0.30      0.31       210\n",
      "           3       0.44      0.44      0.44       210\n",
      "           4       0.27      0.45      0.34       210\n",
      "           5       0.16      0.14      0.15       210\n",
      "           6       0.31      0.28      0.29       210\n",
      "           7       0.51      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.36      0.35      0.35      1470\n",
      "weighted avg       0.36      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  30   9  61  12  17   7]\n",
      " [ 10  70  21  72  11  15  11]\n",
      " [  6  37  94  71   0   1   1]\n",
      " [ 11  35  24 107   7  12  14]\n",
      " [ 21  36  10 117  11   7   8]\n",
      " [ 23  27  31  41  12  38  38]\n",
      " [ 12  19  21  14   8  45  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.35      0.40       210\n",
      "           2       0.28      0.33      0.30       210\n",
      "           3       0.45      0.45      0.45       210\n",
      "           4       0.22      0.51      0.31       210\n",
      "           5       0.18      0.05      0.08       210\n",
      "           6       0.28      0.18      0.22       210\n",
      "           7       0.54      0.43      0.48       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.34      0.33      0.32      1470\n",
      "weighted avg       0.34      0.33      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  24  10  57   8  24  12]\n",
      " [ 12  56  25  72  12  18  15]\n",
      " [  7  17  60 105   3  17   1]\n",
      " [  9  30  15 108   8  25  15]\n",
      " [ 18  26  16 115  12  17   6]\n",
      " [ 26  25   9  45  11  58  36]\n",
      " [ 13  16   2  14  14  56  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.36      0.41       210\n",
      "           2       0.29      0.27      0.28       210\n",
      "           3       0.44      0.29      0.35       210\n",
      "           4       0.21      0.51      0.30       210\n",
      "           5       0.18      0.06      0.09       210\n",
      "           6       0.27      0.28      0.27       210\n",
      "           7       0.53      0.45      0.49       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.34      0.32      0.31      1470\n",
      "weighted avg       0.34      0.32      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.30952380952380953\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  30   7  51  14  22  12]\n",
      " [ 15  64  13  75  10  17  16]\n",
      " [  6  32  44 110   8   9   1]\n",
      " [ 14  32  17 109   6  20  12]\n",
      " [ 18  29  10 118  15  14   6]\n",
      " [ 29  30  15  32  11  55  38]\n",
      " [ 15  14  12  12   9  54  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.35      0.39       210\n",
      "           2       0.28      0.30      0.29       210\n",
      "           3       0.37      0.21      0.27       210\n",
      "           4       0.21      0.52      0.30       210\n",
      "           5       0.21      0.07      0.11       210\n",
      "           6       0.29      0.26      0.27       210\n",
      "           7       0.53      0.45      0.48       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.30      1470\n",
      "weighted avg       0.33      0.31      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35374149659863946\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 90  23  11  42  13  22   9]\n",
      " [ 13  71  15  71  11  12  17]\n",
      " [  7  27  91  57  10   8  10]\n",
      " [ 15  32  18 100   9  21  15]\n",
      " [ 26  32  10 107  20   9   6]\n",
      " [ 33  24  12  31  11  61  38]\n",
      " [ 15  22   5  18   9  54  87]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.43      0.44       210\n",
      "           2       0.31      0.34      0.32       210\n",
      "           3       0.56      0.43      0.49       210\n",
      "           4       0.23      0.48      0.31       210\n",
      "           5       0.24      0.10      0.14       210\n",
      "           6       0.33      0.29      0.31       210\n",
      "           7       0.48      0.41      0.44       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.37      0.35      0.35      1470\n",
      "weighted avg       0.37      0.35      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  21   7  40  25  18   7]\n",
      " [ 17  57  16  75  17  15  13]\n",
      " [ 10  25  84  70  11   9   1]\n",
      " [ 16  16  12 110  19  20  17]\n",
      " [ 26  19  12 109  29   7   8]\n",
      " [ 26  32   9  36  11  64  32]\n",
      " [ 15  19   4  15   9  55  93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.44      0.45       210\n",
      "           2       0.30      0.27      0.29       210\n",
      "           3       0.58      0.40      0.47       210\n",
      "           4       0.24      0.52      0.33       210\n",
      "           5       0.24      0.14      0.18       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.54      0.44      0.49       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.39      0.36      0.36      1470\n",
      "weighted avg       0.39      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[87 30  5 36 24 18 10]\n",
      " [40 70 18 32 17 18 15]\n",
      " [58 25 88 21 12  6  0]\n",
      " [29 48 15 49 29 24 16]\n",
      " [38 43 10 48 54  9  8]\n",
      " [31 24 17 23 24 59 32]\n",
      " [11 21 13 11 15 61 78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.41      0.35       210\n",
      "           2       0.27      0.33      0.30       210\n",
      "           3       0.53      0.42      0.47       210\n",
      "           4       0.22      0.23      0.23       210\n",
      "           5       0.31      0.26      0.28       210\n",
      "           6       0.30      0.28      0.29       210\n",
      "           7       0.49      0.37      0.42       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.35      0.33      0.33      1470\n",
      "weighted avg       0.35      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2870748299319728\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[98 23  7 25 16 27 14]\n",
      " [37 60 13 36 19 27 18]\n",
      " [63 23 44 53 12 13  2]\n",
      " [35 22 15 47 12 64 15]\n",
      " [48 18  9 38 28 59 10]\n",
      " [36 21 21 24 15 65 28]\n",
      " [12 18 17 12 18 53 80]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.47      0.36       210\n",
      "           2       0.32      0.29      0.30       210\n",
      "           3       0.35      0.21      0.26       210\n",
      "           4       0.20      0.22      0.21       210\n",
      "           5       0.23      0.13      0.17       210\n",
      "           6       0.21      0.31      0.25       210\n",
      "           7       0.48      0.38      0.42       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.30      0.29      0.28      1470\n",
      "weighted avg       0.30      0.29      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32789115646258504\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[98 21 12 30 17 20 12]\n",
      " [18 66 13 58 20 15 20]\n",
      " [10 23 88 69 11  7  2]\n",
      " [48 20 18 57 21 33 13]\n",
      " [61 19 18 45 39 17 11]\n",
      " [34 26  9 34 15 62 30]\n",
      " [16 13  3 14 13 79 72]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.47      0.40       210\n",
      "           2       0.35      0.31      0.33       210\n",
      "           3       0.55      0.42      0.47       210\n",
      "           4       0.19      0.27      0.22       210\n",
      "           5       0.29      0.19      0.23       210\n",
      "           6       0.27      0.30      0.28       210\n",
      "           7       0.45      0.34      0.39       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.35      0.33      0.33      1470\n",
      "weighted avg       0.35      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3006802721088435\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[91 25  7 24 24 31  8]\n",
      " [21 69 11 56 19 20 14]\n",
      " [ 9 47 53 84 11  4  2]\n",
      " [52 31 21 45 29 19 13]\n",
      " [56 28 13 37 52 16  8]\n",
      " [30 36 19 24 15 56 30]\n",
      " [18 22 12  9 17 56 76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.43      0.37       210\n",
      "           2       0.27      0.33      0.29       210\n",
      "           3       0.39      0.25      0.31       210\n",
      "           4       0.16      0.21      0.18       210\n",
      "           5       0.31      0.25      0.28       210\n",
      "           6       0.28      0.27      0.27       210\n",
      "           7       0.50      0.36      0.42       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.30      1470\n",
      "weighted avg       0.32      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.30952380952380953\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  26   7  22  20  26  12]\n",
      " [ 24  68  25  41  14  18  20]\n",
      " [ 10  27 111  27  11  22   2]\n",
      " [ 52  23  29  30  20  42  14]\n",
      " [ 58  21  19  36  26  37  13]\n",
      " [ 29  25  25  25  15  56  35]\n",
      " [ 14  23  11   9  22  64  67]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.46      0.39       210\n",
      "           2       0.32      0.32      0.32       210\n",
      "           3       0.49      0.53      0.51       210\n",
      "           4       0.16      0.14      0.15       210\n",
      "           5       0.20      0.12      0.15       210\n",
      "           6       0.21      0.27      0.24       210\n",
      "           7       0.41      0.32      0.36       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.30      0.31      0.30      1470\n",
      "weighted avg       0.30      0.31      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20   0   1 136   2   0  51]\n",
      " [  3   0   9 144   1   0  53]\n",
      " [  0   0 107  81   0   0  22]\n",
      " [  0   0   3 168   0   0  39]\n",
      " [  0   0   3 185   0   0  22]\n",
      " [  8   0  12  69   0   0 121]\n",
      " [  4   0   0  18   0   0 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.10      0.16       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.79      0.51      0.62       210\n",
      "           4       0.21      0.80      0.33       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.90      0.53       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.28      0.33      0.24      1470\n",
      "weighted avg       0.28      0.33      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.38095238095238093\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 51   0   5  75  38   2  39]\n",
      " [  9   0  27  91  32   0  51]\n",
      " [  0   0 140  51   6   0  13]\n",
      " [  2   0  14 113  43   0  38]\n",
      " [  5   0   7 114  65   0  19]\n",
      " [ 12   0  12  49  20   4 113]\n",
      " [  4   0   1  11   6   1 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.24      0.35       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.68      0.67      0.67       210\n",
      "           4       0.22      0.54      0.32       210\n",
      "           5       0.31      0.31      0.31       210\n",
      "           6       0.57      0.02      0.04       210\n",
      "           7       0.41      0.89      0.56       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.40      0.38      0.32      1470\n",
      "weighted avg       0.40      0.38      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.43333333333333335\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   0   0  38  14   8  17]\n",
      " [ 42  10   7  64  37  15  35]\n",
      " [  8   6 123  57   3   2  11]\n",
      " [ 31   0   3  99  41   2  34]\n",
      " [ 45   0   2  65  80   3  15]\n",
      " [ 47   0   8  31  11  11 102]\n",
      " [ 17   0   0   5   1   6 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.63      0.50       210\n",
      "           2       0.62      0.05      0.09       210\n",
      "           3       0.86      0.59      0.70       210\n",
      "           4       0.28      0.47      0.35       210\n",
      "           5       0.43      0.38      0.40       210\n",
      "           6       0.23      0.05      0.09       210\n",
      "           7       0.46      0.86      0.60       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.47      0.43      0.39      1470\n",
      "weighted avg       0.47      0.43      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45850340136054424\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   4   0  30  18   9  16]\n",
      " [ 41  45   7  35  32  23  27]\n",
      " [  8  20 142  28   4   3   5]\n",
      " [ 29  13   6  65  61   9  27]\n",
      " [ 45   5   4  43  98   1  14]\n",
      " [ 48   8  14  26  10  23  81]\n",
      " [ 15   0   5   3   4  15 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.63      0.50       210\n",
      "           2       0.47      0.21      0.30       210\n",
      "           3       0.80      0.68      0.73       210\n",
      "           4       0.28      0.31      0.30       210\n",
      "           5       0.43      0.47      0.45       210\n",
      "           6       0.28      0.11      0.16       210\n",
      "           7       0.50      0.80      0.61       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.45      0.46      0.43      1470\n",
      "weighted avg       0.45      0.46      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   8   2  27  18   8  14]\n",
      " [ 35  65   3  27  34  20  26]\n",
      " [  8  39 136  16   4   5   2]\n",
      " [ 28  15   5  65  63  10  24]\n",
      " [ 40   8   5  43  99   3  12]\n",
      " [ 42  10  15  23  13  33  74]\n",
      " [ 14   0   8   5   3  19 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.63      0.52       210\n",
      "           2       0.45      0.31      0.37       210\n",
      "           3       0.78      0.65      0.71       210\n",
      "           4       0.32      0.31      0.31       210\n",
      "           5       0.42      0.47      0.45       210\n",
      "           6       0.34      0.16      0.21       210\n",
      "           7       0.51      0.77      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.45      1470\n",
      "weighted avg       0.47      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   2  30  18  11  11]\n",
      " [ 35  74   3  31  29  18  20]\n",
      " [  8  45 131  17   2   3   4]\n",
      " [ 26  18   7  74  51  13  21]\n",
      " [ 43  10   2  51  89   4  11]\n",
      " [ 39  12  19  25  12  37  66]\n",
      " [ 15   0  16   3   4  22 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.63      0.52       210\n",
      "           2       0.45      0.35      0.39       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.32      0.35      0.34       210\n",
      "           5       0.43      0.42      0.43       210\n",
      "           6       0.34      0.18      0.23       210\n",
      "           7       0.53      0.71      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.46      0.47      0.46      1470\n",
      "weighted avg       0.46      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   6   2  23  18  11  11]\n",
      " [ 33  88   1  30  23  15  20]\n",
      " [  8  35 144  12   4   3   4]\n",
      " [ 29  21   8  74  44  13  21]\n",
      " [ 49  16   1  39  90   4  11]\n",
      " [ 35  14  18  26  11  41  65]\n",
      " [ 13   0  16   3   4  26 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.66      0.54       210\n",
      "           2       0.49      0.42      0.45       210\n",
      "           3       0.76      0.69      0.72       210\n",
      "           4       0.36      0.35      0.35       210\n",
      "           5       0.46      0.43      0.45       210\n",
      "           6       0.36      0.20      0.25       210\n",
      "           7       0.53      0.70      0.60       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.48      1470\n",
      "weighted avg       0.49      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49795918367346936\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   5   2  24  18  11  11]\n",
      " [ 33  84   3  44  12  15  19]\n",
      " [  6  19 148  30   0   5   2]\n",
      " [ 28  15  10  92  34   9  22]\n",
      " [ 46   9   3  66  71   3  12]\n",
      " [ 34   7  17  35  12  47  58]\n",
      " [ 11   0  15   5   4  24 151]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.66      0.55       210\n",
      "           2       0.60      0.40      0.48       210\n",
      "           3       0.75      0.70      0.73       210\n",
      "           4       0.31      0.44      0.36       210\n",
      "           5       0.47      0.34      0.39       210\n",
      "           6       0.41      0.22      0.29       210\n",
      "           7       0.55      0.72      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.49      1470\n",
      "weighted avg       0.51      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   6   3  23  19  13  10]\n",
      " [ 26  85   7  41  18  15  18]\n",
      " [  6  24 153  17   3   5   2]\n",
      " [ 24  19   5  83  42  14  23]\n",
      " [ 43  14   3  54  80   6  10]\n",
      " [ 32  16  18  30   8  49  57]\n",
      " [ 11   2  14   4   4  27 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.65      0.56       210\n",
      "           2       0.51      0.40      0.45       210\n",
      "           3       0.75      0.73      0.74       210\n",
      "           4       0.33      0.40      0.36       210\n",
      "           5       0.46      0.38      0.42       210\n",
      "           6       0.38      0.23      0.29       210\n",
      "           7       0.55      0.70      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   5   2  19  24  11  10]\n",
      " [ 21  86   2  45  21  18  17]\n",
      " [  7  20 142  34   1   4   2]\n",
      " [ 25  18   8  82  46  10  21]\n",
      " [ 40  11   3  51  88   7  10]\n",
      " [ 24  12  15  31  17  49  62]\n",
      " [ 10   4  17   4   6  20 149]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.66      0.58       210\n",
      "           2       0.55      0.41      0.47       210\n",
      "           3       0.75      0.68      0.71       210\n",
      "           4       0.31      0.39      0.34       210\n",
      "           5       0.43      0.42      0.43       210\n",
      "           6       0.41      0.23      0.30       210\n",
      "           7       0.55      0.71      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   7   2  21  23  10  12]\n",
      " [ 19  97   1  44  19  13  17]\n",
      " [  2  26 141  30   1   8   2]\n",
      " [ 22  14   5 100  34  16  19]\n",
      " [ 30  12   2  65  83   8  10]\n",
      " [ 21  19  14  30  14  59  53]\n",
      " [  8   1  10   4   6  33 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.55      0.46      0.50       210\n",
      "           3       0.81      0.67      0.73       210\n",
      "           4       0.34      0.48      0.40       210\n",
      "           5       0.46      0.40      0.43       210\n",
      "           6       0.40      0.28      0.33       210\n",
      "           7       0.57      0.70      0.63       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   6   4  19  24   8  14]\n",
      " [ 16  97   7  35  24  13  18]\n",
      " [  5  17 157  22   2   4   3]\n",
      " [ 22  28   5  78  44  15  18]\n",
      " [ 34  18   3  55  80   7  13]\n",
      " [ 21  21   8  29  14  60  57]\n",
      " [  5   4   6   6   6  37 146]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.51      0.46      0.48       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.32      0.37      0.34       210\n",
      "           5       0.41      0.38      0.40       210\n",
      "           6       0.42      0.29      0.34       210\n",
      "           7       0.54      0.70      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   7   2  22  24  11  11]\n",
      " [ 17 103   3  33  22  22  10]\n",
      " [  4  19 164  17   2   2   2]\n",
      " [ 17  22  11  83  48  11  18]\n",
      " [ 31  11   4  59  83  12  10]\n",
      " [ 24  14  24  31  15  50  52]\n",
      " [  7   2  18   6   6  22 149]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.58      0.49      0.53       210\n",
      "           3       0.73      0.78      0.75       210\n",
      "           4       0.33      0.40      0.36       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.38      0.24      0.29       210\n",
      "           7       0.59      0.71      0.65       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.51      0.52      0.51      1470\n",
      "weighted avg       0.51      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   8   2  24  20   9  11]\n",
      " [ 18  93  11  42  13  17  16]\n",
      " [  3  15 154  33   1   2   2]\n",
      " [ 22  21   9 100  24  17  17]\n",
      " [ 36  18   2  71  66   6  11]\n",
      " [ 26  17  19  29  13  54  52]\n",
      " [  9   1  16   4   5  35 140]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.65      0.59       210\n",
      "           2       0.54      0.44      0.49       210\n",
      "           3       0.72      0.73      0.73       210\n",
      "           4       0.33      0.48      0.39       210\n",
      "           5       0.46      0.31      0.38       210\n",
      "           6       0.39      0.26      0.31       210\n",
      "           7       0.56      0.67      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   2  14  29  15  12]\n",
      " [ 15 100   4  34  27  15  15]\n",
      " [  4  22 155  16   5   5   3]\n",
      " [ 19  22   5  69  58  22  15]\n",
      " [ 31  22   1  37 100   9  10]\n",
      " [ 26  23   7  24  15  64  51]\n",
      " [  8   5   2   4   6  47 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.51      0.48      0.49       210\n",
      "           3       0.88      0.74      0.80       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.42      0.48      0.44       210\n",
      "           6       0.36      0.30      0.33       210\n",
      "           7       0.57      0.66      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   6   2  18  20  11  12]\n",
      " [ 18 101   9  37  15  16  14]\n",
      " [  5  19 163  16   2   3   2]\n",
      " [ 14  33   5  85  37  17  19]\n",
      " [ 38  16   3  48  82  13  10]\n",
      " [ 19  19   9  29  13  64  57]\n",
      " [  9   3   6   1   8  42 141]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.67      0.62       210\n",
      "           2       0.51      0.48      0.50       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.46      0.39      0.42       210\n",
      "           6       0.39      0.30      0.34       210\n",
      "           7       0.55      0.67      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5081632653061224\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   7   2  19  26  12  11]\n",
      " [ 17 108   2  35  17  16  15]\n",
      " [  5  31 152  17   3   1   1]\n",
      " [ 15  27  11  93  32  15  17]\n",
      " [ 33  19   2  65  72  10   9]\n",
      " [ 22  25  22  24  14  52  51]\n",
      " [ 10   1  17   4  10  31 137]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.50      0.51      0.50       210\n",
      "           3       0.73      0.72      0.73       210\n",
      "           4       0.36      0.44      0.40       210\n",
      "           5       0.41      0.34      0.38       210\n",
      "           6       0.38      0.25      0.30       210\n",
      "           7       0.57      0.65      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.50      0.51      0.50      1470\n",
      "weighted avg       0.50      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.48639455782312924\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129  10   3  22  20  12  14]\n",
      " [ 16 107   3  34  18  15  17]\n",
      " [  4  49 135  17   1   2   2]\n",
      " [ 21  31   7  79  40  14  18]\n",
      " [ 34  18   3  61  73  11  10]\n",
      " [ 20  20  16  28  17  54  55]\n",
      " [ 10   2  10   5   6  39 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.61      0.58       210\n",
      "           2       0.45      0.51      0.48       210\n",
      "           3       0.76      0.64      0.70       210\n",
      "           4       0.32      0.38      0.35       210\n",
      "           5       0.42      0.35      0.38       210\n",
      "           6       0.37      0.26      0.30       210\n",
      "           7       0.54      0.66      0.59       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.48      1470\n",
      "weighted avg       0.49      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   5   3  17  22  12  13]\n",
      " [ 15  92   7  41  22  16  17]\n",
      " [  1  25 144  30   3   6   1]\n",
      " [ 17  22   6  86  42  19  18]\n",
      " [ 35  12   3  56  84  11   9]\n",
      " [ 18  14  10  31  18  67  52]\n",
      " [  6   3   6   5   8  40 142]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.66      0.63       210\n",
      "           2       0.53      0.44      0.48       210\n",
      "           3       0.80      0.69      0.74       210\n",
      "           4       0.32      0.41      0.36       210\n",
      "           5       0.42      0.40      0.41       210\n",
      "           6       0.39      0.32      0.35       210\n",
      "           7       0.56      0.68      0.61       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   7   2  20  26  11  11]\n",
      " [ 18 105   5  29  22  16  15]\n",
      " [  4  29 150  20   4   2   1]\n",
      " [ 18  19   7  70  59  19  18]\n",
      " [ 31  16   3  48  92  12   8]\n",
      " [ 23  17  14  28  15  64  49]\n",
      " [  6   3   9   6   8  50 128]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.54      0.50      0.52       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.32      0.33      0.32       210\n",
      "           5       0.41      0.44      0.42       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.56      0.61      0.58       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   7   2  22  19  15   9]\n",
      " [ 12 113   6  25  25  18  11]\n",
      " [  1  41 148  15   1   4   0]\n",
      " [ 14  31   6  77  47  18  17]\n",
      " [ 38  20   4  49  79  11   9]\n",
      " [ 18  30  12  17  20  65  48]\n",
      " [  5   4   8   4   7  44 138]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.65      0.63       210\n",
      "           2       0.46      0.54      0.50       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.37      0.37      0.37       210\n",
      "           5       0.40      0.38      0.39       210\n",
      "           6       0.37      0.31      0.34       210\n",
      "           7       0.59      0.66      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3040816326530612\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 44   0  56  39   1  14  56]\n",
      " [ 16   0 113  25   0   4  52]\n",
      " [  5   0 179   4   0  15   7]\n",
      " [ 10   0 132  29   0  10  29]\n",
      " [ 16   0 137  33   2   4  18]\n",
      " [ 13   0  47  21   3  29  97]\n",
      " [  6   0   5   7   1  27 164]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.21      0.28       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.27      0.85      0.41       210\n",
      "           4       0.18      0.14      0.16       210\n",
      "           5       0.29      0.01      0.02       210\n",
      "           6       0.28      0.14      0.19       210\n",
      "           7       0.39      0.78      0.52       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.26      0.30      0.22      1470\n",
      "weighted avg       0.26      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_gkb.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[157   3   1   1  36  11   1]\n",
      " [  3 161   4  16  15  11   0]\n",
      " [  1   6 188  10   2   3   0]\n",
      " [  3  13   6 144  25  17   2]\n",
      " [ 38  17   1  19 127   4   4]\n",
      " [ 13  20   6  24   7 113  27]\n",
      " [  3   3   0   2   6  33 163]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.72      0.77      0.74       210\n",
      "           3       0.91      0.90      0.90       210\n",
      "           4       0.67      0.69      0.68       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.59      0.54      0.56       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6068027210884354\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   5   5   4  42   4   4]\n",
      " [ 20 136  10   7  25   7   5]\n",
      " [  6   6 188   2   7   1   0]\n",
      " [ 33  20  15  90  44   4   4]\n",
      " [ 62  16   8  22  95   5   2]\n",
      " [ 29  19   4  19  15  59  65]\n",
      " [  9   3   1   4   5  10 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.70      0.57       210\n",
      "           2       0.66      0.65      0.66       210\n",
      "           3       0.81      0.90      0.85       210\n",
      "           4       0.61      0.43      0.50       210\n",
      "           5       0.41      0.45      0.43       210\n",
      "           6       0.66      0.28      0.39       210\n",
      "           7       0.69      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.59      1470\n",
      "weighted avg       0.62      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6272108843537415\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   4   5   3  35   7   3]\n",
      " [ 20 137  11   6  25   7   4]\n",
      " [  6   6 188   4   5   1   0]\n",
      " [ 29  12  16  86  55   6   6]\n",
      " [ 52  13   8  25 103   8   1]\n",
      " [ 29  15   3  18   8  76  61]\n",
      " [  4   3   0   1   0  23 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.73      0.61       210\n",
      "           2       0.72      0.65      0.68       210\n",
      "           3       0.81      0.90      0.85       210\n",
      "           4       0.60      0.41      0.49       210\n",
      "           5       0.45      0.49      0.47       210\n",
      "           6       0.59      0.36      0.45       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   3   3   4  44   8   4]\n",
      " [ 17 138  10   7  22  10   6]\n",
      " [  2   9 185   6   6   1   1]\n",
      " [ 26  14  15  83  58   8   6]\n",
      " [ 50  11   9  28 102   8   2]\n",
      " [ 23  18   4  15  14  58  78]\n",
      " [  4   2   0   1   1  15 187]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.69      0.61       210\n",
      "           2       0.71      0.66      0.68       210\n",
      "           3       0.82      0.88      0.85       210\n",
      "           4       0.58      0.40      0.47       210\n",
      "           5       0.41      0.49      0.45       210\n",
      "           6       0.54      0.28      0.36       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6278911564625851\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   4   3   7  44   8   3]\n",
      " [ 13 137  11   7  27  11   4]\n",
      " [  3   8 183   6   9   1   0]\n",
      " [ 27  10  12  91  57   9   4]\n",
      " [ 43  11   6  25 116   6   3]\n",
      " [ 24  18   4  14  17  69  64]\n",
      " [  2   1   0   1   2  18 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61       210\n",
      "           2       0.72      0.65      0.69       210\n",
      "           3       0.84      0.87      0.85       210\n",
      "           4       0.60      0.43      0.50       210\n",
      "           5       0.43      0.55      0.48       210\n",
      "           6       0.57      0.33      0.42       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   4   4   4  48   8   3]\n",
      " [ 11 135  11  10  29   8   6]\n",
      " [  3   9 183   5   9   1   0]\n",
      " [ 27   9  14  91  55  10   4]\n",
      " [ 41  10   7  27 118   3   4]\n",
      " [ 23  18   4  17  16  56  76]\n",
      " [  1   1   0   1   3  13 191]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.66      0.61       210\n",
      "           2       0.73      0.64      0.68       210\n",
      "           3       0.82      0.87      0.85       210\n",
      "           4       0.59      0.43      0.50       210\n",
      "           5       0.42      0.56      0.48       210\n",
      "           6       0.57      0.27      0.36       210\n",
      "           7       0.67      0.91      0.77       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138   1   3   6  50   7   5]\n",
      " [  8 130  12  12  32   9   7]\n",
      " [  4   6 189   3   7   1   0]\n",
      " [ 23   8  13  91  61  10   4]\n",
      " [ 39  10   6  25 121   5   4]\n",
      " [ 27  13   5  17  15  54  79]\n",
      " [  2   1   0   2   3  15 187]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.66      0.61       210\n",
      "           2       0.77      0.62      0.69       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.58      0.43      0.50       210\n",
      "           5       0.42      0.58      0.48       210\n",
      "           6       0.53      0.26      0.35       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5217687074829932\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 89  10  20   8  48  28   7]\n",
      " [  1  87  18   9  54  33   8]\n",
      " [  7  16 142  11  12  22   0]\n",
      " [ 11  13  15  57  80  27   7]\n",
      " [ 11  17   6  19 136  15   6]\n",
      " [ 18  14   3  13  10  75  77]\n",
      " [  0   4   0   1   0  24 181]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.42      0.51       210\n",
      "           2       0.54      0.41      0.47       210\n",
      "           3       0.70      0.68      0.69       210\n",
      "           4       0.48      0.27      0.35       210\n",
      "           5       0.40      0.65      0.49       210\n",
      "           6       0.33      0.36      0.35       210\n",
      "           7       0.63      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.51      1470\n",
      "weighted avg       0.53      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 90  12  24  10  35  32   7]\n",
      " [  2  73  24  11  41  47  12]\n",
      " [  8  24 146   7   7  17   1]\n",
      " [  8  18  23  61  61  30   9]\n",
      " [ 13  22  23  16 107  24   5]\n",
      " [ 18  15   6  11   4  72  84]\n",
      " [  0   3   0   1   0  20 186]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.43      0.52       210\n",
      "           2       0.44      0.35      0.39       210\n",
      "           3       0.59      0.70      0.64       210\n",
      "           4       0.52      0.29      0.37       210\n",
      "           5       0.42      0.51      0.46       210\n",
      "           6       0.30      0.34      0.32       210\n",
      "           7       0.61      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   4   0   3  35  14   2]\n",
      " [  5 160   4  18  12  11   0]\n",
      " [  0   7 190   6   2   5   0]\n",
      " [  4  19   6 134  25  20   2]\n",
      " [ 55  16   1  22 110   4   2]\n",
      " [ 15  15   8  23  13 105  31]\n",
      " [  3   2   0   1   2  44 158]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.72      0.68       210\n",
      "           2       0.72      0.76      0.74       210\n",
      "           3       0.91      0.90      0.91       210\n",
      "           4       0.65      0.64      0.64       210\n",
      "           5       0.55      0.52      0.54       210\n",
      "           6       0.52      0.50      0.51       210\n",
      "           7       0.81      0.75      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6986394557823129\n",
      "Confusion Matrix of SVM is:\n",
      " [[127   4   2   4  59  12   2]\n",
      " [  4 138   5  20  30  11   2]\n",
      " [  1   7 179   8  11   4   0]\n",
      " [  5   2   3 138  48  13   1]\n",
      " [ 17   7   1  21 159   4   1]\n",
      " [ 10  11   1  31  21  99  37]\n",
      " [  0   0   0   2   3  18 187]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.60      0.68       210\n",
      "           2       0.82      0.66      0.73       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.62      0.66      0.64       210\n",
      "           5       0.48      0.76      0.59       210\n",
      "           6       0.61      0.47      0.53       210\n",
      "           7       0.81      0.89      0.85       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7292517006802721\n",
      "Confusion Matrix of SVM is:\n",
      " [[139   3   2   4  39  20   3]\n",
      " [  3 157   6  15  14  13   2]\n",
      " [  1   5 187   8   3   6   0]\n",
      " [  4   5   7 144  27  20   3]\n",
      " [ 26  18   1  28 129   4   4]\n",
      " [ 10  12   2  20   4 130  32]\n",
      " [  0   1   0   1   1  21 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.66      0.71       210\n",
      "           2       0.78      0.75      0.76       210\n",
      "           3       0.91      0.89      0.90       210\n",
      "           4       0.65      0.69      0.67       210\n",
      "           5       0.59      0.61      0.60       210\n",
      "           6       0.61      0.62      0.61       210\n",
      "           7       0.81      0.89      0.85       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of SVM is:\n",
      " [[140   6   3   6  28  23   4]\n",
      " [  3 142   9  13  18  19   6]\n",
      " [  0   9 173  11   5  12   0]\n",
      " [  3  11   7 128  31  26   4]\n",
      " [ 24  20   1  26 125  10   4]\n",
      " [ 11  15   7  26   6  92  53]\n",
      " [  1   6   0   1   2  40 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.71       210\n",
      "           2       0.68      0.68      0.68       210\n",
      "           3       0.86      0.82      0.84       210\n",
      "           4       0.61      0.61      0.61       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.41      0.44      0.43       210\n",
      "           7       0.69      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2612244897959184\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0 185   0   0   0  25]\n",
      " [  0   0 178   0   0   0  32]\n",
      " [  0   0 194   0   0   0  16]\n",
      " [  0   0 193   0   0   0  17]\n",
      " [  0   0 201   0   0   0   9]\n",
      " [  0   0  73   0   0   0 137]\n",
      " [  0   0  20   0   0   0 190]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.19      0.92      0.31       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.45      0.90      0.60       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.09      0.26      0.13      1470\n",
      "weighted avg       0.09      0.26      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38095238095238093\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  12   0 173  15  10]\n",
      " [  0   0  11   0 167  25   7]\n",
      " [  0   0 131   0  63  15   1]\n",
      " [  0   0  21   0 172  13   4]\n",
      " [  0   0   4   0 197   5   4]\n",
      " [  0   0   3   0  70  69  68]\n",
      " [  0   0   0   0  20  27 163]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.94      0.37       210\n",
      "           6       0.41      0.33      0.36       210\n",
      "           7       0.63      0.78      0.70       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.28      0.38      0.30      1470\n",
      "weighted avg       0.28      0.38      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[166   9   4   8   0  19   4]\n",
      " [100  72   3   8   0  22   5]\n",
      " [ 44  19 103  28   0  16   0]\n",
      " [159  13   4  17   0  14   3]\n",
      " [184  13   1   3   0   5   4]\n",
      " [ 64   8   1   2   0  82  53]\n",
      " [ 20   1   0   0   0  40 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.79      0.35       210\n",
      "           2       0.53      0.34      0.42       210\n",
      "           3       0.89      0.49      0.63       210\n",
      "           4       0.26      0.08      0.12       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.68      0.71      0.70       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.43      0.40      0.37      1470\n",
      "weighted avg       0.43      0.40      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   5   9   8  56  15   7]\n",
      " [ 13  70   8   8  87  20   4]\n",
      " [  2   6 126  23  42  10   1]\n",
      " [ 21  13   4  17 138  17   0]\n",
      " [ 51  12   3   3 133   5   3]\n",
      " [ 19   6   7   2  45  83  48]\n",
      " [ 15   1   0   0   5  35 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.52      0.50       210\n",
      "           2       0.62      0.33      0.43       210\n",
      "           3       0.80      0.60      0.69       210\n",
      "           4       0.28      0.08      0.13       210\n",
      "           5       0.26      0.63      0.37       210\n",
      "           6       0.45      0.40      0.42       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.47      1470\n",
      "weighted avg       0.51      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49795918367346936\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   9   6  13  48  17   6]\n",
      " [ 16  76   3  21  69  20   5]\n",
      " [  2  25 122  25  25  10   1]\n",
      " [ 21  20   3  82  67  17   0]\n",
      " [ 51  12   2  32 105   5   3]\n",
      " [ 24   5   2  13  35  85  46]\n",
      " [ 15   1   0   1   4  38 151]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.53      0.49       210\n",
      "           2       0.51      0.36      0.42       210\n",
      "           3       0.88      0.58      0.70       210\n",
      "           4       0.44      0.39      0.41       210\n",
      "           5       0.30      0.50      0.37       210\n",
      "           6       0.44      0.40      0.42       210\n",
      "           7       0.71      0.72      0.72       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.51      1470\n",
      "weighted avg       0.54      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 91   6  12  12  59  28   2]\n",
      " [ 10  71   8  24  72  23   2]\n",
      " [  1   9 145  27  17  11   0]\n",
      " [ 17   9  10  84  72  18   0]\n",
      " [ 23  12   2  29 135   6   3]\n",
      " [ 16  15   2  13  38  91  35]\n",
      " [ 14   1   0   4   4  53 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.43      0.48       210\n",
      "           2       0.58      0.34      0.43       210\n",
      "           3       0.81      0.69      0.75       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.34      0.64      0.44       210\n",
      "           6       0.40      0.43      0.41       210\n",
      "           7       0.76      0.64      0.69       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.55      0.51      0.52      1470\n",
      "weighted avg       0.55      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   5  10  27  35  18   3]\n",
      " [ 13  68   7  65  30  25   2]\n",
      " [  6   6 144  31  10  13   0]\n",
      " [ 22   8  10 123  29  15   3]\n",
      " [ 41   4   3  59  97   3   3]\n",
      " [ 23   9   1  40   9  82  46]\n",
      " [ 11   1   0   8   0  57 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.53      0.51       210\n",
      "           2       0.67      0.32      0.44       210\n",
      "           3       0.82      0.69      0.75       210\n",
      "           4       0.35      0.59      0.44       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.38      0.39      0.39       210\n",
      "           7       0.70      0.63      0.67       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.52      1470\n",
      "weighted avg       0.55      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  22   8  16  44  20   3]\n",
      " [  7 115   7  26  30  23   2]\n",
      " [  3  27 146  14  12   8   0]\n",
      " [ 18  32  12  98  32  16   2]\n",
      " [ 29  41   3  28 102   4   3]\n",
      " [ 19  23   3  34  11  81  39]\n",
      " [  8   3   0   6   0  53 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.46      0.50       210\n",
      "           2       0.44      0.55      0.49       210\n",
      "           3       0.82      0.70      0.75       210\n",
      "           4       0.44      0.47      0.45       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.40      0.39      0.39       210\n",
      "           7       0.74      0.67      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109  13   9  17  42  15   5]\n",
      " [ 16  98   9  24  37  25   1]\n",
      " [  4   6 160  11  12  15   2]\n",
      " [ 23  28  10  92  35  20   2]\n",
      " [ 40  25   3  24 108   6   4]\n",
      " [ 26  18   3  25  15  83  40]\n",
      " [  4   3   0   9   6  48 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.52      0.50       210\n",
      "           2       0.51      0.47      0.49       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.46      0.44      0.45       210\n",
      "           5       0.42      0.51      0.46       210\n",
      "           6       0.39      0.40      0.39       210\n",
      "           7       0.72      0.67      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  14   6  22  37  16   7]\n",
      " [ 15 101  11  34  25  21   3]\n",
      " [  6  11 157  13   7  14   2]\n",
      " [ 25  25   6 102  34  15   3]\n",
      " [ 30  28   5  39  96   8   4]\n",
      " [ 23  19   1  33   9  84  41]\n",
      " [  4   6   0   8   2  50 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.51      0.51       210\n",
      "           2       0.50      0.48      0.49       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.41      0.49      0.44       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.70      0.67      0.68       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100  18  12  18  36  22   4]\n",
      " [ 11 112  11  32  23  18   3]\n",
      " [  5  10 157  14   7  15   2]\n",
      " [ 17  30   8 104  31  18   2]\n",
      " [ 20  35   9  34 100   9   3]\n",
      " [ 17  31   2  24  15  84  37]\n",
      " [  8   9   0   7   2  47 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.48      0.52       210\n",
      "           2       0.46      0.53      0.49       210\n",
      "           3       0.79      0.75      0.77       210\n",
      "           4       0.45      0.50      0.47       210\n",
      "           5       0.47      0.48      0.47       210\n",
      "           6       0.39      0.40      0.40       210\n",
      "           7       0.73      0.65      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5224489795918368\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  19   9  23  34  15   5]\n",
      " [ 16 111  12  26  19  22   4]\n",
      " [  8  14 160  12   7   7   2]\n",
      " [ 20  31   8  94  35  20   2]\n",
      " [ 28  35   6  38  86  15   2]\n",
      " [ 21  25   4  31  10  79  40]\n",
      " [  6   6   1   8   4  52 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.50      0.51       210\n",
      "           2       0.46      0.53      0.49       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.41      0.45      0.43       210\n",
      "           5       0.44      0.41      0.42       210\n",
      "           6       0.38      0.38      0.38       210\n",
      "           7       0.71      0.63      0.67       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  20   8  18  39  16   3]\n",
      " [ 18 111   9  24  24  19   5]\n",
      " [  6  15 163  11   7   6   2]\n",
      " [ 20  26   8  94  39  20   3]\n",
      " [ 34  33   4  37  90   5   7]\n",
      " [ 24  30   4  18  16  75  43]\n",
      " [  7   9   1   2   8  49 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.50       210\n",
      "           2       0.45      0.53      0.49       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.46      0.45      0.45       210\n",
      "           5       0.40      0.43      0.42       210\n",
      "           6       0.39      0.36      0.38       210\n",
      "           7       0.68      0.64      0.66       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  20   8  21  40  11   5]\n",
      " [ 15 104  11  32  20  25   3]\n",
      " [  6  19 159  10   7   7   2]\n",
      " [ 19  31   7  94  35  21   3]\n",
      " [ 30  34   6  35  86  14   5]\n",
      " [ 22  29   4  21  12  81  41]\n",
      " [  6   6   0   7   8  46 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.50      0.51       210\n",
      "           2       0.43      0.50      0.46       210\n",
      "           3       0.82      0.76      0.79       210\n",
      "           4       0.43      0.45      0.44       210\n",
      "           5       0.41      0.41      0.41       210\n",
      "           6       0.40      0.39      0.39       210\n",
      "           7       0.70      0.65      0.67       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.52      1470\n",
      "weighted avg       0.53      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  19   7  21  39  12   5]\n",
      " [ 16 101  13  29  22  24   5]\n",
      " [  6  15 162  12   5   8   2]\n",
      " [ 22  30   7  87  39  22   3]\n",
      " [ 32  32   5  35  88   9   9]\n",
      " [ 24  21   6  25  16  74  44]\n",
      " [  8  10   1   1   7  47 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.50       210\n",
      "           2       0.44      0.48      0.46       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.41      0.41      0.41       210\n",
      "           5       0.41      0.42      0.41       210\n",
      "           6       0.38      0.35      0.36       210\n",
      "           7       0.67      0.65      0.66       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  17   7  21  38  16   4]\n",
      " [ 18 104  15  20  25  26   2]\n",
      " [  7  15 160  12   6   8   2]\n",
      " [ 22  30   8  87  39  20   4]\n",
      " [ 36  30   7  37  83  14   3]\n",
      " [ 23  21   5  21  14  82  44]\n",
      " [  5   5   1   9   7  46 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.51      0.50       210\n",
      "           2       0.47      0.50      0.48       210\n",
      "           3       0.79      0.76      0.77       210\n",
      "           4       0.42      0.41      0.42       210\n",
      "           5       0.39      0.40      0.39       210\n",
      "           6       0.39      0.39      0.39       210\n",
      "           7       0.70      0.65      0.67       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  18   6  26  37  10   7]\n",
      " [ 15 110  14  24  18  21   8]\n",
      " [  6  17 161  10   5   9   2]\n",
      " [ 22  34  11  82  32  25   4]\n",
      " [ 31  36   4  35  89   9   6]\n",
      " [ 26  23   5  20  18  75  43]\n",
      " [  5   7   1   4   7  49 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       210\n",
      "           2       0.45      0.52      0.48       210\n",
      "           3       0.80      0.77      0.78       210\n",
      "           4       0.41      0.39      0.40       210\n",
      "           5       0.43      0.42      0.43       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.66      0.65      0.66       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  17   6  23  36  17   6]\n",
      " [ 18 102  12  25  26  24   3]\n",
      " [  6  17 162  12   5   7   1]\n",
      " [ 21  29  10  89  32  25   4]\n",
      " [ 38  32   4  40  80  10   6]\n",
      " [ 22  25   7  30  13  78  35]\n",
      " [  8   3   1   5   6  47 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.50      0.49       210\n",
      "           2       0.45      0.49      0.47       210\n",
      "           3       0.80      0.77      0.79       210\n",
      "           4       0.40      0.42      0.41       210\n",
      "           5       0.40      0.38      0.39       210\n",
      "           6       0.38      0.37      0.37       210\n",
      "           7       0.72      0.67      0.69       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.52      1470\n",
      "weighted avg       0.52      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109  21   8  21  34  11   6]\n",
      " [ 16 100  13  30  24  21   6]\n",
      " [  6  17 160  12   5   8   2]\n",
      " [ 25  33  10  82  38  19   3]\n",
      " [ 35  31   7  34  84  13   6]\n",
      " [ 20  19   5  25  17  83  41]\n",
      " [  6   6   1   7   4  53 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.52      0.51       210\n",
      "           2       0.44      0.48      0.46       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.39      0.39      0.39       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.68      0.63      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  22   7  24  38   7   8]\n",
      " [ 21 103  11  26  24  21   4]\n",
      " [  7  16 162  11   6   7   1]\n",
      " [ 19  30  11  90  34  24   2]\n",
      " [ 34  33   4  38  81  15   5]\n",
      " [ 24  20   8  27  13  80  38]\n",
      " [  4   7   2   6  10  50 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.45      0.49      0.47       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.39      0.39      0.39       210\n",
      "           6       0.39      0.38      0.39       210\n",
      "           7       0.69      0.62      0.66       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  22   7  24  38   7   8]\n",
      " [ 21 103  11  26  24  21   4]\n",
      " [  7  16 162  11   6   7   1]\n",
      " [ 19  30  11  90  34  24   2]\n",
      " [ 34  33   4  38  81  15   5]\n",
      " [ 24  20   8  27  13  80  38]\n",
      " [  4   7   2   6  10  50 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.49       210\n",
      "           2       0.45      0.49      0.47       210\n",
      "           3       0.79      0.77      0.78       210\n",
      "           4       0.41      0.43      0.42       210\n",
      "           5       0.39      0.39      0.39       210\n",
      "           6       0.39      0.38      0.39       210\n",
      "           7       0.69      0.62      0.66       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.28503401360544217\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  3   1 174   1   2   1  28]\n",
      " [  0   5 134   0  11   0  60]\n",
      " [  0   0 193   0   0   1  16]\n",
      " [  1   0 168   0  14   0  27]\n",
      " [  0   3 181   1   9   1  15]\n",
      " [  1   1  50   3   7   3 145]\n",
      " [  1   0   3   0   0   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.01      0.03       210\n",
      "           2       0.50      0.02      0.05       210\n",
      "           3       0.21      0.92      0.35       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.21      0.04      0.07       210\n",
      "           6       0.50      0.01      0.03       210\n",
      "           7       0.41      0.98      0.58       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.33      0.29      0.16      1470\n",
      "weighted avg       0.33      0.29      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61   6  39   1  75  15  13]\n",
      " [  7  56  30   4  68  26  19]\n",
      " [  7   6 159   5  17  10   6]\n",
      " [  4   9  26  11 135  11  14]\n",
      " [  3   8  13   3 170   4   9]\n",
      " [ 12  11   8   0  34  32 113]\n",
      " [  1   2   0   0   2   4 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.29      0.40       210\n",
      "           2       0.57      0.27      0.36       210\n",
      "           3       0.58      0.76      0.66       210\n",
      "           4       0.46      0.05      0.09       210\n",
      "           5       0.34      0.81      0.48       210\n",
      "           6       0.31      0.15      0.21       210\n",
      "           7       0.54      0.96      0.69       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.41      1470\n",
      "weighted avg       0.49      0.47      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121  13   2   5  41  20   8]\n",
      " [  6 110   5  17  46  15  11]\n",
      " [  6  26 152   7   6  12   1]\n",
      " [ 12  22  11  79  62  16   8]\n",
      " [ 26  18   6  24 123   6   7]\n",
      " [ 14  22   3  10  16  53  92]\n",
      " [  0   6   0   1   0   8 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.58      0.61       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.55      0.38      0.45       210\n",
      "           5       0.42      0.59      0.49       210\n",
      "           6       0.41      0.25      0.31       210\n",
      "           7       0.61      0.93      0.73       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133  11   1   7  29  23   6]\n",
      " [  4 118   5  20  37  19   7]\n",
      " [ 11  13 157   9   7  13   0]\n",
      " [ 12  19   6  96  51  21   5]\n",
      " [ 27  22   0  27 119   9   6]\n",
      " [ 20  16   2  14   9  72  77]\n",
      " [  0   5   0   1   0  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.63      0.64       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.92      0.75      0.82       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.47      0.57      0.52       210\n",
      "           6       0.41      0.34      0.37       210\n",
      "           7       0.65      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125  10   1  13  32  24   5]\n",
      " [  5 120   3  20  38  19   5]\n",
      " [  4   9 161  13  11  12   0]\n",
      " [ 10  15   5 112  42  21   5]\n",
      " [ 20  20   0  35 121   8   6]\n",
      " [ 13  18   1  21   8  77  72]\n",
      " [  0   5   0   1   0  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.60      0.65       210\n",
      "           2       0.61      0.57      0.59       210\n",
      "           3       0.94      0.77      0.85       210\n",
      "           4       0.52      0.53      0.53       210\n",
      "           5       0.48      0.58      0.52       210\n",
      "           6       0.43      0.37      0.39       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   9   1  14  36  25   5]\n",
      " [  4 118   2  28  34  18   6]\n",
      " [  2   9 163  12  14  10   0]\n",
      " [  7  16   4 125  32  22   4]\n",
      " [ 16  16   0  37 126  11   4]\n",
      " [ 14  14   1  21   9  83  68]\n",
      " [  0   4   0   1   0  22 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.57      0.64       210\n",
      "           2       0.63      0.56      0.60       210\n",
      "           3       0.95      0.78      0.86       210\n",
      "           4       0.53      0.60      0.56       210\n",
      "           5       0.50      0.60      0.55       210\n",
      "           6       0.43      0.40      0.41       210\n",
      "           7       0.68      0.87      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.63      1470\n",
      "weighted avg       0.64      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   9   0  13  37  25   4]\n",
      " [  3 123   2  26  30  22   4]\n",
      " [  5  12 163  11   9  10   0]\n",
      " [  7  11   4 128  36  21   3]\n",
      " [ 18  17   0  39 121  10   5]\n",
      " [  9  15   2  28   6  90  60]\n",
      " [  0   4   0   1   0  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.58      0.65       210\n",
      "           2       0.64      0.59      0.61       210\n",
      "           3       0.95      0.78      0.86       210\n",
      "           4       0.52      0.61      0.56       210\n",
      "           5       0.51      0.58      0.54       210\n",
      "           6       0.46      0.43      0.44       210\n",
      "           7       0.71      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.64      1470\n",
      "weighted avg       0.65      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   9   0  13  32  24   4]\n",
      " [  2 126   3  27  28  20   4]\n",
      " [  4   7 170  12   7  10   0]\n",
      " [  9  11   3 132  32  20   3]\n",
      " [ 20  15   0  41 121   8   5]\n",
      " [ 12  15   0  26   4 106  47]\n",
      " [  0   3   0   1   1  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.61      0.66       210\n",
      "           2       0.68      0.60      0.64       210\n",
      "           3       0.97      0.81      0.88       210\n",
      "           4       0.52      0.63      0.57       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.51      0.50      0.51       210\n",
      "           7       0.74      0.88      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   6   0  14  36  22   4]\n",
      " [  4 129   4  21  28  18   6]\n",
      " [  2   6 172  12   8  10   0]\n",
      " [  7   7   4 130  36  24   2]\n",
      " [ 20  16   0  36 124   9   5]\n",
      " [ 12  16   0  26   7  95  54]\n",
      " [  0   4   0   1   0  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.61      0.67       210\n",
      "           2       0.70      0.61      0.65       210\n",
      "           3       0.96      0.82      0.88       210\n",
      "           4       0.54      0.62      0.58       210\n",
      "           5       0.52      0.59      0.55       210\n",
      "           6       0.48      0.45      0.46       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.66      1470\n",
      "weighted avg       0.67      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   6   0  13  36  23   4]\n",
      " [  2 135   4  22  25  16   6]\n",
      " [  2   9 170  12   8   9   0]\n",
      " [ 10   9   4 132  32  21   2]\n",
      " [ 22  13   0  35 128   6   6]\n",
      " [ 15  14   0  22   9  94  56]\n",
      " [  0   1   0   1   1  24 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.61      0.66       210\n",
      "           2       0.72      0.64      0.68       210\n",
      "           3       0.96      0.81      0.88       210\n",
      "           4       0.56      0.63      0.59       210\n",
      "           5       0.54      0.61      0.57       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   9   0   8  37  21   4]\n",
      " [  4 138   5  26  18  15   4]\n",
      " [  3   6 172  11   7  11   0]\n",
      " [  8   7   3 135  34  18   5]\n",
      " [ 22  14   0  43 119   8   4]\n",
      " [ 11  17   2  25   3 103  49]\n",
      " [  0   3   0   1   0  24 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.62      0.67       210\n",
      "           2       0.71      0.66      0.68       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.54      0.64      0.59       210\n",
      "           5       0.55      0.57      0.56       210\n",
      "           6       0.52      0.49      0.50       210\n",
      "           7       0.73      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   7   1   9  33  22   4]\n",
      " [  2 139   4  21  22  21   1]\n",
      " [  2   7 177   9   6   9   0]\n",
      " [ 11  10   4 123  40  20   2]\n",
      " [ 29  15   0  37 119   6   4]\n",
      " [  8  16   0  30   4 101  51]\n",
      " [  0   3   0   1   0  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.71      0.66      0.68       210\n",
      "           3       0.95      0.84      0.89       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.53      0.57      0.55       210\n",
      "           6       0.50      0.48      0.49       210\n",
      "           7       0.75      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.67      1470\n",
      "weighted avg       0.67      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   4   2  15  27  23   4]\n",
      " [  2 138   4  20  24  18   4]\n",
      " [  3   8 172  10   8   9   0]\n",
      " [  8   7   3 144  26  19   3]\n",
      " [ 26  15   1  33 123   9   3]\n",
      " [ 13  18   2  23   3 100  51]\n",
      " [  0   4   0   1   0  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.71      0.66      0.68       210\n",
      "           3       0.93      0.82      0.87       210\n",
      "           4       0.59      0.69      0.63       210\n",
      "           5       0.58      0.59      0.58       210\n",
      "           6       0.51      0.48      0.49       210\n",
      "           7       0.74      0.89      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   4   2  12  36  23   3]\n",
      " [  3 141   5  19  21  17   4]\n",
      " [  3   8 174   8   7  10   0]\n",
      " [  7  12   3 134  33  18   3]\n",
      " [ 28  13   1  34 121   7   6]\n",
      " [ 10  17   1  24   6 104  48]\n",
      " [  0   3   0   1   0  22 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.62      0.66       210\n",
      "           2       0.71      0.67      0.69       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.58      0.64      0.61       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.52      0.50      0.51       210\n",
      "           7       0.74      0.88      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   6   2   9  35  20   3]\n",
      " [  2 134   5  22  25  18   4]\n",
      " [  4   8 173  12   5   8   0]\n",
      " [ 10   7   3 138  30  20   2]\n",
      " [ 22  17   0  35 124   9   3]\n",
      " [ 13  11   1  23   4 108  50]\n",
      " [  0   2   0   1   0  21 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.64      0.68       210\n",
      "           2       0.72      0.64      0.68       210\n",
      "           3       0.94      0.82      0.88       210\n",
      "           4       0.57      0.66      0.61       210\n",
      "           5       0.56      0.59      0.57       210\n",
      "           6       0.53      0.51      0.52       210\n",
      "           7       0.75      0.89      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   0   9  37  24   2]\n",
      " [  3 139   5  19  23  19   2]\n",
      " [  2   7 179   9   5   7   1]\n",
      " [  9   8   3 137  30  20   3]\n",
      " [ 24  19   0  35 121   6   5]\n",
      " [ 12  13   2  21   5 106  51]\n",
      " [  0   2   0   1   0  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.67       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.95      0.85      0.90       210\n",
      "           4       0.59      0.65      0.62       210\n",
      "           5       0.55      0.58      0.56       210\n",
      "           6       0.51      0.50      0.51       210\n",
      "           7       0.74      0.86      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   6   0   8  34  18   5]\n",
      " [  4 144   4  19  18  17   4]\n",
      " [  2   9 176  11   4   8   0]\n",
      " [ 11   5   4 134  32  22   2]\n",
      " [ 23  17   0  39 119   6   6]\n",
      " [ 18  15   2  16   4 110  45]\n",
      " [  0   2   0   1   0  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.66      0.68       210\n",
      "           2       0.73      0.69      0.71       210\n",
      "           3       0.95      0.84      0.89       210\n",
      "           4       0.59      0.64      0.61       210\n",
      "           5       0.56      0.57      0.57       210\n",
      "           6       0.53      0.52      0.53       210\n",
      "           7       0.74      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   1  10  34  22   3]\n",
      " [  3 139   3  23  20  18   4]\n",
      " [  4   8 175  11   4   8   0]\n",
      " [  9  12   4 128  33  22   2]\n",
      " [ 22  17   0  34 126   6   5]\n",
      " [ 13  18   1  21   5 103  49]\n",
      " [  1   2   0   1   0  23 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       210\n",
      "           2       0.69      0.66      0.68       210\n",
      "           3       0.95      0.83      0.89       210\n",
      "           4       0.56      0.61      0.58       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.51      0.49      0.50       210\n",
      "           7       0.74      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   5   2   7  33  22   3]\n",
      " [  4 139   6  19  21  18   3]\n",
      " [  4   6 178   8   6   8   0]\n",
      " [  9   9   4 131  35  21   1]\n",
      " [ 23  15   0  40 119   7   6]\n",
      " [ 14  15   1  22   6 107  45]\n",
      " [  1   3   0   1   0  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.66      0.68       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.93      0.85      0.89       210\n",
      "           4       0.57      0.62      0.60       210\n",
      "           5       0.54      0.57      0.55       210\n",
      "           6       0.52      0.51      0.52       210\n",
      "           7       0.76      0.88      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   6   3   7  32  23   3]\n",
      " [  2 146   4  19  18  17   4]\n",
      " [  1  10 176   8   5  10   0]\n",
      " [  6   7   4 135  33  23   2]\n",
      " [ 22  14   0  34 127   6   7]\n",
      " [ 15  16   2  23   3 110  41]\n",
      " [  0   1   0   1   1  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.65      0.69       210\n",
      "           2       0.73      0.70      0.71       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.59      0.64      0.62       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.52      0.52      0.52       210\n",
      "           7       0.76      0.88      0.82       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   6   1  12  28  20   4]\n",
      " [  3 142   6  18  18  20   3]\n",
      " [  0   3 182  10   6   9   0]\n",
      " [  9   8   4 137  31  20   1]\n",
      " [ 25  15   0  39 118   9   4]\n",
      " [ 20  17   2  20   1 105  45]\n",
      " [  1   1   0   1   0  31 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.66      0.68       210\n",
      "           2       0.74      0.68      0.71       210\n",
      "           3       0.93      0.87      0.90       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.58      0.56      0.57       210\n",
      "           6       0.49      0.50      0.50       210\n",
      "           7       0.76      0.84      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 82  13  31   8  42  28   6]\n",
      " [  0  81  25  11  47  37   9]\n",
      " [ 11  16 150   8   8  14   3]\n",
      " [ 14  15  30  51  65  30   5]\n",
      " [ 15  21  18  15 119  18   4]\n",
      " [ 23  15   7  10   7  74  74]\n",
      " [  0   5   0   1   0  26 178]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.39      0.46       210\n",
      "           2       0.49      0.39      0.43       210\n",
      "           3       0.57      0.71      0.64       210\n",
      "           4       0.49      0.24      0.32       210\n",
      "           5       0.41      0.57      0.48       210\n",
      "           6       0.33      0.35      0.34       210\n",
      "           7       0.64      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_ndisbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80480feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7244897959183674\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[165   1   1   2  25  15   1]\n",
      " [  3 157   2  14  15  18   1]\n",
      " [  0   5 191  10   2   2   0]\n",
      " [  5  16   5 136  30  15   3]\n",
      " [ 34  16   1  30 118   5   6]\n",
      " [  8  15   6  23   7 119  32]\n",
      " [  0   0   0   1   3  27 179]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.79      0.78       210\n",
      "           2       0.75      0.75      0.75       210\n",
      "           3       0.93      0.91      0.92       210\n",
      "           4       0.63      0.65      0.64       210\n",
      "           5       0.59      0.56      0.58       210\n",
      "           6       0.59      0.57      0.58       210\n",
      "           7       0.81      0.85      0.83       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   4   4   2  41   7   2]\n",
      " [ 15 147  12   7  22   6   1]\n",
      " [  1   8 194   4   3   0   0]\n",
      " [ 21  23  24 101  35   5   1]\n",
      " [ 60  20   4  18 105   1   2]\n",
      " [ 29  24  20  23  18  61  35]\n",
      " [ 12   1   0   4   6   8 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.71      0.60       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.75      0.92      0.83       210\n",
      "           4       0.64      0.48      0.55       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.69      0.29      0.41       210\n",
      "           7       0.81      0.85      0.83       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.62      1470\n",
      "weighted avg       0.65      0.64      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   3   2   2  35   8   5]\n",
      " [ 12 144  14   9  22   8   1]\n",
      " [  0   9 193   4   4   0   0]\n",
      " [ 12  18  24 108  41   6   1]\n",
      " [ 54  19   3  19 111   2   2]\n",
      " [ 31  22  19  19  21  61  37]\n",
      " [  5   0   0   4   7  13 181]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.74      0.65       210\n",
      "           2       0.67      0.69      0.68       210\n",
      "           3       0.76      0.92      0.83       210\n",
      "           4       0.65      0.51      0.58       210\n",
      "           5       0.46      0.53      0.49       210\n",
      "           6       0.62      0.29      0.40       210\n",
      "           7       0.80      0.86      0.83       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   5   1   2  39   9   3]\n",
      " [ 11 141  19  11  23   4   1]\n",
      " [  1   5 196   4   4   0   0]\n",
      " [ 14  19  21 103  44   4   5]\n",
      " [ 44  16   5  19 120   2   4]\n",
      " [ 21  15  20  26  20  64  44]\n",
      " [  1   0   1   3   8  11 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.72      0.67       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.75      0.93      0.83       210\n",
      "           4       0.61      0.49      0.54       210\n",
      "           5       0.47      0.57      0.51       210\n",
      "           6       0.68      0.30      0.42       210\n",
      "           7       0.77      0.89      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[157   4   2   1  34   8   4]\n",
      " [  8 148  19   9  20   3   3]\n",
      " [  2   9 191   4   4   0   0]\n",
      " [ 11  18  18 109  47   5   2]\n",
      " [ 45  20   6  17 117   1   4]\n",
      " [ 19  18  22  27  21  61  42]\n",
      " [  0   2   1   3  10  12 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.75      0.69       210\n",
      "           2       0.68      0.70      0.69       210\n",
      "           3       0.74      0.91      0.81       210\n",
      "           4       0.64      0.52      0.57       210\n",
      "           5       0.46      0.56      0.51       210\n",
      "           6       0.68      0.29      0.41       210\n",
      "           7       0.77      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.64      1470\n",
      "weighted avg       0.66      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   3   3   1  42   6   6]\n",
      " [  7 146  19   9  25   1   3]\n",
      " [  1  10 192   4   3   0   0]\n",
      " [  9  15  18 108  52   5   3]\n",
      " [ 40  17   6  19 125   1   2]\n",
      " [ 21  17  25  25  21  55  46]\n",
      " [  1   1   1   2   7  12 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.71      0.68       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.73      0.91      0.81       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.45      0.60      0.52       210\n",
      "           6       0.69      0.26      0.38       210\n",
      "           7       0.76      0.89      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   2   3   2  43   5   6]\n",
      " [  7 150  20  10  18   2   3]\n",
      " [  2   8 193   3   3   1   0]\n",
      " [ 13  15  20 109  45   4   4]\n",
      " [ 36  17   7  20 127   1   2]\n",
      " [ 21  15  23  24  21  58  48]\n",
      " [  1   0   1   1   9  17 181]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.71      0.68       210\n",
      "           2       0.72      0.71      0.72       210\n",
      "           3       0.72      0.92      0.81       210\n",
      "           4       0.64      0.52      0.58       210\n",
      "           5       0.48      0.60      0.53       210\n",
      "           6       0.66      0.28      0.39       210\n",
      "           7       0.74      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.64      1470\n",
      "weighted avg       0.66      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[102  10  16   2  48   9  23]\n",
      " [  1 129  17  14  24  13  12]\n",
      " [  0  23 170   5   8   3   1]\n",
      " [  4  17  16  78  45  25  25]\n",
      " [  9  22   1  12 126   5  35]\n",
      " [  5  25  24  11  18  63  64]\n",
      " [  0   6   0   3   5  27 169]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.49      0.62       210\n",
      "           2       0.56      0.61      0.58       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.62      0.37      0.47       210\n",
      "           5       0.46      0.60      0.52       210\n",
      "           6       0.43      0.30      0.35       210\n",
      "           7       0.51      0.80      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.56      1470\n",
      "weighted avg       0.59      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 99   8  23   1  45  13  21]\n",
      " [  1 117  27  15  26  13  11]\n",
      " [  1  20 170   7   7   4   1]\n",
      " [  7  19  18  71  46  23  26]\n",
      " [ 18  19   2   9 124   6  32]\n",
      " [  5  23  27  15  20  57  63]\n",
      " [  0   9   0   3   8  31 159]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.47      0.58       210\n",
      "           2       0.54      0.56      0.55       210\n",
      "           3       0.64      0.81      0.71       210\n",
      "           4       0.59      0.34      0.43       210\n",
      "           5       0.45      0.59      0.51       210\n",
      "           6       0.39      0.27      0.32       210\n",
      "           7       0.51      0.76      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7217687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[167   2   1   2  27  11   0]\n",
      " [  3 162   6  10  13  16   0]\n",
      " [  0   8 194   7   0   1   0]\n",
      " [  4  18   9 141  21  14   3]\n",
      " [ 42  15   2  26 116   5   4]\n",
      " [ 13  21   6  28   5 104  33]\n",
      " [  4   0   0   1   3  25 177]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.80      0.75       210\n",
      "           2       0.72      0.77      0.74       210\n",
      "           3       0.89      0.92      0.91       210\n",
      "           4       0.66      0.67      0.66       210\n",
      "           5       0.63      0.55      0.59       210\n",
      "           6       0.59      0.50      0.54       210\n",
      "           7       0.82      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7319727891156462\n",
      "Confusion Matrix of SVM is:\n",
      " [[124   0   2   1  63  19   1]\n",
      " [  1 136   3  15  28  27   0]\n",
      " [  0   8 182   9   5   6   0]\n",
      " [  0   5   5 137  44  18   1]\n",
      " [  5   4   1  17 171   8   4]\n",
      " [  1   4   2  18   8 154  23]\n",
      " [  0   0   0   0   2  36 172]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.59      0.73       210\n",
      "           2       0.87      0.65      0.74       210\n",
      "           3       0.93      0.87      0.90       210\n",
      "           4       0.70      0.65      0.67       210\n",
      "           5       0.53      0.81      0.64       210\n",
      "           6       0.57      0.73      0.64       210\n",
      "           7       0.86      0.82      0.84       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.77      0.73      0.74      1470\n",
      "weighted avg       0.77      0.73      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7714285714285715\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   2   0   1  35  14   0]\n",
      " [  5 154   2  15  12  20   2]\n",
      " [  0   4 193   5   2   6   0]\n",
      " [  1  10   7 150  23  18   1]\n",
      " [ 21   9   1  16 146  11   6]\n",
      " [  4   7   2  12   4 152  29]\n",
      " [  0   0   0   1   1  27 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.75      0.79       210\n",
      "           2       0.83      0.73      0.78       210\n",
      "           3       0.94      0.92      0.93       210\n",
      "           4       0.75      0.71      0.73       210\n",
      "           5       0.65      0.70      0.67       210\n",
      "           6       0.61      0.72      0.66       210\n",
      "           7       0.83      0.86      0.84       210\n",
      "\n",
      "    accuracy                           0.77      1470\n",
      "   macro avg       0.78      0.77      0.77      1470\n",
      "weighted avg       0.78      0.77      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7374149659863946\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   1   0   2  34  15   2]\n",
      " [  2 146  11  13  13  24   1]\n",
      " [  0  10 184   8   4   4   0]\n",
      " [  4  10   8 140  33  13   2]\n",
      " [ 25  11   2  12 150   5   5]\n",
      " [  8  10  12  14   7 126  33]\n",
      " [  0   0   0   1   1  26 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.74      0.77       210\n",
      "           2       0.78      0.70      0.73       210\n",
      "           3       0.85      0.88      0.86       210\n",
      "           4       0.74      0.67      0.70       210\n",
      "           5       0.62      0.71      0.66       210\n",
      "           6       0.59      0.60      0.60       210\n",
      "           7       0.81      0.87      0.84       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.74      0.74      0.74      1470\n",
      "weighted avg       0.74      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   6   0   0   0 204]\n",
      " [  0   0  46   0   0   0 164]\n",
      " [  0   0 174   0   0   0  36]\n",
      " [  0   0  45   0   0   0 165]\n",
      " [  0   0   4   0   0   0 206]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.57      0.83      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      0.99      0.30       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.11      0.26      0.14      1470\n",
      "weighted avg       0.11      0.26      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   5 183   0  21]\n",
      " [  0   0  12  34 121   0  43]\n",
      " [  0   0 132  42  29   0   7]\n",
      " [  0   0   9  36 138   0  27]\n",
      " [  0   0   1   3 189   0  17]\n",
      " [  0   0   4  23  76   0 107]\n",
      " [  0   0   1   2  32   0 175]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.82      0.63      0.71       210\n",
      "           4       0.25      0.17      0.20       210\n",
      "           5       0.25      0.90      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.44      0.83      0.58       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.25      0.36      0.27      1470\n",
      "weighted avg       0.25      0.36      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43537414965986393\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   4   1   1 116  13   8]\n",
      " [  4  36   7   3 117  30  13]\n",
      " [  0  41 127   6  29   5   2]\n",
      " [  8  18   4  23 130   8  19]\n",
      " [ 11   1   1   2 178   7  10]\n",
      " [  2  10   4  13  74  51  56]\n",
      " [  0   1   1   1  32  17 158]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.32      0.44       210\n",
      "           2       0.32      0.17      0.22       210\n",
      "           3       0.88      0.60      0.72       210\n",
      "           4       0.47      0.11      0.18       210\n",
      "           5       0.26      0.85      0.40       210\n",
      "           6       0.39      0.24      0.30       210\n",
      "           7       0.59      0.75      0.66       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.52      0.44      0.42      1470\n",
      "weighted avg       0.52      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  28   5   1  97  11   1]\n",
      " [  4 110  25   1  48  20   2]\n",
      " [  0  27 163   5  12   3   0]\n",
      " [  8  38  15  25 102  18   4]\n",
      " [ 11  22   2   2 158   9   6]\n",
      " [  2  34  14  12  58  62  28]\n",
      " [  0  10   2   1  24  61 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.32      0.44       210\n",
      "           2       0.41      0.52      0.46       210\n",
      "           3       0.72      0.78      0.75       210\n",
      "           4       0.53      0.12      0.19       210\n",
      "           5       0.32      0.75      0.45       210\n",
      "           6       0.34      0.30      0.31       210\n",
      "           7       0.73      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.54      0.47      0.46      1470\n",
      "weighted avg       0.54      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63  20   2  25  79  13   8]\n",
      " [  8 105  17  24  28  20   8]\n",
      " [ 11  24 152  11   6   5   1]\n",
      " [  6  36  13  64  65  14  12]\n",
      " [  6  21   1  41 124   5  12]\n",
      " [  3  20  10  55  17  48  57]\n",
      " [  1   9   1  19   5  28 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.30      0.41       210\n",
      "           2       0.45      0.50      0.47       210\n",
      "           3       0.78      0.72      0.75       210\n",
      "           4       0.27      0.30      0.29       210\n",
      "           5       0.38      0.59      0.46       210\n",
      "           6       0.36      0.23      0.28       210\n",
      "           7       0.60      0.70      0.65       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.50      0.48      0.47      1470\n",
      "weighted avg       0.50      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  16   1  41  60  15   1]\n",
      " [  3 121   9  27  19  25   6]\n",
      " [  2  40 143  12   4   8   1]\n",
      " [  5  47   6  87  38  17  10]\n",
      " [  9  22   1  49 113   8   8]\n",
      " [  2  31   6  63   8  62  38]\n",
      " [  0  14   1  20   4  33 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.36      0.50       210\n",
      "           2       0.42      0.58      0.48       210\n",
      "           3       0.86      0.68      0.76       210\n",
      "           4       0.29      0.41      0.34       210\n",
      "           5       0.46      0.54      0.50       210\n",
      "           6       0.37      0.30      0.33       210\n",
      "           7       0.68      0.66      0.67       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.51      1470\n",
      "weighted avg       0.55      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   4   2  22  45  26   1]\n",
      " [  8 104  12  37  18  27   4]\n",
      " [  3  22 145  26   8   5   1]\n",
      " [ 12  19   9  92  43  30   5]\n",
      " [ 53   9   3  41  74  21   9]\n",
      " [ 18  11   8  41  10  85  37]\n",
      " [  3   2   1  15  10  49 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.52      0.53       210\n",
      "           2       0.61      0.50      0.55       210\n",
      "           3       0.81      0.69      0.74       210\n",
      "           4       0.34      0.44      0.38       210\n",
      "           5       0.36      0.35      0.35       210\n",
      "           6       0.35      0.40      0.38       210\n",
      "           7       0.70      0.62      0.65       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.53      0.50      0.51      1470\n",
      "weighted avg       0.53      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   3   3  31  43  20   5]\n",
      " [  9 101   9  44  19  20   8]\n",
      " [  3  19 154  18   7   8   1]\n",
      " [ 14  18  13 105  37  16   7]\n",
      " [ 37   6   1  56  92   9   9]\n",
      " [ 15  10   6  62   7  67  43]\n",
      " [  5   3   2  24   5  37 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.50      0.53       210\n",
      "           2       0.63      0.48      0.55       210\n",
      "           3       0.82      0.73      0.77       210\n",
      "           4       0.31      0.50      0.38       210\n",
      "           5       0.44      0.44      0.44       210\n",
      "           6       0.38      0.32      0.35       210\n",
      "           7       0.65      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.52      1470\n",
      "weighted avg       0.54      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   4   6  29  55   9   6]\n",
      " [  7 108  12  34  29  14   6]\n",
      " [  3  17 150  23   9   7   1]\n",
      " [ 17  21  10  86  52  19   5]\n",
      " [ 36   6   1  35 113  10   9]\n",
      " [ 12  10   8  57  17  61  45]\n",
      " [  3   3   2  26  12  31 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.48      0.52       210\n",
      "           2       0.64      0.51      0.57       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.30      0.41      0.34       210\n",
      "           5       0.39      0.54      0.45       210\n",
      "           6       0.40      0.29      0.34       210\n",
      "           7       0.65      0.63      0.64       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.52      1470\n",
      "weighted avg       0.53      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   7   7  15  46  11   7]\n",
      " [ 14 108  11  22  29  20   6]\n",
      " [  4  15 158  15   9   8   1]\n",
      " [ 33  21  10  72  47  20   7]\n",
      " [ 58  14   3  24  94   8   9]\n",
      " [ 32  14  10  36  15  60  43]\n",
      " [ 18   6   2  12   7  39 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.56      0.48       210\n",
      "           2       0.58      0.51      0.55       210\n",
      "           3       0.79      0.75      0.77       210\n",
      "           4       0.37      0.34      0.35       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.36      0.29      0.32       210\n",
      "           7       0.63      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   9   6  11  46   7   6]\n",
      " [ 16 114  10  12  30  22   6]\n",
      " [  3  18 155  16   7   9   2]\n",
      " [ 22  27  10  68  51  22  10]\n",
      " [ 49  13   3  25  98  11  11]\n",
      " [ 24  27  13  28  12  57  49]\n",
      " [ 10   5   2  13   8  40 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.60      0.54       210\n",
      "           2       0.54      0.54      0.54       210\n",
      "           3       0.78      0.74      0.76       210\n",
      "           4       0.39      0.32      0.36       210\n",
      "           5       0.39      0.47      0.42       210\n",
      "           6       0.34      0.27      0.30       210\n",
      "           7       0.61      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116   8   7  13  48  11   7]\n",
      " [ 14 110  13  15  28  22   8]\n",
      " [  2  18 157  14   9   9   1]\n",
      " [ 28  27  12  73  41  22   7]\n",
      " [ 42  16   4  28  97  13  10]\n",
      " [ 25  15  18  28  15  67  42]\n",
      " [  8  12   0  14   7  36 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52       210\n",
      "           2       0.53      0.52      0.53       210\n",
      "           3       0.74      0.75      0.75       210\n",
      "           4       0.39      0.35      0.37       210\n",
      "           5       0.40      0.46      0.43       210\n",
      "           6       0.37      0.32      0.34       210\n",
      "           7       0.64      0.63      0.64       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   7   7   9  48   9  10]\n",
      " [  9 107  14  26  27  19   8]\n",
      " [  3  16 157  16  10   7   1]\n",
      " [ 25  22  14  73  43  24   9]\n",
      " [ 47  14   5  29  90  14  11]\n",
      " [ 25  12  20  35  15  60  43]\n",
      " [ 10   7   2   9   8  42 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.57      0.53       210\n",
      "           2       0.58      0.51      0.54       210\n",
      "           3       0.72      0.75      0.73       210\n",
      "           4       0.37      0.35      0.36       210\n",
      "           5       0.37      0.43      0.40       210\n",
      "           6       0.34      0.29      0.31       210\n",
      "           7       0.62      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   8   5  14  51  11   6]\n",
      " [ 10 109  16  16  32  21   6]\n",
      " [  4  22 154  14   7   8   1]\n",
      " [ 24  22  24  70  43  18   9]\n",
      " [ 39  16   6  34  93  11  11]\n",
      " [ 16  23  12  34  19  66  40]\n",
      " [  9   7   2  16   7  41 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.53      0.52      0.52       210\n",
      "           3       0.70      0.73      0.72       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.37      0.44      0.40       210\n",
      "           6       0.38      0.31      0.34       210\n",
      "           7       0.64      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  13   2  12  48  12   8]\n",
      " [ 13 110  12  17  34  17   7]\n",
      " [  3  16 155  15   7  13   1]\n",
      " [ 26  30  14  70  45  15  10]\n",
      " [ 38  18   8  35  95   7   9]\n",
      " [ 22  20  13  34  19  60  42]\n",
      " [  9   7   4  10  12  44 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.55      0.53       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.75      0.74      0.74       210\n",
      "           4       0.36      0.33      0.35       210\n",
      "           5       0.37      0.45      0.40       210\n",
      "           6       0.36      0.29      0.32       210\n",
      "           7       0.62      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  12   6  13  49  10   6]\n",
      " [ 12 109  10  21  28  21   9]\n",
      " [  2  21 154  13  12   7   1]\n",
      " [ 19  32  14  72  42  21  10]\n",
      " [ 39  16   3  30  96  13  13]\n",
      " [ 17  13  14  30  26  65  45]\n",
      " [  8  10   0  13   9  45 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.54      0.54       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.77      0.73      0.75       210\n",
      "           4       0.38      0.34      0.36       210\n",
      "           5       0.37      0.46      0.41       210\n",
      "           6       0.36      0.31      0.33       210\n",
      "           7       0.60      0.60      0.60       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   6  10  11  52  12   8]\n",
      " [ 10 117  14  15  30  18   6]\n",
      " [  2  22 155  15  10   5   1]\n",
      " [ 21  26  17  70  44  22  10]\n",
      " [ 34  17   6  27 100  11  15]\n",
      " [ 22  23  15  26  15  64  45]\n",
      " [  5   8   2  14  12  37 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.53       210\n",
      "           2       0.53      0.56      0.55       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.39      0.33      0.36       210\n",
      "           5       0.38      0.48      0.42       210\n",
      "           6       0.38      0.30      0.34       210\n",
      "           7       0.61      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111   8   9  15  49  10   8]\n",
      " [ 14 107  10  17  32  21   9]\n",
      " [  1  22 155  15  11   5   1]\n",
      " [ 22  26  14  72  45  22   9]\n",
      " [ 38  17   6  32  92  13  12]\n",
      " [ 19  20  13  31  17  69  41]\n",
      " [  6   8   1  14   9  40 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       210\n",
      "           2       0.51      0.51      0.51       210\n",
      "           3       0.75      0.74      0.74       210\n",
      "           4       0.37      0.34      0.35       210\n",
      "           5       0.36      0.44      0.40       210\n",
      "           6       0.38      0.33      0.35       210\n",
      "           7       0.62      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   8   3  22  48  11   5]\n",
      " [ 11 116   7  19  28  23   6]\n",
      " [  1  21 155  12  12   8   1]\n",
      " [ 27  32  13  70  43  17   8]\n",
      " [ 36  20   3  30  96  11  14]\n",
      " [ 21  16  15  36  17  63  42]\n",
      " [  6  10   1  11  10  42 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.53       210\n",
      "           2       0.52      0.55      0.54       210\n",
      "           3       0.79      0.74      0.76       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.38      0.46      0.41       210\n",
      "           6       0.36      0.30      0.33       210\n",
      "           7       0.63      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   7   6  16  48  10   8]\n",
      " [ 12 109  13  19  31  19   7]\n",
      " [  4  16 155  16   5  13   1]\n",
      " [ 23  30  14  69  46  21   7]\n",
      " [ 36  18   5  27  95  16  13]\n",
      " [ 19  20  13  33  17  65  43]\n",
      " [ 10   6   1  14   9  52 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.53      0.52      0.52       210\n",
      "           3       0.75      0.74      0.74       210\n",
      "           4       0.36      0.33      0.34       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.33      0.31      0.32       210\n",
      "           7       0.60      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.49      1470\n",
      "weighted avg       0.50      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   7   6  16  47  11   8]\n",
      " [ 12 109  13  20  30  19   7]\n",
      " [  4  16 155  16   6  12   1]\n",
      " [ 22  32  14  71  45  19   7]\n",
      " [ 34  18   5  29  94  17  13]\n",
      " [ 19  20  13  33  17  64  44]\n",
      " [  5   8   0  15   9  47 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.55      0.55       210\n",
      "           2       0.52      0.52      0.52       210\n",
      "           3       0.75      0.74      0.75       210\n",
      "           4       0.35      0.34      0.35       210\n",
      "           5       0.38      0.45      0.41       210\n",
      "           6       0.34      0.30      0.32       210\n",
      "           7       0.61      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.40680272108843535\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 23   2  60   0  95   0  30]\n",
      " [  0  15  50   4 100   0  41]\n",
      " [  1   4 183   3  15   0   4]\n",
      " [  1   4  25   9 120   0  51]\n",
      " [  2   3   4   0 173   0  28]\n",
      " [  3   7  36   3  39   1 121]\n",
      " [  0   1   1   0  14   0 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.11      0.19       210\n",
      "           2       0.42      0.07      0.12       210\n",
      "           3       0.51      0.87      0.64       210\n",
      "           4       0.47      0.04      0.08       210\n",
      "           5       0.31      0.82      0.45       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.41      0.92      0.57       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.56      0.41      0.30      1470\n",
      "weighted avg       0.56      0.41      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49863945578231295\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 84  10  10   0  69   0  37]\n",
      " [  1 102  26   0  49   0  32]\n",
      " [  1  24 172   0   8   0   5]\n",
      " [  2  29  17  16  94   0  52]\n",
      " [  1  15   2   0 152   0  40]\n",
      " [  2  23  33   1  16   3 132]\n",
      " [  0   2   0   0   4   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.40      0.56       210\n",
      "           2       0.50      0.49      0.49       210\n",
      "           3       0.66      0.82      0.73       210\n",
      "           4       0.94      0.08      0.14       210\n",
      "           5       0.39      0.72      0.50       210\n",
      "           6       1.00      0.01      0.03       210\n",
      "           7       0.41      0.97      0.57       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.69      0.50      0.43      1470\n",
      "weighted avg       0.69      0.50      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  15   2   1  57   4  25]\n",
      " [  1 143  14   4  32   1  15]\n",
      " [  2  39 160   0   7   0   2]\n",
      " [  4  31  13  42  84   2  34]\n",
      " [  7  14   1   2 152   0  34]\n",
      " [  3  40  23   5  18   8 113]\n",
      " [  0   7   0   0   5   0 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.50      0.64       210\n",
      "           2       0.49      0.68      0.57       210\n",
      "           3       0.75      0.76      0.76       210\n",
      "           4       0.78      0.20      0.32       210\n",
      "           5       0.43      0.72      0.54       210\n",
      "           6       0.53      0.04      0.07       210\n",
      "           7       0.47      0.94      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.62      0.55      0.50      1470\n",
      "weighted avg       0.62      0.55      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116  15   2   1  52   6  18]\n",
      " [  1 140  12   8  29   7  13]\n",
      " [  1  36 165   2   4   0   2]\n",
      " [  3  26  11  71  66   8  25]\n",
      " [  7  14   1   4 155   4  25]\n",
      " [  6  39  18   6  17  27  97]\n",
      " [  0   6   0   0   7   0 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.55      0.67       210\n",
      "           2       0.51      0.67      0.58       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.77      0.34      0.47       210\n",
      "           5       0.47      0.74      0.57       210\n",
      "           6       0.52      0.13      0.21       210\n",
      "           7       0.52      0.94      0.67       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.57      1470\n",
      "weighted avg       0.64      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115  17   3   3  48   9  15]\n",
      " [  1 141  11  12  24  10  11]\n",
      " [  1  29 168   3   5   3   1]\n",
      " [  1  15   7 102  58  12  15]\n",
      " [  4  17   1  14 154   3  17]\n",
      " [  4  28  15  17  16  40  90]\n",
      " [  0   3   0   1   5   9 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.55      0.68       210\n",
      "           2       0.56      0.67      0.61       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.67      0.49      0.56       210\n",
      "           5       0.50      0.73      0.59       210\n",
      "           6       0.47      0.19      0.27       210\n",
      "           7       0.56      0.91      0.70       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.60      1470\n",
      "weighted avg       0.64      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   8   4   5  47  13  12]\n",
      " [  1 141   9  15  23  11  10]\n",
      " [  0  24 173   3   4   5   1]\n",
      " [  2  13   8 119  45  11  12]\n",
      " [  3  18   0  14 159   4  12]\n",
      " [  3  20  10  12  15  72  78]\n",
      " [  0   3   0   1   4   8 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.58      0.71       210\n",
      "           2       0.62      0.67      0.65       210\n",
      "           3       0.85      0.82      0.84       210\n",
      "           4       0.70      0.57      0.63       210\n",
      "           5       0.54      0.76      0.63       210\n",
      "           6       0.58      0.34      0.43       210\n",
      "           7       0.61      0.92      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.66      1470\n",
      "weighted avg       0.69      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   4   3   3  45  19   9]\n",
      " [  1 137   7  21  22  14   8]\n",
      " [  0  14 179   4   5   7   1]\n",
      " [  2  12   6 127  43  12   8]\n",
      " [  9  14   1  13 158   5  10]\n",
      " [  5  17  10  17  11  81  69]\n",
      " [  0   1   0   1   5  13 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.60      0.72       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.55      0.75      0.63       210\n",
      "           6       0.54      0.39      0.45       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   4   1   6  42  21   8]\n",
      " [  1 142   6  24  18  11   8]\n",
      " [  0  16 178   7   2   7   0]\n",
      " [  1  13   7 125  44  11   9]\n",
      " [  9  15   2  18 149   6  11]\n",
      " [  5  20   8  17  10  87  63]\n",
      " [  0   1   0   2   4  15 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.61      0.72       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.88      0.85      0.86       210\n",
      "           4       0.63      0.60      0.61       210\n",
      "           5       0.55      0.71      0.62       210\n",
      "           6       0.55      0.41      0.47       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.67      1470\n",
      "weighted avg       0.69      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7020408163265306\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   5   2   4  43  22   8]\n",
      " [  2 147   8  12  22  15   4]\n",
      " [  0  15 183   6   3   3   0]\n",
      " [  1  10   7 135  39  10   8]\n",
      " [  6  15   1  20 152   5  11]\n",
      " [  5  16  11  13   9 102  54]\n",
      " [  1   1   0   2   3  16 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.60      0.72       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.86      0.87      0.87       210\n",
      "           4       0.70      0.64      0.67       210\n",
      "           5       0.56      0.72      0.63       210\n",
      "           6       0.59      0.49      0.53       210\n",
      "           7       0.69      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   3   1   6  43  18   8]\n",
      " [  2 136   8  17  22  20   5]\n",
      " [  0  13 181   6   5   5   0]\n",
      " [  2  13   7 133  37  11   7]\n",
      " [  5  15   1  15 155   9  10]\n",
      " [  6  12   9  13   9  98  63]\n",
      " [  0   1   0   0   2  18 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.62      0.74       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.87      0.86      0.87       210\n",
      "           4       0.70      0.63      0.67       210\n",
      "           5       0.57      0.74      0.64       210\n",
      "           6       0.55      0.47      0.50       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.69      1470\n",
      "weighted avg       0.71      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   3   2   3  43  23   6]\n",
      " [  2 142   8  16  18  18   6]\n",
      " [  0  11 183   6   4   6   0]\n",
      " [  3  14   6 128  34  18   7]\n",
      " [ 12  14   1  19 146   8  10]\n",
      " [  6  13  10  16   6 104  55]\n",
      " [  0   0   0   2   2  14 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.62      0.72       210\n",
      "           2       0.72      0.68      0.70       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.58      0.70      0.63       210\n",
      "           6       0.54      0.50      0.52       210\n",
      "           7       0.70      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   2   1   3  48  23   4]\n",
      " [  2 139   9  17  21  16   6]\n",
      " [  0  13 182   7   4   4   0]\n",
      " [  2  10   8 131  38  13   8]\n",
      " [  8  12   2  15 157   7   9]\n",
      " [  2  17  14  12   8  97  60]\n",
      " [  1   0   0   1   4  19 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.61      0.73       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.84      0.87      0.85       210\n",
      "           4       0.70      0.62      0.66       210\n",
      "           5       0.56      0.75      0.64       210\n",
      "           6       0.54      0.46      0.50       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   3   2   4  36  19   7]\n",
      " [  3 138   8  24  17  16   4]\n",
      " [  0  12 182   7   4   5   0]\n",
      " [  3  15   7 126  35  17   7]\n",
      " [  8  15   2  17 149  10   9]\n",
      " [  7  16   6  17   6 102  56]\n",
      " [  1   0   0   1   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.69      0.66      0.67       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.60      0.71      0.65       210\n",
      "           6       0.54      0.49      0.51       210\n",
      "           7       0.69      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   4   3   5  42  20   5]\n",
      " [  1 147   8  14  19  17   4]\n",
      " [  0  11 184   6   4   5   0]\n",
      " [  2   9   7 127  42  15   8]\n",
      " [ 10  17   1  18 147   9   8]\n",
      " [  5  14   7  23   6 100  55]\n",
      " [  1   1   0   2   2  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.62      0.73       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.65      0.60      0.63       210\n",
      "           5       0.56      0.70      0.62       210\n",
      "           6       0.55      0.48      0.51       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7013605442176871\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   5   3   5  40  20   5]\n",
      " [  2 141   9  19  18  15   6]\n",
      " [  1  12 184   6   3   4   0]\n",
      " [  1  11   7 137  32  15   7]\n",
      " [ 11  13   1  22 145   7  11]\n",
      " [  4  14  10  15  10 107  50]\n",
      " [  1   1   0   2   1  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.63      0.73       210\n",
      "           2       0.72      0.67      0.69       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.57      0.51      0.54       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   2   4  38  14   7]\n",
      " [  4 143   7  19  19  13   5]\n",
      " [  0  13 181   7   4   5   0]\n",
      " [  1  10   8 131  33  20   7]\n",
      " [ 10  16   1  20 145   8  10]\n",
      " [  6  17   7  21   8  99  52]\n",
      " [  1   0   0   1   2  18 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.88      0.86      0.87       210\n",
      "           4       0.65      0.62      0.63       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.56      0.47      0.51       210\n",
      "           7       0.70      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   3   2   5  36  17   7]\n",
      " [  2 141   6  19  18  22   2]\n",
      " [  0  13 182   4   5   5   1]\n",
      " [  1  11   7 135  34  17   5]\n",
      " [ 13  18   1  16 142  10  10]\n",
      " [ 10  14   6  16   7 108  49]\n",
      " [  1   0   0   3   2  14 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.58      0.68      0.63       210\n",
      "           6       0.56      0.51      0.54       210\n",
      "           7       0.72      0.90      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.70      1470\n",
      "weighted avg       0.71      0.71      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   5   1   5  37  16  10]\n",
      " [  2 145   7  20  15  18   3]\n",
      " [  1  12 183   6   3   5   0]\n",
      " [  3  10   6 134  36  13   8]\n",
      " [ 11  16   2  20 146   7   8]\n",
      " [  5  13   7  21   6 107  51]\n",
      " [  1   0   0   2   1  17 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.65      0.74       210\n",
      "           2       0.72      0.69      0.71       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.64      0.64      0.64       210\n",
      "           5       0.60      0.70      0.64       210\n",
      "           6       0.58      0.51      0.54       210\n",
      "           7       0.70      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   6   2   3  43  15   7]\n",
      " [  1 146   5  18  16  22   2]\n",
      " [  1  13 181   6   4   5   0]\n",
      " [  4  12   6 132  34  14   8]\n",
      " [ 13  16   1  16 145   9  10]\n",
      " [  6  15  12  18   7 102  50]\n",
      " [  1   2   0   1   2  16 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.64      0.72       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.87      0.86      0.87       210\n",
      "           4       0.68      0.63      0.65       210\n",
      "           5       0.58      0.69      0.63       210\n",
      "           6       0.56      0.49      0.52       210\n",
      "           7       0.71      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   4   3   2  43  16   6]\n",
      " [  5 144   7  22  14  15   3]\n",
      " [  1  12 183   6   3   5   0]\n",
      " [  4  12   5 135  31  17   6]\n",
      " [ 20  18   1  16 136   9  10]\n",
      " [  8  16  10  18   6  98  54]\n",
      " [  1   0   0   2   3  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71       210\n",
      "           2       0.70      0.69      0.69       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.67      0.64      0.66       210\n",
      "           5       0.58      0.65      0.61       210\n",
      "           6       0.55      0.47      0.51       210\n",
      "           7       0.70      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   2   4  40  17   9]\n",
      " [  3 144   7  18  16  20   2]\n",
      " [  1  12 185   5   4   3   0]\n",
      " [  4  10   5 134  32  18   7]\n",
      " [ 15  17   2  22 137   8   9]\n",
      " [  9  16   7  18   5 101  54]\n",
      " [  1   1   0   0   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.64      0.71       210\n",
      "           2       0.71      0.69      0.70       210\n",
      "           3       0.89      0.88      0.89       210\n",
      "           4       0.67      0.64      0.65       210\n",
      "           5       0.58      0.65      0.61       210\n",
      "           6       0.54      0.48      0.51       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 99   7  25   2  55   9  13]\n",
      " [  4 109  32  12  35   8  10]\n",
      " [  2  23 167   6  10   2   0]\n",
      " [  7  19  18  77  58  10  21]\n",
      " [ 25  13   2   7 142   5  16]\n",
      " [ 10  27  32  17  27  40  57]\n",
      " [  0  14   0   9  14  28 145]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.47      0.55       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.61      0.80      0.69       210\n",
      "           4       0.59      0.37      0.45       210\n",
      "           5       0.42      0.68      0.52       210\n",
      "           6       0.39      0.19      0.26       210\n",
      "           7       0.55      0.69      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.51      1470\n",
      "weighted avg       0.54      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_vbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[158   4   1   3  24  17   3]\n",
      " [  3 156   5  17  12  17   0]\n",
      " [  2   3 197   1   2   5   0]\n",
      " [  3  13   7 146  18  20   3]\n",
      " [ 30  12   1  30 128   6   3]\n",
      " [  9  17  11  24  11 106  32]\n",
      " [  4   1   0   3   3  21 178]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.75       210\n",
      "           2       0.76      0.74      0.75       210\n",
      "           3       0.89      0.94      0.91       210\n",
      "           4       0.65      0.70      0.67       210\n",
      "           5       0.65      0.61      0.63       210\n",
      "           6       0.55      0.50      0.53       210\n",
      "           7       0.81      0.85      0.83       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.72      0.73      0.72      1470\n",
      "weighted avg       0.72      0.73      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   4  11   6  27   4   8]\n",
      " [ 12 160  11   7  16   3   1]\n",
      " [  6   5 194   0   1   4   0]\n",
      " [ 29  18  16 114  26   5   2]\n",
      " [ 57  36   8  16  85   1   7]\n",
      " [ 50  23  22  24  20  35  36]\n",
      " [ 16   1   3  10  15  14 151]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.71      0.57       210\n",
      "           2       0.65      0.76      0.70       210\n",
      "           3       0.73      0.92      0.82       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.45      0.40      0.43       210\n",
      "           6       0.53      0.17      0.25       210\n",
      "           7       0.74      0.72      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.58      1470\n",
      "weighted avg       0.60      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   6  10   5  25   7  10]\n",
      " [  9 163  12   6  15   3   2]\n",
      " [  7   4 192   1   3   3   0]\n",
      " [ 20  14  19 125  24   6   2]\n",
      " [ 51  39   9  25  76   2   8]\n",
      " [ 47  26  27  20  13  41  36]\n",
      " [ 12   2   2   4  13  21 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.70      0.58       210\n",
      "           2       0.64      0.78      0.70       210\n",
      "           3       0.71      0.91      0.80       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.45      0.36      0.40       210\n",
      "           6       0.49      0.20      0.28       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.60      0.61      0.59      1470\n",
      "weighted avg       0.60      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   5  10   3  25   3  10]\n",
      " [ 11 160  15   9  13   2   0]\n",
      " [  3   5 197   1   2   2   0]\n",
      " [ 19  12  22 121  26   8   2]\n",
      " [ 48  44  10  22  77   3   6]\n",
      " [ 38  29  26  20  18  39  40]\n",
      " [ 10   2   3   2  17  19 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.73      0.62       210\n",
      "           2       0.62      0.76      0.69       210\n",
      "           3       0.70      0.94      0.80       210\n",
      "           4       0.68      0.58      0.62       210\n",
      "           5       0.43      0.37      0.40       210\n",
      "           6       0.51      0.19      0.27       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.60      0.62      0.59      1470\n",
      "weighted avg       0.60      0.62      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   6   8   5  24   6   9]\n",
      " [ 11 161  13   6  14   5   0]\n",
      " [  2   5 197   1   3   2   0]\n",
      " [ 19  11  26 120  24   5   5]\n",
      " [ 48  39   9  21  88   2   3]\n",
      " [ 41  29  26  18  19  38  39]\n",
      " [  9   2   3   2  13  10 171]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.72      0.62       210\n",
      "           2       0.64      0.77      0.70       210\n",
      "           3       0.70      0.94      0.80       210\n",
      "           4       0.69      0.57      0.63       210\n",
      "           5       0.48      0.42      0.45       210\n",
      "           6       0.56      0.18      0.27       210\n",
      "           7       0.75      0.81      0.78       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.62      0.63      0.61      1470\n",
      "weighted avg       0.62      0.63      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6258503401360545\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   6   7   4  26   3   9]\n",
      " [  7 161  13   7  18   2   2]\n",
      " [  4   5 195   1   3   2   0]\n",
      " [ 16  11  28 115  29   5   6]\n",
      " [ 48  37   8  23  90   1   3]\n",
      " [ 38  27  29  18  17  33  48]\n",
      " [ 10   3   3   1  12  10 171]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.74      0.64       210\n",
      "           2       0.64      0.77      0.70       210\n",
      "           3       0.69      0.93      0.79       210\n",
      "           4       0.68      0.55      0.61       210\n",
      "           5       0.46      0.43      0.44       210\n",
      "           6       0.59      0.16      0.25       210\n",
      "           7       0.72      0.81      0.76       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.62      0.63      0.60      1470\n",
      "weighted avg       0.62      0.63      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   5   8   5  28   4  10]\n",
      " [ 10 157  15   7  17   2   2]\n",
      " [  3   5 197   0   3   2   0]\n",
      " [ 16  11  27 119  28   6   3]\n",
      " [ 50  35   7  26  89   0   3]\n",
      " [ 35  28  32  12  16  33  54]\n",
      " [ 12   3   3   4  10   9 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.71      0.62       210\n",
      "           2       0.64      0.75      0.69       210\n",
      "           3       0.68      0.94      0.79       210\n",
      "           4       0.69      0.57      0.62       210\n",
      "           5       0.47      0.42      0.44       210\n",
      "           6       0.59      0.16      0.25       210\n",
      "           7       0.70      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.59      1470\n",
      "weighted avg       0.62      0.62      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[110   3  14   3  27  24  29]\n",
      " [  0 121  16  14  21  28  10]\n",
      " [  8   5 168  12   1  16   0]\n",
      " [  5  16   8  94  23  28  36]\n",
      " [ 19  12   1  17 118   7  36]\n",
      " [ 12  13   5  25   1  78  76]\n",
      " [  0   0   0   2   3  23 182]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.52      0.60       210\n",
      "           2       0.71      0.58      0.64       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.56      0.45      0.50       210\n",
      "           5       0.61      0.56      0.58       210\n",
      "           6       0.38      0.37      0.38       210\n",
      "           7       0.49      0.87      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[108   3  14   6  27  35  17]\n",
      " [  0 121  18   8  27  27   9]\n",
      " [ 21  11 150  16   0  12   0]\n",
      " [  7  14   8  88  32  32  29]\n",
      " [ 19  12   1  14 125  14  25]\n",
      " [ 15  19   7  22   7  77  63]\n",
      " [  0   7   0   1   3  28 171]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.51      0.57       210\n",
      "           2       0.65      0.58      0.61       210\n",
      "           3       0.76      0.71      0.74       210\n",
      "           4       0.57      0.42      0.48       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.34      0.37      0.35       210\n",
      "           7       0.54      0.81      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7081632653061225\n",
      "Confusion Matrix of SVM is:\n",
      " [[165   5   0   2  23  14   1]\n",
      " [  4 161   5  13  13  13   1]\n",
      " [  0   5 199   2   2   2   0]\n",
      " [  9  19   6 138  17  18   3]\n",
      " [ 42  16   1  25 119   5   2]\n",
      " [ 15  23   6  32  10  91  33]\n",
      " [  4   2   0   3   4  29 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.79      0.73       210\n",
      "           2       0.70      0.77      0.73       210\n",
      "           3       0.92      0.95      0.93       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.63      0.57      0.60       210\n",
      "           6       0.53      0.43      0.48       210\n",
      "           7       0.81      0.80      0.80       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.70      0.71      0.70      1470\n",
      "weighted avg       0.70      0.71      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7122448979591837\n",
      "Confusion Matrix of SVM is:\n",
      " [[133   4   0   2  33  35   3]\n",
      " [  1 160   1   7  15  26   0]\n",
      " [  1   4 182   4   9  10   0]\n",
      " [  1   4   4 128  31  38   4]\n",
      " [ 17  11   0  25 131  22   4]\n",
      " [  5   7   5  14   6 140  33]\n",
      " [  0   0   0   0   2  35 173]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.63      0.72       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.95      0.87      0.91       210\n",
      "           4       0.71      0.61      0.66       210\n",
      "           5       0.58      0.62      0.60       210\n",
      "           6       0.46      0.67      0.54       210\n",
      "           7       0.80      0.82      0.81       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.74      0.71      0.72      1470\n",
      "weighted avg       0.74      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7489795918367347\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   3   2   3  22  20   4]\n",
      " [  1 164   6   7   9  23   0]\n",
      " [  0   1 197   5   2   5   0]\n",
      " [  0   7   7 147  20  24   5]\n",
      " [ 26  14   1  22 132  10   5]\n",
      " [  8  11   6  26   2 127  30]\n",
      " [  0   0   0   1   3  28 178]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.74      0.78       210\n",
      "           2       0.82      0.78      0.80       210\n",
      "           3       0.90      0.94      0.92       210\n",
      "           4       0.70      0.70      0.70       210\n",
      "           5       0.69      0.63      0.66       210\n",
      "           6       0.54      0.60      0.57       210\n",
      "           7       0.80      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.717687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   4   0   3  27  19   3]\n",
      " [  2 160   5  11  10  20   2]\n",
      " [  0   1 199   3   2   5   0]\n",
      " [  1  15  11 134  15  28   6]\n",
      " [ 32   9   1  33 122   8   5]\n",
      " [ 12  12  11  27   5 108  35]\n",
      " [  0   0   0   4   1  27 178]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.80      0.76      0.78       210\n",
      "           3       0.88      0.95      0.91       210\n",
      "           4       0.62      0.64      0.63       210\n",
      "           5       0.67      0.58      0.62       210\n",
      "           6       0.50      0.51      0.51       210\n",
      "           7       0.78      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.24421768707482994\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  24   0 186   0   0]\n",
      " [  0   0  11   0 199   0   0]\n",
      " [  0   0 152   0  58   0   0]\n",
      " [  0   0  17   0 193   0   0]\n",
      " [  0   0   3   0 207   0   0]\n",
      " [  0   0  19   0 191   0   0]\n",
      " [  0   0  11   0 199   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.64      0.72      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.17      0.99      0.29       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.12      0.24      0.14      1470\n",
      "weighted avg       0.12      0.24      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  24   0 140   0  46]\n",
      " [  0   0  11   0 154   0  45]\n",
      " [  0   0 152   0  42   0  16]\n",
      " [  0   0  17   0 123   0  70]\n",
      " [  0   0   3   0 170   0  37]\n",
      " [  0   0  19   0  91   0 100]\n",
      " [  0   0  11   0  32   0 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.64      0.72      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.81      0.35       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.80      0.48       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.17      0.33      0.22      1470\n",
      "weighted avg       0.17      0.33      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.408843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  50   8   0   0  23  23]\n",
      " [  3 152   9   1   0  33  12]\n",
      " [  3  40 143   8   0  14   2]\n",
      " [ 10 113  15   2   0  40  30]\n",
      " [ 26 145   1   1   0  16  21]\n",
      " [ 17  78  14   1   0  65  35]\n",
      " [ 14  27   2   0   0  34 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.50      0.54       210\n",
      "           2       0.25      0.72      0.37       210\n",
      "           3       0.74      0.68      0.71       210\n",
      "           4       0.15      0.01      0.02       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.29      0.31      0.30       210\n",
      "           7       0.52      0.63      0.57       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.36      0.41      0.36      1470\n",
      "weighted avg       0.36      0.41      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.45918367346938777\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  15   5   8  40  18  19]\n",
      " [  6 105   5   3  61  20  10]\n",
      " [ 16  30 125  13  24   2   0]\n",
      " [ 10  32  10  23  96  25  14]\n",
      " [ 26  20   0   5 127  15  17]\n",
      " [ 15  28  12   5  61  55  34]\n",
      " [  5   3   1   8  25  33 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.50      0.53       210\n",
      "           2       0.45      0.50      0.47       210\n",
      "           3       0.79      0.60      0.68       210\n",
      "           4       0.35      0.11      0.17       210\n",
      "           5       0.29      0.60      0.39       210\n",
      "           6       0.33      0.26      0.29       210\n",
      "           7       0.59      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.48      0.46      0.45      1470\n",
      "weighted avg       0.48      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4714285714285714\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   8   6  41  23  17  18]\n",
      " [  4  84  10  58  35   9  10]\n",
      " [  9  11 135  39   6  10   0]\n",
      " [  5  22  15 103  30  21  14]\n",
      " [ 17  12   1  64  92   8  16]\n",
      " [  5  13  12  80  19  48  33]\n",
      " [  3   3   1  27  13  29 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.46      0.55       210\n",
      "           2       0.55      0.40      0.46       210\n",
      "           3       0.75      0.64      0.69       210\n",
      "           4       0.25      0.49      0.33       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.34      0.23      0.27       210\n",
      "           7       0.60      0.64      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.48      1470\n",
      "weighted avg       0.51      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   9   4  11  27  45  14]\n",
      " [  3  88  14  14  35  50   6]\n",
      " [  2  12 151  12   7  26   0]\n",
      " [  9  14  16  53  33  74  11]\n",
      " [ 10  12   2  20 103  54   9]\n",
      " [  3  11  18  19  23  99  37]\n",
      " [  4   2   1  10  12  49 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.48      0.59       210\n",
      "           2       0.59      0.42      0.49       210\n",
      "           3       0.73      0.72      0.73       210\n",
      "           4       0.38      0.25      0.30       210\n",
      "           5       0.43      0.49      0.46       210\n",
      "           6       0.25      0.47      0.33       210\n",
      "           7       0.63      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.54      0.49      0.50      1470\n",
      "weighted avg       0.54      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  11   1  15  45  27  13]\n",
      " [  3  93   9  20  50  29   6]\n",
      " [  1  16 147  14  20  12   0]\n",
      " [ 13  19  10  64  64  30  10]\n",
      " [ 11  16   0  21 140  15   7]\n",
      " [  6  15  14  22  49  72  32]\n",
      " [  8   2   0  15  18  42 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.47      0.56       210\n",
      "           2       0.54      0.44      0.49       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.37      0.30      0.34       210\n",
      "           5       0.36      0.67      0.47       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.65      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.51      1470\n",
      "weighted avg       0.54      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 87  16   2  27  32  32  14]\n",
      " [  4 108   7  28  29  24  10]\n",
      " [  1  18 147  21   7  15   1]\n",
      " [ 14  31  11  89  34  18  13]\n",
      " [ 16  18   0  55 103  10   8]\n",
      " [  8  27  12  46  22  63  32]\n",
      " [  9  14   0  16   8  32 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.41      0.50       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.82      0.70      0.76       210\n",
      "           4       0.32      0.42      0.36       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.63      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.50      1470\n",
      "weighted avg       0.52      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  12   3  25  41  17  15]\n",
      " [  7 107  10  32  23  21  10]\n",
      " [  0  20 151  26   2  10   1]\n",
      " [ 19  24  10  81  42  20  14]\n",
      " [ 27  18   2  40 108   8   7]\n",
      " [ 19  25   8  44  21  47  46]\n",
      " [ 11   5   0  17   7  32 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.46      0.50       210\n",
      "           2       0.51      0.51      0.51       210\n",
      "           3       0.82      0.72      0.77       210\n",
      "           4       0.31      0.39      0.34       210\n",
      "           5       0.44      0.51      0.48       210\n",
      "           6       0.30      0.22      0.26       210\n",
      "           7       0.60      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   9   3  16  34  41  11]\n",
      " [ 10  99   9  30  25  29   8]\n",
      " [  2  18 150  16   2  22   0]\n",
      " [ 20  21  10  73  42  34  10]\n",
      " [ 25  16   1  40 114   9   5]\n",
      " [ 18  24  13  38  23  58  36]\n",
      " [ 18   2   1  14   7  39 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.46      0.48       210\n",
      "           2       0.52      0.47      0.50       210\n",
      "           3       0.80      0.71      0.76       210\n",
      "           4       0.32      0.35      0.33       210\n",
      "           5       0.46      0.54      0.50       210\n",
      "           6       0.25      0.28      0.26       210\n",
      "           7       0.65      0.61      0.63       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.50      0.49      0.49      1470\n",
      "weighted avg       0.50      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  15   5  17  32  23   8]\n",
      " [ 12 104   8  24  31  24   7]\n",
      " [  1  13 154  16   3  22   1]\n",
      " [ 18  21  11  69  43  36  12]\n",
      " [ 15  18   3  39 116  14   5]\n",
      " [ 11  25  15  31  30  66  32]\n",
      " [  9   6   3  16  15  37 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.52      0.57       210\n",
      "           2       0.51      0.50      0.50       210\n",
      "           3       0.77      0.73      0.75       210\n",
      "           4       0.33      0.33      0.33       210\n",
      "           5       0.43      0.55      0.48       210\n",
      "           6       0.30      0.31      0.31       210\n",
      "           7       0.66      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.51      1470\n",
      "weighted avg       0.52      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  11   2  14  28  28  11]\n",
      " [ 20 106   6  18  27  25   8]\n",
      " [  6  14 153  17   4  15   1]\n",
      " [ 26  21  13  70  35  31  14]\n",
      " [ 34  16   1  34 106  13   6]\n",
      " [ 15  26  11  35  25  62  36]\n",
      " [ 19   2   2   8  14  35 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52       210\n",
      "           2       0.54      0.50      0.52       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.36      0.33      0.34       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.63      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5136054421768708\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118  13   4  16  29  20  10]\n",
      " [ 14 115  11  21  21  20   8]\n",
      " [  2  20 149  24   1  14   0]\n",
      " [ 19  31  12  75  30  26  17]\n",
      " [ 35  20   0  34 102  13   6]\n",
      " [ 21  23  12  35  18  67  34]\n",
      " [ 11   5   1  13  11  40 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.56      0.55       210\n",
      "           2       0.51      0.55      0.53       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.34      0.36      0.35       210\n",
      "           5       0.48      0.49      0.48       210\n",
      "           6       0.34      0.32      0.33       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.52      1470\n",
      "weighted avg       0.52      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   6   8  19  30  19  13]\n",
      " [ 11 106   6  21  31  24  11]\n",
      " [  5  15 150  16   7  17   0]\n",
      " [ 18  21  18  80  34  23  16]\n",
      " [ 32  15   3  33 106  14   7]\n",
      " [ 18  20  14  34  23  62  39]\n",
      " [ 16   4   1  17   9  38 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.75      0.71      0.73       210\n",
      "           4       0.36      0.38      0.37       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.59      0.60      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  14   5  14  29  27   7]\n",
      " [ 13 107  10  14  33  23  10]\n",
      " [  3  23 161  11   3   7   2]\n",
      " [ 21  26  14  79  34  18  18]\n",
      " [ 30  20   2  33 103  15   7]\n",
      " [ 15  33  11  36  24  58  33]\n",
      " [ 11   7   3  16  11  33 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.54      0.55       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.39      0.38      0.38       210\n",
      "           5       0.43      0.49      0.46       210\n",
      "           6       0.32      0.28      0.30       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4959183673469388\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  11   5  13  32  26   8]\n",
      " [ 12 107  11  20  26  21  13]\n",
      " [  3  20 150  18   3  16   0]\n",
      " [ 23  25  14  70  38  26  14]\n",
      " [ 34  20   2  28 104  15   7]\n",
      " [ 20  29  12  33  24  61  31]\n",
      " [ 10   6   7  14  17  34 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.55      0.54       210\n",
      "           2       0.49      0.51      0.50       210\n",
      "           3       0.75      0.71      0.73       210\n",
      "           4       0.36      0.33      0.34       210\n",
      "           5       0.43      0.50      0.46       210\n",
      "           6       0.31      0.29      0.30       210\n",
      "           7       0.63      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108   8   5  15  30  37   7]\n",
      " [ 18 106  14  17  27  22   6]\n",
      " [  2  16 162  11   6  13   0]\n",
      " [ 18  33  13  68  36  26  16]\n",
      " [ 32  21   3  30 100  14  10]\n",
      " [ 19  28  11  33  22  63  34]\n",
      " [ 14   6   1  16  11  38 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.51      0.51       210\n",
      "           2       0.49      0.50      0.50       210\n",
      "           3       0.78      0.77      0.77       210\n",
      "           4       0.36      0.32      0.34       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.30      0.30      0.30       210\n",
      "           7       0.63      0.59      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48775510204081635\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   9   8  13  37  25   9]\n",
      " [ 16  98  12  21  30  23  10]\n",
      " [  4  13 154  18   5  15   1]\n",
      " [ 18  30  12  69  36  28  17]\n",
      " [ 34  19   2  28 103  16   8]\n",
      " [ 15  32  15  37  20  58  33]\n",
      " [  9   4   3  17  15  36 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.52      0.53       210\n",
      "           2       0.48      0.47      0.47       210\n",
      "           3       0.75      0.73      0.74       210\n",
      "           4       0.34      0.33      0.33       210\n",
      "           5       0.42      0.49      0.45       210\n",
      "           6       0.29      0.28      0.28       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  10   6  14  29  32  11]\n",
      " [ 16 103  12  15  27  24  13]\n",
      " [  7  13 151  19   3  17   0]\n",
      " [ 20  24  14  72  35  25  20]\n",
      " [ 32  17   2  31 103  15  10]\n",
      " [ 26  27  11  35  17  61  33]\n",
      " [ 12   3   3  19  14  37 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.51      0.50       210\n",
      "           2       0.52      0.49      0.51       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.35      0.34      0.35       210\n",
      "           5       0.45      0.49      0.47       210\n",
      "           6       0.29      0.29      0.29       210\n",
      "           7       0.58      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  10   4  13  28  28   6]\n",
      " [ 14 107  11  19  26  24   9]\n",
      " [  4  22 154  14   4  11   1]\n",
      " [ 17  30  11  74  34  26  18]\n",
      " [ 41  19   3  31  92  17   7]\n",
      " [ 20  26  12  33  24  60  35]\n",
      " [ 11   4   2  16  15  35 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.58      0.55       210\n",
      "           2       0.49      0.51      0.50       210\n",
      "           3       0.78      0.73      0.76       210\n",
      "           4       0.37      0.35      0.36       210\n",
      "           5       0.41      0.44      0.42       210\n",
      "           6       0.30      0.29      0.29       210\n",
      "           7       0.63      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  11   4  13  28  28  10]\n",
      " [ 11 116  15  14  25  21   8]\n",
      " [  6  15 151  21   5  11   1]\n",
      " [ 20  26  11  71  37  27  18]\n",
      " [ 30  18   2  35 102  14   9]\n",
      " [ 18  25  13  33  24  63  34]\n",
      " [ 12   4   3  22  10  35 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.55      0.55       210\n",
      "           2       0.54      0.55      0.55       210\n",
      "           3       0.76      0.72      0.74       210\n",
      "           4       0.34      0.34      0.34       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.61      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41768707482993195\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 50   2  43   2  62   0  51]\n",
      " [ 17  35  46   0  57   3  52]\n",
      " [ 11   4 181   0   7   3   4]\n",
      " [ 12   8  25  15  76   1  73]\n",
      " [ 11   2  10   2 132   0  53]\n",
      " [ 10   8  42   1  17   4 128]\n",
      " [  0   1   7   0   5   0 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.24      0.31       210\n",
      "           2       0.58      0.17      0.26       210\n",
      "           3       0.51      0.86      0.64       210\n",
      "           4       0.75      0.07      0.13       210\n",
      "           5       0.37      0.63      0.47       210\n",
      "           6       0.36      0.02      0.04       210\n",
      "           7       0.35      0.94      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.34      1470\n",
      "weighted avg       0.48      0.42      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113   2   6   0  37   3  49]\n",
      " [  4 115  15   1  32   5  38]\n",
      " [ 10  10 173   0   8   0   9]\n",
      " [ 20  14  13  16  81   3  63]\n",
      " [ 11  15   1   2 133   0  48]\n",
      " [ 19  13  17   2  15   7 137]\n",
      " [  0   0   0   0   4   0 206]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.54      0.58       210\n",
      "           2       0.68      0.55      0.61       210\n",
      "           3       0.77      0.82      0.80       210\n",
      "           4       0.76      0.08      0.14       210\n",
      "           5       0.43      0.63      0.51       210\n",
      "           6       0.39      0.03      0.06       210\n",
      "           7       0.37      0.98      0.54       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.58      0.52      0.46      1470\n",
      "weighted avg       0.58      0.52      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   0   1  28   6  41]\n",
      " [  3 137   6   1  29   6  28]\n",
      " [  5  14 167   6   8   8   2]\n",
      " [ 15  22  11  34  64   6  58]\n",
      " [ 30  21   0   5 111   2  41]\n",
      " [ 18  23   7   8  10  24 120]\n",
      " [  0   1   0   0   4   1 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.61      0.63       210\n",
      "           2       0.61      0.65      0.63       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.62      0.16      0.26       210\n",
      "           5       0.44      0.53      0.48       210\n",
      "           6       0.45      0.11      0.18       210\n",
      "           7       0.41      0.97      0.58       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.58      0.55      0.51      1470\n",
      "weighted avg       0.58      0.55      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   6   0   0  30  12  32]\n",
      " [  1 144   5   5  25  12  18]\n",
      " [  3  11 170  12   4   9   1]\n",
      " [  5  19   9  68  47  13  49]\n",
      " [ 22  19   1   7 120   6  35]\n",
      " [ 13  18   8  18  10  36 107]\n",
      " [  0   4   0   0   2   2 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.62      0.68       210\n",
      "           2       0.65      0.69      0.67       210\n",
      "           3       0.88      0.81      0.84       210\n",
      "           4       0.62      0.32      0.43       210\n",
      "           5       0.50      0.57      0.54       210\n",
      "           6       0.40      0.17      0.24       210\n",
      "           7       0.45      0.96      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.57      1470\n",
      "weighted avg       0.61      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   6   0   2  30  23  23]\n",
      " [  1 147   3   7  22  24   6]\n",
      " [  1   8 176  14   3   7   1]\n",
      " [  5  16   8  88  30  37  26]\n",
      " [ 23  17   1  17 113   9  30]\n",
      " [ 10  21   7  19   8  60  85]\n",
      " [  0   3   0   1   3   8 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.60      0.67       210\n",
      "           2       0.67      0.70      0.69       210\n",
      "           3       0.90      0.84      0.87       210\n",
      "           4       0.59      0.42      0.49       210\n",
      "           5       0.54      0.54      0.54       210\n",
      "           6       0.36      0.29      0.32       210\n",
      "           7       0.53      0.93      0.68       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6387755102040816\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   2   1   4  32  24  18]\n",
      " [  1 144   4  13  22  19   7]\n",
      " [  0   7 179  13   1   9   1]\n",
      " [  2  12   6  99  31  42  18]\n",
      " [ 15  16   1  16 125  15  22]\n",
      " [ 10  17   7  23   6  71  76]\n",
      " [  0   0   0   2   3  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.61      0.70       210\n",
      "           2       0.73      0.69      0.71       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.58      0.47      0.52       210\n",
      "           5       0.57      0.60      0.58       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.57      0.91      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   3   1   1  29  29  18]\n",
      " [  2 145   5  11  21  19   7]\n",
      " [  0   3 186  10   4   6   1]\n",
      " [  1   7   6 115  31  34  16]\n",
      " [ 18  12   1  17 127  17  18]\n",
      " [  6  17   5  24   6  83  69]\n",
      " [  0   0   0   2   2  11 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.70       210\n",
      "           2       0.78      0.69      0.73       210\n",
      "           3       0.91      0.89      0.90       210\n",
      "           4       0.64      0.55      0.59       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.60      0.93      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.66      1470\n",
      "weighted avg       0.68      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   3   1   3  33  27  13]\n",
      " [  1 147   6  10  18  23   5]\n",
      " [  1   3 185  11   4   5   1]\n",
      " [  0   9   4 119  30  37  11]\n",
      " [ 16  17   3  21 122  21  10]\n",
      " [  8  13   5  20   9  92  63]\n",
      " [  0   1   0   1   1  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.62      0.71       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.91      0.88      0.89       210\n",
      "           4       0.64      0.57      0.60       210\n",
      "           5       0.56      0.58      0.57       210\n",
      "           6       0.41      0.44      0.42       210\n",
      "           7       0.65      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6680272108843538\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   4   1   2  30  33  10]\n",
      " [  1 141   5  16  19  23   5]\n",
      " [  0   5 184  10   5   5   1]\n",
      " [  1   7   4 125  27  28  18]\n",
      " [ 17  12   1  25 125  15  15]\n",
      " [  7  12   6  26   6  85  68]\n",
      " [  1   1   0   1   2  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.62      0.71       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.62      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   3   1   7  28  29  10]\n",
      " [  2 146   5  12  21  22   2]\n",
      " [  0   6 184   9   6   5   0]\n",
      " [  2  13   4 121  29  27  14]\n",
      " [ 14  13   1  26 133  16   7]\n",
      " [  7  12   4  23   8  97  59]\n",
      " [  0   1   0   0   3  18 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.63      0.72       210\n",
      "           2       0.75      0.70      0.72       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.61      0.58      0.59       210\n",
      "           5       0.58      0.63      0.61       210\n",
      "           6       0.45      0.46      0.46       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   5   2   3  24  29  10]\n",
      " [  1 147   3   9  23  22   5]\n",
      " [  0   3 186  10   5   6   0]\n",
      " [  0   8   2 128  25  33  14]\n",
      " [ 14  14   2  22 125  18  15]\n",
      " [  8  16   6  21   9  88  62]\n",
      " [  0   0   0   0   3  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.65      0.74       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.66      0.61      0.64       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.41      0.42      0.41       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   2   3  26  34   9]\n",
      " [  3 144   5  15  22  16   5]\n",
      " [  2   3 184  11   5   5   0]\n",
      " [  1   5   3 133  25  29  14]\n",
      " [ 16  12   2  26 131  12  11]\n",
      " [  8  18   4  25   5  87  63]\n",
      " [  0   1   0   1   2  18 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.62      0.71       210\n",
      "           2       0.77      0.69      0.72       210\n",
      "           3       0.92      0.88      0.90       210\n",
      "           4       0.62      0.63      0.63       210\n",
      "           5       0.61      0.62      0.62       210\n",
      "           6       0.43      0.41      0.42       210\n",
      "           7       0.65      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   1   3  31  21  18]\n",
      " [  3 149   3  13  20  20   2]\n",
      " [  0   2 191  11   2   4   0]\n",
      " [  3   7   5 133  28  21  13]\n",
      " [ 20  13   0  27 126   9  15]\n",
      " [  9  15   4  18   9 100  55]\n",
      " [  0   1   0   0   2  24 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.63      0.70       210\n",
      "           2       0.78      0.71      0.74       210\n",
      "           3       0.94      0.91      0.92       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.50      0.48      0.49       210\n",
      "           7       0.64      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   4   2   6  28  24  10]\n",
      " [  2 150   4  14  16  21   3]\n",
      " [  0   4 189  10   4   3   0]\n",
      " [  1   8   4 134  27  22  14]\n",
      " [ 20  16   1  29 120  16   8]\n",
      " [  8  11   5  24   4  96  62]\n",
      " [  0   0   0   2   4  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.65      0.72       210\n",
      "           2       0.78      0.71      0.74       210\n",
      "           3       0.92      0.90      0.91       210\n",
      "           4       0.61      0.64      0.62       210\n",
      "           5       0.59      0.57      0.58       210\n",
      "           6       0.47      0.46      0.46       210\n",
      "           7       0.65      0.87      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   2   2   4  31  29  10]\n",
      " [  5 155   4  10  17  15   4]\n",
      " [  0   2 192   8   4   4   0]\n",
      " [  2   8   3 137  23  27  10]\n",
      " [ 20  17   0  26 127  10  10]\n",
      " [ 12  12   6  23   6  91  60]\n",
      " [  0   1   0   0   3  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.63      0.69       210\n",
      "           2       0.79      0.74      0.76       210\n",
      "           3       0.93      0.91      0.92       210\n",
      "           4       0.66      0.65      0.66       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.47      0.43      0.45       210\n",
      "           7       0.67      0.90      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   2   1   5  29  29   9]\n",
      " [  3 146   3  14  20  21   3]\n",
      " [  4   3 186   9   3   5   0]\n",
      " [  1   9   3 132  24  28  13]\n",
      " [ 18  16   0  26 125  12  13]\n",
      " [ 10  13   5  22   7  86  67]\n",
      " [  0   0   0   1   3  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.63      0.63      0.63       210\n",
      "           5       0.59      0.60      0.59       210\n",
      "           6       0.43      0.41      0.42       210\n",
      "           7       0.64      0.89      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   3   2   4  27  29   9]\n",
      " [  3 147   5  11  16  24   4]\n",
      " [  0   3 192   9   2   4   0]\n",
      " [  5   9   6 135  21  22  12]\n",
      " [ 23  16   1  23 122   9  16]\n",
      " [ 13  14   4  21   5  97  56]\n",
      " [  0   0   0   1   2  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.65      0.70       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.91      0.91      0.91       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.63      0.58      0.60       210\n",
      "           6       0.47      0.46      0.46       210\n",
      "           7       0.65      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   4   1   4  24  27   7]\n",
      " [  2 148   4  10  20  24   2]\n",
      " [  2   4 187  10   1   5   1]\n",
      " [  5   7   7 126  30  28   7]\n",
      " [ 21  13   1  19 132  14  10]\n",
      " [ 11  16   5  24   3  88  63]\n",
      " [  0   1   0   1   1  23 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.91      0.89      0.90       210\n",
      "           4       0.65      0.60      0.62       210\n",
      "           5       0.63      0.63      0.63       210\n",
      "           6       0.42      0.42      0.42       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   4   3   5  25  27   8]\n",
      " [  1 153   4  15  15  19   3]\n",
      " [  1   4 186  13   1   5   0]\n",
      " [  4  11   5 131  24  25  10]\n",
      " [ 24  12   0  27 125   9  13]\n",
      " [ 15  18   3  22   3  89  60]\n",
      " [  0   0   0   0   3  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.66      0.70       210\n",
      "           2       0.76      0.73      0.74       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.64      0.60      0.62       210\n",
      "           6       0.46      0.42      0.44       210\n",
      "           7       0.67      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6918367346938775\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   2   4  25  23  11]\n",
      " [  1 149   4  13  19  21   3]\n",
      " [  2   2 190   9   2   4   1]\n",
      " [  7  11   5 127  27  24   9]\n",
      " [ 19  11   0  29 129  10  12]\n",
      " [ 14  10   3  23   4  96  60]\n",
      " [  0   0   0   2   2  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.71       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.93      0.90      0.92       210\n",
      "           4       0.61      0.60      0.61       210\n",
      "           5       0.62      0.61      0.62       210\n",
      "           6       0.48      0.46      0.47       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   4   3   5  28  24   8]\n",
      " [  1 151   4  14  17  20   3]\n",
      " [  2   4 188  10   1   3   2]\n",
      " [  3   9   6 133  28  22   9]\n",
      " [ 21  13   0  29 127   9  11]\n",
      " [ 12  12   5  24   6  94  57]\n",
      " [  0   0   0   2   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.71       210\n",
      "           2       0.78      0.72      0.75       210\n",
      "           3       0.91      0.90      0.90       210\n",
      "           4       0.61      0.63      0.62       210\n",
      "           5       0.61      0.60      0.61       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[107   3  20   3  24  40  13]\n",
      " [  1 118  20   6  24  32   9]\n",
      " [ 23   6 156   9   2  14   0]\n",
      " [  8  14  11  86  28  46  17]\n",
      " [ 25  14   1  15 115  22  18]\n",
      " [ 18  17   9  20   4  81  61]\n",
      " [  0   3   0   1   3  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.51      0.55       210\n",
      "           2       0.67      0.56      0.61       210\n",
      "           3       0.72      0.74      0.73       210\n",
      "           4       0.61      0.41      0.49       210\n",
      "           5       0.57      0.55      0.56       210\n",
      "           6       0.31      0.39      0.34       210\n",
      "           7       0.60      0.84      0.70       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//gpt_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7476190476190476\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[161   1   2   4  31   8   3]\n",
      " [  4 175   2   6  11  11   1]\n",
      " [  0   4 200   1   0   5   0]\n",
      " [  5  16   2 143  20  21   3]\n",
      " [ 34  16   1  22 130   3   4]\n",
      " [ 13  10   8  29  12 118  20]\n",
      " [  0   1   1   4   2  30 172]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.78      0.83      0.81       210\n",
      "           3       0.93      0.95      0.94       210\n",
      "           4       0.68      0.68      0.68       210\n",
      "           5       0.63      0.62      0.62       210\n",
      "           6       0.60      0.56      0.58       210\n",
      "           7       0.85      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   3   2  10  33   6   4]\n",
      " [ 10 168   6   8  12   6   0]\n",
      " [  3   8 189   8   0   1   1]\n",
      " [ 17  29  18 105  25   8   8]\n",
      " [ 44  27   3  13 116   0   7]\n",
      " [ 21  20  13  41  11  70  34]\n",
      " [  8   1   0  16   6  22 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.72      0.65       210\n",
      "           2       0.66      0.80      0.72       210\n",
      "           3       0.82      0.90      0.86       210\n",
      "           4       0.52      0.50      0.51       210\n",
      "           5       0.57      0.55      0.56       210\n",
      "           6       0.62      0.33      0.43       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   2   1  11  39   7   5]\n",
      " [  6 171   6   8  12   6   1]\n",
      " [  3   6 193   4   0   3   1]\n",
      " [ 14  25  20 100  28  13  10]\n",
      " [ 36  29   4  17 113   3   8]\n",
      " [ 19  19  11  33  10  73  45]\n",
      " [  4   0   0  10   0  45 151]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.69      0.66       210\n",
      "           2       0.68      0.81      0.74       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.55      0.48      0.51       210\n",
      "           5       0.56      0.54      0.55       210\n",
      "           6       0.49      0.35      0.41       210\n",
      "           7       0.68      0.72      0.70       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.63      0.64      0.63      1470\n",
      "weighted avg       0.63      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   3   2  10  43   8   4]\n",
      " [  5 171   5   8  12   6   3]\n",
      " [  0   7 189   9   1   3   1]\n",
      " [  8  25  19 106  29  15   8]\n",
      " [ 30  27   3  16 125   2   7]\n",
      " [ 17  16   9  39  11  72  46]\n",
      " [  3   0   0  10   1  36 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68       210\n",
      "           2       0.69      0.81      0.75       210\n",
      "           3       0.83      0.90      0.86       210\n",
      "           4       0.54      0.50      0.52       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.51      0.34      0.41       210\n",
      "           7       0.70      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.64      0.66      0.65      1470\n",
      "weighted avg       0.64      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   2   3  10  37   5   7]\n",
      " [  4 171   5   6  14   8   2]\n",
      " [  2   5 193   5   2   2   1]\n",
      " [  8  21  23 109  29  12   8]\n",
      " [ 34  28   3  12 122   2   9]\n",
      " [ 12  21  11  37  11  64  54]\n",
      " [  5   0   0  11   1  36 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.70      0.69       210\n",
      "           2       0.69      0.81      0.75       210\n",
      "           3       0.81      0.92      0.86       210\n",
      "           4       0.57      0.52      0.55       210\n",
      "           5       0.56      0.58      0.57       210\n",
      "           6       0.50      0.30      0.38       210\n",
      "           7       0.66      0.75      0.70       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.64      0.65      0.64      1470\n",
      "weighted avg       0.64      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   1   2   8  44   7   7]\n",
      " [  3 173   4   6  15   7   2]\n",
      " [  3   7 188   6   1   4   1]\n",
      " [  6  19  24 108  33  13   7]\n",
      " [ 25  26   3  12 133   3   8]\n",
      " [ 13  19  12  38  10  65  53]\n",
      " [  4   0   0   9   1  34 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.67      0.70       210\n",
      "           2       0.71      0.82      0.76       210\n",
      "           3       0.81      0.90      0.85       210\n",
      "           4       0.58      0.51      0.54       210\n",
      "           5       0.56      0.63      0.60       210\n",
      "           6       0.49      0.31      0.38       210\n",
      "           7       0.68      0.77      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   4   2   8  44   8   5]\n",
      " [  3 175   5   4  13   7   3]\n",
      " [  1   7 191   5   1   4   1]\n",
      " [  7  17  23 108  33  14   8]\n",
      " [ 28  28   3  12 129   3   7]\n",
      " [ 11  20  11  36   8  67  57]\n",
      " [  3   0   0  10   1  32 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.66      0.69       210\n",
      "           2       0.70      0.83      0.76       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.59      0.51      0.55       210\n",
      "           5       0.56      0.61      0.59       210\n",
      "           6       0.50      0.32      0.39       210\n",
      "           7       0.67      0.78      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.6319727891156462\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[133   2   0   5  35  23  12]\n",
      " [  4 133  12   9  22  21   9]\n",
      " [  4   2 172  17   2  12   1]\n",
      " [  3  15  12  84  41  29  26]\n",
      " [ 30  18   2  10 126   6  18]\n",
      " [ 11   6  10  17   5  93  68]\n",
      " [  0   0   0   0   2  20 188]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.83      0.82      0.82       210\n",
      "           4       0.59      0.40      0.48       210\n",
      "           5       0.54      0.60      0.57       210\n",
      "           6       0.46      0.44      0.45       210\n",
      "           7       0.58      0.90      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[132   1   1   6  37  26   7]\n",
      " [  2 126  18  10  24  20  10]\n",
      " [  6   7 163  14   3  17   0]\n",
      " [  3  19  13  75  41  42  17]\n",
      " [ 29  18   3  12 124   4  20]\n",
      " [ 11  11  10  15   5  97  61]\n",
      " [  0   0   0   1   3  25 181]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       210\n",
      "           2       0.69      0.60      0.64       210\n",
      "           3       0.78      0.78      0.78       210\n",
      "           4       0.56      0.36      0.44       210\n",
      "           5       0.52      0.59      0.55       210\n",
      "           6       0.42      0.46      0.44       210\n",
      "           7       0.61      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7231292517006803\n",
      "Confusion Matrix of SVM is:\n",
      " [[167   1   1   3  26  11   1]\n",
      " [  8 170   5   8  13   6   0]\n",
      " [  1   4 196   4   0   4   1]\n",
      " [  9  19   8 134  19  17   4]\n",
      " [ 35  18   1  25 125   3   3]\n",
      " [ 17  16   9  32   9 108  19]\n",
      " [  3   0   1   3   3  37 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.80      0.74       210\n",
      "           2       0.75      0.81      0.78       210\n",
      "           3       0.89      0.93      0.91       210\n",
      "           4       0.64      0.64      0.64       210\n",
      "           5       0.64      0.60      0.62       210\n",
      "           6       0.58      0.51      0.55       210\n",
      "           7       0.85      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7435374149659864\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   2   0   7  44  18   1]\n",
      " [  3 171   2  10  11  13   0]\n",
      " [  3   6 184   9   2   6   0]\n",
      " [  5  12   2 130  25  35   1]\n",
      " [  9  16   1  17 156   5   6]\n",
      " [  2   9   2  16   9 143  29]\n",
      " [  0   0   0   1   2  36 171]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.79      0.81      0.80       210\n",
      "           3       0.96      0.88      0.92       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.63      0.74      0.68       210\n",
      "           6       0.56      0.68      0.61       210\n",
      "           7       0.82      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.76      0.74      0.75      1470\n",
      "weighted avg       0.76      0.74      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   2   1   4  31  16   3]\n",
      " [  2 176   1   6   8  15   2]\n",
      " [  0   4 194   6   1   5   0]\n",
      " [  2  10   5 139  18  34   2]\n",
      " [ 15  16   0  15 152   6   6]\n",
      " [  3   9   2  16   1 140  39]\n",
      " [  0   0   0   0   1  23 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.73      0.79       210\n",
      "           2       0.81      0.84      0.82       210\n",
      "           3       0.96      0.92      0.94       210\n",
      "           4       0.75      0.66      0.70       210\n",
      "           5       0.72      0.72      0.72       210\n",
      "           6       0.59      0.67      0.62       210\n",
      "           7       0.78      0.89      0.83       210\n",
      "\n",
      "    accuracy                           0.78      1470\n",
      "   macro avg       0.78      0.78      0.78      1470\n",
      "weighted avg       0.78      0.78      0.78      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6945578231292517\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   1   4   2  28  18   3]\n",
      " [  2 160   7  12  11  18   0]\n",
      " [  0  20 173   8   2   7   0]\n",
      " [  1  21  12 113  22  38   3]\n",
      " [ 20  16   1  22 139   7   5]\n",
      " [  8  11  11  20   3 112  45]\n",
      " [  0   1   0   0   1  38 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.73      0.78       210\n",
      "           2       0.70      0.76      0.73       210\n",
      "           3       0.83      0.82      0.83       210\n",
      "           4       0.64      0.54      0.58       210\n",
      "           5       0.67      0.66      0.67       210\n",
      "           6       0.47      0.53      0.50       210\n",
      "           7       0.75      0.81      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.70      1470\n",
      "weighted avg       0.70      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 210   0   0]\n",
      " [  0   0   2   0 208   0   0]\n",
      " [  0   0 120   0  90   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   2   0 208   0   0]\n",
      " [  0   0   2   0 208   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.92      0.57      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.15      0.22      0.14      1470\n",
      "weighted avg       0.15      0.22      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 183   0  27]\n",
      " [  0   0   2   0 187   0  21]\n",
      " [  0   0 120   0  72   0  18]\n",
      " [  0   0   2   2 168   0  38]\n",
      " [  0   0   0   0 197   0  13]\n",
      " [  0   0   2   0  74   0 134]\n",
      " [  0   0   2   0  20   0 188]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.94      0.57      0.71       210\n",
      "           4       1.00      0.01      0.02       210\n",
      "           5       0.22      0.94      0.35       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.90      0.58       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.37      0.34      0.24      1470\n",
      "weighted avg       0.37      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[160  23   0   0   0  10  17]\n",
      " [ 18 169   2   0   0  10  11]\n",
      " [  7  65 120   0   0  16   2]\n",
      " [ 56 112   1   2   0  15  24]\n",
      " [131  66   0   0   0   1  12]\n",
      " [ 42  32   2   0   0  49  85]\n",
      " [ 18   2   0   0   0  10 180]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.76      0.50       210\n",
      "           2       0.36      0.80      0.50       210\n",
      "           3       0.96      0.57      0.72       210\n",
      "           4       1.00      0.01      0.02       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.44      0.23      0.31       210\n",
      "           7       0.54      0.86      0.67       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.53      0.46      0.39      1470\n",
      "weighted avg       0.53      0.46      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96  10   0  15  64  19   6]\n",
      " [  1 140   1  35  17  15   1]\n",
      " [  0  18 120  55   7   9   1]\n",
      " [  1  43   1  72  55  33   5]\n",
      " [ 15  35   0  31 116   9   4]\n",
      " [  4  31   0  13  38  86  38]\n",
      " [  0   3   0   1  18  61 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.46      0.59       210\n",
      "           2       0.50      0.67      0.57       210\n",
      "           3       0.98      0.57      0.72       210\n",
      "           4       0.32      0.34      0.33       210\n",
      "           5       0.37      0.55      0.44       210\n",
      "           6       0.37      0.41      0.39       210\n",
      "           7       0.70      0.60      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.58      0.51      0.53      1470\n",
      "weighted avg       0.58      0.51      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5428571428571428\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   5   8  12  66  27  10]\n",
      " [  1 114   5  57   9  19   5]\n",
      " [  0  13 165  15   4  12   1]\n",
      " [  0  20  10  86  38  42  14]\n",
      " [  3  10   4  52 109  27   5]\n",
      " [  1  17   3  24  15  85  65]\n",
      " [  0   3   0   0   2  48 157]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.39      0.55       210\n",
      "           2       0.63      0.54      0.58       210\n",
      "           3       0.85      0.79      0.81       210\n",
      "           4       0.35      0.41      0.38       210\n",
      "           5       0.45      0.52      0.48       210\n",
      "           6       0.33      0.40      0.36       210\n",
      "           7       0.61      0.75      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.59      0.54      0.55      1470\n",
      "weighted avg       0.59      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98   7   0  21  50  17  17]\n",
      " [  3 130   3  41  12  17   4]\n",
      " [  0   9 161  19   4  13   4]\n",
      " [  4  31   4  92  38  26  15]\n",
      " [ 11  33   0  35 115   9   7]\n",
      " [ 10  19   2  32  10  76  61]\n",
      " [  2   2   0   4   2  42 158]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.47      0.58       210\n",
      "           2       0.56      0.62      0.59       210\n",
      "           3       0.95      0.77      0.85       210\n",
      "           4       0.38      0.44      0.41       210\n",
      "           5       0.50      0.55      0.52       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.59      0.75      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.57      1470\n",
      "weighted avg       0.59      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   4   4  11  54  20  12]\n",
      " [ 10 122   6  38  13  11  10]\n",
      " [  0   6 170  19   5   8   2]\n",
      " [ 11  17   4 102  35  20  21]\n",
      " [ 27  24   0  25 118   6  10]\n",
      " [ 19   8  12  26  14  69  62]\n",
      " [  4   1   0   3   1  34 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.50      0.54       210\n",
      "           2       0.67      0.58      0.62       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.46      0.49      0.47       210\n",
      "           5       0.49      0.56      0.52       210\n",
      "           6       0.41      0.33      0.37       210\n",
      "           7       0.59      0.80      0.68       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   4   2  17  38  16   9]\n",
      " [ 12 113  12  37  18  12   6]\n",
      " [  2   5 182  11   4   5   1]\n",
      " [ 19  14  12 101  30  20  14]\n",
      " [ 50  16   0  31 102   5   6]\n",
      " [ 24  13   9  36   9  71  48]\n",
      " [  4   2   0  16   2  34 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.59      0.56       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.84      0.87      0.85       210\n",
      "           4       0.41      0.48      0.44       210\n",
      "           5       0.50      0.49      0.49       210\n",
      "           6       0.44      0.34      0.38       210\n",
      "           7       0.64      0.72      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5795918367346938\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115   6   1  14  50  19   5]\n",
      " [  9 118  11  38  15  16   3]\n",
      " [  0   4 179  12   4  10   1]\n",
      " [ 13  16   7 105  34  24  11]\n",
      " [ 34  22   0  33 108   7   6]\n",
      " [ 19  13   8  34  11  82  43]\n",
      " [  5   1   0  10   4  45 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.55      0.57       210\n",
      "           2       0.66      0.56      0.61       210\n",
      "           3       0.87      0.85      0.86       210\n",
      "           4       0.43      0.50      0.46       210\n",
      "           5       0.48      0.51      0.50       210\n",
      "           6       0.40      0.39      0.40       210\n",
      "           7       0.68      0.69      0.68       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.573469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  10   1  14  51  15   5]\n",
      " [ 11 113  11  37  24  12   2]\n",
      " [  4   6 182  13   2   2   1]\n",
      " [ 17  12   4 110  35  21  11]\n",
      " [ 30  29   1  30 108   8   4]\n",
      " [ 22  16   8  39  10  74  41]\n",
      " [ 10   3   0  15   3  37 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.54      0.55       210\n",
      "           2       0.60      0.54      0.57       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.43      0.52      0.47       210\n",
      "           5       0.46      0.51      0.49       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.69      0.68      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   9   4  14  47  12   6]\n",
      " [  7 114   8  33  30  15   3]\n",
      " [  3   5 185  13   1   3   0]\n",
      " [ 16  12   4  96  40  29  13]\n",
      " [ 38  29   2  22 108   8   3]\n",
      " [ 18  20   8  33  12  74  45]\n",
      " [  5   6   0   9   4  37 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.56      0.57       210\n",
      "           2       0.58      0.54      0.56       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.44      0.46      0.45       210\n",
      "           5       0.45      0.51      0.48       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.68      0.71      0.69       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   6   1  12  48  14   7]\n",
      " [  8 118  12  29  20  19   4]\n",
      " [  4   5 180  15   3   3   0]\n",
      " [ 16  17   4  96  41  23  13]\n",
      " [ 42  33   0  22  98  11   4]\n",
      " [ 21  19   6  29   8  82  45]\n",
      " [  7   6   4   9   3  35 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.58      0.57       210\n",
      "           2       0.58      0.56      0.57       210\n",
      "           3       0.87      0.86      0.86       210\n",
      "           4       0.45      0.46      0.45       210\n",
      "           5       0.44      0.47      0.45       210\n",
      "           6       0.44      0.39      0.41       210\n",
      "           7       0.67      0.70      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   8   2   8  47  16   6]\n",
      " [  4 113  14  28  24  23   4]\n",
      " [  0   7 185  10   2   2   4]\n",
      " [ 21  16  10  94  29  27  13]\n",
      " [ 39  35   2  16  97  17   4]\n",
      " [ 18  18   8  28  12  80  46]\n",
      " [  9   5   1  11   3  41 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.59      0.58       210\n",
      "           2       0.56      0.54      0.55       210\n",
      "           3       0.83      0.88      0.86       210\n",
      "           4       0.48      0.45      0.46       210\n",
      "           5       0.45      0.46      0.46       210\n",
      "           6       0.39      0.38      0.38       210\n",
      "           7       0.65      0.67      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   7   2  10  46  16   6]\n",
      " [  8 108  10  42  21  19   2]\n",
      " [  0   4 185  10   4   3   4]\n",
      " [ 19  14   5  99  32  26  15]\n",
      " [ 45  22   4  23 100  12   4]\n",
      " [ 17  18   9  27  13  81  45]\n",
      " [  7   5   0  10   8  38 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.59      0.57       210\n",
      "           2       0.61      0.51      0.56       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.45      0.47      0.46       210\n",
      "           5       0.45      0.48      0.46       210\n",
      "           6       0.42      0.39      0.40       210\n",
      "           7       0.65      0.68      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121   9   2  10  39  21   8]\n",
      " [  6 112  11  33  27  17   4]\n",
      " [  2   4 184  10   4   4   2]\n",
      " [ 18  17   6  97  36  24  12]\n",
      " [ 42  26   6  23  95  14   4]\n",
      " [ 20  16  10  27   9  82  46]\n",
      " [  9   5   0  10   4  36 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.58      0.57       210\n",
      "           2       0.59      0.53      0.56       210\n",
      "           3       0.84      0.88      0.86       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.44      0.45      0.45       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.66      0.70      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117   6   5  15  45  14   8]\n",
      " [  5 114  14  30  25  19   3]\n",
      " [  2   4 177  11   6   9   1]\n",
      " [ 19  17   6  97  33  25  13]\n",
      " [ 44  23   5  20  94  18   6]\n",
      " [ 15  18   9  29  13  76  50]\n",
      " [  6   6   0   8   4  38 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.56      0.56       210\n",
      "           2       0.61      0.54      0.57       210\n",
      "           3       0.82      0.84      0.83       210\n",
      "           4       0.46      0.46      0.46       210\n",
      "           5       0.43      0.45      0.44       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.65      0.70      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   8   5  14  44  12   8]\n",
      " [  9 112  12  30  29  15   3]\n",
      " [  2   6 174  10   4  12   2]\n",
      " [ 19  12   8  95  33  30  13]\n",
      " [ 41  29   1  25  93  16   5]\n",
      " [ 17  18   9  30  12  75  49]\n",
      " [  8   6   0   9   4  37 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.57      0.56       210\n",
      "           2       0.59      0.53      0.56       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.65      0.70      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   7   2  15  41  18   9]\n",
      " [  5 115  13  37  19  18   3]\n",
      " [  2   5 179   9   5   9   1]\n",
      " [ 18  13   8  96  32  30  13]\n",
      " [ 41  23   2  28  97  15   4]\n",
      " [ 14  22   9  26  12  80  47]\n",
      " [  7   4   0   8   4  38 149]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.56      0.57       210\n",
      "           2       0.61      0.55      0.58       210\n",
      "           3       0.84      0.85      0.85       210\n",
      "           4       0.44      0.46      0.45       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.38      0.38      0.38       210\n",
      "           7       0.66      0.71      0.68       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.57      1470\n",
      "weighted avg       0.57      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   7   4  13  47  11   8]\n",
      " [  5 118  11  31  23  19   3]\n",
      " [  0   3 180  10   6   8   3]\n",
      " [ 20  15   6  99  35  20  15]\n",
      " [ 49  25   4  24  89  15   4]\n",
      " [ 16  18   9  27  10  80  50]\n",
      " [  6   5   0  10   4  40 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.57      0.56       210\n",
      "           2       0.62      0.56      0.59       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.46      0.47      0.47       210\n",
      "           5       0.42      0.42      0.42       210\n",
      "           6       0.41      0.38      0.40       210\n",
      "           7       0.64      0.69      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   6   2  16  45  14   9]\n",
      " [  7 116  12  29  23  20   3]\n",
      " [  2   7 177   9   6   7   2]\n",
      " [ 22  12  10  94  32  28  12]\n",
      " [ 47  25   1  24  92  17   4]\n",
      " [ 16  18   9  30   8  79  50]\n",
      " [  7   5   0   8   6  37 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.56      0.55       210\n",
      "           2       0.61      0.55      0.58       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.45      0.45      0.45       210\n",
      "           5       0.43      0.44      0.44       210\n",
      "           6       0.39      0.38      0.38       210\n",
      "           7       0.65      0.70      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.563265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   6   2  13  45  14  10]\n",
      " [  7 117  12  28  23  20   3]\n",
      " [  2   7 177   9   6   7   2]\n",
      " [ 22  12  10  95  31  28  12]\n",
      " [ 49  25   1  23  92  16   4]\n",
      " [ 16  18   9  29   8  80  50]\n",
      " [  7   5   0   8   6  37 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.57      0.55       210\n",
      "           2       0.62      0.56      0.58       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.46      0.45      0.46       210\n",
      "           5       0.44      0.44      0.44       210\n",
      "           6       0.40      0.38      0.39       210\n",
      "           7       0.64      0.70      0.67       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 77   3  25   0  58   0  47]\n",
      " [  1 115  31   0  34   0  29]\n",
      " [  1   8 186   0   6   0   9]\n",
      " [  1  35  41   0  64   0  69]\n",
      " [ 11  18   6   0 142   0  33]\n",
      " [  4   5  25   0  16   1 159]\n",
      " [  0   0   0   0   1   0 209]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.37      0.50       210\n",
      "           2       0.62      0.55      0.58       210\n",
      "           3       0.59      0.89      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.44      0.68      0.53       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.38      1.00      0.55       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.41      1470\n",
      "weighted avg       0.55      0.50      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   0  31   6  31]\n",
      " [  2 139   6   0  34   4  25]\n",
      " [  1  14 175   0   8   6   6]\n",
      " [  6  38  27   2  73   8  56]\n",
      " [ 41  20   2   0 122   1  24]\n",
      " [ 13  10  14   1  18  11 143]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.66      0.67       210\n",
      "           2       0.62      0.66      0.64       210\n",
      "           3       0.78      0.83      0.80       210\n",
      "           4       0.67      0.01      0.02       210\n",
      "           5       0.42      0.58      0.49       210\n",
      "           6       0.31      0.05      0.09       210\n",
      "           7       0.42      0.99      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.47      1470\n",
      "weighted avg       0.56      0.54      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   3   1   0  36  14  20]\n",
      " [  2 165   3   1  15  11  13]\n",
      " [  1  15 172   3   7  11   1]\n",
      " [  2  51  14  21  60  23  39]\n",
      " [ 34  24   2   1 130   3  16]\n",
      " [  7  15  12   4  17  41 114]\n",
      " [  0   0   0   0   2   4 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.65      0.69       210\n",
      "           2       0.60      0.79      0.68       210\n",
      "           3       0.84      0.82      0.83       210\n",
      "           4       0.70      0.10      0.17       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.38      0.20      0.26       210\n",
      "           7       0.50      0.97      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.55      1470\n",
      "weighted avg       0.61      0.59      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6285714285714286\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   4   0   4  47  15  16]\n",
      " [  1 157   1   8  19  12  12]\n",
      " [  1  13 170  11   4  10   1]\n",
      " [  0  29   7  54  64  30  26]\n",
      " [ 20  20   0   1 151   2  16]\n",
      " [  5  12   6  13  20  69  85]\n",
      " [  0   0   0   0   2   9 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.67      0.75      0.71       210\n",
      "           3       0.92      0.81      0.86       210\n",
      "           4       0.59      0.26      0.36       210\n",
      "           5       0.49      0.72      0.58       210\n",
      "           6       0.47      0.33      0.39       210\n",
      "           7       0.56      0.95      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.61      1470\n",
      "weighted avg       0.65      0.63      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   3   0   5  50  23   8]\n",
      " [  1 163   1  10  13  18   4]\n",
      " [  0   7 176  12   4  11   0]\n",
      " [  0  24   5  80  46  36  19]\n",
      " [ 13  22   0   7 151   5  12]\n",
      " [  3  14   4  18  16  71  84]\n",
      " [  0   0   0   0   2  15 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.58      0.70       210\n",
      "           2       0.70      0.78      0.74       210\n",
      "           3       0.95      0.84      0.89       210\n",
      "           4       0.61      0.38      0.47       210\n",
      "           5       0.54      0.72      0.61       210\n",
      "           6       0.40      0.34      0.37       210\n",
      "           7       0.60      0.92      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.64      1470\n",
      "weighted avg       0.67      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   3   0   8  43  21   9]\n",
      " [  1 165   1   8  15  16   4]\n",
      " [  0   6 178  14   4   8   0]\n",
      " [  1  15   3 104  40  35  12]\n",
      " [ 12  19   0   8 154   5  12]\n",
      " [  4   9   4  19  14  92  68]\n",
      " [  0   0   0   0   2  18 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.60      0.71       210\n",
      "           2       0.76      0.79      0.77       210\n",
      "           3       0.96      0.85      0.90       210\n",
      "           4       0.65      0.50      0.56       210\n",
      "           5       0.57      0.73      0.64       210\n",
      "           6       0.47      0.44      0.45       210\n",
      "           7       0.64      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7040816326530612\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   2   0   4  41  28   4]\n",
      " [  1 166   2   8  11  21   1]\n",
      " [  0   5 184  12   2   7   0]\n",
      " [  0  12   3 112  38  33  12]\n",
      " [ 10  19   0   9 155   8   9]\n",
      " [  4  12   4  19   8 101  62]\n",
      " [  0   0   0   0   2  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.62      0.74       210\n",
      "           2       0.77      0.79      0.78       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.68      0.53      0.60       210\n",
      "           5       0.60      0.74      0.66       210\n",
      "           6       0.46      0.48      0.47       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.710204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   2   0   6  45  23   6]\n",
      " [  1 165   2   8  14  17   3]\n",
      " [  0   6 183  10   3   8   0]\n",
      " [  0  11   2 115  35  36  11]\n",
      " [  9  19   0   8 157   6  11]\n",
      " [  4  11   3  23   8 114  47]\n",
      " [  0   0   0   0   2  26 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.61      0.73       210\n",
      "           2       0.77      0.79      0.78       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.68      0.55      0.61       210\n",
      "           5       0.59      0.75      0.66       210\n",
      "           6       0.50      0.54      0.52       210\n",
      "           7       0.70      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   0   7  37  22   4]\n",
      " [  2 169   1   7  12  17   2]\n",
      " [  0   5 182  14   3   6   0]\n",
      " [  0  13   2 119  31  36   9]\n",
      " [ 11  19   0  12 152   7   9]\n",
      " [  5   9   1  25   6 107  57]\n",
      " [  0   0   0   0   2  21 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.66      0.75       210\n",
      "           2       0.78      0.80      0.79       210\n",
      "           3       0.98      0.87      0.92       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.63      0.72      0.67       210\n",
      "           6       0.50      0.51      0.50       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   6  38  19   5]\n",
      " [  1 165   2   9  12  18   3]\n",
      " [  0   7 184   9   4   6   0]\n",
      " [  1  11   3 120  31  35   9]\n",
      " [ 12  18   0  15 150   4  11]\n",
      " [  5  12   3  18   8 112  52]\n",
      " [  0   0   0   0   2  25 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.66      0.76       210\n",
      "           2       0.77      0.79      0.78       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.61      0.71      0.66       210\n",
      "           6       0.51      0.53      0.52       210\n",
      "           7       0.70      0.87      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   1   5  35  21   5]\n",
      " [  2 164   2  11  13  15   3]\n",
      " [  0   3 182  15   3   7   0]\n",
      " [  1  11   2 117  37  33   9]\n",
      " [ 15  19   0  15 146   6   9]\n",
      " [  5  10   2  27   5 112  49]\n",
      " [  0   0   0   0   2  28 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.62      0.56      0.58       210\n",
      "           5       0.61      0.70      0.65       210\n",
      "           6       0.50      0.53      0.52       210\n",
      "           7       0.71      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7312925170068028\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   1   5  38  20   6]\n",
      " [  2 163   1  10  14  18   2]\n",
      " [  0   4 190   8   3   5   0]\n",
      " [  1   9   2 126  32  27  13]\n",
      " [ 13  13   0  14 155   7   8]\n",
      " [  6   8   2  25   6 114  49]\n",
      " [  0   0   0   0   2  19 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.66      0.75       210\n",
      "           2       0.82      0.78      0.80       210\n",
      "           3       0.97      0.90      0.94       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.62      0.74      0.67       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.71      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   6  34  22   6]\n",
      " [  4 164   1   8  14  14   5]\n",
      " [  0   5 186  10   3   6   0]\n",
      " [  3  11   3 127  28  30   8]\n",
      " [ 14  15   0  16 152   3  10]\n",
      " [  5   9   3  24   7 110  52]\n",
      " [  0   0   0   0   2  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.66      0.74       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.63      0.72      0.68       210\n",
      "           6       0.52      0.52      0.52       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   2   1   7  37  20   3]\n",
      " [  2 164   2  11  14  15   2]\n",
      " [  0   5 188   8   4   5   0]\n",
      " [  3   9   3 130  31  26   8]\n",
      " [ 11  16   0  20 149   2  12]\n",
      " [  7   8   3  22   4 113  53]\n",
      " [  0   0   0   0   2  23 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.67      0.75       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.62      0.71      0.66       210\n",
      "           6       0.55      0.54      0.55       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7292517006802721\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   6  35  23   4]\n",
      " [  3 164   1   6  15  19   2]\n",
      " [  0   5 187   9   3   6   0]\n",
      " [  2  11   4 127  30  26  10]\n",
      " [ 10  15   0  17 152   6  10]\n",
      " [  4   9   4  24   7 117  45]\n",
      " [  1   0   0   0   2  21 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.66      0.75       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.67      0.60      0.64       210\n",
      "           5       0.62      0.72      0.67       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.72      0.89      0.80       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   2   1   7  33  17   7]\n",
      " [  2 166   1   9  12  18   2]\n",
      " [  1   4 190   6   3   6   0]\n",
      " [  1  10   2 131  29  26  11]\n",
      " [ 13  17   0  16 150   5   9]\n",
      " [  3   6   3  25   7 115  51]\n",
      " [  1   0   0   0   1  24 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.68      0.76       210\n",
      "           2       0.81      0.79      0.80       210\n",
      "           3       0.96      0.90      0.93       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.64      0.71      0.67       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7258503401360544\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   2   1   6  34  16   5]\n",
      " [  3 166   1   9  11  16   4]\n",
      " [  0   5 186  10   3   6   0]\n",
      " [  2  10   3 127  30  29   9]\n",
      " [ 18  16   0  18 141   6  11]\n",
      " [  7  10   3  19   5 115  51]\n",
      " [  0   0   0   0   2  22 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.79      0.79      0.79       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.67      0.60      0.64       210\n",
      "           5       0.62      0.67      0.65       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   1   1   8  30  19   5]\n",
      " [  4 165   1   9  11  16   4]\n",
      " [  0   4 183  11   4   8   0]\n",
      " [  1   9   2 127  31  31   9]\n",
      " [ 17  17   0  17 145   3  11]\n",
      " [  6   5   3  24   8 118  46]\n",
      " [  0   0   0   0   2  24 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.70      0.76       210\n",
      "           2       0.82      0.79      0.80       210\n",
      "           3       0.96      0.87      0.91       210\n",
      "           4       0.65      0.60      0.63       210\n",
      "           5       0.63      0.69      0.66       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.71      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   1   1   8  32  16   5]\n",
      " [  3 167   1   6  14  16   3]\n",
      " [  1   6 185   7   3   8   0]\n",
      " [  2   9   2 131  28  31   7]\n",
      " [ 20  17   0  17 141   5  10]\n",
      " [  4   6   2  27   8 116  47]\n",
      " [  1   0   0   0   1  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.81      0.80      0.80       210\n",
      "           3       0.97      0.88      0.92       210\n",
      "           4       0.67      0.62      0.65       210\n",
      "           5       0.62      0.67      0.65       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.726530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   1   1   6  35  16   6]\n",
      " [  3 164   1   7  18  15   2]\n",
      " [  0   5 187   7   5   6   0]\n",
      " [  2  12   2 126  30  31   7]\n",
      " [ 17  14   0  20 143   5  11]\n",
      " [  5   8   4  20   7 119  47]\n",
      " [  1   0   0   0   1  24 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.69      0.76       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.60      0.68      0.64       210\n",
      "           6       0.55      0.57      0.56       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   1   1   6  35  15   5]\n",
      " [  3 167   1   5  15  17   2]\n",
      " [  0   5 191   5   4   5   0]\n",
      " [  3  12   2 122  31  33   7]\n",
      " [ 17  16   0  23 140   3  11]\n",
      " [  6  11   3  22   4 118  46]\n",
      " [  1   0   0   0   1  23 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.79      0.80      0.79       210\n",
      "           3       0.96      0.91      0.94       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.61      0.67      0.64       210\n",
      "           6       0.55      0.56      0.56       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.73      0.73      0.73      1470\n",
      "weighted avg       0.73      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[133   1   2   4  33  31   6]\n",
      " [  4 115  29   8  23  26   5]\n",
      " [ 22   2 159   7   2  18   0]\n",
      " [  6  17  18  69  39  46  15]\n",
      " [ 36  18   4   7 118   9  18]\n",
      " [ 12  11  13  10   5 103  56]\n",
      " [  0   0   0   0   2  40 168]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.63      0.63       210\n",
      "           2       0.70      0.55      0.61       210\n",
      "           3       0.71      0.76      0.73       210\n",
      "           4       0.66      0.33      0.44       210\n",
      "           5       0.53      0.56      0.55       210\n",
      "           6       0.38      0.49      0.43       210\n",
      "           7       0.63      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//xlm_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[143   5   1  10  35  11   5]\n",
      " [  9 134   9  16  20  17   5]\n",
      " [  2  13 174  13   1   6   1]\n",
      " [  4  20   6 112  25  34   9]\n",
      " [ 37  18   3  23 109  15   5]\n",
      " [ 16  18   5  31  11  96  33]\n",
      " [  4   5   1   3   2  32 163]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.68      0.67       210\n",
      "           2       0.63      0.64      0.63       210\n",
      "           3       0.87      0.83      0.85       210\n",
      "           4       0.54      0.53      0.54       210\n",
      "           5       0.54      0.52      0.53       210\n",
      "           6       0.45      0.46      0.46       210\n",
      "           7       0.74      0.78      0.76       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.63      1470\n",
      "weighted avg       0.63      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   6   3   7  35   1   5]\n",
      " [ 42 110  18  11  20   5   4]\n",
      " [  9  22 169   3   4   2   1]\n",
      " [ 38  22   4  76  45   8  17]\n",
      " [ 56  18   2  18 106   1   9]\n",
      " [ 55  16  10  32  22  37  38]\n",
      " [ 26   3   1  23  10  13 134]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.73      0.52       210\n",
      "           2       0.56      0.52      0.54       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.45      0.36      0.40       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.55      0.18      0.27       210\n",
      "           7       0.64      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   3   3   8  37   5   7]\n",
      " [ 33 109  16  12  25   4  11]\n",
      " [  8  24 163   4   4   3   4]\n",
      " [ 29  21   4  80  44  10  22]\n",
      " [ 50  18   2  22 104   4  10]\n",
      " [ 45  14   8  31  17  43  52]\n",
      " [ 23   4   0  10  13  20 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.70      0.54       210\n",
      "           2       0.56      0.52      0.54       210\n",
      "           3       0.83      0.78      0.80       210\n",
      "           4       0.48      0.38      0.42       210\n",
      "           5       0.43      0.50      0.46       210\n",
      "           6       0.48      0.20      0.29       210\n",
      "           7       0.57      0.67      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.52      1470\n",
      "weighted avg       0.54      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   3   3   9  37   4   8]\n",
      " [ 31 107  13  14  30   6   9]\n",
      " [ 10  25 163   4   2   2   4]\n",
      " [ 26  15   5  79  53  12  20]\n",
      " [ 43  16   2  29 108   1  11]\n",
      " [ 44  15   7  28  19  42  55]\n",
      " [ 15   4   0  11  15  17 148]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.70      0.56       210\n",
      "           2       0.58      0.51      0.54       210\n",
      "           3       0.84      0.78      0.81       210\n",
      "           4       0.45      0.38      0.41       210\n",
      "           5       0.41      0.51      0.46       210\n",
      "           6       0.50      0.20      0.29       210\n",
      "           7       0.58      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   3   3  10  40   6   7]\n",
      " [ 30 110  14  10  31   8   7]\n",
      " [ 11  27 159   4   3   2   4]\n",
      " [ 25  19   2  72  54  11  27]\n",
      " [ 43  14   3  25 114   1  10]\n",
      " [ 44  14   9  28  22  35  58]\n",
      " [ 15   1   0  10  15  10 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.67      0.54       210\n",
      "           2       0.59      0.52      0.55       210\n",
      "           3       0.84      0.76      0.79       210\n",
      "           4       0.45      0.34      0.39       210\n",
      "           5       0.41      0.54      0.47       210\n",
      "           6       0.48      0.17      0.25       210\n",
      "           7       0.58      0.76      0.66       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5428571428571428\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   3   3   7  37   7   8]\n",
      " [ 31 106  13  10  33   6  11]\n",
      " [ 13  28 156   3   4   2   4]\n",
      " [ 25  18   3  71  58  12  23]\n",
      " [ 41  12   2  21 123   4   7]\n",
      " [ 44  15   9  30  19  32  61]\n",
      " [ 17   1   0   8   9  10 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.69      0.55       210\n",
      "           2       0.58      0.50      0.54       210\n",
      "           3       0.84      0.74      0.79       210\n",
      "           4       0.47      0.34      0.39       210\n",
      "           5       0.43      0.59      0.50       210\n",
      "           6       0.44      0.15      0.23       210\n",
      "           7       0.59      0.79      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   3   3   8  38   3  11]\n",
      " [ 27  97  13  12  39   8  14]\n",
      " [ 12  27 157   3   4   3   4]\n",
      " [ 29  17   4  66  61   9  24]\n",
      " [ 35  15   0  19 125   2  14]\n",
      " [ 45  17  10  26  15  31  66]\n",
      " [ 14   1   0   7   9  10 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.69      0.56       210\n",
      "           2       0.55      0.46      0.50       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.47      0.31      0.38       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.47      0.15      0.22       210\n",
      "           7       0.56      0.80      0.66       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 51  15  37  17  48   4  38]\n",
      " [  0 113  20  17  34  10  16]\n",
      " [  2  74 118   5   4   6   1]\n",
      " [  2  28   8  49  61  12  50]\n",
      " [  4  19   3   8 133   3  40]\n",
      " [ 13  27  16  18  29  30  77]\n",
      " [  6   3   3  17  16  17 148]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.24      0.35       210\n",
      "           2       0.41      0.54      0.46       210\n",
      "           3       0.58      0.56      0.57       210\n",
      "           4       0.37      0.23      0.29       210\n",
      "           5       0.41      0.63      0.50       210\n",
      "           6       0.37      0.14      0.21       210\n",
      "           7       0.40      0.70      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.41      1470\n",
      "weighted avg       0.45      0.44      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.45374149659863944\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 77  15  37   6  35   6  34]\n",
      " [  7 110  30  14  22  14  13]\n",
      " [  5  60 129   4   5   6   1]\n",
      " [  4  34  12  54  46  13  47]\n",
      " [ 15  21   2   6 123   6  37]\n",
      " [ 19  30  21  15  24  30  71]\n",
      " [ 13  11   3  14  15  10 144]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.37      0.44       210\n",
      "           2       0.39      0.52      0.45       210\n",
      "           3       0.55      0.61      0.58       210\n",
      "           4       0.48      0.26      0.33       210\n",
      "           5       0.46      0.59      0.51       210\n",
      "           6       0.35      0.14      0.20       210\n",
      "           7       0.41      0.69      0.52       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.43      1470\n",
      "weighted avg       0.46      0.45      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of SVM is:\n",
      " [[143   6   3  12  31  10   5]\n",
      " [ 12 143  12  19  11  11   2]\n",
      " [  4  15 177   7   1   4   2]\n",
      " [ 12  26   8 112  17  27   8]\n",
      " [ 46  21   2  25  96  13   7]\n",
      " [ 16  19   9  36  12  85  33]\n",
      " [  3   5   0   4   7  32 159]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.68      0.64       210\n",
      "           2       0.61      0.68      0.64       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.52      0.53      0.53       210\n",
      "           5       0.55      0.46      0.50       210\n",
      "           6       0.47      0.40      0.43       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 88   3   0   6  89  10  14]\n",
      " [  3  87   3  16  80  17   4]\n",
      " [  2  23 150  11  14   8   2]\n",
      " [  0   7   2  71  96  15  19]\n",
      " [  0   5   0   7 180   3  15]\n",
      " [  2   4   1  20  44  80  59]\n",
      " [  0   0   0   2  15  16 177]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.42      0.58       210\n",
      "           2       0.67      0.41      0.51       210\n",
      "           3       0.96      0.71      0.82       210\n",
      "           4       0.53      0.34      0.41       210\n",
      "           5       0.35      0.86      0.49       210\n",
      "           6       0.54      0.38      0.45       210\n",
      "           7       0.61      0.84      0.71       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.66      0.57      0.57      1470\n",
      "weighted avg       0.66      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   7   6   3  39   9   8]\n",
      " [  2 135  13  13  16  27   4]\n",
      " [  0  16 178   3   2  10   1]\n",
      " [  4  16   7 117  26  28  12]\n",
      " [ 18  15   3  16 136  11  11]\n",
      " [ 14  10   5  15   7 119  40]\n",
      " [  2   0   0   2   5  26 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.71       210\n",
      "           2       0.68      0.64      0.66       210\n",
      "           3       0.84      0.85      0.84       210\n",
      "           4       0.69      0.56      0.62       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.52      0.57      0.54       210\n",
      "           7       0.70      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of SVM is:\n",
      " [[122   4  15  10  42   7  10]\n",
      " [ 17 106  36  19   9  20   3]\n",
      " [ 12  31 152   6   3   4   2]\n",
      " [ 10  15  11 107  20  31  16]\n",
      " [ 21  15   5  19 130  10  10]\n",
      " [ 20  12   9  24   5  85  55]\n",
      " [  3   2   0   3   2  23 177]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59       210\n",
      "           2       0.57      0.50      0.54       210\n",
      "           3       0.67      0.72      0.69       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.62      0.62      0.62       210\n",
      "           6       0.47      0.40      0.44       210\n",
      "           7       0.65      0.84      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.59      0.60      0.59      1470\n",
      "weighted avg       0.59      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  18   0 192   0   0]\n",
      " [  0   0   9   0 201   0   0]\n",
      " [  0   0  92   0 118   0   0]\n",
      " [  0   0   1   0 209   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.74      0.44      0.55       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.13      0.21      0.12      1470\n",
      "weighted avg       0.13      0.21      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29863945578231293\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 18 165   0   0   0   0  27]\n",
      " [  6 176   3   0   0   0  25]\n",
      " [  0 114  92   0   0   0   4]\n",
      " [  1 150   0   0   0   0  59]\n",
      " [  0 157   0   0   0   0  53]\n",
      " [  4 134   0   0   0   0  72]\n",
      " [  0  57   0   0   0   0 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.09      0.15       210\n",
      "           2       0.18      0.84      0.30       210\n",
      "           3       0.97      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.73      0.51       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.31      0.30      0.22      1470\n",
      "weighted avg       0.31      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 14  62   0   0 103   4  27]\n",
      " [  2  86   3   0  90   4  25]\n",
      " [  0  64  91   0  51   0   4]\n",
      " [  0  44   0   0 106   1  59]\n",
      " [  0  21   0   0 136   0  53]\n",
      " [  1  50   0   0  84   3  72]\n",
      " [  0  16   0   0  41   0 153]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.07      0.12       210\n",
      "           2       0.25      0.41      0.31       210\n",
      "           3       0.97      0.43      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.65      0.33       210\n",
      "           6       0.25      0.01      0.03       210\n",
      "           7       0.39      0.73      0.51       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.41      0.33      0.27      1470\n",
      "weighted avg       0.41      0.33      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 62  16   0  63  46   2  21]\n",
      " [ 16  75   3  68  43   1   4]\n",
      " [ 19  45  91  23  30   0   2]\n",
      " [ 13  32   0  73  65   0  27]\n",
      " [  7  14   0  66  97   0  26]\n",
      " [ 13  39   0  82  26   2  48]\n",
      " [  5  11   0  56  11   0 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.30      0.36       210\n",
      "           2       0.32      0.36      0.34       210\n",
      "           3       0.97      0.43      0.60       210\n",
      "           4       0.17      0.35      0.23       210\n",
      "           5       0.31      0.46      0.37       210\n",
      "           6       0.40      0.01      0.02       210\n",
      "           7       0.50      0.60      0.55       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.45      0.36      0.35      1470\n",
      "weighted avg       0.45      0.36      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37755102040816324\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 44  39  22  12  19  53  21]\n",
      " [  6 103  17  26  12  42   4]\n",
      " [  4  57 119   4   6  18   2]\n",
      " [  2  69  14  44  26  28  27]\n",
      " [  5  53   3  26  59  38  26]\n",
      " [  5  54  11  25   8  59  48]\n",
      " [  0  21   5  24   3  30 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.21      0.32       210\n",
      "           2       0.26      0.49      0.34       210\n",
      "           3       0.62      0.57      0.59       210\n",
      "           4       0.27      0.21      0.24       210\n",
      "           5       0.44      0.28      0.34       210\n",
      "           6       0.22      0.28      0.25       210\n",
      "           7       0.50      0.60      0.55       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.43      0.38      0.38      1470\n",
      "weighted avg       0.43      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 62   9  18  35  49  27  10]\n",
      " [ 13  73  30  44  22  27   1]\n",
      " [  8  29 139  19   9   5   1]\n",
      " [ 10  29  26  59  54  14  18]\n",
      " [ 11  24   9  53  88  15  10]\n",
      " [ 11  20  33  45  21  36  44]\n",
      " [ 19   8  10  25  22  29  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.30      0.36       210\n",
      "           2       0.38      0.35      0.36       210\n",
      "           3       0.52      0.66      0.59       210\n",
      "           4       0.21      0.28      0.24       210\n",
      "           5       0.33      0.42      0.37       210\n",
      "           6       0.24      0.17      0.20       210\n",
      "           7       0.54      0.46      0.50       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.38      0.38      0.37      1470\n",
      "weighted avg       0.38      0.38      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36802721088435375\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 44  18   7  11  61  36  33]\n",
      " [  4  82  18  22  30  26  28]\n",
      " [  1  40 130   5   9  20   5]\n",
      " [  1  41   8  48  65  25  22]\n",
      " [  4  29   4  28 101  27  17]\n",
      " [  4  41   8  26  31  39  61]\n",
      " [  7  16   2  20  14  54  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.21      0.32       210\n",
      "           2       0.31      0.39      0.34       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.30      0.23      0.26       210\n",
      "           5       0.32      0.48      0.39       210\n",
      "           6       0.17      0.19      0.18       210\n",
      "           7       0.37      0.46      0.41       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.37      1470\n",
      "weighted avg       0.41      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39183673469387753\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  17   8  20  48  17  28]\n",
      " [ 17  82  22  37  20  17  15]\n",
      " [  7  30 141   9   5  14   4]\n",
      " [ 16  29   9  58  56  16  26]\n",
      " [ 21  31   8  30  90  13  17]\n",
      " [ 14  36  11  44  24  26  55]\n",
      " [ 13   9   2  34  15  30 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.34      0.39       210\n",
      "           2       0.35      0.39      0.37       210\n",
      "           3       0.70      0.67      0.69       210\n",
      "           4       0.25      0.28      0.26       210\n",
      "           5       0.35      0.43      0.38       210\n",
      "           6       0.20      0.12      0.15       210\n",
      "           7       0.42      0.51      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  20   5  31  30  21  25]\n",
      " [ 13  95  16  38  10  29   9]\n",
      " [  8  24 143  13   5  12   5]\n",
      " [ 22  36   9  57  49  17  20]\n",
      " [ 30  32   4  45  69  17  13]\n",
      " [ 17  35   8  60   7  35  48]\n",
      " [ 18  10   1  29  14  36 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.37      0.39       210\n",
      "           2       0.38      0.45      0.41       210\n",
      "           3       0.77      0.68      0.72       210\n",
      "           4       0.21      0.27      0.24       210\n",
      "           5       0.38      0.33      0.35       210\n",
      "           6       0.21      0.17      0.19       210\n",
      "           7       0.46      0.49      0.47       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.40      1470\n",
      "weighted avg       0.40      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3904761904761905\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  14   6  20  40  25  23]\n",
      " [ 31  71  23  28  10  41   6]\n",
      " [ 14  14 154  10   7   8   3]\n",
      " [ 35  24  13  42  48  29  19]\n",
      " [ 40  17   6  29  80  28  10]\n",
      " [ 30  19   9  36  22  54  40]\n",
      " [ 24  10   1  18  18  48  91]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.39      0.35       210\n",
      "           2       0.42      0.34      0.37       210\n",
      "           3       0.73      0.73      0.73       210\n",
      "           4       0.23      0.20      0.21       210\n",
      "           5       0.36      0.38      0.37       210\n",
      "           6       0.23      0.26      0.24       210\n",
      "           7       0.47      0.43      0.45       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40272108843537413\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  18   7  25  30  25  23]\n",
      " [ 21  96  20  16  12  39   6]\n",
      " [  5  22 152  13   5  10   3]\n",
      " [ 22  31  13  54  39  33  18]\n",
      " [ 37  30   7  35  64  26  11]\n",
      " [ 33  29   5  35  15  54  39]\n",
      " [ 20  17   3  16  16  48  90]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.39      0.38       210\n",
      "           2       0.40      0.46      0.42       210\n",
      "           3       0.73      0.72      0.73       210\n",
      "           4       0.28      0.26      0.27       210\n",
      "           5       0.35      0.30      0.33       210\n",
      "           6       0.23      0.26      0.24       210\n",
      "           7       0.47      0.43      0.45       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.39931972789115644\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  17  13  23  30  29  13]\n",
      " [ 23  81  20  24  11  43   8]\n",
      " [  7  21 152  13   7   8   2]\n",
      " [ 22  29  14  51  43  32  19]\n",
      " [ 37  30   8  39  58  26  12]\n",
      " [ 28  29  10  33  15  60  35]\n",
      " [ 17  15   1  17  16  44 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.40       210\n",
      "           2       0.36      0.39      0.38       210\n",
      "           3       0.70      0.72      0.71       210\n",
      "           4       0.26      0.24      0.25       210\n",
      "           5       0.32      0.28      0.30       210\n",
      "           6       0.25      0.29      0.27       210\n",
      "           7       0.53      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.40      0.40      0.40      1470\n",
      "weighted avg       0.40      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39183673469387753\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 89  18   9  30  23  26  15]\n",
      " [ 31  83  24  24  12  31   5]\n",
      " [  9  16 154  11   8  10   2]\n",
      " [ 41  31  19  38  36  32  13]\n",
      " [ 43  25   6  37  61  26  12]\n",
      " [ 32  27  11  36  12  53  39]\n",
      " [ 23   7   1  24  19  38  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.42      0.37       210\n",
      "           2       0.40      0.40      0.40       210\n",
      "           3       0.69      0.73      0.71       210\n",
      "           4       0.19      0.18      0.19       210\n",
      "           5       0.36      0.29      0.32       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.53      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3877551020408163\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  19   7  27  29  24  23]\n",
      " [ 22  80  23  29  15  32   9]\n",
      " [ 11  19 154  13   4   6   3]\n",
      " [ 30  26  23  49  41  24  17]\n",
      " [ 41  20   6  40  62  26  15]\n",
      " [ 28  26  11  40  14  50  41]\n",
      " [ 25   7   2  21  18  43  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.39      0.36       210\n",
      "           2       0.41      0.38      0.39       210\n",
      "           3       0.68      0.73      0.71       210\n",
      "           4       0.22      0.23      0.23       210\n",
      "           5       0.34      0.30      0.32       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.47      0.45      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  20   8  21  36  31  16]\n",
      " [ 24  78  19  25  16  37  11]\n",
      " [ 11  13 154  13  11   6   2]\n",
      " [ 30  32  17  45  45  20  21]\n",
      " [ 44  24   5  26  64  24  23]\n",
      " [ 28  23  11  38  19  51  40]\n",
      " [ 19  10   2  19  17  45  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.37      0.35       210\n",
      "           2       0.39      0.37      0.38       210\n",
      "           3       0.71      0.73      0.72       210\n",
      "           4       0.24      0.21      0.23       210\n",
      "           5       0.31      0.30      0.31       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.46      0.47      0.47       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.38      0.39      0.38      1470\n",
      "weighted avg       0.38      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3802721088435374\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  14  12  25  29  28  17]\n",
      " [ 18  74  22  31  16  39  10]\n",
      " [ 10  12 148  11  16   8   5]\n",
      " [ 24  20  13  52  51  27  23]\n",
      " [ 43  20   4  31  61  27  24]\n",
      " [ 27  23  10  34  19  51  46]\n",
      " [ 21  15   3  18  26  39  88]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.40      0.39       210\n",
      "           2       0.42      0.35      0.38       210\n",
      "           3       0.70      0.70      0.70       210\n",
      "           4       0.26      0.25      0.25       210\n",
      "           5       0.28      0.29      0.29       210\n",
      "           6       0.23      0.24      0.24       210\n",
      "           7       0.41      0.42      0.42       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.38      0.38      0.38      1470\n",
      "weighted avg       0.38      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3986394557823129\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  18  11  19  28  28  22]\n",
      " [ 25  74  25  24  20  31  11]\n",
      " [  8  18 152  11   6  13   2]\n",
      " [ 27  22  19  57  41  20  24]\n",
      " [ 39  24   4  32  67  26  18]\n",
      " [ 33  21  10  32  18  54  42]\n",
      " [ 24  11   2  19  22  34  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.40      0.37       210\n",
      "           2       0.39      0.35      0.37       210\n",
      "           3       0.68      0.72      0.70       210\n",
      "           4       0.29      0.27      0.28       210\n",
      "           5       0.33      0.32      0.33       210\n",
      "           6       0.26      0.26      0.26       210\n",
      "           7       0.45      0.47      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.39      0.40      0.40      1470\n",
      "weighted avg       0.39      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  18   7  20  30  26  23]\n",
      " [ 23  76  19  23  19  38  12]\n",
      " [  9  15 155  12  12   6   1]\n",
      " [ 29  21  10  49  48  25  28]\n",
      " [ 35  17   9  34  74  27  14]\n",
      " [ 28  26  10  33  17  56  40]\n",
      " [ 24  10   1  16  18  42  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.41      0.39       210\n",
      "           2       0.42      0.36      0.39       210\n",
      "           3       0.73      0.74      0.74       210\n",
      "           4       0.26      0.23      0.25       210\n",
      "           5       0.34      0.35      0.35       210\n",
      "           6       0.25      0.27      0.26       210\n",
      "           7       0.46      0.47      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.40      0.40      0.40      1470\n",
      "weighted avg       0.40      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  18   9  15  30  29  24]\n",
      " [ 23  80  27  25  15  31   9]\n",
      " [ 12  11 152  13  11   9   2]\n",
      " [ 27  16  18  49  52  26  22]\n",
      " [ 38  24   9  33  66  26  14]\n",
      " [ 26  25  10  38  16  52  43]\n",
      " [ 25  11   1  15  24  40  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.40      0.38       210\n",
      "           2       0.43      0.38      0.41       210\n",
      "           3       0.67      0.72      0.70       210\n",
      "           4       0.26      0.23      0.25       210\n",
      "           5       0.31      0.31      0.31       210\n",
      "           6       0.24      0.25      0.25       210\n",
      "           7       0.45      0.45      0.45       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  18   9  15  30  29  24]\n",
      " [ 23  80  27  25  15  31   9]\n",
      " [ 12  11 152  13  11   9   2]\n",
      " [ 27  16  18  49  52  26  22]\n",
      " [ 38  24   9  33  66  26  14]\n",
      " [ 26  25  10  38  16  52  43]\n",
      " [ 25  11   1  15  24  40  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.40      0.38       210\n",
      "           2       0.43      0.38      0.41       210\n",
      "           3       0.67      0.72      0.70       210\n",
      "           4       0.26      0.23      0.25       210\n",
      "           5       0.31      0.31      0.31       210\n",
      "           6       0.24      0.25      0.25       210\n",
      "           7       0.45      0.45      0.45       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  18   9  15  30  29  24]\n",
      " [ 23  80  27  25  15  31   9]\n",
      " [ 12  11 152  13  11   9   2]\n",
      " [ 27  16  18  49  52  26  22]\n",
      " [ 38  24   9  33  66  26  14]\n",
      " [ 26  25  10  38  16  52  43]\n",
      " [ 25  11   1  15  24  40  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.40      0.38       210\n",
      "           2       0.43      0.38      0.41       210\n",
      "           3       0.67      0.72      0.70       210\n",
      "           4       0.26      0.23      0.25       210\n",
      "           5       0.31      0.31      0.31       210\n",
      "           6       0.24      0.25      0.25       210\n",
      "           7       0.45      0.45      0.45       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  3   3  60   1  15   0 128]\n",
      " [  3  19  58   9  14   0 107]\n",
      " [  1  28 152   1   9   0  19]\n",
      " [  3   4  21   9  16   1 156]\n",
      " [  0   8   7   4  31   0 160]\n",
      " [  1   6  34  13   6   0 150]\n",
      " [  0   0   4   2   6   0 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.01      0.03       210\n",
      "           2       0.28      0.09      0.14       210\n",
      "           3       0.45      0.72      0.56       210\n",
      "           4       0.23      0.04      0.07       210\n",
      "           5       0.32      0.15      0.20       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.22      0.94      0.35       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.25      0.28      0.19      1470\n",
      "weighted avg       0.25      0.28      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 61  35  21   0  37   0  56]\n",
      " [  5 100  33   0  38   0  34]\n",
      " [  1  44 156   2   3   0   4]\n",
      " [  5  36  16   2  63   0  88]\n",
      " [  2  26   4   0 124   0  54]\n",
      " [  9  32  22   2  29   2 114]\n",
      " [  5  11   2   2  16   0 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.29      0.41       210\n",
      "           2       0.35      0.48      0.40       210\n",
      "           3       0.61      0.74      0.67       210\n",
      "           4       0.25      0.01      0.02       210\n",
      "           5       0.40      0.59      0.48       210\n",
      "           6       1.00      0.01      0.02       210\n",
      "           7       0.33      0.83      0.47       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.52      0.42      0.35      1470\n",
      "weighted avg       0.52      0.42      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 66  39  16   4  47   0  38]\n",
      " [  2 118  21   1  41   1  26]\n",
      " [  1  51 152   0   3   1   2]\n",
      " [  6  37  10  10  78   1  68]\n",
      " [  3  29   2   2 128   0  46]\n",
      " [ 10  41  16   3  39   4  97]\n",
      " [  5  10   2   1  26   1 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.31      0.44       210\n",
      "           2       0.36      0.56      0.44       210\n",
      "           3       0.69      0.72      0.71       210\n",
      "           4       0.48      0.05      0.09       210\n",
      "           5       0.35      0.61      0.45       210\n",
      "           6       0.50      0.02      0.04       210\n",
      "           7       0.37      0.79      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.38      1470\n",
      "weighted avg       0.50      0.44      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47551020408163264\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87  28   9   5  47   0  34]\n",
      " [  4 133  12   4  34   3  20]\n",
      " [  2  57 146   1   2   1   1]\n",
      " [  4  45   7  26  69   0  59]\n",
      " [  3  28   1   1 140   0  37]\n",
      " [ 11  53   7  10  34   8  87]\n",
      " [  2  16   1  10  20   2 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.41      0.54       210\n",
      "           2       0.37      0.63      0.47       210\n",
      "           3       0.80      0.70      0.74       210\n",
      "           4       0.46      0.12      0.19       210\n",
      "           5       0.40      0.67      0.50       210\n",
      "           6       0.57      0.04      0.07       210\n",
      "           7       0.40      0.76      0.52       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.54      0.48      0.43      1470\n",
      "weighted avg       0.54      0.48      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 85  30   5   8  48   2  32]\n",
      " [  3 135   9   8  31   9  15]\n",
      " [  1  52 149   0   4   3   1]\n",
      " [  5  42   7  41  60   1  54]\n",
      " [  3  27   1   5 136   1  37]\n",
      " [  9  51   6   8  30  21  85]\n",
      " [  4  12   1   6  16   7 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.40      0.53       210\n",
      "           2       0.39      0.64      0.48       210\n",
      "           3       0.84      0.71      0.77       210\n",
      "           4       0.54      0.20      0.29       210\n",
      "           5       0.42      0.65      0.51       210\n",
      "           6       0.48      0.10      0.17       210\n",
      "           7       0.42      0.78      0.55       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.55      0.50      0.47      1470\n",
      "weighted avg       0.55      0.50      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  15   8   6  42   5  33]\n",
      " [  4 132   9   8  32   8  17]\n",
      " [  2  47 148   4   2   5   2]\n",
      " [  2  30   6  60  54   4  54]\n",
      " [  7  24   1   5 136   3  34]\n",
      " [ 14  41   7  10  27  25  86]\n",
      " [  1   5   1  12   9  18 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.48      0.59       210\n",
      "           2       0.45      0.63      0.52       210\n",
      "           3       0.82      0.70      0.76       210\n",
      "           4       0.57      0.29      0.38       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.37      0.12      0.18       210\n",
      "           7       0.42      0.78      0.55       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.50      1470\n",
      "weighted avg       0.55      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95  12   8  12  42  10  31]\n",
      " [  4 129   8  13  30  15  11]\n",
      " [  3  42 152   5   3   4   1]\n",
      " [  4  28   5  64  50  14  45]\n",
      " [ 10  22   1  10 133   4  30]\n",
      " [  7  39   5  19  23  33  84]\n",
      " [  2   7   0   9   8   7 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.45      0.57       210\n",
      "           2       0.46      0.61      0.53       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.48      0.30      0.37       210\n",
      "           5       0.46      0.63      0.53       210\n",
      "           6       0.38      0.16      0.22       210\n",
      "           7       0.47      0.84      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98  14   5  14  41  15  23]\n",
      " [  1 128   8  18  26  17  12]\n",
      " [  3  38 157   5   2   4   1]\n",
      " [  1  28   6  70  49  18  38]\n",
      " [  5  21   2   8 138  10  26]\n",
      " [  6  29   5  23  18  51  78]\n",
      " [  3   4   0   6   9  12 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.47      0.60       210\n",
      "           2       0.49      0.61      0.54       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.49      0.33      0.40       210\n",
      "           5       0.49      0.66      0.56       210\n",
      "           6       0.40      0.24      0.30       210\n",
      "           7       0.50      0.84      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  14   7  13  42   8  22]\n",
      " [  4 122  12  19  22  24   7]\n",
      " [  4  38 156   4   2   5   1]\n",
      " [  4  28   5  69  48  20  36]\n",
      " [  6  20   0  14 137   8  25]\n",
      " [  6  18  10  18  15  64  79]\n",
      " [  1   1   1   5   7  16 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.50      0.61       210\n",
      "           2       0.51      0.58      0.54       210\n",
      "           3       0.82      0.74      0.78       210\n",
      "           4       0.49      0.33      0.39       210\n",
      "           5       0.50      0.65      0.57       210\n",
      "           6       0.44      0.30      0.36       210\n",
      "           7       0.51      0.85      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102  11   6  12  40  14  25]\n",
      " [  7 131  11  17  19  13  12]\n",
      " [  5  34 160   2   5   3   1]\n",
      " [  4  24   5  79  46  24  28]\n",
      " [ 15  18   2  15 131  10  19]\n",
      " [ 11  18   8  19  18  69  67]\n",
      " [  3   2   1   6   6  24 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.49      0.57       210\n",
      "           2       0.55      0.62      0.58       210\n",
      "           3       0.83      0.76      0.79       210\n",
      "           4       0.53      0.38      0.44       210\n",
      "           5       0.49      0.62      0.55       210\n",
      "           6       0.44      0.33      0.38       210\n",
      "           7       0.53      0.80      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  13   5  12  44   9  24]\n",
      " [  6 126  10  17  24  17  10]\n",
      " [  0  39 157   4   2   7   1]\n",
      " [  6  22   6  78  43  26  29]\n",
      " [ 10  19   0  16 139  10  16]\n",
      " [  9  23   6  25  15  61  71]\n",
      " [  1   3   1   2   8  22 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.49      0.60       210\n",
      "           2       0.51      0.60      0.55       210\n",
      "           3       0.85      0.75      0.79       210\n",
      "           4       0.51      0.37      0.43       210\n",
      "           5       0.51      0.66      0.57       210\n",
      "           6       0.40      0.29      0.34       210\n",
      "           7       0.53      0.82      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   8   7  12  43  17  16]\n",
      " [  6 128  10  15  22  19  10]\n",
      " [  3  30 163   4   4   5   1]\n",
      " [  5  20   5  82  48  21  29]\n",
      " [ 12  18   3  15 130   9  23]\n",
      " [  2  21   5  17  19  78  68]\n",
      " [  2   1   2   6   4  18 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.51      0.62       210\n",
      "           2       0.57      0.61      0.59       210\n",
      "           3       0.84      0.78      0.80       210\n",
      "           4       0.54      0.39      0.45       210\n",
      "           5       0.48      0.62      0.54       210\n",
      "           6       0.47      0.37      0.41       210\n",
      "           7       0.55      0.84      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117  12   5  13  34  12  17]\n",
      " [  3 128  11  19  23  15  11]\n",
      " [  3  36 161   3   2   4   1]\n",
      " [  3  19   5  77  47  28  31]\n",
      " [ 14  16   2  18 134   7  19]\n",
      " [ 12  17   6  19  10  79  67]\n",
      " [  1   4   0   4   7  19 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.56      0.64       210\n",
      "           2       0.55      0.61      0.58       210\n",
      "           3       0.85      0.77      0.80       210\n",
      "           4       0.50      0.37      0.42       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.48      0.38      0.42       210\n",
      "           7       0.55      0.83      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  16   9  12  39  12  16]\n",
      " [  4 119  14  18  26  24   5]\n",
      " [  5  33 160   5   1   5   1]\n",
      " [  3  24   6  79  47  25  26]\n",
      " [  5  20   1  21 136   7  20]\n",
      " [ 13  23   7  27  14  68  58]\n",
      " [  1   2   2   8   7  19 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.50      0.61       210\n",
      "           2       0.50      0.57      0.53       210\n",
      "           3       0.80      0.76      0.78       210\n",
      "           4       0.46      0.38      0.42       210\n",
      "           5       0.50      0.65      0.57       210\n",
      "           6       0.42      0.32      0.37       210\n",
      "           7       0.58      0.81      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5829931972789115\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114  10   7   8  43  11  17]\n",
      " [  6 118  14  19  19  29   5]\n",
      " [  1  34 161   6   1   6   1]\n",
      " [  5  22   6  87  42  26  22]\n",
      " [ 14  16   1  13 138   7  21]\n",
      " [ 11  23   8  23  16  65  64]\n",
      " [  3   4   1   3   6  19 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.54      0.63       210\n",
      "           2       0.52      0.56      0.54       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.55      0.41      0.47       210\n",
      "           5       0.52      0.66      0.58       210\n",
      "           6       0.40      0.31      0.35       210\n",
      "           7       0.57      0.83      0.68       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   6   5  12  40  12  14]\n",
      " [  4 137  10  27  15  11   6]\n",
      " [  3  27 164   5   4   6   1]\n",
      " [ 11  24   4  76  45  26  24]\n",
      " [ 15  15   1  15 138   9  17]\n",
      " [ 12  25   9  21  15  68  60]\n",
      " [  1   6   1   4   3  20 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.58      0.64       210\n",
      "           2       0.57      0.65      0.61       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.47      0.36      0.41       210\n",
      "           5       0.53      0.66      0.59       210\n",
      "           6       0.45      0.32      0.38       210\n",
      "           7       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  11   7  17  39  11  16]\n",
      " [  5 121  11  18  24  25   6]\n",
      " [  3  28 162   5   5   6   1]\n",
      " [  9  19   6  87  44  17  28]\n",
      " [ 15  15   2  14 139  11  14]\n",
      " [ 13  20  10  29  11  69  58]\n",
      " [  1   2   1   2   7  25 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.52      0.60       210\n",
      "           2       0.56      0.58      0.57       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.51      0.41      0.46       210\n",
      "           5       0.52      0.66      0.58       210\n",
      "           6       0.42      0.33      0.37       210\n",
      "           7       0.58      0.82      0.68       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.59      0.58      0.58      1470\n",
      "weighted avg       0.59      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113  14   8  10  38  13  14]\n",
      " [  4 134   9  16  19  21   7]\n",
      " [  2  28 166   6   2   5   1]\n",
      " [  8  22   7  78  37  30  28]\n",
      " [ 14  18   2  13 137   8  18]\n",
      " [ 13  25   9  26  16  59  62]\n",
      " [  3   2   2   6   5  20 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.54      0.62       210\n",
      "           2       0.55      0.64      0.59       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.50      0.37      0.43       210\n",
      "           5       0.54      0.65      0.59       210\n",
      "           6       0.38      0.28      0.32       210\n",
      "           7       0.57      0.82      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   7   5  13  40  11  15]\n",
      " [  4 126  12  14  23  23   8]\n",
      " [  4  23 167   7   2   6   1]\n",
      " [  9  21   6  83  42  25  24]\n",
      " [ 14  16   1  11 138  13  17]\n",
      " [  4  20   9  21  19  78  59]\n",
      " [  0   4   1   6   4  21 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.57      0.65       210\n",
      "           2       0.58      0.60      0.59       210\n",
      "           3       0.83      0.80      0.81       210\n",
      "           4       0.54      0.40      0.45       210\n",
      "           5       0.51      0.66      0.58       210\n",
      "           6       0.44      0.37      0.40       210\n",
      "           7       0.58      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   9   7   8  38  14  14]\n",
      " [  3 126  12  17  19  25   8]\n",
      " [  3  29 163   6   1   7   1]\n",
      " [  6  20   6  82  44  29  23]\n",
      " [ 16  20   1  16 134   5  18]\n",
      " [  9  23   6  21  16  75  60]\n",
      " [  2   4   0   5   7  23 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.57      0.65       210\n",
      "           2       0.55      0.60      0.57       210\n",
      "           3       0.84      0.78      0.80       210\n",
      "           4       0.53      0.39      0.45       210\n",
      "           5       0.52      0.64      0.57       210\n",
      "           6       0.42      0.36      0.39       210\n",
      "           7       0.58      0.80      0.67       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115  13   4  10  37  14  17]\n",
      " [  2 128  11  19  21  22   7]\n",
      " [  3  24 167   7   2   6   1]\n",
      " [  2  25   5  89  44  20  25]\n",
      " [ 17  20   0  20 126   9  18]\n",
      " [ 17  24   7  26  13  71  52]\n",
      " [  1   2   0   6   5  27 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.55      0.63       210\n",
      "           2       0.54      0.61      0.57       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.50      0.42      0.46       210\n",
      "           5       0.51      0.60      0.55       210\n",
      "           6       0.42      0.34      0.37       210\n",
      "           7       0.58      0.80      0.68       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 54  27  30  18  40   8  33]\n",
      " [  1 122  18  14  28  12  15]\n",
      " [  3  94  98   2   7   5   1]\n",
      " [  2  37   5  60  49   7  50]\n",
      " [  6  26   0   5 132   2  39]\n",
      " [ 11  43   8  21  28  21  78]\n",
      " [  9   9   2  18  16   9 147]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.26      0.36       210\n",
      "           2       0.34      0.58      0.43       210\n",
      "           3       0.61      0.47      0.53       210\n",
      "           4       0.43      0.29      0.34       210\n",
      "           5       0.44      0.63      0.52       210\n",
      "           6       0.33      0.10      0.15       210\n",
      "           7       0.40      0.70      0.51       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.41      1470\n",
      "weighted avg       0.46      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//bert_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[133   8   7   8  32  19   3]\n",
      " [ 11 144   5   6  21  20   3]\n",
      " [  6  12 175   7   4   6   0]\n",
      " [ 16  15   5 123  33  15   3]\n",
      " [ 37  17   3  31 101  12   9]\n",
      " [ 17  16  14  24   9  98  32]\n",
      " [  5   3   0   2   4  39 157]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61       210\n",
      "           2       0.67      0.69      0.68       210\n",
      "           3       0.84      0.83      0.84       210\n",
      "           4       0.61      0.59      0.60       210\n",
      "           5       0.50      0.48      0.49       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.76      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.63      1470\n",
      "weighted avg       0.63      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  14  13   9  32  11   8]\n",
      " [ 29 131   8  13  19   2   8]\n",
      " [ 10  14 149  31   3   3   0]\n",
      " [ 40  19   7  83  50   4   7]\n",
      " [ 70  18   4  25  81   5   7]\n",
      " [ 46  21  11  16  11  52  53]\n",
      " [ 11   2   0   1   8  16 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.59      0.46       210\n",
      "           2       0.60      0.62      0.61       210\n",
      "           3       0.78      0.71      0.74       210\n",
      "           4       0.47      0.40      0.43       210\n",
      "           5       0.40      0.39      0.39       210\n",
      "           6       0.56      0.25      0.34       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  13  13  10  34  10   9]\n",
      " [ 17 142  10   9  20   5   7]\n",
      " [ 11  14 168  13   1   2   1]\n",
      " [ 29  19   5  88  50   9  10]\n",
      " [ 53  16   2  30  90   8  11]\n",
      " [ 40  20  13  12  12  58  55]\n",
      " [  5   2   0   1   6  30 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.58      0.50       210\n",
      "           2       0.63      0.68      0.65       210\n",
      "           3       0.80      0.80      0.80       210\n",
      "           4       0.54      0.42      0.47       210\n",
      "           5       0.42      0.43      0.43       210\n",
      "           6       0.48      0.28      0.35       210\n",
      "           7       0.64      0.79      0.71       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.56      1470\n",
      "weighted avg       0.56      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  14  12  10  31  10  10]\n",
      " [ 20 137  12  11  17   5   8]\n",
      " [  9  14 173   7   4   2   1]\n",
      " [ 34  21   5  90  44   8   8]\n",
      " [ 52  17   2  30  94   5  10]\n",
      " [ 30  19  14  13  14  54  66]\n",
      " [  4   1   0   0   7  25 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.59      0.51       210\n",
      "           2       0.61      0.65      0.63       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.56      0.43      0.49       210\n",
      "           5       0.45      0.45      0.45       210\n",
      "           6       0.50      0.26      0.34       210\n",
      "           7       0.63      0.82      0.71       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.56      1470\n",
      "weighted avg       0.57      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5802721088435374\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  12  14   9  34  11   9]\n",
      " [ 18 141  11  10  17   5   8]\n",
      " [  8  14 176   7   2   2   1]\n",
      " [ 27  17   6  95  52   7   6]\n",
      " [ 51  16   1  25 100   7  10]\n",
      " [ 35  20  14  15  14  50  62]\n",
      " [  5   1   0   1   9  24 170]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.58      0.51       210\n",
      "           2       0.64      0.67      0.65       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.59      0.45      0.51       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.47      0.24      0.32       210\n",
      "           7       0.64      0.81      0.71       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.57      0.58      0.57      1470\n",
      "weighted avg       0.57      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5775510204081633\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[118  12  15  10  37   9   9]\n",
      " [ 18 136  10   9  24   4   9]\n",
      " [  9  14 173   9   2   2   1]\n",
      " [ 23  17   6  95  54   8   7]\n",
      " [ 46  17   2  25 107   3  10]\n",
      " [ 33  20  13  20  15  44  65]\n",
      " [  2   1   0   1   5  25 176]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.56      0.51       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.79      0.82      0.81       210\n",
      "           4       0.56      0.45      0.50       210\n",
      "           5       0.44      0.51      0.47       210\n",
      "           6       0.46      0.21      0.29       210\n",
      "           7       0.64      0.84      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.57      0.58      0.56      1470\n",
      "weighted avg       0.57      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  11  11   9  36   8  12]\n",
      " [ 18 137  10  10  24   3   8]\n",
      " [  9  16 170  11   2   1   1]\n",
      " [ 25  15   4  94  56   9   7]\n",
      " [ 39  16   3  24 115   3  10]\n",
      " [ 33  20  14  19  14  42  68]\n",
      " [  3   1   0   1   5  22 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.53       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.80      0.81      0.81       210\n",
      "           4       0.56      0.45      0.50       210\n",
      "           5       0.46      0.55      0.50       210\n",
      "           6       0.48      0.20      0.28       210\n",
      "           7       0.63      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 63  14   3   7  72  40  11]\n",
      " [  4  95   3   8  49  43   8]\n",
      " [ 16   8  89  28  39  30   0]\n",
      " [  9  10   1  34 116  32   8]\n",
      " [  6  12   0   3 158  20  11]\n",
      " [ 11  18   3  11  22  71  74]\n",
      " [  3   4   0   0   2  22 179]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.30      0.39       210\n",
      "           2       0.59      0.45      0.51       210\n",
      "           3       0.90      0.42      0.58       210\n",
      "           4       0.37      0.16      0.23       210\n",
      "           5       0.34      0.75      0.47       210\n",
      "           6       0.28      0.34      0.30       210\n",
      "           7       0.62      0.85      0.71       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.52      0.47      0.46      1470\n",
      "weighted avg       0.52      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 54  11   2  10  68  51  14]\n",
      " [  3  71   3  12  47  62  12]\n",
      " [ 17   8  79  32  33  39   2]\n",
      " [ 10  10   1  41 105  31  12]\n",
      " [  7  12   0   8 147  25  11]\n",
      " [  9  13   3  18  17  70  80]\n",
      " [  1   5   0   0   2  22 180]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.26      0.35       210\n",
      "           2       0.55      0.34      0.42       210\n",
      "           3       0.90      0.38      0.53       210\n",
      "           4       0.34      0.20      0.25       210\n",
      "           5       0.35      0.70      0.47       210\n",
      "           6       0.23      0.33      0.27       210\n",
      "           7       0.58      0.86      0.69       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.43      1470\n",
      "weighted avg       0.50      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.638095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[147   6   7   8  25  17   0]\n",
      " [ 12 152   6  10  12  17   1]\n",
      " [  5  12 180   4   3   6   0]\n",
      " [ 19  18   5 121  27  17   3]\n",
      " [ 57  17   1  32  91   5   7]\n",
      " [ 28  25  14  15  11  87  30]\n",
      " [  6   3   1   1   6  33 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.70      0.61       210\n",
      "           2       0.65      0.72      0.69       210\n",
      "           3       0.84      0.86      0.85       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.52      0.43      0.47       210\n",
      "           6       0.48      0.41      0.44       210\n",
      "           7       0.80      0.76      0.78       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of SVM is:\n",
      " [[114   4   7   7  53  22   3]\n",
      " [  8 138   7  13  24  17   3]\n",
      " [  9   7 175   9   5   5   0]\n",
      " [ 11   9   4 112  56  13   5]\n",
      " [ 12   9   1  17 154  11   6]\n",
      " [ 18  10   9  18  13 108  34]\n",
      " [  1   0   1   0   4  34 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.54      0.60       210\n",
      "           2       0.78      0.66      0.71       210\n",
      "           3       0.86      0.83      0.85       210\n",
      "           4       0.64      0.53      0.58       210\n",
      "           5       0.50      0.73      0.59       210\n",
      "           6       0.51      0.51      0.51       210\n",
      "           7       0.77      0.81      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[116   4  10   7  45  24   4]\n",
      " [  3 150   7  12  16  19   3]\n",
      " [  2   7 183   8   2   8   0]\n",
      " [  8  13   4 120  45  15   5]\n",
      " [ 20  13   1  13 147   8   8]\n",
      " [ 15  12  11  17   9 105  41]\n",
      " [  3   0   0   2   2  23 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.55      0.62       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.85      0.87      0.86       210\n",
      "           4       0.67      0.57      0.62       210\n",
      "           5       0.55      0.70      0.62       210\n",
      "           6       0.52      0.50      0.51       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of SVM is:\n",
      " [[112   6  12  15  38  18   9]\n",
      " [  7 140   8  16  15  19   5]\n",
      " [  9  12 171   8   3   7   0]\n",
      " [ 12  11   3 114  48  12  10]\n",
      " [ 19  11   1  18 144  10   7]\n",
      " [ 17  23  14  22   8  77  49]\n",
      " [  6   1   1   8   4  36 154]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.53      0.57       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.57      0.54      0.55       210\n",
      "           5       0.55      0.69      0.61       210\n",
      "           6       0.43      0.37      0.40       210\n",
      "           7       0.66      0.73      0.69       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  22   0 188   0   0]\n",
      " [  0   0  18   0 192   0   0]\n",
      " [  0   0 115   0  95   0   0]\n",
      " [  0   0   6   0 204   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0  14   0 196   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.66      0.55      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.28       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.12      0.22      0.13      1470\n",
      "weighted avg       0.12      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29523809523809524\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   5  17   0 178   0  10]\n",
      " [  0  10   8   0 183   0   9]\n",
      " [  0  28  87   0  94   0   1]\n",
      " [  0   1   5   0 192   0  12]\n",
      " [  0   0   0   0 200   0  10]\n",
      " [  0   7   7   0 136   0  60]\n",
      " [  0   0   0   0  73   0 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.20      0.05      0.08       210\n",
      "           3       0.70      0.41      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.19      0.95      0.32       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.57      0.65      0.61       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.24      0.30      0.22      1470\n",
      "weighted avg       0.24      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  5  79  16   0  99   1  10]\n",
      " [  3 130   7   0  60   1   9]\n",
      " [ 27  48  87   0  47   0   1]\n",
      " [  1  40   5   0 152   0  12]\n",
      " [  0  32   0   0 168   0  10]\n",
      " [  6 108   7   0  29   0  60]\n",
      " [  0  60   0   0  13   0 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.12      0.02      0.04       210\n",
      "           2       0.26      0.62      0.37       210\n",
      "           3       0.71      0.41      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.30      0.80      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.57      0.65      0.61       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.28      0.36      0.28      1470\n",
      "weighted avg       0.28      0.36      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  3  44  16   6  95  37   9]\n",
      " [  0  98   7   7  55  35   8]\n",
      " [  0  29  87   7  40  46   1]\n",
      " [  0  11   5  25 131  30   8]\n",
      " [  0  13   0   9 163  19   6]\n",
      " [  1  37   7  14  25  81  45]\n",
      " [  0  18   0   6  13  45 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.01      0.03       210\n",
      "           2       0.39      0.47      0.43       210\n",
      "           3       0.71      0.41      0.52       210\n",
      "           4       0.34      0.12      0.18       210\n",
      "           5       0.31      0.78      0.45       210\n",
      "           6       0.28      0.39      0.32       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.49      0.40      0.36      1470\n",
      "weighted avg       0.49      0.40      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  19  12  10  87  25   8]\n",
      " [ 27 100   8   6  26  36   7]\n",
      " [ 17  33  90   2  25  42   1]\n",
      " [ 10  13   7  21 123  28   8]\n",
      " [  5  34   0   9 137  21   4]\n",
      " [ 21  24   8  13  21  81  42]\n",
      " [ 10   8   0   4  13  53 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.23      0.28       210\n",
      "           2       0.43      0.48      0.45       210\n",
      "           3       0.72      0.43      0.54       210\n",
      "           4       0.32      0.10      0.15       210\n",
      "           5       0.32      0.65      0.43       210\n",
      "           6       0.28      0.39      0.33       210\n",
      "           7       0.64      0.58      0.61       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.40      1470\n",
      "weighted avg       0.44      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.427891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63  37   6  22  57  21   4]\n",
      " [ 12 120   6  21  23  25   3]\n",
      " [ 17  42  91   8  14  37   1]\n",
      " [ 40  17   4  30  90  24   5]\n",
      " [ 19  24   0  14 136  17   0]\n",
      " [ 25  37   6  24  13  77  28]\n",
      " [ 15  17   0   7   4  55 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.30      0.31       210\n",
      "           2       0.41      0.57      0.48       210\n",
      "           3       0.81      0.43      0.56       210\n",
      "           4       0.24      0.14      0.18       210\n",
      "           5       0.40      0.65      0.50       210\n",
      "           6       0.30      0.37      0.33       210\n",
      "           7       0.73      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.43      1470\n",
      "weighted avg       0.46      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4272108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54  34  22  14  56  28   2]\n",
      " [ 10 117  21   8  23  24   7]\n",
      " [  6  33 114   3  12  41   1]\n",
      " [ 37  20  11  26  89  21   6]\n",
      " [ 17  30   1  10 133  18   1]\n",
      " [ 15  45  14  19  11  75  31]\n",
      " [ 10  18   5   5   4  59 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.26      0.30       210\n",
      "           2       0.39      0.56      0.46       210\n",
      "           3       0.61      0.54      0.57       210\n",
      "           4       0.31      0.12      0.18       210\n",
      "           5       0.41      0.63      0.49       210\n",
      "           6       0.28      0.36      0.32       210\n",
      "           7       0.69      0.52      0.59       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.42      1470\n",
      "weighted avg       0.44      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45034013605442175\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  26  12  30  33  25   3]\n",
      " [ 21 105  10  16  18  33   7]\n",
      " [ 19  30 110   8   1  39   3]\n",
      " [ 38  13   8  77  42  25   7]\n",
      " [ 26  25   1  39 101  11   7]\n",
      " [ 21  33  11  24  10  64  47]\n",
      " [ 14  12   0   1   9  50 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.39      0.38       210\n",
      "           2       0.43      0.50      0.46       210\n",
      "           3       0.72      0.52      0.61       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.47      0.48      0.48       210\n",
      "           6       0.26      0.30      0.28       210\n",
      "           7       0.63      0.59      0.61       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.47      0.45      0.46      1470\n",
      "weighted avg       0.47      0.45      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  24  18  21  44  24   7]\n",
      " [ 15 107  10  13  20  37   8]\n",
      " [ 15  27 116   4   6  41   1]\n",
      " [ 35  15   6  59  62  21  12]\n",
      " [ 25  23   5  19 115  13  10]\n",
      " [ 23  26  15  16  13  65  52]\n",
      " [ 14   8   0   2   6  44 136]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.34      0.35       210\n",
      "           2       0.47      0.51      0.49       210\n",
      "           3       0.68      0.55      0.61       210\n",
      "           4       0.44      0.28      0.34       210\n",
      "           5       0.43      0.55      0.48       210\n",
      "           6       0.27      0.31      0.29       210\n",
      "           7       0.60      0.65      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  32  14  24  38  21   8]\n",
      " [ 20 102  10  18  20  30  10]\n",
      " [ 13  28 119   5   5  40   0]\n",
      " [ 37  21   4  73  44  25   6]\n",
      " [ 22  34   4  28  98  15   9]\n",
      " [ 31  26  16  24  12  58  43]\n",
      " [ 11  12   0   3  10  50 124]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.35      0.35       210\n",
      "           2       0.40      0.49      0.44       210\n",
      "           3       0.71      0.57      0.63       210\n",
      "           4       0.42      0.35      0.38       210\n",
      "           5       0.43      0.47      0.45       210\n",
      "           6       0.24      0.28      0.26       210\n",
      "           7       0.62      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  20  20  28  37  22  12]\n",
      " [ 18 103  15  18  18  31   7]\n",
      " [ 16  22 116  10  10  36   0]\n",
      " [ 26  18   8  73  58  19   8]\n",
      " [ 28  26   4  34  96  13   9]\n",
      " [ 30  21  13  34  15  56  41]\n",
      " [ 11  13   0   3   9  47 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.35       210\n",
      "           2       0.46      0.49      0.48       210\n",
      "           3       0.66      0.55      0.60       210\n",
      "           4       0.36      0.35      0.36       210\n",
      "           5       0.40      0.46      0.42       210\n",
      "           6       0.25      0.27      0.26       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.44      1470\n",
      "weighted avg       0.44      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  20  18  29  37  19  11]\n",
      " [ 26  93  15  12  30  27   7]\n",
      " [ 15  22 117  10   6  40   0]\n",
      " [ 22  19   8  63  71  20   7]\n",
      " [ 35  27   5  22 100  10  11]\n",
      " [ 31  22  17  24  20  53  43]\n",
      " [ 16  12   0   7   8  51 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.36      0.35       210\n",
      "           2       0.43      0.44      0.44       210\n",
      "           3       0.65      0.56      0.60       210\n",
      "           4       0.38      0.30      0.33       210\n",
      "           5       0.37      0.48      0.41       210\n",
      "           6       0.24      0.25      0.25       210\n",
      "           7       0.59      0.55      0.57       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  23  23  30  35  26   6]\n",
      " [ 22  96  15  18  21  32   6]\n",
      " [ 12  23 124   6   5  40   0]\n",
      " [ 36  19   7  59  55  26   8]\n",
      " [ 35  29   6  21  91  17  11]\n",
      " [ 29  16  20  28  15  59  43]\n",
      " [ 12  10   0   3  12  50 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.32      0.32       210\n",
      "           2       0.44      0.46      0.45       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.36      0.28      0.31       210\n",
      "           5       0.39      0.43      0.41       210\n",
      "           6       0.24      0.28      0.26       210\n",
      "           7       0.62      0.59      0.60       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  22  21  25  37  23   7]\n",
      " [ 20  95  15  16  27  28   9]\n",
      " [ 13  13 128   7  10  38   1]\n",
      " [ 32  20  12  66  45  28   7]\n",
      " [ 37  26   4  25  85  22  11]\n",
      " [ 34  15  16  29  22  53  41]\n",
      " [ 15  11   1   7  10  49 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.36      0.34       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.65      0.61      0.63       210\n",
      "           4       0.38      0.31      0.34       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.22      0.25      0.24       210\n",
      "           7       0.61      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.427891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  20  19  27  35  19  11]\n",
      " [ 18  95  17  21  25  26   8]\n",
      " [ 11  21 125   5  10  38   0]\n",
      " [ 24  15   9  64  62  26  10]\n",
      " [ 30  26   5  22  94  22  11]\n",
      " [ 32  19  15  25  19  53  47]\n",
      " [  9   9   1   4  11  57 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.38      0.38       210\n",
      "           2       0.46      0.45      0.46       210\n",
      "           3       0.65      0.60      0.62       210\n",
      "           4       0.38      0.30      0.34       210\n",
      "           5       0.37      0.45      0.40       210\n",
      "           6       0.22      0.25      0.24       210\n",
      "           7       0.58      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4231292517006803\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  16  18  31  44  23  10]\n",
      " [ 24  94  14  16  29  28   5]\n",
      " [ 13  20 124   8   8  37   0]\n",
      " [ 20  18   7  67  64  24  10]\n",
      " [ 30  29   6  25  95  15  10]\n",
      " [ 27  14  18  28  23  52  48]\n",
      " [ 10  11   0   5  15  47 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.32      0.34       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.66      0.59      0.62       210\n",
      "           4       0.37      0.32      0.34       210\n",
      "           5       0.34      0.45      0.39       210\n",
      "           6       0.23      0.25      0.24       210\n",
      "           7       0.60      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.43      1470\n",
      "weighted avg       0.43      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42857142857142855\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  17  19  30  31  31   8]\n",
      " [ 25  95  12  17  27  26   8]\n",
      " [ 11  20 126   8   8  37   0]\n",
      " [ 27  20  10  69  53  24   7]\n",
      " [ 37  27   4  21  92  16  13]\n",
      " [ 35  18  16  28  21  53  39]\n",
      " [  9   7   6   6  13  48 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.35       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.65      0.60      0.63       210\n",
      "           4       0.39      0.33      0.35       210\n",
      "           5       0.38      0.44      0.40       210\n",
      "           6       0.23      0.25      0.24       210\n",
      "           7       0.62      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.427891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  19  21  28  36  22   7]\n",
      " [ 22  88  18  15  30  31   6]\n",
      " [ 12  17 125   9  10  37   0]\n",
      " [ 29  17   9  70  50  27   8]\n",
      " [ 31  29   4  25  90  18  13]\n",
      " [ 33  20  14  29  20  53  41]\n",
      " [ 11   8   0   3  11  51 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.37      0.36       210\n",
      "           2       0.44      0.42      0.43       210\n",
      "           3       0.65      0.60      0.62       210\n",
      "           4       0.39      0.33      0.36       210\n",
      "           5       0.36      0.43      0.39       210\n",
      "           6       0.22      0.25      0.24       210\n",
      "           7       0.63      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  20  21  33  27  17  12]\n",
      " [ 24  86  16  15  33  28   8]\n",
      " [ 13  14 127   9  11  36   0]\n",
      " [ 25  17   6  69  58  23  12]\n",
      " [ 33  31   3  27  85  21  10]\n",
      " [ 34  23  14  22  20  55  42]\n",
      " [  9  13   1   3  11  51 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.38      0.37       210\n",
      "           2       0.42      0.41      0.42       210\n",
      "           3       0.68      0.60      0.64       210\n",
      "           4       0.39      0.33      0.36       210\n",
      "           5       0.35      0.40      0.37       210\n",
      "           6       0.24      0.26      0.25       210\n",
      "           7       0.59      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.43      1470\n",
      "weighted avg       0.43      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.42653061224489797\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  17  20  29  32  18  13]\n",
      " [ 24  83  16  16  36  27   8]\n",
      " [ 14  15 128   7  10  36   0]\n",
      " [ 23  18   9  69  57  23  11]\n",
      " [ 31  28   4  25  87  24  11]\n",
      " [ 30  21  14  23  22  58  42]\n",
      " [ 10  11   0   5  10  53 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.39      0.38       210\n",
      "           2       0.43      0.40      0.41       210\n",
      "           3       0.67      0.61      0.64       210\n",
      "           4       0.40      0.33      0.36       210\n",
      "           5       0.34      0.41      0.38       210\n",
      "           6       0.24      0.28      0.26       210\n",
      "           7       0.59      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  18  20  32  25  20  15]\n",
      " [ 22  86  16  15  34  30   7]\n",
      " [ 15  18 129   7   5  36   0]\n",
      " [ 27  18   8  66  53  25  13]\n",
      " [ 35  24   7  23  87  23  11]\n",
      " [ 28  24  16  27  19  56  40]\n",
      " [ 12  13   0   5  10  48 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.38      0.37       210\n",
      "           2       0.43      0.41      0.42       210\n",
      "           3       0.66      0.61      0.64       210\n",
      "           4       0.38      0.31      0.34       210\n",
      "           5       0.37      0.41      0.39       210\n",
      "           6       0.24      0.27      0.25       210\n",
      "           7       0.59      0.58      0.58       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.43      1470\n",
      "weighted avg       0.43      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.36462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  7   4  33   0  98   0  68]\n",
      " [  0  14  24   0  85   1  86]\n",
      " [  1   0 140   0  34   1  34]\n",
      " [  0   5   9   4 149   0  43]\n",
      " [  1   5   3   0 167   1  33]\n",
      " [  1   2  14   0  37   2 154]\n",
      " [  0   2   0   0   5   1 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.03      0.06       210\n",
      "           2       0.44      0.07      0.12       210\n",
      "           3       0.63      0.67      0.65       210\n",
      "           4       1.00      0.02      0.04       210\n",
      "           5       0.29      0.80      0.43       210\n",
      "           6       0.33      0.01      0.02       210\n",
      "           7       0.33      0.96      0.49       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.53      0.36      0.26      1470\n",
      "weighted avg       0.53      0.36      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41496598639455784\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  6  15  55   0  89  13  32]\n",
      " [  0  68  20   1  74  15  32]\n",
      " [  2   3 150   0  35   8  12]\n",
      " [  2   8  12   7 145   8  28]\n",
      " [  0  10   2   1 166   4  27]\n",
      " [  0  14  27   0  33  17 119]\n",
      " [  1   6   0   0   4   3 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.03      0.05       210\n",
      "           2       0.55      0.32      0.41       210\n",
      "           3       0.56      0.71      0.63       210\n",
      "           4       0.78      0.03      0.06       210\n",
      "           5       0.30      0.79      0.44       210\n",
      "           6       0.25      0.08      0.12       210\n",
      "           7       0.44      0.93      0.60       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.49      0.41      0.33      1470\n",
      "weighted avg       0.49      0.41      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5006802721088436\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 49  28  17   7  74  17  18]\n",
      " [  2 124   8   2  47  11  16]\n",
      " [  3  19 140   9  21  13   5]\n",
      " [  5  20   4  47 105  10  19]\n",
      " [  0  23   0   3 156   9  19]\n",
      " [  5  35  15   8  23  30  94]\n",
      " [  1   8   0   0   2   9 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.23      0.36       210\n",
      "           2       0.48      0.59      0.53       210\n",
      "           3       0.76      0.67      0.71       210\n",
      "           4       0.62      0.22      0.33       210\n",
      "           5       0.36      0.74      0.49       210\n",
      "           6       0.30      0.14      0.19       210\n",
      "           7       0.53      0.90      0.67       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.47      1470\n",
      "weighted avg       0.54      0.50      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 74  23   7  19  58  13  16]\n",
      " [  1 129   8   8  36  15  13]\n",
      " [  7  18 146  14  10  13   2]\n",
      " [  6  19   3  81  71  12  18]\n",
      " [  3  22   0  12 145  10  18]\n",
      " [ 13  32   9  17  13  36  90]\n",
      " [  1   7   0   0   2  12 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.35      0.47       210\n",
      "           2       0.52      0.61      0.56       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.54      0.39      0.45       210\n",
      "           5       0.43      0.69      0.53       210\n",
      "           6       0.32      0.17      0.22       210\n",
      "           7       0.54      0.90      0.68       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.53      1470\n",
      "weighted avg       0.56      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79  23   7  22  45  21  13]\n",
      " [  2 135   8   9  29  16  11]\n",
      " [  7  21 147  14   5  15   1]\n",
      " [  7  18   2  90  60  21  12]\n",
      " [  5  20   0  14 142  14  15]\n",
      " [ 11  24   9  16  15  53  82]\n",
      " [  0   7   0   1   3  13 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.38      0.49       210\n",
      "           2       0.54      0.64      0.59       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.54      0.43      0.48       210\n",
      "           5       0.47      0.68      0.56       210\n",
      "           6       0.35      0.25      0.29       210\n",
      "           7       0.58      0.89      0.70       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.55      1470\n",
      "weighted avg       0.58      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  17   6  19  43  22  11]\n",
      " [  5 133   6  11  24  23   8]\n",
      " [  9  14 153  12   7  15   0]\n",
      " [  8  17   1  88  64  19  13]\n",
      " [  7  19   0  15 141  15  13]\n",
      " [ 11  25  11  16  11  55  81]\n",
      " [  1   5   0   0   3  15 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.44      0.54       210\n",
      "           2       0.58      0.63      0.60       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.55      0.42      0.47       210\n",
      "           5       0.48      0.67      0.56       210\n",
      "           6       0.34      0.26      0.29       210\n",
      "           7       0.60      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  16   5  21  42  24   9]\n",
      " [  1 132   9   9  25  23  11]\n",
      " [  9  16 154  11   6  14   0]\n",
      " [ 10  14   1  98  52  25  10]\n",
      " [  6  18   0  16 141  18  11]\n",
      " [ 12  22   9  13  14  66  74]\n",
      " [  0   4   1   0   3  18 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.44      0.55       210\n",
      "           2       0.59      0.63      0.61       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.58      0.47      0.52       210\n",
      "           5       0.50      0.67      0.57       210\n",
      "           6       0.35      0.31      0.33       210\n",
      "           7       0.62      0.88      0.72       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   9   3  18  43  27   9]\n",
      " [  2 140   7   7  22  23   9]\n",
      " [ 26  11 131  12   4  25   1]\n",
      " [ 11  15   1  92  59  21  11]\n",
      " [  9  11   2  15 142  20  11]\n",
      " [ 15  18   4  13  13  72  75]\n",
      " [  1   4   0   0   3  21 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.48      0.54       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.89      0.62      0.73       210\n",
      "           4       0.59      0.44      0.50       210\n",
      "           5       0.50      0.68      0.57       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.61      0.86      0.71       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  14   3  17  41  19  12]\n",
      " [  2 136   7  10  26  21   8]\n",
      " [ 36  11 138  10   5  10   0]\n",
      " [  7  12   3 100  55  23  10]\n",
      " [  6  16   1  14 142  18  13]\n",
      " [ 18  20   5  13  13  77  64]\n",
      " [  2   2   0   0   3  24 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.50      0.54       210\n",
      "           2       0.64      0.65      0.65       210\n",
      "           3       0.88      0.66      0.75       210\n",
      "           4       0.61      0.48      0.53       210\n",
      "           5       0.50      0.68      0.57       210\n",
      "           6       0.40      0.37      0.38       210\n",
      "           7       0.63      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99  14   5  18  42  25   7]\n",
      " [  3 132   7   9  25  23  11]\n",
      " [  6  10 138  13   4  38   1]\n",
      " [ 10  13   1  99  53  25   9]\n",
      " [ 14  15   1  19 135  12  14]\n",
      " [ 14  17   7  15  13  80  64]\n",
      " [  1   4   1   0   3  20 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.47      0.55       210\n",
      "           2       0.64      0.63      0.64       210\n",
      "           3       0.86      0.66      0.75       210\n",
      "           4       0.57      0.47      0.52       210\n",
      "           5       0.49      0.64      0.56       210\n",
      "           6       0.36      0.38      0.37       210\n",
      "           7       0.63      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.59      1470\n",
      "weighted avg       0.60      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  12   4  15  43  28   7]\n",
      " [  6 138   7  10  18  22   9]\n",
      " [ 23   9 151  10   5  12   0]\n",
      " [  4  12   3 101  56  26   8]\n",
      " [ 14  16   1  17 138  14  10]\n",
      " [ 10  21   7  13  13  79  67]\n",
      " [  1   2   1   0   3  20 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.48      0.55       210\n",
      "           2       0.66      0.66      0.66       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.61      0.48      0.54       210\n",
      "           5       0.50      0.66      0.57       210\n",
      "           6       0.39      0.38      0.38       210\n",
      "           7       0.64      0.87      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  13   7  16  39  26   8]\n",
      " [  4 134   7  10  20  27   8]\n",
      " [  7  11 166   7   5  14   0]\n",
      " [ 10  15   2 101  52  22   8]\n",
      " [ 12  15   1  18 136  13  15]\n",
      " [ 15  17  11  13  11  77  66]\n",
      " [  1   2   1   1   4  20 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.48      0.56       210\n",
      "           2       0.65      0.64      0.64       210\n",
      "           3       0.85      0.79      0.82       210\n",
      "           4       0.61      0.48      0.54       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.63      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  16   8  14  40  22   7]\n",
      " [  6 139   8   9  20  22   6]\n",
      " [  5  11 168   8   4  14   0]\n",
      " [  9  15   4 105  46  20  11]\n",
      " [ 10  17   0  18 139  17   9]\n",
      " [ 14  18  10  14  11  77  66]\n",
      " [  2   3   1   1   3  19 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.49      0.57       210\n",
      "           2       0.63      0.66      0.65       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.62      0.50      0.55       210\n",
      "           5       0.53      0.66      0.59       210\n",
      "           6       0.40      0.37      0.38       210\n",
      "           7       0.65      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100  17   7  14  41  23   8]\n",
      " [  3 141   7  10  20  23   6]\n",
      " [  8   9 169  11   2  11   0]\n",
      " [ 13  15   5  98  50  21   8]\n",
      " [ 15  16   2  15 139  11  12]\n",
      " [ 18  15  11  12  10  76  68]\n",
      " [  5   2   0   1   3  21 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.66      0.67      0.66       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.61      0.47      0.53       210\n",
      "           5       0.52      0.66      0.59       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.64      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.61      1470\n",
      "weighted avg       0.61      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  14   4  15  42  23   8]\n",
      " [  5 132   6  13  24  24   6]\n",
      " [  9   9 167   9   5  11   0]\n",
      " [ 14   9   4 104  45  26   8]\n",
      " [ 18  12   1  20 134  16   9]\n",
      " [ 12  14  10  17  12  79  66]\n",
      " [  2   2   1   1   3  25 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.50      0.56       210\n",
      "           2       0.69      0.63      0.66       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.58      0.50      0.53       210\n",
      "           5       0.51      0.64      0.56       210\n",
      "           6       0.39      0.38      0.38       210\n",
      "           7       0.64      0.84      0.73       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  12   5  14  43  22  11]\n",
      " [  5 135   6   9  21  28   6]\n",
      " [  6   6 152  13   4  29   0]\n",
      " [ 12  15   2  98  49  24  10]\n",
      " [ 21  14   1  17 133  14  10]\n",
      " [ 13  19   7  12  12  89  58]\n",
      " [  4   3   0   2   1  21 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.49      0.55       210\n",
      "           2       0.66      0.64      0.65       210\n",
      "           3       0.88      0.72      0.79       210\n",
      "           4       0.59      0.47      0.52       210\n",
      "           5       0.51      0.63      0.56       210\n",
      "           6       0.39      0.42      0.41       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108  13   3  13  42  25   6]\n",
      " [  5 140   9   9  18  24   5]\n",
      " [ 18   8 157   9   6  12   0]\n",
      " [ 10  16   5  95  52  22  10]\n",
      " [ 15  15   0  20 137  13  10]\n",
      " [ 16  15   7  14  12  84  62]\n",
      " [  1   1   1   1   3  18 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.51      0.56       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.59      0.45      0.51       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  12   5  15  45  20  10]\n",
      " [  4 141   5  12  18  22   8]\n",
      " [  6   9 143   9   6  37   0]\n",
      " [ 14  17   2  99  43  28   7]\n",
      " [ 12  13   1  21 141  12  10]\n",
      " [ 18  16   6  12  14  82  62]\n",
      " [  1   3   1   1   4  23 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.49      0.56       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.88      0.68      0.77       210\n",
      "           4       0.59      0.47      0.52       210\n",
      "           5       0.52      0.67      0.59       210\n",
      "           6       0.37      0.39      0.38       210\n",
      "           7       0.65      0.84      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.60      1470\n",
      "weighted avg       0.62      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  14   5  14  43  25   8]\n",
      " [  6 135   7   9  21  25   7]\n",
      " [  8  11 153  10   2  26   0]\n",
      " [ 10  12   3 103  48  27   7]\n",
      " [ 12  14   1  22 138  11  12]\n",
      " [ 17  15   7  12  11  90  58]\n",
      " [  3   2   1   2   2  23 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.48      0.55       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.52      0.66      0.58       210\n",
      "           6       0.40      0.43      0.41       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.61      1470\n",
      "weighted avg       0.62      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111  12   6  15  37  22   7]\n",
      " [  5 137   6  10  20  25   7]\n",
      " [ 37  10 140   9   4  10   0]\n",
      " [  8  20   4  96  48  28   6]\n",
      " [ 16  14   1  21 135  14   9]\n",
      " [ 20  19   5  12  11  83  60]\n",
      " [  2   4   1   0   4  21 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.53      0.54       210\n",
      "           2       0.63      0.65      0.64       210\n",
      "           3       0.86      0.67      0.75       210\n",
      "           4       0.59      0.46      0.51       210\n",
      "           5       0.52      0.64      0.58       210\n",
      "           6       0.41      0.40      0.40       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102  16   4  17  41  24   6]\n",
      " [  5 139   5  12  18  26   5]\n",
      " [ 21  11 142  10   4  22   0]\n",
      " [ 12  15   2 102  47  23   9]\n",
      " [ 16  17   1  19 136  10  11]\n",
      " [ 18  20   5   9  12  90  56]\n",
      " [  4   3   1   0   2  20 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.49      0.53       210\n",
      "           2       0.63      0.66      0.65       210\n",
      "           3       0.89      0.68      0.77       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.52      0.65      0.58       210\n",
      "           6       0.42      0.43      0.42       210\n",
      "           7       0.67      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.42517006802721086\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 52  12   3  13  66  49  15]\n",
      " [  4  77   6   8  52  48  15]\n",
      " [ 15   8  68  43  46  28   2]\n",
      " [  9  10   2  40 109  27  13]\n",
      " [  9  13   0   8 148  21  11]\n",
      " [  9  18   3  17  19  65  79]\n",
      " [  1   5   0   0   2  27 175]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.25      0.34       210\n",
      "           2       0.54      0.37      0.44       210\n",
      "           3       0.83      0.32      0.47       210\n",
      "           4       0.31      0.19      0.24       210\n",
      "           5       0.33      0.70      0.45       210\n",
      "           6       0.25      0.31      0.27       210\n",
      "           7       0.56      0.83      0.67       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.48      0.43      0.41      1470\n",
      "weighted avg       0.48      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[145   4   1   8  35  15   2]\n",
      " [  6 152   1  13  21  15   2]\n",
      " [  1   6 190   1   4   8   0]\n",
      " [  6  16   3 141  21  19   4]\n",
      " [ 24   8   1  30 137   4   6]\n",
      " [ 13  14   5  23   9 115  31]\n",
      " [  6   2   0   2   4  31 165]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.69      0.71       210\n",
      "           2       0.75      0.72      0.74       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.56      0.55      0.55       210\n",
      "           7       0.79      0.79      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5904761904761905\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   9   9   4  34   3   5]\n",
      " [ 16 144  10  14  22   0   4]\n",
      " [  5  17 179   1   5   3   0]\n",
      " [ 27  37  10  89  38   6   3]\n",
      " [ 61  18   6  16  99   5   5]\n",
      " [ 43  29   6  32  17  52  31]\n",
      " [ 23   5   0   5   8  10 159]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.70      0.55       210\n",
      "           2       0.56      0.69      0.61       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.55      0.42      0.48       210\n",
      "           5       0.44      0.47      0.46       210\n",
      "           6       0.66      0.25      0.36       210\n",
      "           7       0.77      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.58      1470\n",
      "weighted avg       0.61      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5945578231292517\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   7   9   9  33   5   5]\n",
      " [ 16 143  12  14  18   3   4]\n",
      " [  3  21 176   3   4   3   0]\n",
      " [ 21  28  11  91  43  13   3]\n",
      " [ 52  16   7  23  99   5   8]\n",
      " [ 38  24   8  27  15  59  39]\n",
      " [ 19   1   0   1  10  15 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.68      0.57       210\n",
      "           2       0.60      0.68      0.64       210\n",
      "           3       0.79      0.84      0.81       210\n",
      "           4       0.54      0.43      0.48       210\n",
      "           5       0.45      0.47      0.46       210\n",
      "           6       0.57      0.28      0.38       210\n",
      "           7       0.74      0.78      0.76       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   5   8  13  39   6   4]\n",
      " [ 13 144  14  12  19   3   5]\n",
      " [  5  18 180   1   4   2   0]\n",
      " [ 20  31  10  93  44   8   4]\n",
      " [ 48  20   6  22 102   5   7]\n",
      " [ 31  26   7  36  21  46  43]\n",
      " [ 10   0   0   3  12  14 171]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.64      0.57       210\n",
      "           2       0.59      0.69      0.63       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.52      0.44      0.48       210\n",
      "           5       0.42      0.49      0.45       210\n",
      "           6       0.55      0.22      0.31       210\n",
      "           7       0.73      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   5   8  10  44   3   5]\n",
      " [ 13 142  14  13  21   2   5]\n",
      " [  4  18 180   2   4   2   0]\n",
      " [ 17  26  12 102  44   6   3]\n",
      " [ 48  18   5  23 107   3   6]\n",
      " [ 34  32   9  39  14  38  44]\n",
      " [  9   1   0   1  10  14 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.64      0.57       210\n",
      "           2       0.59      0.68      0.63       210\n",
      "           3       0.79      0.86      0.82       210\n",
      "           4       0.54      0.49      0.51       210\n",
      "           5       0.44      0.51      0.47       210\n",
      "           6       0.56      0.18      0.27       210\n",
      "           7       0.74      0.83      0.78       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.59      0.60      0.58      1470\n",
      "weighted avg       0.59      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   9   9   8  42   2   4]\n",
      " [ 10 146  14  11  22   1   6]\n",
      " [  3  16 182   3   5   1   0]\n",
      " [ 14  22  13 104  45   7   5]\n",
      " [ 45  17   5  24 112   2   5]\n",
      " [ 35  34   7  33  17  43  41]\n",
      " [ 12   1   0   1   9  12 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.65      0.58       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.44      0.53      0.48       210\n",
      "           6       0.63      0.20      0.31       210\n",
      "           7       0.74      0.83      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.59      1470\n",
      "weighted avg       0.61      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.608843537414966\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   9  10   8  39   4   3]\n",
      " [  9 141  14  14  25   2   5]\n",
      " [  5  15 180   4   4   2   0]\n",
      " [ 14  21  15 103  49   4   4]\n",
      " [ 39  18   5  23 116   2   7]\n",
      " [ 38  29   9  33  16  42  43]\n",
      " [ 13   2   0   2   8   9 176]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.65      0.59       210\n",
      "           2       0.60      0.67      0.63       210\n",
      "           3       0.77      0.86      0.81       210\n",
      "           4       0.55      0.49      0.52       210\n",
      "           5       0.45      0.55      0.50       210\n",
      "           6       0.65      0.20      0.31       210\n",
      "           7       0.74      0.84      0.79       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.59      1470\n",
      "weighted avg       0.61      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5428571428571428\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[106  11  14   4  36   9  30]\n",
      " [  0 138  17   9  18  15  13]\n",
      " [  1  35 162   8   1   2   1]\n",
      " [  3  20  10  83  34  14  46]\n",
      " [ 14  23   1  15 113   3  41]\n",
      " [  8  38   8  21  16  38  81]\n",
      " [  0  12   0   7   7  26 158]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.50      0.62       210\n",
      "           2       0.50      0.66      0.57       210\n",
      "           3       0.76      0.77      0.77       210\n",
      "           4       0.56      0.40      0.46       210\n",
      "           5       0.50      0.54      0.52       210\n",
      "           6       0.36      0.18      0.24       210\n",
      "           7       0.43      0.75      0.54       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.53      1470\n",
      "weighted avg       0.56      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[111   5  18   8  26  12  30]\n",
      " [  0 122  24  18  16  16  14]\n",
      " [  1  16 167  22   1   2   1]\n",
      " [  3  16  15  81  33  16  46]\n",
      " [ 18  21   1  14 108   8  40]\n",
      " [  6  43  11  22  17  32  79]\n",
      " [  1  28   0  17   7  13 144]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.53      0.63       210\n",
      "           2       0.49      0.58      0.53       210\n",
      "           3       0.71      0.80      0.75       210\n",
      "           4       0.45      0.39      0.41       210\n",
      "           5       0.52      0.51      0.52       210\n",
      "           6       0.32      0.15      0.21       210\n",
      "           7       0.41      0.69      0.51       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.53      0.52      0.51      1470\n",
      "weighted avg       0.53      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.7061224489795919\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   1   1   6  27  12   2]\n",
      " [  4 159   6  11  17  11   2]\n",
      " [  0   9 191   3   3   4   0]\n",
      " [ 11  20   8 126  29  13   3]\n",
      " [ 33  20   2  23 125   2   5]\n",
      " [ 15  15   9  22   6 112  31]\n",
      " [  5   1   0   3   4  33 164]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73       210\n",
      "           2       0.71      0.76      0.73       210\n",
      "           3       0.88      0.91      0.89       210\n",
      "           4       0.65      0.60      0.62       210\n",
      "           5       0.59      0.60      0.59       210\n",
      "           6       0.60      0.53      0.56       210\n",
      "           7       0.79      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.70      0.71      0.70      1470\n",
      "weighted avg       0.70      0.71      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of SVM is:\n",
      " [[115   2   5  10  56  18   4]\n",
      " [  3 133   2  21  23  26   2]\n",
      " [  1  10 178   8   3  10   0]\n",
      " [  1   8   2 140  31  23   5]\n",
      " [  4   6   0  31 157   7   5]\n",
      " [  3   4   4  26  16 123  34]\n",
      " [  0   0   0   3   3  28 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.55      0.68       210\n",
      "           2       0.82      0.63      0.71       210\n",
      "           3       0.93      0.85      0.89       210\n",
      "           4       0.59      0.67      0.62       210\n",
      "           5       0.54      0.75      0.63       210\n",
      "           6       0.52      0.59      0.55       210\n",
      "           7       0.78      0.84      0.81       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.746938775510204\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   5   2   3  29  15   3]\n",
      " [  3 151   6  15  13  20   2]\n",
      " [  1  10 193   2   1   3   0]\n",
      " [  1  15   4 139  23  23   5]\n",
      " [ 20  16   0  21 142   5   6]\n",
      " [  3   7   2  19   8 132  39]\n",
      " [  0   0   0   2   1  19 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.73      0.78       210\n",
      "           2       0.74      0.72      0.73       210\n",
      "           3       0.93      0.92      0.93       210\n",
      "           4       0.69      0.66      0.68       210\n",
      "           5       0.65      0.68      0.67       210\n",
      "           6       0.61      0.63      0.62       210\n",
      "           7       0.77      0.90      0.83       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.75      0.75      0.75      1470\n",
      "weighted avg       0.75      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7095238095238096\n",
      "Confusion Matrix of SVM is:\n",
      " [[146   4   2   6  29  19   4]\n",
      " [  3 147   9  22   7  20   2]\n",
      " [  0   6 186  15   1   2   0]\n",
      " [  3  18  22 128  19  15   5]\n",
      " [ 22  20   4  22 131   5   6]\n",
      " [  6  10   6  19  10 120  39]\n",
      " [  1   1   0   3   2  18 185]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.70      0.75       210\n",
      "           2       0.71      0.70      0.71       210\n",
      "           3       0.81      0.89      0.85       210\n",
      "           4       0.60      0.61      0.60       210\n",
      "           5       0.66      0.62      0.64       210\n",
      "           6       0.60      0.57      0.59       210\n",
      "           7       0.77      0.88      0.82       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.24965986394557824\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  46   0   0   0 164]\n",
      " [  0   0  56   0   0   0 154]\n",
      " [  0   0 157   0   0   0  53]\n",
      " [  0   0  10   0   0   0 200]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0  23   0   0   0 187]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.53      0.75      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.10      0.25      0.13      1470\n",
      "weighted avg       0.10      0.25      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0  32  14   0 131   0  33]\n",
      " [  0  38  18   0  80   0  74]\n",
      " [  0  19 138   0  48   0   5]\n",
      " [  0   5   5   0 142   0  58]\n",
      " [  0   3   0   0 153   0  54]\n",
      " [  0  12  11   0  82   0 105]\n",
      " [  0   0   0   0  30   0 180]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.35      0.18      0.24       210\n",
      "           3       0.74      0.66      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.73      0.35       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.35      0.86      0.50       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.24      0.35      0.26      1470\n",
      "weighted avg       0.24      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3816326530612245\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  17   5  53   0  16  17]\n",
      " [ 11  41  11  73   0  58  16]\n",
      " [ 15  26 126  38   0   3   2]\n",
      " [ 31   5   4 112   0  41  17]\n",
      " [ 71   2   0  83   0  30  24]\n",
      " [ 26  11   8  60   0  45  60]\n",
      " [ 13   0   0  17   0  45 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.49      0.43       210\n",
      "           2       0.40      0.20      0.26       210\n",
      "           3       0.82      0.60      0.69       210\n",
      "           4       0.26      0.53      0.35       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.19      0.21      0.20       210\n",
      "           7       0.50      0.64      0.56       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.36      0.38      0.36      1470\n",
      "weighted avg       0.36      0.38      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  46   6  15  35  33   2]\n",
      " [  3  97  13  27   6  56   8]\n",
      " [  5  39 137  15   9   4   1]\n",
      " [ 13  41   4  78  18  55   1]\n",
      " [ 13  59   0  28  57  45   8]\n",
      " [  2  30  10  39  21  83  25]\n",
      " [  0  16   0   4  13  90  87]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.35      0.46       210\n",
      "           2       0.30      0.46      0.36       210\n",
      "           3       0.81      0.65      0.72       210\n",
      "           4       0.38      0.37      0.37       210\n",
      "           5       0.36      0.27      0.31       210\n",
      "           6       0.23      0.40      0.29       210\n",
      "           7       0.66      0.41      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.43      1470\n",
      "weighted avg       0.48      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39183673469387753\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[69 27  9 20 54 28  3]\n",
      " [ 3 70 15 33 27 54  8]\n",
      " [ 2 27 82 22 12 65  0]\n",
      " [10 21  4 82 40 47  6]\n",
      " [ 7 23  1 34 98 36 11]\n",
      " [ 2 15  6 45 34 76 32]\n",
      " [ 0  3  0 10 26 72 99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.33      0.46       210\n",
      "           2       0.38      0.33      0.35       210\n",
      "           3       0.70      0.39      0.50       210\n",
      "           4       0.33      0.39      0.36       210\n",
      "           5       0.34      0.47      0.39       210\n",
      "           6       0.20      0.36      0.26       210\n",
      "           7       0.62      0.47      0.54       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.47      0.39      0.41      1470\n",
      "weighted avg       0.47      0.39      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  10   8  27  30  24  12]\n",
      " [  5  83  13  30  17  41  21]\n",
      " [  6  33  79  20   7  63   2]\n",
      " [ 13  20   4  92  23  41  17]\n",
      " [ 22  26   0  35  82  28  17]\n",
      " [  5  19   5  48  17  68  48]\n",
      " [  3   2   0  20   1  45 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.47      0.55       210\n",
      "           2       0.43      0.40      0.41       210\n",
      "           3       0.72      0.38      0.50       210\n",
      "           4       0.34      0.44      0.38       210\n",
      "           5       0.46      0.39      0.42       210\n",
      "           6       0.22      0.32      0.26       210\n",
      "           7       0.54      0.66      0.60       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.45      1470\n",
      "weighted avg       0.48      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4387755102040816\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8  16  21  38  24   3]\n",
      " [  6  88  26  27  27  26  10]\n",
      " [  9  15  96  14  10  65   1]\n",
      " [ 13  18  17  80  43  34   5]\n",
      " [ 29  29   6  28  91  18   9]\n",
      " [ 19  24  13  29  19  71  35]\n",
      " [  7  10   0  11  12  51 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.48      0.51       210\n",
      "           2       0.46      0.42      0.44       210\n",
      "           3       0.55      0.46      0.50       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.38      0.43      0.40       210\n",
      "           6       0.25      0.34      0.28       210\n",
      "           7       0.65      0.57      0.61       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.45      1470\n",
      "weighted avg       0.46      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92  11  14  28  34  28   3]\n",
      " [  8  92  18  41  12  31   8]\n",
      " [  8  16  86  26   8  64   2]\n",
      " [ 17  21  11 100  24  31   6]\n",
      " [ 23  29   2  47  77  24   8]\n",
      " [ 26  25   8  36  19  66  30]\n",
      " [  7   4   0  13   7  71 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.44      0.47       210\n",
      "           2       0.46      0.44      0.45       210\n",
      "           3       0.62      0.41      0.49       210\n",
      "           4       0.34      0.48      0.40       210\n",
      "           5       0.43      0.37      0.39       210\n",
      "           6       0.21      0.31      0.25       210\n",
      "           7       0.65      0.51      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.46      0.42      0.43      1470\n",
      "weighted avg       0.46      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  14  15  26  30  21   9]\n",
      " [ 10 101  16  30   9  32  12]\n",
      " [  7  13  93  20   8  67   2]\n",
      " [ 16  26   8  93  25  30  12]\n",
      " [ 29  32   2  43  79  14  11]\n",
      " [ 21  23  10  38  20  58  40]\n",
      " [  7   4   0  11  10  49 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.45      0.48       210\n",
      "           2       0.47      0.48      0.48       210\n",
      "           3       0.65      0.44      0.53       210\n",
      "           4       0.36      0.44      0.39       210\n",
      "           5       0.44      0.38      0.40       210\n",
      "           6       0.21      0.28      0.24       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.45      1470\n",
      "weighted avg       0.46      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 99  13  11  27  31  20   9]\n",
      " [ 14  95  20  22  16  33  10]\n",
      " [  9  13  92  16  11  67   2]\n",
      " [ 26  24  11  91  27  21  10]\n",
      " [ 35  25   3  30  82  19  16]\n",
      " [ 19  27   9  36  22  59  38]\n",
      " [  8   6   1  12   7  47 129]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.47      0.47       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.63      0.44      0.52       210\n",
      "           4       0.39      0.43      0.41       210\n",
      "           5       0.42      0.39      0.40       210\n",
      "           6       0.22      0.28      0.25       210\n",
      "           7       0.60      0.61      0.61       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.45      1470\n",
      "weighted avg       0.46      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97  15  11  29  32  22   4]\n",
      " [ 15  93  17  24  19  32  10]\n",
      " [  9  12  90  22   7  68   2]\n",
      " [ 27  20  11  87  25  27  13]\n",
      " [ 41  24   2  33  82  20   8]\n",
      " [ 19  27  11  28  21  67  37]\n",
      " [ 11   7   0  15   9  40 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.46      0.45       210\n",
      "           2       0.47      0.44      0.46       210\n",
      "           3       0.63      0.43      0.51       210\n",
      "           4       0.37      0.41      0.39       210\n",
      "           5       0.42      0.39      0.40       210\n",
      "           6       0.24      0.32      0.28       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.44      1470\n",
      "weighted avg       0.46      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8  12  24  35  23   8]\n",
      " [ 15  90  21  26  19  31   8]\n",
      " [  4  10  99  19   7  70   1]\n",
      " [ 21  22  11  84  30  28  14]\n",
      " [ 33  22   8  24  84  22  17]\n",
      " [ 24  19  11  34  28  59  35]\n",
      " [ 17   9   0  12  13  37 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.48      0.47       210\n",
      "           2       0.50      0.43      0.46       210\n",
      "           3       0.61      0.47      0.53       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.39      0.40      0.39       210\n",
      "           6       0.22      0.28      0.25       210\n",
      "           7       0.60      0.58      0.59       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.44      1470\n",
      "weighted avg       0.45      0.43      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101  11  11  23  37  19   8]\n",
      " [ 21  84  23  27  15  29  11]\n",
      " [  7  16  92  14   7  71   3]\n",
      " [ 31  20   9  84  28  27  11]\n",
      " [ 39  20   7  28  82  22  12]\n",
      " [ 26  25  10  34  21  59  35]\n",
      " [ 15   9   1  15  14  37 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.48      0.45       210\n",
      "           2       0.45      0.40      0.43       210\n",
      "           3       0.60      0.44      0.51       210\n",
      "           4       0.37      0.40      0.39       210\n",
      "           5       0.40      0.39      0.40       210\n",
      "           6       0.22      0.28      0.25       210\n",
      "           7       0.60      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.43      1470\n",
      "weighted avg       0.44      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   9   9  25  34  27   9]\n",
      " [ 13  85  19  28  21  32  12]\n",
      " [  8  13  93  19   7  65   5]\n",
      " [ 22  19  11  86  32  28  12]\n",
      " [ 36  21   6  33  78  22  14]\n",
      " [ 23  27  12  30  22  60  36]\n",
      " [ 16   7   1  17   8  41 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.46      0.46       210\n",
      "           2       0.47      0.40      0.43       210\n",
      "           3       0.62      0.44      0.52       210\n",
      "           4       0.36      0.41      0.38       210\n",
      "           5       0.39      0.37      0.38       210\n",
      "           6       0.22      0.29      0.25       210\n",
      "           7       0.58      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.43      1470\n",
      "weighted avg       0.44      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43333333333333335\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  12  17  19  35  22   3]\n",
      " [ 12  88  21  24  18  36  11]\n",
      " [  7  11  97  18   7  67   3]\n",
      " [ 19  22   9  81  37  28  14]\n",
      " [ 37  20   7  26  83  25  12]\n",
      " [ 30  20  12  32  23  60  33]\n",
      " [ 14   7   1  14  10  38 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.49      0.47       210\n",
      "           2       0.49      0.42      0.45       210\n",
      "           3       0.59      0.46      0.52       210\n",
      "           4       0.38      0.39      0.38       210\n",
      "           5       0.39      0.40      0.39       210\n",
      "           6       0.22      0.29      0.25       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.44      1470\n",
      "weighted avg       0.45      0.43      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4238095238095238\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   8  12  27  30  27   6]\n",
      " [ 12  84  21  20  16  44  13]\n",
      " [  9  11  94  14  10  69   3]\n",
      " [ 19  21   7  84  31  31  17]\n",
      " [ 39  17   8  26  83  26  11]\n",
      " [ 23  20  13  34  25  60  35]\n",
      " [ 15   8   2  17  12  38 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.50      0.40      0.44       210\n",
      "           3       0.60      0.45      0.51       210\n",
      "           4       0.38      0.40      0.39       210\n",
      "           5       0.40      0.40      0.40       210\n",
      "           6       0.20      0.29      0.24       210\n",
      "           7       0.58      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.45      0.42      0.43      1470\n",
      "weighted avg       0.45      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   9  13  19  36  24   9]\n",
      " [ 14  85  22  25  16  35  13]\n",
      " [  9  11  96  18   7  67   2]\n",
      " [ 21  23  11  84  30  28  13]\n",
      " [ 38  26   5  31  76  25   9]\n",
      " [ 21  21  11  35  20  68  34]\n",
      " [ 16   8   1  23  11  34 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.48      0.47       210\n",
      "           2       0.46      0.40      0.43       210\n",
      "           3       0.60      0.46      0.52       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.39      0.36      0.37       210\n",
      "           6       0.24      0.32      0.28       210\n",
      "           7       0.59      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  12  12  27  36  23   5]\n",
      " [ 16  83  23  27  16  31  14]\n",
      " [  4  12  94  18  11  69   2]\n",
      " [ 22  23  10  88  32  25  10]\n",
      " [ 37  21   7  28  77  28  12]\n",
      " [ 20  23  13  36  18  64  36]\n",
      " [ 10   7   2  21  13  37 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.45      0.46       210\n",
      "           2       0.46      0.40      0.42       210\n",
      "           3       0.58      0.45      0.51       210\n",
      "           4       0.36      0.42      0.39       210\n",
      "           5       0.38      0.37      0.37       210\n",
      "           6       0.23      0.30      0.26       210\n",
      "           7       0.60      0.57      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.43      1470\n",
      "weighted avg       0.44      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  12  15  22  35  28   5]\n",
      " [ 17  79  21  26  16  37  14]\n",
      " [  5  10  95  17   8  72   3]\n",
      " [ 24  22  10  85  27  29  13]\n",
      " [ 37  18   8  27  81  27  12]\n",
      " [ 26  19  13  33  26  61  32]\n",
      " [ 12   9   1  21  14  35 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.44      0.44       210\n",
      "           2       0.47      0.38      0.42       210\n",
      "           3       0.58      0.45      0.51       210\n",
      "           4       0.37      0.40      0.39       210\n",
      "           5       0.39      0.39      0.39       210\n",
      "           6       0.21      0.29      0.24       210\n",
      "           7       0.60      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.42      1470\n",
      "weighted avg       0.44      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41768707482993195\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   7  14  22  32  28  10]\n",
      " [ 14  90  19  25  17  31  14]\n",
      " [ 11  14  96  13   6  67   3]\n",
      " [ 19  20   8  83  35  33  12]\n",
      " [ 41  18  10  29  73  24  15]\n",
      " [ 23  21  12  32  29  57  36]\n",
      " [ 12   8   1  19  15  37 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.46      0.45       210\n",
      "           2       0.51      0.43      0.46       210\n",
      "           3       0.60      0.46      0.52       210\n",
      "           4       0.37      0.40      0.38       210\n",
      "           5       0.35      0.35      0.35       210\n",
      "           6       0.21      0.27      0.23       210\n",
      "           7       0.57      0.56      0.56       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.42      1470\n",
      "weighted avg       0.44      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 92   7  14  23  42  23   9]\n",
      " [ 12  85  21  27  18  32  15]\n",
      " [  7  18  94  13  11  63   4]\n",
      " [ 22  21  11  85  33  25  13]\n",
      " [ 29  23   6  35  80  23  14]\n",
      " [ 24  22  10  36  23  62  33]\n",
      " [ 12   6   1  19  13  39 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.44      0.45       210\n",
      "           2       0.47      0.40      0.43       210\n",
      "           3       0.60      0.45      0.51       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.36      0.38      0.37       210\n",
      "           6       0.23      0.30      0.26       210\n",
      "           7       0.58      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.43      1470\n",
      "weighted avg       0.44      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20   2  66   1  70   0  51]\n",
      " [  1  23  80   3  67   1  35]\n",
      " [  1   4 181   2  17   0   5]\n",
      " [  0   8  27   6  82   2  85]\n",
      " [  2   2  12   0 129   0  65]\n",
      " [  1   7  45   3  26   1 127]\n",
      " [  0   2   2   0   2   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.10      0.17       210\n",
      "           2       0.48      0.11      0.18       210\n",
      "           3       0.44      0.86      0.58       210\n",
      "           4       0.40      0.03      0.05       210\n",
      "           5       0.33      0.61      0.43       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.36      0.97      0.52       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.44      0.38      0.28      1470\n",
      "weighted avg       0.44      0.38      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 60   7  33   1  75   0  34]\n",
      " [  3  74  45   1  64   0  23]\n",
      " [  1  19 168   3  17   0   2]\n",
      " [  2  17  20   6 105   0  60]\n",
      " [  6  11   3   0 144   0  46]\n",
      " [  7  26  22   8  39   2 106]\n",
      " [  0   3   0   3   8   0 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.29      0.42       210\n",
      "           2       0.47      0.35      0.40       210\n",
      "           3       0.58      0.80      0.67       210\n",
      "           4       0.27      0.03      0.05       210\n",
      "           5       0.32      0.69      0.44       210\n",
      "           6       1.00      0.01      0.02       210\n",
      "           7       0.42      0.93      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.55      0.44      0.37      1470\n",
      "weighted avg       0.55      0.44      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5258503401360545\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   9   8   7  47   3  30]\n",
      " [  1 124  18   7  42   1  17]\n",
      " [  0  32 164   4   9   0   1]\n",
      " [  1  31   9  46  75   2  46]\n",
      " [ 19  15   1   3 130   1  41]\n",
      " [  9  45  13  15  21   6 101]\n",
      " [  0   4   0   1   6   2 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.50      0.61       210\n",
      "           2       0.48      0.59      0.53       210\n",
      "           3       0.77      0.78      0.78       210\n",
      "           4       0.55      0.22      0.31       210\n",
      "           5       0.39      0.62      0.48       210\n",
      "           6       0.40      0.03      0.05       210\n",
      "           7       0.45      0.94      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.48      1470\n",
      "weighted avg       0.55      0.53      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114   7   5  12  43   2  27]\n",
      " [  1 136  12   8  32  10  11]\n",
      " [  0  47 156   3   3   0   1]\n",
      " [  3  24  10  72  53   7  41]\n",
      " [ 14  19   1   9 132   2  33]\n",
      " [ 11  38  11  26  17  16  91]\n",
      " [  0   3   0   4   3   3 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.54      0.65       210\n",
      "           2       0.50      0.65      0.56       210\n",
      "           3       0.80      0.74      0.77       210\n",
      "           4       0.54      0.34      0.42       210\n",
      "           5       0.47      0.63      0.54       210\n",
      "           6       0.40      0.08      0.13       210\n",
      "           7       0.49      0.94      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.53      1470\n",
      "weighted avg       0.57      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   9   4   8  41   4  25]\n",
      " [  1 144   6  11  24  15   9]\n",
      " [  0  36 164   8   1   1   0]\n",
      " [  1  24  10  85  43  17  30]\n",
      " [ 13  20   1  11 130   9  26]\n",
      " [  8  38   9  25  13  26  91]\n",
      " [  0   1   0   1   3   6 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.57      0.68       210\n",
      "           2       0.53      0.69      0.60       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.57      0.40      0.47       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.33      0.12      0.18       210\n",
      "           7       0.52      0.95      0.67       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.57      1470\n",
      "weighted avg       0.59      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   9   4  11  42  10  19]\n",
      " [  1 147   5  10  23  14  10]\n",
      " [  0  31 171   7   0   1   0]\n",
      " [  1  21   7  99  35  23  24]\n",
      " [ 12  19   0  15 133   8  23]\n",
      " [  6  32   9  32  11  38  82]\n",
      " [  0   2   0   3   3   4 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.55      0.67       210\n",
      "           2       0.56      0.70      0.62       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.56      0.47      0.51       210\n",
      "           5       0.54      0.63      0.58       210\n",
      "           6       0.39      0.18      0.25       210\n",
      "           7       0.56      0.94      0.70       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6401360544217687\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   8   3  10  44  11  17]\n",
      " [  1 156   3  10  18  15   7]\n",
      " [  0  29 172   6   2   1   0]\n",
      " [  2  14   7 106  36  26  19]\n",
      " [ 11  20   0  17 135   6  21]\n",
      " [  7  27   5  28  11  58  74]\n",
      " [  0   3   0   1   3   6 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.56      0.67       210\n",
      "           2       0.61      0.74      0.67       210\n",
      "           3       0.91      0.82      0.86       210\n",
      "           4       0.60      0.50      0.55       210\n",
      "           5       0.54      0.64      0.59       210\n",
      "           6       0.47      0.28      0.35       210\n",
      "           7       0.59      0.94      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   7   4   5  47  14  14]\n",
      " [  3 145   4  13  22  16   7]\n",
      " [  0  23 176   6   3   2   0]\n",
      " [  1  15   7 103  43  30  11]\n",
      " [ 10  14   0  25 136  11  14]\n",
      " [  5  16   6  28  10  74  71]\n",
      " [  0   1   0   1   3   8 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.57      0.68       210\n",
      "           2       0.66      0.69      0.67       210\n",
      "           3       0.89      0.84      0.86       210\n",
      "           4       0.57      0.49      0.53       210\n",
      "           5       0.52      0.65      0.57       210\n",
      "           6       0.48      0.35      0.41       210\n",
      "           7       0.63      0.94      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   4   4   6  44  15  13]\n",
      " [  2 148   4  12  17  18   9]\n",
      " [  0  22 177   6   2   3   0]\n",
      " [  1  14   8 104  37  37   9]\n",
      " [  6  15   1  27 134  13  14]\n",
      " [  8  18   8  27  10  68  71]\n",
      " [  0   2   0   1   2   8 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.59      0.71       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.88      0.84      0.86       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.54      0.64      0.59       210\n",
      "           6       0.42      0.32      0.37       210\n",
      "           7       0.63      0.94      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   6   5  10  36  16  12]\n",
      " [  2 143   9  12  22  15   7]\n",
      " [  0  15 183   4   4   4   0]\n",
      " [  3  14   6 106  39  31  11]\n",
      " [ 14  18   0  17 139  10  12]\n",
      " [  7  20   6  26   9  67  75]\n",
      " [  0   2   0   0   3  17 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.69       210\n",
      "           2       0.66      0.68      0.67       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.61      0.50      0.55       210\n",
      "           5       0.55      0.66      0.60       210\n",
      "           6       0.42      0.32      0.36       210\n",
      "           7       0.62      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   4   7  10  33  15  13]\n",
      " [  3 145   4  17  17  15   9]\n",
      " [  0  18 180   8   1   3   0]\n",
      " [  1  15   8 114  34  26  12]\n",
      " [ 12  15   1  18 143   9  12]\n",
      " [  9  13   6  29   7  85  61]\n",
      " [  0   1   0   1   2  15 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.61      0.71       210\n",
      "           2       0.69      0.69      0.69       210\n",
      "           3       0.87      0.86      0.87       210\n",
      "           4       0.58      0.54      0.56       210\n",
      "           5       0.60      0.68      0.64       210\n",
      "           6       0.51      0.40      0.45       210\n",
      "           7       0.64      0.91      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   6   8   8  39  16   9]\n",
      " [  2 144   8  16  16  19   5]\n",
      " [  1  17 182   3   3   4   0]\n",
      " [  1  14   6 111  38  27  13]\n",
      " [ 13  15   0  25 139   9   9]\n",
      " [ 10  13   8  24  11  81  63]\n",
      " [  0   0   0   1   2  17 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.69      0.69      0.69       210\n",
      "           3       0.86      0.87      0.86       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.56      0.66      0.61       210\n",
      "           6       0.47      0.39      0.42       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   7   8  36  13  12]\n",
      " [  2 149   7  14  14  19   5]\n",
      " [  1  15 184   3   1   6   0]\n",
      " [  2  17   5 103  40  32  11]\n",
      " [ 14  15   0  18 137  13  13]\n",
      " [  8  17   6  24   8  81  66]\n",
      " [  0   2   0   0   3  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.70       210\n",
      "           2       0.68      0.71      0.69       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.61      0.49      0.54       210\n",
      "           5       0.57      0.65      0.61       210\n",
      "           6       0.46      0.39      0.42       210\n",
      "           7       0.64      0.91      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   4   8  13  33  15   8]\n",
      " [  2 150   5  15  17  13   8]\n",
      " [  1  16 180   7   1   5   0]\n",
      " [  5  17   6 110  35  24  13]\n",
      " [ 22  16   1  22 130   8  11]\n",
      " [ 12  18   6  28   6  68  72]\n",
      " [  0   0   0   2   4  14 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.61      0.68       210\n",
      "           2       0.68      0.71      0.70       210\n",
      "           3       0.87      0.86      0.87       210\n",
      "           4       0.56      0.52      0.54       210\n",
      "           5       0.58      0.62      0.60       210\n",
      "           6       0.46      0.32      0.38       210\n",
      "           7       0.63      0.90      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6850340136054421\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   6  12  35  15   8]\n",
      " [  2 156   4  12  15  14   7]\n",
      " [  0  16 185   5   0   3   1]\n",
      " [  3  13   6 118  41  19  10]\n",
      " [ 17  16   0  18 141   9   9]\n",
      " [  7  16   5  29  10  86  57]\n",
      " [  1   0   0   2   4  11 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.61      0.70       210\n",
      "           2       0.70      0.74      0.72       210\n",
      "           3       0.90      0.88      0.89       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.57      0.67      0.62       210\n",
      "           6       0.55      0.41      0.47       210\n",
      "           7       0.68      0.91      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   6   4  33  19   8]\n",
      " [  3 150   4  14  13  20   6]\n",
      " [  0  12 186   4   3   5   0]\n",
      " [  2  11   5 109  39  35   9]\n",
      " [ 13  17   0  19 136  12  13]\n",
      " [  7  20   6  26  11  78  62]\n",
      " [  0   2   0   2   3  10 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.64      0.73       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.90      0.89      0.89       210\n",
      "           4       0.61      0.52      0.56       210\n",
      "           5       0.57      0.65      0.61       210\n",
      "           6       0.44      0.37      0.40       210\n",
      "           7       0.66      0.92      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   5   8   6  36  19  10]\n",
      " [  2 146   7  12  23  12   8]\n",
      " [  0  14 185   6   0   5   0]\n",
      " [  3  17   5 107  40  27  11]\n",
      " [ 15  22   0  21 133   9  10]\n",
      " [  8  19   5  26  12  80  60]\n",
      " [  0   0   0   1   3  16 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.69       210\n",
      "           2       0.65      0.70      0.67       210\n",
      "           3       0.88      0.88      0.88       210\n",
      "           4       0.60      0.51      0.55       210\n",
      "           5       0.54      0.63      0.58       210\n",
      "           6       0.48      0.38      0.42       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   4   8   8  39  12   9]\n",
      " [  3 147   7  13  20  13   7]\n",
      " [  0  15 184   6   1   4   0]\n",
      " [  3  16   7 116  31  24  13]\n",
      " [ 16  19   0  24 132  10   9]\n",
      " [ 10  21   6  24   9  81  59]\n",
      " [  0   1   0   2   2  16 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.62      0.70       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.87      0.88      0.87       210\n",
      "           4       0.60      0.55      0.58       210\n",
      "           5       0.56      0.63      0.59       210\n",
      "           6       0.51      0.39      0.44       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   6   7   8  37  14   8]\n",
      " [  2 146   6  15  20  15   6]\n",
      " [  0  14 184   7   2   3   0]\n",
      " [  3  16   5 109  38  28  11]\n",
      " [ 16  19   0  27 132   7   9]\n",
      " [ 13  16   5  27   5  82  62]\n",
      " [  0   0   0   1   2  20 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.62      0.70       210\n",
      "           2       0.67      0.70      0.68       210\n",
      "           3       0.89      0.88      0.88       210\n",
      "           4       0.56      0.52      0.54       210\n",
      "           5       0.56      0.63      0.59       210\n",
      "           6       0.49      0.39      0.43       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   6   8  10  38  15   8]\n",
      " [  3 145   6  16  18  16   6]\n",
      " [  1  14 182   7   2   4   0]\n",
      " [  4  16   7 110  30  31  12]\n",
      " [ 18  22   0  21 129  10  10]\n",
      " [ 10  20   5  27   9  74  65]\n",
      " [  0   1   0   1   2  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.60      0.67       210\n",
      "           2       0.65      0.69      0.67       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.57      0.52      0.55       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.65      0.89      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   7   5   8  39  16   8]\n",
      " [  1 149   7  16  19  11   7]\n",
      " [  0  13 183   7   2   5   0]\n",
      " [  4  18   7 104  37  27  13]\n",
      " [ 13  19   0  26 133   8  11]\n",
      " [  9  22   3  27  10  75  64]\n",
      " [  0   1   0   2   1  17 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.65      0.71      0.68       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.55      0.50      0.52       210\n",
      "           5       0.55      0.63      0.59       210\n",
      "           6       0.47      0.36      0.41       210\n",
      "           7       0.65      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[114   5  23   8  21   9  30]\n",
      " [  1 119  34  12  15  16  13]\n",
      " [  1  11 174  21   1   1   1]\n",
      " [  7  16  17  80  31  17  42]\n",
      " [ 32  26   1  12  94   8  37]\n",
      " [ 12  38  18  19  12  39  72]\n",
      " [  0  31   0  17   8  12 142]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.54      0.60       210\n",
      "           2       0.48      0.57      0.52       210\n",
      "           3       0.65      0.83      0.73       210\n",
      "           4       0.47      0.38      0.42       210\n",
      "           5       0.52      0.45      0.48       210\n",
      "           6       0.38      0.19      0.25       210\n",
      "           7       0.42      0.68      0.52       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.50      1470\n",
      "weighted avg       0.52      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7251700680272108\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[156   2   3   4  34   9   2]\n",
      " [  3 160   4  12  18  13   0]\n",
      " [  1   9 192   3   3   2   0]\n",
      " [  6  17   3 138  22  18   6]\n",
      " [ 38  11   1  24 126   6   4]\n",
      " [ 11  15   5  25   7 118  29]\n",
      " [  0   0   0   3   3  28 176]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73       210\n",
      "           2       0.75      0.76      0.75       210\n",
      "           3       0.92      0.91      0.92       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.59      0.60      0.60       210\n",
      "           6       0.61      0.56      0.58       210\n",
      "           7       0.81      0.84      0.82       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.72      0.73      0.72      1470\n",
      "weighted avg       0.72      0.73      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133  12  12   4  47   1   1]\n",
      " [ 24 133  14  11  24   3   1]\n",
      " [ 11  19 175   2   2   1   0]\n",
      " [ 32  22  12  89  45   7   3]\n",
      " [ 59  21   4  15 107   1   3]\n",
      " [ 53  24  13  33  16  35  36]\n",
      " [ 15   0   0   6   9  15 165]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.63      0.50       210\n",
      "           2       0.58      0.63      0.60       210\n",
      "           3       0.76      0.83      0.80       210\n",
      "           4       0.56      0.42      0.48       210\n",
      "           5       0.43      0.51      0.47       210\n",
      "           6       0.56      0.17      0.26       210\n",
      "           7       0.79      0.79      0.79       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.55      1470\n",
      "weighted avg       0.58      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   6  13   6  41   2   1]\n",
      " [ 22 133  13  10  25   5   2]\n",
      " [  8  17 177   3   3   2   0]\n",
      " [ 29  24  10  96  39  10   2]\n",
      " [ 60  16   3  18 105   3   5]\n",
      " [ 46  21  12  26  18  46  41]\n",
      " [ 10   0   0   4   6  23 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.67      0.54       210\n",
      "           2       0.61      0.63      0.62       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.59      0.46      0.51       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.51      0.22      0.31       210\n",
      "           7       0.77      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5918367346938775\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   8  11   5  48   2   1]\n",
      " [ 21 130  14  12  27   3   3]\n",
      " [  5  17 180   3   3   2   0]\n",
      " [ 22  20   9  98  49  10   2]\n",
      " [ 47  19   4  17 116   3   4]\n",
      " [ 42  23  12  28  15  42  48]\n",
      " [  7   0   0   2  10  22 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.64      0.55       210\n",
      "           2       0.60      0.62      0.61       210\n",
      "           3       0.78      0.86      0.82       210\n",
      "           4       0.59      0.47      0.52       210\n",
      "           5       0.43      0.55      0.49       210\n",
      "           6       0.50      0.20      0.29       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5959183673469388\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   4  11   4  43   2   2]\n",
      " [ 15 133  14  13  30   2   3]\n",
      " [  5  21 175   4   4   1   0]\n",
      " [ 24  19  11  93  48  12   3]\n",
      " [ 59  12   5  16 111   4   3]\n",
      " [ 45  18  13  26  17  47  44]\n",
      " [  5   0   0   4  10  18 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.69      0.57       210\n",
      "           2       0.64      0.63      0.64       210\n",
      "           3       0.76      0.83      0.80       210\n",
      "           4       0.58      0.44      0.50       210\n",
      "           5       0.42      0.53      0.47       210\n",
      "           6       0.55      0.22      0.32       210\n",
      "           7       0.76      0.82      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.58      1470\n",
      "weighted avg       0.60      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   6   8   5  44   2   2]\n",
      " [ 18 126  16  12  31   4   3]\n",
      " [  9  19 176   1   4   0   1]\n",
      " [ 22  16  12  99  48   9   4]\n",
      " [ 48  14   6  15 122   2   3]\n",
      " [ 40  24  10  26  22  45  43]\n",
      " [  9   0   0   3   8  13 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.68      0.57       210\n",
      "           2       0.61      0.60      0.61       210\n",
      "           3       0.77      0.84      0.80       210\n",
      "           4       0.61      0.47      0.53       210\n",
      "           5       0.44      0.58      0.50       210\n",
      "           6       0.60      0.21      0.32       210\n",
      "           7       0.76      0.84      0.80       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138   6  10   6  43   5   2]\n",
      " [ 16 130  13  12  31   4   4]\n",
      " [  7  20 173   2   6   2   0]\n",
      " [ 19  19  11  96  53   6   6]\n",
      " [ 48  15   4  18 119   1   5]\n",
      " [ 35  24   9  23  23  47  49]\n",
      " [  9   0   0   3   8  13 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.66      0.57       210\n",
      "           2       0.61      0.62      0.61       210\n",
      "           3       0.79      0.82      0.80       210\n",
      "           4       0.60      0.46      0.52       210\n",
      "           5       0.42      0.57      0.48       210\n",
      "           6       0.60      0.22      0.33       210\n",
      "           7       0.73      0.84      0.78       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 96   7  16   5  43  14  29]\n",
      " [  3 121   9  16  24  23  14]\n",
      " [ 14  27 147   8   4   9   1]\n",
      " [  3  17   5  81  38  25  41]\n",
      " [ 12   8   0  10 130  10  40]\n",
      " [ 13  22   6  30  12  42  85]\n",
      " [  1   3   0   7   6  28 165]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.46      0.55       210\n",
      "           2       0.59      0.58      0.58       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.52      0.39      0.44       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.28      0.20      0.23       210\n",
      "           7       0.44      0.79      0.56       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.52      1470\n",
      "weighted avg       0.54      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[100   3  16   6  43  20  22]\n",
      " [  1  87  31  23  30  27  11]\n",
      " [ 16  18 139  18   6  12   1]\n",
      " [  4  15   5  83  43  30  30]\n",
      " [ 10   7   1   8 135  17  32]\n",
      " [ 13  21   6  32  18  48  72]\n",
      " [  0   7   0  16  10  19 158]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.48      0.56       210\n",
      "           2       0.55      0.41      0.47       210\n",
      "           3       0.70      0.66      0.68       210\n",
      "           4       0.45      0.40      0.42       210\n",
      "           5       0.47      0.64      0.55       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.48      0.75      0.59       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7224489795918367\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   3   1   3  37  10   0]\n",
      " [  2 170   5  14  10   7   2]\n",
      " [  0   6 196   3   2   3   0]\n",
      " [  9  19   6 136  20  19   1]\n",
      " [ 45  14   1  21 123   4   2]\n",
      " [  8  20  14  23   5 113  27]\n",
      " [  1   0   0   5   2  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.73      0.81      0.77       210\n",
      "           3       0.88      0.93      0.91       210\n",
      "           4       0.66      0.65      0.66       210\n",
      "           5       0.62      0.59      0.60       210\n",
      "           6       0.59      0.54      0.56       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of SVM is:\n",
      " [[105   2   3   5  50  41   4]\n",
      " [  3 131   1  10  21  41   3]\n",
      " [  1  14 174   3   8  10   0]\n",
      " [  0   6   2 110  26  62   4]\n",
      " [  4   7   0  13 144  35   7]\n",
      " [  0   4   4  11   2 141  48]\n",
      " [  0   0   0   0   3  25 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.50      0.65       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.95      0.83      0.88       210\n",
      "           4       0.72      0.52      0.61       210\n",
      "           5       0.57      0.69      0.62       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.73      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.73      0.67      0.68      1470\n",
      "weighted avg       0.73      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7612244897959184\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   4   4   6  34  14   0]\n",
      " [  1 161   3  15  10  18   2]\n",
      " [  0  11 193   2   1   3   0]\n",
      " [  0  14   7 147  18  22   2]\n",
      " [ 20  14   2  18 142   9   5]\n",
      " [  4  10   6  13   4 142  31]\n",
      " [  0   0   0   0   1  23 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.70      0.77       210\n",
      "           2       0.75      0.77      0.76       210\n",
      "           3       0.90      0.92      0.91       210\n",
      "           4       0.73      0.70      0.72       210\n",
      "           5       0.68      0.68      0.68       210\n",
      "           6       0.61      0.68      0.64       210\n",
      "           7       0.82      0.89      0.85       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.76      0.76      0.76      1470\n",
      "weighted avg       0.76      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   3   7   2  40  20   0]\n",
      " [  2 149  10  20   4  24   1]\n",
      " [  0  16 173  15   3   3   0]\n",
      " [  1  17  24 125  16  25   2]\n",
      " [ 29  19   4  22 124   6   6]\n",
      " [  5  13  12  16   4 120  40]\n",
      " [  0   0   0   0   1  27 182]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.75      0.82      0.79       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.65      0.59      0.62       210\n",
      "           6       0.53      0.57      0.55       210\n",
      "           7       0.79      0.87      0.83       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23061224489795917\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  22   0   0   0 188]\n",
      " [  0   0  17   0   0   0 193]\n",
      " [  0   0 130   0   0   0  80]\n",
      " [  0   0  19   0   0   0 191]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   9   0   0   0 201]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.65      0.62      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.12      0.23      0.13      1470\n",
      "weighted avg       0.12      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.34217687074829933\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 22   0   0   0 121   0  67]\n",
      " [ 13   0   4   0  98   0  95]\n",
      " [  9   0 121   0  35   0  45]\n",
      " [ 13   0   6   0 121   0  70]\n",
      " [  1   0   0   0 177   0  32]\n",
      " [  3   0   6   0  61   0 140]\n",
      " [  1   0   0   0  26   0 183]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.10      0.16       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.88      0.58      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.28      0.84      0.42       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.29      0.87      0.43       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.26      0.34      0.24      1470\n",
      "weighted avg       0.26      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 22  74   0   0  98   0  16]\n",
      " [  1 138   3   1  40   0  27]\n",
      " [  3  72 118   3  11   0   3]\n",
      " [  2 113   2   4  64   0  25]\n",
      " [  0  60   0   0 133   0  17]\n",
      " [  1 107   3   3  15   0  81]\n",
      " [  0  39   0   0   9   0 162]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.10      0.18       210\n",
      "           2       0.23      0.66      0.34       210\n",
      "           3       0.94      0.56      0.70       210\n",
      "           4       0.36      0.02      0.04       210\n",
      "           5       0.36      0.63      0.46       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.49      0.77      0.60       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.45      0.39      0.33      1470\n",
      "weighted avg       0.45      0.39      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54   3   0  71  66  13   3]\n",
      " [  2  86   3  53  39  17  10]\n",
      " [  5  28 118  47   9   2   1]\n",
      " [  2  16   1 102  64  15  10]\n",
      " [  2   5   0  55 131   5  12]\n",
      " [  1  20   2  91  15  28  53]\n",
      " [  0   3   0  36   9  39 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.26      0.39       210\n",
      "           2       0.53      0.41      0.46       210\n",
      "           3       0.95      0.56      0.71       210\n",
      "           4       0.22      0.49      0.31       210\n",
      "           5       0.39      0.62      0.48       210\n",
      "           6       0.24      0.13      0.17       210\n",
      "           7       0.58      0.59      0.58       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.53      0.44      0.44      1470\n",
      "weighted avg       0.53      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   4   1  54  64  18   2]\n",
      " [  1  81   7  55  34  26   6]\n",
      " [  5  21 120  53   5   6   0]\n",
      " [  3   8   1 117  48  24   9]\n",
      " [  2   5   0  55 117  22   9]\n",
      " [  2  10   2  93  14  52  37]\n",
      " [  0   3   0  33   6  58 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.32      0.46       210\n",
      "           2       0.61      0.39      0.47       210\n",
      "           3       0.92      0.57      0.70       210\n",
      "           4       0.25      0.56      0.35       210\n",
      "           5       0.41      0.56      0.47       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.64      0.52      0.57       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.56      0.45      0.47      1470\n",
      "weighted avg       0.56      0.45      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65   5   6  37  76  17   4]\n",
      " [  2  95  11  39  29  23  11]\n",
      " [  5  29 150  16   2   7   1]\n",
      " [  3  24  11  77  63  16  16]\n",
      " [  2  19   2  30 126  19  12]\n",
      " [  1  18   9  63  31  30  58]\n",
      " [  0   2   0  23  15  29 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.31      0.45       210\n",
      "           2       0.49      0.45      0.47       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.27      0.37      0.31       210\n",
      "           5       0.37      0.60      0.46       210\n",
      "           6       0.21      0.14      0.17       210\n",
      "           7       0.58      0.67      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.46      1470\n",
      "weighted avg       0.51      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   6   6  35  63  19   3]\n",
      " [  4  82  12  27  47  25  13]\n",
      " [  4  23 146  20   8   4   5]\n",
      " [  8  14  10  75  72  20  11]\n",
      " [ 10   9   2  26 134  16  13]\n",
      " [  3  16   6  50  31  43  61]\n",
      " [  0   7   0  10  15  38 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.37      0.49       210\n",
      "           2       0.52      0.39      0.45       210\n",
      "           3       0.80      0.70      0.74       210\n",
      "           4       0.31      0.36      0.33       210\n",
      "           5       0.36      0.64      0.46       210\n",
      "           6       0.26      0.20      0.23       210\n",
      "           7       0.57      0.67      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.51      0.47      0.47      1470\n",
      "weighted avg       0.51      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106   6  23  16  36  20   3]\n",
      " [ 21  88  23  20  25  24   9]\n",
      " [  8  24 159   2   5   9   3]\n",
      " [ 19  16  18  83  46  20   8]\n",
      " [ 41   9   7  28 100  18   7]\n",
      " [  8  16  34  32  20  55  45]\n",
      " [  6   6   2  23   4  42 127]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.50      0.51       210\n",
      "           2       0.53      0.42      0.47       210\n",
      "           3       0.60      0.76      0.67       210\n",
      "           4       0.41      0.40      0.40       210\n",
      "           5       0.42      0.48      0.45       210\n",
      "           6       0.29      0.26      0.28       210\n",
      "           7       0.63      0.60      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.48      1470\n",
      "weighted avg       0.48      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47959183673469385\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  32   6   7  36  27   4]\n",
      " [ 18 100  14  16  28  22  12]\n",
      " [  9  23 157   2   5  12   2]\n",
      " [ 15  24  15  63  53  31   9]\n",
      " [ 32  15   3  29 101  23   7]\n",
      " [  9  30  17  29  22  51  52]\n",
      " [  4   8   1  14   6  42 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.47      0.50       210\n",
      "           2       0.43      0.48      0.45       210\n",
      "           3       0.74      0.75      0.74       210\n",
      "           4       0.39      0.30      0.34       210\n",
      "           5       0.40      0.48      0.44       210\n",
      "           6       0.25      0.24      0.24       210\n",
      "           7       0.61      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48095238095238096\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106  15   6  11  49  21   2]\n",
      " [ 20  90  15  28  22  24  11]\n",
      " [ 12  14 154   7   8  13   2]\n",
      " [ 26  21  11  77  41  24  10]\n",
      " [ 31   8   2  37 106  20   6]\n",
      " [ 36  21   8  37  18  46  44]\n",
      " [  7  13   3  15   5  39 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.50      0.47       210\n",
      "           2       0.49      0.43      0.46       210\n",
      "           3       0.77      0.73      0.75       210\n",
      "           4       0.36      0.37      0.36       210\n",
      "           5       0.43      0.50      0.46       210\n",
      "           6       0.25      0.22      0.23       210\n",
      "           7       0.63      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.48      0.48      0.48      1470\n",
      "weighted avg       0.48      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4748299319727891\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  12   6  22  39  15   3]\n",
      " [ 19  89  19  24  25  21  13]\n",
      " [ 10  17 155  11   4  12   1]\n",
      " [ 20  24  12  78  42  25   9]\n",
      " [ 34   6   4  46  97  17   6]\n",
      " [ 35  19   8  33  22  48  45]\n",
      " [  9  10   1  16   6  50 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.54      0.50       210\n",
      "           2       0.50      0.42      0.46       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.34      0.37      0.35       210\n",
      "           5       0.41      0.46      0.44       210\n",
      "           6       0.26      0.23      0.24       210\n",
      "           7       0.61      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.48      0.47      0.47      1470\n",
      "weighted avg       0.48      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.46870748299319726\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  14   4  19  39  14   4]\n",
      " [ 21  88  18  22  27  22  12]\n",
      " [ 12  17 154   5   6  14   2]\n",
      " [ 24  20  19  64  45  28  10]\n",
      " [ 44   9   2  44  89  17   5]\n",
      " [ 26  20   9  25  26  61  43]\n",
      " [ 13  11   3  12   9  45 117]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.55      0.50       210\n",
      "           2       0.49      0.42      0.45       210\n",
      "           3       0.74      0.73      0.74       210\n",
      "           4       0.34      0.30      0.32       210\n",
      "           5       0.37      0.42      0.39       210\n",
      "           6       0.30      0.29      0.30       210\n",
      "           7       0.61      0.56      0.58       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  14   5  16  43  20   5]\n",
      " [ 14  94  16  24  23  28  11]\n",
      " [ 13  19 155   7   5   8   3]\n",
      " [ 22  24  17  59  40  35  13]\n",
      " [ 33  11   0  44  96  17   9]\n",
      " [ 17  23  14  33  25  53  45]\n",
      " [  6  15   5   9   7  54 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.51       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.73      0.74      0.73       210\n",
      "           4       0.31      0.28      0.29       210\n",
      "           5       0.40      0.46      0.43       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.57      0.54      0.56       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46938775510204084\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  14   6  13  45  18   3]\n",
      " [ 10  90  20  22  29  30   9]\n",
      " [  9  16 158   5   6  14   2]\n",
      " [ 18  25  15  63  45  35   9]\n",
      " [ 35  12   2  39  95  18   9]\n",
      " [ 18  20  12  32  20  60  48]\n",
      " [ 11  15   4   9   7  51 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.53      0.53       210\n",
      "           2       0.47      0.43      0.45       210\n",
      "           3       0.73      0.75      0.74       210\n",
      "           4       0.34      0.30      0.32       210\n",
      "           5       0.38      0.45      0.42       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.59      0.54      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  13   6  11  46  15   5]\n",
      " [ 13  90  20  20  31  26  10]\n",
      " [ 11  16 152   8   4  17   2]\n",
      " [ 13  22  18  64  48  33  12]\n",
      " [ 39  12   2  46  85  17   9]\n",
      " [ 19  25  10  32  24  51  49]\n",
      " [  8  15   3  11   9  44 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.53       210\n",
      "           2       0.47      0.43      0.45       210\n",
      "           3       0.72      0.72      0.72       210\n",
      "           4       0.33      0.30      0.32       210\n",
      "           5       0.34      0.40      0.37       210\n",
      "           6       0.25      0.24      0.25       210\n",
      "           7       0.58      0.57      0.58       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45714285714285713\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  20  10  12  39  13   6]\n",
      " [ 16  89  22  18  27  29   9]\n",
      " [  8  17 156   7   5  15   2]\n",
      " [ 19  24  14  62  44  36  11]\n",
      " [ 40   9   3  45  84  21   8]\n",
      " [ 19  27  12  34  19  55  44]\n",
      " [  6  10   3  11  12  52 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.52      0.51       210\n",
      "           2       0.45      0.42      0.44       210\n",
      "           3       0.71      0.74      0.73       210\n",
      "           4       0.33      0.30      0.31       210\n",
      "           5       0.37      0.40      0.38       210\n",
      "           6       0.25      0.26      0.26       210\n",
      "           7       0.59      0.55      0.57       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  14   7  15  39  16   6]\n",
      " [ 14  95  23  18  28  21  11]\n",
      " [ 10  17 154   8   5  12   4]\n",
      " [ 21  23  13  66  42  37   8]\n",
      " [ 37  10   5  42  87  21   8]\n",
      " [ 21  26  10  31  25  51  46]\n",
      " [ 10  13   5  11   7  54 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52       210\n",
      "           2       0.48      0.45      0.47       210\n",
      "           3       0.71      0.73      0.72       210\n",
      "           4       0.35      0.31      0.33       210\n",
      "           5       0.37      0.41      0.39       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.57      0.52      0.55       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  18   5  11  40  17   5]\n",
      " [ 17  92  17  18  26  29  11]\n",
      " [  7  17 156   7   6  15   2]\n",
      " [ 19  27  16  60  41  35  12]\n",
      " [ 43  12   3  40  87  17   8]\n",
      " [ 24  23   9  32  24  48  50]\n",
      " [  6  14   4  10  13  49 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52       210\n",
      "           2       0.45      0.44      0.45       210\n",
      "           3       0.74      0.74      0.74       210\n",
      "           4       0.34      0.29      0.31       210\n",
      "           5       0.37      0.41      0.39       210\n",
      "           6       0.23      0.23      0.23       210\n",
      "           7       0.56      0.54      0.55       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110  18   5  16  33  21   7]\n",
      " [ 12  92  19  21  27  27  12]\n",
      " [ 12  13 161   5   5  12   2]\n",
      " [ 14  29  12  65  41  35  14]\n",
      " [ 40  14   4  44  80  21   7]\n",
      " [ 18  23  12  34  27  52  44]\n",
      " [  6  10   6  11   9  50 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.52      0.52       210\n",
      "           2       0.46      0.44      0.45       210\n",
      "           3       0.74      0.77      0.75       210\n",
      "           4       0.33      0.31      0.32       210\n",
      "           5       0.36      0.38      0.37       210\n",
      "           6       0.24      0.25      0.24       210\n",
      "           7       0.58      0.56      0.57       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4605442176870748\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  17  10  15  34  13  13]\n",
      " [ 13  93  22  20  25  24  13]\n",
      " [  8  16 155   7   5  16   3]\n",
      " [ 13  24  12  70  46  35  10]\n",
      " [ 43  10   4  42  84  15  12]\n",
      " [ 19  26  12  40  17  51  45]\n",
      " [ 13  12   3  10  11  45 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.51      0.51       210\n",
      "           2       0.47      0.44      0.46       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.34      0.33      0.34       210\n",
      "           5       0.38      0.40      0.39       210\n",
      "           6       0.26      0.24      0.25       210\n",
      "           7       0.55      0.55      0.55       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  20   7  16  37  16   6]\n",
      " [  9  94  23  20  30  22  12]\n",
      " [ 10  21 155   7   3  12   2]\n",
      " [ 15  25  13  63  39  40  15]\n",
      " [ 41  18   5  44  78  15   9]\n",
      " [ 17  23  12  34  22  55  47]\n",
      " [  8  12   4  12  15  49 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.51      0.52       210\n",
      "           2       0.44      0.45      0.44       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.32      0.30      0.31       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.26      0.26      0.26       210\n",
      "           7       0.55      0.52      0.54       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.38231292517006804\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 19   7  38   0  91   1  54]\n",
      " [  2  37  60   1  52   0  58]\n",
      " [  3   4 177   2   9   0  15]\n",
      " [  4   4  18   8  87   0  89]\n",
      " [  1   4   3   1 121   0  80]\n",
      " [  2  15  27   1  39   0 126]\n",
      " [  0   0   0   0  10   0 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.09      0.16       210\n",
      "           2       0.52      0.18      0.26       210\n",
      "           3       0.55      0.84      0.66       210\n",
      "           4       0.62      0.04      0.07       210\n",
      "           5       0.30      0.58      0.39       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.95      0.48       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.42      0.38      0.29      1470\n",
      "weighted avg       0.42      0.38      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4816326530612245\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 75  11   4   1  85   0  34]\n",
      " [  1  90  22   2  64   0  31]\n",
      " [  3  20 165   0  15   1   6]\n",
      " [  3  18  10  16 106   0  57]\n",
      " [  3   7   1   2 156   0  41]\n",
      " [  8  25  11   4  35   2 125]\n",
      " [  0   0   0   0   6   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.36      0.50       210\n",
      "           2       0.53      0.43      0.47       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.64      0.08      0.14       210\n",
      "           5       0.33      0.74      0.46       210\n",
      "           6       0.67      0.01      0.02       210\n",
      "           7       0.41      0.97      0.58       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.59      0.48      0.42      1470\n",
      "weighted avg       0.59      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102  17   1   1  57   5  27]\n",
      " [  1 135  11   3  39   1  20]\n",
      " [  4  36 160   1   5   2   2]\n",
      " [  0  26   9  29  88   9  49]\n",
      " [  6  13   0   6 148   0  37]\n",
      " [ 11  40   9   8  22   6 114]\n",
      " [  0   0   0   0   5   2 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.49      0.61       210\n",
      "           2       0.51      0.64      0.57       210\n",
      "           3       0.84      0.76      0.80       210\n",
      "           4       0.60      0.14      0.22       210\n",
      "           5       0.41      0.70      0.52       210\n",
      "           6       0.24      0.03      0.05       210\n",
      "           7       0.45      0.97      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.48      1470\n",
      "weighted avg       0.55      0.53      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  16   1   3  52   3  26]\n",
      " [  1 150   5   6  25   4  19]\n",
      " [  0  37 162   5   4   0   2]\n",
      " [  1  32   4  64  60  10  39]\n",
      " [ 16  15   0   8 135   6  30]\n",
      " [  7  40   8  13  17  22 103]\n",
      " [  0   1   0   0   5   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.52      0.63       210\n",
      "           2       0.52      0.71      0.60       210\n",
      "           3       0.90      0.77      0.83       210\n",
      "           4       0.65      0.30      0.41       210\n",
      "           5       0.45      0.64      0.53       210\n",
      "           6       0.49      0.10      0.17       210\n",
      "           7       0.48      0.97      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.55      1470\n",
      "weighted avg       0.61      0.58      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[113  13   1   4  48  11  20]\n",
      " [  1 147   3  11  24  11  13]\n",
      " [  1  38 160   4   4   2   1]\n",
      " [  1  28   3  90  42  23  23]\n",
      " [  9  15   0  16 137   8  25]\n",
      " [  7  38   6  20  13  39  87]\n",
      " [  0   0   0   1   5   4 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.54      0.66       210\n",
      "           2       0.53      0.70      0.60       210\n",
      "           3       0.92      0.76      0.84       210\n",
      "           4       0.62      0.43      0.51       210\n",
      "           5       0.50      0.65      0.57       210\n",
      "           6       0.40      0.19      0.25       210\n",
      "           7       0.54      0.95      0.69       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.62      0.60      0.59      1470\n",
      "weighted avg       0.62      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116  11   0   6  48  17  12]\n",
      " [  1 139   3  18  23  19   7]\n",
      " [  0  35 161   7   4   2   1]\n",
      " [  0  23   3 108  31  24  21]\n",
      " [  8  13   0  19 136  15  19]\n",
      " [  5  29   6  32  12  44  82]\n",
      " [  0   1   0   1   5   3 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.55      0.68       210\n",
      "           2       0.55      0.66      0.60       210\n",
      "           3       0.93      0.77      0.84       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.53      0.65      0.58       210\n",
      "           6       0.35      0.21      0.26       210\n",
      "           7       0.58      0.95      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.60      1470\n",
      "weighted avg       0.63      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   8   3   4  45  17  12]\n",
      " [  1 148   3  16  17  19   6]\n",
      " [  0  33 162   8   2   5   0]\n",
      " [  1  22   3 102  33  38  11]\n",
      " [  7  10   0  22 140  17  14]\n",
      " [  8  23   5  19  11  66  78]\n",
      " [  0   0   0   0   5   7 198]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.58      0.70       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.92      0.77      0.84       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.55      0.67      0.60       210\n",
      "           6       0.39      0.31      0.35       210\n",
      "           7       0.62      0.94      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   7   6   7  49  15  11]\n",
      " [  1 149   4  16  17  18   5]\n",
      " [  0  25 170   7   4   3   1]\n",
      " [  1  23   3 111  28  30  14]\n",
      " [ 10  11   0  20 140  18  11]\n",
      " [  5  22   9  26  11  66  71]\n",
      " [  0   1   0   0   3  10 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.55      0.67       210\n",
      "           2       0.63      0.71      0.67       210\n",
      "           3       0.89      0.81      0.85       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.56      0.67      0.61       210\n",
      "           6       0.41      0.31      0.36       210\n",
      "           7       0.63      0.93      0.76       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   9   2   7  47  16   9]\n",
      " [  1 153   2  14  18  17   5]\n",
      " [  2  21 174   9   1   3   0]\n",
      " [  2  25   3 106  27  38   9]\n",
      " [  8  11   0  25 143   9  14]\n",
      " [  7  15   8  24  10  76  70]\n",
      " [  0   1   0   0   3   9 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.57      0.69       210\n",
      "           2       0.65      0.73      0.69       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.57      0.50      0.54       210\n",
      "           5       0.57      0.68      0.62       210\n",
      "           6       0.45      0.36      0.40       210\n",
      "           7       0.65      0.94      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.65      1470\n",
      "weighted avg       0.67      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   9   2  10  44  11   9]\n",
      " [  1 146   4  20  14  19   6]\n",
      " [  0  25 165  10   6   3   1]\n",
      " [  2  22   3 112  30  31  10]\n",
      " [  8  12   1  25 135  21   8]\n",
      " [  7  19   5  27   7  76  69]\n",
      " [  0   0   0   0   2  15 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.60      0.71       210\n",
      "           2       0.63      0.70      0.66       210\n",
      "           3       0.92      0.79      0.85       210\n",
      "           4       0.55      0.53      0.54       210\n",
      "           5       0.57      0.64      0.60       210\n",
      "           6       0.43      0.36      0.39       210\n",
      "           7       0.65      0.92      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   3   7   4  45  19   8]\n",
      " [  2 146   3  19  16  17   7]\n",
      " [  0  20 181   6   0   2   1]\n",
      " [  1  21   3 120  29  27   9]\n",
      " [ 12  12   0  17 141  20   8]\n",
      " [  9  18   4  20  10  89  60]\n",
      " [  0   0   0   0   3  13 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.59      0.69       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.91      0.86      0.89       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.58      0.67      0.62       210\n",
      "           6       0.48      0.42      0.45       210\n",
      "           7       0.68      0.92      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.67      1470\n",
      "weighted avg       0.68      0.68      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   9   3   4  48  17   8]\n",
      " [  1 147   2  16  20  19   5]\n",
      " [  0  28 169   5   2   5   1]\n",
      " [  2  22   3 111  31  31  10]\n",
      " [ 14  13   0  22 141   7  13]\n",
      " [  4  13   6  25   7  99  56]\n",
      " [  0   1   0   0   3  11 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.58      0.69       210\n",
      "           2       0.63      0.70      0.66       210\n",
      "           3       0.92      0.80      0.86       210\n",
      "           4       0.61      0.53      0.56       210\n",
      "           5       0.56      0.67      0.61       210\n",
      "           6       0.52      0.47      0.50       210\n",
      "           7       0.68      0.93      0.78       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   7   6   7  40  19   4]\n",
      " [  2 148   3  19  17  17   4]\n",
      " [  0  25 171   5   3   6   0]\n",
      " [  2  20   4 119  30  29   6]\n",
      " [ 17  12   1  20 138  13   9]\n",
      " [  8  19   4  14  14  92  59]\n",
      " [  0   0   0   0   2  16 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.64      0.70      0.67       210\n",
      "           3       0.90      0.81      0.86       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.48      0.44      0.46       210\n",
      "           7       0.70      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   6   7   7  43  14   7]\n",
      " [  2 154   3  15  15  18   3]\n",
      " [  0  26 172   3   5   4   0]\n",
      " [  2  19   4 107  31  36  11]\n",
      " [ 14  12   0  20 143  14   7]\n",
      " [  9  17   7  16   8  96  57]\n",
      " [  0   0   0   0   5  14 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.69       210\n",
      "           2       0.66      0.73      0.69       210\n",
      "           3       0.89      0.82      0.85       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.57      0.68      0.62       210\n",
      "           6       0.49      0.46      0.47       210\n",
      "           7       0.69      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   4   8  10  43  16   7]\n",
      " [  2 147   1  19  17  21   3]\n",
      " [  0  25 174   5   4   1   1]\n",
      " [  2  19   4 110  31  33  11]\n",
      " [ 13  12   0  21 144  12   8]\n",
      " [  8  15   6  25  11  83  62]\n",
      " [  0   0   0   0   4  12 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.58      0.68       210\n",
      "           2       0.66      0.70      0.68       210\n",
      "           3       0.90      0.83      0.86       210\n",
      "           4       0.58      0.52      0.55       210\n",
      "           5       0.57      0.69      0.62       210\n",
      "           6       0.47      0.40      0.43       210\n",
      "           7       0.68      0.92      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   6   6   4  46  15   8]\n",
      " [  2 156   1  16  14  15   6]\n",
      " [  3  31 166   5   2   3   0]\n",
      " [  1  22   3 111  29  31  13]\n",
      " [ 15  19   0  20 139   9   8]\n",
      " [ 11  20   6  24  11  81  57]\n",
      " [  0   0   0   0   2  14 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.60      0.68       210\n",
      "           2       0.61      0.74      0.67       210\n",
      "           3       0.91      0.79      0.85       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.48      0.39      0.43       210\n",
      "           7       0.68      0.92      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   6   7   9  38  17   6]\n",
      " [  2 150   2  14  17  21   4]\n",
      " [  0  24 174   4   4   4   0]\n",
      " [  1  23   3 112  28  33  10]\n",
      " [ 15  14   0  21 139  14   7]\n",
      " [  9  21   6  24   4  91  55]\n",
      " [  0   0   0   0   3  17 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.60      0.70       210\n",
      "           2       0.63      0.71      0.67       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.61      0.53      0.57       210\n",
      "           5       0.60      0.66      0.63       210\n",
      "           6       0.46      0.43      0.45       210\n",
      "           7       0.70      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   6   7   6  42  19   6]\n",
      " [  3 147   2  17  19  18   4]\n",
      " [  1  21 175   6   3   4   0]\n",
      " [  1  25   2 109  31  33   9]\n",
      " [ 12  18   0  25 138   9   8]\n",
      " [ 10  20   5  22   5  88  60]\n",
      " [  0   1   0   0   2  12 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.62      0.70      0.66       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.48      0.42      0.45       210\n",
      "           7       0.69      0.93      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   9   6   5  43  16   6]\n",
      " [  3 152   2  14  15  19   5]\n",
      " [  2  28 170   4   2   4   0]\n",
      " [  0  29   5 112  29  27   8]\n",
      " [ 13  14   0  23 141  10   9]\n",
      " [  7  21   3  24   5  91  59]\n",
      " [  0   0   0   0   2  21 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.69       210\n",
      "           2       0.60      0.72      0.66       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.59      0.67      0.63       210\n",
      "           6       0.48      0.43      0.46       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   7   6   6  40  18   7]\n",
      " [  2 149   2  16  17  21   3]\n",
      " [  1  26 171   6   2   3   1]\n",
      " [  1  23   6 113  30  27  10]\n",
      " [ 17  14   0  20 141  11   7]\n",
      " [  8  29   3  18  11  81  60]\n",
      " [  0   0   0   0   2  16 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.60      0.71      0.65       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.58      0.67      0.62       210\n",
      "           6       0.46      0.39      0.42       210\n",
      "           7       0.69      0.91      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129  11   4   4  41  15   6]\n",
      " [  1 154   1  18  15  17   4]\n",
      " [  0  26 174   5   2   3   0]\n",
      " [  1  24   6 110  30  30   9]\n",
      " [ 13  15   0  24 141  11   6]\n",
      " [ 11  22   4  23   6  85  59]\n",
      " [  0   0   0   0   3  17 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.71       210\n",
      "           2       0.61      0.73      0.67       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.60      0.52      0.56       210\n",
      "           5       0.59      0.67      0.63       210\n",
      "           6       0.48      0.40      0.44       210\n",
      "           7       0.69      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 94   2  15  11  43  27  18]\n",
      " [  3  90  19  23  37  26  12]\n",
      " [ 22  12 132  22   8  14   0]\n",
      " [  3  11   5  92  39  35  25]\n",
      " [  8   6   0  13 134  19  30]\n",
      " [ 13  14   6  37  18  49  73]\n",
      " [  1   1   0  10   9   5 184]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.45      0.53       210\n",
      "           2       0.66      0.43      0.52       210\n",
      "           3       0.75      0.63      0.68       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.47      0.64      0.54       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.54      0.88      0.67       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.52      1470\n",
      "weighted avg       0.54      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5027210884353741\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[110  14   6  16  32  17  15]\n",
      " [ 16 107  11  22  29  22   3]\n",
      " [  3  12 172  13   4   3   3]\n",
      " [ 19  15   7  79  37  42  11]\n",
      " [ 35  25   2  43  77  17  11]\n",
      " [ 22  21   7  41  18  65  36]\n",
      " [  7   8   2  17  12  35 129]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.52      0.52       210\n",
      "           2       0.53      0.51      0.52       210\n",
      "           3       0.83      0.82      0.82       210\n",
      "           4       0.34      0.38      0.36       210\n",
      "           5       0.37      0.37      0.37       210\n",
      "           6       0.32      0.31      0.32       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.41904761904761906\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  18   6  20  25   6  16]\n",
      " [ 33 107  11  18  26   7   8]\n",
      " [ 21  20 155   8   4   2   0]\n",
      " [ 54  22   4  80  37   7   6]\n",
      " [ 71  30   3  27  59  12   8]\n",
      " [ 80  35   6  32  25  17  15]\n",
      " [ 38  19   2  32  31   9  79]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.57      0.38       210\n",
      "           2       0.43      0.51      0.46       210\n",
      "           3       0.83      0.74      0.78       210\n",
      "           4       0.37      0.38      0.37       210\n",
      "           5       0.29      0.28      0.28       210\n",
      "           6       0.28      0.08      0.13       210\n",
      "           7       0.60      0.38      0.46       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.41      1470\n",
      "weighted avg       0.44      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4387755102040816\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  16   5  15  28   5  18]\n",
      " [ 25 100   7  27  31  12   8]\n",
      " [ 16  20 156   7   7   4   0]\n",
      " [ 42  21   6  74  44  15   8]\n",
      " [ 56  26   2  25  71  13  17]\n",
      " [ 68  24   4  27  35  26  26]\n",
      " [ 25   9   3  25  36  17  95]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.59      0.44       210\n",
      "           2       0.46      0.48      0.47       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.37      0.35      0.36       210\n",
      "           5       0.28      0.34      0.31       210\n",
      "           6       0.28      0.12      0.17       210\n",
      "           7       0.55      0.45      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.43      1470\n",
      "weighted avg       0.45      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.42925170068027213\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  12   5  22  32   5  14]\n",
      " [ 21  88  15  28  35  16   7]\n",
      " [ 16  20 153   8   6   4   3]\n",
      " [ 40  16   6  77  48  13  10]\n",
      " [ 46  23   1  35  77  12  16]\n",
      " [ 61  18   6  33  40  26  26]\n",
      " [ 31   9   0  27  35  18  90]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.57      0.44       210\n",
      "           2       0.47      0.42      0.44       210\n",
      "           3       0.82      0.73      0.77       210\n",
      "           4       0.33      0.37      0.35       210\n",
      "           5       0.28      0.37      0.32       210\n",
      "           6       0.28      0.12      0.17       210\n",
      "           7       0.54      0.43      0.48       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  13   5  23  32   3  14]\n",
      " [ 25  88  15  26  38  10   8]\n",
      " [ 18  20 151   9   5   4   3]\n",
      " [ 35  19   6  81  48  10  11]\n",
      " [ 41  20   2  35  84  13  15]\n",
      " [ 54  23   6  38  40  21  28]\n",
      " [ 21  12   0  29  41  17  90]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.57      0.46       210\n",
      "           2       0.45      0.42      0.43       210\n",
      "           3       0.82      0.72      0.76       210\n",
      "           4       0.34      0.39      0.36       210\n",
      "           5       0.29      0.40      0.34       210\n",
      "           6       0.27      0.10      0.15       210\n",
      "           7       0.53      0.43      0.47       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.42      1470\n",
      "weighted avg       0.44      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4380952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117   8   8  23  38   2  14]\n",
      " [ 26  94  14  26  31  10   9]\n",
      " [ 18  23 151   8   5   4   1]\n",
      " [ 32  19   5  84  48  10  12]\n",
      " [ 41  21   3  38  81   9  17]\n",
      " [ 54  23   6  41  38  21  27]\n",
      " [ 21  11   0  34  36  12  96]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.56      0.45       210\n",
      "           2       0.47      0.45      0.46       210\n",
      "           3       0.81      0.72      0.76       210\n",
      "           4       0.33      0.40      0.36       210\n",
      "           5       0.29      0.39      0.33       210\n",
      "           6       0.31      0.10      0.15       210\n",
      "           7       0.55      0.46      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.43      1470\n",
      "weighted avg       0.45      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.44693877551020406\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117   9   8  21  41   0  14]\n",
      " [ 24  98  15  25  31   7  10]\n",
      " [ 18  22 149  11   5   3   2]\n",
      " [ 32  16   5  90  44  10  13]\n",
      " [ 36  23   4  37  84   9  17]\n",
      " [ 51  25   6  34  44  19  31]\n",
      " [ 21  10   0  27  40  12 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.56      0.46       210\n",
      "           2       0.48      0.47      0.47       210\n",
      "           3       0.80      0.71      0.75       210\n",
      "           4       0.37      0.43      0.40       210\n",
      "           5       0.29      0.40      0.34       210\n",
      "           6       0.32      0.09      0.14       210\n",
      "           7       0.53      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 82  45   8  17  29   6  23]\n",
      " [ 12 103  23  28  25   6  13]\n",
      " [ 13  45 145   4   2   0   1]\n",
      " [ 12  45   4  57  36  21  35]\n",
      " [ 21  40   4  26  79   7  33]\n",
      " [ 17  59   2  32  30  19  51]\n",
      " [ 12  13   0  30  22  22 111]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.39      0.43       210\n",
      "           2       0.29      0.49      0.37       210\n",
      "           3       0.78      0.69      0.73       210\n",
      "           4       0.29      0.27      0.28       210\n",
      "           5       0.35      0.38      0.36       210\n",
      "           6       0.23      0.09      0.13       210\n",
      "           7       0.42      0.53      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.40      1470\n",
      "weighted avg       0.41      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.38979591836734695\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 83  59   8  10  23   4  23]\n",
      " [ 15 115  26  14  21   7  12]\n",
      " [ 18  52 135   2   2   0   1]\n",
      " [ 24  58   6  39  31  19  33]\n",
      " [ 27  52   3  15  74   6  33]\n",
      " [ 23  65   1  26  27  19  49]\n",
      " [ 14  27   0  23  21  17 108]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.40      0.40       210\n",
      "           2       0.27      0.55      0.36       210\n",
      "           3       0.75      0.64      0.69       210\n",
      "           4       0.30      0.19      0.23       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.26      0.09      0.13       210\n",
      "           7       0.42      0.51      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.38      1470\n",
      "weighted avg       0.40      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.5020408163265306\n",
      "Confusion Matrix of SVM is:\n",
      " [[126  17   8  14  27  12   6]\n",
      " [ 20 110  15  23  22  16   4]\n",
      " [  5  17 172   9   3   3   1]\n",
      " [ 27  25   7  85  25  33   8]\n",
      " [ 55  25   2  41  66   9  12]\n",
      " [ 33  27   9  40  15  55  31]\n",
      " [ 11   5   1  21   5  43 124]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.60      0.52       210\n",
      "           2       0.49      0.52      0.50       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.36      0.40      0.38       210\n",
      "           5       0.40      0.31      0.35       210\n",
      "           6       0.32      0.26      0.29       210\n",
      "           7       0.67      0.59      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.46802721088435373\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 79   5   0  22  84   6  14]\n",
      " [  1  73   2  25  90  13   6]\n",
      " [  0  13 144  12  36   4   1]\n",
      " [  1   8   1  86  84  15  15]\n",
      " [  6   8   0  27 147   4  18]\n",
      " [  1   8   1  29  91  39  41]\n",
      " [  1   0   0  15  55  19 120]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.38      0.53       210\n",
      "           2       0.63      0.35      0.45       210\n",
      "           3       0.97      0.69      0.80       210\n",
      "           4       0.40      0.41      0.40       210\n",
      "           5       0.25      0.70      0.37       210\n",
      "           6       0.39      0.19      0.25       210\n",
      "           7       0.56      0.57      0.56       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.58      0.47      0.48      1470\n",
      "weighted avg       0.58      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of SVM is:\n",
      " [[108  21   5  12  37  12  15]\n",
      " [  5 117  11  26  28  20   3]\n",
      " [  5  29 166   4   2   3   1]\n",
      " [ 12  21   7  97  30  29  14]\n",
      " [ 22  24   4  27 105  13  15]\n",
      " [ 13  25   5  32  25  62  48]\n",
      " [  3   4   0  19  10  38 136]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.51      0.57       210\n",
      "           2       0.49      0.56      0.52       210\n",
      "           3       0.84      0.79      0.81       210\n",
      "           4       0.45      0.46      0.45       210\n",
      "           5       0.44      0.50      0.47       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.59      0.65      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.5238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[104  17   6  12  43  13  15]\n",
      " [  8 120   8  20  30  21   3]\n",
      " [  3  17 174   7   3   5   1]\n",
      " [ 12  21   6  94  30  29  18]\n",
      " [ 29  24   3  28  98  11  17]\n",
      " [ 16  26   9  37  23  52  47]\n",
      " [  4   7   0  20  13  38 128]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.50      0.54       210\n",
      "           2       0.52      0.57      0.54       210\n",
      "           3       0.84      0.83      0.84       210\n",
      "           4       0.43      0.45      0.44       210\n",
      "           5       0.41      0.47      0.44       210\n",
      "           6       0.31      0.25      0.27       210\n",
      "           7       0.56      0.61      0.58       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.21700680272108844\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0   0   0 197]\n",
      " [  0   0  15   0   0   0 195]\n",
      " [  0   0 111   0   0   0  99]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   2   0   0   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.73      0.53      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.99      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2578231292517007\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0  77  13   0   0   0 120]\n",
      " [  0  89  15   0   0   0 106]\n",
      " [  0  62 111   0   0   0  37]\n",
      " [  0  55   3   0   0   0 152]\n",
      " [  0  52   3   0   0   0 155]\n",
      " [  0  56   5   0   0   0 149]\n",
      " [  0  29   2   0   0   0 179]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.21      0.42      0.28       210\n",
      "           3       0.73      0.53      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.85      0.32       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.16      0.26      0.17      1470\n",
      "weighted avg       0.16      0.26      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 47  38   5  85   0   0  35]\n",
      " [ 12  77  15  81   0   0  25]\n",
      " [  6  56 111  30   0   0   7]\n",
      " [ 11  44   3 108   0   0  44]\n",
      " [ 21  31   3 101   0   0  54]\n",
      " [ 21  36   4  93   0   0  56]\n",
      " [ 14  15   2  76   0   0 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.22      0.27       210\n",
      "           2       0.26      0.37      0.30       210\n",
      "           3       0.78      0.53      0.63       210\n",
      "           4       0.19      0.51      0.28       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.49      0.39       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.27      0.30      0.27      1470\n",
      "weighted avg       0.27      0.30      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31700680272108844\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  39   3  68  16   0  35]\n",
      " [  4  83   9  80   9   0  25]\n",
      " [  1  59 108  30   5   0   7]\n",
      " [  3  47   0 106  10   0  44]\n",
      " [  6  34   0  99  17   0  54]\n",
      " [  7  37   3  92  15   0  56]\n",
      " [  0  17   0  76  14   0 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.23      0.35       210\n",
      "           2       0.26      0.40      0.32       210\n",
      "           3       0.88      0.51      0.65       210\n",
      "           4       0.19      0.50      0.28       210\n",
      "           5       0.20      0.08      0.11       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.49      0.39       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.36      0.32      0.30      1470\n",
      "weighted avg       0.36      0.32      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31360544217687075\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[51 39  3 49 40  0 28]\n",
      " [ 7 77  8 55 39  1 23]\n",
      " [ 0 33 95 25 49  1  7]\n",
      " [ 2 41  4 68 58  0 37]\n",
      " [ 4 34  0 48 77  0 47]\n",
      " [ 3 38  8 56 56  0 49]\n",
      " [ 0 17  0 49 51  0 93]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.24      0.37       210\n",
      "           2       0.28      0.37      0.31       210\n",
      "           3       0.81      0.45      0.58       210\n",
      "           4       0.19      0.32      0.24       210\n",
      "           5       0.21      0.37      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.33      0.44      0.38       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.37      0.31      0.31      1470\n",
      "weighted avg       0.37      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3013605442176871\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[59 33  2 50 33  9 24]\n",
      " [ 9 69  7 56 36 11 22]\n",
      " [15 66 90 21  5  6  7]\n",
      " [ 8 33  5 65 49 15 35]\n",
      " [11 26  0 49 65 13 46]\n",
      " [10 30  7 60 46 15 42]\n",
      " [ 6  8  3 48 44 21 80]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.28      0.36       210\n",
      "           2       0.26      0.33      0.29       210\n",
      "           3       0.79      0.43      0.56       210\n",
      "           4       0.19      0.31      0.23       210\n",
      "           5       0.23      0.31      0.27       210\n",
      "           6       0.17      0.07      0.10       210\n",
      "           7       0.31      0.38      0.34       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.35      0.30      0.31      1470\n",
      "weighted avg       0.35      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3074829931972789\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[63 49  0 44 20 26  8]\n",
      " [19 86  4 45 25 26  5]\n",
      " [ 9 41 90 23 36  9  2]\n",
      " [12 47  1 87 24 28 11]\n",
      " [16 32  1 68 40 37 16]\n",
      " [16 36  5 73 23 33 24]\n",
      " [ 6 18  0 66 19 48 53]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.30      0.36       210\n",
      "           2       0.28      0.41      0.33       210\n",
      "           3       0.89      0.43      0.58       210\n",
      "           4       0.21      0.41      0.28       210\n",
      "           5       0.21      0.19      0.20       210\n",
      "           6       0.16      0.16      0.16       210\n",
      "           7       0.45      0.25      0.32       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.38      0.31      0.32      1470\n",
      "weighted avg       0.38      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[78 35  2 42 28 19  6]\n",
      " [27 70 12 43 27 22  9]\n",
      " [48 35 92 20  9  6  0]\n",
      " [17 31  6 71 43 27 15]\n",
      " [25 28  3 51 55 37 11]\n",
      " [28 28  7 56 44 21 26]\n",
      " [21 14  0 33 51 38 53]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.37      0.34       210\n",
      "           2       0.29      0.33      0.31       210\n",
      "           3       0.75      0.44      0.55       210\n",
      "           4       0.22      0.34      0.27       210\n",
      "           5       0.21      0.26      0.24       210\n",
      "           6       0.12      0.10      0.11       210\n",
      "           7       0.44      0.25      0.32       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.34      0.30      0.31      1470\n",
      "weighted avg       0.34      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[71 33  1 39 38 18 10]\n",
      " [25 68 10 39 33 23 12]\n",
      " [11 29 95 19 44  6  6]\n",
      " [19 24  7 73 44 26 17]\n",
      " [24 25  0 45 65 32 19]\n",
      " [24 29  5 54 47 22 29]\n",
      " [18 16  0 39 46 32 59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.34      0.35       210\n",
      "           2       0.30      0.32      0.31       210\n",
      "           3       0.81      0.45      0.58       210\n",
      "           4       0.24      0.35      0.28       210\n",
      "           5       0.21      0.31      0.25       210\n",
      "           6       0.14      0.10      0.12       210\n",
      "           7       0.39      0.28      0.33       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.35      0.31      0.32      1470\n",
      "weighted avg       0.35      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.29183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[58 41  2 36 35 24 14]\n",
      " [16 70  9 42 28 32 13]\n",
      " [20 33 91  8 38 15  5]\n",
      " [28 27  3 52 37 42 21]\n",
      " [22 22  1 44 57 40 24]\n",
      " [25 22  9 44 44 37 29]\n",
      " [27 13  0 38 37 31 64]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.28      0.29       210\n",
      "           2       0.31      0.33      0.32       210\n",
      "           3       0.79      0.43      0.56       210\n",
      "           4       0.20      0.25      0.22       210\n",
      "           5       0.21      0.27      0.23       210\n",
      "           6       0.17      0.18      0.17       210\n",
      "           7       0.38      0.30      0.34       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.33      0.29      0.30      1470\n",
      "weighted avg       0.33      0.29      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[70 27  5 35 34 28 11]\n",
      " [16 67 13 27 30 43 14]\n",
      " [10 31 99  8  4 18 40]\n",
      " [23 27  8 47 30 58 17]\n",
      " [21 22  2 35 52 56 22]\n",
      " [19 26  7 45 36 43 34]\n",
      " [19 12  0 30 30 53 66]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.33      0.36       210\n",
      "           2       0.32      0.32      0.32       210\n",
      "           3       0.74      0.47      0.58       210\n",
      "           4       0.21      0.22      0.22       210\n",
      "           5       0.24      0.25      0.24       210\n",
      "           6       0.14      0.20      0.17       210\n",
      "           7       0.32      0.31      0.32       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.34      0.30      0.31      1470\n",
      "weighted avg       0.34      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[64 29  4 40 35 22 16]\n",
      " [22 72 12 34 27 29 14]\n",
      " [11 28 96 51  7 11  6]\n",
      " [16 29  9 56 38 45 17]\n",
      " [24 19  2 48 59 37 21]\n",
      " [23 25 11 51 34 36 30]\n",
      " [26 15  1 36 38 37 57]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.30      0.32       210\n",
      "           2       0.33      0.34      0.34       210\n",
      "           3       0.71      0.46      0.56       210\n",
      "           4       0.18      0.27      0.21       210\n",
      "           5       0.25      0.28      0.26       210\n",
      "           6       0.17      0.17      0.17       210\n",
      "           7       0.35      0.27      0.31       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.33      0.30      0.31      1470\n",
      "weighted avg       0.33      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  19   6  37  29  31  13]\n",
      " [ 23  62  12  43  27  31  12]\n",
      " [ 10  65 103  10   8   9   5]\n",
      " [ 28  22  11  51  26  52  20]\n",
      " [ 30  19   6  43  57  35  20]\n",
      " [ 21  24   6  46  28  46  39]\n",
      " [ 31  13   1  33  33  40  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.36      0.35       210\n",
      "           2       0.28      0.30      0.29       210\n",
      "           3       0.71      0.49      0.58       210\n",
      "           4       0.19      0.24      0.22       210\n",
      "           5       0.27      0.27      0.27       210\n",
      "           6       0.19      0.22      0.20       210\n",
      "           7       0.35      0.28      0.31       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.32      1470\n",
      "weighted avg       0.33      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.31360544217687075\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[81 18  7 33 28 27 16]\n",
      " [21 69  9 31 31 35 14]\n",
      " [16 26 99 11 10  9 39]\n",
      " [35 32  6 42 32 44 19]\n",
      " [34 18  7 46 53 29 23]\n",
      " [22 21  9 40 30 50 38]\n",
      " [25 15  1 35 24 43 67]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.39      0.36       210\n",
      "           2       0.35      0.33      0.34       210\n",
      "           3       0.72      0.47      0.57       210\n",
      "           4       0.18      0.20      0.19       210\n",
      "           5       0.25      0.25      0.25       210\n",
      "           6       0.21      0.24      0.22       210\n",
      "           7       0.31      0.32      0.31       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.34      0.31      0.32      1470\n",
      "weighted avg       0.34      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.308843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  21   6  31  32  23  18]\n",
      " [ 21  72  13  24  28  34  18]\n",
      " [ 12  29 104  44   7  10   4]\n",
      " [ 34  31   8  41  25  51  20]\n",
      " [ 33  13   5  36  58  37  28]\n",
      " [ 30  21  12  36  31  40  40]\n",
      " [ 31  12   2  34  28  43  60]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.38      0.35       210\n",
      "           2       0.36      0.34      0.35       210\n",
      "           3       0.69      0.50      0.58       210\n",
      "           4       0.17      0.20      0.18       210\n",
      "           5       0.28      0.28      0.28       210\n",
      "           6       0.17      0.19      0.18       210\n",
      "           7       0.32      0.29      0.30       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.32      1470\n",
      "weighted avg       0.33      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 77  23   9  30  26  24  21]\n",
      " [ 24  71  19  27  24  29  16]\n",
      " [ 18  25 135  11   9  10   2]\n",
      " [ 38  26  13  40  32  42  19]\n",
      " [ 26  21   8  39  53  39  24]\n",
      " [ 31  29  12  40  28  37  33]\n",
      " [ 25  21   2  29  27  47  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.37      0.34       210\n",
      "           2       0.33      0.34      0.33       210\n",
      "           3       0.68      0.64      0.66       210\n",
      "           4       0.19      0.19      0.19       210\n",
      "           5       0.27      0.25      0.26       210\n",
      "           6       0.16      0.18      0.17       210\n",
      "           7       0.34      0.28      0.31       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.33      0.32      0.32      1470\n",
      "weighted avg       0.33      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3040816326530612\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[74 22  9 22 41 24 18]\n",
      " [27 70 14 23 29 32 15]\n",
      " [49 27 99 10  8 13  4]\n",
      " [39 30 10 35 29 48 19]\n",
      " [35 13  3 35 57 36 31]\n",
      " [24 24 12 34 35 43 38]\n",
      " [26 16  2 27 29 41 69]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.35      0.31       210\n",
      "           2       0.35      0.33      0.34       210\n",
      "           3       0.66      0.47      0.55       210\n",
      "           4       0.19      0.17      0.18       210\n",
      "           5       0.25      0.27      0.26       210\n",
      "           6       0.18      0.20      0.19       210\n",
      "           7       0.36      0.33      0.34       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.31      1470\n",
      "weighted avg       0.32      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3258503401360544\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  18  10  23  40  23  16]\n",
      " [ 20  68  13  25  28  37  19]\n",
      " [ 12  29 135  11  10  11   2]\n",
      " [ 33  34   9  38  31  44  21]\n",
      " [ 29  24   4  31  61  39  22]\n",
      " [ 30  27   7  34  35  37  40]\n",
      " [ 27  19   1  28  27  48  60]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.38      0.36       210\n",
      "           2       0.31      0.32      0.32       210\n",
      "           3       0.75      0.64      0.69       210\n",
      "           4       0.20      0.18      0.19       210\n",
      "           5       0.26      0.29      0.28       210\n",
      "           6       0.15      0.18      0.16       210\n",
      "           7       0.33      0.29      0.31       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.34      0.33      0.33      1470\n",
      "weighted avg       0.34      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3292517006802721\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  22   6  25  32  24  15]\n",
      " [ 22  66  12  28  31  30  21]\n",
      " [ 14  27 136  10  10   8   5]\n",
      " [ 36  30   8  34  32  47  23]\n",
      " [ 35  20   5  39  55  28  28]\n",
      " [ 31  21  11  26  37  41  43]\n",
      " [ 24  18   2  23  31  46  66]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.41      0.38       210\n",
      "           2       0.32      0.31      0.32       210\n",
      "           3       0.76      0.65      0.70       210\n",
      "           4       0.18      0.16      0.17       210\n",
      "           5       0.24      0.26      0.25       210\n",
      "           6       0.18      0.20      0.19       210\n",
      "           7       0.33      0.31      0.32       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.34      0.33      0.33      1470\n",
      "weighted avg       0.34      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.33537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  26   7  20  31  20  24]\n",
      " [ 20  72  15  25  27  29  22]\n",
      " [ 15  26 142   5   7  12   3]\n",
      " [ 30  30  12  45  27  45  21]\n",
      " [ 30  25   7  37  50  37  24]\n",
      " [ 32  23  11  30  37  35  42]\n",
      " [ 30  14   0  28  31  40  67]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.39      0.37       210\n",
      "           2       0.33      0.34      0.34       210\n",
      "           3       0.73      0.68      0.70       210\n",
      "           4       0.24      0.21      0.23       210\n",
      "           5       0.24      0.24      0.24       210\n",
      "           6       0.16      0.17      0.16       210\n",
      "           7       0.33      0.32      0.32       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.34      0.34      0.34      1470\n",
      "weighted avg       0.34      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3081632653061224\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  20   8  28  32  27  16]\n",
      " [ 22  71  15  24  29  32  17]\n",
      " [ 11  30 103  43  11   8   4]\n",
      " [ 35  36   8  36  26  40  29]\n",
      " [ 33  16   7  38  54  37  25]\n",
      " [ 29  21  10  25  41  46  38]\n",
      " [ 33  14   4  27  20  48  64]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.38      0.35       210\n",
      "           2       0.34      0.34      0.34       210\n",
      "           3       0.66      0.49      0.56       210\n",
      "           4       0.16      0.17      0.17       210\n",
      "           5       0.25      0.26      0.26       210\n",
      "           6       0.19      0.22      0.21       210\n",
      "           7       0.33      0.30      0.32       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.31      1470\n",
      "weighted avg       0.32      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.2857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 25   8  24  11   6   5 131]\n",
      " [ 12  21  53   7   7   0 110]\n",
      " [  3  10 162   7   2   0  26]\n",
      " [  6  10  15  11   6   3 159]\n",
      " [  2   7  11   7   2   1 180]\n",
      " [ 10  10  20   8   3   7 152]\n",
      " [  4   1   1   5   5   2 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.12      0.18       210\n",
      "           2       0.31      0.10      0.15       210\n",
      "           3       0.57      0.77      0.65       210\n",
      "           4       0.20      0.05      0.08       210\n",
      "           5       0.06      0.01      0.02       210\n",
      "           6       0.39      0.03      0.06       210\n",
      "           7       0.20      0.91      0.33       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.31      0.29      0.21      1470\n",
      "weighted avg       0.31      0.29      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.33877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 45  52  13   5   4   2  89]\n",
      " [ 12  88  30   8   8   1  63]\n",
      " [ 12  37 149   3   1   0   8]\n",
      " [ 12  47   8  22  10   4 107]\n",
      " [ 17  25   8  10  10   0 140]\n",
      " [ 11  57   6   8   5   4 119]\n",
      " [  5  11   0   4   7   3 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.21      0.28       210\n",
      "           2       0.28      0.42      0.33       210\n",
      "           3       0.70      0.71      0.70       210\n",
      "           4       0.37      0.10      0.16       210\n",
      "           5       0.22      0.05      0.08       210\n",
      "           6       0.29      0.02      0.04       210\n",
      "           7       0.25      0.86      0.39       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.36      0.34      0.28      1470\n",
      "weighted avg       0.36      0.34      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.373469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 67  49   6  15  16   2  55]\n",
      " [  9 109  17  14  15   5  41]\n",
      " [  7  48 145   0   5   2   3]\n",
      " [  9  55   4  33  15   5  89]\n",
      " [ 19  42   4  20  25   1  99]\n",
      " [ 20  66   2  14   9   7  92]\n",
      " [  5  16   0  16   6   4 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.32      0.39       210\n",
      "           2       0.28      0.52      0.37       210\n",
      "           3       0.81      0.69      0.75       210\n",
      "           4       0.29      0.16      0.20       210\n",
      "           5       0.27      0.12      0.17       210\n",
      "           6       0.27      0.03      0.06       210\n",
      "           7       0.30      0.78      0.43       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.34      1470\n",
      "weighted avg       0.39      0.37      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.39931972789115644\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 71  47   7  14  23   6  42]\n",
      " [  4 125  10  14  21   5  31]\n",
      " [ 10  48 145   2   4   0   1]\n",
      " [ 10  61   6  32  30   9  62]\n",
      " [ 18  50   1  20  60   0  61]\n",
      " [ 13  69   1  25  15   9  78]\n",
      " [  6  22   0  22  11   4 145]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.34      0.42       210\n",
      "           2       0.30      0.60      0.40       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.25      0.15      0.19       210\n",
      "           5       0.37      0.29      0.32       210\n",
      "           6       0.27      0.04      0.07       210\n",
      "           7       0.35      0.69      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.37      1470\n",
      "weighted avg       0.42      0.40      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 71  36   7  25  27   3  41]\n",
      " [  5 119   9  30  24   2  21]\n",
      " [  8  43 146   4   6   2   1]\n",
      " [  1  43   5  53  41  15  52]\n",
      " [  7  36   4  34  66   8  55]\n",
      " [ 10  56   3  30  30  10  71]\n",
      " [  2  13   0  29  14  11 141]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.34      0.45       210\n",
      "           2       0.34      0.57      0.43       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.26      0.25      0.26       210\n",
      "           5       0.32      0.31      0.32       210\n",
      "           6       0.20      0.05      0.08       210\n",
      "           7       0.37      0.67      0.48       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.43      0.41      0.39      1470\n",
      "weighted avg       0.43      0.41      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43945578231292515\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78  34   4  25  30   6  33]\n",
      " [  7 122   6  25  22   9  19]\n",
      " [  4  41 149   6   6   2   2]\n",
      " [  5  47   1  61  32  14  50]\n",
      " [  5  40   2  29  83   4  47]\n",
      " [ 10  51   1  32  32  22  62]\n",
      " [  2  10   0  36  23   8 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.37      0.49       210\n",
      "           2       0.35      0.58      0.44       210\n",
      "           3       0.91      0.71      0.80       210\n",
      "           4       0.29      0.29      0.29       210\n",
      "           5       0.36      0.40      0.38       210\n",
      "           6       0.34      0.10      0.16       210\n",
      "           7       0.38      0.62      0.47       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.43      1470\n",
      "weighted avg       0.48      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 82  34   5  16  31  11  31]\n",
      " [  7 119   6  31  23   6  18]\n",
      " [  8  40 145   9   3   3   2]\n",
      " [ 10  39   4  60  33  20  44]\n",
      " [ 13  33   3  37  81   6  37]\n",
      " [ 12  46   0  38  29  26  59]\n",
      " [  6   8   0  30  27  14 125]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.39      0.47       210\n",
      "           2       0.37      0.57      0.45       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.27      0.29      0.28       210\n",
      "           5       0.36      0.39      0.37       210\n",
      "           6       0.30      0.12      0.18       210\n",
      "           7       0.40      0.60      0.48       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.43      1470\n",
      "weighted avg       0.45      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 82  30   5  20  38  12  23]\n",
      " [  7 114   6  26  28  13  16]\n",
      " [  9  38 147   9   4   2   1]\n",
      " [  7  34   5  59  46  25  34]\n",
      " [ 12  35   2  32  84  10  35]\n",
      " [  9  45   3  31  36  31  55]\n",
      " [  1  12   0  30  28  15 124]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.39      0.49       210\n",
      "           2       0.37      0.54      0.44       210\n",
      "           3       0.88      0.70      0.78       210\n",
      "           4       0.29      0.28      0.28       210\n",
      "           5       0.32      0.40      0.35       210\n",
      "           6       0.29      0.15      0.19       210\n",
      "           7       0.43      0.59      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.43      1470\n",
      "weighted avg       0.46      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 80  32   5  17  41  13  22]\n",
      " [  9 117   6  20  30  18  10]\n",
      " [  6  34 151   8   3   7   1]\n",
      " [  5  28   3  78  41  22  33]\n",
      " [ 12  32   3  34  96   6  27]\n",
      " [ 10  39   3  38  35  28  57]\n",
      " [  9   6   0  33  20  22 120]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.38      0.47       210\n",
      "           2       0.41      0.56      0.47       210\n",
      "           3       0.88      0.72      0.79       210\n",
      "           4       0.34      0.37      0.36       210\n",
      "           5       0.36      0.46      0.40       210\n",
      "           6       0.24      0.13      0.17       210\n",
      "           7       0.44      0.57      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.45      1470\n",
      "weighted avg       0.47      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45510204081632655\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 86  28   7  23  40  10  16]\n",
      " [  6 112   7  29  26  19  11]\n",
      " [  8  32 152   8   2   5   3]\n",
      " [  8  31   4  74  40  23  30]\n",
      " [ 15  27   2  35  92  11  28]\n",
      " [ 11  40   2  32  39  36  50]\n",
      " [  5   7   0  30  26  25 117]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.41      0.49       210\n",
      "           2       0.40      0.53      0.46       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.32      0.35      0.34       210\n",
      "           5       0.35      0.44      0.39       210\n",
      "           6       0.28      0.17      0.21       210\n",
      "           7       0.46      0.56      0.50       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.45      1470\n",
      "weighted avg       0.47      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87  24   6  25  43   6  19]\n",
      " [ 12 116   7  24  27  17   7]\n",
      " [  8  34 152   7   2   4   3]\n",
      " [ 14  33   4  64  33  27  35]\n",
      " [ 16  26   2  37  77  20  32]\n",
      " [  9  46   2  35  37  31  50]\n",
      " [  4   6   0  33  19  27 121]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.41      0.48       210\n",
      "           2       0.41      0.55      0.47       210\n",
      "           3       0.88      0.72      0.79       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.32      0.37      0.34       210\n",
      "           6       0.23      0.15      0.18       210\n",
      "           7       0.45      0.58      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87  32   8  17  41  10  15]\n",
      " [ 13 112   8  22  26  18  11]\n",
      " [  9  24 157   8   4   7   1]\n",
      " [  5  31   5  68  42  30  29]\n",
      " [ 19  27   1  30  89  17  27]\n",
      " [ 15  39   1  36  27  42  50]\n",
      " [  8   5   0  25  26  21 125]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.41      0.48       210\n",
      "           2       0.41      0.53      0.47       210\n",
      "           3       0.87      0.75      0.81       210\n",
      "           4       0.33      0.32      0.33       210\n",
      "           5       0.35      0.42      0.38       210\n",
      "           6       0.29      0.20      0.24       210\n",
      "           7       0.48      0.60      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46258503401360546\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  24   7  19  36  12  19]\n",
      " [ 11 111   7  18  30  25   8]\n",
      " [  8  33 155   4   1   7   2]\n",
      " [ 11  30   3  68  38  27  33]\n",
      " [ 17  29   2  29  90  12  31]\n",
      " [ 17  36   0  39  31  41  46]\n",
      " [  4   3   0  25  24  32 122]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.44      0.50       210\n",
      "           2       0.42      0.53      0.47       210\n",
      "           3       0.89      0.74      0.81       210\n",
      "           4       0.34      0.32      0.33       210\n",
      "           5       0.36      0.43      0.39       210\n",
      "           6       0.26      0.20      0.22       210\n",
      "           7       0.47      0.58      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  23   6  16  44  21  17]\n",
      " [ 13 110  10  26  26  16   9]\n",
      " [  6  24 156   7   2  11   4]\n",
      " [ 13  28   3  64  33  39  30]\n",
      " [ 22  34   1  40  74  12  27]\n",
      " [ 12  39   3  29  36  39  52]\n",
      " [  9   9   0  33  17  25 117]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.40      0.45       210\n",
      "           2       0.41      0.52      0.46       210\n",
      "           3       0.87      0.74      0.80       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.32      0.35      0.33       210\n",
      "           6       0.24      0.19      0.21       210\n",
      "           7       0.46      0.56      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  26   7  20  40  17  17]\n",
      " [ 13 116   6  22  26  20   7]\n",
      " [  7  27 155  11   4   6   0]\n",
      " [ 11  30   6  65  38  32  28]\n",
      " [ 16  27   3  32  87  13  32]\n",
      " [ 15  40   1  27  39  40  48]\n",
      " [  5   6   0  32  19  24 124]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.40      0.46       210\n",
      "           2       0.43      0.55      0.48       210\n",
      "           3       0.87      0.74      0.80       210\n",
      "           4       0.31      0.31      0.31       210\n",
      "           5       0.34      0.41      0.38       210\n",
      "           6       0.26      0.19      0.22       210\n",
      "           7       0.48      0.59      0.53       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.45      1470\n",
      "weighted avg       0.46      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 84  25   6  22  38  20  15]\n",
      " [ 11 110   6  24  30  19  10]\n",
      " [  7  29 158   6   2   7   1]\n",
      " [ 14  21   5  64  39  42  25]\n",
      " [ 22  27   5  28  84  11  33]\n",
      " [ 13  35   2  34  32  53  41]\n",
      " [  7   8   0  23  19  35 118]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.40      0.46       210\n",
      "           2       0.43      0.52      0.47       210\n",
      "           3       0.87      0.75      0.81       210\n",
      "           4       0.32      0.30      0.31       210\n",
      "           5       0.34      0.40      0.37       210\n",
      "           6       0.28      0.25      0.27       210\n",
      "           7       0.49      0.56      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.46598639455782315\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 88  29   9  13  39  16  16]\n",
      " [ 12 109  10  23  31  17   8]\n",
      " [  4  27 160   9   3   6   1]\n",
      " [ 12  27   4  78  37  23  29]\n",
      " [ 20  30   3  29  84  19  25]\n",
      " [ 19  37   4  36  31  40  43]\n",
      " [  6   2   0  30  19  27 126]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.42      0.47       210\n",
      "           2       0.42      0.52      0.46       210\n",
      "           3       0.84      0.76      0.80       210\n",
      "           4       0.36      0.37      0.36       210\n",
      "           5       0.34      0.40      0.37       210\n",
      "           6       0.27      0.19      0.22       210\n",
      "           7       0.51      0.60      0.55       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.46      1470\n",
      "weighted avg       0.47      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.463265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  20   5  13  41  15  23]\n",
      " [ 10 114  12  21  31  15   7]\n",
      " [  9  25 155   9   4   6   2]\n",
      " [ 15  21   6  79  35  26  28]\n",
      " [ 22  33   1  32  85  12  25]\n",
      " [ 12  34   1  26  39  41  57]\n",
      " [  8   4   0  27  27  30 114]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.44      0.49       210\n",
      "           2       0.45      0.54      0.49       210\n",
      "           3       0.86      0.74      0.79       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.32      0.40      0.36       210\n",
      "           6       0.28      0.20      0.23       210\n",
      "           7       0.45      0.54      0.49       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.445578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  26   5  16  41  12  20]\n",
      " [  9 106   6  27  28  23  11]\n",
      " [ 10  30 154   8   3   3   2]\n",
      " [ 13  31   4  68  30  30  34]\n",
      " [ 16  33   4  33  80  18  26]\n",
      " [ 19  35   2  37  29  41  47]\n",
      " [  9   6   0  25  24  30 116]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.43      0.48       210\n",
      "           2       0.40      0.50      0.44       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.32      0.32      0.32       210\n",
      "           5       0.34      0.38      0.36       210\n",
      "           6       0.26      0.20      0.22       210\n",
      "           7       0.45      0.55      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46190476190476193\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95  21   7  14  34  16  23]\n",
      " [ 10 108  11  31  26  17   7]\n",
      " [  7  35 152   5   4   4   3]\n",
      " [ 17  21   4  73  40  27  28]\n",
      " [ 27  27   3  26  86  18  23]\n",
      " [ 12  41   0  38  29  44  46]\n",
      " [  6   6   0  26  25  26 121]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.45      0.49       210\n",
      "           2       0.42      0.51      0.46       210\n",
      "           3       0.86      0.72      0.79       210\n",
      "           4       0.34      0.35      0.35       210\n",
      "           5       0.35      0.41      0.38       210\n",
      "           6       0.29      0.21      0.24       210\n",
      "           7       0.48      0.58      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.47      0.46      0.46      1470\n",
      "weighted avg       0.47      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96  25   6  21  35  10  17]\n",
      " [  9 107  16  26  25  17  10]\n",
      " [ 12  26 158   7   4   3   0]\n",
      " [ 20  23   7  74  30  29  27]\n",
      " [ 21  30   3  30  80  19  27]\n",
      " [ 13  33   6  39  28  38  53]\n",
      " [  8   7   0  29  24  35 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.46      0.49       210\n",
      "           2       0.43      0.51      0.46       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.33      0.35      0.34       210\n",
      "           5       0.35      0.38      0.37       210\n",
      "           6       0.25      0.18      0.21       210\n",
      "           7       0.44      0.51      0.47       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3925170068027211\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 89  50   9  11  21   6  24]\n",
      " [ 16 106  31  17  19   7  14]\n",
      " [ 18  46 141   2   2   0   1]\n",
      " [ 23  55   7  40  29  21  35]\n",
      " [ 26  49   4  17  73   6  35]\n",
      " [ 23  64   5  24  25  19  50]\n",
      " [ 14  22   0  24  22  19 109]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.42      0.42       210\n",
      "           2       0.27      0.50      0.35       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.30      0.19      0.23       210\n",
      "           5       0.38      0.35      0.36       210\n",
      "           6       0.24      0.09      0.13       210\n",
      "           7       0.41      0.52      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.38      1470\n",
      "weighted avg       0.39      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//xlm_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = standard_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=2000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "tv_dt_model = DecisionTreeClassifier(random_state=3)\n",
    "ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "tv_rf_model = RandomForestClassifier(random_state=3)\n",
    "ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# scaling using MinMax scaler\n",
    "mms_scale=MinMaxScaler(feature_range=(0,10))\n",
    "m_train=mms_scale.fit_transform(x_train)\n",
    "m_test=mms_scale.fit_transform(x_test)\n",
    "np.set_printoptions(precision=3)\n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,m_train,m_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
