{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a97c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc7a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kabita_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4900 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kabita_labels\n",
       "0                 7\n",
       "1                 7\n",
       "2                 4\n",
       "3                 2\n",
       "4                 7\n",
       "...             ...\n",
       "4895              1\n",
       "4896              1\n",
       "4897              1\n",
       "4898              4\n",
       "4899              1\n",
       "\n",
       "[4900 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading labels\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Kabita//Input//kabita_dataset_labels.csv\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26cff74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b881f",
   "metadata": {},
   "source": [
    "### Data split for TFIDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5044766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.753061224489796\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[169   0   0   5  14  21   1]\n",
      " [  0 163  12   6   8  21   0]\n",
      " [  0   1 181  10   0  18   0]\n",
      " [  1   8  14 160   5  19   3]\n",
      " [ 23  13  16  21 129   2   6]\n",
      " [  1   4   4  24   2 139  36]\n",
      " [  0   2   0   4   1  37 166]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.80      0.84       210\n",
      "           2       0.85      0.78      0.81       210\n",
      "           3       0.80      0.86      0.83       210\n",
      "           4       0.70      0.76      0.73       210\n",
      "           5       0.81      0.61      0.70       210\n",
      "           6       0.54      0.66      0.60       210\n",
      "           7       0.78      0.79      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.76      1470\n",
      "weighted avg       0.76      0.75      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.5591836734693878\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   6   3   9   7  50   0]\n",
      " [  7 149  20   6   6  22   0]\n",
      " [ 10   4 171   7   1  17   0]\n",
      " [ 25  13  18 106   0  46   2]\n",
      " [ 53  28  19  14  31  63   2]\n",
      " [ 17  14   6  17   1 131  24]\n",
      " [  2   6   0   6   1  96  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.64      0.59       210\n",
      "           2       0.68      0.71      0.69       210\n",
      "           3       0.72      0.81      0.77       210\n",
      "           4       0.64      0.50      0.57       210\n",
      "           5       0.66      0.15      0.24       210\n",
      "           6       0.31      0.62      0.41       210\n",
      "           7       0.78      0.47      0.59       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.62      0.56      0.55      1470\n",
      "weighted avg       0.62      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5612244897959183\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   5   3   9   9  45   0]\n",
      " [  6 145  15  10   9  25   0]\n",
      " [ 11   2 170   9   2  16   0]\n",
      " [ 21  14  19 113   1  40   2]\n",
      " [ 46  43  26  19  26  48   2]\n",
      " [ 16  13   6  17   0 137  21]\n",
      " [  2  21   3   5   0  84  95]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.66      0.62       210\n",
      "           2       0.60      0.69      0.64       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.62      0.54      0.58       210\n",
      "           5       0.55      0.12      0.20       210\n",
      "           6       0.35      0.65      0.45       210\n",
      "           7       0.79      0.45      0.58       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.60      0.56      0.55      1470\n",
      "weighted avg       0.60      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134   8   3  10  12  43   0]\n",
      " [  7 146  17   9   6  24   1]\n",
      " [ 10   3 168  11   1  17   0]\n",
      " [  9  16  18 118   0  48   1]\n",
      " [ 40  46  25  25  21  51   2]\n",
      " [  8  19   7  18   0 138  20]\n",
      " [  2  20   6   8   0  82  92]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.64      0.64       210\n",
      "           2       0.57      0.70      0.62       210\n",
      "           3       0.69      0.80      0.74       210\n",
      "           4       0.59      0.56      0.58       210\n",
      "           5       0.53      0.10      0.17       210\n",
      "           6       0.34      0.66      0.45       210\n",
      "           7       0.79      0.44      0.56       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.54      1470\n",
      "weighted avg       0.59      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.5482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[132   9   2   8   9  50   0]\n",
      " [  7 145  17   9   5  27   0]\n",
      " [  7   5 172  10   1  15   0]\n",
      " [ 11  20  18 118   0  43   0]\n",
      " [ 42  41  26  23  20  56   2]\n",
      " [  6  26   7  17   0 137  17]\n",
      " [  1  23   7   8   0  89  82]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.63      0.63       210\n",
      "           2       0.54      0.69      0.61       210\n",
      "           3       0.69      0.82      0.75       210\n",
      "           4       0.61      0.56      0.59       210\n",
      "           5       0.57      0.10      0.16       210\n",
      "           6       0.33      0.65      0.44       210\n",
      "           7       0.81      0.39      0.53       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.53      1470\n",
      "weighted avg       0.60      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.5408163265306123\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121   8   4   8   5  64   0]\n",
      " [  3 145  19   9   6  28   0]\n",
      " [  7   2 173  10   1  17   0]\n",
      " [ 10  22  17 112   2  47   0]\n",
      " [ 38  44  23  23  20  61   1]\n",
      " [  3  19   5  17   0 148  18]\n",
      " [  1  25   4   4   0 100  76]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.55      0.69      0.61       210\n",
      "           3       0.71      0.82      0.76       210\n",
      "           4       0.61      0.53      0.57       210\n",
      "           5       0.59      0.10      0.16       210\n",
      "           6       0.32      0.70      0.44       210\n",
      "           7       0.80      0.36      0.50       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.52      1470\n",
      "weighted avg       0.60      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.5401360544217687\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  11   4   5   3  64   0]\n",
      " [  3 143  20  11   4  29   0]\n",
      " [  7   2 173  10   1  17   0]\n",
      " [ 10  18  18 111   1  52   0]\n",
      " [ 38  41  24  22  19  65   1]\n",
      " [  4  15   5  14   0 156  16]\n",
      " [  1  20   3   5   0 112  69]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.59      0.62       210\n",
      "           2       0.57      0.68      0.62       210\n",
      "           3       0.70      0.82      0.76       210\n",
      "           4       0.62      0.53      0.57       210\n",
      "           5       0.68      0.09      0.16       210\n",
      "           6       0.32      0.74      0.44       210\n",
      "           7       0.80      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.52      1470\n",
      "weighted avg       0.62      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.5653061224489796\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[153   2   8  20  21   4   2]\n",
      " [  9 122  66   7   3   2   1]\n",
      " [  5   6 193   5   0   0   1]\n",
      " [ 19  21  40 112   9   6   3]\n",
      " [ 75  13  13  44  56   6   3]\n",
      " [ 25  32  42  29   5  41  36]\n",
      " [ 11  13   4   4   0  24 154]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.73      0.60       210\n",
      "           2       0.58      0.58      0.58       210\n",
      "           3       0.53      0.92      0.67       210\n",
      "           4       0.51      0.53      0.52       210\n",
      "           5       0.60      0.27      0.37       210\n",
      "           6       0.49      0.20      0.28       210\n",
      "           7       0.77      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.54      1470\n",
      "weighted avg       0.57      0.57      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes is: 0.7136054421768707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   1  10   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  11  32 143   6   8   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  12  44  18   5  97  28]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       210\n",
      "           2       0.78      0.77      0.77       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.74      0.68      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.64      0.46      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM is: 0.7571428571428571\n",
      "Confusion Matrix of SVM is:\n",
      " [[170   1   1   5  18  14   1]\n",
      " [  0 169  10   9   2  20   0]\n",
      " [  0   5 179  10   0  16   0]\n",
      " [  0   9  15 158   3  22   3]\n",
      " [ 21  18  14  19 131   1   6]\n",
      " [  1   6   1  22   2 139  39]\n",
      " [  0   2   0   5   1  35 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.81      0.85       210\n",
      "           2       0.80      0.80      0.80       210\n",
      "           3       0.81      0.85      0.83       210\n",
      "           4       0.69      0.75      0.72       210\n",
      "           5       0.83      0.62      0.71       210\n",
      "           6       0.56      0.66      0.61       210\n",
      "           7       0.77      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.6680272108843538\n",
      "Confusion Matrix of SVM is:\n",
      " [[121   0   0   8  28  51   2]\n",
      " [  1 141   8  12  18  29   1]\n",
      " [  5   2 172  10   3  18   0]\n",
      " [  7   6   9 141   7  37   3]\n",
      " [ 15   6   5  20 117  43   4]\n",
      " [  5   4   1  15   4 143  38]\n",
      " [  0   0   0   1   1  61 147]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.58      0.66       210\n",
      "           2       0.89      0.67      0.76       210\n",
      "           3       0.88      0.82      0.85       210\n",
      "           4       0.68      0.67      0.68       210\n",
      "           5       0.66      0.56      0.60       210\n",
      "           6       0.37      0.68      0.48       210\n",
      "           7       0.75      0.70      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.72      0.67      0.68      1470\n",
      "weighted avg       0.72      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.754421768707483\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   0   0   7  25  15   2]\n",
      " [  1 160   8  12   8  21   0]\n",
      " [  0   6 177  13   0  14   0]\n",
      " [  3   5   9 163   7  20   3]\n",
      " [ 16  13   8  26 138   3   6]\n",
      " [  6   5   1  24   1 131  42]\n",
      " [  0   1   0   4   1  25 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.77      0.81       210\n",
      "           2       0.84      0.76      0.80       210\n",
      "           3       0.87      0.84      0.86       210\n",
      "           4       0.65      0.78      0.71       210\n",
      "           5       0.77      0.66      0.71       210\n",
      "           6       0.57      0.62      0.60       210\n",
      "           7       0.77      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.76      1470\n",
      "weighted avg       0.76      0.75      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.7238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[173   1   0   6  14  14   2]\n",
      " [  0 161  19   9   4  17   0]\n",
      " [  0   1 181   9   0  19   0]\n",
      " [  0  10  18 152   2  22   6]\n",
      " [ 51  18  22  19  93   1   6]\n",
      " [  1   4   3  19   2 136  45]\n",
      " [  1   2   0   5   0  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.82      0.79       210\n",
      "           2       0.82      0.77      0.79       210\n",
      "           3       0.74      0.86      0.80       210\n",
      "           4       0.69      0.72      0.71       210\n",
      "           5       0.81      0.44      0.57       210\n",
      "           6       0.56      0.65      0.60       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.20748299319727892\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [115   0  95   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.16      0.21      0.13      1470\n",
      "weighted avg       0.16      0.21      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.2653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   2   0   0 153   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.25      0.27      0.20      1470\n",
      "weighted avg       0.25      0.27      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.3122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[112   0   0   0  43  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 78   0   2   0  42  88   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.53      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.20      0.28       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.25      1470\n",
      "weighted avg       0.32      0.31      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66   2   0   0  89   0  53]\n",
      " [  0  54   2   0   2   0 152]\n",
      " [  0   0  95   0   0   0 115]\n",
      " [  0   6   1   0   1   0 202]\n",
      " [ 13   4   2   0 107   0  84]\n",
      " [  0   3   0   0   0   0 207]\n",
      " [  0   0   0   0   2   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.31      0.46       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.53      0.51      0.52       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.99      0.34       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.47      0.36      0.33      1470\n",
      "weighted avg       0.47      0.36      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.3979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   2   0  53  46   0   0]\n",
      " [  0  54   2 152   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 40   4   2  81  80   0   3]\n",
      " [  0   3   0 203   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.52      0.61       210\n",
      "           2       0.78      0.26      0.39       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.21      0.96      0.34       210\n",
      "           5       0.62      0.38      0.47       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.39      1470\n",
      "weighted avg       0.59      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  53   0   0   0]\n",
      " [  0  83   2 123   2   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 202   0   0   0]\n",
      " [ 82   9   2  75  39   1   2]\n",
      " [  0   2   0 203   0   1   4]\n",
      " [  2   1   0 162   0   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.74      0.69       210\n",
      "           2       0.81      0.40      0.53       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.22      0.96      0.35       210\n",
      "           5       0.95      0.19      0.31       210\n",
      "           6       0.50      0.00      0.01       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.71      0.42      0.41      1470\n",
      "weighted avg       0.71      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.45374149659863944\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0   0   0  53   0]\n",
      " [  0 122   2   0   3  83   0]\n",
      " [  0   0  95   0   0 115   0]\n",
      " [  1   6   1   1   0 201   0]\n",
      " [ 74  20   2   0  47  65   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.74      0.70       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       1.00      0.00      0.01       210\n",
      "           5       0.94      0.22      0.36       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.78      0.45      0.44      1470\n",
      "weighted avg       0.78      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.48095238095238096\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[136   2   0  53  19   0   0]\n",
      " [  0 122   2  83   3   0   0]\n",
      " [  0   0  95 115   0   0   0]\n",
      " [  1   6   1 200   0   0   2]\n",
      " [ 38  20   2  64  83   1   2]\n",
      " [  0   3   0 190   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71       210\n",
      "           2       0.79      0.58      0.67       210\n",
      "           3       0.95      0.45      0.61       210\n",
      "           4       0.24      0.95      0.38       210\n",
      "           5       0.78      0.40      0.52       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.66      0.48      0.48      1470\n",
      "weighted avg       0.66      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   2   0  53  20   0   0]\n",
      " [  0 122   3  82   3   0   0]\n",
      " [  0   0 109 101   0   0   0]\n",
      " [  0   5   4 197   2   0   2]\n",
      " [ 35  18   3  63  88   1   2]\n",
      " [  0   3   1 189   0   1  16]\n",
      " [  0   1   0 136   2   1  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.81      0.58      0.68       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.24      0.94      0.38       210\n",
      "           5       0.77      0.42      0.54       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.66      0.49      0.49      1470\n",
      "weighted avg       0.66      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree is: 0.5027210884353741\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[126   3   0   0  29  52   0]\n",
      " [  0 141   3   0   3  63   0]\n",
      " [  0  37 109   0   0  64   0]\n",
      " [  0  21   4   1   2 180   2]\n",
      " [ 24  30   3   0 104  47   2]\n",
      " [  0   5   1   0   0 188  16]\n",
      " [  0   1   0   1   2 136  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.59      0.67      0.63       210\n",
      "           3       0.91      0.52      0.66       210\n",
      "           4       0.50      0.00      0.01       210\n",
      "           5       0.74      0.50      0.59       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.78      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.66      0.50      0.49      1470\n",
      "weighted avg       0.66      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   3   0  52  11   0   0]\n",
      " [  0 140   4  63   3   0   0]\n",
      " [  0  21 125  64   0   0   0]\n",
      " [  0  21   4 179   2   0   4]\n",
      " [ 51  29   5  45  76   1   3]\n",
      " [  0   5   1 183   0   1  20]\n",
      " [  2   1   0 111   0   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.69      0.71       210\n",
      "           2       0.64      0.67      0.65       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.26      0.85      0.39       210\n",
      "           5       0.83      0.36      0.50       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.64      0.52      0.51      1470\n",
      "weighted avg       0.64      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5408163265306123\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[134   2   0  52  22   0   0]\n",
      " [  0 133   4  63  10   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 179  13   0   4]\n",
      " [ 30  13   5  45 113   1   3]\n",
      " [  0   3   1 179   2   1  24]\n",
      " [  0   1   0  96   2   1 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.74      0.63      0.68       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.26      0.85      0.40       210\n",
      "           5       0.68      0.54      0.60       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.78      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.65      0.54      0.54      1470\n",
      "weighted avg       0.65      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5476190476190477\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   2   0  42  10   0   0]\n",
      " [  0 134   4  63   9   0   0]\n",
      " [  0  17 125  64   4   0   0]\n",
      " [  0  10   4 183   9   0   4]\n",
      " [ 53  12   5  43  96   1   0]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  2   1   0  96   0   1 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.74      0.64      0.69       210\n",
      "           3       0.90      0.60      0.72       210\n",
      "           4       0.27      0.87      0.42       210\n",
      "           5       0.74      0.46      0.56       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.65      0.55      0.54      1470\n",
      "weighted avg       0.65      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.5564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   2   0  42  11   0   0]\n",
      " [  0 136   5  63   6   0   0]\n",
      " [  0  13 138  55   4   0   0]\n",
      " [  0  10   4 182  10   0   4]\n",
      " [ 50  13   5  42  97   1   2]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  2   1   0  96   0   2 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.74       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.90      0.66      0.76       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.75      0.46      0.57       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.79      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.64      0.56      0.55      1470\n",
      "weighted avg       0.64      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0  42  27   0   0]\n",
      " [  0 136   6  62   6   0   0]\n",
      " [  0  13 144  49   4   0   0]\n",
      " [  1  10   5 182   8   0   4]\n",
      " [ 32  13   5  43 116   1   0]\n",
      " [  0   4   1 179   2   1  23]\n",
      " [  0   1   0  96   4   1 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.76      0.65      0.70       210\n",
      "           3       0.89      0.69      0.78       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.69      0.55      0.62       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.80      0.51      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.65      0.56      0.55      1470\n",
      "weighted avg       0.65      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree is: 0.5598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0  43  16   0   0]\n",
      " [  0 134   7  61   8   0   0]\n",
      " [  0  10 152  44   4   0   0]\n",
      " [  0  10   6 180  10   0   4]\n",
      " [ 50  12   5  42  98   1   2]\n",
      " [  0   4   1 179   2   3  21]\n",
      " [  2   1   0  96   0   5 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.72      0.80       210\n",
      "           4       0.28      0.86      0.42       210\n",
      "           5       0.71      0.47      0.56       210\n",
      "           6       0.33      0.01      0.03       210\n",
      "           7       0.80      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.65      0.56      0.55      1470\n",
      "weighted avg       0.65      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0  43  17   0   0]\n",
      " [  0 135   6  62   7   0   0]\n",
      " [  0   9 153  44   4   0   0]\n",
      " [  0  10   6 181   9   0   4]\n",
      " [ 43  13   5  42 106   1   0]\n",
      " [  0   4   1 175   2   3  25]\n",
      " [  1   1   0  89   1  11 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.28      0.86      0.43       210\n",
      "           5       0.73      0.50      0.60       210\n",
      "           6       0.20      0.01      0.03       210\n",
      "           7       0.79      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.63      0.57      0.56      1470\n",
      "weighted avg       0.63      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree is: 0.5727891156462585\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   1   0   1  19  42   0]\n",
      " [  0 134   7   0   8  61   0]\n",
      " [  0   9 153   0   4  44   0]\n",
      " [  0  10   6  14   9 167   4]\n",
      " [ 45  13   5   0 104  43   0]\n",
      " [  0   4   1   0   2 180  23]\n",
      " [  1   1   0   1   1  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73       210\n",
      "           2       0.78      0.64      0.70       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.88      0.07      0.12       210\n",
      "           5       0.71      0.50      0.58       210\n",
      "           6       0.28      0.86      0.43       210\n",
      "           7       0.80      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.73      0.57      0.57      1470\n",
      "weighted avg       0.73      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.5897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   1   0   2  22  42   0]\n",
      " [  0 133   7   0   9  61   0]\n",
      " [  0   8 154   1   4  43   0]\n",
      " [  0   9   8  33   9 147   4]\n",
      " [ 32  12   5   3 118  40   0]\n",
      " [  0   4   1   1   2 179  23]\n",
      " [  0   1   0   2   4  96 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.79      0.63      0.70       210\n",
      "           3       0.88      0.73      0.80       210\n",
      "           4       0.79      0.16      0.26       210\n",
      "           5       0.70      0.56      0.62       210\n",
      "           6       0.29      0.85      0.44       210\n",
      "           7       0.80      0.51      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.72      0.59      0.60      1470\n",
      "weighted avg       0.72      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.591156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[146   1   0   2  19  42   0]\n",
      " [  0 145   7   0   8  50   0]\n",
      " [  0   9 154   0   3  44   0]\n",
      " [  0   8   7  34   9 148   4]\n",
      " [ 41  18   5   3 107  36   0]\n",
      " [  0   4   1   1   2 178  24]\n",
      " [  1   1   0   2   1 100 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.73       210\n",
      "           2       0.78      0.69      0.73       210\n",
      "           3       0.89      0.73      0.80       210\n",
      "           4       0.81      0.16      0.27       210\n",
      "           5       0.72      0.51      0.60       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.72      0.59      0.60      1470\n",
      "weighted avg       0.72      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   3   0  19   5  19   8]\n",
      " [  1 111   7  13  35  43   0]\n",
      " [  0   0 151  23   0  35   1]\n",
      " [  0  12   7 123  11  50   7]\n",
      " [ 62  15   5  28  73  13  14]\n",
      " [  0   7   4  24   4 129  42]\n",
      " [  0   1   0  16   0  45 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.74      0.53      0.62       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.50      0.59      0.54       210\n",
      "           5       0.57      0.35      0.43       210\n",
      "           6       0.39      0.61      0.47       210\n",
      "           7       0.67      0.70      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   5   2  18   6  21   3]\n",
      " [  1 124   6  11  25  43   0]\n",
      " [  0   0 152  27   0  30   1]\n",
      " [  1   7   8 140   8  41   5]\n",
      " [ 60  17   5  25  73  14  16]\n",
      " [  0   2   4  20   4 139  41]\n",
      " [  0   0   1  14   0  45 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.80      0.59      0.68       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.55      0.67      0.60       210\n",
      "           5       0.63      0.35      0.45       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.69      0.71      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   0  18   5  21   1]\n",
      " [  0 130   9  10  18  43   0]\n",
      " [  0   0 156  17   0  36   1]\n",
      " [  1   7   8 140   4  43   7]\n",
      " [ 67  17   6  22  69  16  13]\n",
      " [  0   3   4  24   1 136  42]\n",
      " [  1   0   1  11   0  44 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.73       210\n",
      "           2       0.81      0.62      0.70       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.58      0.67      0.62       210\n",
      "           5       0.71      0.33      0.45       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.64      1470\n",
      "weighted avg       0.68      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   7   0  16   5  22   2]\n",
      " [  0 132   9  11  19  39   0]\n",
      " [  0   0 156  17   0  36   1]\n",
      " [  1  11   7 141   9  37   4]\n",
      " [ 67  20   6  23  69  13  12]\n",
      " [  0   6   4  28   3 126  43]\n",
      " [  0   1   0  13   0  41 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.72       210\n",
      "           2       0.75      0.63      0.68       210\n",
      "           3       0.86      0.74      0.80       210\n",
      "           4       0.57      0.67      0.61       210\n",
      "           5       0.66      0.33      0.44       210\n",
      "           6       0.40      0.60      0.48       210\n",
      "           7       0.71      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   3   0  16   7  23   2]\n",
      " [  0 138  10  13  13  36   0]\n",
      " [  0   0 167  14   0  28   1]\n",
      " [  0   7   8 145   9  37   4]\n",
      " [ 56  15   6  26  81  13  13]\n",
      " [  0   3   4  27   3 131  42]\n",
      " [  0   0   0  14   0  39 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.83      0.66      0.73       210\n",
      "           3       0.86      0.80      0.82       210\n",
      "           4       0.57      0.69      0.62       210\n",
      "           5       0.72      0.39      0.50       210\n",
      "           6       0.43      0.62      0.51       210\n",
      "           7       0.72      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   3   0  18   9  22   1]\n",
      " [  0 137   9  12  15  37   0]\n",
      " [  0   0 158  15   0  36   1]\n",
      " [  0   9   8 149   3  37   4]\n",
      " [ 55  15   6  23  85  13  13]\n",
      " [  0   3   4  28   2 132  41]\n",
      " [  0   0   1  13   0  40 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.74       210\n",
      "           2       0.82      0.65      0.73       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.58      0.71      0.64       210\n",
      "           5       0.75      0.40      0.52       210\n",
      "           6       0.42      0.63      0.50       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  16   8  23   2]\n",
      " [  0 138  11  10  16  35   0]\n",
      " [  0   0 161  13   0  35   1]\n",
      " [  1   8   8 142   5  42   4]\n",
      " [ 55  16   6  25  80  16  12]\n",
      " [  0   4   4  22   3 136  41]\n",
      " [  0   0   1   9   0  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.82      0.66      0.73       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.60      0.68      0.64       210\n",
      "           5       0.71      0.38      0.50       210\n",
      "           6       0.41      0.65      0.50       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0  17  11  22   2]\n",
      " [  0 140   7  12  14  37   0]\n",
      " [  0   0 160  13   0  36   1]\n",
      " [  1   6   8 143   5  43   4]\n",
      " [ 45  17   6  22  94  15  11]\n",
      " [  0   3   4  17   3 142  41]\n",
      " [  0   0   1   9   0  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.76       210\n",
      "           2       0.83      0.67      0.74       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.61      0.68      0.65       210\n",
      "           5       0.74      0.45      0.56       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0  17  10  23   1]\n",
      " [  0 139   7  13  15  36   0]\n",
      " [  0   0 161  13   0  35   1]\n",
      " [  0   6   8 142   4  46   4]\n",
      " [ 50  16   6  21  89  17  11]\n",
      " [  0   4   4  17   2 142  41]\n",
      " [  0   0   0   8   1  46 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.75       210\n",
      "           2       0.83      0.66      0.74       210\n",
      "           3       0.87      0.77      0.81       210\n",
      "           4       0.61      0.68      0.64       210\n",
      "           5       0.74      0.42      0.54       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6761904761904762\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   9  12  31   0]\n",
      " [  0 141  11  10  11  37   0]\n",
      " [  0   1 167  14   0  27   1]\n",
      " [  0   6   9 132   4  55   4]\n",
      " [ 50  15   6  19  95  16   9]\n",
      " [  0   4   4  13   2 147  40]\n",
      " [  0   0   1   5   0  48 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.83      0.67      0.74       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.77      0.45      0.57       210\n",
      "           6       0.41      0.70      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   2   0  10   8  29   0]\n",
      " [  0 142   8   9  14  37   0]\n",
      " [  0   0 160  11   0  38   1]\n",
      " [  0   6   8 136   7  49   4]\n",
      " [ 54  15   6  18  90  17  10]\n",
      " [  0   3   4  15   3 145  40]\n",
      " [  1   0   0   6   1  47 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76       210\n",
      "           2       0.85      0.68      0.75       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.66      0.65      0.66       210\n",
      "           5       0.73      0.43      0.54       210\n",
      "           6       0.40      0.69      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0  12   9  27   0]\n",
      " [  0 139  11  10  16  34   0]\n",
      " [  0   0 166  13   0  30   1]\n",
      " [  0   6   9 140   4  47   4]\n",
      " [ 58  16   6  19  86  16   9]\n",
      " [  0   4   5  15   2 141  43]\n",
      " [  1   0   0   7   1  48 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       210\n",
      "           2       0.83      0.66      0.74       210\n",
      "           3       0.84      0.79      0.82       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.73      0.41      0.52       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.73      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0  12  10  28   1]\n",
      " [  0 143  10   9  11  37   0]\n",
      " [  0   0 167  12   0  30   1]\n",
      " [  0   6   9 139   3  49   4]\n",
      " [ 42  17   6  23  95  16  11]\n",
      " [  0   4   4  15   2 143  42]\n",
      " [  0   0   0   7   0  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.75      0.77       210\n",
      "           2       0.83      0.68      0.75       210\n",
      "           3       0.85      0.80      0.82       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.79      0.45      0.57       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.69      1470\n",
      "weighted avg       0.72      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest is: 0.6850340136054421\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   0  12   9  28   0]\n",
      " [  0 147  10   7  12  34   0]\n",
      " [  0   0 168  11   0  30   1]\n",
      " [  0   6   9 138   6  47   4]\n",
      " [ 46  15   6  21  95  17  10]\n",
      " [  0   5   3  14   2 143  43]\n",
      " [  0   0   0   5   1  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.84      0.70      0.76       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.66      0.66      0.66       210\n",
      "           5       0.76      0.45      0.57       210\n",
      "           6       0.41      0.68      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.69      1470\n",
      "weighted avg       0.72      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   2   0  13   7  27   1]\n",
      " [  0 150   7   9  13  31   0]\n",
      " [  0   4 161   9   0  35   1]\n",
      " [  0   7   7 138   5  49   4]\n",
      " [ 39  14   6  19 107  15  10]\n",
      " [  0   3   2  16   2 146  41]\n",
      " [  0   0   0   7   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.76      0.78       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.88      0.77      0.82       210\n",
      "           4       0.65      0.66      0.66       210\n",
      "           5       0.79      0.51      0.62       210\n",
      "           6       0.42      0.70      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.73      0.69      0.70      1470\n",
      "weighted avg       0.73      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6965986394557823\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   0  11  14  28   0]\n",
      " [  0 149   9  11  12  29   0]\n",
      " [  0   4 169  10   1  25   1]\n",
      " [  0   8   9 139   6  44   4]\n",
      " [ 32  13   6  20 114  13  12]\n",
      " [  0   3   3  18   2 142  42]\n",
      " [  0   0   0   7   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.78       210\n",
      "           2       0.83      0.71      0.77       210\n",
      "           3       0.86      0.80      0.83       210\n",
      "           4       0.64      0.66      0.65       210\n",
      "           5       0.76      0.54      0.63       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.70      1470\n",
      "weighted avg       0.73      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.691156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   2   0  10  17  28   1]\n",
      " [  0 148   7   7  16  32   0]\n",
      " [  0   5 161  10   0  33   1]\n",
      " [  0   9   8 139   7  43   4]\n",
      " [ 31  14   6  21 113  15  10]\n",
      " [  0   3   4  14   2 145  42]\n",
      " [  0   0   0   5   2  45 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.72      0.77       210\n",
      "           2       0.82      0.70      0.76       210\n",
      "           3       0.87      0.77      0.81       210\n",
      "           4       0.67      0.66      0.67       210\n",
      "           5       0.72      0.54      0.62       210\n",
      "           6       0.43      0.69      0.53       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   2   0   9  17  29   1]\n",
      " [  0 152   8   8  12  30   0]\n",
      " [  0   3 170  11   0  25   1]\n",
      " [  0   8   9 141   5  43   4]\n",
      " [ 37  14   6  20 108  15  10]\n",
      " [  0   3   3  18   3 140  43]\n",
      " [  1   0   0   5   2  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.84      0.72      0.78       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.73      0.51      0.61       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.73      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.72      0.69      0.70      1470\n",
      "weighted avg       0.72      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.7006802721088435\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   0   9  14  29   2]\n",
      " [  0 156   8   7   8  31   0]\n",
      " [  0   4 168  13   0  24   1]\n",
      " [  0   9   9 140   7  41   4]\n",
      " [ 34  13   6  22 110  15  10]\n",
      " [  0   5   3  17   3 142  40]\n",
      " [  0   0   0   5   2  43 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.73      0.77       210\n",
      "           2       0.83      0.74      0.78       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.66      0.67      0.66       210\n",
      "           5       0.76      0.52      0.62       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.71      1470\n",
      "weighted avg       0.73      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest is: 0.6993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   3   0  10  14  27   1]\n",
      " [  0 153   7   8  11  31   0]\n",
      " [  0   3 170   9   0  27   1]\n",
      " [  0  10   9 138   6  43   4]\n",
      " [ 34  16   6  18 109  17  10]\n",
      " [  0   3   2  16   2 146  41]\n",
      " [  1   1   0   6   1  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.74      0.78       210\n",
      "           2       0.81      0.73      0.77       210\n",
      "           3       0.88      0.81      0.84       210\n",
      "           4       0.67      0.66      0.67       210\n",
      "           5       0.76      0.52      0.62       210\n",
      "           6       0.44      0.70      0.54       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.73      0.70      0.71      1470\n",
      "weighted avg       0.73      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.7034013605442176\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[160   1   0   3  38   7   1]\n",
      " [ 12 152  12   8  23   3   0]\n",
      " [ 14   2 179  11   2   2   0]\n",
      " [ 16   4  13 151  15   8   3]\n",
      " [ 26  11  15  17 132   4   5]\n",
      " [ 35   8   6  23   7  79  52]\n",
      " [  4   3   0   2   2  18 181]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.76      0.67       210\n",
      "           2       0.84      0.72      0.78       210\n",
      "           3       0.80      0.85      0.82       210\n",
      "           4       0.70      0.72      0.71       210\n",
      "           5       0.60      0.63      0.62       210\n",
      "           6       0.65      0.38      0.48       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "tfidf_500_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tfidf_500_vectors.csv\",encoding_errors='ignore')\n",
    "# Splitting the data\n",
    "x_train,x_test,y_train,y_test = train_test_split(tfidf_500_df,labels_df['kabita_labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['kabita_labels'])\n",
    "\n",
    "#Modelling\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression()\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af5083",
   "metadata": {},
   "source": [
    "### Data split for Count vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3271f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.746938775510204\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[168   0   2   7  17  14   2]\n",
      " [  0 167  12   8   5  18   0]\n",
      " [  0   0 183   9   0  18   0]\n",
      " [  0   9  19 153   6  20   3]\n",
      " [ 19  14  15  14 141   2   5]\n",
      " [  2   8   4  19   3 140  34]\n",
      " [  1   4   0   6   1  52 146]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.80      0.84       210\n",
      "           2       0.83      0.80      0.81       210\n",
      "           3       0.78      0.87      0.82       210\n",
      "           4       0.71      0.73      0.72       210\n",
      "           5       0.82      0.67      0.74       210\n",
      "           6       0.53      0.67      0.59       210\n",
      "           7       0.77      0.70      0.73       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[175   8   4   2   0  21   0]\n",
      " [  3 155  25   3   3  21   0]\n",
      " [  2   5 180   5   0  18   0]\n",
      " [ 19  20  30 107   0  33   1]\n",
      " [ 83  40  32  12  36   6   1]\n",
      " [ 13  21   4  10   0 151  11]\n",
      " [ 23  15   0  14   0  74  84]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.83      0.66       210\n",
      "           2       0.59      0.74      0.65       210\n",
      "           3       0.65      0.86      0.74       210\n",
      "           4       0.70      0.51      0.59       210\n",
      "           5       0.92      0.17      0.29       210\n",
      "           6       0.47      0.72      0.57       210\n",
      "           7       0.87      0.40      0.55       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.68      0.60      0.58      1470\n",
      "weighted avg       0.68      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5857142857142857\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[168   7   6   3   0  26   0]\n",
      " [  2 153  29   6   1  19   0]\n",
      " [  3   2 184   6   0  15   0]\n",
      " [ 12  22  33 112   0  30   1]\n",
      " [ 85  41  35  16  25   7   1]\n",
      " [ 16  25   9  13   0 135  12]\n",
      " [ 17  12   4   7   0  86  84]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.80      0.65       210\n",
      "           2       0.58      0.73      0.65       210\n",
      "           3       0.61      0.88      0.72       210\n",
      "           4       0.69      0.53      0.60       210\n",
      "           5       0.96      0.12      0.21       210\n",
      "           6       0.42      0.64      0.51       210\n",
      "           7       0.86      0.40      0.55       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.67      0.59      0.56      1470\n",
      "weighted avg       0.67      0.59      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5850340136054422\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[170   6   7   4   0  23   0]\n",
      " [  2 151  30   7   0  20   0]\n",
      " [  1   0 186   7   0  16   0]\n",
      " [ 13  21  38 107   0  30   1]\n",
      " [ 95  38  37  13  20   6   1]\n",
      " [ 11  21  11  14   0 139  14]\n",
      " [ 13   9   6  12   0  83  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.81      0.66       210\n",
      "           2       0.61      0.72      0.66       210\n",
      "           3       0.59      0.89      0.71       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       1.00      0.10      0.17       210\n",
      "           6       0.44      0.66      0.53       210\n",
      "           7       0.84      0.41      0.56       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.67      0.59      0.55      1470\n",
      "weighted avg       0.67      0.59      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.5795918367346938\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[168   7   7   3   0  25   0]\n",
      " [  2 153  30   3   0  22   0]\n",
      " [  1   0 186   7   0  16   0]\n",
      " [ 13  19  42 100   0  34   2]\n",
      " [101  34  40  13  14   7   1]\n",
      " [  9  16  11  15   0 151   8]\n",
      " [ 14  11   3   8   0  94  80]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.80      0.65       210\n",
      "           2       0.64      0.73      0.68       210\n",
      "           3       0.58      0.89      0.70       210\n",
      "           4       0.67      0.48      0.56       210\n",
      "           5       1.00      0.07      0.12       210\n",
      "           6       0.43      0.72      0.54       210\n",
      "           7       0.88      0.38      0.53       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.68      0.58      0.54      1470\n",
      "weighted avg       0.68      0.58      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.5748299319727891\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[169   7   7   2   0  25   0]\n",
      " [  2 147  31   5   0  25   0]\n",
      " [  0   0 187   7   0  16   0]\n",
      " [ 13  19  43  94   0  39   2]\n",
      " [ 96  40  41  12  14   7   0]\n",
      " [ 11  16  10   7   0 152  14]\n",
      " [ 13   8   4   4   0  99  82]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.80      0.66       210\n",
      "           2       0.62      0.70      0.66       210\n",
      "           3       0.58      0.89      0.70       210\n",
      "           4       0.72      0.45      0.55       210\n",
      "           5       1.00      0.07      0.12       210\n",
      "           6       0.42      0.72      0.53       210\n",
      "           7       0.84      0.39      0.53       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.68      0.57      0.54      1470\n",
      "weighted avg       0.68      0.57      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.5761904761904761\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[169   6   6   2   1  26   0]\n",
      " [  2 147  31   6   0  24   0]\n",
      " [  0   1 187   6   0  16   0]\n",
      " [ 14  17  42  94   0  41   2]\n",
      " [ 95  41  41  11  12   8   2]\n",
      " [ 10  14   8   6   0 160  12]\n",
      " [ 14   8   3   5   0 102  78]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.80      0.66       210\n",
      "           2       0.63      0.70      0.66       210\n",
      "           3       0.59      0.89      0.71       210\n",
      "           4       0.72      0.45      0.55       210\n",
      "           5       0.92      0.06      0.11       210\n",
      "           6       0.42      0.76      0.55       210\n",
      "           7       0.83      0.37      0.51       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.67      0.58      0.54      1470\n",
      "weighted avg       0.67      0.58      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.5272108843537415\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[158   2   9  19  19   1   2]\n",
      " [ 10  98  89   7   3   3   0]\n",
      " [  7   6 193   3   0   0   1]\n",
      " [ 35  20  41 102   9   2   1]\n",
      " [ 88  13  13  38  53   3   2]\n",
      " [ 29  32  49  29   3  37  31]\n",
      " [ 19  11   7   9   1  29 134]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.75      0.57       210\n",
      "           2       0.54      0.47      0.50       210\n",
      "           3       0.48      0.92      0.63       210\n",
      "           4       0.49      0.49      0.49       210\n",
      "           5       0.60      0.25      0.36       210\n",
      "           6       0.49      0.18      0.26       210\n",
      "           7       0.78      0.64      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.50      1470\n",
      "weighted avg       0.55      0.53      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM is: 0.7496598639455783\n",
      "Confusion Matrix of SVM is:\n",
      " [[171   0   1   6  18  12   2]\n",
      " [  0 168  11   9   3  19   0]\n",
      " [  0   0 183   6   1  20   0]\n",
      " [  0  12  19 146   4  26   3]\n",
      " [ 24  15  13   8 145   2   3]\n",
      " [  2   8   3  20   2 138  37]\n",
      " [  1   4   0   7   2  45 151]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.81      0.84       210\n",
      "           2       0.81      0.80      0.81       210\n",
      "           3       0.80      0.87      0.83       210\n",
      "           4       0.72      0.70      0.71       210\n",
      "           5       0.83      0.69      0.75       210\n",
      "           6       0.53      0.66      0.58       210\n",
      "           7       0.77      0.72      0.74       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.5972789115646259\n",
      "Confusion Matrix of SVM is:\n",
      " [[151   0   1   3   7  47   1]\n",
      " [  1 132  15   5   3  54   0]\n",
      " [  0   0 151   1   1  57   0]\n",
      " [  0   4  18  88   3  95   2]\n",
      " [ 43  22  22  16  83  21   3]\n",
      " [  0   3   2   6   0 187  12]\n",
      " [  2   2   0   0   0 120  86]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.74       210\n",
      "           2       0.81      0.63      0.71       210\n",
      "           3       0.72      0.72      0.72       210\n",
      "           4       0.74      0.42      0.53       210\n",
      "           5       0.86      0.40      0.54       210\n",
      "           6       0.32      0.89      0.47       210\n",
      "           7       0.83      0.41      0.55       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.72      0.60      0.61      1470\n",
      "weighted avg       0.72      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.7353741496598639\n",
      "Confusion Matrix of SVM is:\n",
      " [[154   0   0   5  33  15   3]\n",
      " [  0 155  12   9  12  22   0]\n",
      " [  0   1 179   7   3  20   0]\n",
      " [  0   8  13 140  20  25   4]\n",
      " [ 13  12   8  14 156   2   5]\n",
      " [  0   7   2  11   8 135  47]\n",
      " [  0   2   0   5  13  28 162]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.73      0.82       210\n",
      "           2       0.84      0.74      0.78       210\n",
      "           3       0.84      0.85      0.84       210\n",
      "           4       0.73      0.67      0.70       210\n",
      "           5       0.64      0.74      0.69       210\n",
      "           6       0.55      0.64      0.59       210\n",
      "           7       0.73      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.74      1470\n",
      "   macro avg       0.75      0.74      0.74      1470\n",
      "weighted avg       0.75      0.74      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.7122448979591837\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   4   0   8  22  15   3]\n",
      " [  1 153  15  10   7  24   0]\n",
      " [  0   9 174   7   0  20   0]\n",
      " [  1  13  18 144   4  28   2]\n",
      " [ 34  24  11  12 124   1   4]\n",
      " [  0   5   4  18   4 141  38]\n",
      " [  2   3   0   6   2  44 153]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.75      0.78       210\n",
      "           2       0.73      0.73      0.73       210\n",
      "           3       0.78      0.83      0.81       210\n",
      "           4       0.70      0.69      0.69       210\n",
      "           5       0.76      0.59      0.66       210\n",
      "           6       0.52      0.67      0.58       210\n",
      "           7       0.77      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.2\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85 125   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [ 55 155   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.16      1.00      0.27       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.11      0.20      0.11      1470\n",
      "weighted avg       0.11      0.20      0.11      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.254421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155  55   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  1 209   0   0   0   0   0]\n",
      " [109  90   0   0  11   0   0]\n",
      " [  0 210   0   0   0   0   0]\n",
      " [  2 208   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.74      0.65       210\n",
      "           2       0.17      0.99      0.30       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       1.00      0.05      0.10       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.25      0.25      0.15      1470\n",
      "weighted avg       0.25      0.25      0.15      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.35034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0   0  52   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   0  17   0   0 192   0]\n",
      " [100   0  26   0  20  64   0]\n",
      " [  0   0   2   0   0 208   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.57      0.63      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.91      0.10      0.17       210\n",
      "           6       0.22      0.99      0.36       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.33      0.35      0.26      1470\n",
      "weighted avg       0.33      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree is: 0.40816326530612246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   1   0   0  54   0]\n",
      " [  0  30  22   0   2 156   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   1  16   0   0 192   0]\n",
      " [ 86   4  22   0  34  63   1]\n",
      " [  0   0   2   0   0 204   4]\n",
      " [  2   0   0   0   0 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.74      0.68       210\n",
      "           2       0.86      0.14      0.24       210\n",
      "           3       0.68      0.63      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.94      0.16      0.28       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.90      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.37      1470\n",
      "weighted avg       0.61      0.41      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.43673469387755104\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[137   0   1   0  18  54   0]\n",
      " [  0  70  17   0   2 121   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   5  13   0   1 191   0]\n",
      " [ 67  13  22   0  54  54   0]\n",
      " [  0   1   1   0   0 204   4]\n",
      " [  2   1   0   0   0 162  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.65      0.66       210\n",
      "           2       0.78      0.33      0.47       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.72      0.26      0.38       210\n",
      "           6       0.24      0.97      0.38       210\n",
      "           7       0.92      0.21      0.35       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.58      0.44      0.41      1470\n",
      "weighted avg       0.58      0.44      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.4741496598639456\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1   0   1  54   0]\n",
      " [  0 110  17   0   3  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   7  12   0   0 190   0]\n",
      " [ 69  19  22   0  55  45   0]\n",
      " [  0   3   1   0   0 202   4]\n",
      " [  2   1   0   0   0 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.73      0.71       210\n",
      "           2       0.79      0.52      0.63       210\n",
      "           3       0.71      0.63      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.93      0.26      0.41       210\n",
      "           6       0.25      0.96      0.40       210\n",
      "           7       0.92      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.61      0.47      0.45      1470\n",
      "weighted avg       0.61      0.47      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.4891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1   0   1  54   0]\n",
      " [  0 106  17   3   4  80   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  1   4   8   6   1 188   2]\n",
      " [ 63  18  22   0  62  45   0]\n",
      " [  0   2   1   1   0 188  18]\n",
      " [  2   1   0   0   0 136  71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.72       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.73      0.63      0.68       210\n",
      "           4       0.60      0.03      0.05       210\n",
      "           5       0.91      0.30      0.45       210\n",
      "           6       0.24      0.90      0.38       210\n",
      "           7       0.78      0.34      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.68      0.49      0.48      1470\n",
      "weighted avg       0.68      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.5095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   1  54   1   0   0]\n",
      " [  0 104  16  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   3   8 191   3   0   4]\n",
      " [ 56  16  21  44  72   0   1]\n",
      " [  0   2   1 185   0   0  22]\n",
      " [  2   1   0 110   0   1  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.83      0.50      0.62       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.26      0.91      0.40       210\n",
      "           5       0.87      0.34      0.49       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.78      0.46      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.60      0.51      0.50      1470\n",
      "weighted avg       0.60      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.5265306122448979\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   1  54   3   0   0]\n",
      " [  1 104  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  1   5   8 191   1   0   4]\n",
      " [ 51  16  18  44  81   0   0]\n",
      " [  0   2   1 181   0   0  26]\n",
      " [  2   1   0  92   0   1 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.26      0.91      0.41       210\n",
      "           5       0.88      0.39      0.54       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.61      0.53      0.52      1470\n",
      "weighted avg       0.61      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree is: 0.536734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1  44   4   0   0]\n",
      " [  0 105  15  83   7   0   0]\n",
      " [  0   0 132  78   0   0   0]\n",
      " [  0   5   8 191   2   0   4]\n",
      " [ 48  17  18  38  88   0   1]\n",
      " [  0   2   1 181   1   0  25]\n",
      " [  2   1   0  93   0   2 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.75      0.63      0.69       210\n",
      "           4       0.27      0.91      0.42       210\n",
      "           5       0.86      0.42      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[161   0   1   0   4  44   0]\n",
      " [  0 106  24   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  21   5   2 173   4]\n",
      " [ 48  17  18   0  89  38   0]\n",
      " [  0   2   3   0   1 178  26]\n",
      " [  2   1   1   1   2  93 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.81      0.50      0.62       210\n",
      "           3       0.69      0.71      0.70       210\n",
      "           4       0.56      0.02      0.05       210\n",
      "           5       0.85      0.42      0.57       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.79      0.52      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.67      0.54      0.53      1470\n",
      "weighted avg       0.67      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  20  15   2 164   4]\n",
      " [ 44  17  18   0  93  38   0]\n",
      " [  0   3   3   0   2 178  24]\n",
      " [  2   1   1   1   0  94 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.79      0.07      0.13       210\n",
      "           5       0.85      0.44      0.58       210\n",
      "           6       0.27      0.85      0.41       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.72      0.56      0.56      1470\n",
      "weighted avg       0.72      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5585034013605442\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[159   0   1   0   6  44   0]\n",
      " [  0 115  15   3   7  70   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  1   5  20  14   2 164   4]\n",
      " [ 44  17  18   0  92  38   1]\n",
      " [  0   2   3   0   1 177  27]\n",
      " [  2   1   1   1   3  88 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.82      0.55      0.66       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.78      0.07      0.12       210\n",
      "           5       0.83      0.44      0.57       210\n",
      "           6       0.28      0.84      0.42       210\n",
      "           7       0.78      0.54      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.71      0.56      0.56      1470\n",
      "weighted avg       0.71      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.572108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   1   0   8  44   0]\n",
      " [  0 115  15   4   7  69   0]\n",
      " [  0   0 150   0   0  60   0]\n",
      " [  0   5  19  36   2 144   4]\n",
      " [ 43  19  18   3  92  35   0]\n",
      " [  0   2   3   1   1 176  27]\n",
      " [  2   2   1   2   1  87 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.76       210\n",
      "           2       0.80      0.55      0.65       210\n",
      "           3       0.72      0.71      0.72       210\n",
      "           4       0.78      0.17      0.28       210\n",
      "           5       0.83      0.44      0.57       210\n",
      "           6       0.29      0.84      0.43       210\n",
      "           7       0.79      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.71      0.57      0.58      1470\n",
      "weighted avg       0.71      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree is: 0.5761904761904761\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   1   0   8  44   0]\n",
      " [  0 115  18   4   7  66   0]\n",
      " [  0   0 155   0   0  55   0]\n",
      " [  0   5  22  37   2 140   4]\n",
      " [ 44  19  22   3  92  29   1]\n",
      " [  0   2   3   1   0 179  25]\n",
      " [  2   1   1   2   4  88 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.81      0.55      0.65       210\n",
      "           3       0.70      0.74      0.72       210\n",
      "           4       0.79      0.18      0.29       210\n",
      "           5       0.81      0.44      0.57       210\n",
      "           6       0.30      0.85      0.44       210\n",
      "           7       0.79      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.71      0.58      0.58      1470\n",
      "weighted avg       0.71      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5843537414965987\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[160   0   2   0   5  43   0]\n",
      " [  0 116  22   4   7  61   0]\n",
      " [  0   0 162   0   0  48   0]\n",
      " [  0   5  28  36   3 135   3]\n",
      " [ 43  21  21   3  93  29   0]\n",
      " [  0   2   3   1   2 177  25]\n",
      " [  2   1   1   2   1  88 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.80      0.55      0.65       210\n",
      "           3       0.68      0.77      0.72       210\n",
      "           4       0.78      0.17      0.28       210\n",
      "           5       0.84      0.44      0.58       210\n",
      "           6       0.30      0.84      0.45       210\n",
      "           7       0.80      0.55      0.65       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.71      0.58      0.59      1470\n",
      "weighted avg       0.71      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.591156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[158   0   2   0   7  43   0]\n",
      " [  0 127  20   4   8  51   0]\n",
      " [  0   0 162   0   0  48   0]\n",
      " [  0   6  27  36   2 135   4]\n",
      " [ 41  23  20   5  95  26   0]\n",
      " [  0   2   3   1   1 179  24]\n",
      " [  2   1   1   2   0  92 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.75      0.77       210\n",
      "           2       0.80      0.60      0.69       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.75      0.17      0.28       210\n",
      "           5       0.84      0.45      0.59       210\n",
      "           6       0.31      0.85      0.46       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree is: 0.5918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   0   2   0  11  43   0]\n",
      " [  0 127  18   5  10  50   0]\n",
      " [  0   0 161   2   0  47   0]\n",
      " [  1   5  28  43   2 127   4]\n",
      " [ 43  22  20   5  95  25   0]\n",
      " [  0   2   3   1   1 179  24]\n",
      " [  2   1   1   2   1  92 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.69      0.77      0.73       210\n",
      "           4       0.74      0.20      0.32       210\n",
      "           5       0.79      0.45      0.58       210\n",
      "           6       0.32      0.85      0.46       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.60      1470\n",
      "weighted avg       0.70      0.59      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.6006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   2   0  10  43   0]\n",
      " [  0 126  17   5  12  50   0]\n",
      " [  0   0 171   0   0  39   0]\n",
      " [  1   4  26  47   2 127   3]\n",
      " [ 40  21  21   8  97  23   0]\n",
      " [  0   2   3   2   0 179  24]\n",
      " [  2   2   1   2   3  92 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.81      0.60      0.69       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.73      0.22      0.34       210\n",
      "           5       0.78      0.46      0.58       210\n",
      "           6       0.32      0.85      0.47       210\n",
      "           7       0.80      0.51      0.63       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.71      0.60      0.60      1470\n",
      "weighted avg       0.71      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.6163265306122448\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   2   0   8  43   0]\n",
      " [  0 128  17   6  11  48   0]\n",
      " [  0   0 172   4   0  34   0]\n",
      " [  1   5  25  58   2 116   3]\n",
      " [ 37  21  20   6 102  23   1]\n",
      " [  0   2   3   2   1 178  24]\n",
      " [  2   1   1   2   3  90 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.75      0.77       210\n",
      "           2       0.82      0.61      0.70       210\n",
      "           3       0.72      0.82      0.76       210\n",
      "           4       0.74      0.28      0.40       210\n",
      "           5       0.80      0.49      0.61       210\n",
      "           6       0.33      0.85      0.48       210\n",
      "           7       0.80      0.53      0.64       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.72      0.62      0.62      1470\n",
      "weighted avg       0.72      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.5775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   3   1  19   5  21   5]\n",
      " [  1  97  49  14   5  43   1]\n",
      " [  0   0 158   7   0  45   0]\n",
      " [  1  10  24 114   1  56   4]\n",
      " [ 61  24  33  29  45   6  12]\n",
      " [  0   7   4  28   1 130  40]\n",
      " [  0   1   0  17   0  43 149]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.46      0.55       210\n",
      "           3       0.59      0.75      0.66       210\n",
      "           4       0.50      0.54      0.52       210\n",
      "           5       0.79      0.21      0.34       210\n",
      "           6       0.38      0.62      0.47       210\n",
      "           7       0.71      0.71      0.71       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.62      0.58      0.57      1470\n",
      "weighted avg       0.62      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.5843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   2  11  11  25   5]\n",
      " [  1  98  50  12  16  33   0]\n",
      " [  0   0 156   7   0  47   0]\n",
      " [  0  14  24 103   3  62   4]\n",
      " [ 56  23  28  18  58  13  14]\n",
      " [  0   8   5  16   2 138  41]\n",
      " [  0   2   0   4   0  50 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.66      0.47      0.55       210\n",
      "           3       0.59      0.74      0.66       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.64      0.28      0.39       210\n",
      "           6       0.38      0.66      0.48       210\n",
      "           7       0.71      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.61      0.58      0.58      1470\n",
      "weighted avg       0.61      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest is: 0.5748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   4   1  10   8  27   5]\n",
      " [  1  98  48  12  16  35   0]\n",
      " [  0   0 135   6   0  69   0]\n",
      " [  0  11  15 109   4  67   4]\n",
      " [ 62  22  30  20  53  10  13]\n",
      " [  0   7   2  14   3 141  43]\n",
      " [  0   1   0   6   0  49 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.72       210\n",
      "           2       0.69      0.47      0.56       210\n",
      "           3       0.58      0.64      0.61       210\n",
      "           4       0.62      0.52      0.56       210\n",
      "           5       0.63      0.25      0.36       210\n",
      "           6       0.35      0.67      0.46       210\n",
      "           7       0.70      0.73      0.72       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.61      0.57      0.57      1470\n",
      "weighted avg       0.61      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   4   2   8  11  28   3]\n",
      " [  0 105  51   7  12  35   0]\n",
      " [  0   0 161   6   0  43   0]\n",
      " [  0  13  27 106   7  53   4]\n",
      " [ 54  20  28  16  71   9  12]\n",
      " [  0   9   5  17   2 137  40]\n",
      " [  0   1   0   5   0  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.59      0.77      0.67       210\n",
      "           4       0.64      0.50      0.57       210\n",
      "           5       0.69      0.34      0.45       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.60      1470\n",
      "weighted avg       0.64      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   4   1   8   8  29   2]\n",
      " [  1 137  20  10   8  34   0]\n",
      " [  0   0 149   6   0  55   0]\n",
      " [  0  16  21 109   4  56   4]\n",
      " [ 54  23  25  13  74  10  11]\n",
      " [  0  10   4  16   1 138  41]\n",
      " [  1   2   0   6   1  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.71      0.65      0.68       210\n",
      "           3       0.68      0.71      0.69       210\n",
      "           4       0.65      0.52      0.58       210\n",
      "           5       0.77      0.35      0.48       210\n",
      "           6       0.38      0.66      0.48       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.63      1470\n",
      "weighted avg       0.67      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest is: 0.6306122448979592\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   4   2   8  10  27   2]\n",
      " [  0 138  21   9   9  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  18  23 104   4  58   3]\n",
      " [ 56  21  21  15  75  11  11]\n",
      " [  0   9   5  13   1 139  43]\n",
      " [  1   2   0   6   1  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.68      0.74      0.71       210\n",
      "           4       0.65      0.50      0.56       210\n",
      "           5       0.75      0.36      0.48       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   5   2   9  12  26   2]\n",
      " [  0 138  21   8  10  33   0]\n",
      " [  0   0 156   6   0  48   0]\n",
      " [  0  16  19 111   6  55   3]\n",
      " [ 52  20  18  19  81  10  10]\n",
      " [  0   8   5  14   3 138  42]\n",
      " [  0   2   0   6   1  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       210\n",
      "           2       0.73      0.66      0.69       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.64      0.53      0.58       210\n",
      "           5       0.72      0.39      0.50       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   5   2   8   7  27   1]\n",
      " [  0 136  22   9  11  32   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  13  19 115   6  53   4]\n",
      " [ 53  20  25  14  79   9  10]\n",
      " [  0   8   5  12   2 140  43]\n",
      " [  0   2   0   5   1  42 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.76      0.76       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.69      0.79      0.74       210\n",
      "           4       0.68      0.55      0.61       210\n",
      "           5       0.75      0.38      0.50       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.6551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   1   8   8  29   0]\n",
      " [  0 139  21   9   6  35   0]\n",
      " [  0   0 165   7   0  38   0]\n",
      " [  0  12  19 120   7  49   3]\n",
      " [ 49  23  26  14  80   9   9]\n",
      " [  0   8   5  14   2 139  42]\n",
      " [  1   2   0   5   1  41 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.70      0.79      0.74       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.77      0.38      0.51       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   1   9   8  27   1]\n",
      " [  0 141  23   9   5  32   0]\n",
      " [  0   0 164   7   0  39   0]\n",
      " [  0  15  22 114   5  51   3]\n",
      " [ 45  22  21  14  93   5  10]\n",
      " [  0  10   3  12   1 141  43]\n",
      " [  1   2   0   5   0  41 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.70      0.78      0.74       210\n",
      "           4       0.67      0.54      0.60       210\n",
      "           5       0.83      0.44      0.58       210\n",
      "           6       0.42      0.67      0.52       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   4   2   8  11  28   0]\n",
      " [  0 138  21  10   8  33   0]\n",
      " [  0   0 170   6   0  34   0]\n",
      " [  0  13  21 118   5  50   3]\n",
      " [ 53  22  27  15  76   9   8]\n",
      " [  0   8   4  12   2 141  43]\n",
      " [  1   2   0   5   1  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.75      0.75       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.74      0.36      0.49       210\n",
      "           6       0.42      0.67      0.52       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6571428571428571\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   4   1   8   8  29   1]\n",
      " [  0 141  21   9   6  33   0]\n",
      " [  0   0 163   6   0  41   0]\n",
      " [  0  11  18 124   4  50   3]\n",
      " [ 49  26  24  14  80   7  10]\n",
      " [  0   8   4  12   2 141  43]\n",
      " [  1   2   0   5   2  42 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.73      0.67      0.70       210\n",
      "           3       0.71      0.78      0.74       210\n",
      "           4       0.70      0.59      0.64       210\n",
      "           5       0.78      0.38      0.51       210\n",
      "           6       0.41      0.67      0.51       210\n",
      "           7       0.73      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   5   2   9   7  27   0]\n",
      " [  0 140  22  10   7  31   0]\n",
      " [  0   0 169   7   0  34   0]\n",
      " [  0   9  25 120   5  48   3]\n",
      " [ 49  23  22  12  89   5  10]\n",
      " [  0   6   5  14   3 139  43]\n",
      " [  1   1   1   5   2  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.69      0.80      0.74       210\n",
      "           4       0.68      0.57      0.62       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.42      0.66      0.52       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   4   2   9  10  27   0]\n",
      " [  0 141  21   9   8  31   0]\n",
      " [  0   0 170   6   0  34   0]\n",
      " [  0  13  20 123   5  46   3]\n",
      " [ 48  19  23  15  90   6   9]\n",
      " [  0   9   4  16   1 138  42]\n",
      " [  1   1   0   4   3  44 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.68      0.59      0.63       210\n",
      "           5       0.77      0.43      0.55       210\n",
      "           6       0.42      0.66      0.51       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[162   5   2   9   5  27   0]\n",
      " [  0 140  24  11   6  29   0]\n",
      " [  0   0 170   7   0  33   0]\n",
      " [  0  10  21 125   6  45   3]\n",
      " [ 51  24  24  14  84   6   7]\n",
      " [  0   7   4  17   1 140  41]\n",
      " [  2   2   0   6   0  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.66      0.60      0.63       210\n",
      "           5       0.82      0.40      0.54       210\n",
      "           6       0.43      0.67      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.66      1470\n",
      "weighted avg       0.70      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[161   4   2   9   7  27   0]\n",
      " [  0 141  22   9   8  30   0]\n",
      " [  0   0 170   7   0  33   0]\n",
      " [  0  11  21 126   5  44   3]\n",
      " [ 50  21  24  14  86   7   8]\n",
      " [  0  10   4  18   1 140  37]\n",
      " [  2   2   0   6   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.70      0.81      0.75       210\n",
      "           4       0.67      0.60      0.63       210\n",
      "           5       0.80      0.41      0.54       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.76      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   4   2   8   9  28   0]\n",
      " [  0 141  22   8   8  31   0]\n",
      " [  0   0 170   7   1  32   0]\n",
      " [  0  10  22 131   4  40   3]\n",
      " [ 47  22  23  14  88   7   9]\n",
      " [  0   8   5  17   1 140  39]\n",
      " [  1   2   1   5   1  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.75      0.67      0.71       210\n",
      "           3       0.69      0.81      0.75       210\n",
      "           4       0.69      0.62      0.65       210\n",
      "           5       0.79      0.42      0.55       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.75      0.73      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   2   9   8  27   0]\n",
      " [  0 144  19   8   8  31   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  13  21 128   4  41   3]\n",
      " [ 47  23  22  16  88   7   7]\n",
      " [  0   9   4  15   2 142  38]\n",
      " [  2   2   0   6   0  43 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.76      0.76       210\n",
      "           2       0.74      0.69      0.71       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       0.67      0.61      0.64       210\n",
      "           5       0.80      0.42      0.55       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.77      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   4   2   9   8  27   0]\n",
      " [  0 150  16   5   6  33   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  12  21 129   4  41   3]\n",
      " [ 49  24  23  14  85   7   8]\n",
      " [  0   9   4  16   1 141  39]\n",
      " [  1   2   1   5   1  44 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.76      0.76       210\n",
      "           2       0.75      0.71      0.73       210\n",
      "           3       0.72      0.81      0.76       210\n",
      "           4       0.69      0.61      0.65       210\n",
      "           5       0.81      0.40      0.54       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[158   4   2   9  11  26   0]\n",
      " [  0 149  17   9   5  30   0]\n",
      " [  0   0 171   8   0  31   0]\n",
      " [  0  11  22 130   3  40   4]\n",
      " [ 46  29  24  15  85   5   6]\n",
      " [  0   9   4  16   1 142  38]\n",
      " [  1   2   1   5   1  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.73      0.71      0.72       210\n",
      "           3       0.71      0.81      0.76       210\n",
      "           4       0.68      0.62      0.65       210\n",
      "           5       0.80      0.40      0.54       210\n",
      "           6       0.44      0.68      0.54       210\n",
      "           7       0.76      0.73      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.7122448979591837\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   1   0   2  35   2   2]\n",
      " [ 12 159  13   6  19   1   0]\n",
      " [ 16   2 174   8   9   1   0]\n",
      " [ 19   6  12 152  12   6   3]\n",
      " [ 24  16  18  13 134   2   3]\n",
      " [ 41   8   5  20   9  81  46]\n",
      " [  6   3   0   1   3  18 179]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.80      0.68       210\n",
      "           2       0.82      0.76      0.79       210\n",
      "           3       0.78      0.83      0.81       210\n",
      "           4       0.75      0.72      0.74       210\n",
      "           5       0.61      0.64      0.62       210\n",
      "           6       0.73      0.39      0.50       210\n",
      "           7       0.77      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "cv_500_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//cv_500_vectors.csv\",encoding_errors='ignore')\n",
    "cv_500_df\n",
    "\n",
    "# Train Test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(cv_500_df,labels_df['kabita_labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['kabita_labels'])\n",
    "\n",
    "# Modelling\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression()\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2687f07",
   "metadata": {},
   "source": [
    "### Data split for Term frequency vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4afe912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is: 0.7496598639455783\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[165   3   1   9  15  15   2]\n",
      " [  0 163  15   6   6  20   0]\n",
      " [  0   1 181   9   0  19   0]\n",
      " [  1   9  17 162   2  16   3]\n",
      " [ 24  18  18  17 125   2   6]\n",
      " [  0   7   4  23   2 139  35]\n",
      " [  0   3   0   6   1  33 167]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.79      0.82       210\n",
      "           2       0.80      0.78      0.79       210\n",
      "           3       0.77      0.86      0.81       210\n",
      "           4       0.70      0.77      0.73       210\n",
      "           5       0.83      0.60      0.69       210\n",
      "           6       0.57      0.66      0.61       210\n",
      "           7       0.78      0.80      0.79       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   8   3   3  13  32   1]\n",
      " [  4 155  23   2   8  18   0]\n",
      " [  5   5 180   5   0  15   0]\n",
      " [ 16  20  23 104   4  43   0]\n",
      " [ 55  26  23  14  46  45   1]\n",
      " [ 13  14   4  12   0 151  16]\n",
      " [  5   3   0   4   1  95 102]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.71      0.66       210\n",
      "           2       0.67      0.74      0.70       210\n",
      "           3       0.70      0.86      0.77       210\n",
      "           4       0.72      0.50      0.59       210\n",
      "           5       0.64      0.22      0.33       210\n",
      "           6       0.38      0.72      0.50       210\n",
      "           7       0.85      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.65      0.60      0.59      1470\n",
      "weighted avg       0.65      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model is: 0.5931972789115646\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156   9   2   6   7  30   0]\n",
      " [  2 163  21   1   6  17   0]\n",
      " [  3   1 185   7   0  14   0]\n",
      " [ 17  22  33 105   1  32   0]\n",
      " [ 65  33  29  18  34  30   1]\n",
      " [  7  18   7  18   0 142  18]\n",
      " [  7   9   2   5   0 100  87]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.74      0.67       210\n",
      "           2       0.64      0.78      0.70       210\n",
      "           3       0.66      0.88      0.76       210\n",
      "           4       0.66      0.50      0.57       210\n",
      "           5       0.71      0.16      0.26       210\n",
      "           6       0.39      0.68      0.49       210\n",
      "           7       0.82      0.41      0.55       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.57      1470\n",
      "weighted avg       0.64      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model is: 0.5965986394557823\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   8   2   6   6  34   0]\n",
      " [  2 163  21   1   6  17   0]\n",
      " [  2   1 187   6   0  14   0]\n",
      " [ 13  21  31 107   1  36   1]\n",
      " [ 64  33  32  15  30  35   1]\n",
      " [  7  19   6  17   0 143  18]\n",
      " [  5  11   2   5   0  94  93]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.73      0.67       210\n",
      "           2       0.64      0.78      0.70       210\n",
      "           3       0.67      0.89      0.76       210\n",
      "           4       0.68      0.51      0.58       210\n",
      "           5       0.70      0.14      0.24       210\n",
      "           6       0.38      0.68      0.49       210\n",
      "           7       0.82      0.44      0.58       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.57      1470\n",
      "weighted avg       0.64      0.60      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model is: 0.580952380952381\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156   7   1   4   3  39   0]\n",
      " [  2 160  23   2   4  19   0]\n",
      " [  2   1 186   6   0  15   0]\n",
      " [ 10  19  29 106   1  44   1]\n",
      " [ 69  32  32  14  26  36   1]\n",
      " [  8  23   8  13   0 142  16]\n",
      " [  7  10   2   6   0 107  78]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.74      0.67       210\n",
      "           2       0.63      0.76      0.69       210\n",
      "           3       0.66      0.89      0.76       210\n",
      "           4       0.70      0.50      0.59       210\n",
      "           5       0.76      0.12      0.21       210\n",
      "           6       0.35      0.68      0.46       210\n",
      "           7       0.81      0.37      0.51       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.65      0.58      0.56      1470\n",
      "weighted avg       0.65      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model is: 0.5877551020408164\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   8   1   1   3  43   0]\n",
      " [  2 157  23   2   3  23   0]\n",
      " [  2   1 184   7   0  16   0]\n",
      " [  9  19  29 108   1  44   0]\n",
      " [ 60  30  32  13  29  45   1]\n",
      " [  7  20   8   8   0 150  17]\n",
      " [  7   9   4   7   0 101  82]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.68       210\n",
      "           2       0.64      0.75      0.69       210\n",
      "           3       0.65      0.88      0.75       210\n",
      "           4       0.74      0.51      0.61       210\n",
      "           5       0.81      0.14      0.24       210\n",
      "           6       0.36      0.71      0.47       210\n",
      "           7       0.82      0.39      0.53       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.67      0.59      0.57      1470\n",
      "weighted avg       0.67      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model is: 0.5897959183673469\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   8   1   1   3  43   0]\n",
      " [  2 159  24   4   1  20   0]\n",
      " [  1   1 184   7   0  17   0]\n",
      " [  9  21  29 107   1  43   0]\n",
      " [ 64  29  33  14  24  45   1]\n",
      " [  6  13   9   9   0 158  15]\n",
      " [  5   8   2   6   0 108  81]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.68       210\n",
      "           2       0.67      0.76      0.71       210\n",
      "           3       0.65      0.88      0.75       210\n",
      "           4       0.72      0.51      0.60       210\n",
      "           5       0.83      0.11      0.20       210\n",
      "           6       0.36      0.75      0.49       210\n",
      "           7       0.84      0.39      0.53       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.67      0.59      0.57      1470\n",
      "weighted avg       0.67      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes is: 0.5571428571428572\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[156   2   9  19  21   1   2]\n",
      " [  9  98  89   7   4   3   0]\n",
      " [  4   6 193   6   0   0   1]\n",
      " [ 19  18  41 119   9   4   0]\n",
      " [ 82  13  13  43  53   3   3]\n",
      " [ 19  33  47  31   3  41  36]\n",
      " [ 11  13   4   3   1  19 159]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.74      0.61       210\n",
      "           2       0.54      0.47      0.50       210\n",
      "           3       0.49      0.92      0.64       210\n",
      "           4       0.52      0.57      0.54       210\n",
      "           5       0.58      0.25      0.35       210\n",
      "           6       0.58      0.20      0.29       210\n",
      "           7       0.79      0.76      0.77       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.53      1470\n",
      "weighted avg       0.57      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes is: 0.7142857142857143\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[162   1  11   2  30   4   0]\n",
      " [  1 161  24   7  13   4   0]\n",
      " [  0   1 198  10   0   1   0]\n",
      " [  7  10  33 144   6   7   3]\n",
      " [ 28  15  17  12 134   0   4]\n",
      " [  6  11  42  19   5  98  29]\n",
      " [  3   5   7   2   3  37 153]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       210\n",
      "           2       0.79      0.77      0.78       210\n",
      "           3       0.60      0.94      0.73       210\n",
      "           4       0.73      0.69      0.71       210\n",
      "           5       0.70      0.64      0.67       210\n",
      "           6       0.65      0.47      0.54       210\n",
      "           7       0.81      0.73      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM is: 0.7619047619047619\n",
      "Confusion Matrix of SVM is:\n",
      " [[174   1   0   4  13  16   2]\n",
      " [  0 173  11   7   2  17   0]\n",
      " [  0   1 183  10   0  16   0]\n",
      " [  0  12  18 150   2  24   4]\n",
      " [ 27  17  16  18 127   2   3]\n",
      " [  0   4   4  19   1 143  39]\n",
      " [  1   3   0   6   0  30 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.70      0.71      0.71       210\n",
      "           5       0.88      0.60      0.72       210\n",
      "           6       0.58      0.68      0.62       210\n",
      "           7       0.78      0.81      0.79       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM is: 0.7034013605442176\n",
      "Confusion Matrix of SVM is:\n",
      " [[138   0   0   6  24  40   2]\n",
      " [  0 155   9  17   7  22   0]\n",
      " [  1   4 176   7   2  20   0]\n",
      " [  5   7   9 150   2  34   3]\n",
      " [ 14   9   7  28 118  30   4]\n",
      " [  5   6   1  13   1 148  36]\n",
      " [  0   0   0   2   1  58 149]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.66      0.74       210\n",
      "           2       0.86      0.74      0.79       210\n",
      "           3       0.87      0.84      0.85       210\n",
      "           4       0.67      0.71      0.69       210\n",
      "           5       0.76      0.56      0.65       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.77      0.71      0.74       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.74      0.70      0.71      1470\n",
      "weighted avg       0.74      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM is: 0.7625850340136054\n",
      "Confusion Matrix of SVM is:\n",
      " [[167   1   0   7  18  15   2]\n",
      " [  0 164  10  13   4  19   0]\n",
      " [  0   3 180  11   1  15   0]\n",
      " [  1   6   9 161   3  26   4]\n",
      " [ 20  15   9  23 134   4   5]\n",
      " [  1   6   1  20   2 140  40]\n",
      " [  0   2   0   5   1  27 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.80      0.84       210\n",
      "           2       0.83      0.78      0.81       210\n",
      "           3       0.86      0.86      0.86       210\n",
      "           4       0.67      0.77      0.72       210\n",
      "           5       0.82      0.64      0.72       210\n",
      "           6       0.57      0.67      0.61       210\n",
      "           7       0.77      0.83      0.80       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM is: 0.6870748299319728\n",
      "Confusion Matrix of SVM is:\n",
      " [[158   2   0   5  27  14   4]\n",
      " [  1 155  21  12   4  17   0]\n",
      " [  0   1 160  30   0  19   0]\n",
      " [  0  11  19 150   2  20   8]\n",
      " [ 51  23  27  18  85   2   4]\n",
      " [  0   6   5  21   0 134  44]\n",
      " [  0   2   0   5   1  34 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       210\n",
      "           2       0.78      0.74      0.76       210\n",
      "           3       0.69      0.76      0.72       210\n",
      "           4       0.62      0.71      0.67       210\n",
      "           5       0.71      0.40      0.52       210\n",
      "           6       0.56      0.64      0.60       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree is: 0.20136054421768707\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [124   0  86   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.16      0.20      0.12      1470\n",
      "weighted avg       0.16      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree is: 0.25918367346938775\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85   0   0   0   0 125   0]\n",
      " [  1   0   2   0   0 207   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   0   1   0   0 208   0]\n",
      " [ 55   0   1   0   0 154   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  0   0   0   0   0 210   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.40      0.48       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.17      1.00      0.29       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.25      0.26      0.19      1470\n",
      "weighted avg       0.25      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree is: 0.3047619047619048\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   0   0   0  55  55   0]\n",
      " [  1   0   2   0   1 206   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   0   1   0   1 208   0]\n",
      " [ 68   0   1   0  52  89   0]\n",
      " [  0   0   0   0   0 210   0]\n",
      " [  2   0   0   0   0 208   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.52       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.48      0.25      0.33       210\n",
      "           6       0.19      1.00      0.32       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.25      1470\n",
      "weighted avg       0.32      0.30      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree is: 0.354421768707483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   0   0  55  77   0   0]\n",
      " [  0   0   2 206   2   0   0]\n",
      " [  0   0  86 124   0   0   0]\n",
      " [  0   0   1 208   1   0   0]\n",
      " [ 16   0   1  86 104   0   3]\n",
      " [  0   0   0 206   0   0   4]\n",
      " [  0   0   0 163   2   0  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.37      0.51       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.20      0.99      0.33       210\n",
      "           5       0.56      0.50      0.53       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.49      0.35      0.33      1470\n",
      "weighted avg       0.49      0.35      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  58   2   0   2 148   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 49   5   1   0  72  81   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   0   0   0   2 163  45]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.63      0.68       210\n",
      "           2       0.75      0.28      0.40       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.34      0.47       210\n",
      "           6       0.21      0.97      0.34       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.61      0.41      0.40      1470\n",
      "weighted avg       0.61      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   5   0   0  22  50   0]\n",
      " [  0  92   2   0   2 114   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  1   6   1   0   0 202   0]\n",
      " [ 44  17   1   0  77  69   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.63      0.69       210\n",
      "           2       0.74      0.44      0.55       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.37      0.49       210\n",
      "           6       0.22      0.97      0.36       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.61      0.43      0.43      1470\n",
      "weighted avg       0.61      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   0   0  36  50   0]\n",
      " [  0 131   2   0   2  75   0]\n",
      " [  0   0  86   0   0 124   0]\n",
      " [  0   6   1   0   1 202   0]\n",
      " [ 34  22   1   0  87  64   2]\n",
      " [  0   3   0   0   0 203   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.96      0.41      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.68      0.41      0.51       210\n",
      "           6       0.23      0.97      0.37       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.61      0.46      0.45      1470\n",
      "weighted avg       0.61      0.46      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree is: 0.4884353741496599\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   5   1   0  36  49   0]\n",
      " [  0 130  21   1   2  56   0]\n",
      " [  0   0 132   0   0  78   0]\n",
      " [  0   6  17   0   1 186   0]\n",
      " [ 29  22  19   0  92  46   2]\n",
      " [  0   3   2   0   0 201   4]\n",
      " [  0   1   0   0   2 163  44]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.57      0.66       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.69      0.63      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.69      0.44      0.54       210\n",
      "           6       0.26      0.96      0.41       210\n",
      "           7       0.88      0.21      0.34       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.59      0.49      0.47      1470\n",
      "weighted avg       0.59      0.49      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[119   6   0   0  36  49   0]\n",
      " [  0 147   3   1   3  56   0]\n",
      " [  0  31 101   0   0  78   0]\n",
      " [  0  22   1   0   1 184   2]\n",
      " [ 27  35   3   0  97  45   3]\n",
      " [  0   5   0   0   0 188  17]\n",
      " [  0   1   0   0   2 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.57      0.67       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.94      0.48      0.64       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.46      0.56       210\n",
      "           6       0.26      0.90      0.40       210\n",
      "           7       0.76      0.33      0.46       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.58      0.49      0.48      1470\n",
      "weighted avg       0.58      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree is: 0.4931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   5   0   0  16  49   0]\n",
      " [  0 143   4   1   7  55   0]\n",
      " [  0  30 113   0   1  66   0]\n",
      " [  0  17   4   0   6 181   2]\n",
      " [ 58  29   3   0  72  46   2]\n",
      " [  0   4   1   0   1 187  17]\n",
      " [  2   1   0   0   0 137  70]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.68       210\n",
      "           2       0.62      0.68      0.65       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.70      0.34      0.46       210\n",
      "           6       0.26      0.89      0.40       210\n",
      "           7       0.77      0.33      0.47       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   5   0  49  36   0   0]\n",
      " [  0 143   4  56   7   0   0]\n",
      " [  0  30 113  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 31  26   3  46  99   1   4]\n",
      " [  0   4   1 182   1   1  21]\n",
      " [  0   1   0 111   2   1  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.57      0.66       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.90      0.54      0.67       210\n",
      "           4       0.26      0.87      0.40       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.77      0.45      0.57       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.62      0.51      0.50      1470\n",
      "weighted avg       0.62      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109   5   0  50  46   0   0]\n",
      " [  0 131  15  56   8   0   0]\n",
      " [  0   0 143  66   1   0   0]\n",
      " [  0   7  11 182   6   0   4]\n",
      " [ 23  15  13  45 110   1   3]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   4   2 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.52      0.64       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.78      0.68      0.73       210\n",
      "           4       0.27      0.87      0.41       210\n",
      "           5       0.62      0.52      0.57       210\n",
      "           6       0.25      0.00      0.01       210\n",
      "           7       0.77      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.62      0.53      0.52      1470\n",
      "weighted avg       0.62      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree is: 0.5394557823129251\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   5   0  40  33   0   0]\n",
      " [  0 142   4  56   8   0   0]\n",
      " [  0  21 122  66   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 30  24   4  41 109   1   1]\n",
      " [  0   4   1 178   1   1  25]\n",
      " [  0   1   0  96   2   6 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.63      0.71       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.90      0.58      0.71       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.68      0.52      0.59       210\n",
      "           6       0.12      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.61      0.54      0.53      1470\n",
      "weighted avg       0.61      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   5   0  40  15   0   0]\n",
      " [  0 141   5  56   8   0   0]\n",
      " [  0  17 135  57   1   0   0]\n",
      " [  0  14   4 182   6   0   4]\n",
      " [ 49  23   5  41  88   1   3]\n",
      " [  0   4   1 178   2   1  24]\n",
      " [  2   1   0  96   2   7 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.71      0.73       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.90      0.64      0.75       210\n",
      "           4       0.28      0.87      0.42       210\n",
      "           5       0.72      0.42      0.53       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.49      0.59       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.60      0.54      0.53      1470\n",
      "weighted avg       0.60      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is: 0.5489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[135   5   0  40  30   0   0]\n",
      " [  0 141   7  54   8   0   0]\n",
      " [  0  13 146  50   1   0   0]\n",
      " [  0  13   8 179   6   0   4]\n",
      " [ 36  23   5  40 104   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  0   1   0  96   5   7 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.64      0.71       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.87      0.70      0.77       210\n",
      "           4       0.28      0.85      0.42       210\n",
      "           5       0.67      0.50      0.57       210\n",
      "           6       0.11      0.00      0.01       210\n",
      "           7       0.77      0.48      0.59       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.60      0.55      0.54      1470\n",
      "weighted avg       0.60      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   5   0  40  20   0   0]\n",
      " [  0 140   8  53   9   0   0]\n",
      " [  0  13 151  45   1   0   0]\n",
      " [  0  13  11 176   6   0   4]\n",
      " [ 43  23   5  41  96   1   1]\n",
      " [  0   4   2 177   1   1  25]\n",
      " [  1   1   0  96   3   4 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.69      0.73       210\n",
      "           2       0.70      0.67      0.68       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.28      0.84      0.42       210\n",
      "           5       0.71      0.46      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.78      0.50      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.61      0.55      0.54      1470\n",
      "weighted avg       0.61      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree is: 0.5591836734693878\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[147   5   0  40  18   0   0]\n",
      " [  0 137   7  53  13   0   0]\n",
      " [  0   8 151  45   6   0   0]\n",
      " [  0  13   9 175   9   0   4]\n",
      " [ 43  17   5  40 100   1   4]\n",
      " [  0   5   1 173   2   1  28]\n",
      " [  1   1   0  88   5   4 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.70      0.73       210\n",
      "           2       0.74      0.65      0.69       210\n",
      "           3       0.87      0.72      0.79       210\n",
      "           4       0.29      0.83      0.42       210\n",
      "           5       0.65      0.48      0.55       210\n",
      "           6       0.17      0.00      0.01       210\n",
      "           7       0.76      0.53      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.61      0.56      0.55      1470\n",
      "weighted avg       0.61      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree is: 0.5673469387755102\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 138   8   1  11  52   0]\n",
      " [  0   8 153   0   4  45   0]\n",
      " [  0  13  10  13   8 162   4]\n",
      " [ 40  16   5   2 104  39   4]\n",
      " [  0   4   1   0   2 175  28]\n",
      " [  1   1   0   0   2  98 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.76      0.06      0.11       210\n",
      "           5       0.68      0.50      0.57       210\n",
      "           6       0.29      0.83      0.43       210\n",
      "           7       0.75      0.51      0.61       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.56      1470\n",
      "weighted avg       0.70      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[143   5   0   1  22  39   0]\n",
      " [  0 139   7   2  11  51   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 39  16   5   4 106  36   4]\n",
      " [  0   5   1   1   2 175  26]\n",
      " [  1   1   0   1   1  93 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.73       210\n",
      "           2       0.74      0.66      0.70       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.78      0.17      0.27       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.30      0.83      0.44       210\n",
      "           7       0.77      0.54      0.63       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.71      0.59      0.59      1470\n",
      "weighted avg       0.71      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree is: 0.5877551020408164\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   5   0   1  24  39   0]\n",
      " [  0 148   7   3  11  41   0]\n",
      " [  0   8 153   1   4  44   0]\n",
      " [  0  13  10  35   7 142   3]\n",
      " [ 42  19   5   6 103  33   2]\n",
      " [  0   5   1   1   3 175  25]\n",
      " [  1   1   0   1   1  97 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.72       210\n",
      "           2       0.74      0.70      0.72       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.73      0.17      0.27       210\n",
      "           5       0.67      0.49      0.57       210\n",
      "           6       0.31      0.83      0.45       210\n",
      "           7       0.78      0.52      0.62       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.70      0.59      0.59      1470\n",
      "weighted avg       0.70      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest is: 0.5904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   2  18   9  21   5]\n",
      " [  1 120  20  16   5  47   1]\n",
      " [  0   0 148  15   0  47   0]\n",
      " [  2   7  10 126   2  59   4]\n",
      " [ 62  28  13  31  47  15  14]\n",
      " [  0   4   4  35   0 129  38]\n",
      " [  0   1   0  17   0  45 147]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.73      0.57      0.64       210\n",
      "           3       0.75      0.70      0.73       210\n",
      "           4       0.49      0.60      0.54       210\n",
      "           5       0.75      0.22      0.34       210\n",
      "           6       0.36      0.61      0.45       210\n",
      "           7       0.70      0.70      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.64      0.59      0.59      1470\n",
      "weighted avg       0.64      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   5   3  19  10  21   5]\n",
      " [  1 130  16  10  15  37   1]\n",
      " [  0   0 157  13   0  40   0]\n",
      " [  1  10  13 124   4  54   4]\n",
      " [ 59  20   9  28  66  12  16]\n",
      " [  0   8   5  28   0 126  43]\n",
      " [  0   1   0  12   0  41 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70       210\n",
      "           2       0.75      0.62      0.68       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.69      0.31      0.43       210\n",
      "           6       0.38      0.60      0.47       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.6204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   1  16  11  22   5]\n",
      " [  0 128  17  13  15  36   1]\n",
      " [  0   0 160  14   0  36   0]\n",
      " [  1  12  11 130   6  46   4]\n",
      " [ 65  19  11  31  59  10  15]\n",
      " [  0   7   5  22   3 130  43]\n",
      " [  0   1   0   9   0  46 154]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.75      0.61      0.67       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.55      0.62      0.58       210\n",
      "           5       0.63      0.28      0.39       210\n",
      "           6       0.40      0.62      0.49       210\n",
      "           7       0.69      0.73      0.71       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.64      0.62      0.62      1470\n",
      "weighted avg       0.64      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0  10  12  28   3]\n",
      " [  0 133  16  12  12  36   1]\n",
      " [  0   0 162  12   0  36   0]\n",
      " [  1  11  11 121  10  52   4]\n",
      " [ 53  20   8  22  81  13  13]\n",
      " [  0   6   4  19   3 134  44]\n",
      " [  0   1   0   8   1  40 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.59      0.58      0.58       210\n",
      "           5       0.68      0.39      0.49       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.71      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0  11  13  27   4]\n",
      " [  0 129  17  14  16  33   1]\n",
      " [  0   0 163  13   0  34   0]\n",
      " [  1  11  10 123   8  53   4]\n",
      " [ 51  19   8  24  85  11  12]\n",
      " [  0   7   5  19   2 133  44]\n",
      " [  0   1   0   8   1  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       210\n",
      "           2       0.75      0.61      0.68       210\n",
      "           3       0.80      0.78      0.79       210\n",
      "           4       0.58      0.59      0.58       210\n",
      "           5       0.68      0.40      0.51       210\n",
      "           6       0.40      0.63      0.49       210\n",
      "           7       0.71      0.76      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest is: 0.638095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0  15  14  24   2]\n",
      " [  1 134  15  11  14  35   0]\n",
      " [  0   0 161  14   0  35   0]\n",
      " [  0  11  10 136   9  41   3]\n",
      " [ 62  20   8  26  70  12  12]\n",
      " [  0   6   4  22   3 131  44]\n",
      " [  0   1   0   9   1  43 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.76      0.64      0.69       210\n",
      "           3       0.81      0.77      0.79       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.63      0.33      0.44       210\n",
      "           6       0.41      0.62      0.49       210\n",
      "           7       0.72      0.74      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  19  30   2]\n",
      " [  0 138  14  11  13  34   0]\n",
      " [  0   2 164  11   0  33   0]\n",
      " [  0  10  10 131   9  47   3]\n",
      " [ 55  18   8  18  84  16  11]\n",
      " [  0   6   5  16   3 135  45]\n",
      " [  0   2   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.69      0.71       210\n",
      "           2       0.76      0.66      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.65      0.40      0.50       210\n",
      "           6       0.40      0.64      0.49       210\n",
      "           7       0.72      0.75      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  13  30   2]\n",
      " [  0 138  15  11  14  32   0]\n",
      " [  0   0 166  12   0  32   0]\n",
      " [  0  13  10 132   8  44   3]\n",
      " [ 52  18   8  18  89  15  10]\n",
      " [  0   8   4  16   4 135  43]\n",
      " [  0   2   0   4   1  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.66      0.63      0.64       210\n",
      "           5       0.69      0.42      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.73      0.76      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   5   0   8  15  30   0]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   0 164  13   0  33   0]\n",
      " [  0  13  10 129  12  43   3]\n",
      " [ 49  18   8  18  91  16  10]\n",
      " [  0   8   4  17   3 134  44]\n",
      " [  0   1   0   5   1  42 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       210\n",
      "           2       0.76      0.67      0.71       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.65      0.61      0.63       210\n",
      "           5       0.67      0.43      0.53       210\n",
      "           6       0.41      0.64      0.50       210\n",
      "           7       0.74      0.77      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest is: 0.6625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   5   0   9  22  30   1]\n",
      " [  0 138  15   9  15  33   0]\n",
      " [  0   0 167  12   0  31   0]\n",
      " [  0  12  10 134  10  41   3]\n",
      " [ 42  18   8  18  99  15  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   1   0   6   2  45 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.77      0.66      0.71       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.65      0.47      0.55       210\n",
      "           6       0.41      0.65      0.51       210\n",
      "           7       0.74      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   5   0   9  23  29   0]\n",
      " [  0 140  17  10  14  29   0]\n",
      " [  0   0 173  14   0  23   0]\n",
      " [  0  11  11 133  10  42   3]\n",
      " [ 41  15   9  19 104  12  10]\n",
      " [  0   6   5  16   4 137  42]\n",
      " [  0   0   0   5   2  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.69      0.73       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.65      0.63      0.64       210\n",
      "           5       0.66      0.50      0.57       210\n",
      "           6       0.43      0.65      0.52       210\n",
      "           7       0.74      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   5   0   9  17  29   0]\n",
      " [  0 143  11  10  15  31   0]\n",
      " [  0   1 172  11   0  26   0]\n",
      " [  0   9   8 134   9  47   3]\n",
      " [ 41  17   8  18 105  12   9]\n",
      " [  0   7   1  16   4 141  41]\n",
      " [  1   0   0   5   2  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.75       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.86      0.82      0.84       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.69      0.50      0.58       210\n",
      "           6       0.43      0.67      0.52       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   5   0   9  21  29   1]\n",
      " [  0 141  15  10  14  30   0]\n",
      " [  0   4 174   9   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   8  17 112  13   9]\n",
      " [  0   5   3  16   4 140  42]\n",
      " [  0   1   0   6   2  43 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.69      0.75       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.82      0.83      0.82       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.68      0.53      0.60       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest is: 0.6857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   5   0   9  14  29   0]\n",
      " [  0 141  14   9  16  30   0]\n",
      " [  0   1 175  11   0  23   0]\n",
      " [  0   9  12 131  11  43   4]\n",
      " [ 34  17   7  16 114  13   9]\n",
      " [  0   4   3  16   5 138  44]\n",
      " [  1   1   0   5   1  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.73      0.77       210\n",
      "           2       0.79      0.67      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.62      0.64       210\n",
      "           5       0.71      0.54      0.61       210\n",
      "           6       0.43      0.66      0.52       210\n",
      "           7       0.73      0.74      0.74       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   4   0   9  16  29   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   5 171  10   0  24   0]\n",
      " [  0  10  10 134  10  42   4]\n",
      " [ 38  18   7  20 109  10   8]\n",
      " [  0   5   3  14   5 142  41]\n",
      " [  1   1   0   5   1  43 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.66      0.64      0.65       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.44      0.68      0.54       210\n",
      "           7       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest is: 0.6816326530612244\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   5   0   9  25  29   0]\n",
      " [  0 141  15  12  13  29   0]\n",
      " [  0   1 175  10   0  24   0]\n",
      " [  0  10  10 133  11  42   4]\n",
      " [ 37  16   8  17 111  12   9]\n",
      " [  0   6   2  16   5 142  39]\n",
      " [  1   1   0   5   1  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.68      0.73       210\n",
      "           2       0.78      0.67      0.72       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.66      0.63      0.65       210\n",
      "           5       0.67      0.53      0.59       210\n",
      "           6       0.44      0.68      0.53       210\n",
      "           7       0.75      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   5   0   9  21  29   0]\n",
      " [  0 141  14  11  14  30   0]\n",
      " [  0   4 171  10   0  25   0]\n",
      " [  0   8   9 137  12  41   3]\n",
      " [ 31  17   7  20 115  11   9]\n",
      " [  0   4   1  14   7 146  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.75       210\n",
      "           2       0.79      0.67      0.72       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.67      0.65      0.66       210\n",
      "           5       0.67      0.55      0.60       210\n",
      "           6       0.45      0.70      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest is: 0.6925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   4   0   9  17  29   0]\n",
      " [  0 146  14   9  11  30   0]\n",
      " [  0   4 175   7   0  24   0]\n",
      " [  0  11  11 134  10  41   3]\n",
      " [ 36  21   7  20 109   8   9]\n",
      " [  0   6   3  14   5 144  38]\n",
      " [  1   0   0   5   3  42 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76       210\n",
      "           2       0.76      0.70      0.73       210\n",
      "           3       0.83      0.83      0.83       210\n",
      "           4       0.68      0.64      0.66       210\n",
      "           5       0.70      0.52      0.60       210\n",
      "           6       0.45      0.69      0.55       210\n",
      "           7       0.76      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   0   9  28  28   0]\n",
      " [  0 143  13  10  14  30   0]\n",
      " [  0   4 175   7   1  23   0]\n",
      " [  0   7  10 135  12  43   3]\n",
      " [ 29  20   7  16 118  11   9]\n",
      " [  0   5   2  13   6 144  40]\n",
      " [  1   1   0   5   3  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.77      0.68      0.72       210\n",
      "           3       0.85      0.83      0.84       210\n",
      "           4       0.69      0.64      0.67       210\n",
      "           5       0.65      0.56      0.60       210\n",
      "           6       0.45      0.69      0.54       210\n",
      "           7       0.75      0.76      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.70      1470\n",
      "weighted avg       0.71      0.69      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest is: 0.6979591836734694\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   5   0   8  20  29   0]\n",
      " [  0 150  12  10   8  30   0]\n",
      " [  0   2 176   8   0  24   0]\n",
      " [  0   9  10 135  11  42   3]\n",
      " [ 30  20   8  16 118  10   8]\n",
      " [  0   5   3  15   6 141  40]\n",
      " [  1   0   0   5   2  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       210\n",
      "           2       0.79      0.71      0.75       210\n",
      "           3       0.84      0.84      0.84       210\n",
      "           4       0.69      0.64      0.66       210\n",
      "           5       0.72      0.56      0.63       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.76      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes is: 0.7163265306122449\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   1   0   3  34   4   0]\n",
      " [ 12 158  13   8  16   3   0]\n",
      " [ 14   1 182  11   1   1   0]\n",
      " [ 16   8  13 150  12   8   3]\n",
      " [ 23  17  16  13 135   2   4]\n",
      " [ 37   8   5  21   8  79  52]\n",
      " [  5   3   0   2   3  16 181]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.80      0.69       210\n",
      "           2       0.81      0.75      0.78       210\n",
      "           3       0.79      0.87      0.83       210\n",
      "           4       0.72      0.71      0.72       210\n",
      "           5       0.65      0.64      0.64       210\n",
      "           6       0.70      0.38      0.49       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.71      1470\n",
      "weighted avg       0.72      0.72      0.71      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# reading dataset\n",
    "tf_500_df = pd.read_csv(pwd+\"//Datasets//Kabita//BagOfWords//tf_500_vectors.csv\",encoding_errors='ignore')\n",
    "tf_500_df\n",
    "\n",
    "# Train Test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(tf_500_df,labels_df['kabita_labels'],test_size=0.30,\n",
    "                                                 random_state=21,stratify=labels_df['kabita_labels'])\n",
    "\n",
    "# Modelling\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression()\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158cf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
