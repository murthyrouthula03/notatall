{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0524b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac20b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John is good boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>good is nice Habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>boy does Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>habit of john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>is girl nice?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>doing bad things is so bad and worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>doing bad things is so bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              sentence\n",
       "0   1                      John is good boy\n",
       "1   2                    good is nice Habit\n",
       "2   3                         boy does Good\n",
       "3   4                         habit of john\n",
       "4   5                         is girl nice?\n",
       "5   6  doing bad things is so bad and worst\n",
       "6   7            doing bad things is so bad"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv('C://Users//murth//Desktop//new1.csv')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea26618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'boy', 'does', 'doing', 'girl', 'good', 'habit', 'john', 'nice', 'things', 'worst']\n",
      "[[0.         0.60515811 0.         0.         0.         0.51726909\n",
      "  0.         0.60515811 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.51726909\n",
      "  0.60515811 0.         0.60515811 0.         0.        ]\n",
      " [0.         0.56060334 0.67535583 0.         0.         0.47918515\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.70710678 0.70710678 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.76944876 0.\n",
      "  0.         0.         0.63870855 0.         0.        ]\n",
      " [0.73267992 0.         0.         0.36633996 0.         0.\n",
      "  0.         0.         0.         0.36633996 0.44132778]\n",
      " [0.81649658 0.         0.         0.40824829 0.         0.\n",
      "  0.         0.         0.         0.40824829 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "X = vectorizer.fit_transform(new_df['sentence'])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0ec044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>boy</th>\n",
       "      <th>does</th>\n",
       "      <th>doing</th>\n",
       "      <th>girl</th>\n",
       "      <th>good</th>\n",
       "      <th>habit</th>\n",
       "      <th>john</th>\n",
       "      <th>nice</th>\n",
       "      <th>things</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560603</td>\n",
       "      <td>0.675356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.732680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366340</td>\n",
       "      <td>0.441328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bad       boy      does     doing      girl      good     habit  \\\n",
       "0  0.000000  0.605158  0.000000  0.000000  0.000000  0.517269  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.517269  0.605158   \n",
       "2  0.000000  0.560603  0.675356  0.000000  0.000000  0.479185  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.707107   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.769449  0.000000  0.000000   \n",
       "5  0.732680  0.000000  0.000000  0.366340  0.000000  0.000000  0.000000   \n",
       "6  0.816497  0.000000  0.000000  0.408248  0.000000  0.000000  0.000000   \n",
       "\n",
       "       john      nice    things     worst  \n",
       "0  0.605158  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.605158  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.707107  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.638709  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.366340  0.441328  \n",
       "6  0.000000  0.000000  0.408248  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_df = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da750eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>bad</th>\n",
       "      <th>boy</th>\n",
       "      <th>does</th>\n",
       "      <th>doing</th>\n",
       "      <th>girl</th>\n",
       "      <th>good</th>\n",
       "      <th>habit</th>\n",
       "      <th>john</th>\n",
       "      <th>nice</th>\n",
       "      <th>things</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John is good boy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>good is nice Habit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>boy does Good</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560603</td>\n",
       "      <td>0.675356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>habit of john</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>is girl nice?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>doing bad things is so bad and worst</td>\n",
       "      <td>0.732680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366340</td>\n",
       "      <td>0.441328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>doing bad things is so bad</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              sentence       bad       boy      does  \\\n",
       "0   1                      John is good boy  0.000000  0.605158  0.000000   \n",
       "1   2                    good is nice Habit  0.000000  0.000000  0.000000   \n",
       "2   3                         boy does Good  0.000000  0.560603  0.675356   \n",
       "3   4                         habit of john  0.000000  0.000000  0.000000   \n",
       "4   5                         is girl nice?  0.000000  0.000000  0.000000   \n",
       "5   6  doing bad things is so bad and worst  0.732680  0.000000  0.000000   \n",
       "6   7            doing bad things is so bad  0.816497  0.000000  0.000000   \n",
       "\n",
       "      doing      girl      good     habit      john      nice    things  \\\n",
       "0  0.000000  0.000000  0.517269  0.000000  0.605158  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.517269  0.605158  0.000000  0.605158  0.000000   \n",
       "2  0.000000  0.000000  0.479185  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.707107  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.769449  0.000000  0.000000  0.000000  0.638709  0.000000   \n",
       "5  0.366340  0.000000  0.000000  0.000000  0.000000  0.000000  0.366340   \n",
       "6  0.408248  0.000000  0.000000  0.000000  0.000000  0.000000  0.408248   \n",
       "\n",
       "      worst  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.441328  \n",
       "6  0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df = pd.concat([new_df,con_df],axis=1)\n",
    "fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c40181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aadi', 'aaj', 'aap', 'aapne', 'aata', 'aati', 'aaya', 'aaye', 'ab', 'abbe', 'abbey', 'abe', 'abhi', 'able', 'about', 'above', 'accha', 'according', 'accordingly', 'acha', 'achcha', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'agar', 'ain', 'aint', \"ain't\", 'aisa', 'aise', 'aisi', 'alag', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'andar', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'ap', 'apan', 'apart', 'apna', 'apnaa', 'apne', 'apni', 'appear', 'are', 'aren', 'arent', \"aren't\", 'around', 'arre', 'as', 'aside', 'ask', 'asking', 'at', 'aur', 'avum', 'aya', 'aye', 'baad', 'baar', 'bad', 'bahut', 'bana', 'banae', 'banai', 'banao', 'banaya', 'banaye', 'banayi', 'banda', 'bande', 'bandi', 'bane', 'bani', 'bas', 'bata', 'batao', 'bc', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'bhai', 'bheetar', 'bhi', 'bhitar', 'bht', 'bilkul', 'bohot', 'bol', 'bola', 'bole', 'boli', 'bolo', 'bolta', 'bolte', 'bolti', 'both', 'brief', 'bro', 'btw', 'but', 'by', 'came', 'can', 'cannot', 'cant', \"can't\", 'cause', 'causes', 'certain', 'certainly', 'chahiye', 'chaiye', 'chal', 'chalega', 'chhaiye', 'clearly', \"c'mon\", 'com', 'come', 'comes', 'could', 'couldn', 'couldnt', \"couldn't\", 'd', 'de', 'dede', 'dega', 'degi', 'dekh', 'dekha', 'dekhe', 'dekhi', 'dekho', 'denge', 'dhang', 'di', 'did', 'didn', 'didnt', \"didn't\", 'dijiye', 'diya', 'diyaa', 'diye', 'diyo', 'do', 'does', 'doesn', 'doesnt', \"doesn't\", 'doing', 'done', 'dono', 'dont', \"don't\", 'doosra', 'doosre', 'down', 'downwards', 'dude', 'dunga', 'dungi', 'during', 'dusra', 'dusre', 'dusri', 'dvaara', 'dvara', 'dwaara', 'dwara', 'each', 'edu', 'eg', 'eight', 'either', 'ek', 'else', 'elsewhere', 'enough', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'far', 'few', 'fifth', 'fir', 'first', 'five', 'followed', 'following', 'follows', 'for', 'forth', 'four', 'from', 'further', 'furthermore', 'gaya', 'gaye', 'gayi', 'get', 'gets', 'getting', 'ghar', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'greetings', 'haan', 'had', 'hadd', 'hadn', 'hadnt', \"hadn't\", 'hai', 'hain', 'hamara', 'hamare', 'hamari', 'hamne', 'han', 'happens', 'har', 'hardly', 'has', 'hasn', 'hasnt', \"hasn't\", 'have', 'haven', 'havent', \"haven't\", 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', \"here's\", 'hereupon', 'hers', 'herself', \"he's\", 'hi', 'him', 'himself', 'his', 'hither', 'hm', 'hmm', 'ho', 'hoga', 'hoge', 'hogi', 'hona', 'honaa', 'hone', 'honge', 'hongi', 'honi', 'hopefully', 'hota', 'hotaa', 'hote', 'hoti', 'how', 'howbeit', 'however', 'hoyenge', 'hoyengi', 'hu', 'hua', 'hue', 'huh', 'hui', 'hum', 'humein', 'humne', 'hun', 'huye', 'huyi', 'i', \"i'd\", 'idk', 'ie', 'if', \"i'll\", \"i'm\", 'imo', 'in', 'inasmuch', 'inc', 'inhe', 'inhi', 'inho', 'inka', 'inkaa', 'inke', 'inki', 'inn', 'inner', 'inse', 'insofar', 'into', 'inward', 'is', 'ise', 'isi', 'iska', 'iskaa', 'iske', 'iski', 'isme', 'isn', 'isne', 'isnt', \"isn't\", 'iss', 'isse', 'issi', 'isski', 'it', \"it'd\", \"it'll\", 'itna', 'itne', 'itni', 'itno', 'its', \"it's\", 'itself', 'ityaadi', 'ityadi', \"i've\", 'ja', 'jaa', 'jab', 'jabh', 'jaha', 'jahaan', 'jahan', 'jaisa', 'jaise', 'jaisi', 'jata', 'jayega', 'jidhar', 'jin', 'jinhe', 'jinhi', 'jinho', 'jinhone', 'jinka', 'jinke', 'jinki', 'jinn', 'jis', 'jise', 'jiska', 'jiske', 'jiski', 'jisme', 'jiss', 'jisse', 'jitna', 'jitne', 'jitni', 'jo', 'just', 'jyaada', 'jyada', 'k', 'ka', 'kaafi', 'kab', 'kabhi', 'kafi', 'kaha', 'kahaa', 'kahaan', 'kahan', 'kahi', 'kahin', 'kahte', 'kaisa', 'kaise', 'kaisi', 'kal', 'kam', 'kar', 'kara', 'kare', 'karega', 'karegi', 'karen', 'karenge', 'kari', 'karke', 'karna', 'karne', 'karni', 'karo', 'karta', 'karte', 'karti', 'karu', 'karun', 'karunga', 'karungi', 'kaun', 'kaunsa', 'kayi', 'kch', 'ke', 'keep', 'keeps', 'keh', 'kehte', 'kept', 'khud', 'ki', 'kin', 'kine', 'kinhe', 'kinho', 'kinka', 'kinke', 'kinki', 'kinko', 'kinn', 'kino', 'kis', 'kise', 'kisi', 'kiska', 'kiske', 'kiski', 'kisko', 'kisliye', 'kisne', 'kitna', 'kitne', 'kitni', 'kitno', 'kiya', 'kiye', 'know', 'known', 'knows', 'ko', 'koi', 'kon', 'konsa', 'koyi', 'krna', 'krne', 'kuch', 'kuchch', 'kuchh', 'kul', 'kull', 'kya', 'kyaa', 'kyu', 'kyuki', 'kyun', 'kyunki', 'lagta', 'lagte', 'lagti', 'last', 'lately', 'later', 'le', 'least', 'lekar', 'lekin', 'less', 'lest', 'let', \"let's\", 'li', 'like', 'liked', 'likely', 'little', 'liya', 'liye', 'll', 'lo', 'log', 'logon', 'lol', 'look', 'looking', 'looks', 'ltd', 'lunga', 'm', 'maan', 'maana', 'maane', 'maani', 'maano', 'magar', 'mai', 'main', 'maine', 'mainly', 'mana', 'mane', 'mani', 'mano', 'many', 'mat', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'mein', 'mera', 'mere', 'merely', 'meri', 'might', 'mightn', 'mightnt', \"mightn't\", 'mil', 'mjhe', 'more', 'moreover', 'most', 'mostly', 'much', 'mujhe', 'must', 'mustn', 'mustnt', \"mustn't\", 'my', 'myself', 'na', 'naa', 'naah', 'nahi', 'nahin', 'nai', 'name', 'namely', 'nd', 'ne', 'near', 'nearly', 'necessary', 'neeche', 'need', 'needn', 'neednt', \"needn't\", 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nhi', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nope', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'par', 'pata', 'pe', 'pehla', 'pehle', 'pehli', 'people', 'per', 'perhaps', 'phla', 'phle', 'phli', 'placed', 'please', 'plus', 'poora', 'poori', 'provides', 'pura', 'puri', 'q', 'que', 'quite', 'raha', 'rahaa', 'rahe', 'rahi', 'rakh', 'rakha', 'rakhe', 'rakhen', 'rakhi', 'rakho', 'rather', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'rehte', 'rha', 'rhaa', 'rhe', 'rhi', 'ri', 'right', 's', 'sa', 'saara', 'saare', 'saath', 'sab', 'sabhi', 'sabse', 'sahi', 'said', 'sakta', 'saktaa', 'sakte', 'sakti', 'same', 'sang', 'sara', 'sath', 'saw', 'say', 'saying', 'says', 'se', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'shan', 'shant', \"shan't\", 'she', \"she's\", 'should', 'shouldn', 'shouldnt', \"shouldn't\", \"should've\", 'si', 'since', 'six', 'so', 'soch', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'still', 'sub', 'such', 'sup', 'sure', 't', 'tab', 'tabh', 'tak', 'take', 'taken', 'tarah', 'teen', 'teeno', 'teesra', 'teesre', 'teesri', 'tell', 'tends', 'tera', 'tere', 'teri', 'th', 'tha', 'than', 'thank', 'thanks', 'thanx', 'that', \"that'll\", 'thats', \"that's\", 'the', 'theek', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', \"there's\", 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'thi', 'thik', 'thing', 'think', 'thinking', 'third', 'this', 'tho', 'thoda', 'thodi', 'thorough', 'thoroughly', 'those', 'though', 'thought', 'three', 'through', 'throughout', 'thru', 'thus', 'tjhe', 'to', 'together', 'toh', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'true', 'truly', 'try', 'trying', 'tu', 'tujhe', 'tum', 'tumhara', 'tumhare', 'tumhari', 'tune', 'twice', 'two', 'um', 'umm', 'un', 'under', 'unhe', 'unhi', 'unho', 'unhone', 'unka', 'unkaa', 'unke', 'unki', 'unko', 'unless', 'unlikely', 'unn', 'unse', 'until', 'unto', 'up', 'upar', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'usi', 'using', 'uska', 'uske', 'usne', 'uss', 'usse', 'ussi', 'usually', 'vaala', 'vaale', 'vaali', 'vahaan', 'vahan', 'vahi', 'vahin', 'vaisa', 'vaise', 'vaisi', 'vala', 'vale', 'vali', 'various', 've', 'very', 'via', 'viz', 'vo', 'waala', 'waale', 'waali', 'wagaira', 'wagairah', 'wagerah', 'waha', 'wahaan', 'wahan', 'wahi', 'wahin', 'waisa', 'waise', 'waisi', 'wala', 'wale', 'wali', 'want', 'wants', 'was', 'wasn', 'wasnt', \"wasn't\", 'way', 'we', \"we'd\", 'well', \"we'll\", 'went', 'were', \"we're\", 'weren', 'werent', \"weren't\", \"we've\", 'what', 'whatever', \"what's\", 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', \"where's\", 'whereupon', 'wherever', 'whether', 'which', 'while', 'who', 'whoever', 'whole', 'whom', \"who's\", 'whose', 'why', 'will', 'willing', 'with', 'within', 'without', 'wo', 'woh', 'wohi', 'won', 'wont', \"won't\", 'would', 'wouldn', 'wouldnt', \"wouldn't\", 'y', 'ya', 'yadi', 'yah', 'yaha', 'yahaan', 'yahan', 'yahi', 'yahin', 'ye', 'yeah', 'yeh', 'yehi', 'yes', 'yet', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\", 'yup']\n"
     ]
    }
   ],
   "source": [
    "with open(pwd+'//hinglish_stopwords.txt','r') as sw:\n",
    "    stw_list = sw.readlines()\n",
    "stw_l = list(map(lambda x: x.strip(),stw_list))\n",
    "print(stw_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'boy', 'does', 'doing', 'girl', 'good', 'habit', 'john', 'nice', 'things', 'worst']\n",
      "[[0 1 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0]\n",
      " [2 0 0 1 0 0 0 0 0 1 1]\n",
      " [2 0 0 1 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True,stop_words='english')\n",
    "X = vectorizer.fit_transform(new_df['sentence'])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1fc7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['john', 'is', 'good', 'boy'], ['good', 'is', 'nice', 'habit'], ['boy', 'does', 'good'], ['habit', 'of', 'john'], ['is', 'girl', 'nice', '?'], ['doing', 'bad', 'things', 'is', 'so', 'bad', 'and', 'worst'], ['doing', 'bad', 'things', 'is', 'so', 'bad']]\n",
      "Dictionary(8 unique tokens: ['boy', 'john', 'habit', 'nice', '?']...)\n",
      "{'boy': 0, 'john': 1, 'habit': 2, 'nice': 3, '?': 4, 'girl': 5, 'things': 6, 'worst': 7}\n",
      "[[(0, 1), (1, 1)], [(2, 1), (3, 1)], [(0, 1)], [(1, 1), (2, 1)], [(3, 1), (4, 1), (5, 1)], [(6, 1), (7, 1)], [(6, 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "rows = new_df['sentence']\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in rows]\n",
    "print(tokenized_docs)\n",
    "new_tokenized_docs = [set(row).difference(set(stw_l)) for row in tokenized_docs]\n",
    "dictionary = Dictionary(new_tokenized_docs)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id)\n",
    "\n",
    "# converting doc to token_id and number of tokens\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a563f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.7071067811865475), (3, 0.7071067811865475)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus)\n",
    "tfidf[corpus[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d705ad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x2524409cee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786a6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(John,)\n",
      "John $$$ nsubj $$$ is $$$ AUX $$$ PROPN $$$ []\n",
      "is $$$ ROOT $$$ is $$$ AUX $$$ AUX $$$ [John, boy]\n",
      "good $$$ amod $$$ boy $$$ NOUN $$$ ADJ $$$ []\n",
      "boy $$$ attr $$$ is $$$ AUX $$$ NOUN $$$ [good]\n",
      "(Habit,)\n",
      "good $$$ acomp $$$ is $$$ AUX $$$ ADJ $$$ []\n",
      "is $$$ ROOT $$$ is $$$ AUX $$$ AUX $$$ [good, Habit]\n",
      "nice $$$ amod $$$ Habit $$$ NOUN $$$ ADJ $$$ []\n",
      "Habit $$$ attr $$$ is $$$ AUX $$$ NOUN $$$ [nice]\n",
      "()\n",
      "boy $$$ intj $$$ does $$$ VERB $$$ INTJ $$$ []\n",
      "does $$$ ROOT $$$ does $$$ VERB $$$ VERB $$$ [boy, Good]\n",
      "Good $$$ dobj $$$ does $$$ VERB $$$ PROPN $$$ []\n",
      "()\n",
      "habit $$$ ROOT $$$ habit $$$ NOUN $$$ NOUN $$$ [of]\n",
      "of $$$ prep $$$ habit $$$ NOUN $$$ ADP $$$ [john]\n",
      "john $$$ pobj $$$ of $$$ ADP $$$ NOUN $$$ []\n",
      "()\n",
      "is $$$ ROOT $$$ is $$$ AUX $$$ AUX $$$ [nice, ?]\n",
      "girl $$$ npadvmod $$$ nice $$$ ADJ $$$ NOUN $$$ []\n",
      "nice $$$ acomp $$$ is $$$ AUX $$$ ADJ $$$ [girl]\n",
      "? $$$ punct $$$ is $$$ AUX $$$ PUNCT $$$ []\n",
      "()\n",
      "doing $$$ csubj $$$ is $$$ AUX $$$ VERB $$$ [things]\n",
      "bad $$$ amod $$$ things $$$ NOUN $$$ ADJ $$$ []\n",
      "things $$$ dobj $$$ doing $$$ VERB $$$ NOUN $$$ [bad]\n",
      "is $$$ ROOT $$$ is $$$ AUX $$$ AUX $$$ [doing, bad]\n",
      "so $$$ advmod $$$ bad $$$ ADJ $$$ ADV $$$ []\n",
      "bad $$$ acomp $$$ is $$$ AUX $$$ ADJ $$$ [so, and, worst]\n",
      "and $$$ cc $$$ bad $$$ ADJ $$$ CCONJ $$$ []\n",
      "worst $$$ conj $$$ bad $$$ ADJ $$$ ADJ $$$ []\n",
      "()\n",
      "doing $$$ csubj $$$ is $$$ AUX $$$ VERB $$$ [things]\n",
      "bad $$$ amod $$$ things $$$ NOUN $$$ ADJ $$$ []\n",
      "things $$$ dobj $$$ doing $$$ VERB $$$ NOUN $$$ [bad]\n",
      "is $$$ ROOT $$$ is $$$ AUX $$$ AUX $$$ [doing, bad]\n",
      "so $$$ advmod $$$ bad $$$ ADJ $$$ ADV $$$ []\n",
      "bad $$$ acomp $$$ is $$$ AUX $$$ ADJ $$$ [so]\n"
     ]
    }
   ],
   "source": [
    "for x in new_df['sentence']:\n",
    "    doc = nlp(x)\n",
    "    print(doc.ents)\n",
    "    for token in doc:\n",
    "        print(token.text,\"$$$\", token.dep_,\"$$$\", token.head.text,\"$$$\", token.head.pos_,\"$$$\",token.pos_,\"$$$\",[child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab7a43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': '', 'description': 'good'}, {'aspect': '', 'description': 'nice'}, {'aspect': '', 'description': ''}, {'aspect': '', 'description': ''}, {'aspect': '', 'description': 'nice'}, {'aspect': '', 'description': 'worst'}, {'aspect': '', 'description': 'so bad'}]\n"
     ]
    }
   ],
   "source": [
    "aspects = []\n",
    "for sentence in new_df['sentence']:\n",
    "    doc = nlp(sentence)\n",
    "    descriptive_term = ''\n",
    "    target = ''\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.pos_ == 'NOUN':\n",
    "            target = token.text\n",
    "        if token.pos_ == 'ADJ':\n",
    "            prepend = ''\n",
    "            for child in token.children:\n",
    "                if child.pos_ != 'ADV':\n",
    "                    continue\n",
    "                prepend += child.text + ' '\n",
    "            descriptive_term = prepend + token.text\n",
    "    aspects.append({'aspect': target,'description': descriptive_term})\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3c9bbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John is good boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>good is nice Habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>boy does Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>habit of john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>is girl nice?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>doing bad things is so bad and worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>doing bad things is so bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              sentence\n",
       "0   1                      John is good boy\n",
       "1   2                    good is nice Habit\n",
       "2   3                         boy does Good\n",
       "3   4                         habit of john\n",
       "4   5                         is girl nice?\n",
       "5   6  doing bad things is so bad and worst\n",
       "6   7            doing bad things is so bad"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51076939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
