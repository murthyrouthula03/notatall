{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os,sys\n",
    "    import re\n",
    "    # importing algorithms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "except Exception as e:\n",
    "    print(\"Error is due to\",e)\n",
    "pwd = os.getcwd()\n",
    "labels_df = pd.read_csv(pwd+\"//Datasets//Nisha//Input//Nisha_dataset_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b63a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of Train-test split, MinMax Scaling\n",
    "def minmax_scaling(x_data, y_data):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.30,random_state=21,stratify=y_data)\n",
    "    # MinMax scaling of train data\n",
    "    minmax_model = MinMaxScaler(feature_range=(0,5))\n",
    "    np.set_printoptions(precision=3)\n",
    "    scaled_data_train = minmax_model.fit_transform(x_train)\n",
    "    # MinMax scaling of test data\n",
    "    scaled_data_test = minmax_model.fit_transform(x_test)\n",
    "    return scaled_data_train, scaled_data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c808d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Modelling and extracting Metrics\n",
    "def ml_training(ml_model, x_train, x_test, y_train, y_test, model_name):\n",
    "    ml_model.fit(x_train, y_train)\n",
    "    ml_pred_val = ml_model.predict(x_test)\n",
    "    print(\"Accuracy of \"+model_name+\" after Standard Scaling is:\", ml_model.score(x_test,y_test))\n",
    "    print(\"Confusion Matrix of \"+model_name+\" is:\\n\", confusion_matrix(y_test,ml_pred_val))\n",
    "    print(\"Classification Report of \"+model_name+\" is:\\n\", classification_report(y_test,ml_pred_val))\n",
    "    print(70*\"=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c180d66",
   "metadata": {},
   "source": [
    "### Bag of words Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[163   3   0   3  25  15   1]\n",
      " [  5 152   9  12  16  16   0]\n",
      " [  0  11 172  18   3   6   0]\n",
      " [  6  12  16 128  27  20   1]\n",
      " [ 21  17   3  19 138   7   5]\n",
      " [  7  19   7  21   2 119  35]\n",
      " [  4   1   0   2   1  32 170]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.78      0.78       210\n",
      "           2       0.71      0.72      0.72       210\n",
      "           3       0.83      0.82      0.82       210\n",
      "           4       0.63      0.61      0.62       210\n",
      "           5       0.65      0.66      0.65       210\n",
      "           6       0.55      0.57      0.56       210\n",
      "           7       0.80      0.81      0.81       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.71      0.71      0.71      1470\n",
      "weighted avg       0.71      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5306122448979592\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145  14  16   5   8  17   5]\n",
      " [ 25 127  30  10   9   8   1]\n",
      " [  3  10 181  14   0   2   0]\n",
      " [ 27  25  36 100   9  13   0]\n",
      " [ 50  48  33  25  37  12   5]\n",
      " [ 32  33  50  13   9  57  16]\n",
      " [ 16   9  19   5   3  25 133]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.69      0.57       210\n",
      "           2       0.48      0.60      0.53       210\n",
      "           3       0.50      0.86      0.63       210\n",
      "           4       0.58      0.48      0.52       210\n",
      "           5       0.49      0.18      0.26       210\n",
      "           6       0.43      0.27      0.33       210\n",
      "           7       0.83      0.63      0.72       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.51      1470\n",
      "weighted avg       0.54      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5462585034013605\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[138  15   7   5  12  27   6]\n",
      " [ 22 125  22  12   7  21   1]\n",
      " [  3  16 176   6   2   7   0]\n",
      " [ 17  27  30 100   9  27   0]\n",
      " [ 52  47  18  31  30  27   5]\n",
      " [ 27  33  11  13   7 101  18]\n",
      " [  6  12   8   3   2  46 133]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.66      0.58       210\n",
      "           2       0.45      0.60      0.52       210\n",
      "           3       0.65      0.84      0.73       210\n",
      "           4       0.59      0.48      0.53       210\n",
      "           5       0.43      0.14      0.22       210\n",
      "           6       0.39      0.48      0.43       210\n",
      "           7       0.82      0.63      0.71       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.53      1470\n",
      "weighted avg       0.55      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134  21   7   9  11  24   4]\n",
      " [ 14 131  21  11  14  18   1]\n",
      " [  3  22 177   6   1   1   0]\n",
      " [ 13  26  28 104  10  28   1]\n",
      " [ 43  52  21  33  32  25   4]\n",
      " [ 23  53  10  17   7  85  15]\n",
      " [  4  12  10   4   2  44 134]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.64      0.60       210\n",
      "           2       0.41      0.62      0.50       210\n",
      "           3       0.65      0.84      0.73       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.42      0.15      0.22       210\n",
      "           6       0.38      0.40      0.39       210\n",
      "           7       0.84      0.64      0.73       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.53      1470\n",
      "weighted avg       0.55      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5346938775510204\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[134  23   9   7   9  26   2]\n",
      " [ 11 132  24  14  10  18   1]\n",
      " [  2  21 174   7   4   2   0]\n",
      " [ 12  28  30 108   7  25   0]\n",
      " [ 46  50  23  32  28  28   3]\n",
      " [ 21  60  10  14   6  85  14]\n",
      " [  4  13  11   3   0  54 125]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.64      0.61       210\n",
      "           2       0.40      0.63      0.49       210\n",
      "           3       0.62      0.83      0.71       210\n",
      "           4       0.58      0.51      0.55       210\n",
      "           5       0.44      0.13      0.20       210\n",
      "           6       0.36      0.40      0.38       210\n",
      "           7       0.86      0.60      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.52      1470\n",
      "weighted avg       0.55      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[129  24  11   8   6  31   1]\n",
      " [ 11 128  24  14  12  21   0]\n",
      " [  2  18 174   9   2   5   0]\n",
      " [ 10  29  37 102  10  21   1]\n",
      " [ 42  50  24  29  31  32   2]\n",
      " [ 22  57  14  16   5  87   9]\n",
      " [  6  12  14   3   0  54 121]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.61      0.60       210\n",
      "           2       0.40      0.61      0.48       210\n",
      "           3       0.58      0.83      0.69       210\n",
      "           4       0.56      0.49      0.52       210\n",
      "           5       0.47      0.15      0.22       210\n",
      "           6       0.35      0.41      0.38       210\n",
      "           7       0.90      0.58      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.51      1470\n",
      "weighted avg       0.55      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5360544217687074\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133  16   7   6   4  43   1]\n",
      " [ 11 121  26  11  10  31   0]\n",
      " [  4  12 174   5   4  11   0]\n",
      " [ 11  22  32 101   9  34   1]\n",
      " [ 43  51  24  26  26  37   3]\n",
      " [ 20  35  14  16   1 116   8]\n",
      " [  6  13  10   2   0  62 117]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.63      0.61       210\n",
      "           2       0.45      0.58      0.50       210\n",
      "           3       0.61      0.83      0.70       210\n",
      "           4       0.60      0.48      0.54       210\n",
      "           5       0.48      0.12      0.20       210\n",
      "           6       0.35      0.55      0.43       210\n",
      "           7       0.90      0.56      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.52      1470\n",
      "weighted avg       0.57      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[124   2  11  55   6  11   1]\n",
      " [ 16 128  53   9   2   1   1]\n",
      " [  1   8 196   3   1   0   1]\n",
      " [  9  34  58  84  14   8   3]\n",
      " [ 64  19   4  77  29  11   6]\n",
      " [ 13  34  61  19   5  27  51]\n",
      " [  3   4   3   3   4  15 178]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.59      0.56       210\n",
      "           2       0.56      0.61      0.58       210\n",
      "           3       0.51      0.93      0.66       210\n",
      "           4       0.34      0.40      0.37       210\n",
      "           5       0.48      0.14      0.21       210\n",
      "           6       0.37      0.13      0.19       210\n",
      "           7       0.74      0.85      0.79       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.50      0.52      0.48      1470\n",
      "weighted avg       0.50      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[164   4  11   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 31  18   8  22 124   4   3]\n",
      " [  5  28  47  27   2  77  24]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.78      0.78       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.72      0.59      0.65       210\n",
      "           6       0.65      0.37      0.47       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.69      1470\n",
      "weighted avg       0.70      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of SVM is:\n",
      " [[166   2   0   2  25  15   0]\n",
      " [  6 150  16  12   8  18   0]\n",
      " [  0   7 173  20   2   8   0]\n",
      " [  6  15  19 127  21  20   2]\n",
      " [ 36  23   3  19 120   4   5]\n",
      " [ 10  16  14  24   4 116  26]\n",
      " [  7   2   1   2   1  34 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.79      0.75       210\n",
      "           2       0.70      0.71      0.71       210\n",
      "           3       0.77      0.82      0.79       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.66      0.57      0.61       210\n",
      "           6       0.54      0.55      0.55       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6394557823129252\n",
      "Confusion Matrix of SVM is:\n",
      " [[128   9   0   5  26  38   4]\n",
      " [  4 140   8  15  17  25   1]\n",
      " [  0  14 165  16   5  10   0]\n",
      " [  6  18  10 123  24  29   0]\n",
      " [ 28  29   7  29  96  17   4]\n",
      " [ 13  20   2  16   9 134  16]\n",
      " [  2   2   0   3   0  49 154]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.61      0.65       210\n",
      "           2       0.60      0.67      0.63       210\n",
      "           3       0.86      0.79      0.82       210\n",
      "           4       0.59      0.59      0.59       210\n",
      "           5       0.54      0.46      0.50       210\n",
      "           6       0.44      0.64      0.52       210\n",
      "           7       0.86      0.73      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6972789115646258\n",
      "Confusion Matrix of SVM is:\n",
      " [[143   3   0   2  32  24   6]\n",
      " [  2 148   9  15  13  21   2]\n",
      " [  0  11 169  20   3   7   0]\n",
      " [  2  12  12 136  17  27   4]\n",
      " [ 20  17   3  25 120   9  16]\n",
      " [  4  16   2  20   0 121  47]\n",
      " [  0   1   0   1   0  20 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.68      0.75       210\n",
      "           2       0.71      0.70      0.71       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.62      0.65      0.63       210\n",
      "           5       0.65      0.57      0.61       210\n",
      "           6       0.53      0.58      0.55       210\n",
      "           7       0.71      0.90      0.79       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of SVM is:\n",
      " [[165   3   0   4  22  16   0]\n",
      " [  2 139  20  17   6  26   0]\n",
      " [  0   8 175  17   3   7   0]\n",
      " [  2  16  21 139   9  22   1]\n",
      " [ 28  24   7  24 119   3   5]\n",
      " [  0  12   6  33   2 124  33]\n",
      " [  0   1   0   1   2  31 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.79      0.81       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.76      0.83      0.80       210\n",
      "           4       0.59      0.66      0.62       210\n",
      "           5       0.73      0.57      0.64       210\n",
      "           6       0.54      0.59      0.56       210\n",
      "           7       0.82      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.19931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[210   0   0   0   0   0   0]\n",
      " [207   0   3   0   0   0   0]\n",
      " [127   0  83   0   0   0   0]\n",
      " [208   0   2   0   0   0   0]\n",
      " [209   0   1   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]\n",
      " [210   0   0   0   0   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.15      0.20      0.12      1470\n",
      "weighted avg       0.15      0.20      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.25510204081632654\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82   0   0   0   0   0 128]\n",
      " [  1   0   3   0   0   0 206]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   0   0 205]\n",
      " [ 64   0   1   0   0   0 145]\n",
      " [  1   0   0   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.24      0.26      0.19      1470\n",
      "weighted avg       0.24      0.26      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[110   0   0   0  56   0  44]\n",
      " [  2   0   3   0   0   0 205]\n",
      " [  0   0  83   0   0   0 127]\n",
      " [  3   0   2   0   3   0 202]\n",
      " [ 69   0   1   0  61   0  79]\n",
      " [  2   0   0   0   1   0 207]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.56       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.50      0.29      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      1.00      0.33       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.26      1470\n",
      "weighted avg       0.32      0.32      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122  44   0   0  44   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  3 201   2   0   3   0   1]\n",
      " [ 59  77   1   0  71   0   2]\n",
      " [  1 199   0   0   2   0   8]\n",
      " [  0 134   0   0   0   0  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.58      0.62       210\n",
      "           2       0.21      0.97      0.34       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.34      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.46      0.38      0.35      1470\n",
      "weighted avg       0.46      0.38      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  44   0   0  68   0   0]\n",
      " [  1 204   3   0   1   0   1]\n",
      " [  0 127  83   0   0   0   0]\n",
      " [  0 201   2   0   6   0   1]\n",
      " [ 17  76   1   0 113   0   3]\n",
      " [  0 197   0   0   3   0  10]\n",
      " [  0 108   0   0   0   1 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.47      0.60       210\n",
      "           2       0.21      0.97      0.35       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.59      0.54      0.56       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.49      0.41      0.38      1470\n",
      "weighted avg       0.49      0.41      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41768707482993195\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   0   0   0  70  44   0]\n",
      " [  1  27   3   0   1 177   1]\n",
      " [  0   0  83   0   0 127   0]\n",
      " [  0   0   2   0   6 201   1]\n",
      " [ 13  13   1   0 117  63   3]\n",
      " [  0   0   0   0   5 197   8]\n",
      " [  0   0   0   0   7 109  94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.46      0.60       210\n",
      "           2       0.68      0.13      0.22       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.57      0.56      0.56       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.88      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.59      0.42      0.41      1470\n",
      "weighted avg       0.59      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   1   0   1  41  43   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  35  83   0   0  92   0]\n",
      " [  3  14   2   0   3 187   1]\n",
      " [ 46  25   1   1  83  51   3]\n",
      " [  1   2   0   0   4 195   8]\n",
      " [  0   1   0   0   1 108 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.49      0.36      0.41       210\n",
      "           3       0.93      0.40      0.56       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.62      0.40      0.48       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.44      1470\n",
      "weighted avg       0.55      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47006802721088436\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   0  43  43   0]\n",
      " [  1  74  29   1   1 104   0]\n",
      " [  0   0 118   0   0  92   0]\n",
      " [  3   1  15   0   3 187   1]\n",
      " [ 45  19   9   3  82  49   3]\n",
      " [  1   0   2   0   4 195   8]\n",
      " [  0   1   0   0   1 109  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.59      0.64       210\n",
      "           2       0.77      0.35      0.48       210\n",
      "           3       0.68      0.56      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.39      0.48       210\n",
      "           6       0.25      0.93      0.39       210\n",
      "           7       0.89      0.47      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.56      0.47      0.46      1470\n",
      "weighted avg       0.56      0.47      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.48435374149659866\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  44  43   0]\n",
      " [  1  80  25   0   1 102   1]\n",
      " [  0   0 134   0   0  76   0]\n",
      " [  3   1  16   0   3 186   1]\n",
      " [ 45  19   9   3  82  49   3]\n",
      " [  1   0   3   0   4 194   8]\n",
      " [  0   1   0   0   2 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64       210\n",
      "           2       0.78      0.38      0.51       210\n",
      "           3       0.72      0.64      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.60      0.39      0.47       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.56      0.48      0.47      1470\n",
      "weighted avg       0.56      0.48      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   0   0  43  44   0]\n",
      " [  1  94  12   0   2 100   1]\n",
      " [  0  14 126   0   0  70   0]\n",
      " [  3  10   7   0   3 186   1]\n",
      " [ 48  21   3   1  84  50   3]\n",
      " [  1   2   1   0   4 194   8]\n",
      " [  0   1   0   0   3 107  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64       210\n",
      "           2       0.66      0.45      0.53       210\n",
      "           3       0.85      0.60      0.70       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.60      0.40      0.48       210\n",
      "           6       0.26      0.92      0.40       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.56      0.49      0.48      1470\n",
      "weighted avg       0.56      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5156462585034014\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   0  18  44   0]\n",
      " [  1  93  10   2   5  98   1]\n",
      " [  0  11 129   0   0  70   0]\n",
      " [  4  10   7  16   2 170   1]\n",
      " [ 54  16   5   5  80  47   3]\n",
      " [  2   2   1   0   3 194   8]\n",
      " [  0   1   0   0   2 109  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.61      0.71       210\n",
      "           4       0.70      0.08      0.14       210\n",
      "           5       0.73      0.38      0.50       210\n",
      "           6       0.27      0.92      0.41       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.69      0.52      0.52      1470\n",
      "weighted avg       0.69      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5312925170068027\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   0   0   1  16  45   0]\n",
      " [  1  92  11   4   5  96   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  4  10   7  38   2 148   1]\n",
      " [ 56  19   4   4  78  46   3]\n",
      " [  2   1   2   0   3 194   8]\n",
      " [  0   1   0   0   2 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.81      0.18      0.30       210\n",
      "           5       0.74      0.37      0.49       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.71      0.53      0.54      1470\n",
      "weighted avg       0.71      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   3  15  43   0]\n",
      " [  2  90  12   3   4  98   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11   9  43   2 139   1]\n",
      " [ 55  19   4  11  75  43   3]\n",
      " [  2   1   2   1   3 193   8]\n",
      " [  0   1   0   0   1 110  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.70       210\n",
      "           2       0.69      0.43      0.53       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.70      0.20      0.32       210\n",
      "           5       0.75      0.36      0.48       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  18  37   0]\n",
      " [  2  92  11   4   4  97   0]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  11  10  42   3 139   0]\n",
      " [ 52  19   4   7  86  40   2]\n",
      " [  2   1   2   1   3 194   7]\n",
      " [  0   1   0   0   2 110  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.69      0.44      0.54       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.78      0.20      0.32       210\n",
      "           5       0.74      0.41      0.53       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.92      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.71      0.54      0.55      1470\n",
      "weighted avg       0.71      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   0   0   0  20  35   0]\n",
      " [  2 106  11   1   6  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  17   9  43   3 133   0]\n",
      " [ 50  20   4   7  88  39   2]\n",
      " [  2   5   2   1   3 189   8]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.74      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.83      0.20      0.33       210\n",
      "           5       0.72      0.42      0.53       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.90      0.47      0.62       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.71      0.55      0.56      1470\n",
      "weighted avg       0.71      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   2  17  34   0]\n",
      " [  2 106  11   2   5  83   1]\n",
      " [  0   9 131   0   0  70   0]\n",
      " [  5  16  10  42   4 133   0]\n",
      " [ 55  21   4   6  88  33   3]\n",
      " [  2   5   2   1   3 190   7]\n",
      " [  0   1   0   0   3 110  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.67      0.50      0.58       210\n",
      "           3       0.83      0.62      0.71       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.73      0.42      0.53       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.90      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[156   0   0   0  22  32   0]\n",
      " [  2 104  13   2   6  82   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  11  44   3 131   0]\n",
      " [ 55  22   5   7  87  31   3]\n",
      " [  2   5   2   1   3 189   8]\n",
      " [  0   1   0   0   2 108  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.82      0.67      0.73       210\n",
      "           4       0.81      0.21      0.33       210\n",
      "           5       0.71      0.41      0.52       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.89      0.47      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.56      1470\n",
      "weighted avg       0.70      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   0   0   2  27  32   0]\n",
      " [  2 105  13   2   4  83   1]\n",
      " [  0   9 140   0   0  61   0]\n",
      " [  5  16  12  42   3 131   1]\n",
      " [ 53  21   5   6  89  30   6]\n",
      " [  2   4   2   1   3 188  10]\n",
      " [  0   1   0   0   2 103 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.71      0.71       210\n",
      "           2       0.67      0.50      0.57       210\n",
      "           3       0.81      0.67      0.73       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.70      0.42      0.53       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.69      0.56      0.56      1470\n",
      "weighted avg       0.69      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   0   0   1  23  34   0]\n",
      " [  2 104  11   2   7  83   1]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  15  13  41   4 130   2]\n",
      " [ 50  19   5   5  95  30   6]\n",
      " [  2   4   2   1   3 183  15]\n",
      " [  0   1   0   0   1  94 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.70      0.50      0.58       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.71      0.45      0.55       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.83      0.54      0.66       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.57      1470\n",
      "weighted avg       0.70      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[157   0   0   0  23  30   0]\n",
      " [  2 105  12   3   6  82   0]\n",
      " [  0   6 143   0   0  61   0]\n",
      " [  5  12  13  42   6 130   2]\n",
      " [ 48  18   5   5  96  32   6]\n",
      " [  3   5   2   1   3 183  13]\n",
      " [  0   1   0   0   3 102 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.71      0.50      0.59       210\n",
      "           3       0.82      0.68      0.74       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.70      0.46      0.55       210\n",
      "           6       0.30      0.87      0.44       210\n",
      "           7       0.83      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   4   1   4  23  35   2]\n",
      " [  1  91   6  21  17  73   1]\n",
      " [  2   0 124   3   0  81   0]\n",
      " [  5  10   3  92  15  82   3]\n",
      " [ 57  20   2  24  84  17   6]\n",
      " [  4   6   1  30   3 142  24]\n",
      " [  0   2   0   1   3  47 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67       210\n",
      "           2       0.68      0.43      0.53       210\n",
      "           3       0.91      0.59      0.71       210\n",
      "           4       0.53      0.44      0.48       210\n",
      "           5       0.58      0.40      0.47       210\n",
      "           6       0.30      0.68      0.41       210\n",
      "           7       0.81      0.75      0.78       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.64      0.57      0.58      1470\n",
      "weighted avg       0.64      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   3  10  18  25   1]\n",
      " [  1 119   7  23   4  55   1]\n",
      " [  1   0 134   5   0  70   0]\n",
      " [  4  14   9 118   8  55   2]\n",
      " [ 64  23   3  23  79  13   5]\n",
      " [  3  12   4  41   3 119  28]\n",
      " [  0   5   1   9   1  32 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.70       210\n",
      "           2       0.68      0.57      0.62       210\n",
      "           3       0.83      0.64      0.72       210\n",
      "           4       0.52      0.56      0.54       210\n",
      "           5       0.70      0.38      0.49       210\n",
      "           6       0.32      0.57      0.41       210\n",
      "           7       0.81      0.77      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.65      0.60      0.61      1470\n",
      "weighted avg       0.65      0.60      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6136054421768707\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   2   2   3  23  33   1]\n",
      " [  1 118   7  20   7  56   1]\n",
      " [  0   0 134   3   1  72   0]\n",
      " [  3  15   6 111  12  61   2]\n",
      " [ 52  25   2  20  94  12   5]\n",
      " [  2  15   1  29   2 136  25]\n",
      " [  0   5   0   1   1  40 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.70      0.71       210\n",
      "           2       0.66      0.56      0.61       210\n",
      "           3       0.88      0.64      0.74       210\n",
      "           4       0.59      0.53      0.56       210\n",
      "           5       0.67      0.45      0.54       210\n",
      "           6       0.33      0.65      0.44       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.67      0.61      0.63      1470\n",
      "weighted avg       0.67      0.61      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   1   3  20  35   2]\n",
      " [  1 117  19  19  11  42   1]\n",
      " [  0   0 149   3   0  58   0]\n",
      " [  4  12  10 118  14  50   2]\n",
      " [ 61  26   4  21  82  11   5]\n",
      " [  4  11   2  27   2 137  27]\n",
      " [  0   5   0   1   1  40 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69       210\n",
      "           2       0.68      0.56      0.61       210\n",
      "           3       0.81      0.71      0.75       210\n",
      "           4       0.61      0.56      0.59       210\n",
      "           5       0.63      0.39      0.48       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.81      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.66      0.62      0.63      1470\n",
      "weighted avg       0.66      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   1   1  11  18  28   1]\n",
      " [  1 118  20  24   8  38   1]\n",
      " [  0   0 154   6   0  50   0]\n",
      " [  3  13  11 130  11  41   1]\n",
      " [ 56  28   4  21  89   7   5]\n",
      " [  4  11   2  39   2 126  26]\n",
      " [  0   5   0   9   1  36 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.67      0.56      0.61       210\n",
      "           3       0.80      0.73      0.77       210\n",
      "           4       0.54      0.62      0.58       210\n",
      "           5       0.69      0.42      0.53       210\n",
      "           6       0.39      0.60      0.47       210\n",
      "           7       0.82      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  17  35   1]\n",
      " [  1 124  17  20   7  40   1]\n",
      " [  0   1 148   6   0  55   0]\n",
      " [  3  13  10 123  13  47   1]\n",
      " [ 57  24   5  20  88  11   5]\n",
      " [  3  11   2  26   4 139  25]\n",
      " [  0   5   0   1   1  42 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.71       210\n",
      "           2       0.69      0.59      0.64       210\n",
      "           3       0.81      0.70      0.75       210\n",
      "           4       0.61      0.59      0.60       210\n",
      "           5       0.68      0.42      0.52       210\n",
      "           6       0.38      0.66      0.48       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.67      0.63      0.64      1470\n",
      "weighted avg       0.67      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   3   2   3  19  33   1]\n",
      " [  1 127  20  19   3  39   1]\n",
      " [  0   1 153   3   0  53   0]\n",
      " [  3  12  11 119  13  50   2]\n",
      " [ 48  26   6  19  95  11   5]\n",
      " [  3  13   3  27   1 137  26]\n",
      " [  0   4   0   0   2  40 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.71      0.72       210\n",
      "           2       0.68      0.60      0.64       210\n",
      "           3       0.78      0.73      0.76       210\n",
      "           4       0.63      0.57      0.59       210\n",
      "           5       0.71      0.45      0.55       210\n",
      "           6       0.38      0.65      0.48       210\n",
      "           7       0.82      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.68      0.64      0.65      1470\n",
      "weighted avg       0.68      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   3   2   2  18  34   0]\n",
      " [  1 136  11  19   5  37   1]\n",
      " [  0   9 145   2   0  54   0]\n",
      " [  4  14  10 120  10  50   2]\n",
      " [ 49  28   3  19  95  10   6]\n",
      " [  4  13   1  23   1 145  23]\n",
      " [  0   5   0   1   1  38 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.73      0.45      0.56       210\n",
      "           6       0.39      0.69      0.50       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.69      0.65      0.66      1470\n",
      "weighted avg       0.69      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  21  27   1]\n",
      " [  1 134  12  17   6  39   1]\n",
      " [  0   9 145   5   0  51   0]\n",
      " [  4  12  11 120  10  51   2]\n",
      " [ 60  27   2  18  89   9   5]\n",
      " [  4  13   1  23   2 144  23]\n",
      " [  0   4   0   0   1  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71       210\n",
      "           2       0.67      0.64      0.65       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.69      0.42      0.53       210\n",
      "           6       0.40      0.69      0.50       210\n",
      "           7       0.84      0.78      0.81       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6605442176870748\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   2   2  24  24   1]\n",
      " [  1 134  10  19   3  42   1]\n",
      " [  0  10 144   4   0  52   0]\n",
      " [  3  15  10 121   9  50   2]\n",
      " [ 46  26   3  19 101   9   6]\n",
      " [  4  11   1  21   2 149  22]\n",
      " [  0   5   0   0   1  37 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.66      0.64      0.65       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.65      0.58      0.61       210\n",
      "           5       0.72      0.48      0.58       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.84      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   2   1  24  26   0]\n",
      " [  1 136  10  18   2  42   1]\n",
      " [  0   9 145   3   0  53   0]\n",
      " [  3  16   9 121  11  48   2]\n",
      " [ 41  22   1  19 111  10   6]\n",
      " [  3  10   1  18   3 153  22]\n",
      " [  0   1   0   0   3  36 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.86      0.69      0.77       210\n",
      "           4       0.67      0.58      0.62       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.42      0.73      0.53       210\n",
      "           7       0.85      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   1   2   4  19  25   0]\n",
      " [  1 140  11  18   3  36   1]\n",
      " [  0   8 146   3   0  53   0]\n",
      " [  3  16  10 120  10  48   3]\n",
      " [ 54  24   2  18  97  10   5]\n",
      " [  3  10   2  16   3 150  26]\n",
      " [  0   5   0   1   2  30 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.76      0.74       210\n",
      "           2       0.69      0.67      0.68       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.67      0.57      0.62       210\n",
      "           5       0.72      0.46      0.56       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   3  21  27   0]\n",
      " [  1 137  13  16   5  37   1]\n",
      " [  0  10 146   5   0  49   0]\n",
      " [  4  15  11 122   8  48   2]\n",
      " [ 54  25   2  20  94   9   6]\n",
      " [  3  10   1  19   1 152  24]\n",
      " [  0   0   0   1   2  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.75      0.73       210\n",
      "           2       0.69      0.65      0.67       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.66      0.58      0.62       210\n",
      "           5       0.72      0.45      0.55       210\n",
      "           6       0.42      0.72      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.67      1470\n",
      "weighted avg       0.70      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   1   1   3  19  26   0]\n",
      " [  1 138  11  17   4  38   1]\n",
      " [  0  12 145   2   0  51   0]\n",
      " [  3  16  11 121  11  46   2]\n",
      " [ 47  25   3  18 101  10   6]\n",
      " [  4  13   2  15   1 149  26]\n",
      " [  0   2   0   0   2  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.76      0.75       210\n",
      "           2       0.67      0.66      0.66       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.69      0.58      0.63       210\n",
      "           5       0.73      0.48      0.58       210\n",
      "           6       0.42      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[162   1   2   1  20  24   0]\n",
      " [  1 138  10  17   6  37   1]\n",
      " [  0   9 148   1   0  52   0]\n",
      " [  3  13  12 117  12  51   2]\n",
      " [ 51  22   2  18 103   8   6]\n",
      " [  3  11   1  17   2 151  25]\n",
      " [  0   3   0   1   1  41 164]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.72      0.49      0.58       210\n",
      "           6       0.41      0.72      0.53       210\n",
      "           7       0.83      0.78      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   4  23  24   0]\n",
      " [  1 141  12  16   3  36   1]\n",
      " [  0  12 145   3   0  50   0]\n",
      " [  3  15  10 114  13  53   2]\n",
      " [ 41  22   3  19 110   9   6]\n",
      " [  3  12   1  18   1 149  26]\n",
      " [  0   3   0   1   1  39 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.84      0.69      0.76       210\n",
      "           4       0.65      0.54      0.59       210\n",
      "           5       0.73      0.52      0.61       210\n",
      "           6       0.41      0.71      0.52       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   5  22  24   0]\n",
      " [  1 141  11  17   4  35   1]\n",
      " [  0  12 146   5   0  47   0]\n",
      " [  3  13  12 121  11  48   2]\n",
      " [ 40  24   2  19 112   7   6]\n",
      " [  3  11   1  24   3 143  25]\n",
      " [  0   4   0   3   2  34 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.75      0.76       210\n",
      "           2       0.68      0.67      0.68       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.62      0.58      0.60       210\n",
      "           5       0.73      0.53      0.62       210\n",
      "           6       0.42      0.68      0.52       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   2  25  22   1]\n",
      " [  1 138  12  16   6  36   1]\n",
      " [  0  11 146   5   0  48   0]\n",
      " [  3  13  12 119  13  48   2]\n",
      " [ 45  20   1  21 107   9   7]\n",
      " [  3  11   2  20   3 148  23]\n",
      " [  0   1   0   1   3  39 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.74      0.75       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.83      0.70      0.76       210\n",
      "           4       0.65      0.57      0.60       210\n",
      "           5       0.68      0.51      0.58       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.67      1470\n",
      "weighted avg       0.70      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   2   4  24  26   0]\n",
      " [  1 143  10  17   3  35   1]\n",
      " [  0  13 145   4   0  48   0]\n",
      " [  2  14  10 123  14  45   2]\n",
      " [ 46  22   2  21 107   6   6]\n",
      " [  4  11   1  20   0 149  25]\n",
      " [  0   1   0   3   2  34 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.64      0.59      0.61       210\n",
      "           5       0.71      0.51      0.59       210\n",
      "           6       0.43      0.71      0.54       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   2   5  23  23   0]\n",
      " [  1 143  10  17   3  35   1]\n",
      " [  0  12 149   4   0  45   0]\n",
      " [  3  13  11 126  11  43   3]\n",
      " [ 36  22   1  20 116   9   6]\n",
      " [  4   9   2  24   0 146  25]\n",
      " [  0   0   0   1   2  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.71      0.68      0.70       210\n",
      "           3       0.85      0.71      0.77       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.75      0.55      0.64       210\n",
      "           6       0.43      0.70      0.53       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.69      1470\n",
      "weighted avg       0.71      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[168   3   0   5  22  11   1]\n",
      " [ 12 155  12  11  16   4   0]\n",
      " [  5  14 169  18   4   0   0]\n",
      " [ 17  10  13 133  26  11   0]\n",
      " [ 21  22   3  36 109  15   4]\n",
      " [ 36  21   5  32   3  79  34]\n",
      " [  3   1   1   0   1  29 175]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.80      0.71       210\n",
      "           2       0.69      0.74      0.71       210\n",
      "           3       0.83      0.80      0.82       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.60      0.52      0.56       210\n",
      "           6       0.53      0.38      0.44       210\n",
      "           7       0.82      0.83      0.83       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tfidf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a19273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[159   2   0   5  27  17   0]\n",
      " [  5 143  11  15  18  18   0]\n",
      " [  0   6 179  13   6   6   0]\n",
      " [  5   7  18 123  32  22   3]\n",
      " [ 43  17   3  15 124   5   3]\n",
      " [  8  17   4  33   4 111  33]\n",
      " [  3   1   1   1   1  31 172]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.74      0.68      0.71       210\n",
      "           3       0.83      0.85      0.84       210\n",
      "           4       0.60      0.59      0.59       210\n",
      "           5       0.58      0.59      0.59       210\n",
      "           6       0.53      0.53      0.53       210\n",
      "           7       0.82      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5210884353741496\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142  16  19  10   4  18   1]\n",
      " [ 17 122  43  11   4  12   1]\n",
      " [  4  10 180  10   1   5   0]\n",
      " [ 19  22  38  98   7  26   0]\n",
      " [ 68  42  25  33  29   8   5]\n",
      " [ 31  30  54   8   4  63  20]\n",
      " [ 20   9   7   3   4  35 132]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.68      0.56       210\n",
      "           2       0.49      0.58      0.53       210\n",
      "           3       0.49      0.86      0.62       210\n",
      "           4       0.57      0.47      0.51       210\n",
      "           5       0.55      0.14      0.22       210\n",
      "           6       0.38      0.30      0.33       210\n",
      "           7       0.83      0.63      0.72       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.50      1470\n",
      "weighted avg       0.54      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153  12   8   5   6  26   0]\n",
      " [ 18 122  34  13   2  19   2]\n",
      " [  8   8 174   7   2  11   0]\n",
      " [ 21  20  27 104  10  27   1]\n",
      " [ 60  43  26  38  30   8   5]\n",
      " [ 33  21  12  10   5 110  19]\n",
      " [ 11   8   6   3   2  44 136]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.73      0.60       210\n",
      "           2       0.52      0.58      0.55       210\n",
      "           3       0.61      0.83      0.70       210\n",
      "           4       0.58      0.50      0.53       210\n",
      "           5       0.53      0.14      0.22       210\n",
      "           6       0.45      0.52      0.48       210\n",
      "           7       0.83      0.65      0.73       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.55      1470\n",
      "weighted avg       0.57      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144  10  10   9   9  28   0]\n",
      " [ 10 123  43   8   5  19   2]\n",
      " [  5  11 177   7   3   7   0]\n",
      " [ 17  21  29 110   8  24   1]\n",
      " [ 56  39  31  40  29  10   5]\n",
      " [ 30  25  11   8   4 110  22]\n",
      " [ 11   5   5   5   1  44 139]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.69      0.60       210\n",
      "           2       0.53      0.59      0.55       210\n",
      "           3       0.58      0.84      0.69       210\n",
      "           4       0.59      0.52      0.55       210\n",
      "           5       0.49      0.14      0.22       210\n",
      "           6       0.45      0.52      0.49       210\n",
      "           7       0.82      0.66      0.73       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.57      0.57      0.55      1470\n",
      "weighted avg       0.57      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143  12  10   8  10  27   0]\n",
      " [ 11 118  42   8   7  23   1]\n",
      " [  4  19 171   7   1   8   0]\n",
      " [ 12  24  33 104   6  30   1]\n",
      " [ 56  40  32  39  28   9   6]\n",
      " [ 27  24  12   9   3 117  18]\n",
      " [  8   6   8   4   3  45 136]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.68      0.61       210\n",
      "           2       0.49      0.56      0.52       210\n",
      "           3       0.56      0.81      0.66       210\n",
      "           4       0.58      0.50      0.53       210\n",
      "           5       0.48      0.13      0.21       210\n",
      "           6       0.45      0.56      0.50       210\n",
      "           7       0.84      0.65      0.73       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.54      1470\n",
      "weighted avg       0.56      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5605442176870749\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141  10  12   8  10  29   0]\n",
      " [  8 121  42   9   7  22   1]\n",
      " [  4  16 177   2   2   9   0]\n",
      " [  9  22  39 100   3  36   1]\n",
      " [ 57  46  33  37  25   8   4]\n",
      " [ 25  25  13   7   3 120  17]\n",
      " [  6   5   7   3   5  44 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61       210\n",
      "           2       0.49      0.58      0.53       210\n",
      "           3       0.55      0.84      0.66       210\n",
      "           4       0.60      0.48      0.53       210\n",
      "           5       0.45      0.12      0.19       210\n",
      "           6       0.45      0.57      0.50       210\n",
      "           7       0.86      0.67      0.75       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.54      1470\n",
      "weighted avg       0.57      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145  11   9   8   9  28   0]\n",
      " [  8 115  44  11   6  25   1]\n",
      " [  7  15 171   2   2  13   0]\n",
      " [  8  22  36 100   3  41   0]\n",
      " [ 58  45  37  38  19   9   4]\n",
      " [ 22  24  11   6   2 125  20]\n",
      " [  8   6   7   3   2  48 136]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.69      0.62       210\n",
      "           2       0.48      0.55      0.51       210\n",
      "           3       0.54      0.81      0.65       210\n",
      "           4       0.60      0.48      0.53       210\n",
      "           5       0.44      0.09      0.15       210\n",
      "           6       0.43      0.60      0.50       210\n",
      "           7       0.84      0.65      0.73       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.53      1470\n",
      "weighted avg       0.56      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[106   4  13  74   8   5   0]\n",
      " [ 11 132  50   9   3   2   3]\n",
      " [  2   9 195   2   2   0   0]\n",
      " [ 10  35  58  84  17   5   1]\n",
      " [ 56  20   4  85  33   8   4]\n",
      " [ 19  32  66  21   8  18  46]\n",
      " [  7   3   6   4   3  10 177]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       210\n",
      "           2       0.56      0.63      0.59       210\n",
      "           3       0.50      0.93      0.65       210\n",
      "           4       0.30      0.40      0.34       210\n",
      "           5       0.45      0.16      0.23       210\n",
      "           6       0.38      0.09      0.14       210\n",
      "           7       0.77      0.84      0.80       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.49      0.51      0.47      1470\n",
      "weighted avg       0.49      0.51      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.691156462585034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of SVM is:\n",
      " [[161   2   0   4  22  20   1]\n",
      " [  3 143  13  16   9  20   6]\n",
      " [  0   5 175  14   0  16   0]\n",
      " [  5  14  20 121  18  28   4]\n",
      " [ 37  20   8  13 128   3   1]\n",
      " [  6  18   9  24   4 124  25]\n",
      " [  5   2   2   1   1  31 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.70      0.61      0.65       210\n",
      "           6       0.51      0.59      0.55       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of SVM is:\n",
      " [[115   8  62   1  15   9   0]\n",
      " [ 13  59 127   7   3   1   0]\n",
      " [  2   1 207   0   0   0   0]\n",
      " [ 25  19  68  87   5   6   0]\n",
      " [ 48  29  56  25  44   2   6]\n",
      " [ 34  18  96   6   0  44  12]\n",
      " [ 21  10  48   2   0  26 103]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.55      0.49       210\n",
      "           2       0.41      0.28      0.33       210\n",
      "           3       0.31      0.99      0.47       210\n",
      "           4       0.68      0.41      0.51       210\n",
      "           5       0.66      0.21      0.32       210\n",
      "           6       0.50      0.21      0.30       210\n",
      "           7       0.85      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.44      1470\n",
      "weighted avg       0.55      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of SVM is:\n",
      " [[139   1   0   4  42  17   7]\n",
      " [  1 127  16  17  22  25   2]\n",
      " [  0   4 171  16   7  12   0]\n",
      " [  3   9  13 117  36  25   7]\n",
      " [ 15   9   1  11 154   2  18]\n",
      " [  0   8   2  18   6 127  49]\n",
      " [  0   0   0   1   3  18 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.66      0.76       210\n",
      "           2       0.80      0.60      0.69       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.64      0.56      0.59       210\n",
      "           5       0.57      0.73      0.64       210\n",
      "           6       0.56      0.60      0.58       210\n",
      "           7       0.69      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.7108843537414966\n",
      "Confusion Matrix of SVM is:\n",
      " [[163   1   0   1  26  18   1]\n",
      " [  3 130  22  19   6  30   0]\n",
      " [  0   1 176  17   1  15   0]\n",
      " [  3   9  21 135  14  26   2]\n",
      " [ 38  17   7  19 124   3   2]\n",
      " [  4   4   7  19   4 146  26]\n",
      " [  1   0   3   2   1  32 171]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.80      0.62      0.70       210\n",
      "           3       0.75      0.84      0.79       210\n",
      "           4       0.64      0.64      0.64       210\n",
      "           5       0.70      0.59      0.64       210\n",
      "           6       0.54      0.70      0.61       210\n",
      "           7       0.85      0.81      0.83       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22380952380952382\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   9   0   0   0 201]\n",
      " [  0   0  58   0   0   0 152]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  0   0  21   0   0   0 189]\n",
      " [  0   0  47   0   0   0 163]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   4   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.46      0.59      0.52       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      0.98      0.29       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.09      0.22      0.12      1470\n",
      "weighted avg       0.09      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2938775510204082\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78   2   7   0   0   0 123]\n",
      " [  1  25  33   0   0   0 151]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  3   3  18   0   0   0 186]\n",
      " [ 53  15  32   0   0   0 110]\n",
      " [  1   1   2   0   0   0 206]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.37      0.45       210\n",
      "           2       0.53      0.12      0.19       210\n",
      "           3       0.56      0.59      0.57       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.19      0.98      0.32       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.27      0.29      0.22      1470\n",
      "weighted avg       0.27      0.29      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35918367346938773\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   4   0   8   0  43]\n",
      " [  2  25  33   0   0   0 150]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  5   3  18   0   0   0 184]\n",
      " [ 95  13  23   0  20   0  59]\n",
      " [  3   1   2   0   0   0 204]\n",
      " [  0   1   3   0   0   0 206]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.73      0.66       210\n",
      "           2       0.57      0.12      0.20       210\n",
      "           3       0.60      0.59      0.59       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.71      0.10      0.17       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.22      0.98      0.36       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.28      1470\n",
      "weighted avg       0.38      0.36      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   0  12  43   0]\n",
      " [  1  25  33   0   1 149   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 83   7  14   0  47  57   2]\n",
      " [  3   1   2   0   0 196   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.73      0.68       210\n",
      "           2       0.66      0.12      0.20       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.77      0.22      0.35       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.54      0.42      0.39      1470\n",
      "weighted avg       0.54      0.42      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   1   0   0  18  43   0]\n",
      " [  1  50  33   0   1 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 73  18  14   1  56  46   2]\n",
      " [  2   2   2   0   1 195   8]\n",
      " [  0   1   3   0   0 131  75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.70      0.67       210\n",
      "           2       0.67      0.24      0.35       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.73      0.27      0.39       210\n",
      "           6       0.24      0.93      0.38       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.54      0.44      0.42      1470\n",
      "weighted avg       0.54      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4557823129251701\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   1   0   0  13  43   0]\n",
      " [  1  49  32   0   3 124   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   3  17   0   1 183   1]\n",
      " [ 78  16  14   1  52  47   2]\n",
      " [  3   2   2   0   0 192  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.68       210\n",
      "           2       0.68      0.23      0.35       210\n",
      "           3       0.64      0.59      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.75      0.25      0.37       210\n",
      "           6       0.25      0.91      0.39       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.55      0.46      0.43      1470\n",
      "weighted avg       0.55      0.46      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[140   1   0   0  26  43   0]\n",
      " [  1  82  29   0   3  94   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17   0   2 180   1]\n",
      " [ 52  16  14   0  83  43   2]\n",
      " [  2   3   2   0   1 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.68       210\n",
      "           2       0.75      0.39      0.51       210\n",
      "           3       0.65      0.59      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.72      0.40      0.51       210\n",
      "           6       0.26      0.91      0.40       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.507482993197279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  21  43   0]\n",
      " [  1  83  27   2   4  92   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  4   6  17  22   2 158   1]\n",
      " [ 58  14  12   3  81  41   1]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.69      0.69       210\n",
      "           2       0.77      0.40      0.52       210\n",
      "           3       0.67      0.59      0.62       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.75      0.39      0.51       210\n",
      "           6       0.27      0.91      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.69      0.51      0.51      1470\n",
      "weighted avg       0.69      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5142857142857142\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  21  46   0]\n",
      " [  1  84  26   5   4  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  5   6  16  38   2 142   1]\n",
      " [ 57  16  11   2  77  44   3]\n",
      " [  3   3   2   0   0 191  11]\n",
      " [  0   1   3   0   0 105 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.68      0.68       210\n",
      "           2       0.76      0.40      0.52       210\n",
      "           3       0.68      0.59      0.63       210\n",
      "           4       0.84      0.18      0.30       210\n",
      "           5       0.74      0.37      0.49       210\n",
      "           6       0.27      0.91      0.42       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.69      0.51      0.52      1470\n",
      "weighted avg       0.69      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5170068027210885\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  23  45   0]\n",
      " [  4  80  26   5   5  89   1]\n",
      " [  0   0 123   0   0  87   0]\n",
      " [  6   3  16  47   4 133   1]\n",
      " [ 54  13  11   5  82  42   3]\n",
      " [  4   2   2   2   0 189  11]\n",
      " [  0   1   3   0   3 105  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67       210\n",
      "           2       0.80      0.38      0.52       210\n",
      "           3       0.68      0.59      0.63       210\n",
      "           4       0.80      0.22      0.35       210\n",
      "           5       0.70      0.39      0.50       210\n",
      "           6       0.27      0.90      0.42       210\n",
      "           7       0.86      0.47      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.68      0.52      0.53      1470\n",
      "weighted avg       0.68      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[142   1   0   0  22  45   0]\n",
      " [  3  81  37   6   4  78   1]\n",
      " [  0   0 141   0   0  69   0]\n",
      " [  7   3  25  47   3 124   1]\n",
      " [ 59  15  12   6  75  40   3]\n",
      " [  4   2   6   2   0 185  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.68      0.67       210\n",
      "           2       0.79      0.39      0.52       210\n",
      "           3       0.62      0.67      0.65       210\n",
      "           4       0.77      0.22      0.35       210\n",
      "           5       0.72      0.36      0.48       210\n",
      "           6       0.29      0.88      0.43       210\n",
      "           7       0.86      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.67      0.53      0.53      1470\n",
      "weighted avg       0.67      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[141   1   0   0  25  43   0]\n",
      " [  3  88  33   4   4  78   0]\n",
      " [  0   0 148   0   0  62   0]\n",
      " [  7   3  25  45   5 124   1]\n",
      " [ 54  16  12   7  84  35   2]\n",
      " [  3   2   9   3   0 182  11]\n",
      " [  0   1   5   0   0 103 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.67      0.67       210\n",
      "           2       0.79      0.42      0.55       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.76      0.21      0.33       210\n",
      "           5       0.71      0.40      0.51       210\n",
      "           6       0.29      0.87      0.43       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.68      0.54      0.54      1470\n",
      "weighted avg       0.68      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[148   1   0   0  24  37   0]\n",
      " [  3  88  33   4   3  79   0]\n",
      " [  0   0 147   0   1  62   0]\n",
      " [  6   3  24  46   6 124   1]\n",
      " [ 54  16  11   7  84  36   2]\n",
      " [  3   2   9   3   0 183  10]\n",
      " [  0   1   5   0   0 104 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.70      0.70       210\n",
      "           2       0.79      0.42      0.55       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.77      0.22      0.34       210\n",
      "           5       0.71      0.40      0.51       210\n",
      "           6       0.29      0.87      0.44       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.68      0.54      0.55      1470\n",
      "weighted avg       0.68      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   1   0   0  27  37   0]\n",
      " [  2  87  33   6   5  77   0]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  6   3  23  33  20 124   1]\n",
      " [ 48  17  11   7  89  35   3]\n",
      " [  3   2   9   3   0 180  13]\n",
      " [  0   1   5   0   3  98 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70       210\n",
      "           2       0.78      0.41      0.54       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.67      0.16      0.25       210\n",
      "           5       0.61      0.42      0.50       210\n",
      "           6       0.29      0.86      0.44       210\n",
      "           7       0.86      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.65      0.53      0.53      1470\n",
      "weighted avg       0.65      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   0  21  34   0]\n",
      " [  3  90  31   3   3  79   1]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  5   4  23  46   7 124   1]\n",
      " [ 62  16  11   8  79  30   4]\n",
      " [  2   2   9   2   2 181  12]\n",
      " [  0   1   5   0   2  99 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.73      0.71       210\n",
      "           2       0.79      0.43      0.56       210\n",
      "           3       0.65      0.70      0.67       210\n",
      "           4       0.78      0.22      0.34       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.85      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.68      0.54      0.55      1470\n",
      "weighted avg       0.68      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  23  35   0]\n",
      " [  3  95  31   3   4  73   1]\n",
      " [  0   0 146   0   2  62   0]\n",
      " [  7   3  22  46   7 124   1]\n",
      " [ 64  18  11   7  78  27   5]\n",
      " [  2   2   9   2   2 180  13]\n",
      " [  0   1   5   0   0 100 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.69       210\n",
      "           2       0.79      0.45      0.58       210\n",
      "           3       0.65      0.70      0.67       210\n",
      "           4       0.79      0.22      0.34       210\n",
      "           5       0.67      0.37      0.48       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.84      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.67      0.54      0.55      1470\n",
      "weighted avg       0.67      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   1   0   0  24  34   0]\n",
      " [  6  94  30   3   6  70   1]\n",
      " [  0   0 147   0   2  61   0]\n",
      " [  5   3  23  47   7 124   1]\n",
      " [ 57  18  12   8  85  27   3]\n",
      " [  3   0   8   3   1 182  13]\n",
      " [  0   1   5   0   0  99 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.80      0.45      0.57       210\n",
      "           3       0.65      0.70      0.68       210\n",
      "           4       0.77      0.22      0.35       210\n",
      "           5       0.68      0.40      0.51       210\n",
      "           6       0.30      0.87      0.45       210\n",
      "           7       0.85      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.68      0.55      0.56      1470\n",
      "weighted avg       0.68      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[150   1   0   1  25  33   0]\n",
      " [  3  97  30  17   4  59   0]\n",
      " [  0   0 147   2   2  59   0]\n",
      " [  6   3  23  58   7 112   1]\n",
      " [ 59  19  12  12  84  21   3]\n",
      " [  2   2   8  11   2 173  12]\n",
      " [  0   2   4   2   1  97 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.71      0.70       210\n",
      "           2       0.78      0.46      0.58       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.56      0.28      0.37       210\n",
      "           5       0.67      0.40      0.50       210\n",
      "           6       0.31      0.82      0.45       210\n",
      "           7       0.87      0.50      0.63       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.65      0.55      0.56      1470\n",
      "weighted avg       0.65      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[153   1   0   1  23  32   0]\n",
      " [  3  97  30  11   6  62   1]\n",
      " [  0   0 147   2   2  59   0]\n",
      " [  4   4  21  43  23 114   1]\n",
      " [ 58  20  12  10  85  20   5]\n",
      " [  2   3   8  11   1 172  13]\n",
      " [  0   2   4   2   2  97 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.73      0.71       210\n",
      "           2       0.76      0.46      0.58       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.54      0.20      0.30       210\n",
      "           5       0.60      0.40      0.48       210\n",
      "           6       0.31      0.82      0.45       210\n",
      "           7       0.84      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.63      0.54      0.55      1470\n",
      "weighted avg       0.63      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   1   0   1  23  33   0]\n",
      " [  3  98  29  11   6  62   1]\n",
      " [  0   2 145   2   2  59   0]\n",
      " [  7   6  21  43  19 113   1]\n",
      " [ 61  20  11  11  81  23   3]\n",
      " [  2   1   6  13   2 171  15]\n",
      " [  0   2   4   2   0  98 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.75      0.47      0.58       210\n",
      "           3       0.67      0.69      0.68       210\n",
      "           4       0.52      0.20      0.29       210\n",
      "           5       0.61      0.39      0.47       210\n",
      "           6       0.31      0.81      0.44       210\n",
      "           7       0.84      0.50      0.62       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.62      0.54      0.54      1470\n",
      "weighted avg       0.62      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   8   4  15  22   5]\n",
      " [  1  72  58  30   3  41   5]\n",
      " [  0   0 123  22   0  61   4]\n",
      " [  3   6  21 105   8  48  19]\n",
      " [ 76  15  36  17  49   8   9]\n",
      " [  3   9   3  35   2 116  42]\n",
      " [  0   3   3   2   0  23 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.74      0.69       210\n",
      "           2       0.68      0.34      0.46       210\n",
      "           3       0.49      0.59      0.53       210\n",
      "           4       0.49      0.50      0.49       210\n",
      "           5       0.64      0.23      0.34       210\n",
      "           6       0.36      0.55      0.44       210\n",
      "           7       0.68      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.53      1470\n",
      "weighted avg       0.57      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   2   4   4  21  22   5]\n",
      " [  1 102  40  19   4  40   4]\n",
      " [  0   0 145   5   0  54   6]\n",
      " [  4   8  21 107  10  45  15]\n",
      " [ 64  24  21  15  70   6  10]\n",
      " [  3   9   5  31   3 117  42]\n",
      " [  0   4   3   1   1  27 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.72      0.70       210\n",
      "           2       0.68      0.49      0.57       210\n",
      "           3       0.61      0.69      0.65       210\n",
      "           4       0.59      0.51      0.55       210\n",
      "           5       0.64      0.33      0.44       210\n",
      "           6       0.38      0.56      0.45       210\n",
      "           7       0.68      0.83      0.75       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.61      0.59      0.59      1470\n",
      "weighted avg       0.61      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5891156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   4   7  23  21   1]\n",
      " [  1  98  38  25   4  43   1]\n",
      " [  0   0 146   8   0  56   0]\n",
      " [  4   9  21 119  11  43   3]\n",
      " [ 63  23  21  18  72   7   6]\n",
      " [  3  10   6  45   2 120  24]\n",
      " [  0   5   3  12   0  32 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.73      0.71       210\n",
      "           2       0.67      0.47      0.55       210\n",
      "           3       0.61      0.70      0.65       210\n",
      "           4       0.51      0.57      0.54       210\n",
      "           5       0.64      0.34      0.45       210\n",
      "           6       0.37      0.57      0.45       210\n",
      "           7       0.82      0.75      0.78       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   2   7  20  21   1]\n",
      " [  1 100  37  26   3  42   1]\n",
      " [  0   0 146   8   0  56   0]\n",
      " [  4  11  19 116  10  48   2]\n",
      " [ 64  22  15  20  76   7   6]\n",
      " [  3  10   6  44   2 122  23]\n",
      " [  0   4   3  10   0  34 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72       210\n",
      "           2       0.67      0.48      0.56       210\n",
      "           3       0.64      0.70      0.67       210\n",
      "           4       0.50      0.55      0.53       210\n",
      "           5       0.68      0.36      0.47       210\n",
      "           6       0.37      0.58      0.45       210\n",
      "           7       0.83      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.63      0.60      0.60      1470\n",
      "weighted avg       0.63      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   4   4  19  25   1]\n",
      " [  1 104  37  23   3  41   1]\n",
      " [  0   0 147   5   0  58   0]\n",
      " [  4   9  18 106  13  58   2]\n",
      " [ 72  26  21  18  59   8   6]\n",
      " [  2   9   7  30   3 135  24]\n",
      " [  0   4   3   1   0  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.74      0.70       210\n",
      "           2       0.68      0.50      0.57       210\n",
      "           3       0.62      0.70      0.66       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.61      0.28      0.38       210\n",
      "           6       0.36      0.64      0.46       210\n",
      "           7       0.82      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.58      1470\n",
      "weighted avg       0.62      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6081632653061224\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   4  23  24   1]\n",
      " [  1 105  36  24   3  40   1]\n",
      " [  0   0 147   4   0  59   0]\n",
      " [  3  16  20 107   6  57   1]\n",
      " [ 51  27  13  19  87   8   5]\n",
      " [  3  12   6  31   0 136  22]\n",
      " [  0   4   3   1   0  46 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.63      0.50      0.56       210\n",
      "           3       0.65      0.70      0.68       210\n",
      "           4       0.56      0.51      0.53       210\n",
      "           5       0.73      0.41      0.53       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.84      0.74      0.79       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.65      0.61      0.61      1470\n",
      "weighted avg       0.65      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5925170068027211\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   5   3  18  27   1]\n",
      " [  1 106  37  22   2  41   1]\n",
      " [  0   0 147   4   0  59   0]\n",
      " [  4  14  17 106   8  59   2]\n",
      " [ 65  27  24  15  64   9   6]\n",
      " [  3  12   4  30   0 138  23]\n",
      " [  0   5   3   1   0  46 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.74      0.71       210\n",
      "           2       0.64      0.50      0.57       210\n",
      "           3       0.62      0.70      0.66       210\n",
      "           4       0.59      0.50      0.54       210\n",
      "           5       0.70      0.30      0.42       210\n",
      "           6       0.36      0.66      0.47       210\n",
      "           7       0.82      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.63      0.59      0.59      1470\n",
      "weighted avg       0.63      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   0   3  22  27   1]\n",
      " [  1 106  37  24   1  40   1]\n",
      " [  0   0 147  14   0  49   0]\n",
      " [  4  15  17 113   4  55   2]\n",
      " [ 67  28  12  21  71   6   5]\n",
      " [  3  10   6  30   0 139  22]\n",
      " [  0   3   3   1   0  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.74      0.71       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.66      0.70      0.68       210\n",
      "           4       0.55      0.54      0.54       210\n",
      "           5       0.72      0.34      0.46       210\n",
      "           6       0.38      0.66      0.49       210\n",
      "           7       0.83      0.74      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.64      0.60      0.60      1470\n",
      "weighted avg       0.64      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   4  21  26   1]\n",
      " [  1 106  37  22   2  41   1]\n",
      " [  0   0 148  15   0  47   0]\n",
      " [  3  14  19 111   7  55   1]\n",
      " [ 65  28  13  18  74   7   5]\n",
      " [  3  10   6  30   0 137  24]\n",
      " [  0   4   3   1   0  43 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.74      0.71       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.65      0.70      0.68       210\n",
      "           4       0.55      0.53      0.54       210\n",
      "           5       0.71      0.35      0.47       210\n",
      "           6       0.38      0.65      0.48       210\n",
      "           7       0.83      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   4  21  25   1]\n",
      " [  1 105  38  24   3  38   1]\n",
      " [  0   0 152  15   0  43   0]\n",
      " [  3  13  20 112   7  54   1]\n",
      " [ 61  27  11  19  82   6   4]\n",
      " [  3   8   7  32   0 135  25]\n",
      " [  0   4   3   1   0  47 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.72       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.66      0.72      0.69       210\n",
      "           4       0.54      0.53      0.54       210\n",
      "           5       0.73      0.39      0.51       210\n",
      "           6       0.39      0.64      0.48       210\n",
      "           7       0.83      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   1   0   4  22  26   1]\n",
      " [  1 106  37  20   3  42   1]\n",
      " [  0   0 150  13   0  47   0]\n",
      " [  3  13  20 112   7  54   1]\n",
      " [ 66  25  11  21  76   6   5]\n",
      " [  3  13   7  29   0 134  24]\n",
      " [  0   3   3   1   0  47 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.74      0.71       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.66      0.71      0.68       210\n",
      "           4       0.56      0.53      0.55       210\n",
      "           5       0.70      0.36      0.48       210\n",
      "           6       0.38      0.64      0.47       210\n",
      "           7       0.83      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   0   4  23  25   1]\n",
      " [  1 104  38  21   4  41   1]\n",
      " [  0   0 153  13   0  44   0]\n",
      " [  3  12  18 112  10  54   1]\n",
      " [ 63  27  11  18  79   7   5]\n",
      " [  3  10   7  27   1 139  23]\n",
      " [  0   4   3   1   0  47 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.71       210\n",
      "           2       0.65      0.50      0.56       210\n",
      "           3       0.67      0.73      0.70       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.39      0.66      0.49       210\n",
      "           7       0.83      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.64      0.61      0.61      1470\n",
      "weighted avg       0.64      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   0   3  21  26   1]\n",
      " [  1 106  38  24   2  38   1]\n",
      " [  0   1 153  12   0  44   0]\n",
      " [  3  13  19 115   5  54   1]\n",
      " [ 58  28  11  18  83   7   5]\n",
      " [  3   8   7  31   0 137  24]\n",
      " [  0   3   3   1   0  45 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73       210\n",
      "           2       0.66      0.50      0.57       210\n",
      "           3       0.66      0.73      0.69       210\n",
      "           4       0.56      0.55      0.56       210\n",
      "           5       0.75      0.40      0.52       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.83      0.75      0.79       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6156462585034014\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   0   4  22  25   1]\n",
      " [  1 106  38  20   2  42   1]\n",
      " [  0   0 154  14   0  42   0]\n",
      " [  4  14  20 113   4  54   1]\n",
      " [ 64  29  11  18  76   7   5]\n",
      " [  3   9   7  28   0 140  23]\n",
      " [  0   4   2   1   0  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.66      0.73      0.70       210\n",
      "           4       0.57      0.54      0.55       210\n",
      "           5       0.73      0.36      0.48       210\n",
      "           6       0.40      0.67      0.50       210\n",
      "           7       0.84      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   0   4  22  25   1]\n",
      " [  1 106  38  23   1  40   1]\n",
      " [  0   1 156  12   0  41   0]\n",
      " [  3  14  21 114   5  52   1]\n",
      " [ 50  27  12  18  91   7   5]\n",
      " [  3  10   8  28   0 138  23]\n",
      " [  0   4   3   1   0  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.74       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.66      0.74      0.70       210\n",
      "           4       0.57      0.54      0.56       210\n",
      "           5       0.76      0.43      0.55       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.84      0.75      0.79       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.66      0.62      0.63      1470\n",
      "weighted avg       0.66      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   1   4  21  25   1]\n",
      " [  1 110  35  23   2  38   1]\n",
      " [  0   0 156  11   0  43   0]\n",
      " [  3  14  22 112   7  51   1]\n",
      " [ 62  25  12  18  82   6   5]\n",
      " [  3  11   8  27   0 137  24]\n",
      " [  0   4   2   1   0  44 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72       210\n",
      "           2       0.67      0.52      0.59       210\n",
      "           3       0.66      0.74      0.70       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.73      0.39      0.51       210\n",
      "           6       0.40      0.65      0.49       210\n",
      "           7       0.83      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[160   1   1   3  17  27   1]\n",
      " [  1 109  35  20   3  41   1]\n",
      " [  0   0 158  12   0  40   0]\n",
      " [  4  16  18 116   6  49   1]\n",
      " [ 62  27  11  19  79   8   4]\n",
      " [  3  10  10  27   0 138  22]\n",
      " [  0   4   2   1   0  45 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.76      0.73       210\n",
      "           2       0.65      0.52      0.58       210\n",
      "           3       0.67      0.75      0.71       210\n",
      "           4       0.59      0.55      0.57       210\n",
      "           5       0.75      0.38      0.50       210\n",
      "           6       0.40      0.66      0.49       210\n",
      "           7       0.84      0.75      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.66      0.62      0.63      1470\n",
      "weighted avg       0.66      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6197278911564625\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   1   4  23  26   0]\n",
      " [  1 110  34  22   3  39   1]\n",
      " [  0   0 161   9   0  40   0]\n",
      " [  3  15  21 116   6  48   1]\n",
      " [ 66  28  12  18  75   7   4]\n",
      " [  3  10  10  27   0 137  23]\n",
      " [  0   4   3   1   0  45 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.74      0.71       210\n",
      "           2       0.65      0.52      0.58       210\n",
      "           3       0.67      0.77      0.71       210\n",
      "           4       0.59      0.55      0.57       210\n",
      "           5       0.70      0.36      0.47       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.84      0.75      0.79       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6258503401360545\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   1   1   4  24  26   0]\n",
      " [  1 110  35  21   3  39   1]\n",
      " [  0   1 156  11   0  42   0]\n",
      " [  3  14  19 117   8  48   1]\n",
      " [ 53  28  12  19  87   5   6]\n",
      " [  3   9   9  28   0 138  23]\n",
      " [  0   4   2   1   0  45 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.67      0.74      0.70       210\n",
      "           4       0.58      0.56      0.57       210\n",
      "           5       0.71      0.41      0.52       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.84      0.75      0.79       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   1   4  23  26   0]\n",
      " [  1 111  34  22   3  38   1]\n",
      " [  0   3 158  10   0  39   0]\n",
      " [  4  14  20 119   5  47   1]\n",
      " [ 60  28  11  20  80   7   4]\n",
      " [  3  10   9  28   0 137  23]\n",
      " [  0   4   3   1   0  44 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.65      0.53      0.58       210\n",
      "           3       0.67      0.75      0.71       210\n",
      "           4       0.58      0.57      0.57       210\n",
      "           5       0.72      0.38      0.50       210\n",
      "           6       0.41      0.65      0.50       210\n",
      "           7       0.84      0.75      0.80       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[172   2   2   6  23   5   0]\n",
      " [ 13 145  20  15  13   2   2]\n",
      " [  5  16 176   9   4   0   0]\n",
      " [ 20  12  17 125  27   8   1]\n",
      " [ 31  22   5  32 109  10   1]\n",
      " [ 46  20   9  35   4  66  30]\n",
      " [  4   1   1   0   1  23 180]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.82      0.69       210\n",
      "           2       0.67      0.69      0.68       210\n",
      "           3       0.77      0.84      0.80       210\n",
      "           4       0.56      0.60      0.58       210\n",
      "           5       0.60      0.52      0.56       210\n",
      "           6       0.58      0.31      0.41       210\n",
      "           7       0.84      0.86      0.85       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//cv_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7020408163265306\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[157   3   0   5  28  17   0]\n",
      " [  5 153   8  12  15  17   0]\n",
      " [  0  11 173  19   2   5   0]\n",
      " [  5  12  17 127  28  20   1]\n",
      " [ 24  17   3  17 137   7   5]\n",
      " [  5  21   5  27   2 115  35]\n",
      " [  5   1   1   2   1  30 170]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.75      0.76       210\n",
      "           2       0.70      0.73      0.71       210\n",
      "           3       0.84      0.82      0.83       210\n",
      "           4       0.61      0.60      0.61       210\n",
      "           5       0.64      0.65      0.65       210\n",
      "           6       0.55      0.55      0.55       210\n",
      "           7       0.81      0.81      0.81       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5387755102040817\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152  12  14   3  16  12   1]\n",
      " [ 22 130  27  11  12   7   1]\n",
      " [  3  12 178  13   0   4   0]\n",
      " [ 29  35  39  83   8  16   0]\n",
      " [ 71  42  26  17  44   7   3]\n",
      " [ 27  40  47  13   3  65  15]\n",
      " [ 14  11  12   2   4  27 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.72      0.58       210\n",
      "           2       0.46      0.62      0.53       210\n",
      "           3       0.52      0.85      0.64       210\n",
      "           4       0.58      0.40      0.47       210\n",
      "           5       0.51      0.21      0.30       210\n",
      "           6       0.47      0.31      0.37       210\n",
      "           7       0.88      0.67      0.76       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.52      1470\n",
      "weighted avg       0.56      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[159  14   2   2  11  21   1]\n",
      " [ 14 130  21  14  10  20   1]\n",
      " [  2  17 179   5   0   7   0]\n",
      " [ 20  31  29  91   9  30   0]\n",
      " [ 69  44  21  20  40  15   1]\n",
      " [ 25  38  13  16   3  99  16]\n",
      " [ 11   9   4   2   3  42 139]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.76      0.62       210\n",
      "           2       0.46      0.62      0.53       210\n",
      "           3       0.67      0.85      0.75       210\n",
      "           4       0.61      0.43      0.51       210\n",
      "           5       0.53      0.19      0.28       210\n",
      "           6       0.42      0.47      0.45       210\n",
      "           7       0.88      0.66      0.76       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.55      1470\n",
      "weighted avg       0.58      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5755102040816327\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156  10   3   3  15  23   0]\n",
      " [ 10 130  27  14  11  17   1]\n",
      " [  1  13 181   5   2   8   0]\n",
      " [ 13  35  26  90   7  38   1]\n",
      " [ 66  39  28  19  40  16   2]\n",
      " [ 20  30  14  19   3 110  14]\n",
      " [ 10   8   9   2   3  39 139]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.74      0.64       210\n",
      "           2       0.49      0.62      0.55       210\n",
      "           3       0.63      0.86      0.73       210\n",
      "           4       0.59      0.43      0.50       210\n",
      "           5       0.49      0.19      0.27       210\n",
      "           6       0.44      0.52      0.48       210\n",
      "           7       0.89      0.66      0.76       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.56      1470\n",
      "weighted avg       0.58      0.58      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[156  12   6   4  11  21   0]\n",
      " [ 10 130  29  11  11  18   1]\n",
      " [  1  14 182   5   0   8   0]\n",
      " [ 14  34  30  87   6  39   0]\n",
      " [ 70  44  26  18  37  13   2]\n",
      " [ 19  35  14  14   5 110  13]\n",
      " [  5  10  10   5   1  44 135]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.74      0.64       210\n",
      "           2       0.47      0.62      0.53       210\n",
      "           3       0.61      0.87      0.72       210\n",
      "           4       0.60      0.41      0.49       210\n",
      "           5       0.52      0.18      0.26       210\n",
      "           6       0.43      0.52      0.48       210\n",
      "           7       0.89      0.64      0.75       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.55      1470\n",
      "weighted avg       0.59      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154  12   9   4   9  22   0]\n",
      " [  9 133  30  12   8  18   0]\n",
      " [  1  12 178   9   2   8   0]\n",
      " [ 13  37  35  82   6  37   0]\n",
      " [ 71  49  23  18  35  13   1]\n",
      " [ 16  36  12  16   5 113  12]\n",
      " [  6  13  11   3   1  44 132]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.73      0.64       210\n",
      "           2       0.46      0.63      0.53       210\n",
      "           3       0.60      0.85      0.70       210\n",
      "           4       0.57      0.39      0.46       210\n",
      "           5       0.53      0.17      0.25       210\n",
      "           6       0.44      0.54      0.49       210\n",
      "           7       0.91      0.63      0.74       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5598639455782313\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152  12   7   5   8  26   0]\n",
      " [  7 132  34  11   6  20   0]\n",
      " [  1  12 177   7   3  10   0]\n",
      " [ 11  36  33  82   6  42   0]\n",
      " [ 79  43  24  15  30  18   1]\n",
      " [ 11  34   9  16   3 123  14]\n",
      " [  5  12  11   4   0  51 127]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.72      0.64       210\n",
      "           2       0.47      0.63      0.54       210\n",
      "           3       0.60      0.84      0.70       210\n",
      "           4       0.59      0.39      0.47       210\n",
      "           5       0.54      0.14      0.23       210\n",
      "           6       0.42      0.59      0.49       210\n",
      "           7       0.89      0.60      0.72       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.54      1470\n",
      "weighted avg       0.58      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.49455782312925173\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 96   3  13  81   5  11   1]\n",
      " [ 15 129  53   8   3   1   1]\n",
      " [  1   8 196   3   1   0   1]\n",
      " [  7  35  58  82  16   9   3]\n",
      " [ 63  19   4  81  25  12   6]\n",
      " [ 13  32  63  21   5  26  50]\n",
      " [  4   4   3   4   5  17 173]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.46      0.47       210\n",
      "           2       0.56      0.61      0.59       210\n",
      "           3       0.50      0.93      0.65       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.42      0.12      0.19       210\n",
      "           6       0.34      0.12      0.18       210\n",
      "           7       0.74      0.82      0.78       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.48      0.49      0.46      1470\n",
      "weighted avg       0.48      0.49      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[163   4  12   6  22   2   1]\n",
      " [  1 150  31  19   5   4   0]\n",
      " [  0   8 197   5   0   0   0]\n",
      " [  6   9  36 131  18  10   0]\n",
      " [ 34  18   8  22 121   4   3]\n",
      " [  6  28  47  27   2  75  25]\n",
      " [  1   1   5   0   2  22 179]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.78      0.77       210\n",
      "           2       0.69      0.71      0.70       210\n",
      "           3       0.59      0.94      0.72       210\n",
      "           4       0.62      0.62      0.62       210\n",
      "           5       0.71      0.58      0.64       210\n",
      "           6       0.64      0.36      0.46       210\n",
      "           7       0.86      0.85      0.86       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.68      1470\n",
      "weighted avg       0.70      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.691156462585034\n",
      "Confusion Matrix of SVM is:\n",
      " [[159   3   0   3  27  18   0]\n",
      " [  6 153  12  12   7  20   0]\n",
      " [  0   9 178  14   1   8   0]\n",
      " [  9  19  21 118  19  23   1]\n",
      " [ 30  22   5  18 126   6   3]\n",
      " [ 13  21  10  15   6 117  28]\n",
      " [  8   2   2   2   1  30 165]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.67      0.73      0.70       210\n",
      "           3       0.78      0.85      0.81       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.67      0.60      0.63       210\n",
      "           6       0.53      0.56      0.54       210\n",
      "           7       0.84      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[140   7   1   9  27  26   0]\n",
      " [  1 146  10  14  10  29   0]\n",
      " [  0  14 160  21   1  14   0]\n",
      " [  1  26   9 133  13  28   0]\n",
      " [ 23  27   4  27 108  18   3]\n",
      " [  1  15   2  27   1 153  11]\n",
      " [  1   2   0   3   1  50 153]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       210\n",
      "           2       0.62      0.70      0.65       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.67      0.51      0.58       210\n",
      "           6       0.48      0.73      0.58       210\n",
      "           7       0.92      0.73      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of SVM is:\n",
      " [[143   4   0   1  33  27   2]\n",
      " [  1 147   9  19   7  25   2]\n",
      " [  0  11 168  22   1   8   0]\n",
      " [  2  14  10 142  11  27   4]\n",
      " [ 19  21   2  23 117  13  15]\n",
      " [  0  11   1  21   0 137  40]\n",
      " [  0   1   0   1   1  21 186]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.68      0.76       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.88      0.80      0.84       210\n",
      "           4       0.62      0.68      0.65       210\n",
      "           5       0.69      0.56      0.62       210\n",
      "           6       0.53      0.65      0.59       210\n",
      "           7       0.75      0.89      0.81       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of SVM is:\n",
      " [[148   1   0   4  39  16   2]\n",
      " [  1 133  27  22   8  19   0]\n",
      " [  0   5 181  17   0   7   0]\n",
      " [  1  18  22 136   8  18   7]\n",
      " [ 41  23   9  22 109   2   4]\n",
      " [  0   9   6  33   2 123  37]\n",
      " [  0   1   2   1   2  23 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.70      0.74       210\n",
      "           2       0.70      0.63      0.67       210\n",
      "           3       0.73      0.86      0.79       210\n",
      "           4       0.58      0.65      0.61       210\n",
      "           5       0.65      0.52      0.58       210\n",
      "           6       0.59      0.59      0.59       210\n",
      "           7       0.78      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.68      1470\n",
      "weighted avg       0.69      0.69      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   1   0   0   0 209]\n",
      " [  0   0  27   0   0   0 183]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  0   0   8   0   0   0 202]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.72      0.51      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.27       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.12      1470\n",
      "weighted avg       0.13      0.22      0.12      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.27755102040816326\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81   0   1   0   0   0 128]\n",
      " [  1   9  18   0   0   0 182]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   0   0 199]\n",
      " [ 63   0   5   0   0   0 142]\n",
      " [  1   0   1   0   0   0 208]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.36      0.28      0.21      1470\n",
      "weighted avg       0.36      0.28      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34625850340136055\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   0   1   0  41   0  44]\n",
      " [  2   9  18   0   0   0 181]\n",
      " [  0   0 108   0   0   0 102]\n",
      " [  3   0   8   0   3   0 196]\n",
      " [ 71   0   5   0  58   0  76]\n",
      " [  2   0   1   0   1   0 206]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.59      0.60       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.56      0.28      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.21      1.00      0.34       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.45      0.35      0.29      1470\n",
      "weighted avg       0.45      0.35      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40068027210884355\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   0   1   0  42  44   0]\n",
      " [  1   9  18   0   1 180   1]\n",
      " [  0   0 108   0   0 102   0]\n",
      " [  3   0   8   0   3 195   1]\n",
      " [ 54   0   5   0  75  74   2]\n",
      " [  1   0   1   0   2 198   8]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.59      0.63       210\n",
      "           2       1.00      0.04      0.08       210\n",
      "           3       0.77      0.51      0.62       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.61      0.36      0.45       210\n",
      "           6       0.21      0.94      0.35       210\n",
      "           7       0.86      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.59      0.40      0.38      1470\n",
      "weighted avg       0.59      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   1   0   0  37  44   0]\n",
      " [  1  24   3   0   1 180   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 50   4   1   0  79  73   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 109 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.47      0.11      0.18       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.38      0.48       210\n",
      "           6       0.22      0.93      0.35       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.55      0.42      0.41      1470\n",
      "weighted avg       0.55      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   1   0   0  43  44   0]\n",
      " [  1  50   3   0   1 154   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 40  16   1   1  88  61   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   0 109 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.58      0.65       210\n",
      "           2       0.56      0.24      0.33       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.64      0.42      0.51       210\n",
      "           6       0.23      0.93      0.37       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.57      0.44      0.44      1470\n",
      "weighted avg       0.57      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   3   0   1 129   1]\n",
      " [  0  15  93   0   0 102   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 38  17   1   2  89  60   3]\n",
      " [  1   1   0   0   2 196  10]\n",
      " [  0   0   0   0   1 109 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.59      0.65       210\n",
      "           2       0.65      0.36      0.46       210\n",
      "           3       0.94      0.44      0.60       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.65      0.42      0.51       210\n",
      "           6       0.23      0.93      0.38       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.58      0.46      0.46      1470\n",
      "weighted avg       0.58      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4741496598639456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree is:\n",
      " [[123   1   0   2  40  44   0]\n",
      " [  1  75   5   0   1 127   1]\n",
      " [  0  12 110   0   0  88   0]\n",
      " [  3   6   2   0   3 195   1]\n",
      " [ 35  17   1   2  92  61   2]\n",
      " [  2   1   0   0   1 197   9]\n",
      " [  0   0   0   0   0 110 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.59      0.66       210\n",
      "           2       0.67      0.36      0.47       210\n",
      "           3       0.93      0.52      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.67      0.44      0.53       210\n",
      "           6       0.24      0.94      0.38       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.59      0.47      0.48      1470\n",
      "weighted avg       0.59      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49047619047619045\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[122   2   0   1  41  44   0]\n",
      " [  1 104   5   1   1  98   0]\n",
      " [  0  26 111   0   0  73   0]\n",
      " [  3  18   2   0   3 183   1]\n",
      " [ 42  28   1   2  89  45   3]\n",
      " [  2   3   0   0   1 194  10]\n",
      " [  0   3   0   0   0 106 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.58      0.64       210\n",
      "           2       0.57      0.50      0.53       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.66      0.42      0.52       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49387755102040815\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  1  88  21   0   2  97   1]\n",
      " [  0  11 131   0   0  68   0]\n",
      " [  5   7  13   0   1 183   1]\n",
      " [ 63  18  11   1  69  45   3]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.69      0.68       210\n",
      "           2       0.69      0.42      0.52       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.74      0.33      0.46       210\n",
      "           6       0.26      0.92      0.41       210\n",
      "           7       0.87      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.57      0.49      0.48      1470\n",
      "weighted avg       0.57      0.49      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   2   0   0  19  44   0]\n",
      " [  1  93  15   2   3  95   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  4   8  12  22   2 161   1]\n",
      " [ 55  16  11   3  79  44   2]\n",
      " [  3   1   2   0   0 194  10]\n",
      " [  0   1   2   0   0 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.71      0.44      0.55       210\n",
      "           3       0.76      0.63      0.69       210\n",
      "           4       0.81      0.10      0.19       210\n",
      "           5       0.77      0.38      0.50       210\n",
      "           6       0.27      0.92      0.42       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.70      0.52      0.52      1470\n",
      "weighted avg       0.70      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   2   0   1  35  43   0]\n",
      " [  1  94  15   4   2  93   1]\n",
      " [  0  10 132   0   0  68   0]\n",
      " [  2   7  16  34   4 146   1]\n",
      " [ 28  17  11   4 105  42   3]\n",
      " [  2   1   2   0   1 194  10]\n",
      " [  0   1   2   0   2 108  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.61      0.69       210\n",
      "           2       0.71      0.45      0.55       210\n",
      "           3       0.74      0.63      0.68       210\n",
      "           4       0.79      0.16      0.27       210\n",
      "           5       0.70      0.50      0.58       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.87      0.46      0.60       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.70      0.53      0.54      1470\n",
      "weighted avg       0.70      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   2   0   0  21  43   0]\n",
      " [  2  92   8   4   9  95   0]\n",
      " [  0  10 120   0  12  68   0]\n",
      " [  5   7   7  42  11 137   1]\n",
      " [ 52  18   1   5  91  40   3]\n",
      " [  3   1   1   2   1 193   9]\n",
      " [  0   1   0   0   2 107 100]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.69       210\n",
      "           2       0.70      0.44      0.54       210\n",
      "           3       0.88      0.57      0.69       210\n",
      "           4       0.79      0.20      0.32       210\n",
      "           5       0.62      0.43      0.51       210\n",
      "           6       0.28      0.92      0.43       210\n",
      "           7       0.88      0.48      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.69      0.53      0.54      1470\n",
      "weighted avg       0.69      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[151   2   0   0  22  35   0]\n",
      " [  2  95  11   7   2  93   0]\n",
      " [  0  10 126   6   0  68   0]\n",
      " [  5   7   8  50   2 137   1]\n",
      " [ 56  19   6   9  81  37   2]\n",
      " [  3   1   1   3   0 192  10]\n",
      " [  0   1   0   2   1 107  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71       210\n",
      "           2       0.70      0.45      0.55       210\n",
      "           3       0.83      0.60      0.70       210\n",
      "           4       0.65      0.24      0.35       210\n",
      "           5       0.75      0.39      0.51       210\n",
      "           6       0.29      0.91      0.44       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.69      0.54      0.55      1470\n",
      "weighted avg       0.69      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[152   2   0   0  19  37   0]\n",
      " [  2  97  10   1   5  94   1]\n",
      " [  0  12 128   0   2  68   0]\n",
      " [  5   9   9  41   8 137   1]\n",
      " [ 48  22   4   5  91  38   2]\n",
      " [  1   1   1   2   3 193   9]\n",
      " [  0   1   0   0   5 109  95]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.72      0.73       210\n",
      "           2       0.67      0.46      0.55       210\n",
      "           3       0.84      0.61      0.71       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.68      0.43      0.53       210\n",
      "           6       0.29      0.92      0.44       210\n",
      "           7       0.88      0.45      0.60       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.70      0.54      0.55      1470\n",
      "weighted avg       0.70      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[154   1   0   0  21  34   0]\n",
      " [  2 109  10   2   7  80   0]\n",
      " [  0  10 130   0   2  68   0]\n",
      " [  4  17   8  41   9 130   1]\n",
      " [ 52  22   4   5  95  30   2]\n",
      " [  2   6   1   2   2 188   9]\n",
      " [  0   1   0   0   3 109  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       210\n",
      "           2       0.66      0.52      0.58       210\n",
      "           3       0.85      0.62      0.72       210\n",
      "           4       0.82      0.20      0.32       210\n",
      "           5       0.68      0.45      0.54       210\n",
      "           6       0.29      0.90      0.44       210\n",
      "           7       0.89      0.46      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.70      0.55      0.56      1470\n",
      "weighted avg       0.70      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0   1  26  33   0]\n",
      " [  2 110  11   1   8  77   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  4  17  10  42   9 127   1]\n",
      " [ 46  21   5   4 102  28   4]\n",
      " [  1   6   1   2   3 189   8]\n",
      " [  0   1   0   0   3 108  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.72       210\n",
      "           2       0.66      0.52      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.84      0.20      0.32       210\n",
      "           5       0.67      0.49      0.56       210\n",
      "           6       0.30      0.90      0.45       210\n",
      "           7       0.88      0.47      0.61       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.70      0.56      0.57      1470\n",
      "weighted avg       0.70      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[155   1   0   0  22  32   0]\n",
      " [  2 108  11   2   7  79   1]\n",
      " [  0  10 139   0   2  59   0]\n",
      " [  3  16  10  41  11 128   1]\n",
      " [ 48  21   5   6 100  27   3]\n",
      " [  2   5   1   2   2 186  12]\n",
      " [  0   1   0   0   4 103 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.67      0.51      0.58       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.80      0.20      0.31       210\n",
      "           5       0.68      0.48      0.56       210\n",
      "           6       0.30      0.89      0.45       210\n",
      "           7       0.86      0.49      0.62       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.57      1470\n",
      "weighted avg       0.70      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[149   1   0   0  24  36   0]\n",
      " [  2 105  12   3  10  77   1]\n",
      " [  0   8 139   3   1  59   0]\n",
      " [  3  14  12  40  12 127   2]\n",
      " [ 41  18   6   8 102  30   5]\n",
      " [  2   5   1   3   1 181  17]\n",
      " [  0   1   0   0   4  95 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.71      0.73       210\n",
      "           2       0.69      0.50      0.58       210\n",
      "           3       0.82      0.66      0.73       210\n",
      "           4       0.70      0.19      0.30       210\n",
      "           5       0.66      0.49      0.56       210\n",
      "           6       0.30      0.86      0.44       210\n",
      "           7       0.81      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.68      0.56      0.57      1470\n",
      "weighted avg       0.68      0.56      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[144   1   0   0  33  32   0]\n",
      " [  2 112  11   2  10  72   1]\n",
      " [  0  10 139   1   1  59   0]\n",
      " [  2  16  10  41  13 126   2]\n",
      " [ 30  23   4   5 120  23   5]\n",
      " [  1   5   1   3   2 184  14]\n",
      " [  0   1   0   0   3  96 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.67      0.53      0.59       210\n",
      "           3       0.84      0.66      0.74       210\n",
      "           4       0.79      0.20      0.31       210\n",
      "           5       0.66      0.57      0.61       210\n",
      "           6       0.31      0.88      0.46       210\n",
      "           7       0.83      0.52      0.64       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.70      0.58      0.59      1470\n",
      "weighted avg       0.70      0.58      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[164   3   2   6  15  19   1]\n",
      " [  1  84  40  28   6  48   3]\n",
      " [  0   0 141   8   0  61   0]\n",
      " [  3  11  12 121  12  47   4]\n",
      " [ 64  20  12  19  79  10   6]\n",
      " [  5   6   1  49   2 120  27]\n",
      " [  0   1   0  13   2  31 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.78      0.73       210\n",
      "           2       0.67      0.40      0.50       210\n",
      "           3       0.68      0.67      0.67       210\n",
      "           4       0.50      0.58      0.53       210\n",
      "           5       0.68      0.38      0.48       210\n",
      "           6       0.36      0.57      0.44       210\n",
      "           7       0.80      0.78      0.79       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.62      0.59      0.59      1470\n",
      "weighted avg       0.62      0.59      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   1   2   5  20  21   4]\n",
      " [  1  95  41  23   7  38   5]\n",
      " [  0   7 147   5   0  48   3]\n",
      " [  4  13  13 107  15  40  18]\n",
      " [ 66  20  11  16  80  10   7]\n",
      " [  3  11   1  32   3 119  41]\n",
      " [  0   2   0   0   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       210\n",
      "           2       0.64      0.45      0.53       210\n",
      "           3       0.68      0.70      0.69       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.63      0.38      0.47       210\n",
      "           6       0.39      0.57      0.46       210\n",
      "           7       0.69      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[159   2   2   8  21  17   1]\n",
      " [  1  96  31  27   5  48   2]\n",
      " [  0   0 141   9   0  60   0]\n",
      " [  3   8  11 134  12  40   2]\n",
      " [ 58  18  12  20  90   6   6]\n",
      " [  2  10   2  37   4 127  28]\n",
      " [  0   4   0   9   1  28 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       210\n",
      "           2       0.70      0.46      0.55       210\n",
      "           3       0.71      0.67      0.69       210\n",
      "           4       0.55      0.64      0.59       210\n",
      "           5       0.68      0.43      0.52       210\n",
      "           6       0.39      0.60      0.47       210\n",
      "           7       0.81      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.62      1470\n",
      "weighted avg       0.65      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   6  22  21   1]\n",
      " [  1 101  31  27   4  45   1]\n",
      " [  0   0 148   7   0  55   0]\n",
      " [  3  13  13 124  11  45   1]\n",
      " [ 58  21   7  19  90   9   6]\n",
      " [  2  10   2  29   4 137  26]\n",
      " [  0   1   0   2   4  36 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.74      0.73       210\n",
      "           2       0.68      0.48      0.56       210\n",
      "           3       0.73      0.70      0.72       210\n",
      "           4       0.58      0.59      0.58       210\n",
      "           5       0.67      0.43      0.52       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   1   2   3  24  24   1]\n",
      " [  1 113  30  23   2  40   1]\n",
      " [  0   2 150   6   0  52   0]\n",
      " [  4  12  13 118  11  50   2]\n",
      " [ 58  21   7  18  91   9   6]\n",
      " [  3   9   3  28   3 137  27]\n",
      " [  0   3   0   0   1  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.73      0.71      0.72       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.69      0.43      0.53       210\n",
      "           6       0.39      0.65      0.49       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.64      1470\n",
      "weighted avg       0.66      0.63      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6278911564625851\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   2   3  23  24   2]\n",
      " [  1 108  31  23   4  42   1]\n",
      " [  0   1 149   2   0  58   0]\n",
      " [  4  15  13 115   7  54   2]\n",
      " [ 55  21   7  19  92  11   5]\n",
      " [  3   8   2  21   4 144  28]\n",
      " [  0   4   0   2   0  43 161]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72       210\n",
      "           2       0.68      0.51      0.59       210\n",
      "           3       0.73      0.71      0.72       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.71      0.44      0.54       210\n",
      "           6       0.38      0.69      0.49       210\n",
      "           7       0.81      0.77      0.79       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.66      0.63      0.63      1470\n",
      "weighted avg       0.66      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   3  22  24   1]\n",
      " [  1 112  27  23   4  42   1]\n",
      " [  0   0 150   1   0  59   0]\n",
      " [  3  10  13 117  12  53   2]\n",
      " [ 44  23   7  18 101  12   5]\n",
      " [  2   8   2  29   4 136  29]\n",
      " [  0   3   0   1   2  39 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.74      0.75       210\n",
      "           2       0.71      0.53      0.61       210\n",
      "           3       0.75      0.71      0.73       210\n",
      "           4       0.61      0.56      0.58       210\n",
      "           5       0.70      0.48      0.57       210\n",
      "           6       0.37      0.65      0.47       210\n",
      "           7       0.81      0.79      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.64      1470\n",
      "weighted avg       0.67      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[156   2   2   3  20  26   1]\n",
      " [  1 114  27  22   5  40   1]\n",
      " [  0   1 152   4   0  53   0]\n",
      " [  3  14  13 114  10  54   2]\n",
      " [ 50  24   7  18  94  12   5]\n",
      " [  2   8   2  21   4 146  27]\n",
      " [  0   2   0   0   2  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.74      0.74       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.75      0.72      0.74       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.70      0.45      0.54       210\n",
      "           6       0.40      0.70      0.50       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[157   2   1   3  23  23   1]\n",
      " [  1 113  32  20   4  39   1]\n",
      " [  0   3 151   2   0  54   0]\n",
      " [  3  12  13 115  12  53   2]\n",
      " [ 52  20   6  20  97  10   5]\n",
      " [  2   9   3  24   4 143  25]\n",
      " [  0   3   0   0   1  40 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.73      0.72      0.73       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.69      0.46      0.55       210\n",
      "           6       0.40      0.68      0.50       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   4  23  25   1]\n",
      " [  1 113  31  22   3  39   1]\n",
      " [  0   3 151  10   0  46   0]\n",
      " [  3  14  12 122   9  48   2]\n",
      " [ 49  24   6  19  97  10   5]\n",
      " [  3   8   4  28   3 138  26]\n",
      " [  0   2   0   0   2  38 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.73      0.73       210\n",
      "           2       0.68      0.54      0.60       210\n",
      "           3       0.74      0.72      0.73       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.40      0.66      0.50       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.65      1470\n",
      "weighted avg       0.67      0.64      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   3  24  24   1]\n",
      " [  1 118  25  22   4  39   1]\n",
      " [  0   1 156   6   0  47   0]\n",
      " [  3  14  12 120   9  50   2]\n",
      " [ 41  25   6  20 104   9   5]\n",
      " [  2   7   4  29   4 137  27]\n",
      " [  0   3   0   0   1  35 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.75       210\n",
      "           2       0.69      0.56      0.62       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.60      0.57      0.59       210\n",
      "           5       0.71      0.50      0.58       210\n",
      "           6       0.40      0.65      0.50       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   1   1   4  26  24   1]\n",
      " [  1 115  26  21   5  41   1]\n",
      " [  0   1 156   6   0  47   0]\n",
      " [  3  14  13 121   8  49   2]\n",
      " [ 39  20   6  21 111   8   5]\n",
      " [  3   8   2  20   3 146  28]\n",
      " [  0   3   0   0   1  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.71      0.55      0.62       210\n",
      "           3       0.76      0.74      0.75       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.72      0.53      0.61       210\n",
      "           6       0.41      0.70      0.52       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.66      1470\n",
      "weighted avg       0.69      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[152   1   1   4  27  24   1]\n",
      " [  1 118  26  23   3  38   1]\n",
      " [  0   2 159   5   0  44   0]\n",
      " [  3  14  13 116  11  51   2]\n",
      " [ 43  24   7  21 103   7   5]\n",
      " [  2   7   4  18   4 148  27]\n",
      " [  0   1   0   0   2  38 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74       210\n",
      "           2       0.71      0.56      0.63       210\n",
      "           3       0.76      0.76      0.76       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.69      0.49      0.57       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   1   1   4  28  24   1]\n",
      " [  1 119  24  21   6  38   1]\n",
      " [  0   4 157   6   0  43   0]\n",
      " [  3  15  12 118  10  50   2]\n",
      " [ 38  22   6  17 113   9   5]\n",
      " [  2   7   4  17   3 150  27]\n",
      " [  0   1   0   0   2  37 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.72      0.75       210\n",
      "           2       0.70      0.57      0.63       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.70      0.54      0.61       210\n",
      "           6       0.43      0.71      0.53       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   4  29  23   1]\n",
      " [  1 121  26  20   3  38   1]\n",
      " [  0   4 162   3   0  41   0]\n",
      " [  3  14  13 119   9  50   2]\n",
      " [ 40  21   7  16 112   9   5]\n",
      " [  2   8   3  21   3 147  26]\n",
      " [  0   2   0   0   1  41 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74       210\n",
      "           2       0.70      0.58      0.63       210\n",
      "           3       0.76      0.77      0.77       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.42      0.70      0.53       210\n",
      "           7       0.83      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   4  24  23   1]\n",
      " [  1 120  25  21   4  38   1]\n",
      " [  0   3 162   4   0  41   0]\n",
      " [  2  15  13 120  11  47   2]\n",
      " [ 39  21   7  18 112   8   5]\n",
      " [  1   9   4  26   5 139  26]\n",
      " [  0   1   0   0   2  39 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.74      0.76       210\n",
      "           2       0.70      0.57      0.63       210\n",
      "           3       0.76      0.77      0.77       210\n",
      "           4       0.62      0.57      0.60       210\n",
      "           5       0.71      0.53      0.61       210\n",
      "           6       0.41      0.66      0.51       210\n",
      "           7       0.83      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   5  29  22   1]\n",
      " [  1 126  25  18   4  35   1]\n",
      " [  0   4 159  13   0  34   0]\n",
      " [  2  13  13 125  10  45   2]\n",
      " [ 38  23   7  18 110   9   5]\n",
      " [  2   8   3  25   2 143  27]\n",
      " [  0   1   0   0   1  42 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.74       210\n",
      "           2       0.71      0.60      0.65       210\n",
      "           3       0.76      0.76      0.76       210\n",
      "           4       0.61      0.60      0.60       210\n",
      "           5       0.71      0.52      0.60       210\n",
      "           6       0.43      0.68      0.53       210\n",
      "           7       0.82      0.79      0.81       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   3  27  23   1]\n",
      " [  1 123  24  18   7  36   1]\n",
      " [  0   5 160  11   0  34   0]\n",
      " [  2  14  12 124  11  45   2]\n",
      " [ 35  22   6  20 115   7   5]\n",
      " [  3   8   4  24   3 140  28]\n",
      " [  0   1   0   0   2  35 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.73      0.76       210\n",
      "           2       0.70      0.59      0.64       210\n",
      "           3       0.77      0.76      0.77       210\n",
      "           4       0.62      0.59      0.60       210\n",
      "           5       0.70      0.55      0.61       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.82      0.82      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6748299319727891\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   4  26  24   0]\n",
      " [  1 125  26  18   5  34   1]\n",
      " [  0   3 161  11   0  35   0]\n",
      " [  2  13  13 122  12  46   2]\n",
      " [ 38  21   6  18 113   9   5]\n",
      " [  2   7   3  20   3 148  27]\n",
      " [  0   0   0   1   3  36 170]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.73      0.75       210\n",
      "           2       0.73      0.60      0.66       210\n",
      "           3       0.77      0.77      0.77       210\n",
      "           4       0.63      0.58      0.60       210\n",
      "           5       0.70      0.54      0.61       210\n",
      "           6       0.45      0.70      0.55       210\n",
      "           7       0.83      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[155   2   1   4  25  22   1]\n",
      " [  1 126  24  20   4  34   1]\n",
      " [  0   5 160  11   0  34   0]\n",
      " [  2  13  12 124  10  47   2]\n",
      " [ 36  20   6  22 115   6   5]\n",
      " [  2   8   3  23   4 141  29]\n",
      " [  0   1   0   1   1  40 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.76       210\n",
      "           2       0.72      0.60      0.65       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.60      0.59      0.60       210\n",
      "           5       0.72      0.55      0.62       210\n",
      "           6       0.44      0.67      0.53       210\n",
      "           7       0.81      0.80      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[170   2   0   6  25   7   0]\n",
      " [ 11 154  11  16  13   5   0]\n",
      " [  5  12 172  18   3   0   0]\n",
      " [ 17  10  13 136  23  11   0]\n",
      " [ 24  19   2  30 121  10   4]\n",
      " [ 32  20   4  35   2  86  31]\n",
      " [  3   1   1   0   1  28 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.81      0.72       210\n",
      "           2       0.71      0.73      0.72       210\n",
      "           3       0.85      0.82      0.83       210\n",
      "           4       0.56      0.65      0.60       210\n",
      "           5       0.64      0.58      0.61       210\n",
      "           6       0.59      0.41      0.48       210\n",
      "           7       0.83      0.84      0.84       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//BagOfWords//tf_500_vectors.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=1000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19e40",
   "metadata": {},
   "source": [
    "### Sentence Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c2c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6482993197278911\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 99  18   3  41  36  13   0]\n",
      " [  1 184   1  18   5   0   1]\n",
      " [  0  23 171  15   0   1   0]\n",
      " [  0  29   2 176   2   1   0]\n",
      " [  6  35   1  63 102   1   2]\n",
      " [  1  62   1  60   6  55  25]\n",
      " [  1  10   0  17   4  12 166]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.47      0.62       210\n",
      "           2       0.51      0.88      0.64       210\n",
      "           3       0.96      0.81      0.88       210\n",
      "           4       0.45      0.84      0.59       210\n",
      "           5       0.66      0.49      0.56       210\n",
      "           6       0.66      0.26      0.38       210\n",
      "           7       0.86      0.79      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.72      0.65      0.64      1470\n",
      "weighted avg       0.72      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[152   7   5   4  31   7   4]\n",
      " [  8 163   8   8  19   2   2]\n",
      " [  1   7 193   2   2   5   0]\n",
      " [ 19  25  18 100  33   9   6]\n",
      " [ 42  28   7  23 103   0   7]\n",
      " [ 33  26  10  12  11  74  44]\n",
      " [ 11   3   0   4   6  14 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.72      0.64       210\n",
      "           2       0.63      0.78      0.70       210\n",
      "           3       0.80      0.92      0.86       210\n",
      "           4       0.65      0.48      0.55       210\n",
      "           5       0.50      0.49      0.50       210\n",
      "           6       0.67      0.35      0.46       210\n",
      "           7       0.73      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   8   4   4  33   9   6]\n",
      " [  6 165   6  11  18   2   2]\n",
      " [  0   6 193   4   3   4   0]\n",
      " [ 11  20  18 114  34   9   4]\n",
      " [ 42  29   6  24  98   2   9]\n",
      " [ 27  23   6  12  12  87  43]\n",
      " [  9   2   0   3   4  28 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.70      0.65       210\n",
      "           2       0.65      0.79      0.71       210\n",
      "           3       0.83      0.92      0.87       210\n",
      "           4       0.66      0.54      0.60       210\n",
      "           5       0.49      0.47      0.48       210\n",
      "           6       0.62      0.41      0.50       210\n",
      "           7       0.72      0.78      0.75       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6530612244897959\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   7   5   5  36  13   2]\n",
      " [  7 165   8   8  18   2   2]\n",
      " [  0   6 193   6   2   3   0]\n",
      " [ 10  22  19 111  28  13   7]\n",
      " [ 41  29   7  23 100   0  10]\n",
      " [ 20  21   5  18  12  79  55]\n",
      " [  5   1   0   1   4  29 170]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.68      0.65       210\n",
      "           2       0.66      0.79      0.72       210\n",
      "           3       0.81      0.92      0.86       210\n",
      "           4       0.65      0.53      0.58       210\n",
      "           5       0.50      0.48      0.49       210\n",
      "           6       0.57      0.38      0.45       210\n",
      "           7       0.69      0.81      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.64      0.65      0.64      1470\n",
      "weighted avg       0.64      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6673469387755102\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   6   2   5  32   9   6]\n",
      " [  8 167   8   6  17   1   3]\n",
      " [  0   4 195   5   2   4   0]\n",
      " [ 12  22  22 101  37   9   7]\n",
      " [ 32  35   6  19 107   1  10]\n",
      " [ 23  21   5  18  12  84  47]\n",
      " [  3   1   0   2   5  22 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.71      0.68       210\n",
      "           2       0.65      0.80      0.72       210\n",
      "           3       0.82      0.93      0.87       210\n",
      "           4       0.65      0.48      0.55       210\n",
      "           5       0.50      0.51      0.51       210\n",
      "           6       0.65      0.40      0.49       210\n",
      "           7       0.71      0.84      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   4   2   5  35  12   6]\n",
      " [  8 164   8   6  20   1   3]\n",
      " [  0   6 195   3   3   3   0]\n",
      " [ 12  22  20  98  38  12   8]\n",
      " [ 30  32   7  21 109   2   9]\n",
      " [ 23  19   8  19   9  78  54]\n",
      " [  4   1   0   2   4  20 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.70      0.67       210\n",
      "           2       0.66      0.78      0.72       210\n",
      "           3       0.81      0.93      0.87       210\n",
      "           4       0.64      0.47      0.54       210\n",
      "           5       0.50      0.52      0.51       210\n",
      "           6       0.61      0.37      0.46       210\n",
      "           7       0.69      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.65      0.66      0.65      1470\n",
      "weighted avg       0.65      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   4   3   4  33  11   6]\n",
      " [  5 164  10   4  21   2   4]\n",
      " [  1   5 196   3   2   3   0]\n",
      " [ 12  23  24  93  40   9   9]\n",
      " [ 26  33   7  17 114   3  10]\n",
      " [ 21  22   8  20   8  75  56]\n",
      " [  3   1   0   0   5  17 184]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70       210\n",
      "           2       0.65      0.78      0.71       210\n",
      "           3       0.79      0.93      0.86       210\n",
      "           4       0.66      0.44      0.53       210\n",
      "           5       0.51      0.54      0.53       210\n",
      "           6       0.62      0.36      0.45       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.65      1470\n",
      "weighted avg       0.66      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[113   2  16   7  31  31  10]\n",
      " [  0 106  27  11  34  28   4]\n",
      " [  1   5 159  16   2  27   0]\n",
      " [  3  14  14  78  50  38  13]\n",
      " [ 20  14   2  15 122  17  20]\n",
      " [ 11   2   7  26   1 113  50]\n",
      " [  0   0   0   1   2  51 156]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.54      0.63       210\n",
      "           2       0.74      0.50      0.60       210\n",
      "           3       0.71      0.76      0.73       210\n",
      "           4       0.51      0.37      0.43       210\n",
      "           5       0.50      0.58      0.54       210\n",
      "           6       0.37      0.54      0.44       210\n",
      "           7       0.62      0.74      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.58      1470\n",
      "weighted avg       0.60      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.21564625850340136\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 10   1 165   9   7  13   5]\n",
      " [  4   9 170   9   5  13   0]\n",
      " [  2   4 185   1   2  14   2]\n",
      " [  3   8 146  20   9  15   9]\n",
      " [  8   4 158  12  11   9   8]\n",
      " [  8   7 118  15   8  39  15]\n",
      " [  3   2 129   6   2  25  43]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.05      0.08       210\n",
      "           2       0.26      0.04      0.07       210\n",
      "           3       0.17      0.88      0.29       210\n",
      "           4       0.28      0.10      0.14       210\n",
      "           5       0.25      0.05      0.09       210\n",
      "           6       0.30      0.19      0.23       210\n",
      "           7       0.52      0.20      0.29       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.29      0.22      0.17      1470\n",
      "weighted avg       0.29      0.22      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.5816326530612245\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 55  12   2  45  62  34   0]\n",
      " [  0 172   4  29   1   3   1]\n",
      " [  0  18 140  50   1   1   0]\n",
      " [  0  24   1 169   5   6   5]\n",
      " [ 10  41   1  61  89   4   4]\n",
      " [  1  37   7  52   9  81  23]\n",
      " [  0   3   0   9   2  47 149]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.26      0.40       210\n",
      "           2       0.56      0.82      0.67       210\n",
      "           3       0.90      0.67      0.77       210\n",
      "           4       0.41      0.80      0.54       210\n",
      "           5       0.53      0.42      0.47       210\n",
      "           6       0.46      0.39      0.42       210\n",
      "           7       0.82      0.71      0.76       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.64      0.58      0.57      1470\n",
      "weighted avg       0.64      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7034013605442176\n",
      "Confusion Matrix of SVM is:\n",
      " [[118   9   2  20  44  16   1]\n",
      " [  2 179   6  15   2   4   2]\n",
      " [  0   9 182  17   1   1   0]\n",
      " [  1  24   2 150  20   6   7]\n",
      " [  8  45   0  27 122   2   6]\n",
      " [  2  22   7  32   5 102  40]\n",
      " [  0   0   0   3   2  24 181]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.56      0.69       210\n",
      "           2       0.62      0.85      0.72       210\n",
      "           3       0.91      0.87      0.89       210\n",
      "           4       0.57      0.71      0.63       210\n",
      "           5       0.62      0.58      0.60       210\n",
      "           6       0.66      0.49      0.56       210\n",
      "           7       0.76      0.86      0.81       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.70      1470\n",
      "weighted avg       0.72      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7578231292517007\n",
      "Confusion Matrix of SVM is:\n",
      " [[144   2   1   3  29  28   3]\n",
      " [  2 161   4  19  10  12   2]\n",
      " [  0   2 195   9   2   2   0]\n",
      " [  0   8   4 140  21  32   5]\n",
      " [ 17  15   0  25 135   9   9]\n",
      " [  6   3   2  12   2 150  35]\n",
      " [  0   0   0   0   1  20 189]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.69      0.76       210\n",
      "           2       0.84      0.77      0.80       210\n",
      "           3       0.95      0.93      0.94       210\n",
      "           4       0.67      0.67      0.67       210\n",
      "           5       0.68      0.64      0.66       210\n",
      "           6       0.59      0.71      0.65       210\n",
      "           7       0.78      0.90      0.83       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.77      0.76      0.76      1470\n",
      "weighted avg       0.77      0.76      0.76      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.4095238095238095\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 27   0 126   0  38   7  12]\n",
      " [  0  28 132   0  36   7   7]\n",
      " [  0   0 207   0   1   2   0]\n",
      " [  5   4  87   6  73  13  22]\n",
      " [ 14   5  47   0 124   3  17]\n",
      " [  6   4  72   0  13  34  81]\n",
      " [  0   0   6   0   9  19 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.13      0.21       210\n",
      "           2       0.68      0.13      0.22       210\n",
      "           3       0.31      0.99      0.47       210\n",
      "           4       1.00      0.03      0.06       210\n",
      "           5       0.42      0.59      0.49       210\n",
      "           6       0.40      0.16      0.23       210\n",
      "           7       0.56      0.84      0.67       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.56      0.41      0.33      1470\n",
      "weighted avg       0.56      0.41      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2510204081632653\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   4   0   0   0 206]\n",
      " [  0   0  47   0   0   0 163]\n",
      " [  0   0 159   0   0   0  51]\n",
      " [  0   0  24   0   0   0 186]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0  17   0   0   0 193]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.62      0.76      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.30       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.11      0.25      0.14      1470\n",
      "weighted avg       0.11      0.25      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.391156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   1   3   0 159   0  47]\n",
      " [  0  40   7   0 136   0  27]\n",
      " [  0   1 158   0  36   0  15]\n",
      " [  0   1  23   0 140   0  46]\n",
      " [  0   3   3   0 176   0  28]\n",
      " [  0   3  14   0  51   0 142]\n",
      " [  0   0   0   0   9   0 201]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.82      0.19      0.31       210\n",
      "           3       0.76      0.75      0.76       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.25      0.84      0.38       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.96      0.56       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.32      0.39      0.29      1470\n",
      "weighted avg       0.32      0.39      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   0   4   0  27  29  18]\n",
      " [ 16  40   6   1 120  17  10]\n",
      " [  4   1 157   1  32  10   5]\n",
      " [ 26   1  19   4 114  19  27]\n",
      " [ 45   3   3   0 131   5  23]\n",
      " [ 33   1  15   1  18  70  72]\n",
      " [  6   0   0   0   3  40 161]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.63      0.56       210\n",
      "           2       0.87      0.19      0.31       210\n",
      "           3       0.77      0.75      0.76       210\n",
      "           4       0.57      0.02      0.04       210\n",
      "           5       0.29      0.62      0.40       210\n",
      "           6       0.37      0.33      0.35       210\n",
      "           7       0.51      0.77      0.61       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.56      0.47      0.43      1470\n",
      "weighted avg       0.56      0.47      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   4   1   0  23  26  24]\n",
      " [ 16 116   1   0  44  21  12]\n",
      " [  4  21 151   1  12  15   6]\n",
      " [ 26  37  15   2  78  19  33]\n",
      " [ 45  24   2   0 110   4  25]\n",
      " [ 33   8   8   1  11  49 100]\n",
      " [  6   1   0   0   2   7 194]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.63      0.56       210\n",
      "           2       0.55      0.55      0.55       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.50      0.01      0.02       210\n",
      "           5       0.39      0.52      0.45       210\n",
      "           6       0.35      0.23      0.28       210\n",
      "           7       0.49      0.92      0.64       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.47      1470\n",
      "weighted avg       0.52      0.51      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5333333333333333\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   1   1   7  23  56   4]\n",
      " [  5  90   6  45  25  36   3]\n",
      " [  0  16 155  17   4  17   1]\n",
      " [  9   8  12  76  43  57   5]\n",
      " [ 33   6   2  42  91  31   5]\n",
      " [ 12   6   6  13   9 132  32]\n",
      " [  1   0   0   3   2  82 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.56      0.61       210\n",
      "           2       0.71      0.43      0.53       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.37      0.36      0.37       210\n",
      "           5       0.46      0.43      0.45       210\n",
      "           6       0.32      0.63      0.43       210\n",
      "           7       0.71      0.58      0.64       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.58      0.53      0.54      1470\n",
      "weighted avg       0.58      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[104  18   2  21  31  22  12]\n",
      " [  0  77   8  63  40  16   6]\n",
      " [  0   5 159  27   5  13   1]\n",
      " [  1  10  17 100  35  35  12]\n",
      " [ 11   4   5  51 111  18  10]\n",
      " [  7  10   5  30  11 103  44]\n",
      " [  8   1   0   4   3  37 157]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.50      0.61       210\n",
      "           2       0.62      0.37      0.46       210\n",
      "           3       0.81      0.76      0.78       210\n",
      "           4       0.34      0.48      0.40       210\n",
      "           5       0.47      0.53      0.50       210\n",
      "           6       0.42      0.49      0.45       210\n",
      "           7       0.65      0.75      0.69       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.59      0.55      0.56      1470\n",
      "weighted avg       0.59      0.55      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[108  25   2  23  24  18  10]\n",
      " [  3 103   8  41  33  15   7]\n",
      " [  1   7 154  32   3  12   1]\n",
      " [  6  33  10  95  21  30  15]\n",
      " [ 18  23   2  56  88  14   9]\n",
      " [ 12  13   4  32   8 101  40]\n",
      " [  7   3   0   3   3  52 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.51      0.59       210\n",
      "           2       0.50      0.49      0.49       210\n",
      "           3       0.86      0.73      0.79       210\n",
      "           4       0.34      0.45      0.39       210\n",
      "           5       0.49      0.42      0.45       210\n",
      "           6       0.42      0.48      0.45       210\n",
      "           7       0.63      0.68      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.54      1470\n",
      "weighted avg       0.56      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[117  10   2  18  22  34   7]\n",
      " [  6  89   8  37  44  21   5]\n",
      " [  2   5 168  18   5  11   1]\n",
      " [  9  38   9  88  24  34   8]\n",
      " [ 28  29   2  46  86  10   9]\n",
      " [ 14  13   4  34  10  92  43]\n",
      " [  5   3   0   7   4  56 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.56      0.60       210\n",
      "           2       0.48      0.42      0.45       210\n",
      "           3       0.87      0.80      0.83       210\n",
      "           4       0.35      0.42      0.38       210\n",
      "           5       0.44      0.41      0.42       210\n",
      "           6       0.36      0.44      0.39       210\n",
      "           7       0.65      0.64      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.53      1470\n",
      "weighted avg       0.54      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114   8   2  32  22  23   9]\n",
      " [ 12  91  18  31  38  12   8]\n",
      " [  3   7 165  24   3   8   0]\n",
      " [ 23  26  15  72  21  41  12]\n",
      " [ 43  22   4  37  74  22   8]\n",
      " [ 12  20  12  36   6  82  42]\n",
      " [ 13   3   0   8   3  50 133]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.54      0.53       210\n",
      "           2       0.51      0.43      0.47       210\n",
      "           3       0.76      0.79      0.77       210\n",
      "           4       0.30      0.34      0.32       210\n",
      "           5       0.44      0.35      0.39       210\n",
      "           6       0.34      0.39      0.37       210\n",
      "           7       0.63      0.63      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[118   2   3  24  29  25   9]\n",
      " [ 11  94   7  39  40  15   4]\n",
      " [  5   5 158  28   5   8   1]\n",
      " [ 11  25  10  80  37  33  14]\n",
      " [ 34  17   4  35  92  20   8]\n",
      " [ 17  20  11  38  11  78  35]\n",
      " [ 10   2   1   8   5  63 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.56      0.57       210\n",
      "           2       0.57      0.45      0.50       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.32      0.38      0.35       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.32      0.37      0.35       210\n",
      "           7       0.63      0.58      0.60       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.51      1470\n",
      "weighted avg       0.52      0.50      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.48775510204081635\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113   4   4  35  26  20   8]\n",
      " [  7  92   8  40  39  19   5]\n",
      " [  5   5 166  21   9   4   0]\n",
      " [  9  24  11  78  43  30  15]\n",
      " [ 30  19   3  44  81  24   9]\n",
      " [ 17  23  10  46  10  73  31]\n",
      " [  7   4   1   7  10  67 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.54      0.57       210\n",
      "           2       0.54      0.44      0.48       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.29      0.37      0.32       210\n",
      "           5       0.37      0.39      0.38       210\n",
      "           6       0.31      0.35      0.33       210\n",
      "           7       0.63      0.54      0.58       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.51      0.49      0.50      1470\n",
      "weighted avg       0.51      0.49      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   3   2  12  28  27   8]\n",
      " [ 15  83   8  31  45  20   8]\n",
      " [  2   5 160  28   7   8   0]\n",
      " [ 15  25  13  76  38  31  12]\n",
      " [ 39  18   4  34  84  20  11]\n",
      " [ 21  18  11  36  15  79  30]\n",
      " [ 10   2   0   8   8  59 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.62      0.59       210\n",
      "           2       0.54      0.40      0.46       210\n",
      "           3       0.81      0.76      0.78       210\n",
      "           4       0.34      0.36      0.35       210\n",
      "           5       0.37      0.40      0.39       210\n",
      "           6       0.32      0.38      0.35       210\n",
      "           7       0.64      0.59      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.51      0.50      0.50      1470\n",
      "weighted avg       0.51      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4897959183673469\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[129   6   4  20  24  19   8]\n",
      " [ 16  93  13  31  37  14   6]\n",
      " [  5   8 171  17   6   3   0]\n",
      " [ 26  36  16  61  35  28   8]\n",
      " [ 34  26   2  44  79  17   8]\n",
      " [ 22  22   6  38  15  71  36]\n",
      " [ 13   2   0   8  10  61 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.61      0.57       210\n",
      "           2       0.48      0.44      0.46       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.28      0.29      0.28       210\n",
      "           5       0.38      0.38      0.38       210\n",
      "           6       0.33      0.34      0.34       210\n",
      "           7       0.64      0.55      0.59       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49727891156462584\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   5   3  15  30  21   8]\n",
      " [ 24  90   9  28  32  17  10]\n",
      " [  4  10 170  16   3   7   0]\n",
      " [ 16  25  13  78  28  37  13]\n",
      " [ 41  23   5  39  70  19  13]\n",
      " [ 22  19   5  49  13  70  32]\n",
      " [ 15   1   1   8   6  54 125]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.61      0.56       210\n",
      "           2       0.52      0.43      0.47       210\n",
      "           3       0.83      0.81      0.82       210\n",
      "           4       0.33      0.37      0.35       210\n",
      "           5       0.38      0.33      0.36       210\n",
      "           6       0.31      0.33      0.32       210\n",
      "           7       0.62      0.60      0.61       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.482312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[127   6   3  16  26  24   8]\n",
      " [ 29  76  10  34  42  12   7]\n",
      " [  4   9 166  19   5   7   0]\n",
      " [ 22  27  14  76  31  31   9]\n",
      " [ 37  30   5  36  71  18  13]\n",
      " [ 25  20   9  38  11  75  32]\n",
      " [ 13   4   3   9   7  56 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.60      0.54       210\n",
      "           2       0.44      0.36      0.40       210\n",
      "           3       0.79      0.79      0.79       210\n",
      "           4       0.33      0.36      0.35       210\n",
      "           5       0.37      0.34      0.35       210\n",
      "           6       0.34      0.36      0.35       210\n",
      "           7       0.63      0.56      0.59       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.49      0.48      0.48      1470\n",
      "weighted avg       0.49      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4993197278911565\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   4   3  22  28  21   7]\n",
      " [ 19  87  13  25  44  14   8]\n",
      " [  3   9 171  13   6   8   0]\n",
      " [ 19  27  16  81  28  26  13]\n",
      " [ 35  25   8  39  71  17  15]\n",
      " [ 25  19  10  37  13  71  35]\n",
      " [ 13   3   1   5  10  50 128]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.60      0.56       210\n",
      "           2       0.50      0.41      0.45       210\n",
      "           3       0.77      0.81      0.79       210\n",
      "           4       0.36      0.39      0.38       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.62      0.61      0.62       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.50      1470\n",
      "weighted avg       0.50      0.50      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.49115646258503404\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[133   4   3  14  30  19   7]\n",
      " [ 21  82  12  36  37  17   5]\n",
      " [  5   9 168  19   4   5   0]\n",
      " [ 16  34  17  73  26  30  14]\n",
      " [ 38  24   9  36  74  19  10]\n",
      " [ 25  17   8  42  21  69  28]\n",
      " [ 10   4   1   8   6  58 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.63      0.58       210\n",
      "           2       0.47      0.39      0.43       210\n",
      "           3       0.77      0.80      0.79       210\n",
      "           4       0.32      0.35      0.33       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.32      0.33      0.32       210\n",
      "           7       0.66      0.59      0.62       210\n",
      "\n",
      "    accuracy                           0.49      1470\n",
      "   macro avg       0.49      0.49      0.49      1470\n",
      "weighted avg       0.49      0.49      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   9   6  16  28  22   9]\n",
      " [ 25  87   7  28  38  18   7]\n",
      " [  4   7 147  39   4   9   0]\n",
      " [ 21  28  15  80  30  26  10]\n",
      " [ 34  27   6  47  69  16  11]\n",
      " [ 22  21   4  39  19  72  33]\n",
      " [  9   1   1   5  11  63 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.57      0.54       210\n",
      "           2       0.48      0.41      0.45       210\n",
      "           3       0.79      0.70      0.74       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.35      0.33      0.34       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.63      0.57      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.48      1470\n",
      "weighted avg       0.49      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   9   6  16  28  22   9]\n",
      " [ 25  87   7  28  38  18   7]\n",
      " [  4   7 147  39   4   9   0]\n",
      " [ 21  28  15  80  30  26  10]\n",
      " [ 34  27   6  47  69  16  11]\n",
      " [ 22  21   4  39  19  72  33]\n",
      " [  9   1   1   5  11  63 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.57      0.54       210\n",
      "           2       0.48      0.41      0.45       210\n",
      "           3       0.79      0.70      0.74       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.35      0.33      0.34       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.63      0.57      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.48      1470\n",
      "weighted avg       0.49      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.47278911564625853\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[120   9   6  16  28  22   9]\n",
      " [ 25  87   7  28  38  18   7]\n",
      " [  4   7 147  39   4   9   0]\n",
      " [ 21  28  15  80  30  26  10]\n",
      " [ 34  27   6  47  69  16  11]\n",
      " [ 22  21   4  39  19  72  33]\n",
      " [  9   1   1   5  11  63 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.57      0.54       210\n",
      "           2       0.48      0.41      0.45       210\n",
      "           3       0.79      0.70      0.74       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.35      0.33      0.34       210\n",
      "           6       0.32      0.34      0.33       210\n",
      "           7       0.63      0.57      0.60       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.49      0.47      0.48      1470\n",
      "weighted avg       0.49      0.47      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 62   2  46   0  49   0  51]\n",
      " [  0  49 101   0  40   0  20]\n",
      " [  1   3 193   0   4   0   9]\n",
      " [  6  11  54   4  78   0  57]\n",
      " [  5  15  21   0 123   0  46]\n",
      " [  2   4  34   0  14   1 155]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.30      0.43       210\n",
      "           2       0.58      0.23      0.33       210\n",
      "           3       0.43      0.92      0.58       210\n",
      "           4       1.00      0.02      0.04       210\n",
      "           5       0.40      0.59      0.47       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.38      1.00      0.55       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.66      0.44      0.35      1470\n",
      "weighted avg       0.66      0.44      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96   5  18   0  53   4  34]\n",
      " [  1 111  40   0  36   2  20]\n",
      " [  1   5 181   1   7   9   6]\n",
      " [ 10  22  34   3  88   4  49]\n",
      " [  8  32   2   0 131   1  36]\n",
      " [  3   6  21   1  21  12 146]\n",
      " [  0   1   0   0   1   0 208]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.46      0.58       210\n",
      "           2       0.61      0.53      0.57       210\n",
      "           3       0.61      0.86      0.72       210\n",
      "           4       0.60      0.01      0.03       210\n",
      "           5       0.39      0.62      0.48       210\n",
      "           6       0.38      0.06      0.10       210\n",
      "           7       0.42      0.99      0.59       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.54      0.50      0.44      1470\n",
      "weighted avg       0.54      0.50      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5761904761904761\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   7   0   0  32  13  20]\n",
      " [  2 142  11   1  33   9  12]\n",
      " [  1   8 177   3   6  14   1]\n",
      " [ 18  26  21  23  78  10  34]\n",
      " [ 25  35   1   0 125   2  22]\n",
      " [ 12  17  11   4  12  39 115]\n",
      " [  0   2   0   0   2   3 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.66      0.68       210\n",
      "           2       0.60      0.68      0.64       210\n",
      "           3       0.80      0.84      0.82       210\n",
      "           4       0.74      0.11      0.19       210\n",
      "           5       0.43      0.60      0.50       210\n",
      "           6       0.43      0.19      0.26       210\n",
      "           7       0.50      0.97      0.66       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.60      0.58      0.54      1470\n",
      "weighted avg       0.60      0.58      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.610204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   0   2  40  16  14]\n",
      " [  2 144   8   2  34  14   6]\n",
      " [  0   8 172   9   6  15   0]\n",
      " [ 11  23  12  44  76  19  25]\n",
      " [ 22  22   1   5 137   5  18]\n",
      " [ 10  10   7  20   9  67  87]\n",
      " [  0   2   0   0   2   9 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.65      0.70       210\n",
      "           2       0.68      0.69      0.68       210\n",
      "           3       0.86      0.82      0.84       210\n",
      "           4       0.54      0.21      0.30       210\n",
      "           5       0.45      0.65      0.53       210\n",
      "           6       0.46      0.32      0.38       210\n",
      "           7       0.57      0.94      0.71       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.59      1470\n",
      "weighted avg       0.62      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   0   5  45  22  10]\n",
      " [  2 143   6   8  30  17   4]\n",
      " [  0   8 178  13   3   8   0]\n",
      " [  4  21   6  80  56  26  17]\n",
      " [ 16  21   1  10 137   7  18]\n",
      " [  8  10   5  21   9  89  68]\n",
      " [  0   1   0   1   2  28 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.60      0.69       210\n",
      "           2       0.70      0.68      0.69       210\n",
      "           3       0.91      0.85      0.88       210\n",
      "           4       0.58      0.38      0.46       210\n",
      "           5       0.49      0.65      0.56       210\n",
      "           6       0.45      0.42      0.44       210\n",
      "           7       0.60      0.85      0.70       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.65      0.63      0.63      1470\n",
      "weighted avg       0.65      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   1   0   7  41  25   9]\n",
      " [  1 147   3   9  31  16   3]\n",
      " [  0   7 174  13   3  13   0]\n",
      " [  2  16   7  81  59  29  16]\n",
      " [ 17  17   1  12 138   6  19]\n",
      " [  6   7   2  27  10  93  65]\n",
      " [  0   1   0   1   2  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.70       210\n",
      "           2       0.75      0.70      0.72       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.54      0.39      0.45       210\n",
      "           5       0.49      0.66      0.56       210\n",
      "           6       0.46      0.44      0.45       210\n",
      "           7       0.62      0.89      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.64      1470\n",
      "weighted avg       0.66      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   1   0   5  35  25   6]\n",
      " [  2 138   3  14  34  16   3]\n",
      " [  0   7 179  12   3   9   0]\n",
      " [  5   9   5  95  52  29  15]\n",
      " [ 17  16   1  13 137  11  15]\n",
      " [  8   4   2  27   9 104  56]\n",
      " [  0   1   0   1   2  28 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.66      0.73       210\n",
      "           2       0.78      0.66      0.72       210\n",
      "           3       0.94      0.85      0.89       210\n",
      "           4       0.57      0.45      0.50       210\n",
      "           5       0.50      0.65      0.57       210\n",
      "           6       0.47      0.50      0.48       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   1   0   7  32  25   7]\n",
      " [  3 143   6  15  25  16   2]\n",
      " [  0   6 182  12   3   7   0]\n",
      " [  3  12   4 114  37  29  11]\n",
      " [ 18  14   1  18 136   9  14]\n",
      " [ 10   7   1  25   7 101  59]\n",
      " [  0   1   0   1   2  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.72       210\n",
      "           2       0.78      0.68      0.73       210\n",
      "           3       0.94      0.87      0.90       210\n",
      "           4       0.59      0.54      0.57       210\n",
      "           5       0.56      0.65      0.60       210\n",
      "           6       0.47      0.48      0.47       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   1   7  35  21   6]\n",
      " [  1 146   5  14  25  17   2]\n",
      " [  0   6 184  13   2   5   0]\n",
      " [  6   8   2 111  41  35   7]\n",
      " [ 19  16   1  18 135   9  12]\n",
      " [  9  10   0  27   4 109  51]\n",
      " [  0   0   0   0   3  32 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.66      0.72       210\n",
      "           2       0.78      0.70      0.73       210\n",
      "           3       0.95      0.88      0.91       210\n",
      "           4       0.58      0.53      0.55       210\n",
      "           5       0.55      0.64      0.59       210\n",
      "           6       0.48      0.52      0.50       210\n",
      "           7       0.69      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   1   0   9  32  21   6]\n",
      " [  2 145   5  20  23  12   3]\n",
      " [  0   7 177  15   4   7   0]\n",
      " [  5   7   4 118  38  26  12]\n",
      " [ 18  16   1  18 136   8  13]\n",
      " [ 10   5   3  25   4 113  50]\n",
      " [  0   0   0   0   3  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       210\n",
      "           2       0.80      0.69      0.74       210\n",
      "           3       0.93      0.84      0.88       210\n",
      "           4       0.58      0.56      0.57       210\n",
      "           5       0.57      0.65      0.60       210\n",
      "           6       0.54      0.54      0.54       210\n",
      "           7       0.69      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6877551020408164\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   2   1   6  36  23   3]\n",
      " [  1 145   6  19  22  15   2]\n",
      " [  0   6 184  12   3   5   0]\n",
      " [  6   7   4 120  35  25  13]\n",
      " [ 23  12   1  22 133   9  10]\n",
      " [  8   7   1  22   6 109  57]\n",
      " [  0   1   0   0   2  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.81      0.69      0.74       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.60      0.57      0.58       210\n",
      "           5       0.56      0.63      0.60       210\n",
      "           6       0.51      0.52      0.52       210\n",
      "           7       0.68      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6931972789115646\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   4   2   5  32  19   6]\n",
      " [  2 144   7  18  23  13   3]\n",
      " [  0   4 186  11   3   6   0]\n",
      " [  6   8   4 118  33  31  10]\n",
      " [ 21  15   1  16 135  11  11]\n",
      " [ 13   7   2  22   3 117  46]\n",
      " [  0   0   0   1   2  30 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.68      0.72       210\n",
      "           2       0.79      0.69      0.73       210\n",
      "           3       0.92      0.89      0.90       210\n",
      "           4       0.62      0.56      0.59       210\n",
      "           5       0.58      0.64      0.61       210\n",
      "           6       0.52      0.56      0.54       210\n",
      "           7       0.70      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   0   6  33  20   8]\n",
      " [  3 143   3  25  20  13   3]\n",
      " [  0   6 181  11   3   9   0]\n",
      " [  4  10   4 120  33  26  13]\n",
      " [ 21  14   1  24 129   7  14]\n",
      " [ 11   5   2  23   3 118  48]\n",
      " [  0   0   0   1   2  34 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.67      0.72       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.57      0.57      0.57       210\n",
      "           5       0.58      0.61      0.60       210\n",
      "           6       0.52      0.56      0.54       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.69      1470\n",
      "weighted avg       0.69      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6843537414965987\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   1   0   7  35  21   6]\n",
      " [  3 140   7  20  27  11   2]\n",
      " [  0   4 186  12   3   5   0]\n",
      " [  5   7   5 119  34  24  16]\n",
      " [ 21  14   1  22 132   9  11]\n",
      " [  9   8   3  22   4 112  52]\n",
      " [  0   0   0   0   4  29 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.67      0.72       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.92      0.89      0.90       210\n",
      "           4       0.59      0.57      0.58       210\n",
      "           5       0.55      0.63      0.59       210\n",
      "           6       0.53      0.53      0.53       210\n",
      "           7       0.67      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.69      1470\n",
      "weighted avg       0.69      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   1   1   6  32  22   3]\n",
      " [  3 144   5  20  22  15   1]\n",
      " [  0   5 185  14   2   3   1]\n",
      " [  6   8   5 121  32  33   5]\n",
      " [ 20   9   1  22 136   9  13]\n",
      " [ 10   9   1  26   1 117  46]\n",
      " [  0   0   0   0   2  34 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.69      0.74       210\n",
      "           2       0.82      0.69      0.75       210\n",
      "           3       0.93      0.88      0.91       210\n",
      "           4       0.58      0.58      0.58       210\n",
      "           5       0.60      0.65      0.62       210\n",
      "           6       0.50      0.56      0.53       210\n",
      "           7       0.72      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6986394557823129\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   2   1   4  31  23   5]\n",
      " [  1 144   6  16  27  13   3]\n",
      " [  0   6 186  10   2   6   0]\n",
      " [  6   6   4 124  33  27  10]\n",
      " [ 20  14   1  24 131   8  12]\n",
      " [ 11   6   2  27   4 117  43]\n",
      " [  0   1   0   1   1  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.69      0.73       210\n",
      "           2       0.80      0.69      0.74       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.60      0.59      0.60       210\n",
      "           5       0.57      0.62      0.60       210\n",
      "           6       0.53      0.56      0.54       210\n",
      "           7       0.71      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6863945578231293\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   3   1   6  27  22   6]\n",
      " [  1 145   6  19  20  17   2]\n",
      " [  0   6 181  15   3   5   0]\n",
      " [  8  10   4 119  36  25   8]\n",
      " [ 22  20   1  25 121   9  12]\n",
      " [ 10   6   2  25   3 116  48]\n",
      " [  0   0   0   0   2  26 182]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.69      0.73       210\n",
      "           2       0.76      0.69      0.72       210\n",
      "           3       0.93      0.86      0.89       210\n",
      "           4       0.57      0.57      0.57       210\n",
      "           5       0.57      0.58      0.57       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.71      0.87      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.69      0.69      0.69      1470\n",
      "weighted avg       0.69      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6959183673469388\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   3   0   5  27  22   4]\n",
      " [  2 150   3  16  22  15   2]\n",
      " [  0   7 183  15   2   3   0]\n",
      " [  4   8   6 124  33  28   7]\n",
      " [ 26  16   1  24 120   9  14]\n",
      " [ 10  10   2  23   5 117  43]\n",
      " [  0   0   0   0   2  28 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.74       210\n",
      "           2       0.77      0.71      0.74       210\n",
      "           3       0.94      0.87      0.90       210\n",
      "           4       0.60      0.59      0.59       210\n",
      "           5       0.57      0.57      0.57       210\n",
      "           6       0.53      0.56      0.54       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.70      0.70      0.70      1470\n",
      "weighted avg       0.70      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6938775510204082\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   1   1   5  33  24   4]\n",
      " [  4 153   6  15  19  11   2]\n",
      " [  0   6 183  13   3   5   0]\n",
      " [  4  12   3 127  29  26   9]\n",
      " [ 26  16   1  27 119   8  13]\n",
      " [ 14   8   4  20   5 115  44]\n",
      " [  0   0   0   0   2  27 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.68      0.71       210\n",
      "           2       0.78      0.73      0.75       210\n",
      "           3       0.92      0.87      0.90       210\n",
      "           4       0.61      0.60      0.61       210\n",
      "           5       0.57      0.57      0.57       210\n",
      "           6       0.53      0.55      0.54       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   4   0   4  31  21   5]\n",
      " [  2 146   7  20  20  13   2]\n",
      " [  0   7 181  13   4   5   0]\n",
      " [  5  14   4 120  31  28   8]\n",
      " [ 26  19   1  23 119   9  13]\n",
      " [ 11  12   2  20   5 109  51]\n",
      " [  0   1   0   0   2  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.69      0.73       210\n",
      "           2       0.72      0.70      0.71       210\n",
      "           3       0.93      0.86      0.89       210\n",
      "           4       0.60      0.57      0.59       210\n",
      "           5       0.56      0.57      0.56       210\n",
      "           6       0.51      0.52      0.52       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5421768707482993\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 98   2  37   3  35  26   9]\n",
      " [  0  97  40  11  34  25   3]\n",
      " [  1   2 179   8   3  17   0]\n",
      " [  7  12  32  48  66  33  12]\n",
      " [ 21  15   7   9 131  12  15]\n",
      " [  8   7  17  12   9  93  64]\n",
      " [  0   0   0   1   3  55 151]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57       210\n",
      "           2       0.72      0.46      0.56       210\n",
      "           3       0.57      0.85      0.69       210\n",
      "           4       0.52      0.23      0.32       210\n",
      "           5       0.47      0.62      0.53       210\n",
      "           6       0.36      0.44      0.39       210\n",
      "           7       0.59      0.72      0.65       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.53      1470\n",
      "weighted avg       0.57      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ab723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 61   1   0  71  62  15   0]\n",
      " [  1  21   0 135  35  18   0]\n",
      " [  0   1   1 194   1  13   0]\n",
      " [  1   0   0 168  21  19   1]\n",
      " [  2   1   0 100 101   6   0]\n",
      " [  2   2   0  90  27  88   1]\n",
      " [  1   3   0  26  33 139   8]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.29      0.44       210\n",
      "           2       0.72      0.10      0.18       210\n",
      "           3       1.00      0.00      0.01       210\n",
      "           4       0.21      0.80      0.34       210\n",
      "           5       0.36      0.48      0.41       210\n",
      "           6       0.30      0.42      0.35       210\n",
      "           7       0.80      0.04      0.07       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.61      0.30      0.26      1470\n",
      "weighted avg       0.61      0.30      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136  18  10  17  17   6   6]\n",
      " [ 33  86  37  24  10  12   8]\n",
      " [ 25  10 165   5   1   4   0]\n",
      " [ 46  41  26  51  21  14  11]\n",
      " [ 56  54  14  32  40   4  10]\n",
      " [ 41  41  12  23  16  40  37]\n",
      " [ 20  20   1  17  12  34 106]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.65      0.48       210\n",
      "           2       0.32      0.41      0.36       210\n",
      "           3       0.62      0.79      0.69       210\n",
      "           4       0.30      0.24      0.27       210\n",
      "           5       0.34      0.19      0.24       210\n",
      "           6       0.35      0.19      0.25       210\n",
      "           7       0.60      0.50      0.55       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.41      1470\n",
      "weighted avg       0.42      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4340136054421769\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128  18   5  22  19  10   8]\n",
      " [ 27  83  38  26  12  16   8]\n",
      " [  8   8 175  11   2   4   2]\n",
      " [ 37  38  29  52  24  19  11]\n",
      " [ 45  39  14  44  49   9  10]\n",
      " [ 32  37  12  24   7  51  47]\n",
      " [ 17  15   0  10  10  58 100]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.61      0.51       210\n",
      "           2       0.35      0.40      0.37       210\n",
      "           3       0.64      0.83      0.72       210\n",
      "           4       0.28      0.25      0.26       210\n",
      "           5       0.40      0.23      0.29       210\n",
      "           6       0.31      0.24      0.27       210\n",
      "           7       0.54      0.48      0.51       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.42      0.43      0.42      1470\n",
      "weighted avg       0.42      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126  19   5  26  17  10   7]\n",
      " [ 29  69  44  30  12  17   9]\n",
      " [  6   6 178  13   0   6   1]\n",
      " [ 35  36  30  55  23  17  14]\n",
      " [ 43  41  14  51  40  11  10]\n",
      " [ 28  37  10  27   7  55  46]\n",
      " [ 14  15   1   6   9  53 112]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.60      0.51       210\n",
      "           2       0.31      0.33      0.32       210\n",
      "           3       0.63      0.85      0.72       210\n",
      "           4       0.26      0.26      0.26       210\n",
      "           5       0.37      0.19      0.25       210\n",
      "           6       0.33      0.26      0.29       210\n",
      "           7       0.56      0.53      0.55       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.42      0.43      0.42      1470\n",
      "weighted avg       0.42      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4340136054421769\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[125  22   5  26  17   9   6]\n",
      " [ 30  74  41  29  12  15   9]\n",
      " [  9   8 176  11   0   5   1]\n",
      " [ 38  43  25  59  16  15  14]\n",
      " [ 43  43  14  52  39   9  10]\n",
      " [ 27  38  10  25   8  60  42]\n",
      " [ 13  15   1   7   7  62 105]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.60      0.51       210\n",
      "           2       0.30      0.35      0.33       210\n",
      "           3       0.65      0.84      0.73       210\n",
      "           4       0.28      0.28      0.28       210\n",
      "           5       0.39      0.19      0.25       210\n",
      "           6       0.34      0.29      0.31       210\n",
      "           7       0.56      0.50      0.53       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.42      0.43      0.42      1470\n",
      "weighted avg       0.42      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.43945578231292515\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[130  21   5  23  14   8   9]\n",
      " [ 30  78  40  32   9  13   8]\n",
      " [  8   7 173  13   1   7   1]\n",
      " [ 34  43  28  61  16  11  17]\n",
      " [ 43  39  15  57  42   7   7]\n",
      " [ 30  35  11  22  15  53  44]\n",
      " [ 10  18   2   7   7  57 109]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.62      0.53       210\n",
      "           2       0.32      0.37      0.35       210\n",
      "           3       0.63      0.82      0.71       210\n",
      "           4       0.28      0.29      0.29       210\n",
      "           5       0.40      0.20      0.27       210\n",
      "           6       0.34      0.25      0.29       210\n",
      "           7       0.56      0.52      0.54       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.43      0.44      0.42      1470\n",
      "weighted avg       0.43      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.43537414965986393\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[126  20   7  26  13  10   8]\n",
      " [ 28  76  40  29  11  16  10]\n",
      " [  8   8 172  13   1   7   1]\n",
      " [ 31  39  24  64  22  14  16]\n",
      " [ 36  38  15  64  41   7   9]\n",
      " [ 28  34  11  25  14  55  43]\n",
      " [ 10  16   3   7   9  59 106]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.60      0.53       210\n",
      "           2       0.33      0.36      0.34       210\n",
      "           3       0.63      0.82      0.71       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.37      0.20      0.26       210\n",
      "           6       0.33      0.26      0.29       210\n",
      "           7       0.55      0.50      0.53       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.42      0.44      0.42      1470\n",
      "weighted avg       0.42      0.44      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.2761904761904762\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 44   0   0  96   0   9  61]\n",
      " [ 16   0   0 138   0   2  54]\n",
      " [  5   0   6 177   0   0  22]\n",
      " [ 10   0   1 160   0   1  38]\n",
      " [ 17   0   0 171   0   1  21]\n",
      " [ 14   0   4  66   0   6 120]\n",
      " [  6   0   0  13   0   1 190]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.21      0.27       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.55      0.03      0.05       210\n",
      "           4       0.19      0.76      0.31       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.30      0.03      0.05       210\n",
      "           7       0.38      0.90      0.53       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.26      0.28      0.17      1470\n",
      "weighted avg       0.26      0.28      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.18979591836734694\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 22   6   5   3 161   7   6]\n",
      " [  4   2   2   7 178  16   1]\n",
      " [  0   0   7   2 197   3   1]\n",
      " [  1   7   3   5 189   3   2]\n",
      " [  5   1   3   5 188   2   6]\n",
      " [  9   7   6  10 134  23  21]\n",
      " [  2   6   1   5 146  18  32]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.10      0.17       210\n",
      "           2       0.07      0.01      0.02       210\n",
      "           3       0.26      0.03      0.06       210\n",
      "           4       0.14      0.02      0.04       210\n",
      "           5       0.16      0.90      0.27       210\n",
      "           6       0.32      0.11      0.16       210\n",
      "           7       0.46      0.15      0.23       210\n",
      "\n",
      "    accuracy                           0.19      1470\n",
      "   macro avg       0.27      0.19      0.14      1470\n",
      "weighted avg       0.27      0.19      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.2646258503401361\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 81   5   0  25  98   1   0]\n",
      " [  5  31   0  71 100   3   0]\n",
      " [  1   6   0 161  37   5   0]\n",
      " [  3   5   0  83 112   7   0]\n",
      " [  5   1   0  31 170   2   1]\n",
      " [  5  19   0 119  47  18   2]\n",
      " [  1  17   1  71  45  69   6]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.39      0.52       210\n",
      "           2       0.37      0.15      0.21       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.15      0.40      0.22       210\n",
      "           5       0.28      0.81      0.42       210\n",
      "           6       0.17      0.09      0.11       210\n",
      "           7       0.67      0.03      0.05       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.35      0.26      0.22      1470\n",
      "weighted avg       0.35      0.26      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.4782312925170068\n",
      "Confusion Matrix of SVM is:\n",
      " [[118   7   0  45  26   8   6]\n",
      " [  6  55  11  92  27  13   6]\n",
      " [  5   5 125  61   4   3   7]\n",
      " [ 11  11   5 103  52   9  19]\n",
      " [ 21   4   0  72  98   5  10]\n",
      " [  7  23   7  44  19  44  66]\n",
      " [  6   9   0  10   5  20 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.56      0.61       210\n",
      "           2       0.48      0.26      0.34       210\n",
      "           3       0.84      0.60      0.70       210\n",
      "           4       0.24      0.49      0.32       210\n",
      "           5       0.42      0.47      0.44       210\n",
      "           6       0.43      0.21      0.28       210\n",
      "           7       0.58      0.76      0.66       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.53      0.48      0.48      1470\n",
      "weighted avg       0.53      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.345578231292517\n",
      "Confusion Matrix of SVM is:\n",
      " [[111   0  48  25   0   9  17]\n",
      " [ 24   4 116  16   0  19  31]\n",
      " [ 10   0 186   4   0   4   6]\n",
      " [ 18   0 136  19   0   8  29]\n",
      " [ 30   1 139  23   0   3  14]\n",
      " [ 30   1  47  17   0  21  94]\n",
      " [ 21   0   6   5   0  11 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.53      0.49       210\n",
      "           2       0.67      0.02      0.04       210\n",
      "           3       0.27      0.89      0.42       210\n",
      "           4       0.17      0.09      0.12       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.28      0.10      0.15       210\n",
      "           7       0.47      0.80      0.59       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.33      0.35      0.26      1470\n",
      "weighted avg       0.33      0.35      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.26598639455782314\n",
      "Confusion Matrix of SVM is:\n",
      " [[  0  21  83  57   3   0  46]\n",
      " [  0   4 119  34   3   0  50]\n",
      " [  0   0 184  10   0   0  16]\n",
      " [  0   1 141  39   0   0  29]\n",
      " [  0   5 146  43   1   0  15]\n",
      " [  0  11  73  33   3   0  90]\n",
      " [  0   6  28  12   1   0 163]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.08      0.02      0.03       210\n",
      "           3       0.24      0.88      0.37       210\n",
      "           4       0.17      0.19      0.18       210\n",
      "           5       0.09      0.00      0.01       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.78      0.53       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.14      0.27      0.16      1470\n",
      "weighted avg       0.14      0.27      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.22380952380952382\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3   0   0   0 207]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0 119   0   0   0  91]\n",
      " [  0   0   6   0   0   0 204]\n",
      " [  0   0   9   0   0   0 201]\n",
      " [  0   0  10   0   0   0 200]\n",
      " [  0   0   0   0   0   0 210]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.71      0.57      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      1.00      0.28       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.12      0.22      0.13      1470\n",
      "weighted avg       0.12      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   3 159   0   0  48]\n",
      " [  0   0  20 139   0   0  51]\n",
      " [  0   0 119  69   0   0  22]\n",
      " [  0   0   6 167   0   0  37]\n",
      " [  0   0   9 182   0   0  19]\n",
      " [  0   0  10  80   0   0 120]\n",
      " [  0   0   0  23   0   0 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.71      0.57      0.63       210\n",
      "           4       0.20      0.80      0.32       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.89      0.54       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.19      0.32      0.21      1470\n",
      "weighted avg       0.19      0.32      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57   3   0 116   0   0  34]\n",
      " [ 12  18   2 128   0   0  50]\n",
      " [  4  55  64  65   0   0  22]\n",
      " [  2   4   2 165   0   0  37]\n",
      " [  2   8   1 180   0   0  19]\n",
      " [ 11   8   2  69   0   0 120]\n",
      " [  5   0   0  18   0   0 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.27      0.38       210\n",
      "           2       0.19      0.09      0.12       210\n",
      "           3       0.90      0.30      0.46       210\n",
      "           4       0.22      0.79      0.35       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.89      0.55       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.33      0.33      0.26      1470\n",
      "weighted avg       0.33      0.33      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 51  19   0 100   0   6  34]\n",
      " [  8  25   2 121   0   4  50]\n",
      " [  4  57  64  63   0   0  22]\n",
      " [  2  10   2 159   0   0  37]\n",
      " [  2  19   1 169   0   0  19]\n",
      " [  6  15   3  62   0   5 119]\n",
      " [  1   5   0  13   0   4 187]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.24      0.36       210\n",
      "           2       0.17      0.12      0.14       210\n",
      "           3       0.89      0.30      0.45       210\n",
      "           4       0.23      0.76      0.35       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.26      0.02      0.04       210\n",
      "           7       0.40      0.89      0.55       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.38      0.33      0.27      1470\n",
      "weighted avg       0.38      0.33      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.33945578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55  34   0  80  30   4   7]\n",
      " [ 10  66   2  83  42   2   5]\n",
      " [  4  69  64  50  14   0   9]\n",
      " [  2  22   2  77  87   0  20]\n",
      " [  3  18   1  65 112   2   9]\n",
      " [  8  66   2  41  26   5  62]\n",
      " [  1  68   0  11   6   4 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.26      0.38       210\n",
      "           2       0.19      0.31      0.24       210\n",
      "           3       0.90      0.30      0.46       210\n",
      "           4       0.19      0.37      0.25       210\n",
      "           5       0.35      0.53      0.43       210\n",
      "           6       0.29      0.02      0.04       210\n",
      "           7       0.52      0.57      0.54       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.44      0.34      0.33      1470\n",
      "weighted avg       0.44      0.34      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54  36   4  96  10   1   9]\n",
      " [  8  66  15 108   4   4   5]\n",
      " [  3  60  91  45   1   1   9]\n",
      " [  2  22   7 154   5   3  17]\n",
      " [  2  21   2 167   9   2   7]\n",
      " [  7  67   4  60   5  16  51]\n",
      " [  1  68   0  13   4  25  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.26      0.38       210\n",
      "           2       0.19      0.31      0.24       210\n",
      "           3       0.74      0.43      0.55       210\n",
      "           4       0.24      0.73      0.36       210\n",
      "           5       0.24      0.04      0.07       210\n",
      "           6       0.31      0.08      0.12       210\n",
      "           7       0.50      0.47      0.49       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.42      0.33      0.32      1470\n",
      "weighted avg       0.42      0.33      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  16   6  57  18  25   8]\n",
      " [ 25  21  18  76  25  40   5]\n",
      " [  9   8  92  42   1  48  10]\n",
      " [ 20  11   8  84  53  16  18]\n",
      " [ 20  15   3  70  82  12   8]\n",
      " [ 18  26   6  43  12  49  56]\n",
      " [  8  26   0   9   1  55 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.38      0.41       210\n",
      "           2       0.17      0.10      0.13       210\n",
      "           3       0.69      0.44      0.54       210\n",
      "           4       0.22      0.40      0.28       210\n",
      "           5       0.43      0.39      0.41       210\n",
      "           6       0.20      0.23      0.22       210\n",
      "           7       0.51      0.53      0.52       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.38      0.35      0.36      1470\n",
      "weighted avg       0.38      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.31768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  33   2  66  12   8   8]\n",
      " [ 41  45  12  64  22  21   5]\n",
      " [ 10  15  89  31  12  45   8]\n",
      " [ 50  18   7  60  52   5  18]\n",
      " [ 67  19   3  52  58   3   8]\n",
      " [ 24  51   4  39  13  23  56]\n",
      " [  8  63   1  11   2  14 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.39      0.33       210\n",
      "           2       0.18      0.21      0.20       210\n",
      "           3       0.75      0.42      0.54       210\n",
      "           4       0.19      0.29      0.23       210\n",
      "           5       0.34      0.28      0.30       210\n",
      "           6       0.19      0.11      0.14       210\n",
      "           7       0.52      0.53      0.52       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.35      0.32      0.32      1470\n",
      "weighted avg       0.35      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.30680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 52  26   5  40  16  63   8]\n",
      " [ 21  35  25  24  10  90   5]\n",
      " [  8  20  93   4   0  77   8]\n",
      " [  9  37   7  48  24  67  18]\n",
      " [  6  35   2  68  35  56   8]\n",
      " [  9  34  13  16   8  78  52]\n",
      " [  2  28   2   6   2  60 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.25      0.33       210\n",
      "           2       0.16      0.17      0.16       210\n",
      "           3       0.63      0.44      0.52       210\n",
      "           4       0.23      0.23      0.23       210\n",
      "           5       0.37      0.17      0.23       210\n",
      "           6       0.16      0.37      0.22       210\n",
      "           7       0.53      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.37      0.31      0.32      1470\n",
      "weighted avg       0.37      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.29863945578231293\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 50  18   6  40  13  77   6]\n",
      " [ 20  17  22  28  15 103   5]\n",
      " [  8   8  93   2  12  79   8]\n",
      " [ 10   8  11  59  37  69  16]\n",
      " [ 13  10   3  90  30  58   6]\n",
      " [  8  22   8  20  12  84  56]\n",
      " [  1  23   4   4   5  67 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.24      0.31       210\n",
      "           2       0.16      0.08      0.11       210\n",
      "           3       0.63      0.44      0.52       210\n",
      "           4       0.24      0.28      0.26       210\n",
      "           5       0.24      0.14      0.18       210\n",
      "           6       0.16      0.40      0.22       210\n",
      "           7       0.52      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.34      0.30      0.30      1470\n",
      "weighted avg       0.34      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.291156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 56  15   7  47  14  66   5]\n",
      " [ 40  21  18  27  15  79  10]\n",
      " [ 10   7  94   2  12  82   3]\n",
      " [ 39   6  10  41  37  62  15]\n",
      " [ 44  10   4  64  32  47   9]\n",
      " [ 18  27   9  17  12  70  57]\n",
      " [ 16  25   3   5   8  39 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.27      0.26       210\n",
      "           2       0.19      0.10      0.13       210\n",
      "           3       0.65      0.45      0.53       210\n",
      "           4       0.20      0.20      0.20       210\n",
      "           5       0.25      0.15      0.19       210\n",
      "           6       0.16      0.33      0.21       210\n",
      "           7       0.54      0.54      0.54       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.32      0.29      0.29      1470\n",
      "weighted avg       0.32      0.29      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[55 57 12 51 15 18  2]\n",
      " [24 86 33 35 18  8  6]\n",
      " [ 7 45 94  3 13 44  4]\n",
      " [ 7 63 12 65 36  9 18]\n",
      " [17 50  6 91 35  7  4]\n",
      " [14 67 26 24 15 27 37]\n",
      " [ 7 50 41  8  6 16 82]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.26      0.32       210\n",
      "           2       0.21      0.41      0.27       210\n",
      "           3       0.42      0.45      0.43       210\n",
      "           4       0.23      0.31      0.27       210\n",
      "           5       0.25      0.17      0.20       210\n",
      "           6       0.21      0.13      0.16       210\n",
      "           7       0.54      0.39      0.45       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.33      0.30      0.30      1470\n",
      "weighted avg       0.33      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[39 42 20 32 33 34 10]\n",
      " [21 67 37 28 20 28  9]\n",
      " [ 7 38 99  2 11 49  4]\n",
      " [ 6 50 17 64 34 29 10]\n",
      " [ 5 41  6 91 34 28  5]\n",
      " [12 46 34 22 14 51 31]\n",
      " [12 35 21  8 10 38 86]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.19      0.25       210\n",
      "           2       0.21      0.32      0.25       210\n",
      "           3       0.42      0.47      0.45       210\n",
      "           4       0.26      0.30      0.28       210\n",
      "           5       0.22      0.16      0.19       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.55      0.41      0.47       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.30      1470\n",
      "weighted avg       0.32      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[53 37  8 39 30 36  7]\n",
      " [41 67 23 30 22 21  6]\n",
      " [ 9 41 95  1 14 46  4]\n",
      " [19 48 12 69 33 19 10]\n",
      " [19 36  4 88 39 19  5]\n",
      " [23 42 31 32 15 40 27]\n",
      " [23 37 24 18  3 37 68]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.25      0.27       210\n",
      "           2       0.22      0.32      0.26       210\n",
      "           3       0.48      0.45      0.47       210\n",
      "           4       0.25      0.33      0.28       210\n",
      "           5       0.25      0.19      0.21       210\n",
      "           6       0.18      0.19      0.19       210\n",
      "           7       0.54      0.32      0.40       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.31      0.29      0.30      1470\n",
      "weighted avg       0.31      0.29      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2945578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 57  50   7  39  23  30   4]\n",
      " [ 41  71  20  23  11  40   4]\n",
      " [ 14  35 101   1   7  48   4]\n",
      " [ 23  70  13  51  20  28   5]\n",
      " [ 26  71   3  62  23  21   4]\n",
      " [ 25  49  17  30   6  53  30]\n",
      " [  6  39   8  26   8  46  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.27      0.28       210\n",
      "           2       0.18      0.34      0.24       210\n",
      "           3       0.60      0.48      0.53       210\n",
      "           4       0.22      0.24      0.23       210\n",
      "           5       0.23      0.11      0.15       210\n",
      "           6       0.20      0.25      0.22       210\n",
      "           7       0.60      0.37      0.46       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.33      0.29      0.30      1470\n",
      "weighted avg       0.33      0.29      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2829931972789116\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  37  20  29  19  35   2]\n",
      " [ 51  64  25  23   6  39   2]\n",
      " [  9  35 101   1   2  59   3]\n",
      " [ 38  51  13  53   6  43   6]\n",
      " [ 41  39   8  67  15  37   3]\n",
      " [ 26  48  24  34   8  42  28]\n",
      " [ 19  41  23  24  12  18  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.32      0.29       210\n",
      "           2       0.20      0.30      0.24       210\n",
      "           3       0.47      0.48      0.48       210\n",
      "           4       0.23      0.25      0.24       210\n",
      "           5       0.22      0.07      0.11       210\n",
      "           6       0.15      0.20      0.17       210\n",
      "           7       0.62      0.35      0.45       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.31      0.28      0.28      1470\n",
      "weighted avg       0.31      0.28      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2972789115646258\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[60 49  4 31 23 34  9]\n",
      " [38 89 11 26 16 27  3]\n",
      " [ 8 57 82  1 10 49  3]\n",
      " [18 64  6 70 26 18  8]\n",
      " [28 48  4 83 23 18  6]\n",
      " [22 62 15 29 11 39 32]\n",
      " [19 47 10 28  9 23 74]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.29      0.30       210\n",
      "           2       0.21      0.42      0.28       210\n",
      "           3       0.62      0.39      0.48       210\n",
      "           4       0.26      0.33      0.29       210\n",
      "           5       0.19      0.11      0.14       210\n",
      "           6       0.19      0.19      0.19       210\n",
      "           7       0.55      0.35      0.43       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.33      0.30      0.30      1470\n",
      "weighted avg       0.33      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.28095238095238095\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[59 49 16 22 36 21  7]\n",
      " [41 75 31 19 10 28  6]\n",
      " [ 7 40 99  2  1 57  4]\n",
      " [25 63 11 43 22 34 12]\n",
      " [42 54  6 53 25 25  5]\n",
      " [19 61 19 27 18 41 25]\n",
      " [17 38  7 26 16 35 71]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.28      0.28       210\n",
      "           2       0.20      0.36      0.25       210\n",
      "           3       0.52      0.47      0.50       210\n",
      "           4       0.22      0.20      0.21       210\n",
      "           5       0.20      0.12      0.15       210\n",
      "           6       0.17      0.20      0.18       210\n",
      "           7       0.55      0.34      0.42       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.31      0.28      0.28      1470\n",
      "weighted avg       0.31      0.28      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  47   8  28  16  27  11]\n",
      " [ 36  90  22  29   3  21   9]\n",
      " [ 10  41 100   2   1  52   4]\n",
      " [ 15  72  11  68   5  29  10]\n",
      " [ 30  55   6  88   7  17   7]\n",
      " [ 27  64  18  38   3  35  25]\n",
      " [ 25  53  13  23   3  28  65]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.34       210\n",
      "           2       0.21      0.43      0.28       210\n",
      "           3       0.56      0.48      0.52       210\n",
      "           4       0.25      0.32      0.28       210\n",
      "           5       0.18      0.03      0.06       210\n",
      "           6       0.17      0.17      0.17       210\n",
      "           7       0.50      0.31      0.38       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.29      1470\n",
      "weighted avg       0.32      0.30      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.30680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[66 36  7 29 30 29 13]\n",
      " [36 75 20 28 16 31  4]\n",
      " [ 8 38 96  1 11 53  3]\n",
      " [21 52  9 67 36 18  7]\n",
      " [21 46  3 86 33 18  3]\n",
      " [17 66 10 38 13 45 21]\n",
      " [23 38  3 25  9 43 69]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.31      0.33       210\n",
      "           2       0.21      0.36      0.27       210\n",
      "           3       0.65      0.46      0.54       210\n",
      "           4       0.24      0.32      0.28       210\n",
      "           5       0.22      0.16      0.18       210\n",
      "           6       0.19      0.21      0.20       210\n",
      "           7       0.57      0.33      0.42       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.35      0.31      0.32      1470\n",
      "weighted avg       0.35      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.2857142857142857\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 20   0  67  70   2   0  51]\n",
      " [  3   0 136  17   1   0  53]\n",
      " [  0   0 191   6   0   0  13]\n",
      " [  0   0 150  21   0   0  39]\n",
      " [  0   0 158  30   0   0  22]\n",
      " [  6   0  57  24   1   0 122]\n",
      " [  4   0   7  11   0   0 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.10      0.16       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.25      0.91      0.39       210\n",
      "           4       0.12      0.10      0.11       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.90      0.54       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.19      0.29      0.17      1470\n",
      "weighted avg       0.19      0.29      0.17      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.3115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 47   0  53  59  10   1  40]\n",
      " [  7   0 118  29   5   0  51]\n",
      " [  1   0 189   4   3   0  13]\n",
      " [  2   0 143  22   5   0  38]\n",
      " [  5   0 147  30   9   0  19]\n",
      " [ 12   0  51  22   8   4 113]\n",
      " [  5   0   7   8   3   0 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.22      0.33       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.27      0.90      0.41       210\n",
      "           4       0.13      0.10      0.11       210\n",
      "           5       0.21      0.04      0.07       210\n",
      "           6       0.80      0.02      0.04       210\n",
      "           7       0.41      0.89      0.56       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.34      0.31      0.22      1470\n",
      "weighted avg       0.34      0.31      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.36394557823129253\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   0  34  29   0   3  22]\n",
      " [ 31   0 108  21   0   5  45]\n",
      " [  8   0 180   9   0   1  12]\n",
      " [ 23   0 113  37   0   1  36]\n",
      " [ 36   0 121  35   0   4  14]\n",
      " [ 41   0  37  17   0  11 104]\n",
      " [ 16   0   4   3   0   2 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.58      0.50       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.30      0.86      0.45       210\n",
      "           4       0.25      0.18      0.20       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.41      0.05      0.09       210\n",
      "           7       0.44      0.88      0.59       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.26      0.36      0.26      1470\n",
      "weighted avg       0.26      0.36      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[123   5  12  45   1  10  14]\n",
      " [ 31  10  69  50   0  22  28]\n",
      " [  8   5 169  15   0   5   8]\n",
      " [ 22   6  42 100   3   7  30]\n",
      " [ 38  10  31 112   2   5  12]\n",
      " [ 43   5  18  30   0  28  86]\n",
      " [ 15   1   0   7   0  15 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.59      0.50       210\n",
      "           2       0.24      0.05      0.08       210\n",
      "           3       0.50      0.80      0.61       210\n",
      "           4       0.28      0.48      0.35       210\n",
      "           5       0.33      0.01      0.02       210\n",
      "           6       0.30      0.13      0.19       210\n",
      "           7       0.49      0.82      0.61       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.37      0.41      0.34      1470\n",
      "weighted avg       0.37      0.41      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.38299319727891157\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   0  33  32   0  11  13]\n",
      " [ 29   1 104  27   0  26  23]\n",
      " [ 10   0 187   2   0   3   8]\n",
      " [ 22   0  95  55   1  10  27]\n",
      " [ 32   0  94  68   0   3  13]\n",
      " [ 39   0  33  24   0  36  78]\n",
      " [ 12   0   1  10   0  24 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.58      0.51       210\n",
      "           2       1.00      0.00      0.01       210\n",
      "           3       0.34      0.89      0.49       210\n",
      "           4       0.25      0.26      0.26       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.32      0.17      0.22       210\n",
      "           7       0.50      0.78      0.61       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.41      0.38      0.30      1470\n",
      "weighted avg       0.41      0.38      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.42653061224489797\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   6   3  57   0  13  11]\n",
      " [ 29  17  35  89   0  19  21]\n",
      " [  8   2 151  40   0   5   4]\n",
      " [ 19  11  15 128   0  11  26]\n",
      " [ 32   6   7 149   0   2  14]\n",
      " [ 31   2  10  50   0  42  75]\n",
      " [ 12   2   0   8   0  19 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.57      0.52       210\n",
      "           2       0.37      0.08      0.13       210\n",
      "           3       0.68      0.72      0.70       210\n",
      "           4       0.25      0.61      0.35       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.38      0.20      0.26       210\n",
      "           7       0.53      0.80      0.64       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.38      0.43      0.37      1470\n",
      "weighted avg       0.38      0.43      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   2   1  57   0  12  12]\n",
      " [ 29  19   6 112   0  27  17]\n",
      " [  8   5 135  53   0   6   3]\n",
      " [ 22   3   5 141   1  19  19]\n",
      " [ 36   5   4 145   1   7  12]\n",
      " [ 35   3   9  43   1  56  63]\n",
      " [ 12   1   0   7   0  44 146]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.60      0.53       210\n",
      "           2       0.50      0.09      0.15       210\n",
      "           3       0.84      0.64      0.73       210\n",
      "           4       0.25      0.67      0.37       210\n",
      "           5       0.33      0.00      0.01       210\n",
      "           6       0.33      0.27      0.29       210\n",
      "           7       0.54      0.70      0.61       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.47      0.42      0.38      1470\n",
      "weighted avg       0.47      0.42      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   5   0  57   1  13  15]\n",
      " [ 22  24  11 107   2  28  16]\n",
      " [  7  28  98  68   0   3   6]\n",
      " [ 17   9   1 142   3  18  20]\n",
      " [ 30  11   3 141   6   7  12]\n",
      " [ 30   6   3  51   2  52  66]\n",
      " [ 10   0   0   9   1  34 156]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.57      0.53       210\n",
      "           2       0.29      0.11      0.16       210\n",
      "           3       0.84      0.47      0.60       210\n",
      "           4       0.25      0.68      0.36       210\n",
      "           5       0.40      0.03      0.05       210\n",
      "           6       0.34      0.25      0.28       210\n",
      "           7       0.54      0.74      0.62       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.45      0.41      0.37      1470\n",
      "weighted avg       0.45      0.41      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.37006802721088433\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   9   1  48   8  15  10]\n",
      " [ 29  51  12  63  15  26  14]\n",
      " [  6 136  32  17   6   7   6]\n",
      " [ 15  17   2 109  28  24  15]\n",
      " [ 28  22   2 106  32   9  11]\n",
      " [ 25  13   3  42   6  64  57]\n",
      " [  8   0   0   9   2  54 137]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.57      0.54       210\n",
      "           2       0.21      0.24      0.22       210\n",
      "           3       0.62      0.15      0.24       210\n",
      "           4       0.28      0.52      0.36       210\n",
      "           5       0.33      0.15      0.21       210\n",
      "           6       0.32      0.30      0.31       210\n",
      "           7       0.55      0.65      0.60       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.40      0.37      0.36      1470\n",
      "weighted avg       0.40      0.37      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119   2   1  53   8  16  11]\n",
      " [ 18  29   8 113  10  20  12]\n",
      " [  7   5 112  77   1   5   3]\n",
      " [ 15   6   3 138  10  18  20]\n",
      " [ 35   6   2 135  12  11   9]\n",
      " [ 24   7   5  54   3  57  60]\n",
      " [  8   5   0   9   1  55 132]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.57      0.55       210\n",
      "           2       0.48      0.14      0.21       210\n",
      "           3       0.85      0.53      0.66       210\n",
      "           4       0.24      0.66      0.35       210\n",
      "           5       0.27      0.06      0.09       210\n",
      "           6       0.31      0.27      0.29       210\n",
      "           7       0.53      0.63      0.58       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.46      0.41      0.39      1470\n",
      "weighted avg       0.46      0.41      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114  15   2  46   9  17   7]\n",
      " [ 18  92   8  56   2  21  13]\n",
      " [  3  53  83  56   0  11   4]\n",
      " [ 11  45  10  98   7  16  23]\n",
      " [ 24  52   4 101  11   6  12]\n",
      " [ 21  20   5  43   3  65  53]\n",
      " [  3   7   0   9   4  62 125]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.54      0.56       210\n",
      "           2       0.32      0.44      0.37       210\n",
      "           3       0.74      0.40      0.52       210\n",
      "           4       0.24      0.47      0.32       210\n",
      "           5       0.31      0.05      0.09       210\n",
      "           6       0.33      0.31      0.32       210\n",
      "           7       0.53      0.60      0.56       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.44      0.40      0.39      1470\n",
      "weighted avg       0.44      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117  17   2  43   3  15  13]\n",
      " [ 11  49  12  96   2  30  10]\n",
      " [  5   6 127  58   0  12   2]\n",
      " [ 11  24   6 128   1  23  17]\n",
      " [ 26  34   4 114  11  14   7]\n",
      " [ 18  25   4  39   6  69  49]\n",
      " [  3   3   0   7   5  82 110]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.56      0.58       210\n",
      "           2       0.31      0.23      0.27       210\n",
      "           3       0.82      0.60      0.70       210\n",
      "           4       0.26      0.61      0.37       210\n",
      "           5       0.39      0.05      0.09       210\n",
      "           6       0.28      0.33      0.30       210\n",
      "           7       0.53      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.46      0.42      0.41      1470\n",
      "weighted avg       0.46      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.33741496598639453\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  36   2  33   9  16   8]\n",
      " [ 16  91  11  42  10  26  14]\n",
      " [  3 161  30   9   0   3   4]\n",
      " [  7  75   7  65  14  20  22]\n",
      " [ 24  70   3  71  20  14   8]\n",
      " [ 18  41   3  25   5  53  65]\n",
      " [  4   8   0   6   3  58 131]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.50      0.55       210\n",
      "           2       0.19      0.43      0.26       210\n",
      "           3       0.54      0.14      0.23       210\n",
      "           4       0.26      0.31      0.28       210\n",
      "           5       0.33      0.10      0.15       210\n",
      "           6       0.28      0.25      0.27       210\n",
      "           7       0.52      0.62      0.57       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.39      0.34      0.33      1470\n",
      "weighted avg       0.39      0.34      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[117   6   6  49   4  20   8]\n",
      " [ 14  31  48  76   3  22  16]\n",
      " [  4   2 167  29   0   6   2]\n",
      " [  8   5  17 136   5  26  13]\n",
      " [ 25   7  13 137   7   8  13]\n",
      " [ 14  13  14  43   3  80  43]\n",
      " [  4   4   2   5   5  92  98]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.56      0.59       210\n",
      "           2       0.46      0.15      0.22       210\n",
      "           3       0.63      0.80      0.70       210\n",
      "           4       0.29      0.65      0.40       210\n",
      "           5       0.26      0.03      0.06       210\n",
      "           6       0.31      0.38      0.34       210\n",
      "           7       0.51      0.47      0.49       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.40      1470\n",
      "weighted avg       0.44      0.43      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.427891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100  12   4  51  13  23   7]\n",
      " [ 11  59  38  52  17  24   9]\n",
      " [  3  18 144  29   1  12   3]\n",
      " [  9  29  22  93  20  24  13]\n",
      " [ 14  30  13  88  46  10   9]\n",
      " [ 20   8  16  42   7  81  36]\n",
      " [  4   2   1   9   6  82 106]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54       210\n",
      "           2       0.37      0.28      0.32       210\n",
      "           3       0.61      0.69      0.64       210\n",
      "           4       0.26      0.44      0.32       210\n",
      "           5       0.42      0.22      0.29       210\n",
      "           6       0.32      0.39      0.35       210\n",
      "           7       0.58      0.50      0.54       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.43      1470\n",
      "weighted avg       0.45      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111  20   1  46   8  16   8]\n",
      " [ 10  71  10  72   8  27  12]\n",
      " [  5  31 113  47   2  10   2]\n",
      " [ 11  37   4 108  13  24  13]\n",
      " [ 23  26   3 121  18  11   8]\n",
      " [ 17  29   6  31   7  78  42]\n",
      " [  6   8   0   5   4  80 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.53      0.56       210\n",
      "           2       0.32      0.34      0.33       210\n",
      "           3       0.82      0.54      0.65       210\n",
      "           4       0.25      0.51      0.34       210\n",
      "           5       0.30      0.09      0.13       210\n",
      "           6       0.32      0.37      0.34       210\n",
      "           7       0.56      0.51      0.53       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.45      0.41      0.41      1470\n",
      "weighted avg       0.45      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.41904761904761906\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   7  16  27  18  12  14]\n",
      " [  9  20  91  32  14  29  15]\n",
      " [  5   2 181  12   3   6   1]\n",
      " [ 17   5  77  33  40  24  14]\n",
      " [ 28   3  69  24  65  11  10]\n",
      " [ 17   9  27  20  14  72  51]\n",
      " [  6   2   2   7   5  59 129]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.55      0.57       210\n",
      "           2       0.42      0.10      0.16       210\n",
      "           3       0.39      0.86      0.54       210\n",
      "           4       0.21      0.16      0.18       210\n",
      "           5       0.41      0.31      0.35       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.55      0.61      0.58       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.41      0.42      0.39      1470\n",
      "weighted avg       0.41      0.42      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3625850340136054\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114  21   0  32  15  18  10]\n",
      " [ 12  77   9  50  23  18  21]\n",
      " [  4 124  40  17  16   6   3]\n",
      " [ 16  33   5  78  35  24  19]\n",
      " [ 31  30   2  91  34  10  12]\n",
      " [ 19  18   8  33   8  56  68]\n",
      " [  3   9   0   6   5  53 134]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.54      0.56       210\n",
      "           2       0.25      0.37      0.30       210\n",
      "           3       0.62      0.19      0.29       210\n",
      "           4       0.25      0.37      0.30       210\n",
      "           5       0.25      0.16      0.20       210\n",
      "           6       0.30      0.27      0.28       210\n",
      "           7       0.50      0.64      0.56       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.39      0.36      0.36      1470\n",
      "weighted avg       0.39      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  10  11  55   9  17   7]\n",
      " [  8  36  42  90   2  28   4]\n",
      " [  2   1 167  26   2   9   3]\n",
      " [ 12   9  32 114   6  18  19]\n",
      " [ 23   3  20 120  24  14   6]\n",
      " [ 16  11  12  42   9  78  42]\n",
      " [  5   6   1  11   2  93  92]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.48      0.54       210\n",
      "           2       0.47      0.17      0.25       210\n",
      "           3       0.59      0.80      0.67       210\n",
      "           4       0.25      0.54      0.34       210\n",
      "           5       0.44      0.11      0.18       210\n",
      "           6       0.30      0.37      0.33       210\n",
      "           7       0.53      0.44      0.48       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.46      0.42      0.40      1470\n",
      "weighted avg       0.46      0.42      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.37482993197278913\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[111  19   9  39   7  22   3]\n",
      " [ 10  47  34  63  16  36   4]\n",
      " [  5  40 118  41   1   5   0]\n",
      " [ 10  39  21  73  31  26  10]\n",
      " [ 26  45  15  70  36  13   5]\n",
      " [ 19  16  15  32   8  96  24]\n",
      " [  5   9   4   7   2 113  70]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.53      0.56       210\n",
      "           2       0.22      0.22      0.22       210\n",
      "           3       0.55      0.56      0.55       210\n",
      "           4       0.22      0.35      0.27       210\n",
      "           5       0.36      0.17      0.23       210\n",
      "           6       0.31      0.46      0.37       210\n",
      "           7       0.60      0.33      0.43       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.41      0.37      0.38      1470\n",
      "weighted avg       0.41      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 44   0  56  39   1  14  56]\n",
      " [ 16   0 113  25   0   4  52]\n",
      " [  5   0 180   3   0  15   7]\n",
      " [ 10   0 132  29   0  10  29]\n",
      " [ 16   0 137  33   2   4  18]\n",
      " [ 13   0  47  21   3  29  97]\n",
      " [  6   0   5   7   1  27 164]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.21      0.28       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.27      0.86      0.41       210\n",
      "           4       0.18      0.14      0.16       210\n",
      "           5       0.29      0.01      0.02       210\n",
      "           6       0.28      0.14      0.19       210\n",
      "           7       0.39      0.78      0.52       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.26      0.30      0.22      1470\n",
      "weighted avg       0.26      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# GKB BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_gkb.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab727c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[162   0   1   1  31  15   0]\n",
      " [ 13  89  18  25  32  33   0]\n",
      " [  2   0 197   4   3   4   0]\n",
      " [ 11   2   7 125  39  25   1]\n",
      " [ 42   4   3  11 140   7   3]\n",
      " [ 21   3  13  16  11 125  21]\n",
      " [ 11   0   1   1   5  53 139]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.77      0.69       210\n",
      "           2       0.91      0.42      0.58       210\n",
      "           3       0.82      0.94      0.88       210\n",
      "           4       0.68      0.60      0.64       210\n",
      "           5       0.54      0.67      0.59       210\n",
      "           6       0.48      0.60      0.53       210\n",
      "           7       0.85      0.66      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.66      1470\n",
      "weighted avg       0.70      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[144   7   5   3  44   5   2]\n",
      " [ 20 134   8   6  28   9   5]\n",
      " [  6   5 187   3   8   1   0]\n",
      " [ 32  16  14  91  48   5   4]\n",
      " [ 60  17   8  20  97   7   1]\n",
      " [ 32  23   5  18  11  61  60]\n",
      " [ 11   3   1   4   4  12 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.69      0.56       210\n",
      "           2       0.65      0.64      0.65       210\n",
      "           3       0.82      0.89      0.85       210\n",
      "           4       0.63      0.43      0.51       210\n",
      "           5       0.40      0.46      0.43       210\n",
      "           6       0.61      0.29      0.39       210\n",
      "           7       0.71      0.83      0.77       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[149   5   4   3  38   9   2]\n",
      " [ 11 135  10   8  30   9   7]\n",
      " [  6   7 185   4   7   1   0]\n",
      " [ 27  10  16  87  56   8   6]\n",
      " [ 52  15   7  28 101   6   1]\n",
      " [ 27  19   3  17   9  71  64]\n",
      " [  7   1   0   2   1  21 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.71      0.61       210\n",
      "           2       0.70      0.64      0.67       210\n",
      "           3       0.82      0.88      0.85       210\n",
      "           4       0.58      0.41      0.48       210\n",
      "           5       0.42      0.48      0.45       210\n",
      "           6       0.57      0.34      0.42       210\n",
      "           7       0.69      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6115646258503401\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   3   3   5  51  10   2]\n",
      " [ 12 136   9   7  29  12   5]\n",
      " [  3   7 187   6   5   2   0]\n",
      " [ 23  16  17  90  50   8   6]\n",
      " [ 52  13   6  26 105   5   3]\n",
      " [ 27  16   4  21  10  59  73]\n",
      " [  2   1   0   1   3  17 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.65      0.58       210\n",
      "           2       0.71      0.65      0.68       210\n",
      "           3       0.83      0.89      0.86       210\n",
      "           4       0.58      0.43      0.49       210\n",
      "           5       0.42      0.50      0.45       210\n",
      "           6       0.52      0.28      0.37       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6129251700680272\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   3   3   8  49   8   3]\n",
      " [ 11 138  11   2  33  11   4]\n",
      " [  3   7 185   5   8   2   0]\n",
      " [ 23   9  16  87  60   9   6]\n",
      " [ 47  16   7  23 108   6   3]\n",
      " [ 28  18   3  14  14  62  71]\n",
      " [  1   1   0   2   3  18 185]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.65      0.59       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.82      0.88      0.85       210\n",
      "           4       0.62      0.41      0.50       210\n",
      "           5       0.39      0.51      0.45       210\n",
      "           6       0.53      0.30      0.38       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   3   3   4  48   8   3]\n",
      " [  8 135  12   6  32  10   7]\n",
      " [  3   5 186   4   9   3   0]\n",
      " [ 22   8  12  92  63   9   4]\n",
      " [ 45  12   7  22 116   4   4]\n",
      " [ 28  13   4  16  18  54  77]\n",
      " [  2   1   0   1   4  16 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.67      0.61       210\n",
      "           2       0.76      0.64      0.70       210\n",
      "           3       0.83      0.89      0.86       210\n",
      "           4       0.63      0.44      0.52       210\n",
      "           5       0.40      0.55      0.46       210\n",
      "           6       0.52      0.26      0.34       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6278911564625851\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   4   2   4  49   8   3]\n",
      " [  9 133  12   7  32  10   7]\n",
      " [  2   4 190   3   8   3   0]\n",
      " [ 22   7  10  95  63  11   2]\n",
      " [ 43  11   4  24 120   4   4]\n",
      " [ 30  15   4  17  15  58  71]\n",
      " [  2   1   0   1   3  16 187]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.67      0.61       210\n",
      "           2       0.76      0.63      0.69       210\n",
      "           3       0.86      0.90      0.88       210\n",
      "           4       0.63      0.45      0.53       210\n",
      "           5       0.41      0.57      0.48       210\n",
      "           6       0.53      0.28      0.36       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5408163265306123\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 96  12  18  12  36  32   4]\n",
      " [  2  94  17  17  41  33   6]\n",
      " [  8  20 140  14   6  22   0]\n",
      " [  8  16  14  83  55  31   3]\n",
      " [ 14  21   7  25 123  15   5]\n",
      " [ 18  17   3  14   7  92  59]\n",
      " [  0   4   0   1   0  38 167]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.46      0.54       210\n",
      "           2       0.51      0.45      0.48       210\n",
      "           3       0.70      0.67      0.68       210\n",
      "           4       0.50      0.40      0.44       210\n",
      "           5       0.46      0.59      0.51       210\n",
      "           6       0.35      0.44      0.39       210\n",
      "           7       0.68      0.80      0.74       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.21496598639455783\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 12   4   8   4 172   9   1]\n",
      " [  5  26   8   9 146  16   0]\n",
      " [  8   5  18   5 167   6   1]\n",
      " [  8   4   2  18 163  13   2]\n",
      " [  5   5   3   4 186   6   1]\n",
      " [  6  13   7   9 127  35  13]\n",
      " [  5  12   1   2 147  22  21]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.06      0.09       210\n",
      "           2       0.38      0.12      0.19       210\n",
      "           3       0.38      0.09      0.14       210\n",
      "           4       0.35      0.09      0.14       210\n",
      "           5       0.17      0.89      0.28       210\n",
      "           6       0.33      0.17      0.22       210\n",
      "           7       0.54      0.10      0.17       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.34      0.21      0.18      1470\n",
      "weighted avg       0.34      0.21      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6761904761904762\n",
      "Confusion Matrix of SVM is:\n",
      " [[164   1   0   2  38   5   0]\n",
      " [ 13 140   9  23  11  14   0]\n",
      " [  3   4 191   9   2   1   0]\n",
      " [ 12  13   8 130  28  18   1]\n",
      " [ 44  16   2  14 130   3   1]\n",
      " [ 34  13  10  20  11  97  25]\n",
      " [ 18   1   0   1   6  42 142]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.78      0.66       210\n",
      "           2       0.74      0.67      0.70       210\n",
      "           3       0.87      0.91      0.89       210\n",
      "           4       0.65      0.62      0.64       210\n",
      "           5       0.58      0.62      0.60       210\n",
      "           6       0.54      0.46      0.50       210\n",
      "           7       0.84      0.68      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7013605442176871\n",
      "Confusion Matrix of SVM is:\n",
      " [[169   1   0   4  31   5   0]\n",
      " [  6 145   6  30  13  10   0]\n",
      " [  0   2 193  11   2   2   0]\n",
      " [ 13  13   8 134  26  15   1]\n",
      " [ 42  10   3  22 130   2   1]\n",
      " [ 26  13   9  26  10 100  26]\n",
      " [ 11   0   0   2   3  34 160]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.80      0.71       210\n",
      "           2       0.79      0.69      0.74       210\n",
      "           3       0.88      0.92      0.90       210\n",
      "           4       0.59      0.64      0.61       210\n",
      "           5       0.60      0.62      0.61       210\n",
      "           6       0.60      0.48      0.53       210\n",
      "           7       0.85      0.76      0.80       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7238095238095238\n",
      "Confusion Matrix of SVM is:\n",
      " [[146   3   2   6  30  20   3]\n",
      " [  4 153   7  16  11  17   2]\n",
      " [  1   4 184  12   3   6   0]\n",
      " [  6   7   7 144  23  21   2]\n",
      " [ 30  18   1  28 125   5   3]\n",
      " [ 11  13   3  20   4 129  30]\n",
      " [  0   1   0   1   1  24 183]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72       210\n",
      "           2       0.77      0.73      0.75       210\n",
      "           3       0.90      0.88      0.89       210\n",
      "           4       0.63      0.69      0.66       210\n",
      "           5       0.63      0.60      0.61       210\n",
      "           6       0.58      0.61      0.60       210\n",
      "           7       0.82      0.87      0.85       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.3333333333333333\n",
      "Confusion Matrix of SVM is:\n",
      " [[  2   1  10   0 181   0  16]\n",
      " [  2  32   6   0 147   0  23]\n",
      " [  2   1  61   1 137   0   8]\n",
      " [  3   0   4   1 189   0  13]\n",
      " [  1   1   0   0 200   0   8]\n",
      " [  4   6   7   0  85   0 108]\n",
      " [  1   4   0   0  11   0 194]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.01      0.02       210\n",
      "           2       0.71      0.15      0.25       210\n",
      "           3       0.69      0.29      0.41       210\n",
      "           4       0.50      0.00      0.01       210\n",
      "           5       0.21      0.95      0.34       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.52      0.92      0.67       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.40      0.33      0.24      1470\n",
      "weighted avg       0.40      0.33      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2598639455782313\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0 191   0   0   0  19]\n",
      " [  0   0 179   0   0   0  31]\n",
      " [  0   0 194   0   0   0  16]\n",
      " [  0   0 196   0   0   0  14]\n",
      " [  0   0 203   0   0   0   7]\n",
      " [  0   0  77   0   0   0 133]\n",
      " [  0   0  22   0   0   0 188]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.18      0.92      0.31       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.46      0.90      0.61       210\n",
      "\n",
      "    accuracy                           0.26      1470\n",
      "   macro avg       0.09      0.26      0.13      1470\n",
      "weighted avg       0.09      0.26      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38299319727891157\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  15   0 176  10   9]\n",
      " [  0   0  13   0 166  22   9]\n",
      " [  0   0 138   0  56  15   1]\n",
      " [  0   0  22   0 174   9   5]\n",
      " [  0   0   5   0 198   3   4]\n",
      " [  0   0   5   0  72  60  73]\n",
      " [  0   0   0   0  22  21 167]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.70      0.66      0.68       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.23      0.94      0.37       210\n",
      "           6       0.43      0.29      0.34       210\n",
      "           7       0.62      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.28      0.38      0.30      1470\n",
      "weighted avg       0.28      0.38      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[169   9   1  14   0  14   3]\n",
      " [ 98  73   2  11   0  20   6]\n",
      " [ 37  20  98  40   0  15   0]\n",
      " [159  15   2  20   0  11   3]\n",
      " [183  15   0   5   0   3   4]\n",
      " [ 66   7   2   3   0  79  53]\n",
      " [ 22   1   0   0   0  35 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.80      0.36       210\n",
      "           2       0.52      0.35      0.42       210\n",
      "           3       0.93      0.47      0.62       210\n",
      "           4       0.22      0.10      0.13       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.69      0.72      0.71       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.43      0.40      0.38      1470\n",
      "weighted avg       0.43      0.40      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96   7   4  14  73  12   4]\n",
      " [ 11  70   9  11  87  17   5]\n",
      " [  1  11  66  86  36  10   0]\n",
      " [ 19  15   3  19 140  13   1]\n",
      " [ 47  15   1   5 136   3   3]\n",
      " [ 22   5   7   3  44  93  36]\n",
      " [ 16   1   0   0   6  43 144]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.46      0.45       210\n",
      "           2       0.56      0.33      0.42       210\n",
      "           3       0.73      0.31      0.44       210\n",
      "           4       0.14      0.09      0.11       210\n",
      "           5       0.26      0.65      0.37       210\n",
      "           6       0.49      0.44      0.46       210\n",
      "           7       0.75      0.69      0.71       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.48      0.42      0.42      1470\n",
      "weighted avg       0.48      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42925170068027213\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 98  13   1  16  65  12   5]\n",
      " [ 15  74   1  25  70  17   8]\n",
      " [  6  18  27  89  60   9   1]\n",
      " [ 19  17   2  89  69  13   1]\n",
      " [ 48  15   0  35 106   3   3]\n",
      " [ 26   5   2  16  33  89  39]\n",
      " [ 16   1   0   1   5  39 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.47      0.45       210\n",
      "           2       0.52      0.35      0.42       210\n",
      "           3       0.82      0.13      0.22       210\n",
      "           4       0.33      0.42      0.37       210\n",
      "           5       0.26      0.50      0.34       210\n",
      "           6       0.49      0.42      0.45       210\n",
      "           7       0.72      0.70      0.71       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.51      0.43      0.42      1470\n",
      "weighted avg       0.51      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86   6  15  16  66  19   2]\n",
      " [ 11  68   9  22  76  18   6]\n",
      " [  6  12  37  79  67   9   0]\n",
      " [ 17  14   4  85  77  12   1]\n",
      " [ 28  15   0  31 128   5   3]\n",
      " [ 22   8   2  14  36  92  36]\n",
      " [ 15   2   0   1   5  47 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.41      0.44       210\n",
      "           2       0.54      0.32      0.41       210\n",
      "           3       0.55      0.18      0.27       210\n",
      "           4       0.34      0.40      0.37       210\n",
      "           5       0.28      0.61      0.38       210\n",
      "           6       0.46      0.44      0.45       210\n",
      "           7       0.74      0.67      0.70       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.48      0.43      0.43      1470\n",
      "weighted avg       0.48      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102   7  11  44  30  14   2]\n",
      " [ 13  67  10  64  35  17   4]\n",
      " [  8  12  33  81  62  13   1]\n",
      " [ 20   9   4 123  41  10   3]\n",
      " [ 39   6   0  65  95   4   1]\n",
      " [ 26   7   1  42   6  87  41]\n",
      " [ 14   0   0   6   0  45 145]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.49      0.47       210\n",
      "           2       0.62      0.32      0.42       210\n",
      "           3       0.56      0.16      0.25       210\n",
      "           4       0.29      0.59      0.39       210\n",
      "           5       0.35      0.45      0.40       210\n",
      "           6       0.46      0.41      0.44       210\n",
      "           7       0.74      0.69      0.71       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.44      1470\n",
      "weighted avg       0.50      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4380952380952381\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93  23  10  31  37  12   4]\n",
      " [  9 114   7  27  32  18   3]\n",
      " [ 53  23  36  25  66   7   0]\n",
      " [ 17  31   6  97  45  12   2]\n",
      " [ 32  40   0  30 102   5   1]\n",
      " [ 21  28   2  34  10  81  34]\n",
      " [ 12   4   0   8   2  63 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.44      0.42       210\n",
      "           2       0.43      0.54      0.48       210\n",
      "           3       0.59      0.17      0.27       210\n",
      "           4       0.38      0.46      0.42       210\n",
      "           5       0.35      0.49      0.40       210\n",
      "           6       0.41      0.39      0.40       210\n",
      "           7       0.73      0.58      0.65       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.43      1470\n",
      "weighted avg       0.47      0.44      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[115  13  11  23  26  18   4]\n",
      " [ 21  91   8  24  45  18   3]\n",
      " [ 36  13  35  70  44  10   2]\n",
      " [ 30  26   5  88  41  17   3]\n",
      " [ 71  23   1  26  77  10   2]\n",
      " [ 28  18   2  26  15  80  41]\n",
      " [ 17   8   1   7   5  49 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.55      0.44       210\n",
      "           2       0.47      0.43      0.45       210\n",
      "           3       0.56      0.17      0.26       210\n",
      "           4       0.33      0.42      0.37       210\n",
      "           5       0.30      0.37      0.33       210\n",
      "           6       0.40      0.38      0.39       210\n",
      "           7       0.69      0.59      0.63       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.45      0.41      0.41      1470\n",
      "weighted avg       0.45      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43197278911564624\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[121  15   6  27  23  11   7]\n",
      " [ 17  96  10  33  33  17   4]\n",
      " [ 61  19  37  27  49  14   3]\n",
      " [ 36  18   6  93  42  14   1]\n",
      " [ 50  20   6  42  80  10   2]\n",
      " [ 24  19   1  28  15  88  35]\n",
      " [  7   6   0  10   4  63 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.58      0.46       210\n",
      "           2       0.50      0.46      0.48       210\n",
      "           3       0.56      0.18      0.27       210\n",
      "           4       0.36      0.44      0.40       210\n",
      "           5       0.33      0.38      0.35       210\n",
      "           6       0.41      0.42      0.41       210\n",
      "           7       0.70      0.57      0.63       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.43      1470\n",
      "weighted avg       0.46      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  21  17  21  21  13   6]\n",
      " [ 18  95  10  34  34  16   3]\n",
      " [ 32  17  41  77  32   9   2]\n",
      " [ 17  35  13  95  35  11   4]\n",
      " [ 28  27  20  46  77  10   2]\n",
      " [ 18  31   2  21  19  79  40]\n",
      " [ 12   8   0   6   4  58 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.53      0.50       210\n",
      "           2       0.41      0.45      0.43       210\n",
      "           3       0.40      0.20      0.26       210\n",
      "           4       0.32      0.45      0.37       210\n",
      "           5       0.35      0.37      0.36       210\n",
      "           6       0.40      0.38      0.39       210\n",
      "           7       0.68      0.58      0.63       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41768707482993195\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[109  20  17  24  20  15   5]\n",
      " [ 22 101  10  31  23  20   3]\n",
      " [ 13  19  46  21  58  52   1]\n",
      " [ 19  28  17  88  46  10   2]\n",
      " [ 43  28   6  50  67  15   1]\n",
      " [ 20  29   4  21  15  82  39]\n",
      " [ 10   7   1   6   3  62 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.52      0.49       210\n",
      "           2       0.44      0.48      0.46       210\n",
      "           3       0.46      0.22      0.30       210\n",
      "           4       0.37      0.42      0.39       210\n",
      "           5       0.29      0.32      0.30       210\n",
      "           6       0.32      0.39      0.35       210\n",
      "           7       0.70      0.58      0.63       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[114  21  15  21  22  13   4]\n",
      " [ 19 104  10  25  29  18   5]\n",
      " [ 11  19  44  74  55   6   1]\n",
      " [ 18  27  16  84  47  14   4]\n",
      " [ 47  26  10  42  70  12   3]\n",
      " [ 22  30   5  16  18  78  41]\n",
      " [ 11   9   0   6   4  57 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.54      0.50       210\n",
      "           2       0.44      0.50      0.47       210\n",
      "           3       0.44      0.21      0.28       210\n",
      "           4       0.31      0.40      0.35       210\n",
      "           5       0.29      0.33      0.31       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.68      0.59      0.63       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3904761904761905\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[116  15  10  20  28  17   4]\n",
      " [ 19  89  14  30  35  21   2]\n",
      " [ 12  23  33  79  54   8   1]\n",
      " [ 25  26  14  79  45  17   4]\n",
      " [ 42  28  15  39  70  16   0]\n",
      " [ 21  31   7  24  13  69  45]\n",
      " [  9   7   0   9   3  64 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.55      0.51       210\n",
      "           2       0.41      0.42      0.41       210\n",
      "           3       0.35      0.16      0.22       210\n",
      "           4       0.28      0.38      0.32       210\n",
      "           5       0.28      0.33      0.31       210\n",
      "           6       0.33      0.33      0.33       210\n",
      "           7       0.68      0.56      0.61       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.39      1470\n",
      "weighted avg       0.40      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.391156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  15  13  23  29  14   5]\n",
      " [ 16  86  13  21  47  21   6]\n",
      " [ 12  20  42  77  53   4   2]\n",
      " [ 28  23  11  77  48  19   4]\n",
      " [ 51  24  10  41  65  15   4]\n",
      " [ 22  25   4  22  21  72  44]\n",
      " [ 17   9   0   3   8  51 122]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.53      0.48       210\n",
      "           2       0.43      0.41      0.42       210\n",
      "           3       0.45      0.20      0.28       210\n",
      "           4       0.29      0.37      0.32       210\n",
      "           5       0.24      0.31      0.27       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.65      0.58      0.61       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.39      1470\n",
      "weighted avg       0.41      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3891156462585034\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105  20   7  27  24  24   3]\n",
      " [ 18 100  14  21  29  22   6]\n",
      " [ 11  23  35  77  56   7   1]\n",
      " [ 24  23  16  76  51  17   3]\n",
      " [ 45  22   9  51  65  17   1]\n",
      " [ 21  25   5  22  22  72  43]\n",
      " [ 22   5   0   7   7  50 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.50      0.46       210\n",
      "           2       0.46      0.48      0.47       210\n",
      "           3       0.41      0.17      0.24       210\n",
      "           4       0.27      0.36      0.31       210\n",
      "           5       0.26      0.31      0.28       210\n",
      "           6       0.34      0.34      0.34       210\n",
      "           7       0.68      0.57      0.62       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.39      1470\n",
      "weighted avg       0.41      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39727891156462586\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[111  21   8  29  22  14   5]\n",
      " [ 15  96  13  28  34  18   6]\n",
      " [ 12  24  34  73  58   8   1]\n",
      " [ 22  30   9  81  46  18   4]\n",
      " [ 45  29   3  44  72  15   2]\n",
      " [ 24  32   7  21  17  72  37]\n",
      " [ 10   8   0   5   6  63 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.53      0.49       210\n",
      "           2       0.40      0.46      0.43       210\n",
      "           3       0.46      0.16      0.24       210\n",
      "           4       0.29      0.39      0.33       210\n",
      "           5       0.28      0.34      0.31       210\n",
      "           6       0.35      0.34      0.34       210\n",
      "           7       0.68      0.56      0.62       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.39      1470\n",
      "weighted avg       0.42      0.40      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[113  14  11  25  29  14   4]\n",
      " [ 21  91  13  25  39  20   1]\n",
      " [ 13  25  39  74  52   7   0]\n",
      " [ 23  24  12  80  47  21   3]\n",
      " [ 43  24   6  50  67  16   4]\n",
      " [ 19  29   7  23  18  79  35]\n",
      " [ 23   5   0   8   7  80  87]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.54      0.49       210\n",
      "           2       0.43      0.43      0.43       210\n",
      "           3       0.44      0.19      0.26       210\n",
      "           4       0.28      0.38      0.32       210\n",
      "           5       0.26      0.32      0.29       210\n",
      "           6       0.33      0.38      0.35       210\n",
      "           7       0.65      0.41      0.51       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.41      0.38      0.38      1470\n",
      "weighted avg       0.41      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.363265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[102  20  12  23  31  20   2]\n",
      " [ 21  92  14  28  33  20   2]\n",
      " [ 13  24  39  71  53   8   2]\n",
      " [ 22  30  11  76  43  22   6]\n",
      " [ 40  30   6  44  68  19   3]\n",
      " [ 23  26   4  19  21  79  38]\n",
      " [ 21   8   0   8   4  91  78]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.49      0.45       210\n",
      "           2       0.40      0.44      0.42       210\n",
      "           3       0.45      0.19      0.26       210\n",
      "           4       0.28      0.36      0.32       210\n",
      "           5       0.27      0.32      0.29       210\n",
      "           6       0.31      0.38      0.34       210\n",
      "           7       0.60      0.37      0.46       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.39      0.36      0.36      1470\n",
      "weighted avg       0.39      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103  33  10  25  21  12   6]\n",
      " [ 18  92  12  25  37  21   5]\n",
      " [ 11  22  40  72  55   8   2]\n",
      " [ 17  25  14  84  46  22   2]\n",
      " [ 49  21   7  41  65  23   4]\n",
      " [ 21  25   4  19  17  86  38]\n",
      " [  9   7   3   7   8 100  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.49      0.47       210\n",
      "           2       0.41      0.44      0.42       210\n",
      "           3       0.44      0.19      0.27       210\n",
      "           4       0.31      0.40      0.35       210\n",
      "           5       0.26      0.31      0.28       210\n",
      "           6       0.32      0.41      0.36       210\n",
      "           7       0.57      0.36      0.44       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.37      1470\n",
      "weighted avg       0.39      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2795918367346939\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  3   1 174   1   3   0  28]\n",
      " [  0   6 138   0   7   0  59]\n",
      " [  1   0 189   0   0   4  16]\n",
      " [  1   1 169   0  12   0  27]\n",
      " [  1   3 184   3   5   1  13]\n",
      " [  2   4  49   1   6   3 145]\n",
      " [  1   1   3   0   0   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.01      0.03       210\n",
      "           2       0.38      0.03      0.05       210\n",
      "           3       0.21      0.90      0.34       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.15      0.02      0.04       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.42      0.98      0.58       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.27      0.28      0.15      1470\n",
      "weighted avg       0.27      0.28      0.15      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 45   7  61   0  70  15  12]\n",
      " [  4  55  44   2  64  25  16]\n",
      " [  3   6 171   2  14  11   3]\n",
      " [  2   5  51   7 120  12  13]\n",
      " [  4   4  45   3 140   6   8]\n",
      " [ 11  10  12   0  33  30 114]\n",
      " [  1   2   0   0   2   5 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.21      0.32       210\n",
      "           2       0.62      0.26      0.37       210\n",
      "           3       0.45      0.81      0.58       210\n",
      "           4       0.50      0.03      0.06       210\n",
      "           5       0.32      0.67      0.43       210\n",
      "           6       0.29      0.14      0.19       210\n",
      "           7       0.55      0.95      0.69       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.48      0.44      0.38      1470\n",
      "weighted avg       0.48      0.44      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  16  14   3  44  18   9]\n",
      " [  8 108  14  13  43  13  11]\n",
      " [  5  27 156   5   4  13   0]\n",
      " [  9  21  20  58  78  17   7]\n",
      " [ 19  19  12  13 133   8   6]\n",
      " [ 20  20   5   7  15  52  91]\n",
      " [  0   6   0   1   0   7 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.50      0.56       210\n",
      "           2       0.50      0.51      0.51       210\n",
      "           3       0.71      0.74      0.72       210\n",
      "           4       0.58      0.28      0.37       210\n",
      "           5       0.42      0.63      0.50       210\n",
      "           6       0.41      0.25      0.31       210\n",
      "           7       0.61      0.93      0.74       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.53      1470\n",
      "weighted avg       0.55      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5829931972789115\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132  11   0   6  34  21   6]\n",
      " [  6 111   8  20  40  18   7]\n",
      " [  9  14 159   8   6  14   0]\n",
      " [ 12  21   8  83  62  21   3]\n",
      " [ 34  17   1  24 119   9   6]\n",
      " [ 23  19   2  10  12  65  79]\n",
      " [  0   5   0   1   0  16 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.63      0.62       210\n",
      "           2       0.56      0.53      0.54       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.55      0.40      0.46       210\n",
      "           5       0.44      0.57      0.49       210\n",
      "           6       0.40      0.31      0.35       210\n",
      "           7       0.65      0.90      0.75       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6068027210884354\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131  12   1  10  30  21   5]\n",
      " [  6 114   4  19  42  21   4]\n",
      " [  8  10 163   9   8  12   0]\n",
      " [ 16  18   4 104  43  19   6]\n",
      " [ 31  20   0  22 123   8   6]\n",
      " [ 26  16   1  16   5  73  73]\n",
      " [  0   5   0   1   0  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       210\n",
      "           2       0.58      0.54      0.56       210\n",
      "           3       0.94      0.78      0.85       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.49      0.59      0.53       210\n",
      "           6       0.42      0.35      0.38       210\n",
      "           7       0.66      0.88      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   7   1  12  35  26   5]\n",
      " [  5 114   3  28  36  16   8]\n",
      " [  4   8 163  11  14  10   0]\n",
      " [ 11  13   5 124  32  22   3]\n",
      " [ 28  13   0  38 119   8   4]\n",
      " [ 20  13   0  20  10  78  69]\n",
      " [  0   5   0   1   0  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.59      0.62       210\n",
      "           2       0.66      0.54      0.60       210\n",
      "           3       0.95      0.78      0.85       210\n",
      "           4       0.53      0.59      0.56       210\n",
      "           5       0.48      0.57      0.52       210\n",
      "           6       0.43      0.37      0.40       210\n",
      "           7       0.67      0.88      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6299319727891156\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   7   1  14  36  22   4]\n",
      " [  5 115   3  28  36  17   6]\n",
      " [  4   8 159  17  12  10   0]\n",
      " [  9   8   3 130  35  24   1]\n",
      " [ 18  14   1  41 123   6   7]\n",
      " [ 15  12   2  23  10  89  59]\n",
      " [  0   4   0   1   0  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.60      0.65       210\n",
      "           2       0.68      0.55      0.61       210\n",
      "           3       0.94      0.76      0.84       210\n",
      "           4       0.51      0.62      0.56       210\n",
      "           5       0.49      0.59      0.53       210\n",
      "           6       0.47      0.42      0.45       210\n",
      "           7       0.70      0.88      0.78       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.636734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   6   0  10  35  24   4]\n",
      " [  3 121   4  27  32  17   6]\n",
      " [  4   9 159  16  13   9   0]\n",
      " [ 11  15   3 123  36  19   3]\n",
      " [ 21  13   0  42 121   9   4]\n",
      " [ 14  19   0  26   5  96  50]\n",
      " [  0   4   0   1   0  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.62      0.66       210\n",
      "           2       0.65      0.58      0.61       210\n",
      "           3       0.96      0.76      0.85       210\n",
      "           4       0.50      0.59      0.54       210\n",
      "           5       0.50      0.58      0.54       210\n",
      "           6       0.49      0.46      0.48       210\n",
      "           7       0.73      0.88      0.80       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6510204081632653\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   4   0  11  35  22   5]\n",
      " [  4 123   6  21  34  18   4]\n",
      " [  3   4 172  13   9   9   0]\n",
      " [ 11   7   4 122  42  21   3]\n",
      " [ 23  14   0  34 126   8   5]\n",
      " [ 19  17   0  18  10  97  49]\n",
      " [  0   5   0   1   0  20 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.63      0.66       210\n",
      "           2       0.71      0.59      0.64       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.55      0.58      0.57       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.50      0.46      0.48       210\n",
      "           7       0.74      0.88      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   8   0  12  30  21   4]\n",
      " [  2 132   4  25  27  15   5]\n",
      " [  5   8 165  11  13   7   1]\n",
      " [ 13   9   4 132  31  18   3]\n",
      " [ 27  15   0  33 124   7   4]\n",
      " [ 22  17   1  17   4  94  55]\n",
      " [  0   4   0   1   0  19 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.64      0.65       210\n",
      "           2       0.68      0.63      0.66       210\n",
      "           3       0.95      0.79      0.86       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.54      0.59      0.56       210\n",
      "           6       0.52      0.45      0.48       210\n",
      "           7       0.72      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   4   1  10  38  22   4]\n",
      " [  2 128   4  19  36  16   5]\n",
      " [  4   7 166  11  13   9   0]\n",
      " [ 12  11   3 126  35  21   2]\n",
      " [ 28  16   0  40 116   6   4]\n",
      " [ 15  15   1  26   5  91  57]\n",
      " [  0   4   0   1   0  21 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.62      0.65       210\n",
      "           2       0.69      0.61      0.65       210\n",
      "           3       0.95      0.79      0.86       210\n",
      "           4       0.54      0.60      0.57       210\n",
      "           5       0.48      0.55      0.51       210\n",
      "           6       0.49      0.43      0.46       210\n",
      "           7       0.72      0.88      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.64      1470\n",
      "weighted avg       0.65      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   6   1  10  27  20   5]\n",
      " [  4 131   3  21  30  17   4]\n",
      " [  5   8 169   9  11   8   0]\n",
      " [ 14  10   3 120  40  21   2]\n",
      " [ 29  12   0  29 129   5   6]\n",
      " [ 11  15   1  24   9 106  44]\n",
      " [  0   4   0   1   0  24 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68       210\n",
      "           2       0.70      0.62      0.66       210\n",
      "           3       0.95      0.80      0.87       210\n",
      "           4       0.56      0.57      0.57       210\n",
      "           5       0.52      0.61      0.57       210\n",
      "           6       0.53      0.50      0.52       210\n",
      "           7       0.75      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.67      1470\n",
      "weighted avg       0.67      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   5   1   9  30  23   2]\n",
      " [  3 130   7  21  27  18   4]\n",
      " [  3   7 166  17   9   8   0]\n",
      " [ 11   8   3 131  36  18   3]\n",
      " [ 37  19   0  28 117   4   5]\n",
      " [ 23  12   1  15   6 105  48]\n",
      " [  0   4   0   1   0  33 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.67      0.66       210\n",
      "           2       0.70      0.62      0.66       210\n",
      "           3       0.93      0.79      0.86       210\n",
      "           4       0.59      0.62      0.61       210\n",
      "           5       0.52      0.56      0.54       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.74      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.66      1470\n",
      "weighted avg       0.66      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   4   1  10  36  19   4]\n",
      " [  3 133   5  26  22  16   5]\n",
      " [  4   8 174   8   7   9   0]\n",
      " [  9  13   2 130  32  22   2]\n",
      " [ 29  12   0  32 128   3   6]\n",
      " [ 17  14   1  18   4 111  45]\n",
      " [  0   5   0   1   0  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67       210\n",
      "           2       0.70      0.63      0.67       210\n",
      "           3       0.95      0.83      0.89       210\n",
      "           4       0.58      0.62      0.60       210\n",
      "           5       0.56      0.61      0.58       210\n",
      "           6       0.54      0.53      0.53       210\n",
      "           7       0.74      0.85      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.68      1470\n",
      "weighted avg       0.68      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[140   3   2   9  33  20   3]\n",
      " [  4 138   5  16  27  15   5]\n",
      " [  2   6 175  11   9   7   0]\n",
      " [ 14  11   3 125  35  19   3]\n",
      " [ 36  16   0  36 111   5   6]\n",
      " [ 12  14   2  24   7 110  41]\n",
      " [  1   4   0   1   0  24 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67       210\n",
      "           2       0.72      0.66      0.69       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.56      0.60      0.58       210\n",
      "           5       0.50      0.53      0.51       210\n",
      "           6       0.55      0.52      0.54       210\n",
      "           7       0.76      0.86      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6653061224489796\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   4   1  11  35  19   3]\n",
      " [  5 135   5  23  21  19   2]\n",
      " [  2   6 176  10   8   7   1]\n",
      " [ 13   7   3 127  37  19   4]\n",
      " [ 31  18   1  37 114   4   5]\n",
      " [ 14  11   2  19   6 110  48]\n",
      " [  0   3   0   1   0  27 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.65      0.67       210\n",
      "           2       0.73      0.64      0.69       210\n",
      "           3       0.94      0.84      0.88       210\n",
      "           4       0.56      0.60      0.58       210\n",
      "           5       0.52      0.54      0.53       210\n",
      "           6       0.54      0.52      0.53       210\n",
      "           7       0.74      0.85      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.673469387755102\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   3   2   9  29  20   2]\n",
      " [  4 145   6  18  17  16   4]\n",
      " [  4   5 171  14   8   8   0]\n",
      " [ 11   8   3 136  31  20   1]\n",
      " [ 36  22   0  33 108   9   2]\n",
      " [ 20  18   2  21   1 104  44]\n",
      " [  0   2   0   1   0  26 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.69      0.67       210\n",
      "           2       0.71      0.69      0.70       210\n",
      "           3       0.93      0.81      0.87       210\n",
      "           4       0.59      0.65      0.62       210\n",
      "           5       0.56      0.51      0.53       210\n",
      "           6       0.51      0.50      0.50       210\n",
      "           7       0.77      0.86      0.82       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   5   0  10  30  17   5]\n",
      " [  4 136   6  22  23  15   4]\n",
      " [  4   5 173  12   8   8   0]\n",
      " [  8  14   3 134  28  21   2]\n",
      " [ 30  17   0  36 118   6   3]\n",
      " [ 17  16   0  22   5 106  44]\n",
      " [  1   2   0   1   2  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.68      0.69       210\n",
      "           2       0.70      0.65      0.67       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.57      0.64      0.60       210\n",
      "           5       0.55      0.56      0.56       210\n",
      "           6       0.55      0.50      0.52       210\n",
      "           7       0.76      0.87      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[148   4   0   9  28  19   2]\n",
      " [  7 130   6  25  22  17   3]\n",
      " [  5   5 174  12   7   7   0]\n",
      " [  8   9   3 143  26  20   1]\n",
      " [ 33  14   0  35 116   6   6]\n",
      " [ 20  17   0  18   8 109  38]\n",
      " [  0   4   0   1   0  28 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.70      0.69       210\n",
      "           2       0.71      0.62      0.66       210\n",
      "           3       0.95      0.83      0.89       210\n",
      "           4       0.59      0.68      0.63       210\n",
      "           5       0.56      0.55      0.56       210\n",
      "           6       0.53      0.52      0.52       210\n",
      "           7       0.78      0.84      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.68      0.68      0.68      1470\n",
      "weighted avg       0.68      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.682312925170068\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   7   0   7  28  22   2]\n",
      " [  6 142   6  18  19  13   6]\n",
      " [  4   8 173   9   7   8   1]\n",
      " [ 12  10   3 137  28  18   2]\n",
      " [ 33  18   0  33 116   4   6]\n",
      " [ 25  12   1  21   3 113  35]\n",
      " [  0   2   0   1   0  29 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.69      0.66       210\n",
      "           2       0.71      0.68      0.69       210\n",
      "           3       0.95      0.82      0.88       210\n",
      "           4       0.61      0.65      0.63       210\n",
      "           5       0.58      0.55      0.56       210\n",
      "           6       0.55      0.54      0.54       210\n",
      "           7       0.77      0.85      0.81       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 82  13  31   8  42  28   6]\n",
      " [  0  81  25  11  47  37   9]\n",
      " [ 11  16 150   8   8  14   3]\n",
      " [ 14  15  30  51  65  30   5]\n",
      " [ 15  21  18  15 119  18   4]\n",
      " [ 23  15   7  10   7  74  74]\n",
      " [  0   5   0   1   0  26 178]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.39      0.46       210\n",
      "           2       0.49      0.39      0.43       210\n",
      "           3       0.57      0.71      0.64       210\n",
      "           4       0.49      0.24      0.32       210\n",
      "           5       0.41      0.57      0.48       210\n",
      "           6       0.33      0.35      0.34       210\n",
      "           7       0.64      0.85      0.73       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# N Distill BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_ndisbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80480feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6414965986394557\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[186   8   1   4   1  10   0]\n",
      " [  4 193   1   3   0   9   0]\n",
      " [  0  20 184   5   0   1   0]\n",
      " [ 11  50   4 131   2  11   1]\n",
      " [ 85  68   2  42   5   5   3]\n",
      " [ 14  55   4  27   0  95  15]\n",
      " [  8   7   1   2   1  42 149]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.89      0.72       210\n",
      "           2       0.48      0.92      0.63       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.61      0.62      0.62       210\n",
      "           5       0.56      0.02      0.05       210\n",
      "           6       0.55      0.45      0.50       210\n",
      "           7       0.89      0.71      0.79       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.66      0.64      0.60      1470\n",
      "weighted avg       0.66      0.64      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6306122448979592\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   3   4   5  37   6   0]\n",
      " [ 17 150  14   5  21   3   0]\n",
      " [  1  11 189   5   4   0   0]\n",
      " [ 22  13  22 107  42   4   0]\n",
      " [ 54  15   4  19 116   0   2]\n",
      " [ 39  28  17  29  26  50  21]\n",
      " [ 15   3   1   8   8  15 160]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.74      0.60       210\n",
      "           2       0.67      0.71      0.69       210\n",
      "           3       0.75      0.90      0.82       210\n",
      "           4       0.60      0.51      0.55       210\n",
      "           5       0.46      0.55      0.50       210\n",
      "           6       0.64      0.24      0.35       210\n",
      "           7       0.87      0.76      0.81       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.62      1470\n",
      "weighted avg       0.64      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.645578231292517\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   2   5   3  33   5   1]\n",
      " [ 15 149  15  11  16   4   0]\n",
      " [  1  11 189   5   3   1   0]\n",
      " [ 18  15  19 110  42   6   0]\n",
      " [ 50  16   3  24 115   0   2]\n",
      " [ 33  29  20  22  22  58  26]\n",
      " [  9   1   0   3  11  19 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.77      0.65       210\n",
      "           2       0.67      0.71      0.69       210\n",
      "           3       0.75      0.90      0.82       210\n",
      "           4       0.62      0.52      0.57       210\n",
      "           5       0.48      0.55      0.51       210\n",
      "           6       0.62      0.28      0.38       210\n",
      "           7       0.85      0.80      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.63      1470\n",
      "weighted avg       0.65      0.65      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[158   2   3   2  39   5   1]\n",
      " [ 10 147  18  10  22   3   0]\n",
      " [  2   9 190   5   4   0   0]\n",
      " [ 16  13  22 116  38   3   2]\n",
      " [ 38  13   6  25 125   1   2]\n",
      " [ 30  22  23  27  24  56  28]\n",
      " [  5   2   1   3  10  19 170]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.75      0.67       210\n",
      "           2       0.71      0.70      0.70       210\n",
      "           3       0.72      0.90      0.80       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.48      0.60      0.53       210\n",
      "           6       0.64      0.27      0.38       210\n",
      "           7       0.84      0.81      0.82       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[161   2   3   3  36   4   1]\n",
      " [  9 150  17  10  23   1   0]\n",
      " [  4   9 189   5   3   0   0]\n",
      " [ 13  14  20 118  42   1   2]\n",
      " [ 42  13   8  22 123   0   2]\n",
      " [ 36  25  20  27  24  50  28]\n",
      " [  6   2   1   3  12  14 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.77      0.67       210\n",
      "           2       0.70      0.71      0.71       210\n",
      "           3       0.73      0.90      0.81       210\n",
      "           4       0.63      0.56      0.59       210\n",
      "           5       0.47      0.59      0.52       210\n",
      "           6       0.71      0.24      0.36       210\n",
      "           7       0.84      0.82      0.83       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.64      1470\n",
      "weighted avg       0.67      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6557823129251701\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[155   3   4   2  42   4   0]\n",
      " [  9 152  19   8  21   0   1]\n",
      " [  1  10 192   4   3   0   0]\n",
      " [ 13  14  19 116  45   1   2]\n",
      " [ 41  11   7  24 125   0   2]\n",
      " [ 37  21  23  25  29  45  30]\n",
      " [  4   2   1   3   9  12 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66       210\n",
      "           2       0.71      0.72      0.72       210\n",
      "           3       0.72      0.91      0.81       210\n",
      "           4       0.64      0.55      0.59       210\n",
      "           5       0.46      0.60      0.52       210\n",
      "           6       0.73      0.21      0.33       210\n",
      "           7       0.84      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.64      1470\n",
      "weighted avg       0.67      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[163   3   3   1  37   3   0]\n",
      " [  9 151  18   7  23   1   1]\n",
      " [  2   8 195   3   2   0   0]\n",
      " [ 14  13  19 112  49   1   2]\n",
      " [ 38  14   7  21 128   0   2]\n",
      " [ 37  23  23  20  29  45  33]\n",
      " [  4   2   1   2  11  12 178]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.78      0.68       210\n",
      "           2       0.71      0.72      0.71       210\n",
      "           3       0.73      0.93      0.82       210\n",
      "           4       0.67      0.53      0.60       210\n",
      "           5       0.46      0.61      0.52       210\n",
      "           6       0.73      0.21      0.33       210\n",
      "           7       0.82      0.85      0.84       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.64      1470\n",
      "weighted avg       0.68      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[105  13   5  18  43  26   0]\n",
      " [  1 136   7  34  13  19   0]\n",
      " [  0  38 137  31   1   3   0]\n",
      " [  2  18   9 133  25  23   0]\n",
      " [  6  20   0  40 126  17   1]\n",
      " [  3  34   8  53  10 101   1]\n",
      " [  0   9   0  11   7 132  51]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.50      0.64       210\n",
      "           2       0.51      0.65      0.57       210\n",
      "           3       0.83      0.65      0.73       210\n",
      "           4       0.42      0.63      0.50       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.31      0.48      0.38       210\n",
      "           7       0.96      0.24      0.39       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.64      0.54      0.54      1470\n",
      "weighted avg       0.64      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.1782312925170068\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 11   5   4   2  13   1 174]\n",
      " [  1  19   5   3   0   4 178]\n",
      " [  0   7  15   1   1   3 183]\n",
      " [  3   3   1  15   4  11 173]\n",
      " [  5   3   1   4   5   2 190]\n",
      " [  5   9   3   4   4  17 168]\n",
      " [  4   4   2   2   4  14 180]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.05      0.09       210\n",
      "           2       0.38      0.09      0.15       210\n",
      "           3       0.48      0.07      0.12       210\n",
      "           4       0.48      0.07      0.12       210\n",
      "           5       0.16      0.02      0.04       210\n",
      "           6       0.33      0.08      0.13       210\n",
      "           7       0.14      0.86      0.25       210\n",
      "\n",
      "    accuracy                           0.18      1470\n",
      "   macro avg       0.34      0.18      0.13      1470\n",
      "weighted avg       0.34      0.18      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6632653061224489\n",
      "Confusion Matrix of SVM is:\n",
      " [[195   4   1   3   5   2   0]\n",
      " [ 13 180   2   4   2   9   0]\n",
      " [  2   8 193   7   0   0   0]\n",
      " [ 16  32   8 142   1   9   2]\n",
      " [102  34   2  39  31   0   2]\n",
      " [ 38  35   6  25   0  84  22]\n",
      " [ 16   3   0   3   0  38 150]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.93      0.66       210\n",
      "           2       0.61      0.86      0.71       210\n",
      "           3       0.91      0.92      0.91       210\n",
      "           4       0.64      0.68      0.66       210\n",
      "           5       0.79      0.15      0.25       210\n",
      "           6       0.59      0.40      0.48       210\n",
      "           7       0.85      0.71      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.70      0.66      0.63      1470\n",
      "weighted avg       0.70      0.66      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[200   2   0   3   3   2   0]\n",
      " [ 10 181   3   5   3   8   0]\n",
      " [  2   9 190   7   1   1   0]\n",
      " [ 23  24   8 143   2   8   2]\n",
      " [114  23   2  30  39   0   2]\n",
      " [ 52  30   4  24   1  78  21]\n",
      " [ 18   2   0   2   1  25 162]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.95      0.64       210\n",
      "           2       0.67      0.86      0.75       210\n",
      "           3       0.92      0.90      0.91       210\n",
      "           4       0.67      0.68      0.67       210\n",
      "           5       0.78      0.19      0.30       210\n",
      "           6       0.64      0.37      0.47       210\n",
      "           7       0.87      0.77      0.82       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.72      0.68      0.65      1470\n",
      "weighted avg       0.72      0.68      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7299319727891157\n",
      "Confusion Matrix of SVM is:\n",
      " [[162   2   0   2  33  11   0]\n",
      " [  5 147   4  22  15  17   0]\n",
      " [  0   3 193   8   1   5   0]\n",
      " [  3   9   5 164  19  10   0]\n",
      " [ 29   7   1  24 142   6   1]\n",
      " [  7   9   8  24   6 155   1]\n",
      " [  4   0   0   4   3  89 110]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.77      0.77       210\n",
      "           2       0.83      0.70      0.76       210\n",
      "           3       0.91      0.92      0.92       210\n",
      "           4       0.66      0.78      0.72       210\n",
      "           5       0.65      0.68      0.66       210\n",
      "           6       0.53      0.74      0.62       210\n",
      "           7       0.98      0.52      0.68       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.76      0.73      0.73      1470\n",
      "weighted avg       0.76      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 43   4 101   0  16   3  43]\n",
      " [  1  37 135   2   7   1  27]\n",
      " [  1   0 206   0   0   0   3]\n",
      " [  4  12  80  15  28   2  69]\n",
      " [ 18  11  40   1  81   1  58]\n",
      " [  1  10  82   1   2   2 112]\n",
      " [  0   3  11   0   0   1 195]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.20      0.31       210\n",
      "           2       0.48      0.18      0.26       210\n",
      "           3       0.31      0.98      0.48       210\n",
      "           4       0.79      0.07      0.13       210\n",
      "           5       0.60      0.39      0.47       210\n",
      "           6       0.20      0.01      0.02       210\n",
      "           7       0.38      0.93      0.54       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.49      0.39      0.32      1470\n",
      "weighted avg       0.49      0.39      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.26666666666666666\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  29   0   0   0 181]\n",
      " [  0   0  91   0   0   0 119]\n",
      " [  0   0 191   0   0   0  19]\n",
      " [  0   0  87   0   0   0 123]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0  62   0   0   0 148]\n",
      " [  0   0   9   0   0   0 201]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.39      0.91      0.55       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.96      0.34       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.09      0.27      0.13      1470\n",
      "weighted avg       0.09      0.27      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3843537414965986\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  14  15 157   0  24]\n",
      " [  0   0  37  54  93   0  26]\n",
      " [  0   0 167  24  15   0   4]\n",
      " [  0   0  34  53 100   0  23]\n",
      " [  0   0   6  14 173   0  17]\n",
      " [  0   0  23  39  50   0  98]\n",
      " [  0   0   2   7  29   0 172]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.59      0.80      0.68       210\n",
      "           4       0.26      0.25      0.25       210\n",
      "           5       0.28      0.82      0.42       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.47      0.82      0.60       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.23      0.38      0.28      1470\n",
      "weighted avg       0.23      0.38      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3578231292517007\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  19   0  10 108  13  11]\n",
      " [  3  58   0  33  90  16  10]\n",
      " [  0 173   2  16  15   2   2]\n",
      " [  5  38   0  49  95   9  14]\n",
      " [  3   9   0  11 170   4  13]\n",
      " [  1  30   0  32  49  42  56]\n",
      " [  0   3   0   6  29  16 156]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.23      0.36       210\n",
      "           2       0.18      0.28      0.21       210\n",
      "           3       1.00      0.01      0.02       210\n",
      "           4       0.31      0.23      0.27       210\n",
      "           5       0.31      0.81      0.44       210\n",
      "           6       0.41      0.20      0.27       210\n",
      "           7       0.60      0.74      0.66       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.51      0.36      0.32      1470\n",
      "weighted avg       0.51      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  15   4  23 100  16   3]\n",
      " [  3  45  21  56  70  14   1]\n",
      " [  0  18  11 169   9   3   0]\n",
      " [  5  18   3  78  88  14   4]\n",
      " [  3   8   3  16 164  10   6]\n",
      " [  1  13   7  53  46  60  30]\n",
      " [  0   4   1   7  27  59 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.23      0.36       210\n",
      "           2       0.37      0.21      0.27       210\n",
      "           3       0.22      0.05      0.08       210\n",
      "           4       0.19      0.37      0.25       210\n",
      "           5       0.33      0.78      0.46       210\n",
      "           6       0.34      0.29      0.31       210\n",
      "           7       0.72      0.53      0.61       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.42      0.35      0.34      1470\n",
      "weighted avg       0.42      0.35      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 49  12  11  81  35  11  11]\n",
      " [ 12  45  30 101   6  11   5]\n",
      " [  0  16 126  62   1   5   0]\n",
      " [  5  16  24 127  18  12   8]\n",
      " [  4   8   7 119  56   4  12]\n",
      " [  0   7  18  84   5  43  53]\n",
      " [  0   4   2  32   1  32 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.23      0.35       210\n",
      "           2       0.42      0.21      0.28       210\n",
      "           3       0.58      0.60      0.59       210\n",
      "           4       0.21      0.60      0.31       210\n",
      "           5       0.46      0.27      0.34       210\n",
      "           6       0.36      0.20      0.26       210\n",
      "           7       0.61      0.66      0.63       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.48      0.40      0.40      1470\n",
      "weighted avg       0.48      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54  12   7  82  30  20   5]\n",
      " [  6  75  19  80   5  20   5]\n",
      " [  0  54 117  27   5   6   1]\n",
      " [  5  33  16 120  19  11   6]\n",
      " [  3  13   5 117  55   7  10]\n",
      " [  0  21  10  79   5  47  48]\n",
      " [  0   7   1  32   1  31 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.26      0.39       210\n",
      "           2       0.35      0.36      0.35       210\n",
      "           3       0.67      0.56      0.61       210\n",
      "           4       0.22      0.57      0.32       210\n",
      "           5       0.46      0.26      0.33       210\n",
      "           6       0.33      0.22      0.27       210\n",
      "           7       0.65      0.66      0.65       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.50      0.41      0.42      1470\n",
      "weighted avg       0.50      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72   6   9  40  17  63   3]\n",
      " [ 12  70  26  60   9  29   4]\n",
      " [  5  20 120  54   1   9   1]\n",
      " [ 16  20  21 100  14  34   5]\n",
      " [ 33  10   6  76  28  48   9]\n",
      " [ 19  13  14  42   4  76  42]\n",
      " [  7   4   2  14   5  47 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.34      0.39       210\n",
      "           2       0.49      0.33      0.40       210\n",
      "           3       0.61      0.57      0.59       210\n",
      "           4       0.26      0.48      0.34       210\n",
      "           5       0.36      0.13      0.19       210\n",
      "           6       0.25      0.36      0.29       210\n",
      "           7       0.67      0.62      0.65       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.41      1470\n",
      "weighted avg       0.44      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.38299319727891157\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63   4  10  74  24  29   6]\n",
      " [ 11  60  19  72  18  25   5]\n",
      " [  1  44 116  27   5  17   0]\n",
      " [ 17  15  26 107  14  23   8]\n",
      " [ 32   7   6 110  32  13  10]\n",
      " [  8  15  20  57   5  55  50]\n",
      " [  1   5   5  21   3  45 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.30      0.37       210\n",
      "           2       0.40      0.29      0.33       210\n",
      "           3       0.57      0.55      0.56       210\n",
      "           4       0.23      0.51      0.32       210\n",
      "           5       0.32      0.15      0.21       210\n",
      "           6       0.27      0.26      0.26       210\n",
      "           7       0.62      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.41      0.38      0.38      1470\n",
      "weighted avg       0.41      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3782312925170068\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76   5  11  55  39  14  10]\n",
      " [ 14  57  25  57  39  12   6]\n",
      " [  0  12  84  27  39  47   1]\n",
      " [ 13  15  28  83  50  12   9]\n",
      " [ 23   8  10  53  97   8  11]\n",
      " [  7  15  16  52  27  46  47]\n",
      " [  6   5  31  18   8  29 113]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.36      0.44       210\n",
      "           2       0.49      0.27      0.35       210\n",
      "           3       0.41      0.40      0.40       210\n",
      "           4       0.24      0.40      0.30       210\n",
      "           5       0.32      0.46      0.38       210\n",
      "           6       0.27      0.22      0.24       210\n",
      "           7       0.57      0.54      0.56       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.41      0.38      0.38      1470\n",
      "weighted avg       0.41      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3401360544217687\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[105   3  15  31  29  16  11]\n",
      " [ 24  55  11  45  32  37   6]\n",
      " [  3  12  37  56   3  99   0]\n",
      " [ 38  16   9  81  30  25  11]\n",
      " [ 76   8   5  26  73  13   9]\n",
      " [ 23  15  14  46  19  51  42]\n",
      " [ 19   7  28  15   6  37  98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.50      0.42       210\n",
      "           2       0.47      0.26      0.34       210\n",
      "           3       0.31      0.18      0.22       210\n",
      "           4       0.27      0.39      0.32       210\n",
      "           5       0.38      0.35      0.36       210\n",
      "           6       0.18      0.24      0.21       210\n",
      "           7       0.55      0.47      0.51       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.36      0.34      0.34      1470\n",
      "weighted avg       0.36      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40680272108843535\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[101   7  12  25  42  12  11]\n",
      " [ 20  56  27  41  47  13   6]\n",
      " [  2  33 126  35   6   6   2]\n",
      " [ 21  20  17  70  51  19  12]\n",
      " [ 51   6   7  22 103  10  11]\n",
      " [ 20  22  14  57  21  39  37]\n",
      " [ 12   9  15  16  21  34 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.48      0.46       210\n",
      "           2       0.37      0.27      0.31       210\n",
      "           3       0.58      0.60      0.59       210\n",
      "           4       0.26      0.33      0.29       210\n",
      "           5       0.35      0.49      0.41       210\n",
      "           6       0.29      0.19      0.23       210\n",
      "           7       0.57      0.49      0.53       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.40      1470\n",
      "weighted avg       0.41      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.34217687074829933\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[100   7   5  23  43  26   6]\n",
      " [ 19  56  15  40  59  19   2]\n",
      " [  1  16  32  45  27  88   1]\n",
      " [ 26  20  12  69  52  22   9]\n",
      " [ 56   6   3  22  98  18   7]\n",
      " [ 22  21  13  41  24  51  38]\n",
      " [ 15   8   6  30  22  32  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.48      0.45       210\n",
      "           2       0.42      0.27      0.33       210\n",
      "           3       0.37      0.15      0.22       210\n",
      "           4       0.26      0.33      0.29       210\n",
      "           5       0.30      0.47      0.37       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.61      0.46      0.52       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.37      0.34      0.34      1470\n",
      "weighted avg       0.37      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96  11  15  16  42  19  11]\n",
      " [ 17  56  27  33  57  17   3]\n",
      " [  1  59 123  16   5   5   1]\n",
      " [ 23  23  27  64  46  18   9]\n",
      " [ 50   9   9  25  93  15   9]\n",
      " [ 13  26  25  32  29  50  35]\n",
      " [ 17  10  10  19  25  32  97]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.46      0.45       210\n",
      "           2       0.29      0.27      0.28       210\n",
      "           3       0.52      0.59      0.55       210\n",
      "           4       0.31      0.30      0.31       210\n",
      "           5       0.31      0.44      0.37       210\n",
      "           6       0.32      0.24      0.27       210\n",
      "           7       0.59      0.46      0.52       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.39      1470\n",
      "weighted avg       0.40      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80   5   6  25  61  26   7]\n",
      " [ 13  59  35  37  48  15   3]\n",
      " [  2  36  88  32  46   6   0]\n",
      " [ 23  27  25  53  59  19   4]\n",
      " [ 34  12  14  24 102  20   4]\n",
      " [ 12  20  17  56  24  51  30]\n",
      " [ 11  13  14  44  13  46  69]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.38      0.42       210\n",
      "           2       0.34      0.28      0.31       210\n",
      "           3       0.44      0.42      0.43       210\n",
      "           4       0.20      0.25      0.22       210\n",
      "           5       0.29      0.49      0.36       210\n",
      "           6       0.28      0.24      0.26       210\n",
      "           7       0.59      0.33      0.42       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.37      0.34      0.35      1470\n",
      "weighted avg       0.37      0.34      0.35      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  18  12  24  48  19  14]\n",
      " [ 11  53  29  45  48  20   4]\n",
      " [  2  23 126  43  10   6   0]\n",
      " [ 20  19  21  73  54  14   9]\n",
      " [ 36  14   7  25 108  13   7]\n",
      " [ 15  15  18  56  20  46  40]\n",
      " [  9   4  12  38  16  55  76]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.36      0.40       210\n",
      "           2       0.36      0.25      0.30       210\n",
      "           3       0.56      0.60      0.58       210\n",
      "           4       0.24      0.35      0.28       210\n",
      "           5       0.36      0.51      0.42       210\n",
      "           6       0.27      0.22      0.24       210\n",
      "           7       0.51      0.36      0.42       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.39      0.38      0.38      1470\n",
      "weighted avg       0.39      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37142857142857144\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  11  13  22  65  14   6]\n",
      " [ 15  56  24  40  48  24   3]\n",
      " [  2  54 103  15   7  27   2]\n",
      " [ 16  23  18  70  51  24   8]\n",
      " [ 37   9  11  27 109  12   5]\n",
      " [ 14  21   9  49  32  61  24]\n",
      " [ 16   8   9  16  33  60  68]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.38      0.41       210\n",
      "           2       0.31      0.27      0.29       210\n",
      "           3       0.55      0.49      0.52       210\n",
      "           4       0.29      0.33      0.31       210\n",
      "           5       0.32      0.52      0.39       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.59      0.32      0.42       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.40      0.37      0.37      1470\n",
      "weighted avg       0.40      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36054421768707484\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79   3   9  23  61  19  16]\n",
      " [ 16  57  28  31  56  17   5]\n",
      " [  1  34 102  30  16  25   2]\n",
      " [ 17  24  27  60  54  19   9]\n",
      " [ 35   8  12  25 100  22   8]\n",
      " [ 11  19  25  44  18  59  34]\n",
      " [  4  10   5  15  30  73  73]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.38      0.42       210\n",
      "           2       0.37      0.27      0.31       210\n",
      "           3       0.49      0.49      0.49       210\n",
      "           4       0.26      0.29      0.27       210\n",
      "           5       0.30      0.48      0.37       210\n",
      "           6       0.25      0.28      0.27       210\n",
      "           7       0.50      0.35      0.41       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.36      1470\n",
      "weighted avg       0.38      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35306122448979593\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[81  8  9 31 61 14  6]\n",
      " [22 62 10 38 45 31  2]\n",
      " [ 2 12 92 53 25 25  1]\n",
      " [24 22 18 66 52 17 11]\n",
      " [40 16  7 27 97 20  3]\n",
      " [20 17 15 56 25 53 24]\n",
      " [18  8  8 25 34 49 68]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.39      0.39       210\n",
      "           2       0.43      0.30      0.35       210\n",
      "           3       0.58      0.44      0.50       210\n",
      "           4       0.22      0.31      0.26       210\n",
      "           5       0.29      0.46      0.35       210\n",
      "           6       0.25      0.25      0.25       210\n",
      "           7       0.59      0.32      0.42       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.39      0.35      0.36      1470\n",
      "weighted avg       0.39      0.35      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3551020408163265\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[81  6  9 29 49 22 14]\n",
      " [15 57 14 40 46 30  8]\n",
      " [ 1 24 97 44 11 30  3]\n",
      " [20 25 18 71 48 18 10]\n",
      " [44 14  4 28 91 19 10]\n",
      " [ 6 17 17 55 29 50 36]\n",
      " [ 4 11  3 17 38 62 75]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.39      0.43       210\n",
      "           2       0.37      0.27      0.31       210\n",
      "           3       0.60      0.46      0.52       210\n",
      "           4       0.25      0.34      0.29       210\n",
      "           5       0.29      0.43      0.35       210\n",
      "           6       0.22      0.24      0.23       210\n",
      "           7       0.48      0.36      0.41       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.38      0.36      0.36      1470\n",
      "weighted avg       0.38      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[87  7  7 27 50 18 14]\n",
      " [17 62 18 40 49 18  6]\n",
      " [ 4 22 38 45 86 14  1]\n",
      " [21 21 21 63 63 14  7]\n",
      " [36  9 12 33 92 22  6]\n",
      " [15 22 13 51 36 46 27]\n",
      " [ 9  9  8 41 21 80 42]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.41      0.44       210\n",
      "           2       0.41      0.30      0.34       210\n",
      "           3       0.32      0.18      0.23       210\n",
      "           4       0.21      0.30      0.25       210\n",
      "           5       0.23      0.44      0.30       210\n",
      "           6       0.22      0.22      0.22       210\n",
      "           7       0.41      0.20      0.27       210\n",
      "\n",
      "    accuracy                           0.29      1470\n",
      "   macro avg       0.32      0.29      0.29      1470\n",
      "weighted avg       0.32      0.29      0.29      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4108843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 14   6  71   0  92   0  27]\n",
      " [  0  32  63   3  84   0  28]\n",
      " [  0   5 191   0   9   0   5]\n",
      " [  0   7  40   8 110   0  45]\n",
      " [  0   7   9   0 164   0  30]\n",
      " [  0   5  44   2  37   0 122]\n",
      " [  0   1   1   0  12   1 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.07      0.12       210\n",
      "           2       0.51      0.15      0.23       210\n",
      "           3       0.46      0.91      0.61       210\n",
      "           4       0.62      0.04      0.07       210\n",
      "           5       0.32      0.78      0.46       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.93      0.59       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.48      0.41      0.30      1470\n",
      "weighted avg       0.48      0.41      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 83  18  10   0  80   0  19]\n",
      " [  1 119  21   1  51   2  15]\n",
      " [  3  21 176   0   6   0   4]\n",
      " [  1  38  17  11 114   0  29]\n",
      " [  3  18   3   1 164   0  21]\n",
      " [  3  30  32   2  31   3 109]\n",
      " [  1   4   0   0   8   1 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.40      0.54       210\n",
      "           2       0.48      0.57      0.52       210\n",
      "           3       0.68      0.84      0.75       210\n",
      "           4       0.73      0.05      0.10       210\n",
      "           5       0.36      0.78      0.49       210\n",
      "           6       0.50      0.01      0.03       210\n",
      "           7       0.50      0.93      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.59      0.51      0.44      1470\n",
      "weighted avg       0.59      0.51      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5319727891156463\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98  28   3   1  64   1  15]\n",
      " [  1 152  12   6  26   2  11]\n",
      " [  2  48 154   1   3   0   2]\n",
      " [  5  58  12  21  95   1  18]\n",
      " [  7  24   0   2 164   0  13]\n",
      " [  2  58  22   2  36   3  87]\n",
      " [  0  11   0   0   8   1 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.47      0.60       210\n",
      "           2       0.40      0.72      0.52       210\n",
      "           3       0.76      0.73      0.75       210\n",
      "           4       0.64      0.10      0.17       210\n",
      "           5       0.41      0.78      0.54       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.57      0.90      0.70       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.57      0.53      0.47      1470\n",
      "weighted avg       0.57      0.53      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115  21   2   4  55   2  11]\n",
      " [  1 155  10   8  25   1  10]\n",
      " [  1  50 152   2   3   0   2]\n",
      " [  3  43  13  61  75   4  11]\n",
      " [ 10  22   1   6 157   2  12]\n",
      " [  6  63  16   7  29  18  71]\n",
      " [  0  12   0   0   8   6 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.55      0.66       210\n",
      "           2       0.42      0.74      0.54       210\n",
      "           3       0.78      0.72      0.75       210\n",
      "           4       0.69      0.29      0.41       210\n",
      "           5       0.45      0.75      0.56       210\n",
      "           6       0.55      0.09      0.15       210\n",
      "           7       0.61      0.88      0.72       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.62      0.57      0.54      1470\n",
      "weighted avg       0.62      0.57      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.617687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105  22   2   4  64   7   6]\n",
      " [  1 150   8  14  24   5   8]\n",
      " [  1  36 164   4   4   1   0]\n",
      " [  0  24   9 103  61   7   6]\n",
      " [  3  21   0  13 165   2   6]\n",
      " [  2  42  17  22  32  41  54]\n",
      " [  0   6   0   1  11  12 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.50      0.65       210\n",
      "           2       0.50      0.71      0.59       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.64      0.49      0.56       210\n",
      "           5       0.46      0.79      0.58       210\n",
      "           6       0.55      0.20      0.29       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.66      0.62      0.60      1470\n",
      "weighted avg       0.66      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6360544217687075\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107   9   2   8  69  11   4]\n",
      " [  1 142   8  18  27   9   5]\n",
      " [  0  33 162   7   4   3   1]\n",
      " [  2  20  10 115  50   6   7]\n",
      " [  2  14   1  17 167   4   5]\n",
      " [  3  32  11  18  24  68  54]\n",
      " [  0   5   0   3   5  23 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.51      0.66       210\n",
      "           2       0.56      0.68      0.61       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.62      0.55      0.58       210\n",
      "           5       0.48      0.80      0.60       210\n",
      "           6       0.55      0.32      0.41       210\n",
      "           7       0.70      0.83      0.76       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.67      0.64      0.63      1470\n",
      "weighted avg       0.67      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6523809523809524\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   9   4   8  66  17   0]\n",
      " [  1 141   8  23  21  13   3]\n",
      " [  0  18 174   9   4   4   1]\n",
      " [  1  14   6 129  48   9   3]\n",
      " [  1  15   0  22 165   4   3]\n",
      " [  3  32   5  34  28  76  32]\n",
      " [  0   2   0   7   6  27 168]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.50      0.66       210\n",
      "           2       0.61      0.67      0.64       210\n",
      "           3       0.88      0.83      0.86       210\n",
      "           4       0.56      0.61      0.58       210\n",
      "           5       0.49      0.79      0.60       210\n",
      "           6       0.51      0.36      0.42       210\n",
      "           7       0.80      0.80      0.80       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.65      1470\n",
      "weighted avg       0.68      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   3   2   5  53  20   0]\n",
      " [  1 130   9  34  20  13   3]\n",
      " [  0  16 174   6   7   7   0]\n",
      " [  1  15   7 135  39  12   1]\n",
      " [  5  14   0  14 169   5   3]\n",
      " [  5  23   7  32  20  94  29]\n",
      " [  0   2   0   4   4  41 159]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.60      0.73       210\n",
      "           2       0.64      0.62      0.63       210\n",
      "           3       0.87      0.83      0.85       210\n",
      "           4       0.59      0.64      0.61       210\n",
      "           5       0.54      0.80      0.65       210\n",
      "           6       0.49      0.45      0.47       210\n",
      "           7       0.82      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[114   6   3   9  61  15   2]\n",
      " [  1 145   6  21  22  14   1]\n",
      " [  2  16 174   6   5   6   1]\n",
      " [  0  10   9 128  49  12   2]\n",
      " [  2  12   1  16 171   4   4]\n",
      " [  2  23   9  31  16 106  23]\n",
      " [  1   3   0   5   6  37 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.54      0.69       210\n",
      "           2       0.67      0.69      0.68       210\n",
      "           3       0.86      0.83      0.84       210\n",
      "           4       0.59      0.61      0.60       210\n",
      "           5       0.52      0.81      0.63       210\n",
      "           6       0.55      0.50      0.52       210\n",
      "           7       0.83      0.75      0.79       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.71      0.68      0.68      1470\n",
      "weighted avg       0.71      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[115   7   3  12  58  13   2]\n",
      " [  1 139   4  26  22  16   2]\n",
      " [  0  13 175  10   5   7   0]\n",
      " [  3  11   8 133  42  10   3]\n",
      " [  4  15   1  28 156   3   3]\n",
      " [ 11  22   7  32  14  96  28]\n",
      " [  1   2   0   5   2  47 153]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.55      0.67       210\n",
      "           2       0.67      0.66      0.66       210\n",
      "           3       0.88      0.83      0.86       210\n",
      "           4       0.54      0.63      0.58       210\n",
      "           5       0.52      0.74      0.61       210\n",
      "           6       0.50      0.46      0.48       210\n",
      "           7       0.80      0.73      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6619047619047619\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   4   3   3  57  22   0]\n",
      " [  4 136   9  21  28  10   2]\n",
      " [  1  15 178   8   5   3   0]\n",
      " [  0  11   8 124  49  16   2]\n",
      " [  6  14   2  21 160   4   3]\n",
      " [  7  19   8  32  17 106  21]\n",
      " [  1   3   0   3   6  49 148]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.67      0.65      0.66       210\n",
      "           3       0.86      0.85      0.85       210\n",
      "           4       0.58      0.59      0.59       210\n",
      "           5       0.50      0.76      0.60       210\n",
      "           6       0.50      0.50      0.50       210\n",
      "           7       0.84      0.70      0.77       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.67      1470\n",
      "weighted avg       0.69      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   8   2  10  52  16   2]\n",
      " [  2 138   5  18  24  21   2]\n",
      " [  0  16 178  10   2   4   0]\n",
      " [  1  11   6 134  42  15   1]\n",
      " [  0  12   2  24 164   5   3]\n",
      " [  1  16   6  37  16 119  15]\n",
      " [  0   1   0   3   6  70 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.57      0.72       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.89      0.85      0.87       210\n",
      "           4       0.57      0.64      0.60       210\n",
      "           5       0.54      0.78      0.64       210\n",
      "           6       0.48      0.57      0.52       210\n",
      "           7       0.85      0.62      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.71      0.67      0.68      1470\n",
      "weighted avg       0.71      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   3   4   6  57  14   1]\n",
      " [  3 138   5  29  21  13   1]\n",
      " [  1  14 177   5   4   9   0]\n",
      " [  0  11   7 132  47  13   0]\n",
      " [ 11   9   1  23 158   4   4]\n",
      " [  7  19   5  34  13 113  19]\n",
      " [  1   2   0   2   4  60 141]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.60      0.70       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.89      0.84      0.87       210\n",
      "           4       0.57      0.63      0.60       210\n",
      "           5       0.52      0.75      0.61       210\n",
      "           6       0.50      0.54      0.52       210\n",
      "           7       0.85      0.67      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[118   9   1   7  58  14   3]\n",
      " [  1 142   7  24  23  13   0]\n",
      " [  1  13 178  10   5   3   0]\n",
      " [  2  10   6 134  44  10   4]\n",
      " [  4  20   0  27 151   3   5]\n",
      " [  3  15   7  40  14 106  25]\n",
      " [  2   4   0   4   5  35 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.56      0.69       210\n",
      "           2       0.67      0.68      0.67       210\n",
      "           3       0.89      0.85      0.87       210\n",
      "           4       0.54      0.64      0.59       210\n",
      "           5       0.50      0.72      0.59       210\n",
      "           6       0.58      0.50      0.54       210\n",
      "           7       0.81      0.76      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.70      0.67      0.68      1470\n",
      "weighted avg       0.70      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6775510204081633\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   7   2   9  46  11   2]\n",
      " [  4 141   6  21  22  14   2]\n",
      " [  0  17 177   9   3   3   1]\n",
      " [  3   5  10 140  40   9   3]\n",
      " [ 12  15   2  26 150   2   3]\n",
      " [  9  28   9  22  18 100  24]\n",
      " [  2   3   0  10   5  35 155]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.63      0.71       210\n",
      "           2       0.65      0.67      0.66       210\n",
      "           3       0.86      0.84      0.85       210\n",
      "           4       0.59      0.67      0.63       210\n",
      "           5       0.53      0.71      0.61       210\n",
      "           6       0.57      0.48      0.52       210\n",
      "           7       0.82      0.74      0.78       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   8   2  15  41   9   1]\n",
      " [  2 140   4  30  21  11   2]\n",
      " [  1   9 179   9   7   5   0]\n",
      " [  7  10   5 148  28   8   4]\n",
      " [ 13  13   1  35 142   2   4]\n",
      " [  7  14   8  35   6 117  23]\n",
      " [  2   3   0   3   2  67 133]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.64      0.71       210\n",
      "           2       0.71      0.67      0.69       210\n",
      "           3       0.90      0.85      0.88       210\n",
      "           4       0.54      0.70      0.61       210\n",
      "           5       0.57      0.68      0.62       210\n",
      "           6       0.53      0.56      0.55       210\n",
      "           7       0.80      0.63      0.71       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   9   2  13  36  11   2]\n",
      " [  2 140   7  26  18  15   2]\n",
      " [  1  18 174  11   3   2   1]\n",
      " [  3   8   4 153  26  13   3]\n",
      " [ 19  13   3  39 129   4   3]\n",
      " [ 11  21   4  34   9 108  23]\n",
      " [  2   4   0   7   5  56 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71       210\n",
      "           2       0.66      0.67      0.66       210\n",
      "           3       0.90      0.83      0.86       210\n",
      "           4       0.54      0.73      0.62       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.52      0.51      0.52       210\n",
      "           7       0.80      0.65      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6578231292517007\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   6   2  13  40  16   1]\n",
      " [  5 145   8  22  16  12   2]\n",
      " [  1  19 164  16   2   8   0]\n",
      " [  5  12   6 146  27  12   2]\n",
      " [ 17  16   2  36 131   6   2]\n",
      " [ 10  25   7  29  11 115  13]\n",
      " [  2   5   0   5   5  59 134]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.63      0.69       210\n",
      "           2       0.64      0.69      0.66       210\n",
      "           3       0.87      0.78      0.82       210\n",
      "           4       0.55      0.70      0.61       210\n",
      "           5       0.56      0.62      0.59       210\n",
      "           6       0.50      0.55      0.53       210\n",
      "           7       0.87      0.64      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   5   4  11  36  12   1]\n",
      " [  3 140   7  28  17  13   2]\n",
      " [  1  14 171  17   1   6   0]\n",
      " [  4  10   7 142  33  12   2]\n",
      " [ 19  16   2  42 121   7   3]\n",
      " [  5  23   6  30  12 119  15]\n",
      " [  1   2   0   7   3  61 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.67      0.73       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.87      0.81      0.84       210\n",
      "           4       0.51      0.68      0.58       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.52      0.57      0.54       210\n",
      "           7       0.86      0.65      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6537414965986394\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   4  10  42  12   2]\n",
      " [  3 136   7  25  23  15   1]\n",
      " [  1  14 177  12   3   3   0]\n",
      " [  2  10   6 138  40  12   2]\n",
      " [ 23  12   1  39 126   6   3]\n",
      " [  7  25   6  28  16 114  14]\n",
      " [  1   4   0   2   6  62 135]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.64      0.71       210\n",
      "           2       0.66      0.65      0.65       210\n",
      "           3       0.88      0.84      0.86       210\n",
      "           4       0.54      0.66      0.59       210\n",
      "           5       0.49      0.60      0.54       210\n",
      "           6       0.51      0.54      0.53       210\n",
      "           7       0.86      0.64      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.68      0.65      0.66      1470\n",
      "weighted avg       0.68      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 99   7  25   2  55   9  13]\n",
      " [  4 109  32  12  35   8  10]\n",
      " [  2  23 167   6  10   2   0]\n",
      " [  7  19  18  77  58  10  21]\n",
      " [ 25  13   2   7 142   5  16]\n",
      " [ 10  27  32  17  27  40  57]\n",
      " [  0  14   0   9  14  28 145]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.47      0.55       210\n",
      "           2       0.51      0.52      0.52       210\n",
      "           3       0.61      0.80      0.69       210\n",
      "           4       0.59      0.37      0.45       210\n",
      "           5       0.42      0.68      0.52       210\n",
      "           6       0.39      0.19      0.26       210\n",
      "           7       0.55      0.69      0.61       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.51      1470\n",
      "weighted avg       0.54      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# V BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//bert_vectorized_Nisha_dataset_vbert.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[182   1   0   4   5   7  11]\n",
      " [ 12 112   6  30  17  25   8]\n",
      " [  1   0 197   2   2   7   1]\n",
      " [  6   3   7 158   9  12  15]\n",
      " [ 61   4   1  48  85   4   7]\n",
      " [ 16   7   9  22   4  75  77]\n",
      " [  2   0   0   0   1   2 205]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.87      0.74       210\n",
      "           2       0.88      0.53      0.66       210\n",
      "           3       0.90      0.94      0.92       210\n",
      "           4       0.60      0.75      0.67       210\n",
      "           5       0.69      0.40      0.51       210\n",
      "           6       0.57      0.36      0.44       210\n",
      "           7       0.63      0.98      0.77       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.67      1470\n",
      "weighted avg       0.70      0.69      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[148   4  11   3  30   4  10]\n",
      " [ 11 165   8   8  14   4   0]\n",
      " [  5   4 195   0   2   4   0]\n",
      " [ 35  19  20 108  21   5   2]\n",
      " [ 59  38   8  18  79   2   6]\n",
      " [ 40  24  25  25  25  40  31]\n",
      " [ 16   2   3   6  13  14 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.70      0.56       210\n",
      "           2       0.64      0.79      0.71       210\n",
      "           3       0.72      0.93      0.81       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.43      0.38      0.40       210\n",
      "           6       0.55      0.19      0.28       210\n",
      "           7       0.76      0.74      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.60      0.61      0.58      1470\n",
      "weighted avg       0.60      0.61      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6183673469387755\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[150   5  11   4  27   5   8]\n",
      " [  8 163  12   7  14   4   2]\n",
      " [  5   4 193   1   3   4   0]\n",
      " [ 25  14  23 113  24   7   4]\n",
      " [ 48  39   7  28  79   2   7]\n",
      " [ 40  24  25  20  20  47  34]\n",
      " [  7   1   2   5  13  18 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.71      0.61       210\n",
      "           2       0.65      0.78      0.71       210\n",
      "           3       0.71      0.92      0.80       210\n",
      "           4       0.63      0.54      0.58       210\n",
      "           5       0.44      0.38      0.41       210\n",
      "           6       0.54      0.22      0.32       210\n",
      "           7       0.75      0.78      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.61      0.62      0.60      1470\n",
      "weighted avg       0.61      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.617687074829932\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[151   5  12   4  26   3   9]\n",
      " [  7 164  14   9  11   2   3]\n",
      " [  3   5 195   2   3   2   0]\n",
      " [ 27  11  23 113  25   8   3]\n",
      " [ 47  41   9  28  77   3   5]\n",
      " [ 34  27  30  18  21  42  38]\n",
      " [  7   0   2   2  14  19 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.72      0.62       210\n",
      "           2       0.65      0.78      0.71       210\n",
      "           3       0.68      0.93      0.79       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.44      0.37      0.40       210\n",
      "           6       0.53      0.20      0.29       210\n",
      "           7       0.74      0.79      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.60      0.62      0.59      1470\n",
      "weighted avg       0.60      0.62      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   6   8   5  26   4   8]\n",
      " [  8 160  13   9  15   3   2]\n",
      " [  2   5 196   2   3   2   0]\n",
      " [ 22  12  27 116  24   6   3]\n",
      " [ 50  39   8  24  83   3   3]\n",
      " [ 39  28  26  19  20  39  39]\n",
      " [  7   0   3   5  11  16 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.73      0.62       210\n",
      "           2       0.64      0.76      0.70       210\n",
      "           3       0.70      0.93      0.80       210\n",
      "           4       0.64      0.55      0.59       210\n",
      "           5       0.46      0.40      0.42       210\n",
      "           6       0.53      0.19      0.28       210\n",
      "           7       0.75      0.80      0.78       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.61      0.62      0.60      1470\n",
      "weighted avg       0.61      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[154   6   7   4  28   3   8]\n",
      " [  6 160  14   7  17   3   3]\n",
      " [  4   5 194   2   3   2   0]\n",
      " [ 20  13  29 112  26   6   4]\n",
      " [ 49  35   9  21  90   1   5]\n",
      " [ 41  26  30  18  17  38  40]\n",
      " [  7   0   4   5  12  14 168]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.73      0.63       210\n",
      "           2       0.65      0.76      0.70       210\n",
      "           3       0.68      0.92      0.78       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.47      0.43      0.45       210\n",
      "           6       0.57      0.18      0.27       210\n",
      "           7       0.74      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.60      1470\n",
      "weighted avg       0.62      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6333333333333333\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   6   8   3  28   4   8]\n",
      " [  9 161  13   8  14   3   2]\n",
      " [  2   5 198   1   2   2   0]\n",
      " [ 14  11  28 117  28   8   4]\n",
      " [ 48  32   9  23  93   0   5]\n",
      " [ 41  25  32  10  19  39  44]\n",
      " [  5   1   4   4  10  16 170]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.73      0.63       210\n",
      "           2       0.67      0.77      0.71       210\n",
      "           3       0.68      0.94      0.79       210\n",
      "           4       0.70      0.56      0.62       210\n",
      "           5       0.48      0.44      0.46       210\n",
      "           6       0.54      0.19      0.28       210\n",
      "           7       0.73      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.62      0.63      0.61      1470\n",
      "weighted avg       0.62      0.63      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5612244897959183\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 99   2  13  12  18  56  10]\n",
      " [  0 118   4  26   9  49   4]\n",
      " [ 19   5 144  19   0  23   0]\n",
      " [  3  11   2 117   9  53  15]\n",
      " [ 18  13   1  36  97  26  19]\n",
      " [  7  10   5  30   1 117  40]\n",
      " [  0   0   0   3   2  72 133]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.47      0.56       210\n",
      "           2       0.74      0.56      0.64       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.48      0.56      0.52       210\n",
      "           5       0.71      0.46      0.56       210\n",
      "           6       0.30      0.56      0.39       210\n",
      "           7       0.60      0.63      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.62      0.56      0.58      1470\n",
      "weighted avg       0.62      0.56      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.19319727891156463\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 14   1   1   5 181   5   3]\n",
      " [  1  12   0   9 172   9   7]\n",
      " [  1   2  34   4 159   7   3]\n",
      " [  5   6   3  16 162  12   6]\n",
      " [  8  12   3  10 171   3   3]\n",
      " [  8   5   1  13 153  19  11]\n",
      " [  5   6   2   3 161  15  18]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.07      0.11       210\n",
      "           2       0.27      0.06      0.09       210\n",
      "           3       0.77      0.16      0.27       210\n",
      "           4       0.27      0.08      0.12       210\n",
      "           5       0.15      0.81      0.25       210\n",
      "           6       0.27      0.09      0.14       210\n",
      "           7       0.35      0.09      0.14       210\n",
      "\n",
      "    accuracy                           0.19      1470\n",
      "   macro avg       0.35      0.19      0.16      1470\n",
      "weighted avg       0.35      0.19      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6755102040816326\n",
      "Confusion Matrix of SVM is:\n",
      " [[183   3   0   1   7  11   5]\n",
      " [ 15 131   7  29  12  13   3]\n",
      " [  0   4 198   3   1   4   0]\n",
      " [ 27   5   5 150   4  12   7]\n",
      " [ 81   8   2  48  61   4   6]\n",
      " [ 21  13   9  32   3  87  45]\n",
      " [  1   1   0   3   1  21 183]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.87      0.68       210\n",
      "           2       0.79      0.62      0.70       210\n",
      "           3       0.90      0.94      0.92       210\n",
      "           4       0.56      0.71      0.63       210\n",
      "           5       0.69      0.29      0.41       210\n",
      "           6       0.57      0.41      0.48       210\n",
      "           7       0.73      0.87      0.80       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.66      1470\n",
      "weighted avg       0.69      0.68      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.7210884353741497\n",
      "Confusion Matrix of SVM is:\n",
      " [[174   1   0   1  16  14   4]\n",
      " [  6 151   6  14   7  25   1]\n",
      " [  0   3 200   2   1   4   0]\n",
      " [  9  10   6 147   8  23   7]\n",
      " [ 53  11   1  40  91   7   7]\n",
      " [ 13  13  12  20   4 118  30]\n",
      " [  2   0   0   2   1  26 179]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.83      0.75       210\n",
      "           2       0.80      0.72      0.76       210\n",
      "           3       0.89      0.95      0.92       210\n",
      "           4       0.65      0.70      0.67       210\n",
      "           5       0.71      0.43      0.54       210\n",
      "           6       0.54      0.56      0.55       210\n",
      "           7       0.79      0.85      0.82       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.71      1470\n",
      "weighted avg       0.72      0.72      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7346938775510204\n",
      "Confusion Matrix of SVM is:\n",
      " [[142   2   1   2  18  44   1]\n",
      " [  1 158   4   6   4  37   0]\n",
      " [  0   1 195   4   1   9   0]\n",
      " [  1   6   4 141  14  39   5]\n",
      " [ 27  15   1  30 108  24   5]\n",
      " [  2   6   0   9   1 167  25]\n",
      " [  0   0   0   0   1  40 169]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.68      0.74       210\n",
      "           2       0.84      0.75      0.79       210\n",
      "           3       0.95      0.93      0.94       210\n",
      "           4       0.73      0.67      0.70       210\n",
      "           5       0.73      0.51      0.61       210\n",
      "           6       0.46      0.80      0.59       210\n",
      "           7       0.82      0.80      0.81       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.77      0.73      0.74      1470\n",
      "weighted avg       0.77      0.73      0.74      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.38231292517006804\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 68   2  92   0   9   1  38]\n",
      " [  1  36 137   1   8   2  25]\n",
      " [  1   0 208   0   0   0   1]\n",
      " [ 15  10  96  17  17   2  53]\n",
      " [ 35  15  54   3  58   1  44]\n",
      " [  8   2  90   1   0   5 104]\n",
      " [  0   1  37   0   2   0 170]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.32      0.40       210\n",
      "           2       0.55      0.17      0.26       210\n",
      "           3       0.29      0.99      0.45       210\n",
      "           4       0.77      0.08      0.15       210\n",
      "           5       0.62      0.28      0.38       210\n",
      "           6       0.45      0.02      0.05       210\n",
      "           7       0.39      0.81      0.53       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.51      0.38      0.32      1470\n",
      "weighted avg       0.51      0.38      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22925170068027212\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0 200   0   0]\n",
      " [  0   0  10   0 200   0   0]\n",
      " [  0   0 129   0  81   0   0]\n",
      " [  0   0  15   0 195   0   0]\n",
      " [  0   0   2   0 208   0   0]\n",
      " [  0   0  11   0 199   0   0]\n",
      " [  0   0   9   0 201   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.69      0.61      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      0.99      0.28       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.12      0.23      0.13      1470\n",
      "weighted avg       0.12      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3224489795918367\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  10   0 154   0  46]\n",
      " [  0   0  10   0 160   0  40]\n",
      " [  0   0 129   0  64   0  17]\n",
      " [  0   0  15   0 131   0  64]\n",
      " [  0   0   2   0 177   0  31]\n",
      " [  0   0  11   0  96   0 103]\n",
      " [  0   0   9   0  33   0 168]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.69      0.61      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.22      0.84      0.35       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      0.80      0.49       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.18      0.32      0.21      1470\n",
      "weighted avg       0.18      0.32      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3619047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  96   7   0   0  22  24]\n",
      " [  0 160   6   4   0  27  13]\n",
      " [  1  63 105  24   0  15   2]\n",
      " [  6 125  11   4   0  37  27]\n",
      " [ 13 164   1   1   0  12  19]\n",
      " [  8  88  11   0   0  63  40]\n",
      " [  8  31   3   0   0  29 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.29      0.40       210\n",
      "           2       0.22      0.76      0.34       210\n",
      "           3       0.73      0.50      0.59       210\n",
      "           4       0.12      0.02      0.03       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.31      0.30      0.30       210\n",
      "           7       0.53      0.66      0.59       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.36      0.36      0.32      1470\n",
      "weighted avg       0.36      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4306122448979592\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  25   3   9  74  19  19]\n",
      " [  0 104   6   2  67  19  12]\n",
      " [  3  43  98  20  38   7   1]\n",
      " [  6  27   7  17 107  30  16]\n",
      " [ 14  16   0   4 149  12  15]\n",
      " [  8  18   7   7  71  62  37]\n",
      " [  2   2   2   4  29  29 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.29      0.40       210\n",
      "           2       0.44      0.50      0.47       210\n",
      "           3       0.80      0.47      0.59       210\n",
      "           4       0.27      0.08      0.12       210\n",
      "           5       0.28      0.71      0.40       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.59      0.68      0.63       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.48      0.43      0.42      1470\n",
      "weighted avg       0.48      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43605442176870746\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 53  16   5  48  47  22  19]\n",
      " [  0  73   8  62  43  12  12]\n",
      " [  3  15 105  61  19   6   1]\n",
      " [  2  12   8  92  59  21  16]\n",
      " [ 11   5   0  49 123   7  15]\n",
      " [  6  13   2  72  24  56  37]\n",
      " [  2   3   1  21  18  26 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.25      0.37       210\n",
      "           2       0.53      0.35      0.42       210\n",
      "           3       0.81      0.50      0.62       210\n",
      "           4       0.23      0.44      0.30       210\n",
      "           5       0.37      0.59      0.45       210\n",
      "           6       0.37      0.27      0.31       210\n",
      "           7       0.58      0.66      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.51      0.44      0.44      1470\n",
      "weighted avg       0.51      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44829931972789117\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 54  16   7  15  43  47  28]\n",
      " [  1  76  18  17  43  41  14]\n",
      " [  1  13 130  12  14  36   4]\n",
      " [  2   7  12  47  56  61  25]\n",
      " [ 10   5   4  15 124  37  15]\n",
      " [  6   9   8  17  25  78  67]\n",
      " [  3   3   0   7  16  31 150]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.26      0.38       210\n",
      "           2       0.59      0.36      0.45       210\n",
      "           3       0.73      0.62      0.67       210\n",
      "           4       0.36      0.22      0.28       210\n",
      "           5       0.39      0.59      0.47       210\n",
      "           6       0.24      0.37      0.29       210\n",
      "           7       0.50      0.71      0.58       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.50      0.45      0.44      1470\n",
      "weighted avg       0.50      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 52  19   3  16  65  32  23]\n",
      " [  2  80  10  17  63  28  10]\n",
      " [  0  16 110  31  36  12   5]\n",
      " [  5  12   6  53  90  27  17]\n",
      " [  8  10   4  11 148  23   6]\n",
      " [  7   9   4  22  53  68  47]\n",
      " [  6   4   0   9  27  32 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.25      0.36       210\n",
      "           2       0.53      0.38      0.44       210\n",
      "           3       0.80      0.52      0.63       210\n",
      "           4       0.33      0.25      0.29       210\n",
      "           5       0.31      0.70      0.43       210\n",
      "           6       0.31      0.32      0.31       210\n",
      "           7       0.55      0.63      0.59       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.50      0.44      0.44      1470\n",
      "weighted avg       0.50      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 56  16   3  41  37  33  24]\n",
      " [  6  88  11  35  28  31  11]\n",
      " [  5  19  69  37  13  61   6]\n",
      " [  6  24   7  88  47  21  17]\n",
      " [ 10  15   2  38 120  16   9]\n",
      " [ 11  23   4  49  15  63  45]\n",
      " [  7   7   0  22  13  24 137]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.27      0.36       210\n",
      "           2       0.46      0.42      0.44       210\n",
      "           3       0.72      0.33      0.45       210\n",
      "           4       0.28      0.42      0.34       210\n",
      "           5       0.44      0.57      0.50       210\n",
      "           6       0.25      0.30      0.27       210\n",
      "           7       0.55      0.65      0.60       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.47      0.42      0.42      1470\n",
      "weighted avg       0.47      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 58  16  13  43  35  17  28]\n",
      " [  8  97  13  42  17  16  17]\n",
      " [  4  26 116  37   8  11   8]\n",
      " [ 12  26   6  86  43  17  20]\n",
      " [ 22  10   3  60  92   9  14]\n",
      " [ 14  23   6  49  12  49  57]\n",
      " [  6   6   1  23  13  23 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.28      0.35       210\n",
      "           2       0.48      0.46      0.47       210\n",
      "           3       0.73      0.55      0.63       210\n",
      "           4       0.25      0.41      0.31       210\n",
      "           5       0.42      0.44      0.43       210\n",
      "           6       0.35      0.23      0.28       210\n",
      "           7       0.49      0.66      0.56       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.43      1470\n",
      "weighted avg       0.45      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 61  15  14  32  33  34  21]\n",
      " [ 13  80  13  47  17  23  17]\n",
      " [  9  14  68  39  12  59   9]\n",
      " [  7  28   4  91  37  26  17]\n",
      " [ 25  12   3  55  83  23   9]\n",
      " [ 12  17   7  43  11  70  50]\n",
      " [  9   3   1  25  10  36 126]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.29      0.35       210\n",
      "           2       0.47      0.38      0.42       210\n",
      "           3       0.62      0.32      0.43       210\n",
      "           4       0.27      0.43      0.34       210\n",
      "           5       0.41      0.40      0.40       210\n",
      "           6       0.26      0.33      0.29       210\n",
      "           7       0.51      0.60      0.55       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.43      0.39      0.40      1470\n",
      "weighted avg       0.43      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60  15   7  31  44  33  20]\n",
      " [ 12  62   9  33  53  29  12]\n",
      " [  1  25 114  30  19  14   7]\n",
      " [  9  23   4  81  49  29  15]\n",
      " [ 15  16   4  33 106  28   8]\n",
      " [  9  17   9  39  27  68  41]\n",
      " [  9   6   2  17  20  36 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.29      0.37       210\n",
      "           2       0.38      0.30      0.33       210\n",
      "           3       0.77      0.54      0.64       210\n",
      "           4       0.31      0.39      0.34       210\n",
      "           5       0.33      0.50      0.40       210\n",
      "           6       0.29      0.32      0.30       210\n",
      "           7       0.54      0.57      0.55       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.45      0.42      0.42      1470\n",
      "weighted avg       0.45      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  23  17  27  21  29  18]\n",
      " [ 28  88  13  22  19  26  14]\n",
      " [ 19  14 122  25  14   8   8]\n",
      " [ 17  25  11  74  37  32  14]\n",
      " [ 33  37   4  33  72  23   8]\n",
      " [ 14  20  11  33  20  65  47]\n",
      " [ 15   5   4  16  13  34 123]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.36      0.36       210\n",
      "           2       0.42      0.42      0.42       210\n",
      "           3       0.67      0.58      0.62       210\n",
      "           4       0.32      0.35      0.34       210\n",
      "           5       0.37      0.34      0.35       210\n",
      "           6       0.30      0.31      0.30       210\n",
      "           7       0.53      0.59      0.56       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  17  18  24  29  24  20]\n",
      " [ 21  88  17  30  16  23  15]\n",
      " [ 13  33 122  27   3   8   4]\n",
      " [ 18  30   9  76  31  29  17]\n",
      " [ 35  24   6  35  74  25  11]\n",
      " [ 24  20  10  32  13  68  43]\n",
      " [ 12   7   4  19  12  38 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.37      0.38       210\n",
      "           2       0.40      0.42      0.41       210\n",
      "           3       0.66      0.58      0.62       210\n",
      "           4       0.31      0.36      0.34       210\n",
      "           5       0.42      0.35      0.38       210\n",
      "           6       0.32      0.32      0.32       210\n",
      "           7       0.52      0.56      0.54       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.43      1470\n",
      "weighted avg       0.43      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42108843537414964\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  15  13  25  27  34  26]\n",
      " [ 14  92  12  31  19  26  16]\n",
      " [  3  22 130  24  11  10  10]\n",
      " [  8  32   9  84  28  27  22]\n",
      " [ 34  24   5  33  74  29  11]\n",
      " [ 16  22   9  31  23  60  49]\n",
      " [ 17   4   5  25  17  33 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.33      0.38       210\n",
      "           2       0.44      0.44      0.44       210\n",
      "           3       0.71      0.62      0.66       210\n",
      "           4       0.33      0.40      0.36       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.45      0.52      0.48       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41836734693877553\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  22  18  24  23  26  21]\n",
      " [ 17  87  20  23  28  21  14]\n",
      " [ 10  10 128  29  14  10   9]\n",
      " [ 13  27  13  81  35  25  16]\n",
      " [ 34  27   5  32  76  27   9]\n",
      " [ 15  25   7  39  25  56  43]\n",
      " [ 14   7   5  20  19  34 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.36      0.39       210\n",
      "           2       0.42      0.41      0.42       210\n",
      "           3       0.65      0.61      0.63       210\n",
      "           4       0.33      0.39      0.35       210\n",
      "           5       0.35      0.36      0.35       210\n",
      "           6       0.28      0.27      0.27       210\n",
      "           7       0.50      0.53      0.51       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 70  19  11  19  28  44  19]\n",
      " [ 18  82  11  28  24  31  16]\n",
      " [ 11  17 119  31  12  16   4]\n",
      " [ 15  37  10  75  33  22  18]\n",
      " [ 33  30   5  30  74  29   9]\n",
      " [ 22  18  10  35  19  65  41]\n",
      " [ 14   6   7  12  22  34 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.33      0.36       210\n",
      "           2       0.39      0.39      0.39       210\n",
      "           3       0.69      0.57      0.62       210\n",
      "           4       0.33      0.36      0.34       210\n",
      "           5       0.35      0.35      0.35       210\n",
      "           6       0.27      0.31      0.29       210\n",
      "           7       0.52      0.55      0.53       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4197278911564626\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  12  19  30  24  27  17]\n",
      " [ 26  89  11  28  19  19  18]\n",
      " [  8  23 124  23  11  10  11]\n",
      " [ 13  38  11  78  30  21  19]\n",
      " [ 31  25   5  34  77  27  11]\n",
      " [ 20  19  13  31  23  59  45]\n",
      " [ 16   9   4  11  22  39 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.39      0.40       210\n",
      "           2       0.41      0.42      0.42       210\n",
      "           3       0.66      0.59      0.62       210\n",
      "           4       0.33      0.37      0.35       210\n",
      "           5       0.37      0.37      0.37       210\n",
      "           6       0.29      0.28      0.29       210\n",
      "           7       0.47      0.52      0.50       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37482993197278913\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 90  16  11  28  17  32  16]\n",
      " [ 17  58  13  36  52  20  14]\n",
      " [  4  23 112  37  12  14   8]\n",
      " [  9  39   9  79  32  25  17]\n",
      " [ 45  28   6  48  45  28  10]\n",
      " [ 13  18  11  42  24  57  45]\n",
      " [ 12   4   6  17  24  37 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.43      0.45       210\n",
      "           2       0.31      0.28      0.29       210\n",
      "           3       0.67      0.53      0.59       210\n",
      "           4       0.28      0.38      0.32       210\n",
      "           5       0.22      0.21      0.22       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.38      1470\n",
      "weighted avg       0.39      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.35714285714285715\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  18  19  25  20  26  23]\n",
      " [ 15  87  10  32  20  24  22]\n",
      " [ 11  11  67  40  16  59   6]\n",
      " [ 20  24   8  83  30  25  20]\n",
      " [ 54  22   7  45  43  27  12]\n",
      " [ 25  14  10  39  19  63  40]\n",
      " [ 11   3   7  20  21  45 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.38      0.37       210\n",
      "           2       0.49      0.41      0.45       210\n",
      "           3       0.52      0.32      0.40       210\n",
      "           4       0.29      0.40      0.34       210\n",
      "           5       0.25      0.20      0.23       210\n",
      "           6       0.23      0.30      0.26       210\n",
      "           7       0.46      0.49      0.47       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.36      1470\n",
      "weighted avg       0.37      0.36      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40272108843537413\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  16  19  25  20  32  18]\n",
      " [ 27  84  11  31  17  23  17]\n",
      " [  6  17 121  26  16  10  14]\n",
      " [ 18  26   7  85  29  26  19]\n",
      " [ 49  25   8  43  47  31   7]\n",
      " [ 25  18  11  31  18  65  42]\n",
      " [ 12   2   4  20  24  38 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.38      0.37       210\n",
      "           2       0.45      0.40      0.42       210\n",
      "           3       0.67      0.58      0.62       210\n",
      "           4       0.33      0.40      0.36       210\n",
      "           5       0.27      0.22      0.25       210\n",
      "           6       0.29      0.31      0.30       210\n",
      "           7       0.48      0.52      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 58   3  41   2  56   1  49]\n",
      " [ 13  32  57   4  59   3  42]\n",
      " [  6   2 193   0   4   1   4]\n",
      " [ 16   4  40  20  58   2  70]\n",
      " [ 18   3   9   3 135   0  42]\n",
      " [ 11   3  54   2  21   2 117]\n",
      " [  1   1  12   0   9   1 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.28      0.35       210\n",
      "           2       0.67      0.15      0.25       210\n",
      "           3       0.48      0.92      0.63       210\n",
      "           4       0.65      0.10      0.17       210\n",
      "           5       0.39      0.64      0.49       210\n",
      "           6       0.20      0.01      0.02       210\n",
      "           7       0.36      0.89      0.52       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.34      1470\n",
      "weighted avg       0.46      0.43      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.49523809523809526\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96   5  14   0  33   5  57]\n",
      " [  3 108  20   0  36   6  37]\n",
      " [ 12   9 168   2   4   8   7]\n",
      " [ 23  14  15  17  74   5  62]\n",
      " [ 17  13   2   3 126   0  49]\n",
      " [ 21  13  12   5  11   9 139]\n",
      " [  1   0   1   0   4   0 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.46      0.50       210\n",
      "           2       0.67      0.51      0.58       210\n",
      "           3       0.72      0.80      0.76       210\n",
      "           4       0.63      0.08      0.14       210\n",
      "           5       0.44      0.60      0.51       210\n",
      "           6       0.27      0.04      0.07       210\n",
      "           7       0.37      0.97      0.53       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.52      0.50      0.44      1470\n",
      "weighted avg       0.52      0.50      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   4   1   0  23   6  44]\n",
      " [  5 129   9   2  26   6  33]\n",
      " [  6  15 169   5   5   7   3]\n",
      " [ 18  20  11  34  62   5  60]\n",
      " [ 22  14   1   5 120   2  46]\n",
      " [ 19  13   9  14   7  16 132]\n",
      " [  0   2   1   0   4   2 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.63      0.64       210\n",
      "           2       0.65      0.61      0.63       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.57      0.16      0.25       210\n",
      "           5       0.49      0.57      0.53       210\n",
      "           6       0.36      0.08      0.13       210\n",
      "           7       0.39      0.96      0.55       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.51      1470\n",
      "weighted avg       0.56      0.54      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   5   0   2  23   8  36]\n",
      " [  1 127  11  11  24  14  22]\n",
      " [  3   6 177  11   2   9   2]\n",
      " [ 13  16   7  65  46  15  48]\n",
      " [ 25  13   1  10 122   5  34]\n",
      " [ 19  14  10  19   6  31 111]\n",
      " [  0   1   0   0   3   2 204]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67       210\n",
      "           2       0.70      0.60      0.65       210\n",
      "           3       0.86      0.84      0.85       210\n",
      "           4       0.55      0.31      0.40       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.37      0.15      0.21       210\n",
      "           7       0.45      0.97      0.61       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.56      1470\n",
      "weighted avg       0.59      0.59      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6244897959183674\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   1   1  26  19  27]\n",
      " [  1 138   8  10  22  17  14]\n",
      " [  1   1 182  13   2  10   1]\n",
      " [  6  14   8  91  29  34  28]\n",
      " [ 23  13   1  13 121  12  27]\n",
      " [ 17  13   8  21   6  55  90]\n",
      " [  0   0   0   2   3   5 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.62      0.67       210\n",
      "           2       0.75      0.66      0.70       210\n",
      "           3       0.88      0.87      0.87       210\n",
      "           4       0.60      0.43      0.50       210\n",
      "           5       0.58      0.58      0.58       210\n",
      "           6       0.36      0.26      0.30       210\n",
      "           7       0.52      0.95      0.67       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.61      1470\n",
      "weighted avg       0.63      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6469387755102041\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   3   1   8  25  21  21]\n",
      " [  1 139   3  14  22  26   5]\n",
      " [  0   2 182  11   3  11   1]\n",
      " [  1   9   9 105  25  38  23]\n",
      " [ 18  14   1  16 118  24  19]\n",
      " [  9  10   8  26   7  82  68]\n",
      " [  0   0   0   1   4  11 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.71       210\n",
      "           2       0.79      0.66      0.72       210\n",
      "           3       0.89      0.87      0.88       210\n",
      "           4       0.58      0.50      0.54       210\n",
      "           5       0.58      0.56      0.57       210\n",
      "           6       0.38      0.39      0.39       210\n",
      "           7       0.59      0.92      0.72       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   4   0   3  30  26  18]\n",
      " [  1 139   5  12  24  24   5]\n",
      " [  0   4 182   9   5  10   0]\n",
      " [  1   9   7 107  31  41  14]\n",
      " [ 14  12   1  18 130  19  16]\n",
      " [  7  10   6  20  10  88  69]\n",
      " [  0   1   0   1   2  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.61      0.71       210\n",
      "           2       0.78      0.66      0.71       210\n",
      "           3       0.91      0.87      0.89       210\n",
      "           4       0.63      0.51      0.56       210\n",
      "           5       0.56      0.62      0.59       210\n",
      "           6       0.39      0.42      0.40       210\n",
      "           7       0.61      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.66      1470\n",
      "weighted avg       0.67      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   1   6  24  24  17]\n",
      " [  1 143   5  12  17  28   4]\n",
      " [  3   2 185  12   1   7   0]\n",
      " [  2   7   4 117  28  37  15]\n",
      " [ 17  14   1  25 117  21  15]\n",
      " [ 11  12   3  25   5  90  64]\n",
      " [  0   0   0   2   2  15 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.64      0.71       210\n",
      "           2       0.79      0.68      0.73       210\n",
      "           3       0.93      0.88      0.90       210\n",
      "           4       0.59      0.56      0.57       210\n",
      "           5       0.60      0.56      0.58       210\n",
      "           6       0.41      0.43      0.42       210\n",
      "           7       0.62      0.91      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.66      1470\n",
      "weighted avg       0.68      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   3   2   2  24  31  15]\n",
      " [  1 130   3  16  21  32   7]\n",
      " [  1   4 182  15   2   5   1]\n",
      " [  2   7   5 115  32  31  18]\n",
      " [ 18  13   1  24 120  20  14]\n",
      " [ 11   9   5  24   7  90  64]\n",
      " [  1   0   0   1   1  22 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.63      0.71       210\n",
      "           2       0.78      0.62      0.69       210\n",
      "           3       0.92      0.87      0.89       210\n",
      "           4       0.58      0.55      0.57       210\n",
      "           5       0.58      0.57      0.58       210\n",
      "           6       0.39      0.43      0.41       210\n",
      "           7       0.61      0.88      0.72       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.65      1470\n",
      "weighted avg       0.67      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6646258503401361\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   5   0   5  24  25  15]\n",
      " [  2 142   4  14  19  24   5]\n",
      " [  0   5 180  13   3   9   0]\n",
      " [  4   8   8 117  24  37  12]\n",
      " [ 18  13   1  25 124  14  15]\n",
      " [  6  14   3  20   7  98  62]\n",
      " [  0   2   0   1   2  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.65      0.72       210\n",
      "           2       0.75      0.68      0.71       210\n",
      "           3       0.92      0.86      0.89       210\n",
      "           4       0.60      0.56      0.58       210\n",
      "           5       0.61      0.59      0.60       210\n",
      "           6       0.42      0.47      0.44       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.68      0.66      0.67      1470\n",
      "weighted avg       0.68      0.66      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.654421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   1   2   5  26  34  11]\n",
      " [  1 141   4  14  21  26   3]\n",
      " [  0   4 183   8   5  10   0]\n",
      " [  8  10   6 111  27  37  11]\n",
      " [ 16  14   0  27 124  19  10]\n",
      " [ 10  13   6  18  12 100  51]\n",
      " [  1   1   0   3   3  30 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.62      0.69       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.91      0.87      0.89       210\n",
      "           4       0.60      0.53      0.56       210\n",
      "           5       0.57      0.59      0.58       210\n",
      "           6       0.39      0.48      0.43       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.67      0.65      0.66      1470\n",
      "weighted avg       0.67      0.65      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   4   3   4  30  32   8]\n",
      " [  1 141   3  14  19  30   2]\n",
      " [  0   3 187  10   3   7   0]\n",
      " [  4   5   5 115  31  41   9]\n",
      " [ 14  10   1  25 127  26   7]\n",
      " [  7  13   4  21   4 114  47]\n",
      " [  0   0   0   2   2  34 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.61      0.71       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.92      0.89      0.91       210\n",
      "           4       0.60      0.55      0.57       210\n",
      "           5       0.59      0.60      0.60       210\n",
      "           6       0.40      0.54      0.46       210\n",
      "           7       0.70      0.82      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.68      1470\n",
      "weighted avg       0.69      0.67      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.680952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[132   2   2   6  24  34  10]\n",
      " [  2 138   5  13  21  28   3]\n",
      " [  0   4 188   9   4   5   0]\n",
      " [  2   8   7 126  25  28  14]\n",
      " [ 22  10   1  27 125  18   7]\n",
      " [ 16  11   3  17   5 112  46]\n",
      " [  0   0   0   1   2  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.63      0.69       210\n",
      "           2       0.80      0.66      0.72       210\n",
      "           3       0.91      0.90      0.90       210\n",
      "           4       0.63      0.60      0.62       210\n",
      "           5       0.61      0.60      0.60       210\n",
      "           6       0.44      0.53      0.48       210\n",
      "           7       0.69      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6768707482993197\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[136   2   1  10  24  27  10]\n",
      " [  2 144   3  14  15  28   4]\n",
      " [  0   4 188  10   3   5   0]\n",
      " [  3   9   4 134  21  25  14]\n",
      " [ 25  13   1  31 115  14  11]\n",
      " [ 12  10   4  26   4 101  53]\n",
      " [  0   0   0   2   3  28 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.65      0.70       210\n",
      "           2       0.79      0.69      0.73       210\n",
      "           3       0.94      0.90      0.91       210\n",
      "           4       0.59      0.64      0.61       210\n",
      "           5       0.62      0.55      0.58       210\n",
      "           6       0.44      0.48      0.46       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.672108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   3   2   7  25  33  10]\n",
      " [  1 145   5  14  16  28   1]\n",
      " [  1   4 188  10   3   4   0]\n",
      " [  4   8   5 123  26  32  12]\n",
      " [ 18  14   0  24 127  16  11]\n",
      " [ 11  17   4  23   3  95  57]\n",
      " [  1   0   0   0   2  27 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.62      0.69       210\n",
      "           2       0.76      0.69      0.72       210\n",
      "           3       0.92      0.90      0.91       210\n",
      "           4       0.61      0.59      0.60       210\n",
      "           5       0.63      0.60      0.62       210\n",
      "           6       0.40      0.45      0.43       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6789115646258503\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[142   3   0  10  25  20  10]\n",
      " [  2 141   5  13  15  30   4]\n",
      " [  2   2 187   8   5   6   0]\n",
      " [  2  11   4 126  17  32  18]\n",
      " [ 26  12   0  23 117  18  14]\n",
      " [  9  12   4  18   4 110  53]\n",
      " [  0   1   0   0   3  31 175]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.68      0.72       210\n",
      "           2       0.77      0.67      0.72       210\n",
      "           3       0.94      0.89      0.91       210\n",
      "           4       0.64      0.60      0.62       210\n",
      "           5       0.63      0.56      0.59       210\n",
      "           6       0.45      0.52      0.48       210\n",
      "           7       0.64      0.83      0.72       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6687074829931973\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[137   3   1   7  24  29   9]\n",
      " [  3 138   4  12  21  29   3]\n",
      " [  1   4 190   9   1   5   0]\n",
      " [  7  10   6 125  22  29  11]\n",
      " [ 22   9   0  27 120  20  12]\n",
      " [ 12  13   3  20   6 106  50]\n",
      " [  0   0   0   2   2  39 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.65      0.70       210\n",
      "           2       0.78      0.66      0.71       210\n",
      "           3       0.93      0.90      0.92       210\n",
      "           4       0.62      0.60      0.61       210\n",
      "           5       0.61      0.57      0.59       210\n",
      "           6       0.41      0.50      0.45       210\n",
      "           7       0.66      0.80      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6836734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[139   3   1   8  19  32   8]\n",
      " [  3 144   5  12  17  29   0]\n",
      " [  1   2 185  12   3   6   1]\n",
      " [  4   8   6 128  21  33  10]\n",
      " [ 20   9   0  27 124  19  11]\n",
      " [ 10  14   6  19   7 109  45]\n",
      " [  1   0   0   1   3  29 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.72       210\n",
      "           2       0.80      0.69      0.74       210\n",
      "           3       0.91      0.88      0.90       210\n",
      "           4       0.62      0.61      0.61       210\n",
      "           5       0.64      0.59      0.61       210\n",
      "           6       0.42      0.52      0.47       210\n",
      "           7       0.70      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.70      0.68      0.69      1470\n",
      "weighted avg       0.70      0.68      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6802721088435374\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[143   1   0   6  23  31   6]\n",
      " [  2 141   4  15  20  28   0]\n",
      " [  2   2 187  10   3   5   1]\n",
      " [  9   9   6 130  18  23  15]\n",
      " [ 26  12   0  26 117  19  10]\n",
      " [ 11  12   5  19   8 110  45]\n",
      " [  1   0   0   1   5  31 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.68      0.71       210\n",
      "           2       0.80      0.67      0.73       210\n",
      "           3       0.93      0.89      0.91       210\n",
      "           4       0.63      0.62      0.62       210\n",
      "           5       0.60      0.56      0.58       210\n",
      "           6       0.45      0.52      0.48       210\n",
      "           7       0.69      0.82      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   0   4  21  28   8]\n",
      " [  4 144   4  13  19  25   1]\n",
      " [  1   3 189   6   3   6   2]\n",
      " [  5  13   6 118  21  34  13]\n",
      " [ 24   9   0  26 123  17  11]\n",
      " [ 16   9   4  15  12 113  41]\n",
      " [  0   0   0   2   4  28 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.70      0.72       210\n",
      "           2       0.80      0.69      0.74       210\n",
      "           3       0.93      0.90      0.92       210\n",
      "           4       0.64      0.56      0.60       210\n",
      "           5       0.61      0.59      0.60       210\n",
      "           6       0.45      0.54      0.49       210\n",
      "           7       0.70      0.84      0.76       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5707482993197279\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[107   3  20   3  24  40  13]\n",
      " [  1 118  20   6  24  32   9]\n",
      " [ 23   6 156   9   2  14   0]\n",
      " [  8  14  11  86  28  46  17]\n",
      " [ 25  14   1  15 115  22  18]\n",
      " [ 18  17   9  20   4  81  61]\n",
      " [  0   3   0   1   3  27 176]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.51      0.55       210\n",
      "           2       0.67      0.56      0.61       210\n",
      "           3       0.72      0.74      0.73       210\n",
      "           4       0.61      0.41      0.49       210\n",
      "           5       0.57      0.55      0.56       210\n",
      "           6       0.31      0.39      0.34       210\n",
      "           7       0.60      0.84      0.70       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//gpt_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a430c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[135   1   0   0  52  21   1]\n",
      " [  2 125   1   0  56  26   0]\n",
      " [  2   3 161   0  21  23   0]\n",
      " [  5   5   1  20 132  46   1]\n",
      " [ 12   3   0   1 180  13   1]\n",
      " [  7   4   1   1  25 167   5]\n",
      " [  1   0   0   0   9 100 100]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.64      0.72       210\n",
      "           2       0.89      0.60      0.71       210\n",
      "           3       0.98      0.77      0.86       210\n",
      "           4       0.91      0.10      0.17       210\n",
      "           5       0.38      0.86      0.53       210\n",
      "           6       0.42      0.80      0.55       210\n",
      "           7       0.93      0.48      0.63       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.76      0.60      0.60      1470\n",
      "weighted avg       0.76      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[159   3   2   9  28   5   4]\n",
      " [ 10 168   5   6  12   8   1]\n",
      " [  2   7 192   6   2   1   0]\n",
      " [ 19  31  21  97  25   9   8]\n",
      " [ 46  32   3  17 101   2   9]\n",
      " [ 23  21  11  33   6  72  44]\n",
      " [  7   1   0  10   5  30 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.76      0.67       210\n",
      "           2       0.64      0.80      0.71       210\n",
      "           3       0.82      0.91      0.86       210\n",
      "           4       0.54      0.46      0.50       210\n",
      "           5       0.56      0.48      0.52       210\n",
      "           6       0.57      0.34      0.43       210\n",
      "           7       0.70      0.75      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.63      0.64      0.63      1470\n",
      "weighted avg       0.63      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[153   3   2   9  31   6   6]\n",
      " [  5 170   7   8  11   8   1]\n",
      " [  1   6 194   6   0   3   0]\n",
      " [ 17  26  20  96  28  11  12]\n",
      " [ 42  32   5  15 104   3   9]\n",
      " [ 20  22   9  25   8  78  48]\n",
      " [  4   0   0   7   0  44 155]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.73      0.68       210\n",
      "           2       0.66      0.81      0.72       210\n",
      "           3       0.82      0.92      0.87       210\n",
      "           4       0.58      0.46      0.51       210\n",
      "           5       0.57      0.50      0.53       210\n",
      "           6       0.51      0.37      0.43       210\n",
      "           7       0.67      0.74      0.70       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.63      0.65      0.63      1470\n",
      "weighted avg       0.63      0.65      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   3   2   8  40   8   4]\n",
      " [  5 169   6   8  13   7   2]\n",
      " [  0   7 192   8   1   2   0]\n",
      " [  8  22  20 107  31  13   9]\n",
      " [ 32  29   5  13 120   3   8]\n",
      " [ 16  17   8  37  11  74  47]\n",
      " [  3   0   0   9   3  39 156]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.69      0.69       210\n",
      "           2       0.68      0.80      0.74       210\n",
      "           3       0.82      0.91      0.87       210\n",
      "           4       0.56      0.51      0.53       210\n",
      "           5       0.55      0.57      0.56       210\n",
      "           6       0.51      0.35      0.42       210\n",
      "           7       0.69      0.74      0.72       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.64      0.66      0.65      1470\n",
      "weighted avg       0.64      0.66      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[146   2   3   9  38   6   6]\n",
      " [  4 175   5   6  10   9   1]\n",
      " [  2   5 191   7   2   2   1]\n",
      " [  7  19  23 111  29  12   9]\n",
      " [ 34  28   5  11 120   2  10]\n",
      " [ 12  20   9  30  11  79  49]\n",
      " [  5   0   0   8   2  37 158]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       210\n",
      "           2       0.70      0.83      0.76       210\n",
      "           3       0.81      0.91      0.86       210\n",
      "           4       0.61      0.53      0.57       210\n",
      "           5       0.57      0.57      0.57       210\n",
      "           6       0.54      0.38      0.44       210\n",
      "           7       0.68      0.75      0.71       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   1   2   7  44   7   8]\n",
      " [  3 175   5   4  13   7   3]\n",
      " [  4   6 187   8   1   4   0]\n",
      " [  6  18  23 108  32  14   9]\n",
      " [ 29  27   4  10 127   2  11]\n",
      " [ 12  20  11  30  10  76  51]\n",
      " [  4   1   0   3   1  35 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.67      0.69       210\n",
      "           2       0.71      0.83      0.76       210\n",
      "           3       0.81      0.89      0.85       210\n",
      "           4       0.64      0.51      0.57       210\n",
      "           5       0.56      0.60      0.58       210\n",
      "           6       0.52      0.36      0.43       210\n",
      "           7       0.67      0.79      0.72       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140   3   2   6  44   7   8]\n",
      " [  4 175   5   4  12   7   3]\n",
      " [  1   6 193   5   2   2   1]\n",
      " [  7  18  22 108  33  10  12]\n",
      " [ 27  27   5  12 128   2   9]\n",
      " [ 11  19  14  24   8  72  62]\n",
      " [  4   1   0   8   1  32 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.67      0.69       210\n",
      "           2       0.70      0.83      0.76       210\n",
      "           3       0.80      0.92      0.86       210\n",
      "           4       0.65      0.51      0.57       210\n",
      "           5       0.56      0.61      0.58       210\n",
      "           6       0.55      0.34      0.42       210\n",
      "           7       0.63      0.78      0.70       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.66      0.67      0.66      1470\n",
      "weighted avg       0.66      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.6217687074829932\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[126   2   0   8  31  36   7]\n",
      " [  3 133   6  14  17  32   5]\n",
      " [  5   2 159  23   1  20   0]\n",
      " [  2  12   6  99  27  52  12]\n",
      " [ 33  18   0  18 113  13  15]\n",
      " [  7   2  10  24   0 130  37]\n",
      " [  0   0   0   0   2  54 154]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.60      0.65       210\n",
      "           2       0.79      0.63      0.70       210\n",
      "           3       0.88      0.76      0.81       210\n",
      "           4       0.53      0.47      0.50       210\n",
      "           5       0.59      0.54      0.56       210\n",
      "           6       0.39      0.62      0.48       210\n",
      "           7       0.67      0.73      0.70       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.65      0.62      0.63      1470\n",
      "weighted avg       0.65      0.62      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.22312925170068026\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 26   3   2   4 156  11   8]\n",
      " [  1  18   2   4 179   5   1]\n",
      " [  1   1  22  14 161  11   0]\n",
      " [  7   2   3  22 151  18   7]\n",
      " [  8   4   1  10 173  10   4]\n",
      " [  7   6   4  10 136  33  14]\n",
      " [  5   3   4   2 141  21  34]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.12      0.20       210\n",
      "           2       0.49      0.09      0.15       210\n",
      "           3       0.58      0.10      0.18       210\n",
      "           4       0.33      0.10      0.16       210\n",
      "           5       0.16      0.82      0.26       210\n",
      "           6       0.30      0.16      0.21       210\n",
      "           7       0.50      0.16      0.24       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.40      0.22      0.20      1470\n",
      "weighted avg       0.40      0.22      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of SVM is:\n",
      " [[159   3   1   1  37   8   1]\n",
      " [  6 178   2   1  11  12   0]\n",
      " [  0   9 190   0   0  11   0]\n",
      " [ 14  40  16  39  61  37   3]\n",
      " [ 43  18   0   4 133   9   3]\n",
      " [ 24  23   7   4  11 131  10]\n",
      " [  2   0   0   1   3  71 133]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.76      0.69       210\n",
      "           2       0.66      0.85      0.74       210\n",
      "           3       0.88      0.90      0.89       210\n",
      "           4       0.78      0.19      0.30       210\n",
      "           5       0.52      0.63      0.57       210\n",
      "           6       0.47      0.62      0.54       210\n",
      "           7       0.89      0.63      0.74       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.69      0.66      0.64      1470\n",
      "weighted avg       0.69      0.66      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of SVM is:\n",
      " [[165   3   1   0  30  10   1]\n",
      " [  5 177   2   2   9  15   0]\n",
      " [  0   7 192   0   0  10   1]\n",
      " [ 13  34  12  65  44  38   4]\n",
      " [ 32  24   0   6 137   7   4]\n",
      " [ 27  16   5   3  11 124  24]\n",
      " [  5   0   0   1   1  41 162]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.79      0.72       210\n",
      "           2       0.68      0.84      0.75       210\n",
      "           3       0.91      0.91      0.91       210\n",
      "           4       0.84      0.31      0.45       210\n",
      "           5       0.59      0.65      0.62       210\n",
      "           6       0.51      0.59      0.55       210\n",
      "           7       0.83      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.72      0.70      0.69      1470\n",
      "weighted avg       0.72      0.70      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7639455782312925\n",
      "Confusion Matrix of SVM is:\n",
      " [[156   2   0   2  21  27   2]\n",
      " [  1 172   2   6   5  23   1]\n",
      " [  0   3 192   4   1  10   0]\n",
      " [  0  11   6 123  14  53   3]\n",
      " [ 29  18   0  15 131  11   6]\n",
      " [  1   3   1   6   1 172  26]\n",
      " [  0   0   0   0   1  32 177]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.79       210\n",
      "           2       0.82      0.82      0.82       210\n",
      "           3       0.96      0.91      0.93       210\n",
      "           4       0.79      0.59      0.67       210\n",
      "           5       0.75      0.62      0.68       210\n",
      "           6       0.52      0.82      0.64       210\n",
      "           7       0.82      0.84      0.83       210\n",
      "\n",
      "    accuracy                           0.76      1470\n",
      "   macro avg       0.79      0.76      0.77      1470\n",
      "weighted avg       0.79      0.76      0.77      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.45170068027210886\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 68   1  84   0  30   4  23]\n",
      " [  0  58 106   0  24   3  19]\n",
      " [  0   0 202   1   1   2   4]\n",
      " [  4  12  66  11  59   9  49]\n",
      " [ 24   8  44   0 106   0  28]\n",
      " [  4   8  49   1   9  14 125]\n",
      " [  0   0   0   0   2   3 205]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.32      0.44       210\n",
      "           2       0.67      0.28      0.39       210\n",
      "           3       0.37      0.96      0.53       210\n",
      "           4       0.85      0.05      0.10       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.40      0.07      0.11       210\n",
      "           7       0.45      0.98      0.62       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.55      0.45      0.38      1470\n",
      "weighted avg       0.55      0.45      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 210   0   0]\n",
      " [  0   0   2   0 208   0   0]\n",
      " [  0   0 120   0  90   0   0]\n",
      " [  0   0   4   0 206   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   2   0 208   0   0]\n",
      " [  0   0   2   0 208   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.92      0.57      0.71       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.15      0.22      0.14      1470\n",
      "weighted avg       0.15      0.22      0.14      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3476190476190476\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   0   0 178   0  32]\n",
      " [  0   0   2   0 176   0  32]\n",
      " [  0   0 115   5  71   0  19]\n",
      " [  0   0   2   2 160   0  46]\n",
      " [  0   0   0   0 192   0  18]\n",
      " [  0   0   2   0  58   0 150]\n",
      " [  0   0   2   0   6   0 202]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.93      0.55      0.69       210\n",
      "           4       0.29      0.01      0.02       210\n",
      "           5       0.23      0.91      0.37       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.40      0.96      0.57       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.26      0.35      0.23      1470\n",
      "weighted avg       0.26      0.35      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4605442176870748\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[164  14   0   0   0  11  21]\n",
      " [ 24 152   2   0   0  21  11]\n",
      " [  8  63 115   5   0  18   1]\n",
      " [ 63  97   1   2   0  24  23]\n",
      " [137  55   0   0   0   3  15]\n",
      " [ 32  26   2   0   0  58  92]\n",
      " [  6   0   0   0   0  18 186]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.78      0.51       210\n",
      "           2       0.37      0.72      0.49       210\n",
      "           3       0.96      0.55      0.70       210\n",
      "           4       0.29      0.01      0.02       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.38      0.28      0.32       210\n",
      "           7       0.53      0.89      0.67       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.42      0.46      0.39      1470\n",
      "weighted avg       0.42      0.46      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5108843537414965\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[106   3   0  12  58  21  10]\n",
      " [  2 103   1  65  22  11   6]\n",
      " [  6  10 115  60   7  11   1]\n",
      " [  3  22   1  80  60  34  10]\n",
      " [ 24  19   0  36 113  14   4]\n",
      " [  3  22   0  18  29  80  58]\n",
      " [  0   1   0   1   6  48 154]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.50      0.60       210\n",
      "           2       0.57      0.49      0.53       210\n",
      "           3       0.98      0.55      0.70       210\n",
      "           4       0.29      0.38      0.33       210\n",
      "           5       0.38      0.54      0.45       210\n",
      "           6       0.37      0.38      0.37       210\n",
      "           7       0.63      0.73      0.68       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.57      0.51      0.52      1470\n",
      "weighted avg       0.57      0.51      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.536734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 88   1   8   6  71  23  13]\n",
      " [  2  90  19  60  16  16   7]\n",
      " [  0   7 171  12   5  14   1]\n",
      " [  0  10  23  70  47  44  16]\n",
      " [  7  11  10  34 119  19  10]\n",
      " [  1  13   6  21  17  76  76]\n",
      " [  0   1   0   0   1  33 175]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.42      0.57       210\n",
      "           2       0.68      0.43      0.52       210\n",
      "           3       0.72      0.81      0.77       210\n",
      "           4       0.34      0.33      0.34       210\n",
      "           5       0.43      0.57      0.49       210\n",
      "           6       0.34      0.36      0.35       210\n",
      "           7       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.57      0.54      0.53      1470\n",
      "weighted avg       0.57      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 93   1   0  16  69  19  12]\n",
      " [ 10  88   6  66  15  19   6]\n",
      " [  2   3 160  23   3  15   4]\n",
      " [ 16  14  11  82  35  33  19]\n",
      " [ 26  19   2  30 112  11  10]\n",
      " [ 15   9   4  23  10  79  70]\n",
      " [  9   0   0   0   1  35 165]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.44      0.49       210\n",
      "           2       0.66      0.42      0.51       210\n",
      "           3       0.87      0.76      0.81       210\n",
      "           4       0.34      0.39      0.36       210\n",
      "           5       0.46      0.53      0.49       210\n",
      "           6       0.37      0.38      0.38       210\n",
      "           7       0.58      0.79      0.67       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.55      0.53      0.53      1470\n",
      "weighted avg       0.55      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5503401360544218\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[124   2   2   7  43  20  12]\n",
      " [ 13  81   9  63  15  24   5]\n",
      " [  1   2 156  15  16  19   1]\n",
      " [  9  10   8  94  27  40  22]\n",
      " [ 31  21   2  29 103  14  10]\n",
      " [ 13   3   5  24  12  90  63]\n",
      " [  5   0   1   0   1  42 161]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.59      0.61       210\n",
      "           2       0.68      0.39      0.49       210\n",
      "           3       0.85      0.74      0.79       210\n",
      "           4       0.41      0.45      0.43       210\n",
      "           5       0.47      0.49      0.48       210\n",
      "           6       0.36      0.43      0.39       210\n",
      "           7       0.59      0.77      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.55      1470\n",
      "weighted avg       0.57      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[138   0   2  12  32  18   8]\n",
      " [ 14 106  12  39  17  18   4]\n",
      " [  5   9 160   6  14  16   0]\n",
      " [ 17  15  17  91  21  30  19]\n",
      " [ 63  16   3  31  79  11   7]\n",
      " [ 23  14   9  29   2  82  51]\n",
      " [  6   4   1   2   1  48 148]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.66      0.58       210\n",
      "           2       0.65      0.50      0.57       210\n",
      "           3       0.78      0.76      0.77       210\n",
      "           4       0.43      0.43      0.43       210\n",
      "           5       0.48      0.38      0.42       210\n",
      "           6       0.37      0.39      0.38       210\n",
      "           7       0.62      0.70      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[125   3   1   8  44  20   9]\n",
      " [ 14 114   9  35  17  17   4]\n",
      " [  3   3 165  10  12  13   4]\n",
      " [ 18  15  13  89  25  30  20]\n",
      " [ 50  19   3  33  85  13   7]\n",
      " [ 19   7   9  32  10  80  53]\n",
      " [ 10   3   1   0   2  48 146]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.60      0.56       210\n",
      "           2       0.70      0.54      0.61       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.43      0.42      0.43       210\n",
      "           5       0.44      0.40      0.42       210\n",
      "           6       0.36      0.38      0.37       210\n",
      "           7       0.60      0.70      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.55      1470\n",
      "weighted avg       0.55      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[128   8   3  13  36  17   5]\n",
      " [ 16 104  13  35  19  20   3]\n",
      " [  8   4 161  16   9  12   0]\n",
      " [ 24  19   9  91  21  28  18]\n",
      " [ 45  23   3  39  81  13   6]\n",
      " [ 25   8   5  38  10  81  43]\n",
      " [ 14   1   0   6   2  46 141]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.61      0.54       210\n",
      "           2       0.62      0.50      0.55       210\n",
      "           3       0.83      0.77      0.80       210\n",
      "           4       0.38      0.43      0.41       210\n",
      "           5       0.46      0.39      0.42       210\n",
      "           6       0.37      0.39      0.38       210\n",
      "           7       0.65      0.67      0.66       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.54      1470\n",
      "weighted avg       0.54      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   4   4  15  35  16   4]\n",
      " [  8 110  13  26  29  19   5]\n",
      " [  4   3 163  16   8  16   0]\n",
      " [ 21  18  12  81  27  34  17]\n",
      " [ 45  29   2  32  81  15   6]\n",
      " [ 18   9   5  35   9  88  46]\n",
      " [  8   6   0   6   2  58 130]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.63      0.59       210\n",
      "           2       0.61      0.52      0.57       210\n",
      "           3       0.82      0.78      0.80       210\n",
      "           4       0.38      0.39      0.38       210\n",
      "           5       0.42      0.39      0.40       210\n",
      "           6       0.36      0.42      0.39       210\n",
      "           7       0.62      0.62      0.62       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.54      1470\n",
      "weighted avg       0.54      0.53      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5340136054421769\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[145   4   2  12  26  16   5]\n",
      " [ 10 103  19  29  26  17   6]\n",
      " [  4   4 165  13   9  14   1]\n",
      " [ 20  21   9  80  34  33  13]\n",
      " [ 61  29   6  23  68  15   8]\n",
      " [ 17  19   9  29  11  84  41]\n",
      " [  7   4   3   7   2  47 140]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.69      0.61       210\n",
      "           2       0.56      0.49      0.52       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.41      0.38      0.40       210\n",
      "           5       0.39      0.32      0.35       210\n",
      "           6       0.37      0.40      0.39       210\n",
      "           7       0.65      0.67      0.66       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.53      1470\n",
      "weighted avg       0.53      0.53      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5251700680272109\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[136   6   4  14  23  23   4]\n",
      " [  9 103  12  23  36  21   6]\n",
      " [  3   8 165  11  13   9   1]\n",
      " [ 17  18  17  77  30  35  16]\n",
      " [ 58  28  10  23  63  22   6]\n",
      " [ 15  12   5  32  11  89  46]\n",
      " [  5   2   3   8   2  51 139]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.65      0.60       210\n",
      "           2       0.58      0.49      0.53       210\n",
      "           3       0.76      0.79      0.77       210\n",
      "           4       0.41      0.37      0.39       210\n",
      "           5       0.35      0.30      0.32       210\n",
      "           6       0.36      0.42      0.39       210\n",
      "           7       0.64      0.66      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.52      0.53      0.52      1470\n",
      "weighted avg       0.52      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5122448979591837\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[131   6   4  15  31  18   5]\n",
      " [ 11 101  11  27  34  22   4]\n",
      " [  6   5 163   9  10  15   2]\n",
      " [ 18  21  24  76  22  35  14]\n",
      " [ 53  24   9  29  62  22  11]\n",
      " [ 17  15   9  32  12  78  47]\n",
      " [ 14   3   2   6   3  40 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.62      0.57       210\n",
      "           2       0.58      0.48      0.52       210\n",
      "           3       0.73      0.78      0.75       210\n",
      "           4       0.39      0.36      0.38       210\n",
      "           5       0.36      0.30      0.32       210\n",
      "           6       0.34      0.37      0.35       210\n",
      "           7       0.63      0.68      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5231292517006803\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   6   5  14  27  23   5]\n",
      " [ 11 107  10  33  24  21   4]\n",
      " [  2   5 168  20   3  10   2]\n",
      " [ 19  19  22  75  27  30  18]\n",
      " [ 55  27   5  29  63  24   7]\n",
      " [ 17  14   7  29   9  88  46]\n",
      " [  9   3   2   5   2  51 138]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.62      0.57       210\n",
      "           2       0.59      0.51      0.55       210\n",
      "           3       0.77      0.80      0.78       210\n",
      "           4       0.37      0.36      0.36       210\n",
      "           5       0.41      0.30      0.35       210\n",
      "           6       0.36      0.42      0.39       210\n",
      "           7       0.63      0.66      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5115646258503401\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[138   4   4  15  24  20   5]\n",
      " [ 10  98  15  30  31  21   5]\n",
      " [  4   4 164  15   8  15   0]\n",
      " [ 20  18  23  78  25  29  17]\n",
      " [ 62  25   9  26  55  23  10]\n",
      " [ 14  14   7  29  16  84  46]\n",
      " [  5   3   3   8   3  53 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.66      0.60       210\n",
      "           2       0.59      0.47      0.52       210\n",
      "           3       0.73      0.78      0.75       210\n",
      "           4       0.39      0.37      0.38       210\n",
      "           5       0.34      0.26      0.30       210\n",
      "           6       0.34      0.40      0.37       210\n",
      "           7       0.62      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5068027210884354\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[131   6   3  14  29  21   6]\n",
      " [ 12  98  11  30  32  22   5]\n",
      " [  2   6 162  13   9  16   2]\n",
      " [ 17  14  23  80  26  32  18]\n",
      " [ 57  29   6  32  58  21   7]\n",
      " [ 16  14   5  34  14  82  45]\n",
      " [  5   3   3   8   4  53 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.62      0.58       210\n",
      "           2       0.58      0.47      0.52       210\n",
      "           3       0.76      0.77      0.77       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.34      0.28      0.30       210\n",
      "           6       0.33      0.39      0.36       210\n",
      "           7       0.62      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.50      1470\n",
      "weighted avg       0.51      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5102040816326531\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   7   3  16  23  25   4]\n",
      " [  8  96  19  35  29  20   3]\n",
      " [  3   4 166  14   8  14   1]\n",
      " [ 12  21  19  76  30  36  16]\n",
      " [ 54  26   5  33  64  22   6]\n",
      " [ 17  15   6  31  14  82  45]\n",
      " [  5   3   3   8   3  54 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.63      0.60       210\n",
      "           2       0.56      0.46      0.50       210\n",
      "           3       0.75      0.79      0.77       210\n",
      "           4       0.36      0.36      0.36       210\n",
      "           5       0.37      0.30      0.34       210\n",
      "           6       0.32      0.39      0.35       210\n",
      "           7       0.64      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.51      0.51      0.51      1470\n",
      "weighted avg       0.51      0.51      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[132   4   2  11  36  18   7]\n",
      " [ 10 105   9  36  26  20   4]\n",
      " [  3   5 169  13   8  12   0]\n",
      " [ 23  18  19  75  27  32  16]\n",
      " [ 59  26   8  31  62  17   7]\n",
      " [ 16  11   4  35  16  84  44]\n",
      " [  5   3   3   8   3  53 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.63      0.58       210\n",
      "           2       0.61      0.50      0.55       210\n",
      "           3       0.79      0.80      0.80       210\n",
      "           4       0.36      0.36      0.36       210\n",
      "           5       0.35      0.30      0.32       210\n",
      "           6       0.36      0.40      0.38       210\n",
      "           7       0.63      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.52      1470\n",
      "weighted avg       0.52      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[130   6   2  15  28  24   5]\n",
      " [ 10  99  14  24  39  18   6]\n",
      " [  2   4 169  13  10  11   1]\n",
      " [ 23  19  19  68  30  34  17]\n",
      " [ 56  24   5  23  72  23   7]\n",
      " [ 18  12   4  33  13  86  44]\n",
      " [  5   3   3   8   3  53 135]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.62      0.57       210\n",
      "           2       0.59      0.47      0.53       210\n",
      "           3       0.78      0.80      0.79       210\n",
      "           4       0.37      0.32      0.35       210\n",
      "           5       0.37      0.34      0.36       210\n",
      "           6       0.35      0.41      0.37       210\n",
      "           7       0.63      0.64      0.64       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.51      1470\n",
      "weighted avg       0.52      0.52      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47006802721088436\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 56   3  45   0  56   1  49]\n",
      " [  1 103  47   0  26   0  33]\n",
      " [  0   7 191   0   2   1   9]\n",
      " [  0  36  46   0  53   1  74]\n",
      " [  8  20  12   0 132   0  38]\n",
      " [  3   9  26   0  11   0 161]\n",
      " [  0   0   0   0   1   0 209]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.27      0.40       210\n",
      "           2       0.58      0.49      0.53       210\n",
      "           3       0.52      0.91      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.47      0.63      0.54       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      1.00      0.53       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.39      0.47      0.38      1470\n",
      "weighted avg       0.39      0.47      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5380952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   1   0  25   5  36]\n",
      " [  2 133  16   0  29   3  27]\n",
      " [  1  12 181   0   4   6   6]\n",
      " [  9  43  26   3  57  11  61]\n",
      " [ 46  18   5   0 114   1  26]\n",
      " [ 14  10  13   1  12  10 150]\n",
      " [  0   0   0   0   1   0 209]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.67      0.67       210\n",
      "           2       0.61      0.63      0.62       210\n",
      "           3       0.75      0.86      0.80       210\n",
      "           4       0.75      0.01      0.03       210\n",
      "           5       0.47      0.54      0.50       210\n",
      "           6       0.28      0.05      0.08       210\n",
      "           7       0.41      1.00      0.58       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.56      0.54      0.47      1470\n",
      "weighted avg       0.56      0.54      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[146   3   1   0  21  15  24]\n",
      " [  3 165   3   1  11  11  16]\n",
      " [  2  20 168   5   3  10   2]\n",
      " [  5  55  16  20  47  17  50]\n",
      " [ 52  31   2   0 102   1  22]\n",
      " [ 14  20   9   1   7  30 129]\n",
      " [  0   0   0   0   1   2 207]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.70      0.68       210\n",
      "           2       0.56      0.79      0.65       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.74      0.10      0.17       210\n",
      "           5       0.53      0.49      0.51       210\n",
      "           6       0.35      0.14      0.20       210\n",
      "           7       0.46      0.99      0.63       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.59      0.57      0.52      1470\n",
      "weighted avg       0.59      0.57      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   0   1  34  14  23]\n",
      " [  1 159   2   6  15  12  15]\n",
      " [  1  17 164   6   4  16   2]\n",
      " [  2  32   7  50  53  27  39]\n",
      " [ 31  23   0   0 134   1  21]\n",
      " [  5  12   6  16  12  57 102]\n",
      " [  0   0   0   0   1   7 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.64      0.70       210\n",
      "           2       0.64      0.76      0.70       210\n",
      "           3       0.92      0.78      0.84       210\n",
      "           4       0.63      0.24      0.35       210\n",
      "           5       0.53      0.64      0.58       210\n",
      "           6       0.43      0.27      0.33       210\n",
      "           7       0.50      0.96      0.66       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.63      0.61      0.59      1470\n",
      "weighted avg       0.63      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6462585034013606\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   3   0   2  35  25  10]\n",
      " [  1 165   1   6  12  17   8]\n",
      " [  0   7 174  11   4  14   0]\n",
      " [  0  27   9  71  44  38  21]\n",
      " [ 21  25   0   7 139   4  14]\n",
      " [  6  13   5  16   8  72  90]\n",
      " [  0   0   0   0   1  15 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.64      0.72       210\n",
      "           2       0.69      0.79      0.73       210\n",
      "           3       0.92      0.83      0.87       210\n",
      "           4       0.63      0.34      0.44       210\n",
      "           5       0.57      0.66      0.61       210\n",
      "           6       0.39      0.34      0.36       210\n",
      "           7       0.58      0.92      0.71       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6693877551020408\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[126   1   0   3  43  27  10]\n",
      " [  1 160   1   6  17  19   6]\n",
      " [  0   5 179  14   3   9   0]\n",
      " [  1  17   3  91  41  38  19]\n",
      " [ 15  20   0   8 146   7  14]\n",
      " [  3  10   4  18   9  93  73]\n",
      " [  0   0   0   0   1  20 189]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.60      0.71       210\n",
      "           2       0.75      0.76      0.76       210\n",
      "           3       0.96      0.85      0.90       210\n",
      "           4       0.65      0.43      0.52       210\n",
      "           5       0.56      0.70      0.62       210\n",
      "           6       0.44      0.44      0.44       210\n",
      "           7       0.61      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.69      0.67      0.67      1470\n",
      "weighted avg       0.69      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.689795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   1   0   5  32  29   5]\n",
      " [  1 166   2   4  13  20   4]\n",
      " [  0   4 185   8   3  10   0]\n",
      " [  2  13   5 101  34  44  11]\n",
      " [ 19  22   0  11 139   8  11]\n",
      " [  6   7   4  19   8 106  60]\n",
      " [  0   0   0   0   1  30 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.66      0.73       210\n",
      "           2       0.78      0.79      0.78       210\n",
      "           3       0.94      0.88      0.91       210\n",
      "           4       0.68      0.48      0.56       210\n",
      "           5       0.60      0.66      0.63       210\n",
      "           6       0.43      0.50      0.46       210\n",
      "           7       0.66      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.70      0.69      0.69      1470\n",
      "weighted avg       0.70      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6904761904761905\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[138   2   0   5  33  26   6]\n",
      " [  1 163   1   7  11  25   2]\n",
      " [  0   6 175  12   3  14   0]\n",
      " [  0  13   5 105  29  46  12]\n",
      " [ 16  23   0  11 141   8  11]\n",
      " [  4  10   1  20   4 115  56]\n",
      " [  0   0   0   0   1  31 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.66      0.75       210\n",
      "           2       0.75      0.78      0.76       210\n",
      "           3       0.96      0.83      0.89       210\n",
      "           4       0.66      0.50      0.57       210\n",
      "           5       0.64      0.67      0.65       210\n",
      "           6       0.43      0.55      0.48       210\n",
      "           7       0.67      0.85      0.75       210\n",
      "\n",
      "    accuracy                           0.69      1470\n",
      "   macro avg       0.71      0.69      0.69      1470\n",
      "weighted avg       0.71      0.69      0.69      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7115646258503401\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   0   0   7  31  22   6]\n",
      " [  1 166   1   6  15  17   4]\n",
      " [  1   4 179  14   1  11   0]\n",
      " [  1   9   5 111  31  43  10]\n",
      " [ 16  20   0   9 148   8   9]\n",
      " [  5  10   4  20   6 118  47]\n",
      " [  0   0   0   0   1  29 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.69      0.76       210\n",
      "           2       0.79      0.79      0.79       210\n",
      "           3       0.95      0.85      0.90       210\n",
      "           4       0.66      0.53      0.59       210\n",
      "           5       0.64      0.70      0.67       210\n",
      "           6       0.48      0.56      0.52       210\n",
      "           7       0.70      0.86      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.71      1470\n",
      "weighted avg       0.73      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6952380952380952\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[141   2   1   4  34  26   2]\n",
      " [  1 164   1  12  12  17   3]\n",
      " [  0   5 186   6   4   9   0]\n",
      " [  0  13   3 110  30  40  14]\n",
      " [ 23  22   0  14 133   6  12]\n",
      " [  7   7   1  17   6 117  55]\n",
      " [  0   0   0   0   1  38 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       210\n",
      "           2       0.77      0.78      0.78       210\n",
      "           3       0.97      0.89      0.93       210\n",
      "           4       0.67      0.52      0.59       210\n",
      "           5       0.60      0.63      0.62       210\n",
      "           6       0.46      0.56      0.51       210\n",
      "           7       0.67      0.81      0.73       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7163265306122449\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   1   1   5  27  20   7]\n",
      " [  2 163   3   9   9  19   5]\n",
      " [  0   5 187   9   2   7   0]\n",
      " [  1   9   4 117  25  44  10]\n",
      " [ 22  23   0  12 136   8   9]\n",
      " [  3  11   2  21   2 116  55]\n",
      " [  0   0   0   0   1  24 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.71      0.77       210\n",
      "           2       0.77      0.78      0.77       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.68      0.56      0.61       210\n",
      "           5       0.67      0.65      0.66       210\n",
      "           6       0.49      0.55      0.52       210\n",
      "           7       0.68      0.88      0.77       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   2   1   4  27  23   4]\n",
      " [  1 163   2  10  13  17   4]\n",
      " [  0   5 190   6   2   7   0]\n",
      " [  1  11   2 113  29  43  11]\n",
      " [ 20  18   0  13 142   8   9]\n",
      " [  7   7   1  20   5 122  48]\n",
      " [  0   0   0   0   2  36 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.71      0.77       210\n",
      "           2       0.79      0.78      0.78       210\n",
      "           3       0.97      0.90      0.94       210\n",
      "           4       0.68      0.54      0.60       210\n",
      "           5       0.65      0.68      0.66       210\n",
      "           6       0.48      0.58      0.52       210\n",
      "           7       0.69      0.82      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.73      0.71      0.72      1470\n",
      "weighted avg       0.73      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7156462585034014\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[150   2   1   2  27  25   3]\n",
      " [  3 164   1   8  13  17   4]\n",
      " [  0   6 182  10   3   9   0]\n",
      " [  0  10   4 120  29  36  11]\n",
      " [ 20  17   0  15 141   8   9]\n",
      " [  6   8   3  19   5 117  52]\n",
      " [  0   0   0   0   1  31 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.71      0.77       210\n",
      "           2       0.79      0.78      0.79       210\n",
      "           3       0.95      0.87      0.91       210\n",
      "           4       0.69      0.57      0.62       210\n",
      "           5       0.64      0.67      0.66       210\n",
      "           6       0.48      0.56      0.52       210\n",
      "           7       0.69      0.85      0.76       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7047619047619048\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[145   1   0   5  33  21   5]\n",
      " [  2 164   2  14   8  18   2]\n",
      " [  0   4 186   7   4   9   0]\n",
      " [  1  11   5 109  35  38  11]\n",
      " [ 21  19   0  17 135   9   9]\n",
      " [  7  10   3  16   5 119  50]\n",
      " [  0   0   0   0   2  30 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.69      0.75       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.65      0.52      0.58       210\n",
      "           5       0.61      0.64      0.62       210\n",
      "           6       0.49      0.57      0.52       210\n",
      "           7       0.70      0.85      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.71      1470\n",
      "weighted avg       0.71      0.70      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[144   2   0   5  31  23   5]\n",
      " [  3 165   2   6  13  18   3]\n",
      " [  0   4 186  10   3   7   0]\n",
      " [  4   9   4 114  28  40  11]\n",
      " [ 23  20   0  16 135   7   9]\n",
      " [  7   4   2  27   2 125  43]\n",
      " [  0   0   0   1   1  35 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.69      0.74       210\n",
      "           2       0.81      0.79      0.80       210\n",
      "           3       0.96      0.89      0.92       210\n",
      "           4       0.64      0.54      0.59       210\n",
      "           5       0.63      0.64      0.64       210\n",
      "           6       0.49      0.60      0.54       210\n",
      "           7       0.71      0.82      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[154   2   1   5  24  22   2]\n",
      " [  3 164   3  12   9  17   2]\n",
      " [  1   5 187   9   2   6   0]\n",
      " [  2   9   3 118  26  42  10]\n",
      " [ 30  21   0  16 122  12   9]\n",
      " [  5  10   2  21   2 130  40]\n",
      " [  0   0   0   0   1  44 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.73      0.76       210\n",
      "           2       0.78      0.78      0.78       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.65      0.56      0.60       210\n",
      "           5       0.66      0.58      0.62       210\n",
      "           6       0.48      0.62      0.54       210\n",
      "           7       0.72      0.79      0.75       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.708843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[149   2   1   7  26  22   3]\n",
      " [  5 161   2   7  15  15   5]\n",
      " [  0   5 187   9   2   7   0]\n",
      " [  5   7   3 121  21  42  11]\n",
      " [ 28  19   0  19 124  10  10]\n",
      " [  8   8   3  16   5 127  43]\n",
      " [  0   0   0   0   1  36 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.71      0.74       210\n",
      "           2       0.80      0.77      0.78       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.68      0.58      0.62       210\n",
      "           5       0.64      0.59      0.61       210\n",
      "           6       0.49      0.60      0.54       210\n",
      "           7       0.71      0.82      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.7136054421768707\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[153   2   1   5  24  22   3]\n",
      " [  3 163   2  11  12  17   2]\n",
      " [  2   3 190   5   2   8   0]\n",
      " [  1   7   4 120  31  38   9]\n",
      " [ 34  15   1  21 123   7   9]\n",
      " [  7   7   3  19   4 131  39]\n",
      " [  0   0   0   0   1  40 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.83      0.78      0.80       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.66      0.57      0.61       210\n",
      "           5       0.62      0.59      0.60       210\n",
      "           6       0.50      0.62      0.55       210\n",
      "           7       0.73      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.72      1470\n",
      "weighted avg       0.72      0.71      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7074829931972789\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[147   2   0   6  27  25   3]\n",
      " [  3 166   2   6  12  15   6]\n",
      " [  0   5 188   7   3   7   0]\n",
      " [  2   9   6 115  29  42   7]\n",
      " [ 25  15   0  22 131   8   9]\n",
      " [  8  10   1  20   5 126  40]\n",
      " [  0   0   0   0   1  42 167]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.70      0.74       210\n",
      "           2       0.80      0.79      0.80       210\n",
      "           3       0.95      0.90      0.92       210\n",
      "           4       0.65      0.55      0.60       210\n",
      "           5       0.63      0.62      0.63       210\n",
      "           6       0.48      0.60      0.53       210\n",
      "           7       0.72      0.80      0.76       210\n",
      "\n",
      "    accuracy                           0.71      1470\n",
      "   macro avg       0.72      0.71      0.71      1470\n",
      "weighted avg       0.72      0.71      0.71      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.7020408163265306\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[151   2   0   5  25  24   3]\n",
      " [  5 164   2   9  10  15   5]\n",
      " [  1   4 189   5   3   8   0]\n",
      " [  1  12   5 111  30  44   7]\n",
      " [ 35  17   0  22 116  12   8]\n",
      " [  7   8   1  22   4 129  39]\n",
      " [  2   0   0   0   0  36 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.72      0.73       210\n",
      "           2       0.79      0.78      0.79       210\n",
      "           3       0.96      0.90      0.93       210\n",
      "           4       0.64      0.53      0.58       210\n",
      "           5       0.62      0.55      0.58       210\n",
      "           6       0.48      0.61      0.54       210\n",
      "           7       0.74      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5884353741496599\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[133   1   2   4  33  31   6]\n",
      " [  4 115  29   8  23  26   5]\n",
      " [ 22   2 159   7   2  18   0]\n",
      " [  6  17  18  69  39  46  15]\n",
      " [ 36  18   4   7 118   9  18]\n",
      " [ 12  11  13  10   5 103  56]\n",
      " [  0   0   0   0   2  40 168]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.63      0.63       210\n",
      "           2       0.70      0.55      0.61       210\n",
      "           3       0.71      0.76      0.73       210\n",
      "           4       0.66      0.33      0.44       210\n",
      "           5       0.53      0.56      0.55       210\n",
      "           6       0.38      0.49      0.43       210\n",
      "           7       0.63      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//SentenceTransformers//xlm_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1a99",
   "metadata": {},
   "source": [
    "### Fine Tuned Transformers Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5374149659863946\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[125   1   2   2  14  66   0]\n",
      " [  4 105  17   6   5  72   1]\n",
      " [  1   4 180   1   0  23   1]\n",
      " [  4   9   8  44  15 128   2]\n",
      " [ 37  19   5   7  76  64   2]\n",
      " [  5   5   5   5   1 184   5]\n",
      " [  0   0   0   0   0 134  76]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.60      0.65       210\n",
      "           2       0.73      0.50      0.59       210\n",
      "           3       0.83      0.86      0.84       210\n",
      "           4       0.68      0.21      0.32       210\n",
      "           5       0.68      0.36      0.47       210\n",
      "           6       0.27      0.88      0.42       210\n",
      "           7       0.87      0.36      0.51       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.68      0.54      0.54      1470\n",
      "weighted avg       0.68      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5285714285714286\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[141   6   2  13  38   4   6]\n",
      " [ 28 113  19  13  23   7   7]\n",
      " [ 10  21 171   1   4   1   2]\n",
      " [ 30  30   4  80  41  10  15]\n",
      " [ 55  21   3  22  98   2   9]\n",
      " [ 51  24  11  33  16  34  41]\n",
      " [ 18   7   0  25  11   9 140]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.67      0.52       210\n",
      "           2       0.51      0.54      0.52       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.43      0.38      0.40       210\n",
      "           5       0.42      0.47      0.44       210\n",
      "           6       0.51      0.16      0.25       210\n",
      "           7       0.64      0.67      0.65       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.51      1470\n",
      "weighted avg       0.53      0.53      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5394557823129251\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   4   2  12  36   6   8]\n",
      " [ 26 112  15  15  24  10   8]\n",
      " [  5  26 164   5   4   2   4]\n",
      " [ 24  22   5  82  43   9  25]\n",
      " [ 45  23   2  25 102   2  11]\n",
      " [ 53  19   5  25  14  45  49]\n",
      " [ 18   5   0  15  10  16 146]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.68      0.54       210\n",
      "           2       0.53      0.53      0.53       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.46      0.39      0.42       210\n",
      "           5       0.44      0.49      0.46       210\n",
      "           6       0.50      0.21      0.30       210\n",
      "           7       0.58      0.70      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.53      1470\n",
      "weighted avg       0.54      0.54      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5510204081632653\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   5   3  13  37   6  10]\n",
      " [ 19 110  15  17  30  10   9]\n",
      " [  9  26 164   4   2   2   3]\n",
      " [ 20  16   4  85  54  14  17]\n",
      " [ 42  16   2  26 108   4  12]\n",
      " [ 41  20   4  24  23  49  49]\n",
      " [ 13   3   1  10  13  12 158]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.65      0.56       210\n",
      "           2       0.56      0.52      0.54       210\n",
      "           3       0.85      0.78      0.81       210\n",
      "           4       0.47      0.40      0.44       210\n",
      "           5       0.40      0.51      0.45       210\n",
      "           6       0.51      0.23      0.32       210\n",
      "           7       0.61      0.75      0.68       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.54      1470\n",
      "weighted avg       0.56      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[139   5   5   8  39   5   9]\n",
      " [ 20 116  14  14  27  12   7]\n",
      " [  8  31 160   4   2   1   4]\n",
      " [ 18  23   4  78  55  10  22]\n",
      " [ 41  16   2  22 112   3  14]\n",
      " [ 44  16   6  33  24  37  50]\n",
      " [ 10   2   0   9  12   8 169]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.66      0.57       210\n",
      "           2       0.56      0.55      0.55       210\n",
      "           3       0.84      0.76      0.80       210\n",
      "           4       0.46      0.37      0.41       210\n",
      "           5       0.41      0.53      0.47       210\n",
      "           6       0.49      0.18      0.26       210\n",
      "           7       0.61      0.80      0.70       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5517006802721088\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   3   4  11  40   5  10]\n",
      " [ 19 117  13  10  33   9   9]\n",
      " [ 11  30 159   4   1   1   4]\n",
      " [ 18  19   4  74  60  11  24]\n",
      " [ 44  12   2  23 118   1  10]\n",
      " [ 44  17   6  29  25  39  50]\n",
      " [ 10   1   0   7  13  12 167]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.65      0.56       210\n",
      "           2       0.59      0.56      0.57       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.47      0.35      0.40       210\n",
      "           5       0.41      0.56      0.47       210\n",
      "           6       0.50      0.19      0.27       210\n",
      "           7       0.61      0.80      0.69       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.54      1470\n",
      "weighted avg       0.56      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128   6   4  12  45   6   9]\n",
      " [ 17 113  13  13  36   9   9]\n",
      " [ 11  25 160   4   4   2   4]\n",
      " [ 15  19   4  74  60  12  26]\n",
      " [ 39  16   2  19 121   0  13]\n",
      " [ 43  15   8  24  26  38  56]\n",
      " [  7   1   0   7  10  13 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.61      0.54       210\n",
      "           2       0.58      0.54      0.56       210\n",
      "           3       0.84      0.76      0.80       210\n",
      "           4       0.48      0.35      0.41       210\n",
      "           5       0.40      0.58      0.47       210\n",
      "           6       0.47      0.18      0.26       210\n",
      "           7       0.60      0.82      0.69       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.53      1470\n",
      "weighted avg       0.55      0.55      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.3272108843537415\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 26  17  46   6  10 103   2]\n",
      " [  0  80  31   7   3  89   0]\n",
      " [  0  53 136   0   0  21   0]\n",
      " [  1  26  14  24  10 135   0]\n",
      " [  8  35   5   9  38 114   1]\n",
      " [  1   7  25   1   0 174   2]\n",
      " [  0   1   5   1   0 200   3]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.12      0.21       210\n",
      "           2       0.37      0.38      0.37       210\n",
      "           3       0.52      0.65      0.58       210\n",
      "           4       0.50      0.11      0.19       210\n",
      "           5       0.62      0.18      0.28       210\n",
      "           6       0.21      0.83      0.33       210\n",
      "           7       0.38      0.01      0.03       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.47      0.33      0.28      1470\n",
      "weighted avg       0.47      0.33      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2054421768707483\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 26  11   0   6 154  11   2]\n",
      " [  4  11   0   9 166  14   6]\n",
      " [  6  42  50  10  67  34   1]\n",
      " [  0   8   0   5 181  12   4]\n",
      " [  0   2   0  11 187   7   3]\n",
      " [  1  14   1   7 165  16   6]\n",
      " [  0   3   0   3 185  12   7]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.12      0.21       210\n",
      "           2       0.12      0.05      0.07       210\n",
      "           3       0.98      0.24      0.38       210\n",
      "           4       0.10      0.02      0.04       210\n",
      "           5       0.17      0.89      0.28       210\n",
      "           6       0.15      0.08      0.10       210\n",
      "           7       0.24      0.03      0.06       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.35      0.21      0.16      1470\n",
      "weighted avg       0.35      0.21      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of SVM is:\n",
      " [[126  12   6  11  35  15   5]\n",
      " [  3 141  34  12   4  14   2]\n",
      " [  1   5 195   4   1   3   1]\n",
      " [  9  40  13  78  14  45  11]\n",
      " [ 32  46   9  20  83  12   8]\n",
      " [ 11  21  14  16  11  95  42]\n",
      " [  3   6   0   0   7  26 168]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.60      0.64       210\n",
      "           2       0.52      0.67      0.59       210\n",
      "           3       0.72      0.93      0.81       210\n",
      "           4       0.55      0.37      0.44       210\n",
      "           5       0.54      0.40      0.45       210\n",
      "           6       0.45      0.45      0.45       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6224489795918368\n",
      "Confusion Matrix of SVM is:\n",
      " [[129  12   5  16  28  13   7]\n",
      " [  3 148  29  12   3  13   2]\n",
      " [  1   6 195   3   1   4   0]\n",
      " [  8  41  12  96   6  40   7]\n",
      " [ 32  43   7  24  82  16   6]\n",
      " [  9  24  15  21   9  98  34]\n",
      " [  3   4   2   1   5  28 167]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.61      0.65       210\n",
      "           2       0.53      0.70      0.61       210\n",
      "           3       0.74      0.93      0.82       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.61      0.39      0.48       210\n",
      "           6       0.46      0.47      0.46       210\n",
      "           7       0.75      0.80      0.77       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6782312925170068\n",
      "Confusion Matrix of SVM is:\n",
      " [[131   9   6   8  36  13   7]\n",
      " [  1 148  15  12   5  26   3]\n",
      " [  0  12 184   3   0  10   1]\n",
      " [  3  13   8 120  15  41  10]\n",
      " [ 15  31   4  22 116  14   8]\n",
      " [  4  13   5  16   3 129  40]\n",
      " [  0   2   0   3   4  32 169]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.62      0.72       210\n",
      "           2       0.65      0.70      0.68       210\n",
      "           3       0.83      0.88      0.85       210\n",
      "           4       0.65      0.57      0.61       210\n",
      "           5       0.65      0.55      0.60       210\n",
      "           6       0.49      0.61      0.54       210\n",
      "           7       0.71      0.80      0.75       210\n",
      "\n",
      "    accuracy                           0.68      1470\n",
      "   macro avg       0.69      0.68      0.68      1470\n",
      "weighted avg       0.69      0.68      0.68      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.3183673469387755\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 18   4  19   2  74   0  93]\n",
      " [  1  43   9   1  89   0  67]\n",
      " [  1  44  68   7  54   0  36]\n",
      " [  0  10   3   5  81   0 111]\n",
      " [  0   7   0   0 138   0  65]\n",
      " [  1   8   4   5  37   2 153]\n",
      " [  0   3   0   0  13   0 194]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.09      0.16       210\n",
      "           2       0.36      0.20      0.26       210\n",
      "           3       0.66      0.32      0.43       210\n",
      "           4       0.25      0.02      0.04       210\n",
      "           5       0.28      0.66      0.40       210\n",
      "           6       1.00      0.01      0.02       210\n",
      "           7       0.27      0.92      0.42       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.53      0.32      0.25      1470\n",
      "weighted avg       0.53      0.32      0.25      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.18435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  15   0 195   0   0]\n",
      " [  0   0   7   0 203   0   0]\n",
      " [  0   0  61   0 149   0   0]\n",
      " [  0   0   1   0 209   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   3   0 207   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.70      0.29      0.41       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.15      1.00      0.26       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.18      1470\n",
      "   macro avg       0.12      0.18      0.10      1470\n",
      "weighted avg       0.12      0.18      0.10      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.27687074829931974\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 15 168   0   0   0   0  27]\n",
      " [  6 179   1   0   0   0  24]\n",
      " [  0 145  61   0   0   0   4]\n",
      " [  1 152   0   0   0   0  57]\n",
      " [  0 158   0   0   0   0  52]\n",
      " [  3 136   0   0   0   0  71]\n",
      " [  0  58   0   0   0   0 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.07      0.13       210\n",
      "           2       0.18      0.85      0.30       210\n",
      "           3       0.98      0.29      0.45       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.39      0.72      0.51       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.31      0.28      0.20      1470\n",
      "weighted avg       0.31      0.28      0.20      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 14  22   0   0 146   1  27]\n",
      " [  3  32   0   0 148   3  24]\n",
      " [  0  61  46   0  99   0   4]\n",
      " [  0  12   0   0 140   1  57]\n",
      " [  0   7   0   0 151   0  52]\n",
      " [  0  24   0   0 112   3  71]\n",
      " [  0   5   0   0  53   0 152]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.07      0.12       210\n",
      "           2       0.20      0.15      0.17       210\n",
      "           3       1.00      0.22      0.36       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.18      0.72      0.29       210\n",
      "           6       0.38      0.01      0.03       210\n",
      "           7       0.39      0.72      0.51       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.42      0.27      0.21      1470\n",
      "weighted avg       0.42      0.27      0.21      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.28435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 29   8   0  91  66   0  16]\n",
      " [  6  32   0  82  84   0   6]\n",
      " [ 15  46  46  27  74   0   2]\n",
      " [  5   8   0  88  89   0  20]\n",
      " [  3   4   0  67 114   0  22]\n",
      " [  5  20   0 109  39   2  35]\n",
      " [  0   5   0  85  13   0 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.14      0.21       210\n",
      "           2       0.26      0.15      0.19       210\n",
      "           3       1.00      0.22      0.36       210\n",
      "           4       0.16      0.42      0.23       210\n",
      "           5       0.24      0.54      0.33       210\n",
      "           6       1.00      0.01      0.02       210\n",
      "           7       0.51      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.52      0.28      0.27      1470\n",
      "weighted avg       0.52      0.28      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 28  39   4  25  32  66  16]\n",
      " [  5  71  12  37  36  43   6]\n",
      " [  7  98  64   7  13  19   2]\n",
      " [  1  50   7  58  45  29  20]\n",
      " [  2  40   2  30  79  35  22]\n",
      " [  2  41   7  46  15  64  35]\n",
      " [  0  14   0  38   6  45 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.13      0.22       210\n",
      "           2       0.20      0.34      0.25       210\n",
      "           3       0.67      0.30      0.42       210\n",
      "           4       0.24      0.28      0.26       210\n",
      "           5       0.35      0.38      0.36       210\n",
      "           6       0.21      0.30      0.25       210\n",
      "           7       0.51      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.40      0.32      0.32      1470\n",
      "weighted avg       0.40      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3149659863945578\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[29 30  9 56 42 30 14]\n",
      " [ 8 71 15 56 35 22  3]\n",
      " [10 81 79 22 14  3  1]\n",
      " [ 3 42  5 66 60 15 19]\n",
      " [ 7 28  1 57 86 16 15]\n",
      " [ 4 34 15 68 23 34 32]\n",
      " [ 2 10  4 48 13 35 98]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.14      0.21       210\n",
      "           2       0.24      0.34      0.28       210\n",
      "           3       0.62      0.38      0.47       210\n",
      "           4       0.18      0.31      0.23       210\n",
      "           5       0.32      0.41      0.36       210\n",
      "           6       0.22      0.16      0.19       210\n",
      "           7       0.54      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.37      0.31      0.32      1470\n",
      "weighted avg       0.37      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.30680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 28  27   3  23  63  43  23]\n",
      " [  5  64  13  30  52  24  22]\n",
      " [  5  96  65   7  14  21   2]\n",
      " [  2  36   3  48  78  24  19]\n",
      " [  8  27   0  21 112  23  19]\n",
      " [  6  32   7  38  39  38  50]\n",
      " [ 11  13   0  27  25  38  96]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.13      0.20       210\n",
      "           2       0.22      0.30      0.25       210\n",
      "           3       0.71      0.31      0.43       210\n",
      "           4       0.25      0.23      0.24       210\n",
      "           5       0.29      0.53      0.38       210\n",
      "           6       0.18      0.18      0.18       210\n",
      "           7       0.42      0.46      0.44       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.36      0.31      0.30      1470\n",
      "weighted avg       0.36      0.31      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 51  29  10  22  49  29  20]\n",
      " [ 15  62  24  25  43  24  17]\n",
      " [ 10  82  77   6  13  19   3]\n",
      " [ 14  30  12  30  66  36  22]\n",
      " [ 18  27  14  13  90  31  17]\n",
      " [ 15  32  12  35  25  44  47]\n",
      " [ 20   6   4  24  16  34 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.24      0.29       210\n",
      "           2       0.23      0.30      0.26       210\n",
      "           3       0.50      0.37      0.42       210\n",
      "           4       0.19      0.14      0.16       210\n",
      "           5       0.30      0.43      0.35       210\n",
      "           6       0.20      0.21      0.21       210\n",
      "           7       0.46      0.50      0.48       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.31      1470\n",
      "weighted avg       0.32      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3231292517006803\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 65  31   7  39  27  30  11]\n",
      " [ 26  68  15  35  34  23   9]\n",
      " [ 15  76  80  11  10  16   2]\n",
      " [ 21  34   5  41  65  29  15]\n",
      " [ 26  29   1  36  81  25  12]\n",
      " [ 20  29   5  52  30  37  37]\n",
      " [ 19   6   0  23  24  35 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.31      0.32       210\n",
      "           2       0.25      0.32      0.28       210\n",
      "           3       0.71      0.38      0.50       210\n",
      "           4       0.17      0.20      0.18       210\n",
      "           5       0.30      0.39      0.34       210\n",
      "           6       0.19      0.18      0.18       210\n",
      "           7       0.54      0.49      0.52       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.36      0.32      0.33      1470\n",
      "weighted avg       0.36      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.33945578231292517\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  14  11  17  49  34  10]\n",
      " [ 39  51  22  25  34  30   9]\n",
      " [ 16  35 117  12  12  15   3]\n",
      " [ 40  20   5  29  66  31  19]\n",
      " [ 40  15   5  27  88  27   8]\n",
      " [ 37  17  10  36  25  52  33]\n",
      " [ 17   8   1  11  31  55  87]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.36      0.32       210\n",
      "           2       0.32      0.24      0.28       210\n",
      "           3       0.68      0.56      0.61       210\n",
      "           4       0.18      0.14      0.16       210\n",
      "           5       0.29      0.42      0.34       210\n",
      "           6       0.21      0.25      0.23       210\n",
      "           7       0.51      0.41      0.46       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.36      0.34      0.34      1470\n",
      "weighted avg       0.36      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[75 30 10 18 34 32 11]\n",
      " [34 74 20 19 30 23 10]\n",
      " [48 47 84 12 10  6  3]\n",
      " [27 30  7 38 60 31 17]\n",
      " [39 36  1 24 78 19 13]\n",
      " [31 38  6 33 31 39 32]\n",
      " [16 14  1 16 32 46 85]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.36      0.31       210\n",
      "           2       0.28      0.35      0.31       210\n",
      "           3       0.65      0.40      0.50       210\n",
      "           4       0.24      0.18      0.21       210\n",
      "           5       0.28      0.37      0.32       210\n",
      "           6       0.20      0.19      0.19       210\n",
      "           7       0.50      0.40      0.45       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.35      0.32      0.33      1470\n",
      "weighted avg       0.35      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[70 23 13 13 39 43  9]\n",
      " [27 68 20 22 35 30  8]\n",
      " [37 41 88 10 27  5  2]\n",
      " [30 29  6 34 54 35 22]\n",
      " [41 30  1 23 77 23 15]\n",
      " [26 29  9 32 34 46 34]\n",
      " [ 9  8  1 20 35 43 94]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.33      0.31       210\n",
      "           2       0.30      0.32      0.31       210\n",
      "           3       0.64      0.42      0.51       210\n",
      "           4       0.22      0.16      0.19       210\n",
      "           5       0.26      0.37      0.30       210\n",
      "           6       0.20      0.22      0.21       210\n",
      "           7       0.51      0.45      0.48       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.35      0.32      0.33      1470\n",
      "weighted avg       0.35      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3074829931972789\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[77 14 13 21 33 39 13]\n",
      " [39 62 22 21 30 27  9]\n",
      " [40 29 84 16 28 11  2]\n",
      " [51 24  7 33 48 31 16]\n",
      " [57 20  2 29 63 26 13]\n",
      " [32 26  8 38 26 44 36]\n",
      " [22  4  0 22 30 43 89]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.37      0.29       210\n",
      "           2       0.35      0.30      0.32       210\n",
      "           3       0.62      0.40      0.49       210\n",
      "           4       0.18      0.16      0.17       210\n",
      "           5       0.24      0.30      0.27       210\n",
      "           6       0.20      0.21      0.20       210\n",
      "           7       0.50      0.42      0.46       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.31      1470\n",
      "weighted avg       0.33      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.31768707482993197\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  15  12  18  47  24  15]\n",
      " [ 31  49  28  33  31  28  10]\n",
      " [ 26  37 108   7  22   7   3]\n",
      " [ 39  22  10  36  54  29  20]\n",
      " [ 47  12   5  31  73  25  17]\n",
      " [ 26  33   8  39  34  38  32]\n",
      " [ 22   3   2  24  31  44  84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.38      0.33       210\n",
      "           2       0.29      0.23      0.26       210\n",
      "           3       0.62      0.51      0.56       210\n",
      "           4       0.19      0.17      0.18       210\n",
      "           5       0.25      0.35      0.29       210\n",
      "           6       0.19      0.18      0.19       210\n",
      "           7       0.46      0.40      0.43       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.33      0.32      0.32      1470\n",
      "weighted avg       0.33      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.2979591836734694\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[73 16 13 20 45 29 14]\n",
      " [36 58 24 25 25 27 15]\n",
      " [51 34 83 14 18  9  1]\n",
      " [28 20 11 34 62 31 24]\n",
      " [50 20  2 26 72 21 19]\n",
      " [32 29  9 34 34 36 36]\n",
      " [19 10  2 27 33 37 82]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.35      0.29       210\n",
      "           2       0.31      0.28      0.29       210\n",
      "           3       0.58      0.40      0.47       210\n",
      "           4       0.19      0.16      0.17       210\n",
      "           5       0.25      0.34      0.29       210\n",
      "           6       0.19      0.17      0.18       210\n",
      "           7       0.43      0.39      0.41       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.31      0.30      0.30      1470\n",
      "weighted avg       0.31      0.30      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3047619047619048\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[71 19 11 21 37 40 11]\n",
      " [31 57 26 24 29 27 16]\n",
      " [43 37 92  7 18  8  5]\n",
      " [26 17 15 40 60 27 25]\n",
      " [51 14  4 33 68 19 21]\n",
      " [32 30 13 31 36 34 34]\n",
      " [15 11  4 31 33 30 86]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.34      0.30       210\n",
      "           2       0.31      0.27      0.29       210\n",
      "           3       0.56      0.44      0.49       210\n",
      "           4       0.21      0.19      0.20       210\n",
      "           5       0.24      0.32      0.28       210\n",
      "           6       0.18      0.16      0.17       210\n",
      "           7       0.43      0.41      0.42       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.31      0.30      0.31      1470\n",
      "weighted avg       0.31      0.30      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.308843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[76 17  5 21 37 39 15]\n",
      " [31 53 25 25 36 27 13]\n",
      " [48 34 94  9  9 14  2]\n",
      " [30 18  9 40 59 32 22]\n",
      " [44 18  3 28 76 24 17]\n",
      " [31 27  8 33 38 36 37]\n",
      " [20 11  0 27 40 33 79]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.36      0.31       210\n",
      "           2       0.30      0.25      0.27       210\n",
      "           3       0.65      0.45      0.53       210\n",
      "           4       0.22      0.19      0.20       210\n",
      "           5       0.26      0.36      0.30       210\n",
      "           6       0.18      0.17      0.17       210\n",
      "           7       0.43      0.38      0.40       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.31      1470\n",
      "weighted avg       0.33      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[79 16 12 14 40 38 11]\n",
      " [31 63 21 24 30 30 11]\n",
      " [46 32 90 11 18 11  2]\n",
      " [30 20  4 38 63 34 21]\n",
      " [39 15  6 29 74 27 20]\n",
      " [34 36  7 28 32 39 34]\n",
      " [24  8  1 24 33 32 88]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.38      0.32       210\n",
      "           2       0.33      0.30      0.32       210\n",
      "           3       0.64      0.43      0.51       210\n",
      "           4       0.23      0.18      0.20       210\n",
      "           5       0.26      0.35      0.30       210\n",
      "           6       0.18      0.19      0.19       210\n",
      "           7       0.47      0.42      0.44       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.34      0.32      0.32      1470\n",
      "weighted avg       0.34      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[79 13 13 19 40 37  9]\n",
      " [33 57 22 20 31 33 14]\n",
      " [44 31 93 11 23  8  0]\n",
      " [28 19  7 38 65 33 20]\n",
      " [45 16  5 26 71 30 17]\n",
      " [32 32 12 22 38 40 34]\n",
      " [21  8  4 24 31 38 84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.38      0.32       210\n",
      "           2       0.32      0.27      0.30       210\n",
      "           3       0.60      0.44      0.51       210\n",
      "           4       0.24      0.18      0.21       210\n",
      "           5       0.24      0.34      0.28       210\n",
      "           6       0.18      0.19      0.19       210\n",
      "           7       0.47      0.40      0.43       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.32      1470\n",
      "weighted avg       0.33      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[79 13 13 19 40 37  9]\n",
      " [33 57 22 20 31 33 14]\n",
      " [44 31 93 11 23  8  0]\n",
      " [28 19  7 38 65 33 20]\n",
      " [45 16  5 26 71 30 17]\n",
      " [32 32 12 22 38 40 34]\n",
      " [21  8  4 24 31 38 84]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.38      0.32       210\n",
      "           2       0.32      0.27      0.30       210\n",
      "           3       0.60      0.44      0.51       210\n",
      "           4       0.24      0.18      0.21       210\n",
      "           5       0.24      0.34      0.28       210\n",
      "           6       0.18      0.19      0.19       210\n",
      "           7       0.47      0.40      0.43       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.33      0.31      0.32      1470\n",
      "weighted avg       0.33      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.2707482993197279\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  9   1  52   7   6   0 135]\n",
      " [  2  11  54   6  17   0 120]\n",
      " [  0   7 150   2  13   1  37]\n",
      " [  3   1  19   6  11   0 170]\n",
      " [  0   1   5   5  19   0 180]\n",
      " [  3   5  30   9   6   1 156]\n",
      " [  0   0   6   1   1   0 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.04      0.08       210\n",
      "           2       0.42      0.05      0.09       210\n",
      "           3       0.47      0.71      0.57       210\n",
      "           4       0.17      0.03      0.05       210\n",
      "           5       0.26      0.09      0.13       210\n",
      "           6       0.50      0.00      0.01       210\n",
      "           7       0.20      0.96      0.33       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.37      0.27      0.18      1470\n",
      "weighted avg       0.37      0.27      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.40272108843537413\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 58  33  19   2  50   0  48]\n",
      " [  5  92  36   1  49   0  27]\n",
      " [  8  55 140   1   5   0   1]\n",
      " [  9  25  14   0  87   0  75]\n",
      " [  3  24   3   0 131   0  49]\n",
      " [  7  33  23   2  37   0 108]\n",
      " [  4   9   2   1  22   1 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.28      0.38       210\n",
      "           2       0.34      0.44      0.38       210\n",
      "           3       0.59      0.67      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.34      0.62      0.44       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.36      0.81      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.32      0.40      0.33      1470\n",
      "weighted avg       0.32      0.40      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44693877551020406\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79  25  16   1  47   0  42]\n",
      " [  4 125  16   0  41   0  24]\n",
      " [  5  50 149   0   4   1   1]\n",
      " [  6  37   9   7  80   2  69]\n",
      " [  3  26   2   0 131   1  47]\n",
      " [ 14  41  16   2  37   4  96]\n",
      " [  6   8   2   2  27   3 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.38      0.48       210\n",
      "           2       0.40      0.60      0.48       210\n",
      "           3       0.71      0.71      0.71       210\n",
      "           4       0.58      0.03      0.06       210\n",
      "           5       0.36      0.62      0.45       210\n",
      "           6       0.36      0.02      0.04       210\n",
      "           7       0.37      0.77      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.49      0.45      0.39      1470\n",
      "weighted avg       0.49      0.45      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46122448979591835\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  30   6   4  46   2  32]\n",
      " [  4 134  12   2  36   3  19]\n",
      " [  3  66 135   2   3   0   1]\n",
      " [  4  46   6  22  74   1  57]\n",
      " [  3  30   1   3 134   0  39]\n",
      " [ 16  47   8  11  35   5  88]\n",
      " [  3  15   1   6  23   4 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.43      0.54       210\n",
      "           2       0.36      0.64      0.46       210\n",
      "           3       0.80      0.64      0.71       210\n",
      "           4       0.44      0.10      0.17       210\n",
      "           5       0.38      0.64      0.48       210\n",
      "           6       0.33      0.02      0.04       210\n",
      "           7       0.40      0.75      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.49      0.46      0.42      1470\n",
      "weighted avg       0.49      0.46      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5006802721088436\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 91  26   4   6  50   1  32]\n",
      " [  2 143   8   5  33   6  13]\n",
      " [  1  63 141   1   3   0   1]\n",
      " [  4  39   7  36  73   4  47]\n",
      " [  3  27   1   5 143   2  29]\n",
      " [ 12  45  10   9  31  17  86]\n",
      " [  3  14   1   6  18   3 165]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.43      0.56       210\n",
      "           2       0.40      0.68      0.50       210\n",
      "           3       0.82      0.67      0.74       210\n",
      "           4       0.53      0.17      0.26       210\n",
      "           5       0.41      0.68      0.51       210\n",
      "           6       0.52      0.08      0.14       210\n",
      "           7       0.44      0.79      0.57       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.56      0.50      0.47      1470\n",
      "weighted avg       0.56      0.50      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5204081632653061\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[109  14   6   4  41   6  30]\n",
      " [  3 149   6   6  26   6  14]\n",
      " [  2  59 143   0   1   4   1]\n",
      " [  6  36   5  53  58   6  46]\n",
      " [ 11  34   1   6 126   0  32]\n",
      " [ 15  47   3  20  19  19  87]\n",
      " [  4   9   0  14   9   8 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.52      0.61       210\n",
      "           2       0.43      0.71      0.53       210\n",
      "           3       0.87      0.68      0.76       210\n",
      "           4       0.51      0.25      0.34       210\n",
      "           5       0.45      0.60      0.51       210\n",
      "           6       0.39      0.09      0.15       210\n",
      "           7       0.44      0.79      0.57       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.55      0.52      0.50      1470\n",
      "weighted avg       0.55      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 85  20   8  11  49  12  25]\n",
      " [  2 135   8  12  30  12  11]\n",
      " [  2  54 145   3   2   3   1]\n",
      " [  3  34   5  61  52  10  45]\n",
      " [  9  26   1  11 130   5  28]\n",
      " [  5  41   9  20  22  30  83]\n",
      " [  3   6   1  11  15  11 163]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.40      0.53       210\n",
      "           2       0.43      0.64      0.51       210\n",
      "           3       0.82      0.69      0.75       210\n",
      "           4       0.47      0.29      0.36       210\n",
      "           5       0.43      0.62      0.51       210\n",
      "           6       0.36      0.14      0.20       210\n",
      "           7       0.46      0.78      0.58       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.54      0.51      0.49      1470\n",
      "weighted avg       0.54      0.51      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97  14   8  13  45   8  25]\n",
      " [  1 135  10  18  26  10  10]\n",
      " [  5  45 148   5   1   4   2]\n",
      " [  7  31   6  73  44  10  39]\n",
      " [  6  23   1  17 132   6  25]\n",
      " [ 10  29   4  31  12  52  72]\n",
      " [  3   8   0  10  10  10 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.46      0.57       210\n",
      "           2       0.47      0.64      0.55       210\n",
      "           3       0.84      0.70      0.76       210\n",
      "           4       0.44      0.35      0.39       210\n",
      "           5       0.49      0.63      0.55       210\n",
      "           6       0.52      0.25      0.34       210\n",
      "           7       0.49      0.80      0.61       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.54      1470\n",
      "weighted avg       0.57      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5571428571428572\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99  16   6  18  41   7  23]\n",
      " [  4 141  11  19  15  12   8]\n",
      " [  2  42 154   1   3   7   1]\n",
      " [  5  29   4  76  46  14  36]\n",
      " [ 10  24   1  20 123   6  26]\n",
      " [  6  31   8  25  12  55  73]\n",
      " [  1   8   0   7   6  17 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.47      0.59       210\n",
      "           2       0.48      0.67      0.56       210\n",
      "           3       0.84      0.73      0.78       210\n",
      "           4       0.46      0.36      0.40       210\n",
      "           5       0.50      0.59      0.54       210\n",
      "           6       0.47      0.26      0.34       210\n",
      "           7       0.51      0.81      0.62       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.58      0.56      0.55      1470\n",
      "weighted avg       0.58      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5530612244897959\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  18   6  12  43  10  20]\n",
      " [  7 135   7  19  20  10  12]\n",
      " [  3  44 152   2   2   6   1]\n",
      " [  4  28   7  70  44  19  38]\n",
      " [ 15  23   0  15 129   8  20]\n",
      " [ 11  37   5  24  11  52  70]\n",
      " [  1   7   1   8   6  13 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.48      0.57       210\n",
      "           2       0.46      0.64      0.54       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.47      0.33      0.39       210\n",
      "           5       0.51      0.61      0.55       210\n",
      "           6       0.44      0.25      0.32       210\n",
      "           7       0.52      0.83      0.64       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.57      0.55      0.54      1470\n",
      "weighted avg       0.57      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101  15   5  20  40  12  17]\n",
      " [  5 126   8  17  25  19  10]\n",
      " [  3  37 157   5   3   3   2]\n",
      " [  2  20   6  81  46  22  33]\n",
      " [ 13  25   1  20 122   9  20]\n",
      " [ 12  25   6  22  11  73  61]\n",
      " [  2   6   1   8   4  27 162]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.48      0.58       210\n",
      "           2       0.50      0.60      0.54       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.47      0.39      0.42       210\n",
      "           5       0.49      0.58      0.53       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.53      0.77      0.63       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.57      0.56      0.56      1470\n",
      "weighted avg       0.57      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.572108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[108  11   7  23  37  15   9]\n",
      " [  6 129   7  20  18  18  12]\n",
      " [  1  31 159   7   2   9   1]\n",
      " [  7  20   7  96  34  20  26]\n",
      " [ 11  21   2  24 121   8  23]\n",
      " [ 14  30   3  22  11  68  62]\n",
      " [  6   6   0  12   8  18 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.51      0.60       210\n",
      "           2       0.52      0.61      0.56       210\n",
      "           3       0.86      0.76      0.81       210\n",
      "           4       0.47      0.46      0.46       210\n",
      "           5       0.52      0.58      0.55       210\n",
      "           6       0.44      0.32      0.37       210\n",
      "           7       0.55      0.76      0.64       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.57      1470\n",
      "weighted avg       0.58      0.57      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106   8   7  18  43  14  14]\n",
      " [  8 116  15  28  23  15   5]\n",
      " [  3  32 157   5   3  10   0]\n",
      " [  5  29   6  75  43  29  23]\n",
      " [ 14  20   1  17 131  11  16]\n",
      " [  8  26   9  29  11  63  64]\n",
      " [  2   6   1  11   5  19 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.50      0.60       210\n",
      "           2       0.49      0.55      0.52       210\n",
      "           3       0.80      0.75      0.77       210\n",
      "           4       0.41      0.36      0.38       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.39      0.30      0.34       210\n",
      "           7       0.58      0.79      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[107  18   5  19  34  13  14]\n",
      " [  4 128  12  20  22  17   7]\n",
      " [  5  38 158   2   4   2   1]\n",
      " [  3  34   5  78  42  20  28]\n",
      " [ 20  24   1  23 117   8  17]\n",
      " [  7  29   6  22  10  75  61]\n",
      " [  3   7   1  10   7  13 169]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.51      0.60       210\n",
      "           2       0.46      0.61      0.52       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.45      0.37      0.41       210\n",
      "           5       0.50      0.56      0.52       210\n",
      "           6       0.51      0.36      0.42       210\n",
      "           7       0.57      0.80      0.67       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5448979591836735\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  15   6  23  34  16  13]\n",
      " [  9 123   9  20  21  22   6]\n",
      " [  2  37 158   5   3   4   1]\n",
      " [  4  26   9  82  37  30  22]\n",
      " [ 20  28   1  25 110   7  19]\n",
      " [  9  24   7  24  17  75  54]\n",
      " [  2   8   1  10   7  32 150]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.49      0.57       210\n",
      "           2       0.47      0.59      0.52       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.43      0.39      0.41       210\n",
      "           5       0.48      0.52      0.50       210\n",
      "           6       0.40      0.36      0.38       210\n",
      "           7       0.57      0.71      0.63       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.54      1470\n",
      "weighted avg       0.55      0.54      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.5591836734693878\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[106  13   6  17  37  18  13]\n",
      " [  6 128  11  22  17  23   3]\n",
      " [  2  29 162   6   5   5   1]\n",
      " [ 11  26   6  78  39  30  20]\n",
      " [ 15  22   2  21 119  16  15]\n",
      " [ 14  26   7  31   8  77  47]\n",
      " [  1   5   0  10   2  40 152]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.50      0.58       210\n",
      "           2       0.51      0.61      0.56       210\n",
      "           3       0.84      0.77      0.80       210\n",
      "           4       0.42      0.37      0.39       210\n",
      "           5       0.52      0.57      0.54       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.61      0.72      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5544217687074829\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[103  17   8  21  34  14  13]\n",
      " [  4 128  11  29  17  15   6]\n",
      " [  1  36 157   7   3   6   0]\n",
      " [  6  27   6  81  42  26  22]\n",
      " [ 16  25   5  20 108  19  17]\n",
      " [ 12  25   7  25  11  78  52]\n",
      " [  1   3   0   9   3  34 160]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.49      0.58       210\n",
      "           2       0.49      0.61      0.54       210\n",
      "           3       0.81      0.75      0.78       210\n",
      "           4       0.42      0.39      0.40       210\n",
      "           5       0.50      0.51      0.50       210\n",
      "           6       0.41      0.37      0.39       210\n",
      "           7       0.59      0.76      0.67       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.55      1470\n",
      "weighted avg       0.56      0.55      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5482993197278911\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  19   7  18  34  20   8]\n",
      " [  9 135   9  13  19  19   6]\n",
      " [  2  36 157   6   2   5   2]\n",
      " [ 11  30   6  75  38  30  20]\n",
      " [ 17  26   4  23 113  12  15]\n",
      " [ 14  28   9  24  14  64  57]\n",
      " [  0   6   0   7   5  34 158]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.50      0.57       210\n",
      "           2       0.48      0.64      0.55       210\n",
      "           3       0.82      0.75      0.78       210\n",
      "           4       0.45      0.36      0.40       210\n",
      "           5       0.50      0.54      0.52       210\n",
      "           6       0.35      0.30      0.32       210\n",
      "           7       0.59      0.75      0.66       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.55      0.55      0.54      1470\n",
      "weighted avg       0.55      0.55      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5789115646258504\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116  13   8  25  30  11   7]\n",
      " [  5 127   9  20  24  22   3]\n",
      " [  2  25 168   5   2   7   1]\n",
      " [  4  20   9  97  34  25  21]\n",
      " [ 19  23   2  27 111  12  16]\n",
      " [ 12  19   8  25  14  75  57]\n",
      " [  1   4   1   9   6  32 157]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.55      0.63       210\n",
      "           2       0.55      0.60      0.58       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.47      0.46      0.46       210\n",
      "           5       0.50      0.53      0.52       210\n",
      "           6       0.41      0.36      0.38       210\n",
      "           7       0.60      0.75      0.67       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.58      1470\n",
      "weighted avg       0.58      0.58      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5639455782312925\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[112  14   8  19  32  16   9]\n",
      " [  8 127  12  20  17  23   3]\n",
      " [  1  25 167   5   3   7   2]\n",
      " [  8  27   7  86  35  28  19]\n",
      " [ 21  21   2  31 108   9  18]\n",
      " [ 19  22  10  24  12  77  46]\n",
      " [  2   2   1  11   5  37 152]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.53      0.59       210\n",
      "           2       0.53      0.60      0.57       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.44      0.41      0.42       210\n",
      "           5       0.51      0.51      0.51       210\n",
      "           6       0.39      0.37      0.38       210\n",
      "           7       0.61      0.72      0.66       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.56      1470\n",
      "weighted avg       0.56      0.56      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 54  27  30  18  40   8  33]\n",
      " [  1 122  18  14  28  12  15]\n",
      " [  3  94  98   2   7   5   1]\n",
      " [  2  37   5  60  49   7  50]\n",
      " [  6  26   0   5 132   2  39]\n",
      " [ 11  43   8  21  28  21  78]\n",
      " [  9   9   2  18  16   9 147]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.26      0.36       210\n",
      "           2       0.34      0.58      0.43       210\n",
      "           3       0.61      0.47      0.53       210\n",
      "           4       0.43      0.29      0.34       210\n",
      "           5       0.44      0.63      0.52       210\n",
      "           6       0.33      0.10      0.15       210\n",
      "           7       0.40      0.70      0.51       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.46      0.43      0.41      1470\n",
      "weighted avg       0.46      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//bert_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df947aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5469387755102041\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[138   5  13   2   4  34  14]\n",
      " [ 19 114  18   2   5  37  15]\n",
      " [  3   8 188   2   0   7   2]\n",
      " [ 33  15  15  78   2  57  10]\n",
      " [103  12   8  19  10  37  21]\n",
      " [ 18   9  17   4   2  84  76]\n",
      " [  2   2   0   0   0  14 192]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.66      0.52       210\n",
      "           2       0.69      0.54      0.61       210\n",
      "           3       0.73      0.90      0.80       210\n",
      "           4       0.73      0.37      0.49       210\n",
      "           5       0.43      0.05      0.09       210\n",
      "           6       0.31      0.40      0.35       210\n",
      "           7       0.58      0.91      0.71       210\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.56      0.55      0.51      1470\n",
      "weighted avg       0.56      0.55      0.51      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5299319727891156\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  14  15  12  30  11   9]\n",
      " [ 24 138   8  13  16   3   8]\n",
      " [ 11  17 145  33   1   3   0]\n",
      " [ 47  21   5  83  42   5   7]\n",
      " [ 71  21   5  26  72   5  10]\n",
      " [ 36  24  13  22  10  49  56]\n",
      " [  8   2   0   1   9  17 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.57      0.45       210\n",
      "           2       0.58      0.66      0.62       210\n",
      "           3       0.76      0.69      0.72       210\n",
      "           4       0.44      0.40      0.42       210\n",
      "           5       0.40      0.34      0.37       210\n",
      "           6       0.53      0.23      0.32       210\n",
      "           7       0.66      0.82      0.73       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.53      0.53      0.52      1470\n",
      "weighted avg       0.53      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[111  14  15  13  32  15  10]\n",
      " [ 16 144   8  13  16   5   8]\n",
      " [  9  13 149  34   2   2   1]\n",
      " [ 26  22   4  98  43   9   8]\n",
      " [ 48  18   2  31  94   6  11]\n",
      " [ 39  20  11  16   9  56  59]\n",
      " [  4   2   0   1   6  31 166]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.53      0.48       210\n",
      "           2       0.62      0.69      0.65       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.48      0.47      0.47       210\n",
      "           5       0.47      0.45      0.46       210\n",
      "           6       0.45      0.27      0.34       210\n",
      "           7       0.63      0.79      0.70       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.55      1470\n",
      "weighted avg       0.55      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[113  16  15   9  31  14  12]\n",
      " [ 17 140   9  14  14   6  10]\n",
      " [ 12  14 145  10   1  27   1]\n",
      " [ 31  20   3  95  44   9   8]\n",
      " [ 46  17   3  34  94   6  10]\n",
      " [ 28  22  14  15  13  50  68]\n",
      " [  3   1   0   2   7  18 179]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.54      0.49       210\n",
      "           2       0.61      0.67      0.64       210\n",
      "           3       0.77      0.69      0.73       210\n",
      "           4       0.53      0.45      0.49       210\n",
      "           5       0.46      0.45      0.45       210\n",
      "           6       0.38      0.24      0.29       210\n",
      "           7       0.62      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.54      1470\n",
      "weighted avg       0.55      0.56      0.54      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5666666666666667\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[123  11  16   8  30  11  11]\n",
      " [ 13 144   8  13  16   8   8]\n",
      " [  6  13 146  20   4  19   2]\n",
      " [ 26  19   4  91  53   9   8]\n",
      " [ 46  17   3  27 102   6   9]\n",
      " [ 31  23  11  17  12  47  69]\n",
      " [  6   0   0   1   5  18 180]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.53       210\n",
      "           2       0.63      0.69      0.66       210\n",
      "           3       0.78      0.70      0.73       210\n",
      "           4       0.51      0.43      0.47       210\n",
      "           5       0.46      0.49      0.47       210\n",
      "           6       0.40      0.22      0.29       210\n",
      "           7       0.63      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.55      1470\n",
      "weighted avg       0.56      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.564625850340136\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  13  13  12  32  10  11]\n",
      " [ 14 141   8  12  20   5  10]\n",
      " [  7  14 148  35   3   1   2]\n",
      " [ 23  18   4  96  54   6   9]\n",
      " [ 52  15   1  29 100   5   8]\n",
      " [ 32  23  12  20  10  40  73]\n",
      " [  5   0   0   1   6  12 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.57      0.52       210\n",
      "           2       0.63      0.67      0.65       210\n",
      "           3       0.80      0.70      0.75       210\n",
      "           4       0.47      0.46      0.46       210\n",
      "           5       0.44      0.48      0.46       210\n",
      "           6       0.51      0.19      0.28       210\n",
      "           7       0.62      0.89      0.73       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.56      0.56      0.55      1470\n",
      "weighted avg       0.56      0.56      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5659863945578232\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[117  14  12  13  33   8  13]\n",
      " [ 16 142   8  14  16   5   9]\n",
      " [  7  15 145  37   3   2   1]\n",
      " [ 29  16   5  93  51   8   8]\n",
      " [ 43  15   2  28 108   5   9]\n",
      " [ 29  21  14  22  11  41  72]\n",
      " [  4   0   0   1   7  12 186]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.56      0.51       210\n",
      "           2       0.64      0.68      0.66       210\n",
      "           3       0.78      0.69      0.73       210\n",
      "           4       0.45      0.44      0.44       210\n",
      "           5       0.47      0.51      0.49       210\n",
      "           6       0.51      0.20      0.28       210\n",
      "           7       0.62      0.89      0.73       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.56      0.57      0.55      1470\n",
      "weighted avg       0.56      0.57      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.4530612244897959\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 55  13   3  12  64  53  10]\n",
      " [  2  90   2  14  42  52   8]\n",
      " [ 14  11  58  53  32  42   0]\n",
      " [  8  11   1  57  90  35   8]\n",
      " [  6  10   0  12 148  25   9]\n",
      " [ 11  14   3  15  17  87  63]\n",
      " [  1   4   0   0   2  32 171]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.26      0.36       210\n",
      "           2       0.59      0.43      0.50       210\n",
      "           3       0.87      0.28      0.42       210\n",
      "           4       0.35      0.27      0.31       210\n",
      "           5       0.37      0.70      0.49       210\n",
      "           6       0.27      0.41      0.32       210\n",
      "           7       0.64      0.81      0.71       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.52      0.45      0.44      1470\n",
      "weighted avg       0.52      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2054421768707483\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[  8   8   6  11 161  10   6]\n",
      " [  8  30   9  11 133  13   6]\n",
      " [  6  28  19   4 143   8   2]\n",
      " [ 10   7   9  18 145  11  10]\n",
      " [  5   6   4  10 178   5   2]\n",
      " [ 10  13   8   9 124  27  19]\n",
      " [ 11   6   3   7 149  12  22]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.04      0.06       210\n",
      "           2       0.31      0.14      0.19       210\n",
      "           3       0.33      0.09      0.14       210\n",
      "           4       0.26      0.09      0.13       210\n",
      "           5       0.17      0.85      0.29       210\n",
      "           6       0.31      0.13      0.18       210\n",
      "           7       0.33      0.10      0.16       210\n",
      "\n",
      "    accuracy                           0.21      1470\n",
      "   macro avg       0.26      0.21      0.16      1470\n",
      "weighted avg       0.26      0.21      0.16      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.6034013605442177\n",
      "Confusion Matrix of SVM is:\n",
      " [[120  14   8   5  12  47   4]\n",
      " [  6 167   8   2   6  18   3]\n",
      " [  3  15 187   1   1   3   0]\n",
      " [ 16  30  11  94  18  32   9]\n",
      " [ 76  41   2  18  48  13  12]\n",
      " [ 13  26  24   5   3  80  59]\n",
      " [  3   4   1   0   0  11 191]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.57      0.54       210\n",
      "           2       0.56      0.80      0.66       210\n",
      "           3       0.78      0.89      0.83       210\n",
      "           4       0.75      0.45      0.56       210\n",
      "           5       0.55      0.23      0.32       210\n",
      "           6       0.39      0.38      0.39       210\n",
      "           7       0.69      0.91      0.78       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.58      1470\n",
      "weighted avg       0.60      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6068027210884354\n",
      "Confusion Matrix of SVM is:\n",
      " [[121   9  10   5   5  56   4]\n",
      " [ 10 165   8   6   4  15   2]\n",
      " [  1  12 189   4   0   4   0]\n",
      " [ 24  20  12  99  15  32   8]\n",
      " [ 94  24   3  24  39  15  11]\n",
      " [ 13  28  18   8   3  91  49]\n",
      " [  1   3   2   0   0  16 188]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.58      0.51       210\n",
      "           2       0.63      0.79      0.70       210\n",
      "           3       0.78      0.90      0.84       210\n",
      "           4       0.68      0.47      0.56       210\n",
      "           5       0.59      0.19      0.28       210\n",
      "           6       0.40      0.43      0.41       210\n",
      "           7       0.72      0.90      0.80       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.59      1470\n",
      "weighted avg       0.61      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.6714285714285714\n",
      "Confusion Matrix of SVM is:\n",
      " [[108   7  14  10  40  27   4]\n",
      " [  2 153   8  11  10  22   4]\n",
      " [  1   7 185   6   2   9   0]\n",
      " [  6  14   6 130  34  16   4]\n",
      " [ 21  16   1  26 128  10   8]\n",
      " [ 10  15  15  17   8 107  38]\n",
      " [  2   0   1   1   2  28 176]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.51      0.60       210\n",
      "           2       0.72      0.73      0.73       210\n",
      "           3       0.80      0.88      0.84       210\n",
      "           4       0.65      0.62      0.63       210\n",
      "           5       0.57      0.61      0.59       210\n",
      "           6       0.49      0.51      0.50       210\n",
      "           7       0.75      0.84      0.79       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.3006802721088435\n",
      "Confusion Matrix of SVM is:\n",
      " [[  0   6  42   0 154   0   8]\n",
      " [  0  14  39   2 149   0   6]\n",
      " [  0   1 101   1 107   0   0]\n",
      " [  0   4  10   5 185   0   6]\n",
      " [  0   0   4   0 204   0   2]\n",
      " [  0  10  36   4 117   0  43]\n",
      " [  0  11  11   9  61   0 118]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.30      0.07      0.11       210\n",
      "           3       0.42      0.48      0.45       210\n",
      "           4       0.24      0.02      0.04       210\n",
      "           5       0.21      0.97      0.34       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.64      0.56      0.60       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.26      0.30      0.22      1470\n",
      "weighted avg       0.26      0.30      0.22      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.21972789115646257\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0   8   0 202   0   0]\n",
      " [  0   0  13   0 197   0   0]\n",
      " [  0   0 113   0  97   0   0]\n",
      " [  0   0   5   0 205   0   0]\n",
      " [  0   0   0   0 210   0   0]\n",
      " [  0   0   7   0 203   0   0]\n",
      " [  0   0   0   0 210   0   0]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.77      0.54      0.63       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.16      1.00      0.27       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.00      0.00      0.00       210\n",
      "\n",
      "    accuracy                           0.22      1470\n",
      "   macro avg       0.13      0.22      0.13      1470\n",
      "weighted avg       0.13      0.22      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.29931972789115646\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   3   5   0 197   0   5]\n",
      " [  0   7   6   0 192   0   5]\n",
      " [  0   1 112   0  97   0   0]\n",
      " [  0   0   5   0 196   0   9]\n",
      " [  0   0   0   0 206   0   4]\n",
      " [  0   1   6   0 160   0  43]\n",
      " [  0   0   0   0  95   0 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.58      0.03      0.06       210\n",
      "           3       0.84      0.53      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.18      0.98      0.30       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.64      0.55      0.59       210\n",
      "\n",
      "    accuracy                           0.30      1470\n",
      "   macro avg       0.32      0.30      0.23      1470\n",
      "weighted avg       0.32      0.30      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3469387755102041\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  2  82   2   0 116   3   5]\n",
      " [  1 130   3   0  68   3   5]\n",
      " [  0  44  83   0  54  29   0]\n",
      " [  0  39   3   0 157   2   9]\n",
      " [  0  29   0   0 177   0   4]\n",
      " [  0 121   3   0  40   3  43]\n",
      " [  0  71   0   0  24   0 115]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.01      0.02       210\n",
      "           2       0.25      0.62      0.36       210\n",
      "           3       0.88      0.40      0.55       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.28      0.84      0.42       210\n",
      "           6       0.07      0.01      0.02       210\n",
      "           7       0.64      0.55      0.59       210\n",
      "\n",
      "    accuracy                           0.35      1470\n",
      "   macro avg       0.40      0.35      0.28      1470\n",
      "weighted avg       0.40      0.35      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  2  45   2  53  66  37   5]\n",
      " [  0  98   3  35  36  33   5]\n",
      " [  0  27  83  68  15  17   0]\n",
      " [  0  11   3  84  76  29   7]\n",
      " [  0  11   0  80  98  18   3]\n",
      " [  0  42   3  20  29  84  32]\n",
      " [  0  17   0   3  24  58 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.01      0.02       210\n",
      "           2       0.39      0.47      0.43       210\n",
      "           3       0.88      0.40      0.55       210\n",
      "           4       0.24      0.40      0.30       210\n",
      "           5       0.28      0.47      0.35       210\n",
      "           6       0.30      0.40      0.35       210\n",
      "           7       0.68      0.51      0.58       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.54      0.38      0.37      1470\n",
      "weighted avg       0.54      0.38      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39319727891156464\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 53  16  33  22  61  20   5]\n",
      " [ 38  84  24  14  13  32   5]\n",
      " [ 12  21 118  33  11  15   0]\n",
      " [ 14  10  34  52  68  26   6]\n",
      " [  6  23  41  39  81  18   2]\n",
      " [ 26  23   9  14  25  82  31]\n",
      " [  9   9   0   2  23  59 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.25      0.29       210\n",
      "           2       0.45      0.40      0.42       210\n",
      "           3       0.46      0.56      0.50       210\n",
      "           4       0.30      0.25      0.27       210\n",
      "           5       0.29      0.39      0.33       210\n",
      "           6       0.33      0.39      0.35       210\n",
      "           7       0.69      0.51      0.59       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.39      1470\n",
      "weighted avg       0.41      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39387755102040817\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  31  17  40  25  17   5]\n",
      " [ 13 114  11  40   9  20   3]\n",
      " [ 13  30  88  18   1  60   0]\n",
      " [ 42  17  14  75  34  24   4]\n",
      " [ 28  18  20  67  64  12   1]\n",
      " [ 33  39   5  37   8  61  27]\n",
      " [ 24  17   0  10   2  55 102]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.36      0.34       210\n",
      "           2       0.43      0.54      0.48       210\n",
      "           3       0.57      0.42      0.48       210\n",
      "           4       0.26      0.36      0.30       210\n",
      "           5       0.45      0.30      0.36       210\n",
      "           6       0.24      0.29      0.27       210\n",
      "           7       0.72      0.49      0.58       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.43      0.39      0.40      1470\n",
      "weighted avg       0.43      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3952380952380952\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  39  26  22  31  19   5]\n",
      " [ 10 127  20  15  12  21   5]\n",
      " [  9  38  90  33   7  33   0]\n",
      " [ 39  32  18  61  36  20   4]\n",
      " [ 28  46   9  38  76  12   1]\n",
      " [ 26  58  14  18   8  60  26]\n",
      " [ 21  22   5   4   2  57  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.32      0.33       210\n",
      "           2       0.35      0.60      0.44       210\n",
      "           3       0.49      0.43      0.46       210\n",
      "           4       0.32      0.29      0.30       210\n",
      "           5       0.44      0.36      0.40       210\n",
      "           6       0.27      0.29      0.28       210\n",
      "           7       0.71      0.47      0.57       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.40      1470\n",
      "weighted avg       0.42      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41156462585034015\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  32  22  24  23  26   5]\n",
      " [ 21 113  16  16  12  24   8]\n",
      " [ 13  32  80   4  13  62   6]\n",
      " [ 31  24  15  80  29  25   6]\n",
      " [ 38  36   6  47  68  12   3]\n",
      " [ 26  34  11  21   9  75  34]\n",
      " [ 22  10   0   3   6  58 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.37      0.36       210\n",
      "           2       0.40      0.54      0.46       210\n",
      "           3       0.53      0.38      0.44       210\n",
      "           4       0.41      0.38      0.40       210\n",
      "           5       0.42      0.32      0.37       210\n",
      "           6       0.27      0.36      0.30       210\n",
      "           7       0.64      0.53      0.58       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.43      0.41      0.42      1470\n",
      "weighted avg       0.43      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  19  24  29  27  21   7]\n",
      " [ 24 102  18  17  11  29   9]\n",
      " [ 18  22 107  34  13  14   2]\n",
      " [ 34  17  21  70  33  25  10]\n",
      " [ 46  23  16  35  66  21   3]\n",
      " [ 29  32  11  16  14  61  47]\n",
      " [ 21   6   1   3   5  43 131]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.40      0.36       210\n",
      "           2       0.46      0.49      0.47       210\n",
      "           3       0.54      0.51      0.52       210\n",
      "           4       0.34      0.33      0.34       210\n",
      "           5       0.39      0.31      0.35       210\n",
      "           6       0.29      0.29      0.29       210\n",
      "           7       0.63      0.62      0.63       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 85  24  21  24  27  23   6]\n",
      " [ 17 106  21  18  14  24  10]\n",
      " [ 14  24  94   6   7  64   1]\n",
      " [ 34  21  16  78  31  25   5]\n",
      " [ 40  27  16  26  79  17   5]\n",
      " [ 30  32  12  21  10  63  42]\n",
      " [ 23  10   0   2   5  54 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.40      0.38       210\n",
      "           2       0.43      0.50      0.47       210\n",
      "           3       0.52      0.45      0.48       210\n",
      "           4       0.45      0.37      0.41       210\n",
      "           5       0.46      0.38      0.41       210\n",
      "           6       0.23      0.30      0.26       210\n",
      "           7       0.63      0.55      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.43      1470\n",
      "weighted avg       0.44      0.42      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3761904761904762\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  16  21  29  33  18   7]\n",
      " [ 32  80  17  29  20  23   9]\n",
      " [ 21  23  80  35  17  31   3]\n",
      " [ 31  15  14  63  62  20   5]\n",
      " [ 48  19   8  25  91  15   4]\n",
      " [ 34  23   9  31  27  50  36]\n",
      " [ 15   8   1   3  21  59 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.41      0.36       210\n",
      "           2       0.43      0.38      0.41       210\n",
      "           3       0.53      0.38      0.44       210\n",
      "           4       0.29      0.30      0.30       210\n",
      "           5       0.34      0.43      0.38       210\n",
      "           6       0.23      0.24      0.23       210\n",
      "           7       0.62      0.49      0.55       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.40      0.38      0.38      1470\n",
      "weighted avg       0.40      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 69  31  22  36  24  19   9]\n",
      " [ 27  92  18  30  15  20   8]\n",
      " [ 21  24  85  36  10  32   2]\n",
      " [ 21  23  21  64  55  19   7]\n",
      " [ 38  33  16  33  70  15   5]\n",
      " [ 30  22  16  27  25  52  38]\n",
      " [  9   8   0  12  18  58 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.33      0.32       210\n",
      "           2       0.39      0.44      0.42       210\n",
      "           3       0.48      0.40      0.44       210\n",
      "           4       0.27      0.30      0.29       210\n",
      "           5       0.32      0.33      0.33       210\n",
      "           6       0.24      0.25      0.24       210\n",
      "           7       0.60      0.50      0.55       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3761904761904762\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  22  31  29  22  24   8]\n",
      " [ 21  83  24  26  22  23  11]\n",
      " [ 15  24  96  36   7  31   1]\n",
      " [ 24  17  21  78  38  26   6]\n",
      " [ 41  25  15  39  66  17   7]\n",
      " [ 41  15  13  29  21  49  42]\n",
      " [ 13   6   0   4  19  61 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.35      0.34       210\n",
      "           2       0.43      0.40      0.41       210\n",
      "           3       0.48      0.46      0.47       210\n",
      "           4       0.32      0.37      0.35       210\n",
      "           5       0.34      0.31      0.33       210\n",
      "           6       0.21      0.23      0.22       210\n",
      "           7       0.59      0.51      0.55       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.39      0.38      0.38      1470\n",
      "weighted avg       0.39      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.363265306122449\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  18  25  32  26  32   6]\n",
      " [ 20  81  22  24  27  21  15]\n",
      " [ 14  19  97  36  12  31   1]\n",
      " [ 29  23  20  61  41  30   6]\n",
      " [ 41  34  14  22  69  23   7]\n",
      " [ 33  13  19  24  29  52  40]\n",
      " [ 18   7   0   7  19  56 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.34      0.33       210\n",
      "           2       0.42      0.39      0.40       210\n",
      "           3       0.49      0.46      0.48       210\n",
      "           4       0.30      0.29      0.29       210\n",
      "           5       0.31      0.33      0.32       210\n",
      "           6       0.21      0.25      0.23       210\n",
      "           7       0.58      0.49      0.53       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.37      0.36      0.37      1470\n",
      "weighted avg       0.37      0.36      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37755102040816324\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  23  26  34  31  23   6]\n",
      " [ 25  87  21  22  23  16  16]\n",
      " [ 13  24  87  36  17  31   2]\n",
      " [ 22  19  19  68  48  23  11]\n",
      " [ 27  33  10  31  79  23   7]\n",
      " [ 27  21   9  29  31  51  42]\n",
      " [ 14   5   1   6  21  47 116]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.32      0.33       210\n",
      "           2       0.41      0.41      0.41       210\n",
      "           3       0.50      0.41      0.45       210\n",
      "           4       0.30      0.32      0.31       210\n",
      "           5       0.32      0.38      0.34       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.58      0.55      0.57       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.38      0.38      0.38      1470\n",
      "weighted avg       0.38      0.38      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3877551020408163\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  21  23  28  21  28   9]\n",
      " [ 26  86  17  31  19  18  13]\n",
      " [ 17  18  89  36  15  30   5]\n",
      " [ 22  16  19  78  39  27   9]\n",
      " [ 35  35  14  37  62  18   9]\n",
      " [ 26  21  16  23  24  55  45]\n",
      " [  7   6   0   5  20  52 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.38      0.38       210\n",
      "           2       0.42      0.41      0.42       210\n",
      "           3       0.50      0.42      0.46       210\n",
      "           4       0.33      0.37      0.35       210\n",
      "           5       0.31      0.30      0.30       210\n",
      "           6       0.24      0.26      0.25       210\n",
      "           7       0.57      0.57      0.57       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.39      1470\n",
      "weighted avg       0.39      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36666666666666664\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  20  18  35  25  30   8]\n",
      " [ 27  82  15  28  23  19  16]\n",
      " [ 21  20  82  37  16  34   0]\n",
      " [ 24  24  14  73  40  24  11]\n",
      " [ 34  35  23  30  65  12  11]\n",
      " [ 29  19  11  32  26  49  44]\n",
      " [  5   4   3  10  24  50 114]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.35      0.35       210\n",
      "           2       0.40      0.39      0.40       210\n",
      "           3       0.49      0.39      0.44       210\n",
      "           4       0.30      0.35      0.32       210\n",
      "           5       0.30      0.31      0.30       210\n",
      "           6       0.22      0.23      0.23       210\n",
      "           7       0.56      0.54      0.55       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.37      0.37      0.37      1470\n",
      "weighted avg       0.37      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.37006802721088433\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 84  13  18  31  29  26   9]\n",
      " [ 36  74  14  29  22  24  11]\n",
      " [ 23  20  90  37   8  31   1]\n",
      " [ 36  18  15  80  30  25   6]\n",
      " [ 53  30   4  42  61  16   4]\n",
      " [ 33  23  11  31  23  50  39]\n",
      " [  7   3   3   7  20  65 105]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.40      0.35       210\n",
      "           2       0.41      0.35      0.38       210\n",
      "           3       0.58      0.43      0.49       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.32      0.29      0.30       210\n",
      "           6       0.21      0.24      0.22       210\n",
      "           7       0.60      0.50      0.55       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.39      0.37      0.38      1470\n",
      "weighted avg       0.39      0.37      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.36802721088435375\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 78  23  19  31  29  21   9]\n",
      " [ 25  76  19  30  28  23   9]\n",
      " [ 16  24  93  37  11  28   1]\n",
      " [ 30  13  17  65  51  23  11]\n",
      " [ 33  41  11  28  70  20   7]\n",
      " [ 26  21  11  29  27  52  44]\n",
      " [  6   9   2   6  17  63 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.37      0.37       210\n",
      "           2       0.37      0.36      0.36       210\n",
      "           3       0.54      0.44      0.49       210\n",
      "           4       0.29      0.31      0.30       210\n",
      "           5       0.30      0.33      0.32       210\n",
      "           6       0.23      0.25      0.24       210\n",
      "           7       0.57      0.51      0.54       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  30  22  27  25  21   9]\n",
      " [ 26  81  20  18  28  24  13]\n",
      " [ 16  26  91  37  10  28   2]\n",
      " [ 23  23  20  72  35  24  13]\n",
      " [ 26  39  20  39  62  17   7]\n",
      " [ 25  21  12  27  27  52  46]\n",
      " [  9   7   1   6  18  58 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.36      0.37       210\n",
      "           2       0.36      0.39      0.37       210\n",
      "           3       0.49      0.43      0.46       210\n",
      "           4       0.32      0.34      0.33       210\n",
      "           5       0.30      0.30      0.30       210\n",
      "           6       0.23      0.25      0.24       210\n",
      "           7       0.55      0.53      0.54       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.35714285714285715\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  9   5  31   0  94   0  71]\n",
      " [  0   6  34   1  78   1  90]\n",
      " [  0   3 140   0  26   0  41]\n",
      " [  0   4  12   3 146   0  45]\n",
      " [  0   4   4   1 165   0  36]\n",
      " [  1   1  16   0  36   1 155]\n",
      " [  1   2   1   0   4   1 201]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.04      0.08       210\n",
      "           2       0.24      0.03      0.05       210\n",
      "           3       0.59      0.67      0.62       210\n",
      "           4       0.60      0.01      0.03       210\n",
      "           5       0.30      0.79      0.43       210\n",
      "           6       0.33      0.00      0.01       210\n",
      "           7       0.31      0.96      0.47       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.46      0.36      0.24      1470\n",
      "weighted avg       0.46      0.36      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4170068027210884\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  5  13  46   1  86  23  36]\n",
      " [  0  67  18   0  75  15  35]\n",
      " [  0   2 158   1  26   9  14]\n",
      " [  1   9  12  10 141   9  28]\n",
      " [  3   9   2   0 164   5  27]\n",
      " [  1  13  23   5  31  13 124]\n",
      " [  0   5   0   0   4   5 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.02      0.05       210\n",
      "           2       0.57      0.32      0.41       210\n",
      "           3       0.61      0.75      0.67       210\n",
      "           4       0.59      0.05      0.09       210\n",
      "           5       0.31      0.78      0.45       210\n",
      "           6       0.16      0.06      0.09       210\n",
      "           7       0.43      0.93      0.59       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.45      0.42      0.33      1470\n",
      "weighted avg       0.45      0.42      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 47  26  24  18  60  16  19]\n",
      " [  3 105  17   9  44  12  20]\n",
      " [  2  14 152  10  13  12   7]\n",
      " [  5  21   6  68  84   5  21]\n",
      " [  0  19   3  11 148   8  21]\n",
      " [  5  28  18  13  16  31  99]\n",
      " [  1   6   0   0   2   9 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.22      0.34       210\n",
      "           2       0.48      0.50      0.49       210\n",
      "           3       0.69      0.72      0.71       210\n",
      "           4       0.53      0.32      0.40       210\n",
      "           5       0.40      0.70      0.51       210\n",
      "           6       0.33      0.15      0.20       210\n",
      "           7       0.51      0.91      0.65       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.53      0.51      0.47      1470\n",
      "weighted avg       0.53      0.51      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.535374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 64  25  14  34  42  13  18]\n",
      " [  2 123   9  18  30  13  15]\n",
      " [  4  18 146  21   5  14   2]\n",
      " [  6  14   5 102  51  13  19]\n",
      " [  3  21   2  29 126  12  17]\n",
      " [ 11  30  10  19  12  36  92]\n",
      " [  1   6   0   0   2  11 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.30      0.43       210\n",
      "           2       0.52      0.59      0.55       210\n",
      "           3       0.78      0.70      0.74       210\n",
      "           4       0.46      0.49      0.47       210\n",
      "           5       0.47      0.60      0.53       210\n",
      "           6       0.32      0.17      0.22       210\n",
      "           7       0.54      0.90      0.67       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.54      0.54      0.52      1470\n",
      "weighted avg       0.54      0.54      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 75  22   9  30  40  19  15]\n",
      " [  2 135   9  13  23  17  11]\n",
      " [  6  16 151  13   6  17   1]\n",
      " [  8  17   2 101  50  17  15]\n",
      " [  8  20   1  19 133  14  15]\n",
      " [ 12  16   9  17  12  61  83]\n",
      " [  1   6   0   0   1  14 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.36      0.47       210\n",
      "           2       0.58      0.64      0.61       210\n",
      "           3       0.83      0.72      0.77       210\n",
      "           4       0.52      0.48      0.50       210\n",
      "           5       0.50      0.63      0.56       210\n",
      "           6       0.38      0.29      0.33       210\n",
      "           7       0.57      0.90      0.70       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.580952380952381\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 85  17   9  25  39  22  13]\n",
      " [  4 127  11  18  19  20  11]\n",
      " [  9  11 155  10   7  18   0]\n",
      " [  9  15   2 107  44  22  11]\n",
      " [  8  18   2  19 135  19   9]\n",
      " [ 10  21  12  20  10  61  76]\n",
      " [  0   5   0   0   3  18 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.40      0.51       210\n",
      "           2       0.59      0.60      0.60       210\n",
      "           3       0.81      0.74      0.77       210\n",
      "           4       0.54      0.51      0.52       210\n",
      "           5       0.53      0.64      0.58       210\n",
      "           6       0.34      0.29      0.31       210\n",
      "           7       0.61      0.88      0.72       210\n",
      "\n",
      "    accuracy                           0.58      1470\n",
      "   macro avg       0.58      0.58      0.57      1470\n",
      "weighted avg       0.58      0.58      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5863945578231292\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78  17   9  29  39  28  10]\n",
      " [  3 136   7  12  21  22   9]\n",
      " [  8  14 157  10   4  17   0]\n",
      " [  9  13   3 109  44  15  17]\n",
      " [  6  18   1  27 129  14  15]\n",
      " [  9  20   8  21  12  66  74]\n",
      " [  1   3   1   0   3  15 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.37      0.48       210\n",
      "           2       0.62      0.65      0.63       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.52      0.52      0.52       210\n",
      "           5       0.51      0.61      0.56       210\n",
      "           6       0.37      0.31      0.34       210\n",
      "           7       0.60      0.89      0.72       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.58      1470\n",
      "weighted avg       0.59      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6054421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96  12   7  21  37  27  10]\n",
      " [  2 138   9  16  19  17   9]\n",
      " [  7  11 160  13   3  15   1]\n",
      " [ 11  12   2 106  48  22   9]\n",
      " [ 14  10   2  22 130  20  12]\n",
      " [ 10  16  12  18  11  76  67]\n",
      " [  2   2   0   0   3  19 184]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.46      0.55       210\n",
      "           2       0.69      0.66      0.67       210\n",
      "           3       0.83      0.76      0.80       210\n",
      "           4       0.54      0.50      0.52       210\n",
      "           5       0.52      0.62      0.56       210\n",
      "           6       0.39      0.36      0.37       210\n",
      "           7       0.63      0.88      0.73       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  12   7  27  34  25  12]\n",
      " [  1 138   8  11  23  22   7]\n",
      " [  4  13 166  10   5  12   0]\n",
      " [  5  15   4 108  46  22  10]\n",
      " [ 10  13   2  28 126  18  13]\n",
      " [ 13  18   9  17  10  75  68]\n",
      " [  1   2   0   0   3  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.44      0.55       210\n",
      "           2       0.65      0.66      0.66       210\n",
      "           3       0.85      0.79      0.82       210\n",
      "           4       0.54      0.51      0.53       210\n",
      "           5       0.51      0.60      0.55       210\n",
      "           6       0.38      0.36      0.37       210\n",
      "           7       0.62      0.87      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6020408163265306\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97  13   8  22  37  24   9]\n",
      " [  5 135  10   8  22  21   9]\n",
      " [  4   9 166  12   4  15   0]\n",
      " [ 11  10   4 105  45  23  12]\n",
      " [ 11  17   3  23 128  19   9]\n",
      " [ 12  14  12  18  11  71  72]\n",
      " [  0   4   0   0   4  19 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.46      0.55       210\n",
      "           2       0.67      0.64      0.66       210\n",
      "           3       0.82      0.79      0.80       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.51      0.61      0.56       210\n",
      "           6       0.37      0.34      0.35       210\n",
      "           7       0.62      0.87      0.73       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6074829931972789\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 97   9   9  22  39  26   8]\n",
      " [  1 134  11  11  16  26  11]\n",
      " [  8   6 166  11   5  14   0]\n",
      " [ 10  14   3 107  44  20  12]\n",
      " [ 13  15   2  24 127  17  12]\n",
      " [ 11  16  10  13  12  82  66]\n",
      " [  1   1   0   0   3  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.46      0.55       210\n",
      "           2       0.69      0.64      0.66       210\n",
      "           3       0.83      0.79      0.81       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.52      0.60      0.56       210\n",
      "           6       0.39      0.39      0.39       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6061224489795919\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  11   8  24  37  31   7]\n",
      " [  5 130   9  16  16  27   7]\n",
      " [  4   8 170  11   2  15   0]\n",
      " [  9  14   3 107  44  22  11]\n",
      " [ 11  14   3  20 134  13  15]\n",
      " [ 13  15   9  15   9  78  71]\n",
      " [  1   2   0   0   2  25 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.44      0.53       210\n",
      "           2       0.67      0.62      0.64       210\n",
      "           3       0.84      0.81      0.83       210\n",
      "           4       0.55      0.51      0.53       210\n",
      "           5       0.55      0.64      0.59       210\n",
      "           6       0.37      0.37      0.37       210\n",
      "           7       0.62      0.86      0.72       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6190476190476191\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[104  11   7  20  36  22  10]\n",
      " [  3 137   8   9  24  22   7]\n",
      " [  4  11 170  10   2  13   0]\n",
      " [ 15  20   3  99  46  18   9]\n",
      " [ 14  14   0  25 129  19   9]\n",
      " [ 11  13  11  14  11  91  59]\n",
      " [  2   3   0   0   2  23 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.50      0.57       210\n",
      "           2       0.66      0.65      0.65       210\n",
      "           3       0.85      0.81      0.83       210\n",
      "           4       0.56      0.47      0.51       210\n",
      "           5       0.52      0.61      0.56       210\n",
      "           6       0.44      0.43      0.44       210\n",
      "           7       0.66      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.62      1470\n",
      "weighted avg       0.62      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6081632653061224\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99  10  10  19  33  32   7]\n",
      " [  2 135  11  10  21  26   5]\n",
      " [  5  11 171   8   4  10   1]\n",
      " [ 10  11   5 111  41  22  10]\n",
      " [ 13  14   3  33 114  20  13]\n",
      " [ 15  13  11  13  10  84  64]\n",
      " [  2   2   0   1   4  21 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.47      0.56       210\n",
      "           2       0.69      0.64      0.67       210\n",
      "           3       0.81      0.81      0.81       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.50      0.54      0.52       210\n",
      "           6       0.39      0.40      0.40       210\n",
      "           7       0.64      0.86      0.73       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98  10   8  24  34  26  10]\n",
      " [  4 126  12  14  24  23   7]\n",
      " [  7   6 169  11   4  13   0]\n",
      " [ 10  12   3 115  36  25   9]\n",
      " [ 12  16   2  30 122  15  13]\n",
      " [ 12  14  12  18   9  77  68]\n",
      " [  2   0   0   2   3  24 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.47      0.55       210\n",
      "           2       0.68      0.60      0.64       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.54      0.55      0.54       210\n",
      "           5       0.53      0.58      0.55       210\n",
      "           6       0.38      0.37      0.37       210\n",
      "           7       0.63      0.85      0.72       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6231292517006802\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 99   8  10  19  37  27  10]\n",
      " [  4 135  10  10  21  24   6]\n",
      " [  4   6 173  11   3  13   0]\n",
      " [ 13  13   5 110  41  20   8]\n",
      " [ 15  15   4  21 128  17  10]\n",
      " [ 12  14  13   9  11  90  61]\n",
      " [  3   1   0   1   3  21 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.47      0.55       210\n",
      "           2       0.70      0.64      0.67       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.61      0.52      0.56       210\n",
      "           5       0.52      0.61      0.56       210\n",
      "           6       0.42      0.43      0.43       210\n",
      "           7       0.66      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.63      0.62      0.62      1470\n",
      "weighted avg       0.63      0.62      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6210884353741497\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98  13  15  23  27  24  10]\n",
      " [  3 138  10  11  17  26   5]\n",
      " [  4   8 173  10   3  12   0]\n",
      " [ 12  15   4 102  46  23   8]\n",
      " [ 21  16   3  17 129  12  12]\n",
      " [ 10  19  11  14  10  87  59]\n",
      " [  1   4   1   2   3  13 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.47      0.55       210\n",
      "           2       0.65      0.66      0.65       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.57      0.49      0.52       210\n",
      "           5       0.55      0.61      0.58       210\n",
      "           6       0.44      0.41      0.43       210\n",
      "           7       0.66      0.89      0.76       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6149659863945578\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[102   8  12  19  35  25   9]\n",
      " [  4 140  10  11  16  26   3]\n",
      " [  3  11 173   7   4  12   0]\n",
      " [ 12  17   2 107  40  25   7]\n",
      " [ 16  14   3  31 117  16  13]\n",
      " [ 14  16  12  18   6  85  59]\n",
      " [  0   3   1   3   3  20 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.49      0.57       210\n",
      "           2       0.67      0.67      0.67       210\n",
      "           3       0.81      0.82      0.82       210\n",
      "           4       0.55      0.51      0.53       210\n",
      "           5       0.53      0.56      0.54       210\n",
      "           6       0.41      0.40      0.41       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.61      1470\n",
      "weighted avg       0.61      0.61      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6163265306122448\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 98  13   9  22  35  26   7]\n",
      " [  3 136  10  12  16  26   7]\n",
      " [  5   8 172   7   6  11   1]\n",
      " [ 12  17   3 108  37  24   9]\n",
      " [ 15  14   1  34 120  14  12]\n",
      " [  9  11  15  18   7  94  56]\n",
      " [  1   1   1   1   2  26 178]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.47      0.56       210\n",
      "           2       0.68      0.65      0.66       210\n",
      "           3       0.82      0.82      0.82       210\n",
      "           4       0.53      0.51      0.52       210\n",
      "           5       0.54      0.57      0.55       210\n",
      "           6       0.43      0.45      0.44       210\n",
      "           7       0.66      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.62      0.62      0.61      1470\n",
      "weighted avg       0.62      0.62      0.61      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5993197278911565\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[100  13  10  17  34  26  10]\n",
      " [  2 135   9  12  18  30   4]\n",
      " [  5  10 146   6   4  39   0]\n",
      " [  9  21   2 112  33  25   8]\n",
      " [ 17  15   3  32 116  17  10]\n",
      " [ 11  13  12  17   6  91  60]\n",
      " [  0   2   1   1   2  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.48      0.56       210\n",
      "           2       0.65      0.64      0.64       210\n",
      "           3       0.80      0.70      0.74       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.54      0.55      0.55       210\n",
      "           6       0.36      0.43      0.39       210\n",
      "           7       0.66      0.86      0.75       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.60      1470\n",
      "weighted avg       0.61      0.60      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 52  12   3  13  66  49  15]\n",
      " [  4  77   6   8  52  48  15]\n",
      " [ 15   8  69  43  46  28   1]\n",
      " [  9  10   2  40 109  27  13]\n",
      " [  9  13   0   8 148  21  11]\n",
      " [  9  18   3  17  19  65  79]\n",
      " [  1   5   0   0   2  27 175]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.25      0.34       210\n",
      "           2       0.54      0.37      0.44       210\n",
      "           3       0.83      0.33      0.47       210\n",
      "           4       0.31      0.19      0.24       210\n",
      "           5       0.33      0.70      0.45       210\n",
      "           6       0.25      0.31      0.27       210\n",
      "           7       0.57      0.83      0.67       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.48      0.43      0.41      1470\n",
      "weighted avg       0.48      0.43      0.41      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish BERT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//vbert_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ccb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.5741496598639456\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[208   0   0   1   0   1   0]\n",
      " [ 64  98   6  16   9  16   1]\n",
      " [ 21   1 180   1   1   6   0]\n",
      " [ 82   4   2 101  10   9   2]\n",
      " [150   4   0  16  37   1   2]\n",
      " [ 94   3   2  13   4  73  21]\n",
      " [ 42   0   0   2   0  19 147]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.99      0.48       210\n",
      "           2       0.89      0.47      0.61       210\n",
      "           3       0.95      0.86      0.90       210\n",
      "           4       0.67      0.48      0.56       210\n",
      "           5       0.61      0.18      0.27       210\n",
      "           6       0.58      0.35      0.44       210\n",
      "           7       0.85      0.70      0.77       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.70      0.57      0.58      1470\n",
      "weighted avg       0.70      0.57      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5897959183673469\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[145   8  11   7  32   4   3]\n",
      " [ 20 143  10  16  18   0   3]\n",
      " [  4  16 184   1   3   2   0]\n",
      " [ 26  31  11  96  39   5   2]\n",
      " [ 66  21   5  18  90   4   6]\n",
      " [ 46  25   8  26  13  52  40]\n",
      " [ 18   6   0   9   6  14 157]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.69      0.54       210\n",
      "           2       0.57      0.68      0.62       210\n",
      "           3       0.80      0.88      0.84       210\n",
      "           4       0.55      0.46      0.50       210\n",
      "           5       0.45      0.43      0.44       210\n",
      "           6       0.64      0.25      0.36       210\n",
      "           7       0.74      0.75      0.75       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.60      0.59      0.58      1470\n",
      "weighted avg       0.60      0.59      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6095238095238096\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[147   7   7   8  29   7   5]\n",
      " [ 14 145  10  16  16   4   5]\n",
      " [  2  18 185   1   3   1   0]\n",
      " [ 22  22  15  96  40  12   3]\n",
      " [ 56  19   6  23  96   4   6]\n",
      " [ 35  24   8  25  17  65  36]\n",
      " [ 15   4   0   3   6  20 162]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.70      0.59       210\n",
      "           2       0.61      0.69      0.65       210\n",
      "           3       0.80      0.88      0.84       210\n",
      "           4       0.56      0.46      0.50       210\n",
      "           5       0.46      0.46      0.46       210\n",
      "           6       0.58      0.31      0.40       210\n",
      "           7       0.75      0.77      0.76       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6040816326530613\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   5   8   9  32   9   4]\n",
      " [ 13 146  13  12  17   3   6]\n",
      " [  3  18 184   1   3   1   0]\n",
      " [ 17  26  12  93  51   9   2]\n",
      " [ 53  20   8  22  97   2   8]\n",
      " [ 26  23  10  34  20  53  44]\n",
      " [ 11   3   0   0   7  17 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.68      0.60       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.78      0.88      0.83       210\n",
      "           4       0.54      0.44      0.49       210\n",
      "           5       0.43      0.46      0.44       210\n",
      "           6       0.56      0.25      0.35       210\n",
      "           7       0.73      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6054421768707483\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   8   9   8  34   3   5]\n",
      " [ 10 142  16  13  21   4   4]\n",
      " [  3  15 185   2   2   3   0]\n",
      " [ 13  27  13  97  46  10   4]\n",
      " [ 54  19   6  20 100   5   6]\n",
      " [ 29  23  12  33  19  51  43]\n",
      " [  8   2   0   1   9  18 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.68      0.61       210\n",
      "           2       0.60      0.68      0.64       210\n",
      "           3       0.77      0.88      0.82       210\n",
      "           4       0.56      0.46      0.51       210\n",
      "           5       0.43      0.48      0.45       210\n",
      "           6       0.54      0.24      0.34       210\n",
      "           7       0.74      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.60      0.61      0.59      1470\n",
      "weighted avg       0.60      0.61      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[140  10  10   8  39   2   1]\n",
      " [ 10 146  13  13  20   3   5]\n",
      " [  2  18 184   2   1   3   0]\n",
      " [ 12  27  13  94  48  11   5]\n",
      " [ 46  16   6  22 111   2   7]\n",
      " [ 26  22  13  35  16  52  46]\n",
      " [ 10   2   0   2   9  14 173]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.67      0.61       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.77      0.88      0.82       210\n",
      "           4       0.53      0.45      0.49       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.60      0.25      0.35       210\n",
      "           7       0.73      0.82      0.77       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6142857142857143\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[143   7   6   9  38   5   2]\n",
      " [  7 146  13  15  23   2   4]\n",
      " [  2  17 185   2   2   2   0]\n",
      " [ 14  24  14  96  49   9   4]\n",
      " [ 41  20   7  21 111   3   7]\n",
      " [ 29  29  11  32  15  47  47]\n",
      " [  9   2   0   3   8  13 175]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.68      0.63       210\n",
      "           2       0.60      0.70      0.64       210\n",
      "           3       0.78      0.88      0.83       210\n",
      "           4       0.54      0.46      0.49       210\n",
      "           5       0.45      0.53      0.49       210\n",
      "           6       0.58      0.22      0.32       210\n",
      "           7       0.73      0.83      0.78       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.61      0.61      0.60      1470\n",
      "weighted avg       0.61      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.5163265306122449\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[122  10  12   2  12  28  24]\n",
      " [  3 145  10   4   9  30   9]\n",
      " [  7  49 139   4   1   9   1]\n",
      " [  9  35   4  74  21  37  30]\n",
      " [ 39  35   0  10  75  18  33]\n",
      " [ 12  47   3  10   5  77  56]\n",
      " [  0  14   0   0   2  67 127]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.58      0.61       210\n",
      "           2       0.43      0.69      0.53       210\n",
      "           3       0.83      0.66      0.74       210\n",
      "           4       0.71      0.35      0.47       210\n",
      "           5       0.60      0.36      0.45       210\n",
      "           6       0.29      0.37      0.32       210\n",
      "           7       0.45      0.60      0.52       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.56      0.52      0.52      1470\n",
      "weighted avg       0.56      0.52      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 34   5   9   6 145   5   6]\n",
      " [  2  19   9  10 149  11  10]\n",
      " [  9   8  22   2 158  10   1]\n",
      " [  5   5   8   7 171   7   7]\n",
      " [  4   4   1   5 186   6   4]\n",
      " [  6   7   8   9 158  13   9]\n",
      " [  0   5   3   2 173  14  13]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.16      0.25       210\n",
      "           2       0.36      0.09      0.14       210\n",
      "           3       0.37      0.10      0.16       210\n",
      "           4       0.17      0.03      0.06       210\n",
      "           5       0.16      0.89      0.28       210\n",
      "           6       0.20      0.06      0.09       210\n",
      "           7       0.26      0.06      0.10       210\n",
      "\n",
      "    accuracy                           0.20      1470\n",
      "   macro avg       0.30      0.20      0.15      1470\n",
      "weighted avg       0.30      0.20      0.15      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.617687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[201   0   1   1   0   5   2]\n",
      " [ 38 119  12  13  10  17   1]\n",
      " [  4   3 195   1   2   5   0]\n",
      " [ 65   8   3 109   7  17   1]\n",
      " [150   7   1  18  22   7   5]\n",
      " [ 51   9   5  11   2 110  22]\n",
      " [ 16   1   0   1   0  40 152]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.96      0.55       210\n",
      "           2       0.81      0.57      0.67       210\n",
      "           3       0.90      0.93      0.91       210\n",
      "           4       0.71      0.52      0.60       210\n",
      "           5       0.51      0.10      0.17       210\n",
      "           6       0.55      0.52      0.54       210\n",
      "           7       0.83      0.72      0.77       210\n",
      "\n",
      "    accuracy                           0.62      1470\n",
      "   macro avg       0.67      0.62      0.60      1470\n",
      "weighted avg       0.67      0.62      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.6340136054421769\n",
      "Confusion Matrix of SVM is:\n",
      " [[198   0   1   1   0   8   2]\n",
      " [ 28 125  11  11  16  18   1]\n",
      " [  5   4 195   1   2   3   0]\n",
      " [ 57  10   6 109   9  17   2]\n",
      " [137   4   1  20  37   7   4]\n",
      " [ 47   9   3  10   2 118  21]\n",
      " [ 15   1   0   1   0  43 150]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.94      0.57       210\n",
      "           2       0.82      0.60      0.69       210\n",
      "           3       0.90      0.93      0.91       210\n",
      "           4       0.71      0.52      0.60       210\n",
      "           5       0.56      0.18      0.27       210\n",
      "           6       0.55      0.56      0.56       210\n",
      "           7       0.83      0.71      0.77       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.68      0.63      0.62      1470\n",
      "weighted avg       0.68      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7312925170068028\n",
      "Confusion Matrix of SVM is:\n",
      " [[173   4   4   1  11  15   2]\n",
      " [  3 148  11  13   5  28   2]\n",
      " [  1   6 196   2   1   4   0]\n",
      " [  5  11   8 129  19  36   2]\n",
      " [ 60  17   1  20  98   9   5]\n",
      " [  9   7   3  10   3 151  27]\n",
      " [  3   0   0   0   1  26 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.82      0.75       210\n",
      "           2       0.77      0.70      0.73       210\n",
      "           3       0.88      0.93      0.91       210\n",
      "           4       0.74      0.61      0.67       210\n",
      "           5       0.71      0.47      0.56       210\n",
      "           6       0.56      0.72      0.63       210\n",
      "           7       0.83      0.86      0.84       210\n",
      "\n",
      "    accuracy                           0.73      1470\n",
      "   macro avg       0.74      0.73      0.73      1470\n",
      "weighted avg       0.74      0.73      0.73      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.22857142857142856\n",
      "Confusion Matrix of SVM is:\n",
      " [[  0   0   0   0 116   0  94]\n",
      " [  0   0   0   0  85   0 125]\n",
      " [  0   0   0  49  92   0  69]\n",
      " [  0   0   0   1  78   0 131]\n",
      " [  0   0   0   0 129   0  81]\n",
      " [  0   0   0   1  32   0 177]\n",
      " [  0   0   0   0   4   0 206]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.00      0.00      0.00       210\n",
      "           4       0.02      0.00      0.01       210\n",
      "           5       0.24      0.61      0.35       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.23      0.98      0.38       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.07      0.23      0.10      1470\n",
      "weighted avg       0.07      0.23      0.10      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.24897959183673468\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  49   0   0   0 161]\n",
      " [  0   0  62   0   0   0 148]\n",
      " [  0   0 159   0   0   0  51]\n",
      " [  0   0  11   0   0   0 199]\n",
      " [  0   0   4   0   0   0 206]\n",
      " [  0   0  25   0   0   0 185]\n",
      " [  0   0   3   0   0   0 207]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.51      0.76      0.61       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.18      0.99      0.30       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.10      0.25      0.13      1470\n",
      "weighted avg       0.10      0.25      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3408163265306122\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0  14  35   0 120   0  41]\n",
      " [  0  24  38   0  68   0  80]\n",
      " [  0  10 149   0  43   0   8]\n",
      " [  0   4   7   0 127   0  72]\n",
      " [  0   2   2   0 143   0  63]\n",
      " [  0   7  18   0  71   0 114]\n",
      " [  0   3   0   0  22   0 185]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.38      0.11      0.18       210\n",
      "           3       0.60      0.71      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.24      0.68      0.36       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.33      0.88      0.48       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.22      0.34      0.24      1470\n",
      "weighted avg       0.22      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.37891156462585035\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 96  14  26  33   0  18  23]\n",
      " [ 10  34  26  60   0  53  27]\n",
      " [ 12  14 144  32   0   5   3]\n",
      " [ 40   3   7  88   0  44  28]\n",
      " [ 83   2   2  60   0  28  35]\n",
      " [ 26  12  13  45   0  38  76]\n",
      " [ 11   3   0  11   0  28 157]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.46      0.39       210\n",
      "           2       0.41      0.16      0.23       210\n",
      "           3       0.66      0.69      0.67       210\n",
      "           4       0.27      0.42      0.33       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.18      0.18      0.18       210\n",
      "           7       0.45      0.75      0.56       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.33      0.38      0.34      1470\n",
      "weighted avg       0.33      0.38      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 51  24  24  22  48  33   8]\n",
      " [  3  63  21  44   6  52  21]\n",
      " [  3  14 141  35  10   5   2]\n",
      " [  9  17   5  79  31  60   9]\n",
      " [ 14  33   2  32  69  43  17]\n",
      " [  1  14  13  43  25  72  42]\n",
      " [  0  15   0   3  11  60 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.24      0.35       210\n",
      "           2       0.35      0.30      0.32       210\n",
      "           3       0.68      0.67      0.68       210\n",
      "           4       0.31      0.38      0.34       210\n",
      "           5       0.34      0.33      0.34       210\n",
      "           6       0.22      0.34      0.27       210\n",
      "           7       0.55      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.44      0.41      0.41      1470\n",
      "weighted avg       0.44      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4170068027210884\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 50   9  27  28  56  32   8]\n",
      " [  3  43  30  23  16  79  16]\n",
      " [  2   8 141  15  12  32   0]\n",
      " [  7   8   6  65  41  71  12]\n",
      " [  8  12   4  23  94  46  23]\n",
      " [  1   5  12  31  30  86  45]\n",
      " [  0   2   3   5  21  45 134]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.24      0.36       210\n",
      "           2       0.49      0.20      0.29       210\n",
      "           3       0.63      0.67      0.65       210\n",
      "           4       0.34      0.31      0.33       210\n",
      "           5       0.35      0.45      0.39       210\n",
      "           6       0.22      0.41      0.29       210\n",
      "           7       0.56      0.64      0.60       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.47      0.42      0.41      1470\n",
      "weighted avg       0.47      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  12  21  27  26  34   9]\n",
      " [  6  66  19  22  13  71  13]\n",
      " [  8  15 135  16   7  28   1]\n",
      " [ 14   9   5  77  22  67  16]\n",
      " [ 28  17   0  32  67  38  28]\n",
      " [  7  10   9  43  12  79  50]\n",
      " [  5   1   2  11   2  42 147]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.39      0.45       210\n",
      "           2       0.51      0.31      0.39       210\n",
      "           3       0.71      0.64      0.67       210\n",
      "           4       0.34      0.37      0.35       210\n",
      "           5       0.45      0.32      0.37       210\n",
      "           6       0.22      0.38      0.28       210\n",
      "           7       0.56      0.70      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.45      1470\n",
      "weighted avg       0.47      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44285714285714284\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  11  34  18  43  16   8]\n",
      " [  4  79  27  22  46  17  15]\n",
      " [  9   7 140  17  25  10   2]\n",
      " [ 25  24   7  62  53  28  11]\n",
      " [ 31  22   3  22  96  15  21]\n",
      " [ 22  24   8  26  31  52  47]\n",
      " [ 15  13   2   4  10  24 142]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.38      0.40       210\n",
      "           2       0.44      0.38      0.41       210\n",
      "           3       0.63      0.67      0.65       210\n",
      "           4       0.36      0.30      0.33       210\n",
      "           5       0.32      0.46      0.37       210\n",
      "           6       0.32      0.25      0.28       210\n",
      "           7       0.58      0.68      0.62       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.44      1470\n",
      "weighted avg       0.44      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41836734693877553\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63  12  31  25  52  22   5]\n",
      " [ 10  66  24  48  21  33   8]\n",
      " [  8  11 135  32  12  10   2]\n",
      " [ 17  19   9  91  34  34   6]\n",
      " [ 23  17   1  40  83  29  17]\n",
      " [ 19  23   7  30  25  78  28]\n",
      " [  6   5   2   6  15  77  99]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.30      0.35       210\n",
      "           2       0.43      0.31      0.36       210\n",
      "           3       0.65      0.64      0.64       210\n",
      "           4       0.33      0.43      0.38       210\n",
      "           5       0.34      0.40      0.37       210\n",
      "           6       0.28      0.37      0.32       210\n",
      "           7       0.60      0.47      0.53       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.42      1470\n",
      "weighted avg       0.44      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  21  24  34  36  17  10]\n",
      " [ 14  96  16  25  18  31  10]\n",
      " [  3  26 138  18   7  15   3]\n",
      " [ 12  33   9  91  27  25  13]\n",
      " [ 24  27   2  39  75  20  23]\n",
      " [ 14  29   7  33  25  68  34]\n",
      " [  9   5   2  11  13  63 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.32      0.38       210\n",
      "           2       0.41      0.46      0.43       210\n",
      "           3       0.70      0.66      0.68       210\n",
      "           4       0.36      0.43      0.39       210\n",
      "           5       0.37      0.36      0.36       210\n",
      "           6       0.28      0.32      0.30       210\n",
      "           7       0.54      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  11  34  29  42  18   9]\n",
      " [ 14  76  26  19  35  30  10]\n",
      " [  5  21 145  11  15   9   4]\n",
      " [ 12  24  11  80  44  23  16]\n",
      " [ 28  17   5  32  84  18  26]\n",
      " [ 13  23  13  26  29  62  44]\n",
      " [  7   7   2  16   9  63 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.32      0.38       210\n",
      "           2       0.42      0.36      0.39       210\n",
      "           3       0.61      0.69      0.65       210\n",
      "           4       0.38      0.38      0.38       210\n",
      "           5       0.33      0.40      0.36       210\n",
      "           6       0.28      0.30      0.29       210\n",
      "           7       0.49      0.50      0.50       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42448979591836733\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  19  25  23  42  20  10]\n",
      " [ 24  76  16  20  29  35  10]\n",
      " [ 16  10 142  10   7  21   4]\n",
      " [ 24  16  12  67  43  26  22]\n",
      " [ 40  16   1  31  80  18  24]\n",
      " [ 18  19   8  16  32  70  47]\n",
      " [  7   6   3  13  14  49 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.35       210\n",
      "           2       0.47      0.36      0.41       210\n",
      "           3       0.69      0.68      0.68       210\n",
      "           4       0.37      0.32      0.34       210\n",
      "           5       0.32      0.38      0.35       210\n",
      "           6       0.29      0.33      0.31       210\n",
      "           7       0.50      0.56      0.53       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.43      0.42      0.42      1470\n",
      "weighted avg       0.43      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.41496598639455784\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  19  26  21  37  23   8]\n",
      " [ 29  70  19  23  21  37  11]\n",
      " [ 10   9 142  15  10  19   5]\n",
      " [ 32  19  11  68  38  24  18]\n",
      " [ 40  19   4  25  76  24  22]\n",
      " [ 28  13  10  25  21  71  42]\n",
      " [ 18   3   3   7  11  61 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.36      0.34       210\n",
      "           2       0.46      0.33      0.39       210\n",
      "           3       0.66      0.68      0.67       210\n",
      "           4       0.37      0.32      0.35       210\n",
      "           5       0.36      0.36      0.36       210\n",
      "           6       0.27      0.34      0.30       210\n",
      "           7       0.50      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.42      1470\n",
      "weighted avg       0.42      0.41      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 68  15  31  24  49  16   7]\n",
      " [ 27  63  24  33  20  34   9]\n",
      " [  7  17 134  14   9  27   2]\n",
      " [ 27  18   9  72  40  23  21]\n",
      " [ 38  19   6  28  73  25  21]\n",
      " [ 18  18  16  26  25  65  42]\n",
      " [ 18   1   8  14  11  37 121]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.32      0.33       210\n",
      "           2       0.42      0.30      0.35       210\n",
      "           3       0.59      0.64      0.61       210\n",
      "           4       0.34      0.34      0.34       210\n",
      "           5       0.32      0.35      0.33       210\n",
      "           6       0.29      0.31      0.30       210\n",
      "           7       0.54      0.58      0.56       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.40      0.41      0.40      1470\n",
      "weighted avg       0.40      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 69  13  33  17  46  21  11]\n",
      " [ 22  63  28  30  29  25  13]\n",
      " [  9  11 145  14   6  19   6]\n",
      " [ 20  19  15  73  38  26  19]\n",
      " [ 36  13   5  31  83  20  22]\n",
      " [ 23  19  17  27  29  53  42]\n",
      " [ 15   3  20  12  16  33 111]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.33      0.34       210\n",
      "           2       0.45      0.30      0.36       210\n",
      "           3       0.55      0.69      0.61       210\n",
      "           4       0.36      0.35      0.35       210\n",
      "           5       0.34      0.40      0.36       210\n",
      "           6       0.27      0.25      0.26       210\n",
      "           7       0.50      0.53      0.51       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.40      0.41      0.40      1470\n",
      "weighted avg       0.40      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4034013605442177\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  16  34  15  49  16   9]\n",
      " [ 18  61  23  23  32  43  10]\n",
      " [ 12  16 144  18   7  10   3]\n",
      " [ 22  21   8  69  51  20  19]\n",
      " [ 31  14   5  27  87  25  21]\n",
      " [ 37  17  11  26  24  60  35]\n",
      " [  9   4   5  12  17  62 101]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.34      0.35       210\n",
      "           2       0.41      0.29      0.34       210\n",
      "           3       0.63      0.69      0.65       210\n",
      "           4       0.36      0.33      0.35       210\n",
      "           5       0.33      0.41      0.36       210\n",
      "           6       0.25      0.29      0.27       210\n",
      "           7       0.51      0.48      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39727891156462586\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 69  11  21  27  48  26   8]\n",
      " [ 24  59  25  18  20  53  11]\n",
      " [  8  13 142  19   9  14   5]\n",
      " [ 20  20  20  68  36  28  18]\n",
      " [ 33  15   5  29  78  32  18]\n",
      " [ 23  14  19  33  25  61  35]\n",
      " [ 13   4  10  13  15  48 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.33      0.35       210\n",
      "           2       0.43      0.28      0.34       210\n",
      "           3       0.59      0.68      0.63       210\n",
      "           4       0.33      0.32      0.33       210\n",
      "           5       0.34      0.37      0.35       210\n",
      "           6       0.23      0.29      0.26       210\n",
      "           7       0.53      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.40      0.40      0.40      1470\n",
      "weighted avg       0.40      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  13  24  25  49  27   5]\n",
      " [ 21  67  22  22  24  42  12]\n",
      " [  9  11 148  11   8  21   2]\n",
      " [ 18  21  12  69  45  20  25]\n",
      " [ 27  21   5  34  77  24  22]\n",
      " [ 19  17  19  32  25  60  38]\n",
      " [ 11   7  13  12  14  41 112]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.32      0.35       210\n",
      "           2       0.43      0.32      0.37       210\n",
      "           3       0.61      0.70      0.65       210\n",
      "           4       0.34      0.33      0.33       210\n",
      "           5       0.32      0.37      0.34       210\n",
      "           6       0.26      0.29      0.27       210\n",
      "           7       0.52      0.53      0.53       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66  18  25  24  47  23   7]\n",
      " [ 24  72  15  24  26  34  15]\n",
      " [  6  22 141  14  11  13   3]\n",
      " [ 17  22  13  79  45  18  16]\n",
      " [ 38  18   6  32  77  19  20]\n",
      " [ 18  22  19  31  25  58  37]\n",
      " [  8   5   5  16  16  53 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.31      0.34       210\n",
      "           2       0.40      0.34      0.37       210\n",
      "           3       0.63      0.67      0.65       210\n",
      "           4       0.36      0.38      0.37       210\n",
      "           5       0.31      0.37      0.34       210\n",
      "           6       0.27      0.28      0.27       210\n",
      "           7       0.52      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41020408163265304\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 71  11  35  15  46  24   8]\n",
      " [ 21  67  24  24  21  40  13]\n",
      " [  8  16 145  15   9  15   2]\n",
      " [ 22  22  13  69  44  23  17]\n",
      " [ 33  14  10  30  75  24  24]\n",
      " [ 23  15  19  29  30  57  37]\n",
      " [ 17   7  12  16  13  26 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.34      0.35       210\n",
      "           2       0.44      0.32      0.37       210\n",
      "           3       0.56      0.69      0.62       210\n",
      "           4       0.35      0.33      0.34       210\n",
      "           5       0.32      0.36      0.33       210\n",
      "           6       0.27      0.27      0.27       210\n",
      "           7       0.54      0.57      0.55       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  14  30  22  45  16   8]\n",
      " [ 32  69  25  17  25  30  12]\n",
      " [  8  17 151   7   9  14   4]\n",
      " [ 26  17  20  64  48  20  15]\n",
      " [ 42  14   9  23  80  20  22]\n",
      " [ 26  23  22  19  33  51  36]\n",
      " [ 18   4  26  18  14  24 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.36      0.34       210\n",
      "           2       0.44      0.33      0.37       210\n",
      "           3       0.53      0.72      0.61       210\n",
      "           4       0.38      0.30      0.34       210\n",
      "           5       0.31      0.38      0.34       210\n",
      "           6       0.29      0.24      0.26       210\n",
      "           7       0.52      0.50      0.51       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.40      0.41      0.40      1470\n",
      "weighted avg       0.40      0.41      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.37551020408163266\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 14   1  79   3  70   0  43]\n",
      " [  2   9 100   4  60   1  34]\n",
      " [  0   2 183   2  20   0   3]\n",
      " [  0   0  47  14  70   0  79]\n",
      " [  2   2  16   2 131   0  57]\n",
      " [  0   4  60   1  24   2 119]\n",
      " [  0   1   3   0   7   0 199]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.07      0.12       210\n",
      "           2       0.47      0.04      0.08       210\n",
      "           3       0.38      0.87      0.52       210\n",
      "           4       0.54      0.07      0.12       210\n",
      "           5       0.34      0.62      0.44       210\n",
      "           6       0.67      0.01      0.02       210\n",
      "           7       0.37      0.95      0.53       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.51      0.38      0.26      1470\n",
      "weighted avg       0.51      0.38      0.26      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4312925170068027\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 50   5  45   1  74   0  35]\n",
      " [  2  58  62   2  58   2  26]\n",
      " [  0  14 175   2  17   0   2]\n",
      " [  0  19  22  15  96   0  58]\n",
      " [  6   6  10   0 137   0  51]\n",
      " [  3  23  31  12  30   3 108]\n",
      " [  0   3   0   2   8   1 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.24      0.37       210\n",
      "           2       0.45      0.28      0.34       210\n",
      "           3       0.51      0.83      0.63       210\n",
      "           4       0.44      0.07      0.12       210\n",
      "           5       0.33      0.65      0.43       210\n",
      "           6       0.50      0.01      0.03       210\n",
      "           7       0.41      0.93      0.57       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.49      0.43      0.36      1470\n",
      "weighted avg       0.49      0.43      0.36      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5176870748299319\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[101   7  13   8  46   2  33]\n",
      " [  1 110  35   9  34   7  14]\n",
      " [  0  23 171   8   7   0   1]\n",
      " [  4  30  10  57  55   4  50]\n",
      " [ 21  11   5   7 119   2  45]\n",
      " [ 10  40  18  21  16  10  95]\n",
      " [  0   5   0   6   3   3 193]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.48      0.58       210\n",
      "           2       0.49      0.52      0.50       210\n",
      "           3       0.68      0.81      0.74       210\n",
      "           4       0.49      0.27      0.35       210\n",
      "           5       0.42      0.57      0.49       210\n",
      "           6       0.36      0.05      0.08       210\n",
      "           7       0.45      0.92      0.60       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.48      1470\n",
      "weighted avg       0.52      0.52      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   9   7   7  38   4  29]\n",
      " [  2 138  16  14  20   7  13]\n",
      " [  2  35 166   3   3   0   1]\n",
      " [  6  27   9  78  39  10  41]\n",
      " [ 30  16   2  16 105   4  37]\n",
      " [ 14  39  15  23  12  16  91]\n",
      " [  0   4   0   3   3   3 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.55      0.61       210\n",
      "           2       0.51      0.66      0.58       210\n",
      "           3       0.77      0.79      0.78       210\n",
      "           4       0.54      0.37      0.44       210\n",
      "           5       0.48      0.50      0.49       210\n",
      "           6       0.36      0.08      0.13       210\n",
      "           7       0.48      0.94      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.55      0.56      0.52      1470\n",
      "weighted avg       0.55      0.56      0.52      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.591156462585034\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   7   4  10  29   7  26]\n",
      " [  1 138  11  19  17  12  12]\n",
      " [  1  26 172   8   1   2   0]\n",
      " [  1  17  11  94  38  16  33]\n",
      " [ 22  16   2  16 113  11  30]\n",
      " [ 10  32  15  27  11  29  86]\n",
      " [  0   2   0   4   2   6 196]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.60      0.68       210\n",
      "           2       0.58      0.66      0.62       210\n",
      "           3       0.80      0.82      0.81       210\n",
      "           4       0.53      0.45      0.48       210\n",
      "           5       0.54      0.54      0.54       210\n",
      "           6       0.35      0.14      0.20       210\n",
      "           7       0.51      0.93      0.66       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.58      0.59      0.57      1470\n",
      "weighted avg       0.58      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116   5   7  11  36   9  26]\n",
      " [  1 135  11  17  21  13  12]\n",
      " [  0  22 176  10   1   0   1]\n",
      " [  2  18   7 104  30  19  30]\n",
      " [ 16  14   2  16 124   9  29]\n",
      " [ 10  21  15  35  10  36  83]\n",
      " [  0   1   0   4   3   7 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.55      0.65       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.81      0.84      0.82       210\n",
      "           4       0.53      0.50      0.51       210\n",
      "           5       0.55      0.59      0.57       210\n",
      "           6       0.39      0.17      0.24       210\n",
      "           7       0.52      0.93      0.67       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.58      1470\n",
      "weighted avg       0.60      0.60      0.58      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6346938775510204\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   7   3   9  34  17  19]\n",
      " [  1 149   5  12  19  13  11]\n",
      " [  0  22 176   5   3   4   0]\n",
      " [  2  18   4 104  32  29  21]\n",
      " [ 12  15   1  20 127  12  23]\n",
      " [  5  27   8  31   8  65  66]\n",
      " [  0   4   0   3   1  11 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.62      0.71      0.66       210\n",
      "           3       0.89      0.84      0.86       210\n",
      "           4       0.57      0.50      0.53       210\n",
      "           5       0.57      0.60      0.59       210\n",
      "           6       0.43      0.31      0.36       210\n",
      "           7       0.58      0.91      0.71       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6394557823129252\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[125   7   5   8  34  10  21]\n",
      " [  2 138   7  17  19  20   7]\n",
      " [  0  16 182   7   1   4   0]\n",
      " [  0  13   6 106  36  31  18]\n",
      " [ 17  15   1  21 123  14  19]\n",
      " [  7  15  11  27   8  79  63]\n",
      " [  0   1   0   2   3  17 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.69       210\n",
      "           2       0.67      0.66      0.67       210\n",
      "           3       0.86      0.87      0.86       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.55      0.59      0.57       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.59      0.89      0.71       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6292517006802721\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121   6   7   6  39  16  15]\n",
      " [  4 136   8  19  18  16   9]\n",
      " [  1  18 177   6   2   6   0]\n",
      " [  2  16   5 106  33  31  17]\n",
      " [ 17  17   0  23 121  13  19]\n",
      " [ 11  16  12  26   9  74  62]\n",
      " [  0   1   0   3   2  14 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.58      0.66       210\n",
      "           2       0.65      0.65      0.65       210\n",
      "           3       0.85      0.84      0.84       210\n",
      "           4       0.56      0.50      0.53       210\n",
      "           5       0.54      0.58      0.56       210\n",
      "           6       0.44      0.35      0.39       210\n",
      "           7       0.61      0.90      0.73       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.63      0.63      0.62      1470\n",
      "weighted avg       0.63      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6340136054421769\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   4  12  30  21   7]\n",
      " [  3 137  11  18  17  20   4]\n",
      " [  2  13 184   6   1   4   0]\n",
      " [  3  15   6 111  27  38  10]\n",
      " [ 19  16   3  24 122  14  12]\n",
      " [  8  21   9  35   5  74  58]\n",
      " [  0   1   0   3   2  31 173]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.62      0.70       210\n",
      "           2       0.66      0.65      0.66       210\n",
      "           3       0.85      0.88      0.86       210\n",
      "           4       0.53      0.53      0.53       210\n",
      "           5       0.60      0.58      0.59       210\n",
      "           6       0.37      0.35      0.36       210\n",
      "           7       0.66      0.82      0.73       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.63      1470\n",
      "weighted avg       0.64      0.63      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   3   7  14  28  22  12]\n",
      " [  1 139   6  18  15  24   7]\n",
      " [  1  12 186   7   0   4   0]\n",
      " [  1  13   6 110  34  33  13]\n",
      " [ 20  12   3  20 125  16  14]\n",
      " [  8  16   5  25   7  89  60]\n",
      " [  0   3   0   1   1  20 185]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.59      0.68       210\n",
      "           2       0.70      0.66      0.68       210\n",
      "           3       0.87      0.89      0.88       210\n",
      "           4       0.56      0.52      0.54       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.43      0.42      0.43       210\n",
      "           7       0.64      0.88      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6517006802721088\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   5   9  10  25  16  15]\n",
      " [  2 148   6  17  16  17   4]\n",
      " [  2  13 183   6   1   4   1]\n",
      " [  3  15   5 108  30  32  17]\n",
      " [ 22  13   2  22 118  15  18]\n",
      " [ 12  16   7  23   8  80  64]\n",
      " [  0   0   0   3   2  14 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.62      0.68       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.86      0.87      0.87       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.59      0.56      0.58       210\n",
      "           6       0.45      0.38      0.41       210\n",
      "           7       0.62      0.91      0.73       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.65      1470\n",
      "weighted avg       0.65      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   4   8   8  27  22  11]\n",
      " [  2 147   8  16  14  20   3]\n",
      " [  0  10 185   7   3   5   0]\n",
      " [  0  14   5 107  33  38  13]\n",
      " [ 20  13   2  23 122  18  12]\n",
      " [  7  20  12  23   8  83  57]\n",
      " [  0   2   0   3   1  23 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.62      0.70       210\n",
      "           2       0.70      0.70      0.70       210\n",
      "           3       0.84      0.88      0.86       210\n",
      "           4       0.57      0.51      0.54       210\n",
      "           5       0.59      0.58      0.58       210\n",
      "           6       0.40      0.40      0.40       210\n",
      "           7       0.65      0.86      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.65      1470\n",
      "weighted avg       0.65      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   5   9  11  27  16  13]\n",
      " [  3 142   7  18  17  16   7]\n",
      " [  1  10 182   9   1   7   0]\n",
      " [  6  11   6 109  37  28  13]\n",
      " [ 29  16   1  27 112  12  13]\n",
      " [  9  20   6  25   4  94  52]\n",
      " [  1   1   0   3   1  25 179]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.61      0.66       210\n",
      "           2       0.69      0.68      0.68       210\n",
      "           3       0.86      0.87      0.86       210\n",
      "           4       0.54      0.52      0.53       210\n",
      "           5       0.56      0.53      0.55       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.65      0.85      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.636734693877551\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   7   9  13  26  22   6]\n",
      " [  5 141   8  17  14  21   4]\n",
      " [  0  10 183  10   3   3   1]\n",
      " [  2  14   4 111  33  36  10]\n",
      " [ 30  12   3  25 106  19  15]\n",
      " [  7  15  10  27   6  91  54]\n",
      " [  0   2   0   3   1  27 177]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.60      0.67       210\n",
      "           2       0.70      0.67      0.69       210\n",
      "           3       0.84      0.87      0.86       210\n",
      "           4       0.54      0.53      0.53       210\n",
      "           5       0.56      0.50      0.53       210\n",
      "           6       0.42      0.43      0.42       210\n",
      "           7       0.66      0.84      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.63      1470\n",
      "weighted avg       0.64      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.64421768707483\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   5   6   8  33  17  11]\n",
      " [  4 139   6  22  12  19   8]\n",
      " [  2  12 182   9   2   2   1]\n",
      " [  5  15   6 111  31  35   7]\n",
      " [ 19  19   1  23 124  16   8]\n",
      " [ 14  18   9  27   6  85  51]\n",
      " [  1   2   0   1   4  26 176]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.68       210\n",
      "           2       0.66      0.66      0.66       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.55      0.53      0.54       210\n",
      "           5       0.58      0.59      0.59       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.67      0.84      0.75       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6408163265306123\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   5   7  11  28  19   5]\n",
      " [  2 138  11  22  14  17   6]\n",
      " [  2  10 183   9   2   4   0]\n",
      " [  6  14   5 111  23  41  10]\n",
      " [ 22  15   2  23 121  15  12]\n",
      " [ 13  19   9  23  10  83  53]\n",
      " [  1   2   0   2   1  33 171]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.64      0.69       210\n",
      "           2       0.68      0.66      0.67       210\n",
      "           3       0.84      0.87      0.86       210\n",
      "           4       0.55      0.53      0.54       210\n",
      "           5       0.61      0.58      0.59       210\n",
      "           6       0.39      0.40      0.39       210\n",
      "           7       0.67      0.81      0.73       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6394557823129252\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   7   7  11  30  20   8]\n",
      " [  2 143   9  17  17  19   3]\n",
      " [  1  13 184   8   2   1   1]\n",
      " [  5  16   4 113  31  32   9]\n",
      " [ 27  14   2  25 116  14  12]\n",
      " [ 14  18   9  25   6  83  55]\n",
      " [  0   1   0   6   2  27 174]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.60      0.66       210\n",
      "           2       0.67      0.68      0.68       210\n",
      "           3       0.86      0.88      0.87       210\n",
      "           4       0.55      0.54      0.54       210\n",
      "           5       0.57      0.55      0.56       210\n",
      "           6       0.42      0.40      0.41       210\n",
      "           7       0.66      0.83      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.645578231292517\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[131   5   7   8  30  21   8]\n",
      " [  4 139   9  20  12  22   4]\n",
      " [  2   9 187   6   2   3   1]\n",
      " [  4  17   4 119  26  33   7]\n",
      " [ 24  17   1  27 114  14  13]\n",
      " [ 10  17   8  26  10  87  52]\n",
      " [  1   2   0   3   1  31 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.68       210\n",
      "           2       0.67      0.66      0.67       210\n",
      "           3       0.87      0.89      0.88       210\n",
      "           4       0.57      0.57      0.57       210\n",
      "           5       0.58      0.54      0.56       210\n",
      "           6       0.41      0.41      0.41       210\n",
      "           7       0.67      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.65      0.65      0.64      1470\n",
      "weighted avg       0.65      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6428571428571429\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[130   3   9   7  31  21   9]\n",
      " [  4 137   8  21  17  20   3]\n",
      " [  2  12 182   8   3   2   1]\n",
      " [  5  19   4 115  25  35   7]\n",
      " [ 22  14   2  29 114  16  13]\n",
      " [ 13  22   5  22   6  95  47]\n",
      " [  0   2   0   2   3  31 172]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.67       210\n",
      "           2       0.66      0.65      0.65       210\n",
      "           3       0.87      0.87      0.87       210\n",
      "           4       0.56      0.55      0.56       210\n",
      "           5       0.57      0.54      0.56       210\n",
      "           6       0.43      0.45      0.44       210\n",
      "           7       0.68      0.82      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.64      0.64      0.64      1470\n",
      "weighted avg       0.64      0.64      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5183673469387755\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[114   5  23   8  21   9  30]\n",
      " [  1 119  34  12  15  16  13]\n",
      " [  1  11 174  21   1   1   1]\n",
      " [  7  16  17  80  31  17  42]\n",
      " [ 32  26   1  12  94   8  37]\n",
      " [ 12  38  18  19  12  39  72]\n",
      " [  0  31   0  17   8  12 142]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.54      0.60       210\n",
      "           2       0.48      0.57      0.52       210\n",
      "           3       0.65      0.83      0.73       210\n",
      "           4       0.47      0.38      0.42       210\n",
      "           5       0.52      0.45      0.48       210\n",
      "           6       0.38      0.19      0.25       210\n",
      "           7       0.42      0.68      0.52       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.52      0.52      0.50      1470\n",
      "weighted avg       0.52      0.52      0.50      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e359cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.7204081632653061\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[146  11   2   4  32  14   1]\n",
      " [  1 185   3   9   8   4   0]\n",
      " [  1  15 186   3   3   2   0]\n",
      " [  3  33   2 144  12  15   1]\n",
      " [ 27  25   2  33 111  10   2]\n",
      " [  5  45   1  18   6 121  14]\n",
      " [  0   5   0   4   2  33 166]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.70      0.74       210\n",
      "           2       0.58      0.88      0.70       210\n",
      "           3       0.95      0.89      0.92       210\n",
      "           4       0.67      0.69      0.68       210\n",
      "           5       0.64      0.53      0.58       210\n",
      "           6       0.61      0.58      0.59       210\n",
      "           7       0.90      0.79      0.84       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.73      0.72      0.72      1470\n",
      "weighted avg       0.73      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5693877551020409\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128  11  14   5  50   1   1]\n",
      " [ 27 131  14  13  21   1   3]\n",
      " [ 11  20 174   2   3   0   0]\n",
      " [ 31  24  12  94  36   9   4]\n",
      " [ 62  19   4  22  97   4   2]\n",
      " [ 43  19  16  33  15  49  35]\n",
      " [ 13   0   0   8   8  17 164]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.61      0.49       210\n",
      "           2       0.58      0.62      0.60       210\n",
      "           3       0.74      0.83      0.78       210\n",
      "           4       0.53      0.45      0.49       210\n",
      "           5       0.42      0.46      0.44       210\n",
      "           6       0.60      0.23      0.34       210\n",
      "           7       0.78      0.78      0.78       210\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.58      0.57      0.56      1470\n",
      "weighted avg       0.58      0.57      0.56      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5986394557823129\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[142   8  13   4  41   2   0]\n",
      " [ 21 132  12  12  26   3   4]\n",
      " [  8  18 176   3   2   3   0]\n",
      " [ 25  24  12  97  36  12   4]\n",
      " [ 55  20   3  20 104   5   3]\n",
      " [ 39  21  14  25  13  57  41]\n",
      " [  7   0   0   3   5  23 172]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.68      0.56       210\n",
      "           2       0.59      0.63      0.61       210\n",
      "           3       0.77      0.84      0.80       210\n",
      "           4       0.59      0.46      0.52       210\n",
      "           5       0.46      0.50      0.48       210\n",
      "           6       0.54      0.27      0.36       210\n",
      "           7       0.77      0.82      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.5979591836734693\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[133   7  12   4  47   5   2]\n",
      " [ 17 133  14  10  26   7   3]\n",
      " [  4  19 178   3   3   3   0]\n",
      " [ 20  22  11 103  41   9   4]\n",
      " [ 45  19   4  19 113   5   5]\n",
      " [ 31  20  15  28  21  48  47]\n",
      " [  6   0   0   4   6  23 171]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.63      0.57       210\n",
      "           2       0.60      0.63      0.62       210\n",
      "           3       0.76      0.85      0.80       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.44      0.54      0.48       210\n",
      "           6       0.48      0.23      0.31       210\n",
      "           7       0.74      0.81      0.77       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.59      0.60      0.59      1470\n",
      "weighted avg       0.59      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6034013605442177\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[137   8  10   6  42   4   3]\n",
      " [ 15 138  13  11  25   3   5]\n",
      " [  5  20 177   4   2   2   0]\n",
      " [ 21  22  12 100  44   8   3]\n",
      " [ 54  16   4  17 111   4   4]\n",
      " [ 31  21  12  29  22  47  48]\n",
      " [  5   1   0   3   8  16 177]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.65      0.57       210\n",
      "           2       0.61      0.66      0.63       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.59      0.48      0.53       210\n",
      "           5       0.44      0.53      0.48       210\n",
      "           6       0.56      0.22      0.32       210\n",
      "           7       0.74      0.84      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6047619047619047\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[136   7   8   4  48   4   3]\n",
      " [ 14 134  15  12  27   4   4]\n",
      " [  7  17 177   3   4   2   0]\n",
      " [ 19  22  12 102  44   8   3]\n",
      " [ 51  16   5  16 115   4   3]\n",
      " [ 31  19  10  31  20  43  56]\n",
      " [  6   0   0   1  10  11 182]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.65      0.57       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.78      0.84      0.81       210\n",
      "           4       0.60      0.49      0.54       210\n",
      "           5       0.43      0.55      0.48       210\n",
      "           6       0.57      0.20      0.30       210\n",
      "           7       0.73      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.61      0.60      0.59      1470\n",
      "weighted avg       0.61      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.6027210884353742\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[135   7  11   5  43   6   3]\n",
      " [ 14 134  14  11  28   4   5]\n",
      " [  7  18 175   5   3   2   0]\n",
      " [ 20  22  12 103  42   8   3]\n",
      " [ 49  13   5  20 116   4   3]\n",
      " [ 33  21   9  29  20  43  55]\n",
      " [  6   0   0   4   6  14 180]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.64      0.57       210\n",
      "           2       0.62      0.64      0.63       210\n",
      "           3       0.77      0.83      0.80       210\n",
      "           4       0.58      0.49      0.53       210\n",
      "           5       0.45      0.55      0.50       210\n",
      "           6       0.53      0.20      0.30       210\n",
      "           7       0.72      0.86      0.78       210\n",
      "\n",
      "    accuracy                           0.60      1470\n",
      "   macro avg       0.60      0.60      0.59      1470\n",
      "weighted avg       0.60      0.60      0.59      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.54421768707483\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[105   9  16   4  37  17  22]\n",
      " [  3 126  11  24  13  24   9]\n",
      " [ 15  26 150  10   0   8   1]\n",
      " [  6  15   7 102  19  38  23]\n",
      " [ 20  10   0  22 111  15  32]\n",
      " [ 17  24   6  33   5  67  58]\n",
      " [  1   4   0   9   5  52 139]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.50      0.56       210\n",
      "           2       0.59      0.60      0.59       210\n",
      "           3       0.79      0.71      0.75       210\n",
      "           4       0.50      0.49      0.49       210\n",
      "           5       0.58      0.53      0.55       210\n",
      "           6       0.30      0.32      0.31       210\n",
      "           7       0.49      0.66      0.56       210\n",
      "\n",
      "    accuracy                           0.54      1470\n",
      "   macro avg       0.55      0.54      0.55      1470\n",
      "weighted avg       0.55      0.54      0.55      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2530612244897959\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 36   5   7  12 134  14   2]\n",
      " [  4  20   4  13 155   7   7]\n",
      " [  5   5  80  16  92  11   1]\n",
      " [  6   6   6  16 163   9   4]\n",
      " [  5   2   1  10 182   7   3]\n",
      " [  8   9   5  13 138  22  15]\n",
      " [  1   1   3   3 179   7  16]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.17      0.26       210\n",
      "           2       0.42      0.10      0.16       210\n",
      "           3       0.75      0.38      0.51       210\n",
      "           4       0.19      0.08      0.11       210\n",
      "           5       0.17      0.87      0.29       210\n",
      "           6       0.29      0.10      0.15       210\n",
      "           7       0.33      0.08      0.12       210\n",
      "\n",
      "    accuracy                           0.25      1470\n",
      "   macro avg       0.39      0.25      0.23      1470\n",
      "weighted avg       0.39      0.25      0.23      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM after Standard Scaling is: 0.7\n",
      "Confusion Matrix of SVM is:\n",
      " [[150   7   1   7  33  11   1]\n",
      " [  3 179   3  11   7   7   0]\n",
      " [  0   8 195   2   3   2   0]\n",
      " [  6  36   5 140  16   6   1]\n",
      " [ 32  26   1  24 120   4   3]\n",
      " [  7  40  10  25   5 105  18]\n",
      " [  0   2   0   6   2  60 140]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.71      0.74       210\n",
      "           2       0.60      0.85      0.70       210\n",
      "           3       0.91      0.93      0.92       210\n",
      "           4       0.65      0.67      0.66       210\n",
      "           5       0.65      0.57      0.61       210\n",
      "           6       0.54      0.50      0.52       210\n",
      "           7       0.86      0.67      0.75       210\n",
      "\n",
      "    accuracy                           0.70      1470\n",
      "   macro avg       0.71      0.70      0.70      1470\n",
      "weighted avg       0.71      0.70      0.70      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.719047619047619\n",
      "Confusion Matrix of SVM is:\n",
      " [[153   5   1   7  34  10   0]\n",
      " [  3 177   3  12   6   8   1]\n",
      " [  0   9 195   3   2   1   0]\n",
      " [  8  28   5 148  12   7   2]\n",
      " [ 32  18   1  38 113   4   4]\n",
      " [  3  30   8  33   2 110  24]\n",
      " [  1   2   0   8   1  37 161]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75       210\n",
      "           2       0.66      0.84      0.74       210\n",
      "           3       0.92      0.93      0.92       210\n",
      "           4       0.59      0.70      0.64       210\n",
      "           5       0.66      0.54      0.59       210\n",
      "           6       0.62      0.52      0.57       210\n",
      "           7       0.84      0.77      0.80       210\n",
      "\n",
      "    accuracy                           0.72      1470\n",
      "   macro avg       0.72      0.72      0.72      1470\n",
      "weighted avg       0.72      0.72      0.72      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.7510204081632653\n",
      "Confusion Matrix of SVM is:\n",
      " [[152   4   6   7  20  21   0]\n",
      " [  2 159   6  16   3  22   2]\n",
      " [  0   8 196   3   0   3   0]\n",
      " [  0  10   9 151  11  28   1]\n",
      " [ 30  17   2  26 116  14   5]\n",
      " [  2   9   6  15   1 150  27]\n",
      " [  0   0   0   0   1  29 180]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.72      0.77       210\n",
      "           2       0.77      0.76      0.76       210\n",
      "           3       0.87      0.93      0.90       210\n",
      "           4       0.69      0.72      0.71       210\n",
      "           5       0.76      0.55      0.64       210\n",
      "           6       0.56      0.71      0.63       210\n",
      "           7       0.84      0.86      0.85       210\n",
      "\n",
      "    accuracy                           0.75      1470\n",
      "   macro avg       0.76      0.75      0.75      1470\n",
      "weighted avg       0.76      0.75      0.75      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 68   0  34   1  40   1  66]\n",
      " [  1  21  60   6  35   2  85]\n",
      " [  0   0 170   3   8   2  27]\n",
      " [  1   0  12  46  50   1 100]\n",
      " [  4   1   6   2 130   1  66]\n",
      " [  5   2  22   7  14   4 156]\n",
      " [  0   0   0   0   6   0 204]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.32      0.47       210\n",
      "           2       0.88      0.10      0.18       210\n",
      "           3       0.56      0.81      0.66       210\n",
      "           4       0.71      0.22      0.33       210\n",
      "           5       0.46      0.62      0.53       210\n",
      "           6       0.36      0.02      0.04       210\n",
      "           7       0.29      0.97      0.45       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.59      0.44      0.38      1470\n",
      "weighted avg       0.59      0.44      0.38      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.23605442176870747\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  24   0   0   0 186]\n",
      " [  0   0  21   0   0   0 189]\n",
      " [  0   0 138   0   0   0  72]\n",
      " [  0   0  20   0   0   0 190]\n",
      " [  0   0   1   0   0   0 209]\n",
      " [  0   0  11   0   0   0 199]\n",
      " [  0   0   1   0   0   0 209]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.64      0.66      0.65       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.17      1.00      0.29       210\n",
      "\n",
      "    accuracy                           0.24      1470\n",
      "   macro avg       0.12      0.24      0.13      1470\n",
      "weighted avg       0.12      0.24      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3414965986394558\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 12   0  12   0 133   0  53]\n",
      " [ 14   0   7   0 111   0  78]\n",
      " [  7   0 131   0  37   0  35]\n",
      " [ 10   0  10   0 135   0  55]\n",
      " [  1   0   0   0 182   0  27]\n",
      " [  2   0   9   0  73   0 126]\n",
      " [  1   0   0   0  32   0 177]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.06      0.09       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.78      0.62      0.69       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.26      0.87      0.40       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.32      0.84      0.47       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.23      0.34      0.24      1470\n",
      "weighted avg       0.23      0.34      0.24      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.38571428571428573\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 12  36  10   2 130   0  20]\n",
      " [  0  91   6   1  75   0  37]\n",
      " [  4  30 111  20  27   0  18]\n",
      " [  3  59   2   8 108   0  30]\n",
      " [  0  21   0   0 171   0  18]\n",
      " [  1  49   1   8  47   0 104]\n",
      " [  0   8   0   0  28   0 174]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.06      0.10       210\n",
      "           2       0.31      0.43      0.36       210\n",
      "           3       0.85      0.53      0.65       210\n",
      "           4       0.21      0.04      0.06       210\n",
      "           5       0.29      0.81      0.43       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.43      0.83      0.57       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.38      0.39      0.31      1470\n",
      "weighted avg       0.38      0.39      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60   0   0  48  82  20   0]\n",
      " [  5  57   5  36  70  30   7]\n",
      " [  8  22 111  28  23   9   9]\n",
      " [  5   8   2  59 106  25   5]\n",
      " [  7   1   0  20 164  13   5]\n",
      " [  6  15   1  42  42  81  23]\n",
      " [  1   0   0   8  27 106  68]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.29      0.40       210\n",
      "           2       0.55      0.27      0.36       210\n",
      "           3       0.93      0.53      0.67       210\n",
      "           4       0.24      0.28      0.26       210\n",
      "           5       0.32      0.78      0.45       210\n",
      "           6       0.29      0.39      0.33       210\n",
      "           7       0.58      0.32      0.42       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.51      0.41      0.41      1470\n",
      "weighted avg       0.51      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.42585034013605444\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67   0   2  40  80  21   0]\n",
      " [  2  55  11  47  58  37   0]\n",
      " [  7  12 114  42  12  18   5]\n",
      " [  6   1   2  87  81  30   3]\n",
      " [  5   1   2  33 146  19   4]\n",
      " [  5   8   3  48  36  95  15]\n",
      " [  1   2   0   8  24 113  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.32      0.44       210\n",
      "           2       0.70      0.26      0.38       210\n",
      "           3       0.85      0.54      0.66       210\n",
      "           4       0.29      0.41      0.34       210\n",
      "           5       0.33      0.70      0.45       210\n",
      "           6       0.29      0.45      0.35       210\n",
      "           7       0.70      0.30      0.41       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.55      0.43      0.43      1470\n",
      "weighted avg       0.55      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44013605442176873\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55  19   5  24  73  26   8]\n",
      " [  2 102  10  32  22  33   9]\n",
      " [ 16  19 123  24   2  17   9]\n",
      " [  4  53   5  73  39  17  19]\n",
      " [  3  58   1  29  95  15   9]\n",
      " [  4  22   4  42  27  43  68]\n",
      " [  0   9   0   7  19  19 156]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.26      0.37       210\n",
      "           2       0.36      0.49      0.41       210\n",
      "           3       0.83      0.59      0.69       210\n",
      "           4       0.32      0.35      0.33       210\n",
      "           5       0.34      0.45      0.39       210\n",
      "           6       0.25      0.20      0.23       210\n",
      "           7       0.56      0.74      0.64       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.47      0.44      0.44      1470\n",
      "weighted avg       0.47      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.44285714285714284\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55   8   6  22  88  28   3]\n",
      " [  0  78  12  21  48  39  12]\n",
      " [  9  17 127  22  16  13   6]\n",
      " [  4  14   4  70  83  25  10]\n",
      " [  3  18   1  26 141  15   6]\n",
      " [  3  16   1  31  46  71  42]\n",
      " [  0   5   0   4  27  65 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.26      0.39       210\n",
      "           2       0.50      0.37      0.43       210\n",
      "           3       0.84      0.60      0.70       210\n",
      "           4       0.36      0.33      0.34       210\n",
      "           5       0.31      0.67      0.43       210\n",
      "           6       0.28      0.34      0.30       210\n",
      "           7       0.58      0.52      0.55       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.52      0.44      0.45      1470\n",
      "weighted avg       0.52      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[107  12  18   8  32  28   5]\n",
      " [ 18  88  20  15  26  35   8]\n",
      " [ 10  21 131  18  11  15   4]\n",
      " [ 28  30  14  62  45  22   9]\n",
      " [ 56  29   8  22  75  16   4]\n",
      " [ 20  18  15  32  19  67  39]\n",
      " [ 19   8   0  14   6  57 106]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.51      0.46       210\n",
      "           2       0.43      0.42      0.42       210\n",
      "           3       0.64      0.62      0.63       210\n",
      "           4       0.36      0.30      0.33       210\n",
      "           5       0.35      0.36      0.35       210\n",
      "           6       0.28      0.32      0.30       210\n",
      "           7       0.61      0.50      0.55       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.44      0.43      0.43      1470\n",
      "weighted avg       0.44      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.43741496598639457\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95  31   7  14  30  24   9]\n",
      " [ 10 104  10  14  30  28  14]\n",
      " [  6  28 125  23  13  11   4]\n",
      " [ 15  44  10  51  42  34  14]\n",
      " [ 47  42   2  18  72  26   3]\n",
      " [ 11  26  12  28  14  64  55]\n",
      " [  7   8   1   9   6  47 132]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.45      0.47       210\n",
      "           2       0.37      0.50      0.42       210\n",
      "           3       0.75      0.60      0.66       210\n",
      "           4       0.32      0.24      0.28       210\n",
      "           5       0.35      0.34      0.35       210\n",
      "           6       0.27      0.30      0.29       210\n",
      "           7       0.57      0.63      0.60       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.41564625850340137\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 95   7   5  17  43  32  11]\n",
      " [ 28  76   8  33  21  28  16]\n",
      " [ 10  19 124  29  15   9   4]\n",
      " [ 24  26   4  79  24  37  16]\n",
      " [ 37  18   1  61  68  19   6]\n",
      " [ 27  17   5  38  21  50  52]\n",
      " [  8   6   1  14  16  46 119]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.45      0.43       210\n",
      "           2       0.45      0.36      0.40       210\n",
      "           3       0.84      0.59      0.69       210\n",
      "           4       0.29      0.38      0.33       210\n",
      "           5       0.33      0.32      0.33       210\n",
      "           6       0.23      0.24      0.23       210\n",
      "           7       0.53      0.57      0.55       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.42      1470\n",
      "weighted avg       0.44      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4054421768707483\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 97   9   6  19  41  28  10]\n",
      " [ 28  82  11  27  25  25  12]\n",
      " [  5  22 126  30  14  10   3]\n",
      " [ 24  30  10  76  25  32  13]\n",
      " [ 45  21   3  62  56  17   6]\n",
      " [ 32  21   5  35  18  52  47]\n",
      " [ 15   8   2  15  14  49 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.46      0.43       210\n",
      "           2       0.42      0.39      0.41       210\n",
      "           3       0.77      0.60      0.68       210\n",
      "           4       0.29      0.36      0.32       210\n",
      "           5       0.29      0.27      0.28       210\n",
      "           6       0.24      0.25      0.25       210\n",
      "           7       0.54      0.51      0.52       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.40748299319727893\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[103   8   3  21  33  30  12]\n",
      " [ 28  91  13  21  21  22  14]\n",
      " [  9  20 123  25  17  11   5]\n",
      " [ 37  26   7  67  31  29  13]\n",
      " [ 62  19   1  44  60  15   9]\n",
      " [ 22  25   8  34  24  47  50]\n",
      " [ 12   6   5  16  17  46 108]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.49      0.43       210\n",
      "           2       0.47      0.43      0.45       210\n",
      "           3       0.77      0.59      0.66       210\n",
      "           4       0.29      0.32      0.31       210\n",
      "           5       0.30      0.29      0.29       210\n",
      "           6       0.23      0.22      0.23       210\n",
      "           7       0.51      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4061224489795918\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 87  12   5  23  42  28  13]\n",
      " [ 23  93  12  22  20  25  15]\n",
      " [  9  20 126  28  18   8   1]\n",
      " [ 30  37   6  66  27  30  14]\n",
      " [ 42  24   3  48  64  19  10]\n",
      " [ 16  22  12  39  20  43  58]\n",
      " [  8  10  12  16   3  43 118]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.41      0.41       210\n",
      "           2       0.43      0.44      0.43       210\n",
      "           3       0.72      0.60      0.65       210\n",
      "           4       0.27      0.31      0.29       210\n",
      "           5       0.33      0.30      0.32       210\n",
      "           6       0.22      0.20      0.21       210\n",
      "           7       0.52      0.56      0.54       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.41      0.41      0.41      1470\n",
      "weighted avg       0.41      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.40816326530612246\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 82  20   6  15  46  28  13]\n",
      " [ 15  90  13  22  27  26  17]\n",
      " [  7  20 127  24  16  13   3]\n",
      " [ 24  30   7  63  39  30  17]\n",
      " [ 38  26   3  45  68  23   7]\n",
      " [ 11  22  18  29  28  50  52]\n",
      " [  5  11   5  14  18  37 120]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.39      0.42       210\n",
      "           2       0.41      0.43      0.42       210\n",
      "           3       0.71      0.60      0.65       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.28      0.32      0.30       210\n",
      "           6       0.24      0.24      0.24       210\n",
      "           7       0.52      0.57      0.55       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.41      1470\n",
      "weighted avg       0.42      0.41      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.38639455782312926\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 86  10   6  15  51  30  12]\n",
      " [ 20  85  16  23  27  30   9]\n",
      " [  5  18 125  27  19  13   3]\n",
      " [ 26  28  10  63  40  26  17]\n",
      " [ 42  26   5  51  58  18  10]\n",
      " [ 16  21  10  35  35  42  51]\n",
      " [ 13  15   1  19  21  32 109]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.41      0.41       210\n",
      "           2       0.42      0.40      0.41       210\n",
      "           3       0.72      0.60      0.65       210\n",
      "           4       0.27      0.30      0.28       210\n",
      "           5       0.23      0.28      0.25       210\n",
      "           6       0.22      0.20      0.21       210\n",
      "           7       0.52      0.52      0.52       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.40      0.39      0.39      1470\n",
      "weighted avg       0.40      0.39      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.4020408163265306\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 81  17   5  18  47  30  12]\n",
      " [ 17 102  14  24  18  24  11]\n",
      " [  7  25 128  19  18  10   3]\n",
      " [ 24  31   6  64  40  28  17]\n",
      " [ 40  23   8  46  64  18  11]\n",
      " [ 14  25   6  33  36  49  47]\n",
      " [ 11  10   2  17  23  44 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.39      0.40       210\n",
      "           2       0.44      0.49      0.46       210\n",
      "           3       0.76      0.61      0.68       210\n",
      "           4       0.29      0.30      0.30       210\n",
      "           5       0.26      0.30      0.28       210\n",
      "           6       0.24      0.23      0.24       210\n",
      "           7       0.50      0.49      0.50       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.41      1470\n",
      "weighted avg       0.42      0.40      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39591836734693875\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  13  13  15  53  27   9]\n",
      " [ 13  95  12  25  23  26  16]\n",
      " [ 10  18 125  28  20   6   3]\n",
      " [ 25  27   8  64  42  29  15]\n",
      " [ 42  23   4  47  67  20   7]\n",
      " [ 14  26   6  38  37  41  48]\n",
      " [  8  12   3  15  22  40 110]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.38      0.40       210\n",
      "           2       0.44      0.45      0.45       210\n",
      "           3       0.73      0.60      0.66       210\n",
      "           4       0.28      0.30      0.29       210\n",
      "           5       0.25      0.32      0.28       210\n",
      "           6       0.22      0.20      0.21       210\n",
      "           7       0.53      0.52      0.53       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.41      0.40      0.40      1470\n",
      "weighted avg       0.41      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3925170068027211\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 80  13   7  17  47  31  15]\n",
      " [ 13  94  12  25  21  30  15]\n",
      " [  6  18 124  27  20  13   2]\n",
      " [ 26  28   6  70  29  32  19]\n",
      " [ 36  27   4  49  61  23  10]\n",
      " [ 20  22   8  39  26  44  51]\n",
      " [  6  12   2  19  23  44 104]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.38      0.40       210\n",
      "           2       0.44      0.45      0.44       210\n",
      "           3       0.76      0.59      0.66       210\n",
      "           4       0.28      0.33      0.31       210\n",
      "           5       0.27      0.29      0.28       210\n",
      "           6       0.20      0.21      0.21       210\n",
      "           7       0.48      0.50      0.49       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.40      1470\n",
      "weighted avg       0.41      0.39      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.39727891156462586\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 79  16   5  19  49  31  11]\n",
      " [ 12  91  11  28  24  28  16]\n",
      " [  8  20 127  24  17  12   2]\n",
      " [ 22  31   7  65  38  30  17]\n",
      " [ 42  20   3  49  67  22   7]\n",
      " [ 16  22   7  41  24  48  52]\n",
      " [  5   9   5  15  19  50 107]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.38      0.40       210\n",
      "           2       0.44      0.43      0.43       210\n",
      "           3       0.77      0.60      0.68       210\n",
      "           4       0.27      0.31      0.29       210\n",
      "           5       0.28      0.32      0.30       210\n",
      "           6       0.22      0.23      0.22       210\n",
      "           7       0.50      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.42      0.40      0.40      1470\n",
      "weighted avg       0.42      0.40      0.40      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.3707482993197279\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60  11  28  16  51  28  16]\n",
      " [ 19  83  16  24  23  28  17]\n",
      " [  7  21 125  20  21  14   2]\n",
      " [ 23  27   8  63  42  28  19]\n",
      " [ 39  23   6  44  68  22   8]\n",
      " [ 17  20  11  34  35  43  50]\n",
      " [  9  10   4  18  30  36 103]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.29      0.31       210\n",
      "           2       0.43      0.40      0.41       210\n",
      "           3       0.63      0.60      0.61       210\n",
      "           4       0.29      0.30      0.29       210\n",
      "           5       0.25      0.32      0.28       210\n",
      "           6       0.22      0.20      0.21       210\n",
      "           7       0.48      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.38      0.37      0.37      1470\n",
      "weighted avg       0.38      0.37      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3727891156462585\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 23   7  39   2  69   0  70]\n",
      " [  4  29  69   1  28   0  79]\n",
      " [  2   6 179   0   7   0  16]\n",
      " [  3   2  27  10  71   0  97]\n",
      " [  0   4   5   1 101   0  99]\n",
      " [  1  10  29   3  17   1 149]\n",
      " [  0   1   1   0   3   0 205]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.11      0.19       210\n",
      "           2       0.49      0.14      0.22       210\n",
      "           3       0.51      0.85      0.64       210\n",
      "           4       0.59      0.05      0.09       210\n",
      "           5       0.34      0.48      0.40       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.29      0.98      0.44       210\n",
      "\n",
      "    accuracy                           0.37      1470\n",
      "   macro avg       0.56      0.37      0.28      1470\n",
      "weighted avg       0.56      0.37      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.47891156462585033\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87   9   8   0  78   0  28]\n",
      " [  4  82  25   3  65   0  31]\n",
      " [  4  20 162   0  17   0   7]\n",
      " [  7  14  11  15 104   0  59]\n",
      " [  6   9   1   0 154   0  40]\n",
      " [  9  24  11   3  35   1 127]\n",
      " [  0   0   0   0   7   0 203]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.41      0.53       210\n",
      "           2       0.52      0.39      0.45       210\n",
      "           3       0.74      0.77      0.76       210\n",
      "           4       0.71      0.07      0.13       210\n",
      "           5       0.33      0.73      0.46       210\n",
      "           6       1.00      0.00      0.01       210\n",
      "           7       0.41      0.97      0.58       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.64      0.48      0.42      1470\n",
      "weighted avg       0.64      0.48      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5326530612244897\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[105  11   3   0  60   1  30]\n",
      " [  2 132  13   3  37   2  21]\n",
      " [  2  39 158   0   6   3   2]\n",
      " [  3  23  11  33  80   4  56]\n",
      " [  8  10   0   3 148   1  40]\n",
      " [ 10  36   8   6  27   5 118]\n",
      " [  0   1   0   0   7   0 202]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.50      0.62       210\n",
      "           2       0.52      0.63      0.57       210\n",
      "           3       0.82      0.75      0.78       210\n",
      "           4       0.73      0.16      0.26       210\n",
      "           5       0.41      0.70      0.51       210\n",
      "           6       0.31      0.02      0.04       210\n",
      "           7       0.43      0.96      0.59       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.58      0.53      0.48      1470\n",
      "weighted avg       0.58      0.53      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5625850340136055\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116  11   1   0  55   9  18]\n",
      " [  1 138   4   7  38   4  18]\n",
      " [  0  37 160   2   5   4   2]\n",
      " [  0  25   8  54  70  13  40]\n",
      " [ 20   9   0   5 140   4  32]\n",
      " [ 12  33   7  12  21  19 106]\n",
      " [  0   0   0   1   7   2 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.55      0.65       210\n",
      "           2       0.55      0.66      0.60       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.67      0.26      0.37       210\n",
      "           5       0.42      0.67      0.51       210\n",
      "           6       0.35      0.09      0.14       210\n",
      "           7       0.48      0.95      0.64       210\n",
      "\n",
      "    accuracy                           0.56      1470\n",
      "   macro avg       0.59      0.56      0.53      1470\n",
      "weighted avg       0.59      0.56      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.5870748299319728\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[116  12   1   8  45  13  15]\n",
      " [  1 141   3  19  22  12  12]\n",
      " [  2  39 157   6   1   3   2]\n",
      " [  1  22   4  97  42  18  26]\n",
      " [ 13  14   0  20 130   7  26]\n",
      " [  9  33   6  30  11  22  99]\n",
      " [  0   1   0   0   6   3 200]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.55      0.66       210\n",
      "           2       0.54      0.67      0.60       210\n",
      "           3       0.92      0.75      0.82       210\n",
      "           4       0.54      0.46      0.50       210\n",
      "           5       0.51      0.62      0.56       210\n",
      "           6       0.28      0.10      0.15       210\n",
      "           7       0.53      0.95      0.68       210\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.59      0.59      0.57      1470\n",
      "weighted avg       0.59      0.59      0.57      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6122448979591837\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122   7   1   8  44  14  14]\n",
      " [  1 136   4  20  25  11  13]\n",
      " [  1  32 159   9   4   3   2]\n",
      " [  1  11   7 109  38  18  26]\n",
      " [ 13  11   0  20 137  11  18]\n",
      " [  4  26   7  32  13  42  86]\n",
      " [  0   0   0   2   6   7 195]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.61      0.65      0.63       210\n",
      "           3       0.89      0.76      0.82       210\n",
      "           4       0.55      0.52      0.53       210\n",
      "           5       0.51      0.65      0.57       210\n",
      "           6       0.40      0.20      0.27       210\n",
      "           7       0.55      0.93      0.69       210\n",
      "\n",
      "    accuracy                           0.61      1470\n",
      "   macro avg       0.62      0.61      0.60      1470\n",
      "weighted avg       0.62      0.61      0.60      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6258503401360545\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[119  12   1   5  49  14  10]\n",
      " [  1 147   4  12  23  16   7]\n",
      " [  0  30 163   7   2   7   1]\n",
      " [  2  17   5 104  34  33  15]\n",
      " [  7  11   0  24 140   8  20]\n",
      " [  8  23   4  35  12  50  78]\n",
      " [  0   0   0   2   3   8 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.57      0.69       210\n",
      "           2       0.61      0.70      0.65       210\n",
      "           3       0.92      0.78      0.84       210\n",
      "           4       0.55      0.50      0.52       210\n",
      "           5       0.53      0.67      0.59       210\n",
      "           6       0.37      0.24      0.29       210\n",
      "           7       0.60      0.94      0.73       210\n",
      "\n",
      "    accuracy                           0.63      1470\n",
      "   macro avg       0.64      0.63      0.62      1470\n",
      "weighted avg       0.64      0.63      0.62      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6374149659863946\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[120   7   2   8  45  20   8]\n",
      " [  3 147   2  15  18  19   6]\n",
      " [  1  32 163   8   3   3   0]\n",
      " [  0  14   2 114  34  33  13]\n",
      " [ 13  10   0  22 140  12  13]\n",
      " [  7  23   4  27  12  59  78]\n",
      " [  0   0   0   1   3  12 194]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.57      0.68       210\n",
      "           2       0.63      0.70      0.66       210\n",
      "           3       0.94      0.78      0.85       210\n",
      "           4       0.58      0.54      0.56       210\n",
      "           5       0.55      0.67      0.60       210\n",
      "           6       0.37      0.28      0.32       210\n",
      "           7       0.62      0.92      0.74       210\n",
      "\n",
      "    accuracy                           0.64      1470\n",
      "   macro avg       0.65      0.64      0.63      1470\n",
      "weighted avg       0.65      0.64      0.63      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6496598639455783\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[122  11   2   9  40  14  12]\n",
      " [  2 145   3  20  16  18   6]\n",
      " [  0  22 171   8   3   6   0]\n",
      " [  2  23   3 111  35  27   9]\n",
      " [  9  10   0  23 145   9  14]\n",
      " [  7  25   6  26  11  69  66]\n",
      " [  0   0   0   1   4  13 192]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.58      0.69       210\n",
      "           2       0.61      0.69      0.65       210\n",
      "           3       0.92      0.81      0.87       210\n",
      "           4       0.56      0.53      0.54       210\n",
      "           5       0.57      0.69      0.62       210\n",
      "           6       0.44      0.33      0.38       210\n",
      "           7       0.64      0.91      0.75       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   8   0  12  37  19   6]\n",
      " [  2 145   5  21  13  19   5]\n",
      " [  1  26 166   8   5   3   1]\n",
      " [  0  19   3 120  28  29  11]\n",
      " [ 11   9   0  35 128  15  12]\n",
      " [  8  20   7  27   8  68  72]\n",
      " [  0   0   0   0   2  11 197]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.61      0.71       210\n",
      "           2       0.64      0.69      0.66       210\n",
      "           3       0.92      0.79      0.85       210\n",
      "           4       0.54      0.57      0.55       210\n",
      "           5       0.58      0.61      0.59       210\n",
      "           6       0.41      0.32      0.36       210\n",
      "           7       0.65      0.94      0.77       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.64      1470\n",
      "weighted avg       0.66      0.65      0.64      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6598639455782312\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   5   2   9  38  21   7]\n",
      " [  2 139   4  20  20  21   4]\n",
      " [  0  22 175   6   2   4   1]\n",
      " [  3  21   5 111  29  32   9]\n",
      " [ 14  12   0  22 140  11  11]\n",
      " [ 11  17   1  27  10  89  55]\n",
      " [  0   0   0   1   2  19 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.61      0.70       210\n",
      "           2       0.64      0.66      0.65       210\n",
      "           3       0.94      0.83      0.88       210\n",
      "           4       0.57      0.53      0.55       210\n",
      "           5       0.58      0.67      0.62       210\n",
      "           6       0.45      0.42      0.44       210\n",
      "           7       0.68      0.90      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6476190476190476\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[121  10   2   7  47  19   4]\n",
      " [  2 138   3  23  22  17   5]\n",
      " [  1  19 174  10   0   6   0]\n",
      " [  2  16   5 116  32  26  13]\n",
      " [ 12  18   0  25 130  13  12]\n",
      " [  9  20   7  20  13  92  49]\n",
      " [  0   2   0   0   3  24 181]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.58      0.68       210\n",
      "           2       0.62      0.66      0.64       210\n",
      "           3       0.91      0.83      0.87       210\n",
      "           4       0.58      0.55      0.56       210\n",
      "           5       0.53      0.62      0.57       210\n",
      "           6       0.47      0.44      0.45       210\n",
      "           7       0.69      0.86      0.76       210\n",
      "\n",
      "    accuracy                           0.65      1470\n",
      "   macro avg       0.66      0.65      0.65      1470\n",
      "weighted avg       0.66      0.65      0.65      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6571428571428571\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[124   7   4   9  39  22   5]\n",
      " [  3 136   5  27  17  17   5]\n",
      " [  1  26 167   9   1   4   2]\n",
      " [  0  18   4 119  34  25  10]\n",
      " [ 11  13   1  28 135  13   9]\n",
      " [ 11  13   5  25  10  94  52]\n",
      " [  1   0   0   3   2  13 191]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.59      0.69       210\n",
      "           2       0.64      0.65      0.64       210\n",
      "           3       0.90      0.80      0.84       210\n",
      "           4       0.54      0.57      0.55       210\n",
      "           5       0.57      0.64      0.60       210\n",
      "           6       0.50      0.45      0.47       210\n",
      "           7       0.70      0.91      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6700680272108843\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[127   6   4  10  36  18   9]\n",
      " [  2 147   5  16  14  20   6]\n",
      " [  0  20 175   7   5   2   1]\n",
      " [  1  21   5 116  26  35   6]\n",
      " [ 14  10   0  25 135  16  10]\n",
      " [  8  10   7  25   6  99  55]\n",
      " [  1   0   0   0   3  20 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.60      0.70       210\n",
      "           2       0.69      0.70      0.69       210\n",
      "           3       0.89      0.83      0.86       210\n",
      "           4       0.58      0.55      0.57       210\n",
      "           5       0.60      0.64      0.62       210\n",
      "           6       0.47      0.47      0.47       210\n",
      "           7       0.68      0.89      0.77       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.68      0.67      0.67      1470\n",
      "weighted avg       0.68      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   7   4   9  34  16  12]\n",
      " [  1 147   2  18  18  19   5]\n",
      " [  0  24 174   4   3   5   0]\n",
      " [  5  20   3 122  22  29   9]\n",
      " [ 17  12   0  23 132  10  16]\n",
      " [ 11  19   4  26   7  87  56]\n",
      " [  0   0   0   1   4  15 190]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.61      0.69       210\n",
      "           2       0.64      0.70      0.67       210\n",
      "           3       0.93      0.83      0.88       210\n",
      "           4       0.60      0.58      0.59       210\n",
      "           5       0.60      0.63      0.61       210\n",
      "           6       0.48      0.41      0.45       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.66      1470\n",
      "weighted avg       0.67      0.67      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.6571428571428571\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[129   6   5  10  35  20   5]\n",
      " [  4 151   1  19  10  21   4]\n",
      " [  2  25 164   8   2   9   0]\n",
      " [  2  19   3 109  30  38   9]\n",
      " [ 17  20   0  21 125  13  14]\n",
      " [ 12  18   4  24   4 101  47]\n",
      " [  0   0   0   1   2  20 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.61      0.69       210\n",
      "           2       0.63      0.72      0.67       210\n",
      "           3       0.93      0.78      0.85       210\n",
      "           4       0.57      0.52      0.54       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.45      0.48      0.47       210\n",
      "           7       0.70      0.89      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6551020408163265\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[134   4   3  13  36  12   8]\n",
      " [  2 141   2  15  19  26   5]\n",
      " [  0  25 165  10   4   5   1]\n",
      " [  5  14   3 120  24  37   7]\n",
      " [ 20  13   0  29 126  17   5]\n",
      " [ 12  20   3  26   5  90  54]\n",
      " [  0   0   0   1   3  19 187]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.64      0.70       210\n",
      "           2       0.65      0.67      0.66       210\n",
      "           3       0.94      0.79      0.85       210\n",
      "           4       0.56      0.57      0.57       210\n",
      "           5       0.58      0.60      0.59       210\n",
      "           6       0.44      0.43      0.43       210\n",
      "           7       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.66      0.66      0.66      1470\n",
      "weighted avg       0.66      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[133   4   5  12  32  18   6]\n",
      " [  2 142   1  22  18  17   8]\n",
      " [  2  20 170   8   5   5   0]\n",
      " [  3  25   2 124  22  26   8]\n",
      " [ 17  17   0  20 125  14  17]\n",
      " [ 10  17   9  25   2  90  57]\n",
      " [  1   0   0   1   2  18 188]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.63      0.70       210\n",
      "           2       0.63      0.68      0.65       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.58      0.59      0.59       210\n",
      "           5       0.61      0.60      0.60       210\n",
      "           6       0.48      0.43      0.45       210\n",
      "           7       0.66      0.90      0.76       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6612244897959184\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[135   3   3  12  37  19   1]\n",
      " [  4 141   2  22  19  18   4]\n",
      " [  3  21 168  11   1   6   0]\n",
      " [  5  16   8 118  31  25   7]\n",
      " [ 16  15   0  26 131  11  11]\n",
      " [ 11  17   6  23   7  96  50]\n",
      " [  0   0   0   3   3  21 183]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.64      0.70       210\n",
      "           2       0.66      0.67      0.67       210\n",
      "           3       0.90      0.80      0.85       210\n",
      "           4       0.55      0.56      0.56       210\n",
      "           5       0.57      0.62      0.60       210\n",
      "           6       0.49      0.46      0.47       210\n",
      "           7       0.71      0.87      0.79       210\n",
      "\n",
      "    accuracy                           0.66      1470\n",
      "   macro avg       0.67      0.66      0.66      1470\n",
      "weighted avg       0.67      0.66      0.66      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.6666666666666666\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[128   7   2  12  35  25   1]\n",
      " [  2 151   4  20  14  17   2]\n",
      " [  1  20 171  11   2   5   0]\n",
      " [  3  18   6 123  24  27   9]\n",
      " [ 20  18   0  25 126  13   8]\n",
      " [  9  20   4  27   5  95  50]\n",
      " [  0   0   0   0   3  21 186]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.61      0.69       210\n",
      "           2       0.65      0.72      0.68       210\n",
      "           3       0.91      0.81      0.86       210\n",
      "           4       0.56      0.59      0.57       210\n",
      "           5       0.60      0.60      0.60       210\n",
      "           6       0.47      0.45      0.46       210\n",
      "           7       0.73      0.89      0.80       210\n",
      "\n",
      "    accuracy                           0.67      1470\n",
      "   macro avg       0.67      0.67      0.67      1470\n",
      "weighted avg       0.67      0.67      0.67      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.5272108843537415\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 94   2  15  11  43  27  18]\n",
      " [  3  90  19  23  37  26  12]\n",
      " [ 22  12 132  22   8  14   0]\n",
      " [  3  11   5  92  39  35  25]\n",
      " [  8   6   0  13 134  19  30]\n",
      " [ 13  14   6  37  18  49  73]\n",
      " [  1   1   0  10   9   5 184]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.45      0.53       210\n",
      "           2       0.66      0.43      0.52       210\n",
      "           3       0.75      0.63      0.68       210\n",
      "           4       0.44      0.44      0.44       210\n",
      "           5       0.47      0.64      0.54       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.54      0.88      0.67       210\n",
      "\n",
      "    accuracy                           0.53      1470\n",
      "   macro avg       0.54      0.53      0.52      1470\n",
      "weighted avg       0.54      0.53      0.52      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hinglish GPT vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//gpt_hinglish_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97690a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression after Standard Scaling is: 0.482312925170068\n",
      "Confusion Matrix of Logistic Regression is:\n",
      " [[ 97  12   5   4  21  45  26]\n",
      " [ 11 111   4   9  22  42  11]\n",
      " [  3  18 163   7   2  13   4]\n",
      " [ 12  16   8  39  22  88  25]\n",
      " [ 29  29   2  21  51  51  27]\n",
      " [ 10  18   3  16   7 110  46]\n",
      " [  4   3   0   3   2  60 138]]\n",
      "Classification Report of Logistic Regression is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.46      0.52       210\n",
      "           2       0.54      0.53      0.53       210\n",
      "           3       0.88      0.78      0.83       210\n",
      "           4       0.39      0.19      0.25       210\n",
      "           5       0.40      0.24      0.30       210\n",
      "           6       0.27      0.52      0.36       210\n",
      "           7       0.50      0.66      0.57       210\n",
      "\n",
      "    accuracy                           0.48      1470\n",
      "   macro avg       0.51      0.48      0.48      1470\n",
      "weighted avg       0.51      0.48      0.48      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 3 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.42244897959183675\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[124  16   5  17  25   7  16]\n",
      " [ 29 109  11  19  24   7  11]\n",
      " [ 22  18 157   8   3   2   0]\n",
      " [ 57  20   4  82  34   8   5]\n",
      " [ 70  29   3  30  53  16   9]\n",
      " [ 79  30   7  33  27  17  17]\n",
      " [ 39  17   2  32  30  11  79]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.59      0.39       210\n",
      "           2       0.46      0.52      0.49       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.37      0.39      0.38       210\n",
      "           5       0.27      0.25      0.26       210\n",
      "           6       0.25      0.08      0.12       210\n",
      "           7       0.58      0.38      0.46       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.41      1470\n",
      "weighted avg       0.44      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 4 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.44761904761904764\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[128  14   5  16  25   5  17]\n",
      " [ 22 103  10  24  25  13  13]\n",
      " [ 21  16 159   6   4   4   0]\n",
      " [ 39  24   5  75  44  13  10]\n",
      " [ 60  27   2  23  66  15  17]\n",
      " [ 68  19   5  28  32  28  30]\n",
      " [ 25  11   1  21  36  17  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.61      0.45       210\n",
      "           2       0.48      0.49      0.49       210\n",
      "           3       0.85      0.76      0.80       210\n",
      "           4       0.39      0.36      0.37       210\n",
      "           5       0.28      0.31      0.30       210\n",
      "           6       0.29      0.13      0.18       210\n",
      "           7       0.53      0.47      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 5 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.42653061224489797\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[120  12   7  20  28   6  17]\n",
      " [ 21  86  16  27  34  18   8]\n",
      " [ 17  18 153   8   8   4   2]\n",
      " [ 37  18   5  74  47  18  11]\n",
      " [ 52  27   1  32  71  13  14]\n",
      " [ 62  24   6  32  34  26  26]\n",
      " [ 27  11   0  25  35  15  97]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.57      0.44       210\n",
      "           2       0.44      0.41      0.42       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.34      0.35      0.35       210\n",
      "           5       0.28      0.34      0.30       210\n",
      "           6       0.26      0.12      0.17       210\n",
      "           7       0.55      0.46      0.50       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.43      0.43      0.42      1470\n",
      "weighted avg       0.43      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 6 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[121  13   7  18  28   5  18]\n",
      " [ 25  92  14  25  35  13   6]\n",
      " [ 18  18 154   7   7   4   2]\n",
      " [ 36  18   6  82  47  10  11]\n",
      " [ 40  21   3  34  84  11  17]\n",
      " [ 56  25   5  34  38  23  29]\n",
      " [ 21  12   0  27  38  16  96]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.58      0.46       210\n",
      "           2       0.46      0.44      0.45       210\n",
      "           3       0.81      0.73      0.77       210\n",
      "           4       0.36      0.39      0.38       210\n",
      "           5       0.30      0.40      0.34       210\n",
      "           6       0.28      0.11      0.16       210\n",
      "           7       0.54      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 7 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4496598639455782\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[119  13   9  22  27   2  18]\n",
      " [ 24  99  13  28  28  10   8]\n",
      " [ 16  19 155   9   6   3   2]\n",
      " [ 34  18   5  87  44   9  13]\n",
      " [ 39  23   3  36  83   8  18]\n",
      " [ 50  24   7  38  41  21  29]\n",
      " [ 23  12   0  27  36  15  97]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.57      0.46       210\n",
      "           2       0.48      0.47      0.47       210\n",
      "           3       0.81      0.74      0.77       210\n",
      "           4       0.35      0.41      0.38       210\n",
      "           5       0.31      0.40      0.35       210\n",
      "           6       0.31      0.10      0.15       210\n",
      "           7       0.52      0.46      0.49       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "KNN with 8 Neighbors\n",
      "Accuracy of KNN Model after Standard Scaling is: 0.4496598639455782\n",
      "Confusion Matrix of KNN Model is:\n",
      " [[112  11  11  20  39   1  16]\n",
      " [ 23  98  12  25  35   8   9]\n",
      " [ 17  16 153  14   6   2   2]\n",
      " [ 32  17   7  92  37  12  13]\n",
      " [ 35  20   4  36  89   7  19]\n",
      " [ 45  26   6  34  48  18  33]\n",
      " [ 22  11   0  28  37  13  99]]\n",
      "Classification Report of KNN Model is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.53      0.45       210\n",
      "           2       0.49      0.47      0.48       210\n",
      "           3       0.79      0.73      0.76       210\n",
      "           4       0.37      0.44      0.40       210\n",
      "           5       0.31      0.42      0.36       210\n",
      "           6       0.30      0.09      0.13       210\n",
      "           7       0.52      0.47      0.49       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.44      1470\n",
      "weighted avg       0.45      0.45      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Gaussian Naive Bayes after Standard Scaling is: 0.3891156462585034\n",
      "Confusion Matrix of Gaussian Naive Bayes is:\n",
      " [[ 77  66   9  11  20   4  23]\n",
      " [ 12 123  24   9  17  15  10]\n",
      " [  9  51 145   1   0   3   1]\n",
      " [ 15  78   4  40  27  14  32]\n",
      " [ 21  54   4  24  66  13  28]\n",
      " [ 13  84   1  19  25  25  43]\n",
      " [ 11  33   0  16  19  35  96]]\n",
      "Classification Report of Gaussian Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.37      0.42       210\n",
      "           2       0.25      0.59      0.35       210\n",
      "           3       0.78      0.69      0.73       210\n",
      "           4       0.33      0.19      0.24       210\n",
      "           5       0.38      0.31      0.34       210\n",
      "           6       0.23      0.12      0.16       210\n",
      "           7       0.41      0.46      0.43       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.41      0.39      0.38      1470\n",
      "weighted avg       0.41      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Naive Bayes after Standard Scaling is: 0.2680272108843537\n",
      "Confusion Matrix of Bernoulli Naive Bayes is:\n",
      " [[ 45   7   3  16  14  11 114]\n",
      " [  9  47   1  17  21  26  89]\n",
      " [ 12  18 109   7   9  11  44]\n",
      " [  8  13   0  23  18  22 126]\n",
      " [ 17  10   0  18  16  22 127]\n",
      " [ 14  19   1  14  15  25 122]\n",
      " [ 10   7   0  25  17  22 129]]\n",
      "Classification Report of Bernoulli Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.21      0.28       210\n",
      "           2       0.39      0.22      0.28       210\n",
      "           3       0.96      0.52      0.67       210\n",
      "           4       0.19      0.11      0.14       210\n",
      "           5       0.15      0.08      0.10       210\n",
      "           6       0.18      0.12      0.14       210\n",
      "           7       0.17      0.61      0.27       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.35      0.27      0.27      1470\n",
      "weighted avg       0.35      0.27      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: linear\n",
      "Accuracy of SVM after Standard Scaling is: 0.5\n",
      "Confusion Matrix of SVM is:\n",
      " [[117  19   7   7  18  28  14]\n",
      " [ 15 115  12  14  15  33   6]\n",
      " [  5  17 167   8   1  10   2]\n",
      " [ 23  27   6  61  14  65  14]\n",
      " [ 46  29   3  30  43  37  22]\n",
      " [ 17  29  10  15   8  92  39]\n",
      " [  7   6   1   5   4  47 140]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.56      0.53       210\n",
      "           2       0.48      0.55      0.51       210\n",
      "           3       0.81      0.80      0.80       210\n",
      "           4       0.44      0.29      0.35       210\n",
      "           5       0.42      0.20      0.27       210\n",
      "           6       0.29      0.44      0.35       210\n",
      "           7       0.59      0.67      0.63       210\n",
      "\n",
      "    accuracy                           0.50      1470\n",
      "   macro avg       0.50      0.50      0.49      1470\n",
      "weighted avg       0.50      0.50      0.49      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: poly\n",
      "Accuracy of SVM after Standard Scaling is: 0.5095238095238095\n",
      "Confusion Matrix of SVM is:\n",
      " [[117  22   5   7  19  26  14]\n",
      " [ 11 121  10  15  19  28   6]\n",
      " [  4  19 169   6   2   9   1]\n",
      " [ 20  27   6  66  17  60  14]\n",
      " [ 46  29   3  34  48  35  15]\n",
      " [ 20  29   8  18   7  93  35]\n",
      " [  7   7   1   6   3  51 135]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.56      0.54       210\n",
      "           2       0.48      0.58      0.52       210\n",
      "           3       0.84      0.80      0.82       210\n",
      "           4       0.43      0.31      0.36       210\n",
      "           5       0.42      0.23      0.30       210\n",
      "           6       0.31      0.44      0.36       210\n",
      "           7       0.61      0.64      0.63       210\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.52      0.51      0.50      1470\n",
      "weighted avg       0.52      0.51      0.50      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: rbf\n",
      "Accuracy of SVM after Standard Scaling is: 0.5217687074829932\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 99  27   8  13  22  27  14]\n",
      " [  4 124  11  21  18  28   4]\n",
      " [  2  28 168   3   0   9   0]\n",
      " [ 11  23   7  92  21  44  12]\n",
      " [ 22  30   5  34  80  26  13]\n",
      " [  7  29   6  26  13  90  39]\n",
      " [  2   4   0  16   9  65 114]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.47      0.55       210\n",
      "           2       0.47      0.59      0.52       210\n",
      "           3       0.82      0.80      0.81       210\n",
      "           4       0.45      0.44      0.44       210\n",
      "           5       0.49      0.38      0.43       210\n",
      "           6       0.31      0.43      0.36       210\n",
      "           7       0.58      0.54      0.56       210\n",
      "\n",
      "    accuracy                           0.52      1470\n",
      "   macro avg       0.54      0.52      0.53      1470\n",
      "weighted avg       0.54      0.52      0.53      1470\n",
      "\n",
      "======================================================================\n",
      "Working on SVM Kernal: sigmoid\n",
      "Accuracy of SVM after Standard Scaling is: 0.3795918367346939\n",
      "Confusion Matrix of SVM is:\n",
      " [[ 68  18  45   4  15   3  57]\n",
      " [  9  62  64  11  16   3  45]\n",
      " [ 16  14 172   0   2   1   5]\n",
      " [ 17  22  25  35  19   4  88]\n",
      " [ 20  27  15  11  42   1  94]\n",
      " [ 17  24  34  14  13   4 104]\n",
      " [  4   7   3  13   5   3 175]]\n",
      "Classification Report of SVM is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.32      0.38       210\n",
      "           2       0.36      0.30      0.32       210\n",
      "           3       0.48      0.82      0.61       210\n",
      "           4       0.40      0.17      0.23       210\n",
      "           5       0.38      0.20      0.26       210\n",
      "           6       0.21      0.02      0.03       210\n",
      "           7       0.31      0.83      0.45       210\n",
      "\n",
      "    accuracy                           0.38      1470\n",
      "   macro avg       0.37      0.38      0.33      1470\n",
      "weighted avg       0.37      0.38      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 1 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.22517006802721087\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0   0  13   0   0   0 197]\n",
      " [  0   0  16   0   0   0 194]\n",
      " [  0   0 123   0   0   0  87]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   3   0   0   0 207]\n",
      " [  0   0   5   0   0   0 205]\n",
      " [  0   0   2   0   0   0 208]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00       210\n",
      "           3       0.75      0.59      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.16      0.99      0.27       210\n",
      "\n",
      "    accuracy                           0.23      1470\n",
      "   macro avg       0.13      0.23      0.13      1470\n",
      "weighted avg       0.13      0.23      0.13      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 2 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.2653061224489796\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[  0  79  13   0   0   0 118]\n",
      " [  0  88  16   0   0   0 106]\n",
      " [  0  51 123   0   0   0  36]\n",
      " [  0  57   3   0   0   0 150]\n",
      " [  0  55   3   0   0   0 152]\n",
      " [  0  57   5   0   0   0 148]\n",
      " [  0  29   2   0   0   0 179]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.21      0.42      0.28       210\n",
      "           3       0.75      0.59      0.66       210\n",
      "           4       0.00      0.00      0.00       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.20      0.85      0.33       210\n",
      "\n",
      "    accuracy                           0.27      1470\n",
      "   macro avg       0.17      0.27      0.18      1470\n",
      "weighted avg       0.17      0.27      0.18      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 3 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.30680272108843537\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 42  45   5  96   0   0  22]\n",
      " [  8  80  16  96   0   0  10]\n",
      " [  4  47 123  30   0   0   6]\n",
      " [ 11  46   3 129   0   0  21]\n",
      " [ 19  36   3 118   0   0  34]\n",
      " [ 16  42   4 113   0   0  35]\n",
      " [ 12  17   2 102   0   0  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.20      0.26       210\n",
      "           2       0.26      0.38      0.31       210\n",
      "           3       0.79      0.59      0.67       210\n",
      "           4       0.19      0.61      0.29       210\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.37      0.37       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.28      0.31      0.27      1470\n",
      "weighted avg       0.28      0.31      0.27      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 4 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32108843537414966\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 50  46   4  79   9   0  22]\n",
      " [  3  86   8  95   8   0  10]\n",
      " [  0  52 118  30   4   0   6]\n",
      " [  5  49   0 127   8   0  21]\n",
      " [  7  39   0 116  14   0  34]\n",
      " [  9  43   3 111   9   0  35]\n",
      " [  0  19   0 102  12   0  77]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.24      0.35       210\n",
      "           2       0.26      0.41      0.32       210\n",
      "           3       0.89      0.56      0.69       210\n",
      "           4       0.19      0.60      0.29       210\n",
      "           5       0.22      0.07      0.10       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.37      0.37       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.37      0.32      0.30      1470\n",
      "weighted avg       0.37      0.32      0.30      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 5 max_depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\murth\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32789115646258504\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 50  43   6  57  38   0  16]\n",
      " [  6  81   7  65  40   1  10]\n",
      " [  0  39 122  29  10   4   6]\n",
      " [  4  48   0  89  52   0  17]\n",
      " [  6  38   0  64  74   0  28]\n",
      " [  5  48   3  78  46   0  30]\n",
      " [  0  19   0  74  51   0  66]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.24      0.36       210\n",
      "           2       0.26      0.39      0.31       210\n",
      "           3       0.88      0.58      0.70       210\n",
      "           4       0.20      0.42      0.27       210\n",
      "           5       0.24      0.35      0.28       210\n",
      "           6       0.00      0.00      0.00       210\n",
      "           7       0.38      0.31      0.34       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.38      0.33      0.32      1470\n",
      "weighted avg       0.38      0.33      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 6 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32040816326530613\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 55  34   5  56  29  20  11]\n",
      " [  7  74   9  62  36  13   9]\n",
      " [ 10  32 126  23   3  11   5]\n",
      " [  6  34   4  87  41  22  16]\n",
      " [ 16  29   2  63  57  16  27]\n",
      " [ 10  38   6  78  37  17  24]\n",
      " [ 10  12   3  71  36  23  55]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.26      0.34       210\n",
      "           2       0.29      0.35      0.32       210\n",
      "           3       0.81      0.60      0.69       210\n",
      "           4       0.20      0.41      0.27       210\n",
      "           5       0.24      0.27      0.25       210\n",
      "           6       0.14      0.08      0.10       210\n",
      "           7       0.37      0.26      0.31       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.36      0.32      0.33      1470\n",
      "weighted avg       0.36      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 7 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3258503401360544\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 63  60   1  46  13  21   6]\n",
      " [ 10  98   5  52  20  20   5]\n",
      " [  6  47 120  26   1   7   3]\n",
      " [ 12  59   1  93  20  17   8]\n",
      " [ 17  43   1  74  33  27  15]\n",
      " [ 15  53   4  80  14  26  18]\n",
      " [  5  28   0  84  12  35  46]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.30      0.37       210\n",
      "           2       0.25      0.47      0.33       210\n",
      "           3       0.91      0.57      0.70       210\n",
      "           4       0.20      0.44      0.28       210\n",
      "           5       0.29      0.16      0.20       210\n",
      "           6       0.17      0.12      0.14       210\n",
      "           7       0.46      0.22      0.30       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.40      0.33      0.33      1470\n",
      "weighted avg       0.40      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 8 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3258503401360544\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 83  34   3  32  23  24  11]\n",
      " [ 32  72  11  40  26  18  11]\n",
      " [ 18  28 128  22   8   4   2]\n",
      " [ 26  33   6  71  29  20  25]\n",
      " [ 34  32   4  48  44  29  19]\n",
      " [ 33  32   8  50  33  22  32]\n",
      " [ 26  15   1  40  41  28  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.40      0.36       210\n",
      "           2       0.29      0.34      0.32       210\n",
      "           3       0.80      0.61      0.69       210\n",
      "           4       0.23      0.34      0.28       210\n",
      "           5       0.22      0.21      0.21       210\n",
      "           6       0.15      0.10      0.12       210\n",
      "           7       0.37      0.28      0.32       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.34      0.33      0.33      1470\n",
      "weighted avg       0.34      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 9 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3129251700680272\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 72  44   6  26  28  21  13]\n",
      " [ 29  60  21  34  29  21  16]\n",
      " [ 18  21 128  15   7  16   5]\n",
      " [ 26  29   7  68  31  19  30]\n",
      " [ 29  32   1  41  54  26  27]\n",
      " [ 30  30   6  50  40  21  33]\n",
      " [ 21  18   1  43  45  25  57]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.34      0.33       210\n",
      "           2       0.26      0.29      0.27       210\n",
      "           3       0.75      0.61      0.67       210\n",
      "           4       0.25      0.32      0.28       210\n",
      "           5       0.23      0.26      0.24       210\n",
      "           6       0.14      0.10      0.12       210\n",
      "           7       0.31      0.27      0.29       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.32      1470\n",
      "weighted avg       0.32      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 10 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  29   6  28  23  32  17]\n",
      " [ 10  71   9  41  29  36  14]\n",
      " [ 18  24 124  11   4  22   7]\n",
      " [ 17  30   5  48  33  44  33]\n",
      " [ 17  29   3  31  55  47  28]\n",
      " [ 23  31   7  30  36  46  37]\n",
      " [ 24  13   1  37  32  39  64]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.36      0.38       210\n",
      "           2       0.31      0.34      0.32       210\n",
      "           3       0.80      0.59      0.68       210\n",
      "           4       0.21      0.23      0.22       210\n",
      "           5       0.26      0.26      0.26       210\n",
      "           6       0.17      0.22      0.19       210\n",
      "           7       0.32      0.30      0.31       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.36      0.33      0.34      1470\n",
      "weighted avg       0.36      0.33      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 11 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.319047619047619\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 60  31  11  30  26  35  17]\n",
      " [  9  56  23  31  36  43  12]\n",
      " [ 14  25 130   8   3  25   5]\n",
      " [ 15  26   6  57  29  53  24]\n",
      " [ 17  31   6  29  48  60  19]\n",
      " [ 19  34   9  28  37  51  32]\n",
      " [ 15  15   2  27  32  52  67]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.29      0.33       210\n",
      "           2       0.26      0.27      0.26       210\n",
      "           3       0.70      0.62      0.65       210\n",
      "           4       0.27      0.27      0.27       210\n",
      "           5       0.23      0.23      0.23       210\n",
      "           6       0.16      0.24      0.19       210\n",
      "           7       0.38      0.32      0.35       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.34      0.32      0.33      1470\n",
      "weighted avg       0.34      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 12 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3224489795918367\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 67  28  12  33  27  27  16]\n",
      " [ 14  58  23  36  29  38  12]\n",
      " [ 13  24 135  12   7  15   4]\n",
      " [ 11  25  14  65  26  41  28]\n",
      " [ 20  21   8  43  50  45  23]\n",
      " [ 19  32   9  36  36  45  33]\n",
      " [ 18  22   3  43  28  42  54]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.32      0.36       210\n",
      "           2       0.28      0.28      0.28       210\n",
      "           3       0.66      0.64      0.65       210\n",
      "           4       0.24      0.31      0.27       210\n",
      "           5       0.25      0.24      0.24       210\n",
      "           6       0.18      0.21      0.19       210\n",
      "           7       0.32      0.26      0.28       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.33      0.32      0.33      1470\n",
      "weighted avg       0.33      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 13 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree after Standard Scaling is: 0.32857142857142857\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  21  11  28  25  33  18]\n",
      " [ 19  57  28  33  23  36  14]\n",
      " [ 18  23 137  14   8   7   3]\n",
      " [ 20  28  13  57  22  41  29]\n",
      " [ 23  24   9  39  52  41  22]\n",
      " [ 17  29   8  37  31  45  43]\n",
      " [ 24  17   3  38  33  34  61]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.35      0.37       210\n",
      "           2       0.29      0.27      0.28       210\n",
      "           3       0.66      0.65      0.65       210\n",
      "           4       0.23      0.27      0.25       210\n",
      "           5       0.27      0.25      0.26       210\n",
      "           6       0.19      0.21      0.20       210\n",
      "           7       0.32      0.29      0.31       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.33      0.33      0.33      1470\n",
      "weighted avg       0.33      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 14 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.336734693877551\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  22  11  24  27  34  16]\n",
      " [ 15  70  15  26  25  39  20]\n",
      " [ 22  19 129  10   9  18   3]\n",
      " [ 22  43  10  50  27  35  23]\n",
      " [ 22  28  10  34  53  35  28]\n",
      " [ 22  24  11  31  30  50  42]\n",
      " [ 23  14   3  33  33  37  67]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.36      0.37       210\n",
      "           2       0.32      0.33      0.33       210\n",
      "           3       0.68      0.61      0.65       210\n",
      "           4       0.24      0.24      0.24       210\n",
      "           5       0.26      0.25      0.26       210\n",
      "           6       0.20      0.24      0.22       210\n",
      "           7       0.34      0.32      0.33       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.35      0.34      0.34      1470\n",
      "weighted avg       0.35      0.34      0.34      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 15 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3217687074829932\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 76  24  10  18  29  30  23]\n",
      " [ 21  70  16  25  22  33  23]\n",
      " [ 16  20 135  11   8  16   4]\n",
      " [ 18  36  12  43  21  50  30]\n",
      " [ 28  31   5  32  42  40  32]\n",
      " [ 28  27  11  31  28  43  42]\n",
      " [ 23  14   8  34  24  43  64]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.36      0.36       210\n",
      "           2       0.32      0.33      0.32       210\n",
      "           3       0.69      0.64      0.66       210\n",
      "           4       0.22      0.20      0.21       210\n",
      "           5       0.24      0.20      0.22       210\n",
      "           6       0.17      0.20      0.18       210\n",
      "           7       0.29      0.30      0.30       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.33      0.32      0.32      1470\n",
      "weighted avg       0.33      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 16 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.31564625850340133\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  28  14  21  20  36  17]\n",
      " [ 23  71  17  23  19  32  25]\n",
      " [ 17  21 129  12   9  19   3]\n",
      " [ 27  31  12  43  26  45  26]\n",
      " [ 33  26   6  35  44  36  30]\n",
      " [ 27  27   8  31  29  44  44]\n",
      " [ 22  19   5  33  25  47  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.35      0.34       210\n",
      "           2       0.32      0.34      0.33       210\n",
      "           3       0.68      0.61      0.64       210\n",
      "           4       0.22      0.20      0.21       210\n",
      "           5       0.26      0.21      0.23       210\n",
      "           6       0.17      0.21      0.19       210\n",
      "           7       0.29      0.28      0.29       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.32      0.32      0.32      1470\n",
      "weighted avg       0.32      0.32      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 17 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.32448979591836735\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 73  21  12  18  22  42  22]\n",
      " [ 22  70  16  18  33  33  18]\n",
      " [ 21  19 135   8  12  13   2]\n",
      " [ 29  37   6  37  30  40  31]\n",
      " [ 31  21   5  30  52  41  30]\n",
      " [ 29  31   8  26  24  48  44]\n",
      " [ 26  22   2  26  27  45  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.35      0.33       210\n",
      "           2       0.32      0.33      0.32       210\n",
      "           3       0.73      0.64      0.69       210\n",
      "           4       0.23      0.18      0.20       210\n",
      "           5       0.26      0.25      0.25       210\n",
      "           6       0.18      0.23      0.20       210\n",
      "           7       0.30      0.30      0.30       210\n",
      "\n",
      "    accuracy                           0.32      1470\n",
      "   macro avg       0.33      0.32      0.33      1470\n",
      "weighted avg       0.33      0.32      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 18 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3142857142857143\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 74  28  12  15  27  37  17]\n",
      " [ 17  64  11  27  36  36  19]\n",
      " [ 13  23 128  13  10  19   4]\n",
      " [ 31  38  10  35  30  39  27]\n",
      " [ 28  32   8  26  49  42  25]\n",
      " [ 28  31  10  19  30  50  42]\n",
      " [ 27  19   4  27  26  45  62]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.35       210\n",
      "           2       0.27      0.30      0.29       210\n",
      "           3       0.70      0.61      0.65       210\n",
      "           4       0.22      0.17      0.19       210\n",
      "           5       0.24      0.23      0.23       210\n",
      "           6       0.19      0.24      0.21       210\n",
      "           7       0.32      0.30      0.31       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.32      0.31      0.32      1470\n",
      "weighted avg       0.32      0.31      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 19 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.30952380952380953\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 66  21   9  20  24  36  34]\n",
      " [ 16  59  23  25  27  34  26]\n",
      " [ 21  20 141   8   7   8   5]\n",
      " [ 25  29   9  33  33  48  33]\n",
      " [ 34  26   4  26  52  36  32]\n",
      " [ 36  27   7  21  35  45  39]\n",
      " [ 34  19   1  23  30  44  59]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.31      0.30       210\n",
      "           2       0.29      0.28      0.29       210\n",
      "           3       0.73      0.67      0.70       210\n",
      "           4       0.21      0.16      0.18       210\n",
      "           5       0.25      0.25      0.25       210\n",
      "           6       0.18      0.21      0.20       210\n",
      "           7       0.26      0.28      0.27       210\n",
      "\n",
      "    accuracy                           0.31      1470\n",
      "   macro avg       0.31      0.31      0.31      1470\n",
      "weighted avg       0.31      0.31      0.31      1470\n",
      "\n",
      "======================================================================\n",
      "Decision Tree with 20 max_depth\n",
      "Accuracy of Decision Tree after Standard Scaling is: 0.3299319727891156\n",
      "Confusion Matrix of Decision Tree is:\n",
      " [[ 75  23  12  19  26  34  21]\n",
      " [ 19  71  16  25  29  28  22]\n",
      " [ 18  18 139   5   7  19   4]\n",
      " [ 26  30   8  37  30  44  35]\n",
      " [ 28  31   4  25  52  39  31]\n",
      " [ 20  32  13  20  38  46  41]\n",
      " [ 27  21   1  29  30  37  65]]\n",
      "Classification Report of Decision Tree is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.36      0.35       210\n",
      "           2       0.31      0.34      0.33       210\n",
      "           3       0.72      0.66      0.69       210\n",
      "           4       0.23      0.18      0.20       210\n",
      "           5       0.25      0.25      0.25       210\n",
      "           6       0.19      0.22      0.20       210\n",
      "           7       0.30      0.31      0.30       210\n",
      "\n",
      "    accuracy                           0.33      1470\n",
      "   macro avg       0.34      0.33      0.33      1470\n",
      "weighted avg       0.34      0.33      0.33      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 1 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.2755102040816326\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[  6  18  37   2  21   1 125]\n",
      " [  3  25  61   9  12   2  98]\n",
      " [  1  14 168   3   2   0  22]\n",
      " [  4  12  26   8  11   3 146]\n",
      " [  2   8  14   8  12   0 166]\n",
      " [  1  18  29   6   7   6 143]\n",
      " [  2   4   2   5  11   6 180]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.03      0.05       210\n",
      "           2       0.25      0.12      0.16       210\n",
      "           3       0.50      0.80      0.61       210\n",
      "           4       0.20      0.04      0.06       210\n",
      "           5       0.16      0.06      0.08       210\n",
      "           6       0.33      0.03      0.05       210\n",
      "           7       0.20      0.86      0.33       210\n",
      "\n",
      "    accuracy                           0.28      1470\n",
      "   macro avg       0.28      0.28      0.19      1470\n",
      "weighted avg       0.28      0.28      0.19      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 2 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.33537414965986395\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 38  54  21   4  13   2  78]\n",
      " [  5 101  35   6   9   1  53]\n",
      " [  8  37 152   4   2   0   7]\n",
      " [ 12  68   9  12   9   2  98]\n",
      " [  8  41  10  14  18   2 117]\n",
      " [ 10  66  10   5   4   6 109]\n",
      " [  2  24   0   6   7   5 166]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.18      0.26       210\n",
      "           2       0.26      0.48      0.34       210\n",
      "           3       0.64      0.72      0.68       210\n",
      "           4       0.24      0.06      0.09       210\n",
      "           5       0.29      0.09      0.13       210\n",
      "           6       0.33      0.03      0.05       210\n",
      "           7       0.26      0.79      0.40       210\n",
      "\n",
      "    accuracy                           0.34      1470\n",
      "   macro avg       0.35      0.34      0.28      1470\n",
      "weighted avg       0.35      0.34      0.28      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 3 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3585034013605442\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 59  69   7  16  11   2  46]\n",
      " [  8 135  13   6   7   8  33]\n",
      " [  8  45 148   2   5   0   2]\n",
      " [ 17  84   5  16  13   9  66]\n",
      " [ 30  49   6  18  27   7  73]\n",
      " [ 15  79   3  18  10   6  79]\n",
      " [  3  31   0  21  12   7 136]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.28      0.34       210\n",
      "           2       0.27      0.64      0.38       210\n",
      "           3       0.81      0.70      0.76       210\n",
      "           4       0.16      0.08      0.10       210\n",
      "           5       0.32      0.13      0.18       210\n",
      "           6       0.15      0.03      0.05       210\n",
      "           7       0.31      0.65      0.42       210\n",
      "\n",
      "    accuracy                           0.36      1470\n",
      "   macro avg       0.35      0.36      0.32      1470\n",
      "weighted avg       0.35      0.36      0.32      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 4 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.3979591836734694\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 78  60   7  10  15   2  38]\n",
      " [ 10 138  10   8  20   2  22]\n",
      " [  7  46 148   3   4   1   1]\n",
      " [ 17  78   5  22  30   7  51]\n",
      " [ 18  64   2  13  57   0  56]\n",
      " [ 17  85   3  11  20  12  62]\n",
      " [  9  36   0  12  15   8 130]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.37      0.43       210\n",
      "           2       0.27      0.66      0.38       210\n",
      "           3       0.85      0.70      0.77       210\n",
      "           4       0.28      0.10      0.15       210\n",
      "           5       0.35      0.27      0.31       210\n",
      "           6       0.38      0.06      0.10       210\n",
      "           7       0.36      0.62      0.46       210\n",
      "\n",
      "    accuracy                           0.40      1470\n",
      "   macro avg       0.43      0.40      0.37      1470\n",
      "weighted avg       0.43      0.40      0.37      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 5 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.408843537414966\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 72  53   9  10  23   5  38]\n",
      " [  6 132  16  13  23   2  18]\n",
      " [  9  38 151   6   5   0   1]\n",
      " [ 10  68   4  39  38  11  40]\n",
      " [ 16  51   4  20  68   8  43]\n",
      " [ 11  70   4  22  25  12  66]\n",
      " [  1  23   0  32  15  12 127]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.34      0.43       210\n",
      "           2       0.30      0.63      0.41       210\n",
      "           3       0.80      0.72      0.76       210\n",
      "           4       0.27      0.19      0.22       210\n",
      "           5       0.35      0.32      0.33       210\n",
      "           6       0.24      0.06      0.09       210\n",
      "           7       0.38      0.60      0.47       210\n",
      "\n",
      "    accuracy                           0.41      1470\n",
      "   macro avg       0.42      0.41      0.39      1470\n",
      "weighted avg       0.42      0.41      0.39      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 6 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4238095238095238\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 79  42   4  18  28   7  32]\n",
      " [ 11 125   8  21  20  11  14]\n",
      " [ 14  37 150   3   2   2   2]\n",
      " [ 12  56   3  47  35  14  43]\n",
      " [ 19  44   1  30  64  10  42]\n",
      " [ 14  63   0  25  24  24  60]\n",
      " [  7  12   0  28  13  16 134]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.38      0.43       210\n",
      "           2       0.33      0.60      0.42       210\n",
      "           3       0.90      0.71      0.80       210\n",
      "           4       0.27      0.22      0.25       210\n",
      "           5       0.34      0.30      0.32       210\n",
      "           6       0.29      0.11      0.16       210\n",
      "           7       0.41      0.64      0.50       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.41      1470\n",
      "weighted avg       0.44      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 7 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  45   4  10  22   8  31]\n",
      " [  9 133   6  18  15  11  18]\n",
      " [  9  42 149   5   3   0   2]\n",
      " [ 13  60   3  43  28  21  42]\n",
      " [ 19  53   2  19  64  11  42]\n",
      " [ 13  63   2  31  22  25  54]\n",
      " [ 10  18   0  25  18  23 116]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.43      0.48       210\n",
      "           2       0.32      0.63      0.43       210\n",
      "           3       0.90      0.71      0.79       210\n",
      "           4       0.28      0.20      0.24       210\n",
      "           5       0.37      0.30      0.34       210\n",
      "           6       0.25      0.12      0.16       210\n",
      "           7       0.38      0.55      0.45       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.44      0.42      0.41      1470\n",
      "weighted avg       0.44      0.42      0.41      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 8 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4272108843537415\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  42   8  14  20   7  27]\n",
      " [  7 121   8  23  18  18  15]\n",
      " [  5  48 144   5   3   4   1]\n",
      " [  7  44   5  52  40  28  34]\n",
      " [ 20  45   3  31  62  15  34]\n",
      " [ 10  57   1  35  21  35  51]\n",
      " [  7  17   0  27  13  24 122]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.44      0.51       210\n",
      "           2       0.32      0.58      0.41       210\n",
      "           3       0.85      0.69      0.76       210\n",
      "           4       0.28      0.25      0.26       210\n",
      "           5       0.35      0.30      0.32       210\n",
      "           6       0.27      0.17      0.21       210\n",
      "           7       0.43      0.58      0.49       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.42      1470\n",
      "weighted avg       0.45      0.43      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 9 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4326530612244898\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 85  29   9  25  31  12  19]\n",
      " [  8 119   7  24  26  13  13]\n",
      " [  8  35 152   7   2   5   1]\n",
      " [  6  42   5  57  37  32  31]\n",
      " [ 18  38   4  30  74  16  30]\n",
      " [ 11  45   1  36  30  35  52]\n",
      " [  4  10   1  31  18  32 114]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.40      0.49       210\n",
      "           2       0.37      0.57      0.45       210\n",
      "           3       0.85      0.72      0.78       210\n",
      "           4       0.27      0.27      0.27       210\n",
      "           5       0.34      0.35      0.35       210\n",
      "           6       0.24      0.17      0.20       210\n",
      "           7       0.44      0.54      0.49       210\n",
      "\n",
      "    accuracy                           0.43      1470\n",
      "   macro avg       0.45      0.43      0.43      1470\n",
      "weighted avg       0.45      0.43      0.43      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 10 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 93  30   8  20  27  10  22]\n",
      " [  8 128   6  20  23  16   9]\n",
      " [  6  37 150   7   4   5   1]\n",
      " [ 11  40   3  64  30  28  34]\n",
      " [ 23  39   3  26  71  16  32]\n",
      " [ 13  41   2  36  34  35  49]\n",
      " [  9   9   0  28  24  33 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.44      0.50       210\n",
      "           2       0.40      0.61      0.48       210\n",
      "           3       0.87      0.71      0.79       210\n",
      "           4       0.32      0.30      0.31       210\n",
      "           5       0.33      0.34      0.34       210\n",
      "           6       0.24      0.17      0.20       210\n",
      "           7       0.42      0.51      0.46       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 11 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4217687074829932\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 87  32   7  25  36   8  15]\n",
      " [  9 113  14  23  23  16  12]\n",
      " [  8  33 153   9   2   3   2]\n",
      " [ 10  38   5  68  30  28  31]\n",
      " [ 25  35   5  34  66  17  28]\n",
      " [ 18  43   6  42  26  30  45]\n",
      " [  8   8   0  31  25  35 103]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.41      0.46       210\n",
      "           2       0.37      0.54      0.44       210\n",
      "           3       0.81      0.73      0.76       210\n",
      "           4       0.29      0.32      0.31       210\n",
      "           5       0.32      0.31      0.32       210\n",
      "           6       0.22      0.14      0.17       210\n",
      "           7       0.44      0.49      0.46       210\n",
      "\n",
      "    accuracy                           0.42      1470\n",
      "   macro avg       0.42      0.42      0.42      1470\n",
      "weighted avg       0.42      0.42      0.42      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 12 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44081632653061226\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 84  32   9  21  33  15  16]\n",
      " [ 11 122  12  22  20  13  10]\n",
      " [ 12  28 153   9   4   3   1]\n",
      " [ 15  40   4  69  32  27  23]\n",
      " [ 24  36   3  39  68  14  26]\n",
      " [ 16  38   2  34  27  50  43]\n",
      " [ 10   9   1  30  28  30 102]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.40      0.44       210\n",
      "           2       0.40      0.58      0.47       210\n",
      "           3       0.83      0.73      0.78       210\n",
      "           4       0.31      0.33      0.32       210\n",
      "           5       0.32      0.32      0.32       210\n",
      "           6       0.33      0.24      0.28       210\n",
      "           7       0.46      0.49      0.47       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 13 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.46530612244897956\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95  27   7  24  25  13  19]\n",
      " [  5 123   9  23  25  17   8]\n",
      " [ 10  26 156   9   1   7   1]\n",
      " [ 11  32   3  69  31  38  26]\n",
      " [ 21  37   3  32  76  15  26]\n",
      " [ 16  34   4  41  27  51  37]\n",
      " [  7  10   0  25  19  35 114]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.45      0.51       210\n",
      "           2       0.43      0.59      0.49       210\n",
      "           3       0.86      0.74      0.80       210\n",
      "           4       0.31      0.33      0.32       210\n",
      "           5       0.37      0.36      0.37       210\n",
      "           6       0.29      0.24      0.26       210\n",
      "           7       0.49      0.54      0.52       210\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.47      0.47      0.47      1470\n",
      "weighted avg       0.47      0.47      0.47      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 14 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44285714285714284\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 95  26   7  22  30  17  13]\n",
      " [ 15 116   7  25  21  20   6]\n",
      " [  8  31 153   5   5   7   1]\n",
      " [ 12  36   4  55  35  42  26]\n",
      " [ 19  38   3  33  77  18  22]\n",
      " [ 17  36   2  42  26  47  40]\n",
      " [  7  10   0  26  21  38 108]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.45      0.50       210\n",
      "           2       0.40      0.55      0.46       210\n",
      "           3       0.87      0.73      0.79       210\n",
      "           4       0.26      0.26      0.26       210\n",
      "           5       0.36      0.37      0.36       210\n",
      "           6       0.25      0.22      0.24       210\n",
      "           7       0.50      0.51      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.46      0.44      0.45      1470\n",
      "weighted avg       0.46      0.44      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 15 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4564625850340136\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 92  26   7  24  28  15  18]\n",
      " [ 13 124  11  20  18  19   5]\n",
      " [  8  26 157  12   2   4   1]\n",
      " [ 16  36   4  64  34  33  23]\n",
      " [ 20  33   5  32  74  22  24]\n",
      " [ 17  46   5  31  25  48  38]\n",
      " [ 10   6   0  24  17  41 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.44      0.48       210\n",
      "           2       0.42      0.59      0.49       210\n",
      "           3       0.83      0.75      0.79       210\n",
      "           4       0.31      0.30      0.31       210\n",
      "           5       0.37      0.35      0.36       210\n",
      "           6       0.26      0.23      0.24       210\n",
      "           7       0.51      0.53      0.52       210\n",
      "\n",
      "    accuracy                           0.46      1470\n",
      "   macro avg       0.46      0.46      0.46      1470\n",
      "weighted avg       0.46      0.46      0.46      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 16 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.45102040816326533\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 90  30   9  21  34  11  15]\n",
      " [  7 127   5  23  20  19   9]\n",
      " [  7  32 156   6   3   6   0]\n",
      " [ 16  32   8  64  32  33  25]\n",
      " [ 23  31   5  37  69  22  23]\n",
      " [ 12  43   6  32  27  49  41]\n",
      " [  7  10   0  30  18  37 108]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.43      0.48       210\n",
      "           2       0.42      0.60      0.49       210\n",
      "           3       0.83      0.74      0.78       210\n",
      "           4       0.30      0.30      0.30       210\n",
      "           5       0.34      0.33      0.33       210\n",
      "           6       0.28      0.23      0.25       210\n",
      "           7       0.49      0.51      0.50       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.46      0.45      0.45      1470\n",
      "weighted avg       0.46      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 17 max_depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest after Standard Scaling is: 0.4421768707482993\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 89  36   6  26  25  15  13]\n",
      " [ 14 123   8  15  25  20   5]\n",
      " [  7  29 157  10   3   3   1]\n",
      " [ 20  26   6  66  31  35  26]\n",
      " [ 29  35   3  30  60  28  25]\n",
      " [ 19  36   6  37  25  46  41]\n",
      " [ 13   9   0  27  18  34 109]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.42      0.44       210\n",
      "           2       0.42      0.59      0.49       210\n",
      "           3       0.84      0.75      0.79       210\n",
      "           4       0.31      0.31      0.31       210\n",
      "           5       0.32      0.29      0.30       210\n",
      "           6       0.25      0.22      0.24       210\n",
      "           7       0.50      0.52      0.51       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.44      0.44      0.44      1470\n",
      "weighted avg       0.44      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 18 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.44421768707482995\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94  27   6  16  22  26  19]\n",
      " [ 10 124  11  19  20  20   6]\n",
      " [  9  28 157   8   2   6   0]\n",
      " [ 21  35   4  70  31  26  23]\n",
      " [ 29  39   2  28  61  28  23]\n",
      " [ 18  41   3  46  17  40  45]\n",
      " [  8  13   0  28  20  34 107]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.45      0.47       210\n",
      "           2       0.40      0.59      0.48       210\n",
      "           3       0.86      0.75      0.80       210\n",
      "           4       0.33      0.33      0.33       210\n",
      "           5       0.35      0.29      0.32       210\n",
      "           6       0.22      0.19      0.21       210\n",
      "           7       0.48      0.51      0.49       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 19 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4435374149659864\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 96  29   5  13  27  20  20]\n",
      " [ 10 115   8  22  18  27  10]\n",
      " [  6  35 157   4   3   4   1]\n",
      " [ 15  37   7  61  22  40  28]\n",
      " [ 27  34   4  40  63  16  26]\n",
      " [ 16  49   3  25  25  48  44]\n",
      " [ 10  10   0  20  17  41 112]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.46      0.49       210\n",
      "           2       0.37      0.55      0.44       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.33      0.29      0.31       210\n",
      "           5       0.36      0.30      0.33       210\n",
      "           6       0.24      0.23      0.24       210\n",
      "           7       0.46      0.53      0.50       210\n",
      "\n",
      "    accuracy                           0.44      1470\n",
      "   macro avg       0.45      0.44      0.44      1470\n",
      "weighted avg       0.45      0.44      0.44      1470\n",
      "\n",
      "======================================================================\n",
      "Random Forest with 20 max_depth\n",
      "Accuracy of Random Forest after Standard Scaling is: 0.4489795918367347\n",
      "Confusion Matrix of Random Forest is:\n",
      " [[ 94  30   6  19  25  19  17]\n",
      " [ 11 129   8  20  17  19   6]\n",
      " [  4  31 158   9   3   4   1]\n",
      " [ 10  36   5  66  31  35  27]\n",
      " [ 28  38   4  30  62  30  18]\n",
      " [ 21  40   5  26  23  48  47]\n",
      " [ 11  10   0  24  19  43 103]]\n",
      "Classification Report of Random Forest is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.45      0.48       210\n",
      "           2       0.41      0.61      0.49       210\n",
      "           3       0.85      0.75      0.80       210\n",
      "           4       0.34      0.31      0.33       210\n",
      "           5       0.34      0.30      0.32       210\n",
      "           6       0.24      0.23      0.24       210\n",
      "           7       0.47      0.49      0.48       210\n",
      "\n",
      "    accuracy                           0.45      1470\n",
      "   macro avg       0.45      0.45      0.45      1470\n",
      "weighted avg       0.45      0.45      0.45      1470\n",
      "\n",
      "======================================================================\n",
      "Accuracy of Multinomial Naive Bayes after Standard Scaling is: 0.3925170068027211\n",
      "Confusion Matrix of Multinomial Naive Bayes is:\n",
      " [[ 89  50   9  11  21   6  24]\n",
      " [ 16 106  31  17  19   7  14]\n",
      " [ 18  46 141   2   2   0   1]\n",
      " [ 23  55   7  40  29  21  35]\n",
      " [ 26  49   4  17  73   6  35]\n",
      " [ 23  64   5  24  25  19  50]\n",
      " [ 14  22   0  24  22  19 109]]\n",
      "Classification Report of Multinomial Naive Bayes is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.42      0.42       210\n",
      "           2       0.27      0.50      0.35       210\n",
      "           3       0.72      0.67      0.69       210\n",
      "           4       0.30      0.19      0.23       210\n",
      "           5       0.38      0.35      0.36       210\n",
      "           6       0.24      0.09      0.13       210\n",
      "           7       0.41      0.52      0.46       210\n",
      "\n",
      "    accuracy                           0.39      1470\n",
      "   macro avg       0.39      0.39      0.38      1470\n",
      "weighted avg       0.39      0.39      0.38      1470\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# XLM vectorized data\n",
    "x_df = pd.read_csv(pwd+\"//Datasets//Nisha//FineTunedTransformers//xlm_base_finetuned_vectorized_Nisha_dataset.csv\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = minmax_scaling(x_df,labels_df['Labels'])\n",
    "\n",
    "# Logistic regression\n",
    "tv_lr_model = LogisticRegression(max_iter=5000)\n",
    "ml_training(tv_lr_model,x_train,x_test,y_train,y_test,\"Logistic Regression\")\n",
    "\n",
    "# KNN Model\n",
    "neighbors_list = [3, 4, 5, 6, 7, 8]\n",
    "for x in neighbors_list:\n",
    "    print(\"KNN with\",x,\"Neighbors\")\n",
    "    tv_knn_model = KNeighborsClassifier(n_neighbors=x)\n",
    "    ml_training(tv_knn_model,x_train,x_test,y_train,y_test,\"KNN Model\")\n",
    "    \n",
    "# Gaussian Naive Bayes\n",
    "tv_gnb_model = GaussianNB()\n",
    "ml_training(tv_gnb_model,x_train,x_test,y_train,y_test,\"Gaussian Naive Bayes\")\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "tv_bnb_model = BernoulliNB()\n",
    "ml_training(tv_bnb_model,x_train,x_test,y_train,y_test,\"Bernoulli Naive Bayes\")\n",
    "\n",
    "# Support Vector Machine Classifier\n",
    "svm_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for a_kernel in svm_kernels:\n",
    "    print(\"Working on SVM Kernal:\", a_kernel)\n",
    "    tv_svm_model = svm.SVC(kernel=a_kernel)\n",
    "    ml_training(tv_svm_model,x_train,x_test,y_train,y_test,\"SVM\")\n",
    "\n",
    "# Decision Tree Classifier\n",
    "for x in range(1,21):\n",
    "    print(\"Decision Tree with\",x,\"max_depth\")\n",
    "    tv_dt_model = DecisionTreeClassifier(random_state=3, max_depth=x)\n",
    "    ml_training(tv_dt_model,x_train,x_test,y_train,y_test,\"Decision Tree\")\n",
    "    \n",
    "# Random Forest\n",
    "for x in range(1,21):\n",
    "    print(\"Random Forest with\",x,\"max_depth\")\n",
    "    tv_rf_model = RandomForestClassifier(max_depth=x, random_state=3)\n",
    "    ml_training(tv_rf_model,x_train,x_test,y_train,y_test,\"Random Forest\")\n",
    "    \n",
    "# Multinomial Naive Bayes\n",
    "tv_mnb_model = MultinomialNB()\n",
    "ml_training(tv_mnb_model,x_train,x_test,y_train,y_test,\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
